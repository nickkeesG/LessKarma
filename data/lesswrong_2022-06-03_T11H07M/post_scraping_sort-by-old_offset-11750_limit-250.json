{"results": [{"createdAt": null, "postedAt": "2014-12-01T08:26:06.039Z", "modifiedAt": null, "url": null, "title": "December 2014 Media Thread", "slug": "december-2014-media-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:31.574Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RcBfsMvL32sYvPnnm/december-2014-media-thread", "pageUrlRelative": "/posts/RcBfsMvL32sYvPnnm/december-2014-media-thread", "linkUrl": "https://www.lesswrong.com/posts/RcBfsMvL32sYvPnnm/december-2014-media-thread", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20December%202014%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADecember%202014%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRcBfsMvL32sYvPnnm%2Fdecember-2014-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=December%202014%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRcBfsMvL32sYvPnnm%2Fdecember-2014-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRcBfsMvL32sYvPnnm%2Fdecember-2014-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<p>This is the monthly thread for posting media of various types that you've found that you enjoy. Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing! To see previous recommendations, check out the <a href=\"/r/discussion/tag/media_thread/\">older threads</a>.</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a <a href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please post only under one of the already created subthreads, and never directly under the parent media thread.</li>\n<li>Use the \"Other Media\" thread if you believe the piece of media you want to discuss doesn't fit under any of the established categories.</li>\n<li>Use the \"Meta\" thread if you want to discuss about the monthly media thread itself (e.g. to propose adding/removing/splitting/merging subthreads, or to discuss the type of content properly belonging to each subthread) or for any other question or issue you may have about the thread or the rules.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RcBfsMvL32sYvPnnm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 2.225457321741873e-06, "legacy": true, "legacyId": "27646", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 91, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T08:29:02.166Z", "modifiedAt": null, "url": null, "title": "Open thread, Dec. 1 - Dec. 7, 2014", "slug": "open-thread-dec-1-dec-7-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:37.706Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MrMind", "createdAt": "2011-04-19T08:43:22.388Z", "isAdmin": false, "displayName": "MrMind"}, "userId": "LJ4br8GWFXetsXkM8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r2Zds5jy3dAaiFsPN/open-thread-dec-1-dec-7-2014", "pageUrlRelative": "/posts/r2Zds5jy3dAaiFsPN/open-thread-dec-1-dec-7-2014", "linkUrl": "https://www.lesswrong.com/posts/r2Zds5jy3dAaiFsPN/open-thread-dec-1-dec-7-2014", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20Dec.%201%20-%20Dec.%207%2C%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20Dec.%201%20-%20Dec.%207%2C%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2Zds5jy3dAaiFsPN%2Fopen-thread-dec-1-dec-7-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20Dec.%201%20-%20Dec.%207%2C%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2Zds5jy3dAaiFsPN%2Fopen-thread-dec-1-dec-7-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2Zds5jy3dAaiFsPN%2Fopen-thread-dec-1-dec-7-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 66, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px; font-weight: bold;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the list-of-threads page before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">3.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should be posted in Discussion, and not Main.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">4.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r2Zds5jy3dAaiFsPN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 2.225463671295579e-06, "legacy": true, "legacyId": "27647", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 346, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T15:58:30.302Z", "modifiedAt": null, "url": null, "title": "Meetup : London Social Meetup, 07/12/2014", "slug": "meetup-london-social-meetup-07-12-2014", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tenoke", "createdAt": "2012-04-10T21:37:29.739Z", "isAdmin": false, "displayName": "Tenoke"}, "userId": "CRSZPEg9dHyMspTzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/am2oB5jESJQYn65Xh/meetup-london-social-meetup-07-12-2014", "pageUrlRelative": "/posts/am2oB5jESJQYn65Xh/meetup-london-social-meetup-07-12-2014", "linkUrl": "https://www.lesswrong.com/posts/am2oB5jESJQYn65Xh/meetup-london-social-meetup-07-12-2014", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Social%20Meetup%2C%2007%2F12%2F2014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Social%20Meetup%2C%2007%2F12%2F2014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fam2oB5jESJQYn65Xh%2Fmeetup-london-social-meetup-07-12-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Social%20Meetup%2C%2007%2F12%2F2014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fam2oB5jESJQYn65Xh%2Fmeetup-london-social-meetup-07-12-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fam2oB5jESJQYn65Xh%2Fmeetup-london-social-meetup-07-12-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17k'>London Social Meetup, 07/12/2014</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 December 2014 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having another meetup this Sunday (07/12) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:</p>\n\n<p>We run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17k'>London Social Meetup, 07/12/2014</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "am2oB5jESJQYn65Xh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.2264362887810333e-06, "legacy": true, "legacyId": "27649", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Social_Meetup__07_12_2014\">Discussion article for the meetup : <a href=\"/meetups/17k\">London Social Meetup, 07/12/2014</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 December 2014 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having another meetup this Sunday (07/12) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:</p>\n\n<p>We run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_Social_Meetup__07_12_20141\">Discussion article for the meetup : <a href=\"/meetups/17k\">London Social Meetup, 07/12/2014</a></h2>", "sections": [{"title": "Discussion article for the meetup : London Social Meetup, 07/12/2014", "anchor": "Discussion_article_for_the_meetup___London_Social_Meetup__07_12_2014", "level": 1}, {"title": "Discussion article for the meetup : London Social Meetup, 07/12/2014", "anchor": "Discussion_article_for_the_meetup___London_Social_Meetup__07_12_20141", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T16:56:46.675Z", "modifiedAt": null, "url": null, "title": "[Need advice] Likely consequences of disclosing you have Asperger's Syndrome - given you have a 2.5 years gap in your resume?", "slug": "need-advice-likely-consequences-of-disclosing-you-have", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:05.479Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chemotaxis101", "createdAt": "2012-11-02T20:01:09.176Z", "isAdmin": false, "displayName": "chemotaxis101"}, "userId": "xjcwPGvZBi3aYfooc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DCxzCz5XnnFrgaCw5/need-advice-likely-consequences-of-disclosing-you-have", "pageUrlRelative": "/posts/DCxzCz5XnnFrgaCw5/need-advice-likely-consequences-of-disclosing-you-have", "linkUrl": "https://www.lesswrong.com/posts/DCxzCz5XnnFrgaCw5/need-advice-likely-consequences-of-disclosing-you-have", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BNeed%20advice%5D%20Likely%20consequences%20of%20disclosing%20you%20have%20Asperger's%20Syndrome%20-%20given%20you%20have%20a%202.5%20years%20gap%20in%20your%20resume%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BNeed%20advice%5D%20Likely%20consequences%20of%20disclosing%20you%20have%20Asperger's%20Syndrome%20-%20given%20you%20have%20a%202.5%20years%20gap%20in%20your%20resume%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDCxzCz5XnnFrgaCw5%2Fneed-advice-likely-consequences-of-disclosing-you-have%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BNeed%20advice%5D%20Likely%20consequences%20of%20disclosing%20you%20have%20Asperger's%20Syndrome%20-%20given%20you%20have%20a%202.5%20years%20gap%20in%20your%20resume%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDCxzCz5XnnFrgaCw5%2Fneed-advice-likely-consequences-of-disclosing-you-have", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDCxzCz5XnnFrgaCw5%2Fneed-advice-likely-consequences-of-disclosing-you-have", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 280, "htmlBody": "<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\"><strong style=\"margin: 0px; padding: 0px; border: 0px; vertical-align: baseline;\">Background</strong></p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">A few years ago I (was forced to) left grad school (halfway into it) because of complications related to a set of anxiety disorders (a typical comorbidity in Autism Spectrum Disorders; I now have a Master's degree in Electrical Engineering. I'm also planning to return to grad school next year).</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\"><span style=\"line-height: 18.2000007629395px;\">I have a family (2 children). Around the same time I left grad school, we received my daughter's diagnosis (she has more of a classical form of autism), followed by my own diagnosis.</span></p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">With regards to my professional record, after approx. 2.5 years in grad school and 2.5 years completely out of the job market, I finally began to work at a small consulting firm. They are aware of my daughter's autism, but they don't know of my own diagnosis.</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\"><strong style=\"margin: 0px; padding: 0px; border: 0px; vertical-align: baseline;\">NGO</strong></p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">I'm also vice-president of a local, small, autism-related NGO who is now trying to convince me to disclose my being on the autism spectrum (for publicity and awareness reasons). They are planning to arrange an interview for me at a TV channel. In fact, the decision was already made, as I'm effectively coming out of the closet on December 9th, by means of an interview on a local radio station.</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">I'm&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; vertical-align: baseline;\">enthusiasticaly</em>&nbsp;in favour of such a move (for both egoistic and altruistic reasons), but am also afraid of potential consequences on my future professional prospects. Also consider that it's likely that I will need a new work position very soon.</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">In summary, I'm only worried with the fact of also having a track record of being out of the job market for quite some time, so that I'm afraid some hiring manager could be tempted to negatively associate the gap in my resume to my condition.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DCxzCz5XnnFrgaCw5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 2.2265624420261063e-06, "legacy": true, "legacyId": "27650", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\"><strong style=\"margin: 0px; padding: 0px; border: 0px; vertical-align: baseline;\" id=\"Background\">Background</strong></p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">A few years ago I (was forced to) left grad school (halfway into it) because of complications related to a set of anxiety disorders (a typical comorbidity in Autism Spectrum Disorders; I now have a Master's degree in Electrical Engineering. I'm also planning to return to grad school next year).</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\"><span style=\"line-height: 18.2000007629395px;\">I have a family (2 children). Around the same time I left grad school, we received my daughter's diagnosis (she has more of a classical form of autism), followed by my own diagnosis.</span></p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">With regards to my professional record, after approx. 2.5 years in grad school and 2.5 years completely out of the job market, I finally began to work at a small consulting firm. They are aware of my daughter's autism, but they don't know of my own diagnosis.</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\"><strong style=\"margin: 0px; padding: 0px; border: 0px; vertical-align: baseline;\" id=\"NGO\">NGO</strong></p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">I'm also vice-president of a local, small, autism-related NGO who is now trying to convince me to disclose my being on the autism spectrum (for publicity and awareness reasons). They are planning to arrange an interview for me at a TV channel. In fact, the decision was already made, as I'm effectively coming out of the closet on December 9th, by means of an interview on a local radio station.</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">I'm&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; vertical-align: baseline;\">enthusiasticaly</em>&nbsp;in favour of such a move (for both egoistic and altruistic reasons), but am also afraid of potential consequences on my future professional prospects. Also consider that it's likely that I will need a new work position very soon.</p>\n<p style=\"margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 14px; vertical-align: baseline; clear: both; color: #444444; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 18.2000007629395px;\">In summary, I'm only worried with the fact of also having a track record of being out of the job market for quite some time, so that I'm afraid some hiring manager could be tempted to negatively associate the gap in my resume to my condition.</p>", "sections": [{"title": "Background", "anchor": "Background", "level": 1}, {"title": "NGO", "anchor": "NGO", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "10 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T18:04:56.293Z", "modifiedAt": null, "url": null, "title": "Integral versus differential ethics", "slug": "integral-versus-differential-ethics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:03.754Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fhkk75xKfqiqDnLBE/integral-versus-differential-ethics", "pageUrlRelative": "/posts/fhkk75xKfqiqDnLBE/integral-versus-differential-ethics", "linkUrl": "https://www.lesswrong.com/posts/fhkk75xKfqiqDnLBE/integral-versus-differential-ethics", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Integral%20versus%20differential%20ethics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntegral%20versus%20differential%20ethics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffhkk75xKfqiqDnLBE%2Fintegral-versus-differential-ethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Integral%20versus%20differential%20ethics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffhkk75xKfqiqDnLBE%2Fintegral-versus-differential-ethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffhkk75xKfqiqDnLBE%2Fintegral-versus-differential-ethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 628, "htmlBody": "<h2>In population ethics...</h2>\n<p>Most people start out believing that the following are true:</p>\n<ol>\n<li>That adding more happy lives is a net positive.</li>\n<li>That redistributing happiness more fairly is not a net negative.</li>\n<li>That the <a href=\"http://plato.stanford.edu/entries/repugnant-conclusion/\">repugnant conclusion</a> is indeed repugnant.</li>\n</ol>\n<p>Some will baulk on the first statement on equality grounds, but most people should accept those three statements as presented. Then they find out about the <a href=\"http://en.wikipedia.org/wiki/Mere_addition_paradox\">mere addition paradox</a>.</p>\n<p><img src=\"http://images.lesswrong.com/t3_lc0_0.png?v=4a298fb26d94ed7f95d879f6a8b240f8\" alt=\"\" width=\"500\" height=\"200\" /></p>\n<p>Someone who then accepts the repugnant could then reason something like this:</p>\n<blockquote>\n<p>Adding happy people and redistributing fairly happiness, if done many, many times, in the way described above, will result in a repugnant conclusion. Each step along the way seems solid, but the conclusion seems wrong. <em>Therefore I will <strong>accept</strong> the repugnant conclusion, not on its own merits, but because each step is clearly intuitively correct.</em></p>\n</blockquote>\n<p>Call this the \"differential\" (or local) way or reasoning about population ethics. As long as each small change seems intuitively an improvement, then the global change must also be.</p>\n<blockquote>\n<p>Adding happy people and redistributing fairly happiness, if done many, many times, in the way described above, will result in a repugnant conclusion. Each step along the way seems solid, but the conclusion seems wrong.&nbsp;<em>Therefore I will <strong>reject</strong> (at least) one step, not on its own merits, but because the conclusion is clearly intuitively incorrect.</em></p>\n</blockquote>\n<p>Call this the \"integral\" (or global) way of reasoning about population ethics. As long as the overall change seems intuitively a deterioration, then some of the small changes along the way must also be.</p>\n<p>&nbsp;</p>\n<h2>In general...</h2>\n<p>Now, I personally tend towards integral rather than differential reasoning on this particular topic. However, I want to make a more general point: philosophy may be over dedicated to differential reasoning. Mainly because it's easy: you can take things apart, simplify them, abstract details away, and appeal to simple principles - and avoid many potential biases along the way.</p>\n<p>But it's also a very destructive tool to use in areas where concepts are unclear and cannot easily be made clear. Take the statement \"human life is valuable\". This can be taken apart quite easily, critiqued from all directions, its lack of easily described meaning its weakness. Nevertheless, integral reasoning is almost always applied: something called \"human life\" is taken to be \"valuable\", and many caveats and subdefinitions can be added to these terms without changing the fundamental (integral) acceptance of the statement. If we followed the differential approach, we might end up with the definition of \"human life\" as \"energy exchange across a neurone cell membrane\" or something equally ridiculous but much more rigorous.</p>\n<p>Now, that example is a parody... but only because no-one sensible does that, we know that we'd lose too much value from that kind of definition. We want to build an extensive/integral definition of life, using our analysis to add clarity rather than simplify to a few core underlying concepts. But in population ethics and many other cases, we do feel free to use differential ethics, replacing vague overarching concepts with clear simplified versions <em>that clearly throw away a lot of the initial concept</em>.</p>\n<p>Maybe we do it too much. To pick an example I disagree with (always a good habit), maybe there is such a thing as \"society\", for instance, not simply the total of individuals and their interactions. You can already use pretty crude consequentialist arguments with \"societies\" as agents subject to predictable actions and reactions (social science does it all the time), but what if we tried to build a rigorous definition of society as something morally valuable, rather than focusing on individual?</p>\n<p>Anyway, we should be aware when, in arguments, we are keeping the broad goal and making the small steps and definitions conform to it, and when we are focusing on the small steps and definitions and following them wherever they lead.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fhkk75xKfqiqDnLBE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 6.4e-05, "legacy": true, "legacyId": "27648", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"In_population_ethics___\">In population ethics...</h2>\n<p>Most people start out believing that the following are true:</p>\n<ol>\n<li>That adding more happy lives is a net positive.</li>\n<li>That redistributing happiness more fairly is not a net negative.</li>\n<li>That the <a href=\"http://plato.stanford.edu/entries/repugnant-conclusion/\">repugnant conclusion</a> is indeed repugnant.</li>\n</ol>\n<p>Some will baulk on the first statement on equality grounds, but most people should accept those three statements as presented. Then they find out about the <a href=\"http://en.wikipedia.org/wiki/Mere_addition_paradox\">mere addition paradox</a>.</p>\n<p><img src=\"http://images.lesswrong.com/t3_lc0_0.png?v=4a298fb26d94ed7f95d879f6a8b240f8\" alt=\"\" width=\"500\" height=\"200\"></p>\n<p>Someone who then accepts the repugnant could then reason something like this:</p>\n<blockquote>\n<p>Adding happy people and redistributing fairly happiness, if done many, many times, in the way described above, will result in a repugnant conclusion. Each step along the way seems solid, but the conclusion seems wrong. <em>Therefore I will <strong>accept</strong> the repugnant conclusion, not on its own merits, but because each step is clearly intuitively correct.</em></p>\n</blockquote>\n<p>Call this the \"differential\" (or local) way or reasoning about population ethics. As long as each small change seems intuitively an improvement, then the global change must also be.</p>\n<blockquote>\n<p>Adding happy people and redistributing fairly happiness, if done many, many times, in the way described above, will result in a repugnant conclusion. Each step along the way seems solid, but the conclusion seems wrong.&nbsp;<em>Therefore I will <strong>reject</strong> (at least) one step, not on its own merits, but because the conclusion is clearly intuitively incorrect.</em></p>\n</blockquote>\n<p>Call this the \"integral\" (or global) way of reasoning about population ethics. As long as the overall change seems intuitively a deterioration, then some of the small changes along the way must also be.</p>\n<p>&nbsp;</p>\n<h2 id=\"In_general___\">In general...</h2>\n<p>Now, I personally tend towards integral rather than differential reasoning on this particular topic. However, I want to make a more general point: philosophy may be over dedicated to differential reasoning. Mainly because it's easy: you can take things apart, simplify them, abstract details away, and appeal to simple principles - and avoid many potential biases along the way.</p>\n<p>But it's also a very destructive tool to use in areas where concepts are unclear and cannot easily be made clear. Take the statement \"human life is valuable\". This can be taken apart quite easily, critiqued from all directions, its lack of easily described meaning its weakness. Nevertheless, integral reasoning is almost always applied: something called \"human life\" is taken to be \"valuable\", and many caveats and subdefinitions can be added to these terms without changing the fundamental (integral) acceptance of the statement. If we followed the differential approach, we might end up with the definition of \"human life\" as \"energy exchange across a neurone cell membrane\" or something equally ridiculous but much more rigorous.</p>\n<p>Now, that example is a parody... but only because no-one sensible does that, we know that we'd lose too much value from that kind of definition. We want to build an extensive/integral definition of life, using our analysis to add clarity rather than simplify to a few core underlying concepts. But in population ethics and many other cases, we do feel free to use differential ethics, replacing vague overarching concepts with clear simplified versions <em>that clearly throw away a lot of the initial concept</em>.</p>\n<p>Maybe we do it too much. To pick an example I disagree with (always a good habit), maybe there is such a thing as \"society\", for instance, not simply the total of individuals and their interactions. You can already use pretty crude consequentialist arguments with \"societies\" as agents subject to predictable actions and reactions (social science does it all the time), but what if we tried to build a rigorous definition of society as something morally valuable, rather than focusing on individual?</p>\n<p>Anyway, we should be aware when, in arguments, we are keeping the broad goal and making the small steps and definitions conform to it, and when we are focusing on the small steps and definitions and following them wherever they lead.</p>", "sections": [{"title": "In population ethics...", "anchor": "In_population_ethics___", "level": 1}, {"title": "In general...", "anchor": "In_general___", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "44 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T19:41:52.405Z", "modifiedAt": null, "url": null, "title": "The cryopreservation of bad people", "slug": "the-cryopreservation-of-bad-people", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:36.329Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "polymathwannabe", "createdAt": "2013-08-29T03:03:37.800Z", "isAdmin": false, "displayName": "polymathwannabe"}, "userId": "NkxHWoA85iw2PpxSt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JWqD9LS5DL3b9Sbgi/the-cryopreservation-of-bad-people", "pageUrlRelative": "/posts/JWqD9LS5DL3b9Sbgi/the-cryopreservation-of-bad-people", "linkUrl": "https://www.lesswrong.com/posts/JWqD9LS5DL3b9Sbgi/the-cryopreservation-of-bad-people", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20cryopreservation%20of%20bad%20people&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20cryopreservation%20of%20bad%20people%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJWqD9LS5DL3b9Sbgi%2Fthe-cryopreservation-of-bad-people%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20cryopreservation%20of%20bad%20people%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJWqD9LS5DL3b9Sbgi%2Fthe-cryopreservation-of-bad-people", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJWqD9LS5DL3b9Sbgi%2Fthe-cryopreservation-of-bad-people", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<p>This month's media thread includes a short article on some people's idea to have Ayn Rand frozen, which ultimately didn't happen. My first reaction was a shudder. I thought, <em>I definitely wouldn't want Ayn Rand preserved forever</em>. My second thought was, <em>What right do I have to say who can and who can't get frozen?</em><br /><br />Whatever your thoughts on Ayn Rand, I think this can spark an interesting conversation: What, if anything, should humankind do about people who are widely seen as harmful for the whole? For example, if the Castro dynasty in Cuba or the Kim dynasty in North Korea decide to freeze themselves to ensure they will continue oppressing their countries forever, should that be prevented? (And yes, my opinion of Ayn Rand is such that these examples came to mind.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JWqD9LS5DL3b9Sbgi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": -17, "extendedScore": null, "score": -7.2e-05, "legacy": true, "legacyId": "27652", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 76, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T19:44:37.494Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, December 1-15", "slug": "group-rationality-diary-december-1-15", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:36.254Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/e5HxstneFmGdJhFfz/group-rationality-diary-december-1-15", "pageUrlRelative": "/posts/e5HxstneFmGdJhFfz/group-rationality-diary-december-1-15", "linkUrl": "https://www.lesswrong.com/posts/e5HxstneFmGdJhFfz/group-rationality-diary-december-1-15", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20December%201-15&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20December%201-15%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe5HxstneFmGdJhFfz%2Fgroup-rationality-diary-december-1-15%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20December%201-15%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe5HxstneFmGdJhFfz%2Fgroup-rationality-diary-december-1-15", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe5HxstneFmGdJhFfz%2Fgroup-rationality-diary-december-1-15", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<h2 style=\"margin: 0px 0px 0.75em; color: #333333; font-size: 1.3333em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"line-height: 24.2727279663086px; font-size: small; color: #000000; font-weight: normal;\">This is the public group rationality diary for December 1-15.</span></h2>\n<div id=\"entry_t3_l4c\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px; line-height: 18px;\">\n<div class=\"md\">\n<div id=\"entry_t3_l1z\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<blockquote style=\"line-height: 24.2727279663086px;\">\n<p style=\"margin: 0px 0px 1em;\">It's a place to record and chat about it if you have done, or are actively doing, things like:&nbsp;</p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating.</p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Previous diary:&nbsp;<span style=\"line-height: 24.2727279663086px;\"><a href=\"/lw/l9i/group_rationality_diary_november_1630/\">November 16-30</a></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\"><span style=\"line-height: 24.2727279663086px;\">Next diary: <a href=\"/r/discussion/lw/le6/group_rationality_diary_december_1631/\">December 16-31</a></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality diaries archive</a></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "e5HxstneFmGdJhFfz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "27653", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kxgntZAZ9zaXApfRy", "z87oRFkoCBe4yySfF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T21:20:23.819Z", "modifiedAt": null, "url": null, "title": "The new GiveWell recommendations are out: here's a summary of the charities", "slug": "the-new-givewell-recommendations-are-out-here-s-a-summary-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:32.365Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "tog", "createdAt": "2011-10-04T12:54:07.164Z", "isAdmin": false, "displayName": "tog"}, "userId": "b4f6teTtsKfegjTaH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mAtNMy74zNGicbQK9/the-new-givewell-recommendations-are-out-here-s-a-summary-of", "pageUrlRelative": "/posts/mAtNMy74zNGicbQK9/the-new-givewell-recommendations-are-out-here-s-a-summary-of", "linkUrl": "https://www.lesswrong.com/posts/mAtNMy74zNGicbQK9/the-new-givewell-recommendations-are-out-here-s-a-summary-of", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20new%20GiveWell%20recommendations%20are%20out%3A%20here's%20a%20summary%20of%20the%20charities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20new%20GiveWell%20recommendations%20are%20out%3A%20here's%20a%20summary%20of%20the%20charities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmAtNMy74zNGicbQK9%2Fthe-new-givewell-recommendations-are-out-here-s-a-summary-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20new%20GiveWell%20recommendations%20are%20out%3A%20here's%20a%20summary%20of%20the%20charities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmAtNMy74zNGicbQK9%2Fthe-new-givewell-recommendations-are-out-here-s-a-summary-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmAtNMy74zNGicbQK9%2Fthe-new-givewell-recommendations-are-out-here-s-a-summary-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 829, "htmlBody": "<p>GiveWell have <a href=\"http://blog.givewell.org/2014/12/01/our-updated-top-charities/\">just announced</a> their latest charity recommendations! What are everyone&rsquo;s thoughts on them?</p>\n<p>A summary: all of the old charities (GiveDirectly, SCI and Deworm the World) remain on the list. They're rejoined by AMF, as the room for more funding issues that led to it being delisted have been resolved to GiveWell's satisfaction. Together these organisations form GiveWell's list of 'top charities', which is now joined by a list of other charities which they see as excellent but not quite in the top tier. The charities on this list are Development Media International, Living Goods, and two salt fortification programs (run by GAIN and ICCIDD).</p>\n<p>As normal, GiveWell's site contains extremely detailed writeups on these organisations. Here are some shorter descriptions which I wrote for <a href=\"http://www.charityscience.com/proven-charities.html\">Charity Science's donations page</a> and my <a href=\"http://effectivealtruismhub.com/actions/donating\">tool for donating tax-efficiently</a>, starting with the new entries:</p>\n<h2>GiveWell's newly-added charities</h2>\n<h3>Boost health and cognitive development with salt fortification</h3>\n<p>The charities <a href=\"http://www.gainhealth.org/\">GAIN</a> and <a href=\"http://www.iccidd.org/\">ICCIDD</a> run programs that fortify the salt that millions of poor people eat with iodine. There is <a href=\"http://www.who.int/nutrition/topics/idd/en/\">strong evidence</a> that this boosts their health and cognitive development; iodine deficiency causes pervasive mental impairment, as well as stillbirth and congenital abnormalities such as severe retardation. It can be done very cheaply on a mass scale, so is highly cost-effective. GAIN is registered in the US and ICCIDD in Canada <span class=\"canada country-specific\">(although Canadians can give to either via Charity Science, which for complex reasons helps others who donate tax-deductibly to other charities)</span>, allowing for especially efficient donations from these countries, and taxpayers from other countries can also often give to them tax-deductibly. For more information, read GiveWell's detailed reviews of <a href=\"http://www.givewell.org/international/charities/GAIN\">GAIN</a> and <a href=\"http://www.givewell.org/international/charities/iccidd\">ICCIDD</a>.</p>\n<h3>Educate millions in life-saving practices with Development Media International</h3>\n<p>Development Media International (DMI) produces radio and television broadcasts in developing countries that tell people about improved health practices that can save lives, especially those of young children. Examples of such practices include exclusive breastfeeding. DMI are conducting a randomized controlled trial of their program which has found promising indications of a large decrease in children's deaths. With more funds they would be able to reach millions of people, due to the unparalleled reach of broadcasting. For more information, read <a href=\"http://www.givewell.org/international/charities/DMI\">GiveWell's detailed review</a>.</p>\n<h3>Bring badly-needed goods and health services to the poor with Living Goods</h3>\n<p>Living Goods is a non-profit which runs a network of people selling badly-needed health and household goods door-to-door in their communities in Uganda and Kenya and provide free health advice. A randomized controlled trial suggested that this caused a 25% reduction in under-5 mortality among other benefits. Products sold range from fortified foods and mosquito nets to cookstoves and contraceptives. Giving to Living Goods is an exciting opportunity to bring these badly needed goods and services to some of the poorest families in the world. For more information, read <a href=\"http://www.givewell.org/international/charities/living-goods\">GiveWell's detailed review</a>.</p>\n<h2>GiveWell's old and returning charities</h2>\n<h3>Treat hundreds of people for parasitic worms</h3>\n<p>Deworm the World and the Schistosomiasis Control Initiative (SCI) treat parasitic worm infections such as schistosomiasis, which can cause urinary infections, anemia, and other nutritional problems. For more information, read <a href=\"http://www.givewell.org/international/technical/programs/deworming\">GiveWell's detailed review</a>, or the <a href=\"http://www.charityscience.com/deworming-charities.html\">more accessible Charity Science summary</a>. Deworm the World is registered in the USA and SCI in the UK, allowing for tax-efficient direct donations in those countries, and taxpayers from other countries can also often give to them efficiently.</p>\n<h3>Make unconditional cash transfers with GiveDirectly</h3>\n<p>GiveDirectly lets you empower people to purchase whatever they believe will help them most. <a href=\"http://www.givewell.org/international/technical/programs/cash-transfers\" target=\"_blank\">Eleven randomized controlled trials</a> have supported cash transfers&rsquo; impact, and there is strong evidence that recipients know their own situation best and generally invest in things which make them <a href=\"http://www.givewell.org/files/DWDA%202009/Interventions/Cash%20Transfers/Haushofer%20and%20Shapiro%202013.pdf\" target=\"_blank\">happier in the long term</a>. For more information, read <a href=\"http://www.givewell.org/international/top-charities/give-directly\">GiveWell's detailed review</a>, or the <a href=\"http://www.charityscience.com/cash-transfers.html\">more accessible Charity Science summary.</a></p>\n<h3>Save lives and prevent infections with the Against Malaria Foundation</h3>\n<p>Malaria causes about a million deaths and two hundred million infections a year. Thankfully a $6 bednet can stop mosquitos from infecting children while they sleep, preventing this deadly disease. This intervention has exceptionally robust evidence behind it, with many randomized controlled trials suggesting that it is one of the most cost-effective ways to save lives. The Against Malaria Foundation (AMF) is an exceptional charity in every respect, and was GiveWell's top recommendation in 2012 and 2013. Not all bednet charities are created equal, and AMF outperforms the rest on every count. They can distribute nets cheaper than most others, for just $6.13 US. They distribute long-lasting nets which don&rsquo;t need retreating with insecticide. They are extremely transparent and monitor their own impact carefully, requiring photo verification from each net distribution. For more information, read <a href=\"http://www.givewell.org/international/top-charities/AMF\">GiveWell's detailed review</a>, or the <a href=\"http://www.charityscience.com/malaria-charities.html\">more accessible Charity Science summary</a>.</p>\n<h2><a href=\"http://effectivealtruismhub.com/donations\"><img style=\"float: left; height: 126px; margin-bottom: 10px; margin-right: 15px;\" src=\"http://effectivealtruismhub.com/sites/effectivealtruismhub.com/media/images/specific-pages/donations-piggy-bank.jpg\" alt=\"\" /></a>How to donate</h2>\n<p>To find out which charities are tax-deductible in your country and get links to give to them tax-efficiently, you can use <a href=\"http://effectivealtruismhub.com/actions/donating\"><strong>this interactive tool that I made</strong></a>. If you give this season, consider <a href=\"http://effectivealtruismhub.com/donations/past/add\"><strong>sharing the charities you choose on the EA Donation Registry</strong></a>. We can see which charities EAs pick, and which of the new ones prove popular!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xEZwTHPd5AWpgQx9w": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mAtNMy74zNGicbQK9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 27, "extendedScore": null, "score": 2.227133301192414e-06, "legacy": true, "legacyId": "27654", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>GiveWell have <a href=\"http://blog.givewell.org/2014/12/01/our-updated-top-charities/\">just announced</a> their latest charity recommendations! What are everyone\u2019s thoughts on them?</p>\n<p>A summary: all of the old charities (GiveDirectly, SCI and Deworm the World) remain on the list. They're rejoined by AMF, as the room for more funding issues that led to it being delisted have been resolved to GiveWell's satisfaction. Together these organisations form GiveWell's list of 'top charities', which is now joined by a list of other charities which they see as excellent but not quite in the top tier. The charities on this list are Development Media International, Living Goods, and two salt fortification programs (run by GAIN and ICCIDD).</p>\n<p>As normal, GiveWell's site contains extremely detailed writeups on these organisations. Here are some shorter descriptions which I wrote for <a href=\"http://www.charityscience.com/proven-charities.html\">Charity Science's donations page</a> and my <a href=\"http://effectivealtruismhub.com/actions/donating\">tool for donating tax-efficiently</a>, starting with the new entries:</p>\n<h2 id=\"GiveWell_s_newly_added_charities\">GiveWell's newly-added charities</h2>\n<h3 id=\"Boost_health_and_cognitive_development_with_salt_fortification\">Boost health and cognitive development with salt fortification</h3>\n<p>The charities <a href=\"http://www.gainhealth.org/\">GAIN</a> and <a href=\"http://www.iccidd.org/\">ICCIDD</a> run programs that fortify the salt that millions of poor people eat with iodine. There is <a href=\"http://www.who.int/nutrition/topics/idd/en/\">strong evidence</a> that this boosts their health and cognitive development; iodine deficiency causes pervasive mental impairment, as well as stillbirth and congenital abnormalities such as severe retardation. It can be done very cheaply on a mass scale, so is highly cost-effective. GAIN is registered in the US and ICCIDD in Canada <span class=\"canada country-specific\">(although Canadians can give to either via Charity Science, which for complex reasons helps others who donate tax-deductibly to other charities)</span>, allowing for especially efficient donations from these countries, and taxpayers from other countries can also often give to them tax-deductibly. For more information, read GiveWell's detailed reviews of <a href=\"http://www.givewell.org/international/charities/GAIN\">GAIN</a> and <a href=\"http://www.givewell.org/international/charities/iccidd\">ICCIDD</a>.</p>\n<h3 id=\"Educate_millions_in_life_saving_practices_with_Development_Media_International\">Educate millions in life-saving practices with Development Media International</h3>\n<p>Development Media International (DMI) produces radio and television broadcasts in developing countries that tell people about improved health practices that can save lives, especially those of young children. Examples of such practices include exclusive breastfeeding. DMI are conducting a randomized controlled trial of their program which has found promising indications of a large decrease in children's deaths. With more funds they would be able to reach millions of people, due to the unparalleled reach of broadcasting. For more information, read <a href=\"http://www.givewell.org/international/charities/DMI\">GiveWell's detailed review</a>.</p>\n<h3 id=\"Bring_badly_needed_goods_and_health_services_to_the_poor_with_Living_Goods\">Bring badly-needed goods and health services to the poor with Living Goods</h3>\n<p>Living Goods is a non-profit which runs a network of people selling badly-needed health and household goods door-to-door in their communities in Uganda and Kenya and provide free health advice. A randomized controlled trial suggested that this caused a 25% reduction in under-5 mortality among other benefits. Products sold range from fortified foods and mosquito nets to cookstoves and contraceptives. Giving to Living Goods is an exciting opportunity to bring these badly needed goods and services to some of the poorest families in the world. For more information, read <a href=\"http://www.givewell.org/international/charities/living-goods\">GiveWell's detailed review</a>.</p>\n<h2 id=\"GiveWell_s_old_and_returning_charities\">GiveWell's old and returning charities</h2>\n<h3 id=\"Treat_hundreds_of_people_for_parasitic_worms\">Treat hundreds of people for parasitic worms</h3>\n<p>Deworm the World and the Schistosomiasis Control Initiative (SCI) treat parasitic worm infections such as schistosomiasis, which can cause urinary infections, anemia, and other nutritional problems. For more information, read <a href=\"http://www.givewell.org/international/technical/programs/deworming\">GiveWell's detailed review</a>, or the <a href=\"http://www.charityscience.com/deworming-charities.html\">more accessible Charity Science summary</a>. Deworm the World is registered in the USA and SCI in the UK, allowing for tax-efficient direct donations in those countries, and taxpayers from other countries can also often give to them efficiently.</p>\n<h3 id=\"Make_unconditional_cash_transfers_with_GiveDirectly\">Make unconditional cash transfers with GiveDirectly</h3>\n<p>GiveDirectly lets you empower people to purchase whatever they believe will help them most. <a href=\"http://www.givewell.org/international/technical/programs/cash-transfers\" target=\"_blank\">Eleven randomized controlled trials</a> have supported cash transfers\u2019 impact, and there is strong evidence that recipients know their own situation best and generally invest in things which make them <a href=\"http://www.givewell.org/files/DWDA%202009/Interventions/Cash%20Transfers/Haushofer%20and%20Shapiro%202013.pdf\" target=\"_blank\">happier in the long term</a>. For more information, read <a href=\"http://www.givewell.org/international/top-charities/give-directly\">GiveWell's detailed review</a>, or the <a href=\"http://www.charityscience.com/cash-transfers.html\">more accessible Charity Science summary.</a></p>\n<h3 id=\"Save_lives_and_prevent_infections_with_the_Against_Malaria_Foundation\">Save lives and prevent infections with the Against Malaria Foundation</h3>\n<p>Malaria causes about a million deaths and two hundred million infections a year. Thankfully a $6 bednet can stop mosquitos from infecting children while they sleep, preventing this deadly disease. This intervention has exceptionally robust evidence behind it, with many randomized controlled trials suggesting that it is one of the most cost-effective ways to save lives. The Against Malaria Foundation (AMF) is an exceptional charity in every respect, and was GiveWell's top recommendation in 2012 and 2013. Not all bednet charities are created equal, and AMF outperforms the rest on every count. They can distribute nets cheaper than most others, for just $6.13 US. They distribute long-lasting nets which don\u2019t need retreating with insecticide. They are extremely transparent and monitor their own impact carefully, requiring photo verification from each net distribution. For more information, read <a href=\"http://www.givewell.org/international/top-charities/AMF\">GiveWell's detailed review</a>, or the <a href=\"http://www.charityscience.com/malaria-charities.html\">more accessible Charity Science summary</a>.</p>\n<h2 id=\"How_to_donate\"><a href=\"http://effectivealtruismhub.com/donations\"><img style=\"float: left; height: 126px; margin-bottom: 10px; margin-right: 15px;\" src=\"http://effectivealtruismhub.com/sites/effectivealtruismhub.com/media/images/specific-pages/donations-piggy-bank.jpg\" alt=\"\"></a>How to donate</h2>\n<p>To find out which charities are tax-deductible in your country and get links to give to them tax-efficiently, you can use <a href=\"http://effectivealtruismhub.com/actions/donating\"><strong>this interactive tool that I made</strong></a>. If you give this season, consider <a href=\"http://effectivealtruismhub.com/donations/past/add\"><strong>sharing the charities you choose on the EA Donation Registry</strong></a>. We can see which charities EAs pick, and which of the new ones prove popular!</p>", "sections": [{"title": "GiveWell's newly-added charities", "anchor": "GiveWell_s_newly_added_charities", "level": 1}, {"title": "Boost health and cognitive development with salt fortification", "anchor": "Boost_health_and_cognitive_development_with_salt_fortification", "level": 2}, {"title": "Educate millions in life-saving practices with Development Media International", "anchor": "Educate_millions_in_life_saving_practices_with_Development_Media_International", "level": 2}, {"title": "Bring badly-needed goods and health services to the poor with Living Goods", "anchor": "Bring_badly_needed_goods_and_health_services_to_the_poor_with_Living_Goods", "level": 2}, {"title": "GiveWell's old and returning charities", "anchor": "GiveWell_s_old_and_returning_charities", "level": 1}, {"title": "Treat hundreds of people for parasitic worms", "anchor": "Treat_hundreds_of_people_for_parasitic_worms", "level": 2}, {"title": "Make unconditional cash transfers with GiveDirectly", "anchor": "Make_unconditional_cash_transfers_with_GiveDirectly", "level": 2}, {"title": "Save lives and prevent infections with the Against Malaria Foundation", "anchor": "Save_lives_and_prevent_infections_with_the_Against_Malaria_Foundation", "level": 2}, {"title": "How to donate", "anchor": "How_to_donate", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "17 comments"}], "headingsCount": 11}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-01T23:32:31.543Z", "modifiedAt": null, "url": null, "title": "December 2014 Monthly Bragging Thread", "slug": "december-2014-monthly-bragging-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:30.700Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "elharo", "createdAt": "2012-12-28T14:11:02.335Z", "isAdmin": false, "displayName": "elharo"}, "userId": "cgJcCeZhdRnGtwMMR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Nt2rFw7pWggwNLRZg/december-2014-monthly-bragging-thread", "pageUrlRelative": "/posts/Nt2rFw7pWggwNLRZg/december-2014-monthly-bragging-thread", "linkUrl": "https://www.lesswrong.com/posts/Nt2rFw7pWggwNLRZg/december-2014-monthly-bragging-thread", "postedAtFormatted": "Monday, December 1st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20December%202014%20Monthly%20Bragging%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADecember%202014%20Monthly%20Bragging%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNt2rFw7pWggwNLRZg%2Fdecember-2014-monthly-bragging-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=December%202014%20Monthly%20Bragging%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNt2rFw7pWggwNLRZg%2Fdecember-2014-monthly-bragging-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNt2rFw7pWggwNLRZg%2Fdecember-2014-monthly-bragging-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 127, "htmlBody": "<div id=\"entry_t3_l73\" class=\"content clear\">\n<div class=\"md\">\n<div>Your job, should you choose to accept it, is to comment on this thread explaining <strong>the most awesome thing you've done this month</strong>. You may be as blatantly proud of yourself as you feel. You may unabashedly consider yourself <em>the coolest freaking person ever</em> because of that awesome thing you're dying to tell everyone about. This is the place to do just that.\n<div>\n<div>\n<p>Remember, however, that this <strong>isn't</strong> any kind of progress thread. Nor is it any kind of proposal thread. <em>This thread is solely for people to talk about the awesome things they have done. Not \"will do\". Not \"are working on\"</em>. <strong>Have already done.</strong> This is to cultivate an environment of object level productivity rather than meta-productivity methods.</p>\n<p>So, what's the coolest thing you've done this month?</p>\n</div>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Nt2rFw7pWggwNLRZg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "27655", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-02T02:02:24.576Z", "modifiedAt": null, "url": null, "title": "Superintelligence 12: Malignant failure modes", "slug": "superintelligence-12-malignant-failure-modes", "viewCount": null, "lastCommentedAt": "2020-08-13T22:58:07.157Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BqoE5vhPNCB7X6Say/superintelligence-12-malignant-failure-modes", "pageUrlRelative": "/posts/BqoE5vhPNCB7X6Say/superintelligence-12-malignant-failure-modes", "linkUrl": "https://www.lesswrong.com/posts/BqoE5vhPNCB7X6Say/superintelligence-12-malignant-failure-modes", "postedAtFormatted": "Tuesday, December 2nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligence%2012%3A%20Malignant%20failure%20modes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligence%2012%3A%20Malignant%20failure%20modes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBqoE5vhPNCB7X6Say%2Fsuperintelligence-12-malignant-failure-modes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligence%2012%3A%20Malignant%20failure%20modes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBqoE5vhPNCB7X6Say%2Fsuperintelligence-12-malignant-failure-modes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBqoE5vhPNCB7X6Say%2Fsuperintelligence-12-malignant-failure-modes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1500, "htmlBody": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr />\n<p>Welcome. This week we discuss the twelfth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Malignant failure modes</strong></em>.&nbsp;</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>:&nbsp;'Malignant failure modes' from Chapter 8</p>\n<hr />\n<h1>Summary</h1>\n<ol>\n<li><strong>Malignant failure mode: </strong>a failure that&nbsp;involves human extinction; in contrast with many failure modes where the AI doesn't do much.&nbsp;</li>\n<li><strong>Features of malignant failures&nbsp;</strong><ol>\n<li>We don't get a second try&nbsp;</li>\n<li>It supposes we have a great deal of success, i.e. enough to make an unprecedentedly competent agent</li>\n</ol></li>\n<li>Some malignant failures:<ol>\n<li><strong>Perverse instantiation: </strong>the AI does what you ask, but what you ask turns out to be most satisfiable in unforeseen and destructive ways.<ol>\n<li>Example: you ask the AI to make people smile, and it intervenes on their facial muscles or neurochemicals, instead of via their happiness, and in particular via the bits of the world that usually make them happy.</li>\n<li>Possible counterargument: if it's so smart, won't it know what we meant? Answer: Yes, it knows, but it's goal is to make you smile, not to do what you meant when you programmed that goal.</li>\n<li>AI which can manipulate its own mind easily is at risk of 'wireheading' - that is, a goal of maximizing a reward signal might be perversely instantiated by just manipulating the signal directly. In general, animals can be motivated to do outside things to achieve internal states, however AI with sufficient access to internal state can do this more easily by manipulating internal state.&nbsp;</li>\n<li>Even if we think a goal looks good, we should fear it has perverse instantiations that we haven't appreciated.</li>\n</ol></li>\n<li><strong>Infrastructure profusion:</strong> in pursuit of some goal, an AI redirects most resources to infrastructure, at our expense.<ol>\n<li>Even apparently self-limiting goals can lead to infrastructure profusion. For instance, to an agent whose only goal is to make ten paperclips, once it has apparently made ten paperclips it is always more valuable to try to become more certain that there are really ten paperclips than it is to just stop doing anything.</li>\n<li>Examples: Riemann hypothesis catastrophe, paperclip maximizing AI</li>\n</ol></li>\n<li><strong>Mind crime:</strong>&nbsp;AI contains morally relevant computations, and treats them badly<ol>\n<li>Example: AI simulates humans in its mind, for the purpose of learning about human psychology, then quickly destroys them.</li>\n<li>Other reasons for simulating morally relevant creatures:<ol>\n<li>Blackmail</li>\n<li>Creating indexical uncertainty in outside creatures</li>\n</ol></li>\n</ol></li>\n</ol></li>\n</ol>\n<h1>Another view</h1>\n<p><span style=\"color: #333333; font-family: 'Helvetica Neue', Arial, sans-serif; font-size: 15px; line-height: 20px; white-space: pre-wrap;\">In this chapter Bostrom discussed the difficulty he perceives in designing goals that don't lead to indefinite resource acquisition. Steven Pinker <a href=\"http://edge.org/conversation/the-myth-of-ai\">recently offered</a> a different perspective on the inevitability of resource acquisition:</span></p>\n<blockquote>\n<p style=\"margin: 0px 0px 1.5em; font-size: 12px; line-height: 18px;\">...The other problem with AI dystopias is that they project a parochial alpha-male psychology onto the concept of intelligence. Even if we did have superhumanly intelligent robots, why would they&nbsp;<em>want&nbsp;</em>to depose their masters, massacre bystanders, or take over the world? Intelligence is the ability to deploy novel means to attain a goal, but the goals are extraneous to the intelligence itself: being smart is not the same as wanting something. History does turn up the occasional megalomaniacal despot or psychopathic serial killer, but these are products of a history of natural selection shaping testosterone-sensitive circuits in a certain species of primate, not an inevitable feature of intelligent systems. It&rsquo;s telling that many of our techno-prophets can&rsquo;t entertain the possibility that artificial intelligence will naturally develop along female lines: fully capable of solving problems, but with no burning desire to annihilate innocents or dominate the civilization.</p>\n<p style=\"margin: 0px 0px 1.5em; font-size: 12px; line-height: 18px;\">Of course we can imagine an evil genius who deliberately designed, built, and released a battalion of robots to sow mass destruction. &nbsp;But we should keep in mind the chain of probabilities that would have to multiply out before it would be a reality. A Dr. Evil would have to arise with the combination of a thirst for pointless mass murder and a genius for technological innovation. He would have to recruit and manage a team of co-conspirators that exercised perfect secrecy, loyalty, and competence. And the operation would have to survive the hazards of detection, betrayal, stings, blunders, and bad luck. In theory it could happen, but I think we have more pressing things to worry about.&nbsp;</p>\n</blockquote>\n<h1>Notes</h1>\n<p>1. Perverse instantiation is a very old idea. It is what <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/LiteralGenie\">genies</a> are most famous for. <a href=\"http://en.wikipedia.org/wiki/Midas#Myths\">King Midas</a>&nbsp;had similar problems. Apparently it was&nbsp;<a href=\"/lw/bd6/ai_risk_opportunity_a_timeline_of_early_ideas_and/\">applied to AI</a>&nbsp;by 1947, in&nbsp;<em><a href=\"http://www.amazon.com/Folded-Searching-Collected-Stories-Williamson/dp/1893887375/?tag=viglink20784-20\">With Folded Hands</a>.</em></p>\n<p><img style=\"vertical-align: middle;\" src=\"http://images.lesswrong.com/t3_l9t_0.png\" alt=\"\" width=\"200\" /></p>\n<p>2. Adam Elga writes more on simulating people for&nbsp;<a href=\"http://philsci-archive.pitt.edu/1036/1/drevil.pdf\">blackmail and indexical uncertainty</a>.</p>\n<p>3. More directions for making AI which don't lead to infrastructure profusion:</p>\n<ul>\n<li>Some kinds of preferences don't lend themselves to ambitious investments. Anna Salamon <a href=\"https://www.youtube.com/watch?v=0xLw7eAogWk\">talks about</a> risk averse preferences. Short time horizons and goals which are&nbsp;<a href=\"http://meteuphoric.wordpress.com/2010/02/06/cheap-goals-not-explosive/\">cheap</a>&nbsp;to fulfil&nbsp;should also make long term investments in infrastructure or intelligence augmentation less valuable, compared to direct work on the problem at hand.</li>\n<li><a href=\"http://wiki.lesswrong.com/wiki/Oracle_AI\">Oracle</a> and <a href=\"http://wiki.lesswrong.com/wiki/Tool_AI\">tool</a> AIs are intended to not be goal-directed, but as far as I know it is an open question whether this makes sense. We will get to these later in the book.</li>\n</ul>\n<div>4. John Danaher again <a href=\"http://philosophicaldisquisitions.blogspot.com/2014/07/bostrom-on-superintelligence-4.html\">summarizes this section well, and comments on it</a>.</div>\n<div><br /></div>\n<div>5. Often when systems break, or we make errors in them, they don't work at all. Sometimes, they fail more subtly, working well in some sense, but leading us to an undesirable outcome, for instance a malignant failure mode. How can you tell whether a poorly designed AI is likely to just not work, vs. accidentally take over the world? An important consideration for systems in general seems to be the level of abstraction at which the error occurs. We try to build systems so that you can just interact with them at a relatively abstract level, without knowing how the parts work. For instance, you can interact with your GPS by typing places into it, then listening to it, and you don't need to know anything about how it works. If you make an error while up writing your address into the GPS, it will fail by taking you to the wrong place, but it will still direct you there fairly well. If you fail by putting the wires inside the GPS into the wrong places the GPS is more likely to just not work.&nbsp;</div>\n<h1>In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>Are there better ways to specify 'limited' goals? For instance, to ask for ten paperclips without asking for the universe to be devoted to slightly improving the probability of success?</li>\n<li>In what circumstances could you be confident that the goals you have given an AI do not permit perverse instantiations?&nbsp;</li>\n<li><span style=\"color: #333333; font-family: 'Helvetica Neue', Arial, sans-serif; font-size: 15px; line-height: 20px; white-space: pre-wrap;\">Explore possibilities for malignant failure vs. other failures. If we fail, is it actually probable that we will have enough 'success' for our creation to take over the world?</span></li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1>How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about<strong> capability control methods</strong>, section 13. To prepare,&nbsp;<strong>read</strong>&nbsp;&ldquo;Two agency problems&rdquo; and &ldquo;Capability control methods&rdquo; from Chapter 9<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday December 8. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1, "tdt83ChxnEgwwKxi6": 1, "PvridmTCj2qsugQCH": 1, "mxSBcaTrakvCkgLzL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BqoE5vhPNCB7X6Say", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 5e-05, "legacy": true, "legacyId": "27569", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr>\n<p>Welcome. This week we discuss the twelfth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Malignant failure modes</strong></em>.&nbsp;</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>:&nbsp;'Malignant failure modes' from Chapter 8</p>\n<hr>\n<h1 id=\"Summary\">Summary</h1>\n<ol>\n<li><strong>Malignant failure mode: </strong>a failure that&nbsp;involves human extinction; in contrast with many failure modes where the AI doesn't do much.&nbsp;</li>\n<li><strong>Features of malignant failures&nbsp;</strong><ol>\n<li>We don't get a second try&nbsp;</li>\n<li>It supposes we have a great deal of success, i.e. enough to make an unprecedentedly competent agent</li>\n</ol></li>\n<li>Some malignant failures:<ol>\n<li><strong>Perverse instantiation: </strong>the AI does what you ask, but what you ask turns out to be most satisfiable in unforeseen and destructive ways.<ol>\n<li>Example: you ask the AI to make people smile, and it intervenes on their facial muscles or neurochemicals, instead of via their happiness, and in particular via the bits of the world that usually make them happy.</li>\n<li>Possible counterargument: if it's so smart, won't it know what we meant? Answer: Yes, it knows, but it's goal is to make you smile, not to do what you meant when you programmed that goal.</li>\n<li>AI which can manipulate its own mind easily is at risk of 'wireheading' - that is, a goal of maximizing a reward signal might be perversely instantiated by just manipulating the signal directly. In general, animals can be motivated to do outside things to achieve internal states, however AI with sufficient access to internal state can do this more easily by manipulating internal state.&nbsp;</li>\n<li>Even if we think a goal looks good, we should fear it has perverse instantiations that we haven't appreciated.</li>\n</ol></li>\n<li><strong>Infrastructure profusion:</strong> in pursuit of some goal, an AI redirects most resources to infrastructure, at our expense.<ol>\n<li>Even apparently self-limiting goals can lead to infrastructure profusion. For instance, to an agent whose only goal is to make ten paperclips, once it has apparently made ten paperclips it is always more valuable to try to become more certain that there are really ten paperclips than it is to just stop doing anything.</li>\n<li>Examples: Riemann hypothesis catastrophe, paperclip maximizing AI</li>\n</ol></li>\n<li><strong>Mind crime:</strong>&nbsp;AI contains morally relevant computations, and treats them badly<ol>\n<li>Example: AI simulates humans in its mind, for the purpose of learning about human psychology, then quickly destroys them.</li>\n<li>Other reasons for simulating morally relevant creatures:<ol>\n<li>Blackmail</li>\n<li>Creating indexical uncertainty in outside creatures</li>\n</ol></li>\n</ol></li>\n</ol></li>\n</ol>\n<h1 id=\"Another_view\">Another view</h1>\n<p><span style=\"color: #333333; font-family: 'Helvetica Neue', Arial, sans-serif; font-size: 15px; line-height: 20px; white-space: pre-wrap;\">In this chapter Bostrom discussed the difficulty he perceives in designing goals that don't lead to indefinite resource acquisition. Steven Pinker <a href=\"http://edge.org/conversation/the-myth-of-ai\">recently offered</a> a different perspective on the inevitability of resource acquisition:</span></p>\n<blockquote>\n<p style=\"margin: 0px 0px 1.5em; font-size: 12px; line-height: 18px;\">...The other problem with AI dystopias is that they project a parochial alpha-male psychology onto the concept of intelligence. Even if we did have superhumanly intelligent robots, why would they&nbsp;<em>want&nbsp;</em>to depose their masters, massacre bystanders, or take over the world? Intelligence is the ability to deploy novel means to attain a goal, but the goals are extraneous to the intelligence itself: being smart is not the same as wanting something. History does turn up the occasional megalomaniacal despot or psychopathic serial killer, but these are products of a history of natural selection shaping testosterone-sensitive circuits in a certain species of primate, not an inevitable feature of intelligent systems. It\u2019s telling that many of our techno-prophets can\u2019t entertain the possibility that artificial intelligence will naturally develop along female lines: fully capable of solving problems, but with no burning desire to annihilate innocents or dominate the civilization.</p>\n<p style=\"margin: 0px 0px 1.5em; font-size: 12px; line-height: 18px;\">Of course we can imagine an evil genius who deliberately designed, built, and released a battalion of robots to sow mass destruction. &nbsp;But we should keep in mind the chain of probabilities that would have to multiply out before it would be a reality. A Dr. Evil would have to arise with the combination of a thirst for pointless mass murder and a genius for technological innovation. He would have to recruit and manage a team of co-conspirators that exercised perfect secrecy, loyalty, and competence. And the operation would have to survive the hazards of detection, betrayal, stings, blunders, and bad luck. In theory it could happen, but I think we have more pressing things to worry about.&nbsp;</p>\n</blockquote>\n<h1 id=\"Notes\">Notes</h1>\n<p>1. Perverse instantiation is a very old idea. It is what <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/LiteralGenie\">genies</a> are most famous for. <a href=\"http://en.wikipedia.org/wiki/Midas#Myths\">King Midas</a>&nbsp;had similar problems. Apparently it was&nbsp;<a href=\"/lw/bd6/ai_risk_opportunity_a_timeline_of_early_ideas_and/\">applied to AI</a>&nbsp;by 1947, in&nbsp;<em><a href=\"http://www.amazon.com/Folded-Searching-Collected-Stories-Williamson/dp/1893887375/?tag=viglink20784-20\">With Folded Hands</a>.</em></p>\n<p><img style=\"vertical-align: middle;\" src=\"http://images.lesswrong.com/t3_l9t_0.png\" alt=\"\" width=\"200\"></p>\n<p>2. Adam Elga writes more on simulating people for&nbsp;<a href=\"http://philsci-archive.pitt.edu/1036/1/drevil.pdf\">blackmail and indexical uncertainty</a>.</p>\n<p>3. More directions for making AI which don't lead to infrastructure profusion:</p>\n<ul>\n<li>Some kinds of preferences don't lend themselves to ambitious investments. Anna Salamon <a href=\"https://www.youtube.com/watch?v=0xLw7eAogWk\">talks about</a> risk averse preferences. Short time horizons and goals which are&nbsp;<a href=\"http://meteuphoric.wordpress.com/2010/02/06/cheap-goals-not-explosive/\">cheap</a>&nbsp;to fulfil&nbsp;should also make long term investments in infrastructure or intelligence augmentation less valuable, compared to direct work on the problem at hand.</li>\n<li><a href=\"http://wiki.lesswrong.com/wiki/Oracle_AI\">Oracle</a> and <a href=\"http://wiki.lesswrong.com/wiki/Tool_AI\">tool</a> AIs are intended to not be goal-directed, but as far as I know it is an open question whether this makes sense. We will get to these later in the book.</li>\n</ul>\n<div>4. John Danaher again <a href=\"http://philosophicaldisquisitions.blogspot.com/2014/07/bostrom-on-superintelligence-4.html\">summarizes this section well, and comments on it</a>.</div>\n<div><br></div>\n<div>5. Often when systems break, or we make errors in them, they don't work at all. Sometimes, they fail more subtly, working well in some sense, but leading us to an undesirable outcome, for instance a malignant failure mode. How can you tell whether a poorly designed AI is likely to just not work, vs. accidentally take over the world? An important consideration for systems in general seems to be the level of abstraction at which the error occurs. We try to build systems so that you can just interact with them at a relatively abstract level, without knowing how the parts work. For instance, you can interact with your GPS by typing places into it, then listening to it, and you don't need to know anything about how it works. If you make an error while up writing your address into the GPS, it will fail by taking you to the wrong place, but it will still direct you there fairly well. If you fail by putting the wires inside the GPS into the wrong places the GPS is more likely to just not work.&nbsp;</div>\n<h1 id=\"In_depth_investigations\">In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>Are there better ways to specify 'limited' goals? For instance, to ask for ten paperclips without asking for the universe to be devoted to slightly improving the probability of success?</li>\n<li>In what circumstances could you be confident that the goals you have given an AI do not permit perverse instantiations?&nbsp;</li>\n<li><span style=\"color: #333333; font-family: 'Helvetica Neue', Arial, sans-serif; font-size: 15px; line-height: 20px; white-space: pre-wrap;\">Explore possibilities for malignant failure vs. other failures. If we fail, is it actually probable that we will have enough 'success' for our creation to take over the world?</span></li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1 id=\"How_to_proceed\">How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about<strong> capability control methods</strong>, section 13. To prepare,&nbsp;<strong>read</strong>&nbsp;\u201cTwo agency problems\u201d and \u201cCapability control methods\u201d from Chapter 9<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday December 8. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "sections": [{"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Another view", "anchor": "Another_view", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "In-depth investigations", "anchor": "In_depth_investigations", "level": 1}, {"title": "How to proceed", "anchor": "How_to_proceed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "51 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 51, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QDmzDZ9CEHrKQdvcn", "Qdq2SKyMi8vf7Snxq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-02T03:44:12.745Z", "modifiedAt": null, "url": null, "title": "[link] The Philosophy of Intelligence Explosions and Advanced Robotics", "slug": "link-the-philosophy-of-intelligence-explosions-and-advanced", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:41.917Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7sRPMn8zriesE5iYb/link-the-philosophy-of-intelligence-explosions-and-advanced", "pageUrlRelative": "/posts/7sRPMn8zriesE5iYb/link-the-philosophy-of-intelligence-explosions-and-advanced", "linkUrl": "https://www.lesswrong.com/posts/7sRPMn8zriesE5iYb/link-the-philosophy-of-intelligence-explosions-and-advanced", "postedAtFormatted": "Tuesday, December 2nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20The%20Philosophy%20of%20Intelligence%20Explosions%20and%20Advanced%20Robotics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20The%20Philosophy%20of%20Intelligence%20Explosions%20and%20Advanced%20Robotics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7sRPMn8zriesE5iYb%2Flink-the-philosophy-of-intelligence-explosions-and-advanced%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20The%20Philosophy%20of%20Intelligence%20Explosions%20and%20Advanced%20Robotics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7sRPMn8zriesE5iYb%2Flink-the-philosophy-of-intelligence-explosions-and-advanced", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7sRPMn8zriesE5iYb%2Flink-the-philosophy-of-intelligence-explosions-and-advanced", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 687, "htmlBody": "<p>The philosopher John Danaher has posted a list of <a href=\"http://philosophicaldisquisitions.blogspot.fi/2014/11/the-philosophy-of-intelligence.html\">all the posts that he's written on the topic of robotics and AI</a>. Below is the current version of the list: he says that he will keep updating the page as he writes more.</p>\n<blockquote>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2012/12/the-singularity-overview-and-framework.html\">The Singularity: Overview and Framework</a>: This was my first attempt to provide a general overview and framework for understanding the debate about the technological singularity. I suggested that the debate could be organised around three main theses: (i) the explosion thesis -- which claims that there will be an intelligence explosion; (ii) the unfriendliness thesis -- which claims that an advanced artificial intelligence is likely to be \"unfriendly\"; and (iii) the inevitability thesis -- which claims that the creation of an unfriendly AI will be difficult to avoid, if not inevitable.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2013/01/the-singularity-overview-and-framework.html\">The Singularity: Overview and Framework Redux</a>: This was my second attempt to provide a general overview and framework for understanding the debate about the technological singularity. I tried to reduce the framework down to two main theses: (i) the explosion thesis and (ii) the unfriendliness thesis.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2013/01/the-golem-genie-and-unfriendly-ai-part.html\">The Golem Genie and Unfriendly AI (Part One,</a> <a href=\"http://philosophicaldisquisitions.blogspot.ie/2013/02/the-golem-genie-and-unfriendly-ai-part.html\">Part Two)</a>: This two-parter summarises what I think is the best argument for the unfriendliness thesis. The argument was originally presented by Muehlhauser and Helm, but I try to simplify its main components.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2013/02/ais-and-decisive-advantage-thesis.html\">AIs and the Decisive Advantage Thesis</a>: Many people claim that an advanced artificial intelligence would have decisive advantages over human intelligences. Is this right? In this post, I look at Kaj Sotala's argument to that effect.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2013/04/is-there-case-for-robot-slaves.html\">Is there a case for robot slaves?</a> - If robots can be persons -- in the morally thick sense of \"person\" -- then surely it would be wrong to make them cater to our every whim? Or would it? Steve Petersen argues that the creation of robot slaves might be morally permissible. In this post, I look at what he has to say.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2013/10/the-ethics-of-robot-sex.html\">The Ethics of Robot Sex</a>: A reasonably self-explanatory title. This post looks at the ethical issues that might arise from the creation of sex robots.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2014/04/will-sex-workers-be-replaced-by-robots.html\">Will sex workers be replaced by robots? A Precis</a>: A short summary of a longer article examining the possibility of sex workers being replaced by robots. Contrary to the work of others, I suggest that sex work might be resilient to the phenomenon of technological unemployment.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2014/07/bostrom-on-superintelligence-1.html\">Bostrom on Superintelligence (1) The Orthogonality Thesis</a>: The first part in my series on Nick Bostrom's book Superintelligence. This one covers Bostrom's orthogonality thesis, according to which there is no necessary relationship between intelligence and benevolence.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2014/07/bostrom-on-superintelligence-2.html\">Bostrom on Superintelligence (2) The Instrumental Convergence Thesis</a>: The second part in my series on Bostrom's book. This one examines the instrumental convergence thesis, according to which an intelligent agent, no matter what its final goals may be, is likely to converge upon certain instrumental goals that are unfriendly to human beings.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2014/07/bostrom-on-superintelligence-3-doom-and.html\">Bostrom on Superintelligence (3) Doom and the Treacherous Turn</a>: The third part in my series on Bostrom's book. This time I finally get to look at Bostrom's argument for the AI doomsday scenario, and for why it may be difficult to avoid.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2014/07/bostrom-on-superintelligence-4.html\">Bostrom on Superintelligence (4) Malignant Failure Modes</a>: The fourth part in my series on Bostrom's book. This one explains why Bostrom thinks it would be difficult to simply program the AI with the right set of values.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2014/08/bostrom-on-superintelligence-5-limiting.html\">Bostrom on Superintelligence (5) Limiting an AIs Capabilities</a>: The fifth part in my series on Bostrom's book. This one looks at the possibility of hampering or restricting an AI's capabilities, and whether that could help to avoid the doomsday scenario.</li>\n</ul>\n<ul>\n<li><a href=\"http://philosophicaldisquisitions.blogspot.ie/2014/08/bostrom-on-superintelligence-6.html\">Bostrom on Superintelligence (6) Motivation Selection Methods</a>: The sixth (and for now final) part in my series on Bostrom's book. This one considers the advantages and disadvantages of different methods for selecting the motivations of an advanced AI.</li>\n</ul>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7sRPMn8zriesE5iYb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 19, "extendedScore": null, "score": 2.2279649052649783e-06, "legacy": true, "legacyId": "27657", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-02T06:12:42.880Z", "modifiedAt": null, "url": null, "title": "Link: Biotech Corporate Email Hacked", "slug": "link-biotech-corporate-email-hacked", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:33.759Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ilzolende", "createdAt": "2014-11-18T06:19:13.356Z", "isAdmin": false, "displayName": "ilzolende"}, "userId": "4DCb8FeZJ5hxwRsDo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/meJuEE3SyusD3Sqku/link-biotech-corporate-email-hacked", "pageUrlRelative": "/posts/meJuEE3SyusD3Sqku/link-biotech-corporate-email-hacked", "linkUrl": "https://www.lesswrong.com/posts/meJuEE3SyusD3Sqku/link-biotech-corporate-email-hacked", "postedAtFormatted": "Tuesday, December 2nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Biotech%20Corporate%20Email%20Hacked&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Biotech%20Corporate%20Email%20Hacked%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmeJuEE3SyusD3Sqku%2Flink-biotech-corporate-email-hacked%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Biotech%20Corporate%20Email%20Hacked%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmeJuEE3SyusD3Sqku%2Flink-biotech-corporate-email-hacked", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmeJuEE3SyusD3Sqku%2Flink-biotech-corporate-email-hacked", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>Here's the NYTimes story:&nbsp;<a title=\"Hackers With Apparent Investment Banking Background Target Biotech\" href=\"http://www.nytimes.com/2014/12/02/technology/hackers-target-biotech-companies.html\">Hackers With Apparent Investment Banking Background Target Biotech</a></p>\n<p>You should be able to download a copy of the report from the FireEye website&nbsp;<a title=\"Why does a security company let us bypass its request form?\" href=\"https://www2.fireeye.com/rs/fireye/images/rpt-fin4.pdf\">here</a>. Alternatively, you can request a free copy of the FireEye report&nbsp;<a title=\"FireEye FIN4 Complimentary Report\" href=\"https://www2.fireeye.com/fin4.html\">here</a>&nbsp;by&nbsp;pretending to be a company (for example, entering \"no company\" in the \"company\" field). There may be a time delay in between requesting and receiving the report.</p>\n<p>Luckily for all of us, just because the hackers, referred to as FIN4, had financial motivations (getting \"inside information about impending market catalysts\") did not mean that they attempted to maximize their financial gain. If they had, this could would have been on the front page instead of in the technology section, and the headline could have been \"Terrorists Hired Hackers to Manufacture Synthetic Disease,\" or alternately \"Hacker Group Threatens to Release Synthetic Plague if Demands Not Met.\"</p>\n<p>I sincerely hope that, if artificial gene synthesis devices were not kept air-gapped before, that they will be now. If hackers were able to compromise the email accounts of researchers and scientists (listed separately in the report for some reason), and artificial gene synthesis devices took requests from authorized users by internet, then these hackers could have ordered genes synthesized.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "meJuEE3SyusD3Sqku", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -9, "extendedScore": null, "score": -3.3e-05, "legacy": true, "legacyId": "27656", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-02T15:22:58.849Z", "modifiedAt": null, "url": null, "title": "[LINK] Steven Hawking warns of the dangers of AI", "slug": "link-steven-hawking-warns-of-the-dangers-of-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:33.156Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Salemicus", "createdAt": "2012-05-10T20:50:25.455Z", "isAdmin": false, "displayName": "Salemicus"}, "userId": "D8cdrPXwhhiPdqkSz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zgmmyb83iJQJ8sfha/link-steven-hawking-warns-of-the-dangers-of-ai", "pageUrlRelative": "/posts/Zgmmyb83iJQJ8sfha/link-steven-hawking-warns-of-the-dangers-of-ai", "linkUrl": "https://www.lesswrong.com/posts/Zgmmyb83iJQJ8sfha/link-steven-hawking-warns-of-the-dangers-of-ai", "postedAtFormatted": "Tuesday, December 2nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Steven%20Hawking%20warns%20of%20the%20dangers%20of%20AI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Steven%20Hawking%20warns%20of%20the%20dangers%20of%20AI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZgmmyb83iJQJ8sfha%2Flink-steven-hawking-warns-of-the-dangers-of-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Steven%20Hawking%20warns%20of%20the%20dangers%20of%20AI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZgmmyb83iJQJ8sfha%2Flink-steven-hawking-warns-of-the-dangers-of-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZgmmyb83iJQJ8sfha%2Flink-steven-hawking-warns-of-the-dangers-of-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p><a href=\"http://www.bbc.co.uk/news/technology-30290540\">From the BBC:</a></p>\n<blockquote>\n<p>[Hawking]&nbsp;<span style=\"color: #333333; font-family: Arial, Helmet, Freesans, sans-serif; font-size: 14px; line-height: 18px;\">told the BBC:\"The development of full artificial intelligence could spell the end of the human race.\"</span></p>\n<p><span style=\"color: #333333; font-family: Arial, Helmet, Freesans, sans-serif; font-size: 14px; line-height: 18px;\">...</span></p>\n<p style=\"color: #333333; font-family: Arial, Helmet, Freesans, sans-serif; line-height: 18px; margin: 0px 0px 18px; padding: 0px; font-size: 1.077em; text-rendering: auto; clear: left;\">\"It would take off on its own, and re-design itself at an ever increasing rate,\" he said.&nbsp;<span style=\"font-size: 1.077em;\">\"Humans, who are limited by slow biological evolution, couldn't compete, and would be superseded.\"</span></p>\n</blockquote>\n<p style=\"color: #333333; font-family: Arial, Helmet, Freesans, sans-serif; line-height: 18px; margin: 0px 0px 18px; padding: 0px; font-size: 1.077em; text-rendering: auto; clear: left;\">There is, however, no mention of Friendly AI or similar principles.</p>\n<p style=\"color: #333333; font-family: Arial, Helmet, Freesans, sans-serif; line-height: 18px; margin: 0px 0px 18px; padding: 0px; font-size: 1.077em; text-rendering: auto; clear: left;\"><span style=\"font-size: 1.077em;\">In my opinion, this is particularly notable for the coverage this story is getting within the mainstream media. At the current time, this is the most-read and most-shared news story on the BBC website.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zgmmyb83iJQJ8sfha", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 15, "extendedScore": null, "score": 6.6e-05, "legacy": true, "legacyId": "27658", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-02T17:39:04.000Z", "modifiedAt": null, "url": null, "title": "Model-free decisions", "slug": "model-free-decisions", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5bd75cc58225bf0670374eae/model-free-decisions", "pageUrlRelative": "/posts/5bd75cc58225bf0670374eae/model-free-decisions", "linkUrl": "https://www.lesswrong.com/posts/5bd75cc58225bf0670374eae/model-free-decisions", "postedAtFormatted": "Tuesday, December 2nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Model-free%20decisions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModel-free%20decisions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374eae%2Fmodel-free-decisions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Model-free%20decisions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374eae%2Fmodel-free-decisions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374eae%2Fmodel-free-decisions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<html><head></head><body><p>Much concern about AI comes down to the scariness of goal-oriented behavior. A common response to such concerns is \"why would we give an AI goals anyway?\" I think there are good reasons to expect goal-oriented behavior, and I've been on that side of a lot of arguments. But I don't think the issue is settled, and it might be possible to get better outcomes by directly specifying what actions are good. I flesh out one possible alternative <a href=\"https://medium.com/@paulfchristiano/model-free-decisions-6e6609f5d99e\">here</a>.</p>\n<p>(As an experiment I wrote the post on medium, so that it is easier to provide sentence-level feedback, especially feedback on writing or low-level comments. Big-picture discussion should probably stay here.)</p>\n</body></html>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5bd75cc58225bf0670374eae", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": null, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": true, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-02T19:21:15.309Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow Meetup: CBT is back", "slug": "meetup-moscow-meetup-cbt-is-back", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexander230", "createdAt": "2014-08-27T08:55:16.153Z", "isAdmin": false, "displayName": "Alexander230"}, "userId": "xqoKSJayCCtP5juLh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yJkDwsKbnyWNoaNBG/meetup-moscow-meetup-cbt-is-back", "pageUrlRelative": "/posts/yJkDwsKbnyWNoaNBG/meetup-moscow-meetup-cbt-is-back", "linkUrl": "https://www.lesswrong.com/posts/yJkDwsKbnyWNoaNBG/meetup-moscow-meetup-cbt-is-back", "postedAtFormatted": "Tuesday, December 2nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%20Meetup%3A%20CBT%20is%20back&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%20Meetup%3A%20CBT%20is%20back%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyJkDwsKbnyWNoaNBG%2Fmeetup-moscow-meetup-cbt-is-back%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%20Meetup%3A%20CBT%20is%20back%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyJkDwsKbnyWNoaNBG%2Fmeetup-moscow-meetup-cbt-is-back", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyJkDwsKbnyWNoaNBG%2Fmeetup-moscow-meetup-cbt-is-back", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 188, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17l'>Moscow Meetup: CBT is back</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 December 2014 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This meetup will be in semi-closed format! If you hadn't come to our meetups before, please wait for the next open meetup: it's planned to December, 21.</p>\n\n<p>Regular visitors of our meetups, please wait for announce in our group:</p>\n\n<p><a href=\"https://groups.google.com/forum/#!forum/rationality-in-moscow\" rel=\"nofollow\">https://groups.google.com/forum/#!forum/rationality-in-moscow</a></p>\n\n<p>You will feel more comfortable in our meetups if you read the needed materials and became familiar with some base ideas:</p>\n\n<ul>\n<li><p>You understand the Bayes theorem (what is bayesianism - <a href=\"http://lesswrong.com/lw/1to/what_is_bayesianism\" rel=\"nofollow\">http://lesswrong.com/lw/1to/what_is_bayesianism</a> or  <a href=\"http://schegl2g.bget.ru/bayes/YudkowskyBayes.html\" rel=\"nofollow\">http://schegl2g.bget.ru/bayes/YudkowskyBayes.html</a> ).</p></li>\n<li><p>You understand what is \"System 1\" and \"System 2\" (Kahneman and Yudkowsky).</p></li>\n<li><p>You know what is \"rational agent\".</p></li>\n<li><p>You've read the base sequences: \"Map and Territory\" - <a href=\"http://wiki.lesswrong.com/wiki/Map_and_Territory_(sequence\" rel=\"nofollow\">http://wiki.lesswrong.com/wiki/Map_and_Territory_(sequence</a>) and \"Mysterious Answers to Mysterious Questions\" - <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\" rel=\"nofollow\">http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions</a> .</p></li>\n</ul>\n\n<p>It will allow you to understand better, what we talk about, how do we think, and will give you the spirit of our activities.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17l'>Moscow Meetup: CBT is back</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yJkDwsKbnyWNoaNBG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.2299974837910463e-06, "legacy": true, "legacyId": "27659", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow_Meetup__CBT_is_back\">Discussion article for the meetup : <a href=\"/meetups/17l\">Moscow Meetup: CBT is back</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 December 2014 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This meetup will be in semi-closed format! If you hadn't come to our meetups before, please wait for the next open meetup: it's planned to December, 21.</p>\n\n<p>Regular visitors of our meetups, please wait for announce in our group:</p>\n\n<p><a href=\"https://groups.google.com/forum/#!forum/rationality-in-moscow\" rel=\"nofollow\">https://groups.google.com/forum/#!forum/rationality-in-moscow</a></p>\n\n<p>You will feel more comfortable in our meetups if you read the needed materials and became familiar with some base ideas:</p>\n\n<ul>\n<li><p>You understand the Bayes theorem (what is bayesianism - <a href=\"http://lesswrong.com/lw/1to/what_is_bayesianism\" rel=\"nofollow\">http://lesswrong.com/lw/1to/what_is_bayesianism</a> or  <a href=\"http://schegl2g.bget.ru/bayes/YudkowskyBayes.html\" rel=\"nofollow\">http://schegl2g.bget.ru/bayes/YudkowskyBayes.html</a> ).</p></li>\n<li><p>You understand what is \"System 1\" and \"System 2\" (Kahneman and Yudkowsky).</p></li>\n<li><p>You know what is \"rational agent\".</p></li>\n<li><p>You've read the base sequences: \"Map and Territory\" - <a href=\"http://wiki.lesswrong.com/wiki/Map_and_Territory_(sequence\" rel=\"nofollow\">http://wiki.lesswrong.com/wiki/Map_and_Territory_(sequence</a>) and \"Mysterious Answers to Mysterious Questions\" - <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\" rel=\"nofollow\">http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions</a> .</p></li>\n</ul>\n\n<p>It will allow you to understand better, what we talk about, how do we think, and will give you the spirit of our activities.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow_Meetup__CBT_is_back1\">Discussion article for the meetup : <a href=\"/meetups/17l\">Moscow Meetup: CBT is back</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow Meetup: CBT is back", "anchor": "Discussion_article_for_the_meetup___Moscow_Meetup__CBT_is_back", "level": 1}, {"title": "Discussion article for the meetup : Moscow Meetup: CBT is back", "anchor": "Discussion_article_for_the_meetup___Moscow_Meetup__CBT_is_back1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AN2cBr6xKWCB8dRQG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T11:49:07.022Z", "modifiedAt": null, "url": null, "title": "Meetup : Canberra: End of year party", "slug": "meetup-canberra-end-of-year-party", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanielFilan", "createdAt": "2014-01-30T11:04:39.341Z", "isAdmin": false, "displayName": "DanielFilan"}, "userId": "DgsGzjyBXN8XSK22q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LaGgWsWNNmDoS2STB/meetup-canberra-end-of-year-party", "pageUrlRelative": "/posts/LaGgWsWNNmDoS2STB/meetup-canberra-end-of-year-party", "linkUrl": "https://www.lesswrong.com/posts/LaGgWsWNNmDoS2STB/meetup-canberra-end-of-year-party", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Canberra%3A%20End%20of%20year%20party&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Canberra%3A%20End%20of%20year%20party%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLaGgWsWNNmDoS2STB%2Fmeetup-canberra-end-of-year-party%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Canberra%3A%20End%20of%20year%20party%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLaGgWsWNNmDoS2STB%2Fmeetup-canberra-end-of-year-party", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLaGgWsWNNmDoS2STB%2Fmeetup-canberra-end-of-year-party", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17m'>Canberra: End of year party</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 December 2014 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10 Thynne St, Bruce, ACT</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It's a party! The year is ending! Come to my place and we can chill, eat party foods, and chat about LW stuff. I'm in room 70, call me on my mobile number (0468 312 414) and you will get let in.</p>\n\n<p>Note the change in location!</p>\n\n<p>General meetup info:</p>\n\n<ul>\n<li>If you use Facebook, please join our <a href=\"https://www.facebook.com/groups/lwcanberra/\" rel=\"nofollow\">group</a>.</li>\n<li>Structured meetups are (usually) held on the second Saturday and fourth Friday of each month from 6 pm until late in the CSIT building, room N101.</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17m'>Canberra: End of year party</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LaGgWsWNNmDoS2STB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.232143851465682e-06, "legacy": true, "legacyId": "27660", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Canberra__End_of_year_party\">Discussion article for the meetup : <a href=\"/meetups/17m\">Canberra: End of year party</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 December 2014 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10 Thynne St, Bruce, ACT</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It's a party! The year is ending! Come to my place and we can chill, eat party foods, and chat about LW stuff. I'm in room 70, call me on my mobile number (0468 312 414) and you will get let in.</p>\n\n<p>Note the change in location!</p>\n\n<p>General meetup info:</p>\n\n<ul>\n<li>If you use Facebook, please join our <a href=\"https://www.facebook.com/groups/lwcanberra/\" rel=\"nofollow\">group</a>.</li>\n<li>Structured meetups are (usually) held on the second Saturday and fourth Friday of each month from 6 pm until late in the CSIT building, room N101.</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Canberra__End_of_year_party1\">Discussion article for the meetup : <a href=\"/meetups/17m\">Canberra: End of year party</a></h2>", "sections": [{"title": "Discussion article for the meetup : Canberra: End of year party", "anchor": "Discussion_article_for_the_meetup___Canberra__End_of_year_party", "level": 1}, {"title": "Discussion article for the meetup : Canberra: End of year party", "anchor": "Discussion_article_for_the_meetup___Canberra__End_of_year_party1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T11:49:35.338Z", "modifiedAt": null, "url": null, "title": "Meetup : December Rationality Dojo - Online Communication: Conveying Ideas Effectively", "slug": "meetup-december-rationality-dojo-online-communication", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:33.305Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MelbourneLW", "createdAt": "2014-07-15T07:42:47.692Z", "isAdmin": false, "displayName": "MelbourneLW"}, "userId": "fnAEhR2GNN3t6PmFc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kTGsjhR4kkpBmC8qL/meetup-december-rationality-dojo-online-communication", "pageUrlRelative": "/posts/kTGsjhR4kkpBmC8qL/meetup-december-rationality-dojo-online-communication", "linkUrl": "https://www.lesswrong.com/posts/kTGsjhR4kkpBmC8qL/meetup-december-rationality-dojo-online-communication", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20December%20Rationality%20Dojo%20-%20Online%20Communication%3A%20Conveying%20Ideas%20Effectively&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20December%20Rationality%20Dojo%20-%20Online%20Communication%3A%20Conveying%20Ideas%20Effectively%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkTGsjhR4kkpBmC8qL%2Fmeetup-december-rationality-dojo-online-communication%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20December%20Rationality%20Dojo%20-%20Online%20Communication%3A%20Conveying%20Ideas%20Effectively%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkTGsjhR4kkpBmC8qL%2Fmeetup-december-rationality-dojo-online-communication", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkTGsjhR4kkpBmC8qL%2Fmeetup-december-rationality-dojo-online-communication", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 289, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17n'>December Rationality Dojo - Online Communication: Conveying Ideas Effectively</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 December 2014 03:30:00PM (+0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Ross House Association, 247-251 Flinders Lane, Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>[ATTN: Please remember the new location for the dojos: the Jenny Florence Room, Level 3, Ross House at 247 Flinders Lane,Melbourne. 3:30pm start / arrival - formal dojo activities will commence at 4:00pm.]</p>\n\n<p>The Less Wrong Sunday Rationality Dojos are crafted to be serious self-improvement sessions for those committed to the Art ofRationality and personal growth. Each month a community member will run a session involving a presentation of content, discussion, and exercises.</p>\n\n<p>Continuing the succession of immensely successful dojos, Chris will run a session on conveying ideas effectively in online communication.</p>\n\n<p>As always, we will review the personal goals we committed to at the previous Dojo (I will have done X by the next Dojo). Our goals are now being recorded via Google Forms here - <a href=\"https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,\" rel=\"nofollow\">https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,</a> and Melbourne Less Wrong organisers have access to the form results if you wish to review the goals you set last month.</p>\n\n<p>This month, we are also seeking 2-3 lightning talks from members. Speakers will be limited to 5 minutes with room for questions. We will be asking for talks from attendees present, but if you already have a talk topic in mind, please contact Louise at lvalmoria@gmail.com</p>\n\n<p>The Dojo is likely to run for 2-3 hours, after which some people will get dinner together.</p>\n\n<p>If you have any trouble finding the venue or getting in, call Louise on 0419 192 367.</p>\n\n<p>If you would like to present at a future Dojo or suggest a topic, please fill it in on the Rationality Dojo Roster: <a href=\"http://is.gd/dojoroster\" rel=\"nofollow\">http://is.gd/dojoroster</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17n'>December Rationality Dojo - Online Communication: Conveying Ideas Effectively</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kTGsjhR4kkpBmC8qL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.232144877111731e-06, "legacy": true, "legacyId": "27661", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___December_Rationality_Dojo___Online_Communication__Conveying_Ideas_Effectively\">Discussion article for the meetup : <a href=\"/meetups/17n\">December Rationality Dojo - Online Communication: Conveying Ideas Effectively</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 December 2014 03:30:00PM (+0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Ross House Association, 247-251 Flinders Lane, Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>[ATTN: Please remember the new location for the dojos: the Jenny Florence Room, Level 3, Ross House at 247 Flinders Lane,Melbourne. 3:30pm start / arrival - formal dojo activities will commence at 4:00pm.]</p>\n\n<p>The Less Wrong Sunday Rationality Dojos are crafted to be serious self-improvement sessions for those committed to the Art ofRationality and personal growth. Each month a community member will run a session involving a presentation of content, discussion, and exercises.</p>\n\n<p>Continuing the succession of immensely successful dojos, Chris will run a session on conveying ideas effectively in online communication.</p>\n\n<p>As always, we will review the personal goals we committed to at the previous Dojo (I will have done X by the next Dojo). Our goals are now being recorded via Google Forms here - <a href=\"https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,\" rel=\"nofollow\">https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,</a> and Melbourne Less Wrong organisers have access to the form results if you wish to review the goals you set last month.</p>\n\n<p>This month, we are also seeking 2-3 lightning talks from members. Speakers will be limited to 5 minutes with room for questions. We will be asking for talks from attendees present, but if you already have a talk topic in mind, please contact Louise at lvalmoria@gmail.com</p>\n\n<p>The Dojo is likely to run for 2-3 hours, after which some people will get dinner together.</p>\n\n<p>If you have any trouble finding the venue or getting in, call Louise on 0419 192 367.</p>\n\n<p>If you would like to present at a future Dojo or suggest a topic, please fill it in on the Rationality Dojo Roster: <a href=\"http://is.gd/dojoroster\" rel=\"nofollow\">http://is.gd/dojoroster</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___December_Rationality_Dojo___Online_Communication__Conveying_Ideas_Effectively1\">Discussion article for the meetup : <a href=\"/meetups/17n\">December Rationality Dojo - Online Communication: Conveying Ideas Effectively</a></h2>", "sections": [{"title": "Discussion article for the meetup : December Rationality Dojo - Online Communication: Conveying Ideas Effectively", "anchor": "Discussion_article_for_the_meetup___December_Rationality_Dojo___Online_Communication__Conveying_Ideas_Effectively", "level": 1}, {"title": "Discussion article for the meetup : December Rationality Dojo - Online Communication: Conveying Ideas Effectively", "anchor": "Discussion_article_for_the_meetup___December_Rationality_Dojo___Online_Communication__Conveying_Ideas_Effectively1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T16:39:24.576Z", "modifiedAt": null, "url": null, "title": "A hypothetical question for investors ", "slug": "a-hypothetical-question-for-investors", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:35.660Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bokov", "createdAt": "2010-01-11T01:11:23.480Z", "isAdmin": false, "displayName": "bokov"}, "userId": "4sgsBYAsjDHNvB7Q6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LpKYCJvNMGi9HgjKM/a-hypothetical-question-for-investors", "pageUrlRelative": "/posts/LpKYCJvNMGi9HgjKM/a-hypothetical-question-for-investors", "linkUrl": "https://www.lesswrong.com/posts/LpKYCJvNMGi9HgjKM/a-hypothetical-question-for-investors", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20hypothetical%20question%20for%20investors%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20hypothetical%20question%20for%20investors%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLpKYCJvNMGi9HgjKM%2Fa-hypothetical-question-for-investors%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20hypothetical%20question%20for%20investors%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLpKYCJvNMGi9HgjKM%2Fa-hypothetical-question-for-investors", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLpKYCJvNMGi9HgjKM%2Fa-hypothetical-question-for-investors", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>Let's suppose you start with $1000 to invest, and the only thing you can invest it in is stock ABC. You are only permitted to occupy two states:</p>\n<p>* All assets in cash</p>\n<p>* All assets in stock ABC</p>\n<p>You incur a $2 transaction fee every time you buy or sell.</p>\n<p>Kind of annoying limitations to operate under. But you have a powerful advantage as well. You have a perfect crystal ball that each day gives you the [probability density function](http://en.wikipedia.org/wiki/Probability_density_function) of ABC's closing price for the following day (but no further ahead in time).</p>\n<p>What would be an optimal decision rule for when to buy and sell?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LpKYCJvNMGi9HgjKM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 2.2327752754894176e-06, "legacy": true, "legacyId": "27662", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T17:13:59.505Z", "modifiedAt": null, "url": null, "title": "Link: LessWrong and AI risk mentioned in a Business Insider Article", "slug": "link-lesswrong-and-ai-risk-mentioned-in-a-business-insider", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "James_Miller", "createdAt": "2009-03-05T17:14:38.674Z", "isAdmin": false, "displayName": "James_Miller"}, "userId": "LzF2X9eB9oS3q4BXG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DJgLmC5pf5j4FufJn/link-lesswrong-and-ai-risk-mentioned-in-a-business-insider", "pageUrlRelative": "/posts/DJgLmC5pf5j4FufJn/link-lesswrong-and-ai-risk-mentioned-in-a-business-insider", "linkUrl": "https://www.lesswrong.com/posts/DJgLmC5pf5j4FufJn/link-lesswrong-and-ai-risk-mentioned-in-a-business-insider", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20LessWrong%20and%20AI%20risk%20mentioned%20in%20a%20Business%20Insider%20Article&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20LessWrong%20and%20AI%20risk%20mentioned%20in%20a%20Business%20Insider%20Article%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDJgLmC5pf5j4FufJn%2Flink-lesswrong-and-ai-risk-mentioned-in-a-business-insider%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20LessWrong%20and%20AI%20risk%20mentioned%20in%20a%20Business%20Insider%20Article%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDJgLmC5pf5j4FufJn%2Flink-lesswrong-and-ai-risk-mentioned-in-a-business-insider", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDJgLmC5pf5j4FufJn%2Flink-lesswrong-and-ai-risk-mentioned-in-a-business-insider", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 78, "htmlBody": "<p><span style=\"font-family: Helvetica, Arial, sans-serif; font-size: 15.1999998092651px; line-height: 20px;\"><a href=\"http://www.businessinsider.com/if-google-is-worried-about-artificial-intelligence-then-you-should-be-too\">Google Has An Internal Committee To Discuss Its Fears About The Power Of Artificial</a></span></p>\n<p><span style=\"font-family: Helvetica, Arial, sans-serif; font-size: 15.1999998092651px; line-height: 20px;\">\"Worryingly, cofounder Shane Legg thinks the team's advances could be what finishes off the human race. He </span><a style=\"color: #00709a; text-decoration: none; font-family: Helvetica, Arial, sans-serif; font-size: 15.1999998092651px; line-height: 20px;\" href=\"/lw/691/qa_with_shane_legg_on_risks_from_ai/\">told the LessWrong blog in an interview</a><span style=\"font-family: Helvetica, Arial, sans-serif; font-size: 15.1999998092651px; line-height: 20px;\">&nbsp;'Eventually, I think human extinction will probably occur, and technology will likely play a part in this'. He adds he thinks AI is the 'no.1 risk for this century'. It's ominous stuff. (</span><a style=\"color: #00709a; text-decoration: none; font-family: Helvetica, Arial, sans-serif; font-size: 15.1999998092651px; line-height: 20px;\" href=\"http://uk.businessinsider.com/why-elon-musk-is-right-to-be-worried-about-killer-robots-2014-11\">Read about Elon Musk discussing his concerns about AI here.</a>)\"<span style=\"font-family: Helvetica, Arial, sans-serif; font-size: 15.1999998092651px; line-height: 20px;\"><br /><br /></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DJgLmC5pf5j4FufJn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 2.2328505173173106e-06, "legacy": true, "legacyId": "27663", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["No5JpRCHzBrWA4jmS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T17:34:57.989Z", "modifiedAt": null, "url": null, "title": "Autonomy, utility, and desire; against consequentialism in AI design", "slug": "autonomy-utility-and-desire-against-consequentialism-in-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:33.210Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sbenthall", "createdAt": "2012-12-23T03:31:10.842Z", "isAdmin": false, "displayName": "sbenthall"}, "userId": "pbnv8yAoxSjxvEZr8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cF7uPSxCfn8L5jw9s/autonomy-utility-and-desire-against-consequentialism-in-ai", "pageUrlRelative": "/posts/cF7uPSxCfn8L5jw9s/autonomy-utility-and-desire-against-consequentialism-in-ai", "linkUrl": "https://www.lesswrong.com/posts/cF7uPSxCfn8L5jw9s/autonomy-utility-and-desire-against-consequentialism-in-ai", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Autonomy%2C%20utility%2C%20and%20desire%3B%20against%20consequentialism%20in%20AI%20design&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAutonomy%2C%20utility%2C%20and%20desire%3B%20against%20consequentialism%20in%20AI%20design%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcF7uPSxCfn8L5jw9s%2Fautonomy-utility-and-desire-against-consequentialism-in-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Autonomy%2C%20utility%2C%20and%20desire%3B%20against%20consequentialism%20in%20AI%20design%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcF7uPSxCfn8L5jw9s%2Fautonomy-utility-and-desire-against-consequentialism-in-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcF7uPSxCfn8L5jw9s%2Fautonomy-utility-and-desire-against-consequentialism-in-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 793, "htmlBody": "<p>For the sake of argument, let's consider an agent to be <strong>autonomous</strong> if:</p>\n<p>&nbsp;</p>\n<ul>\n<li>It has sensors and actuators (important for an agent)</li>\n<li>It has an internal representation of its goals. I will call this internal representation its <strong>desires.</strong></li>\n<li>It has some kind of internal planning function that given sensations and desires, chooses actions to maximize the desirability of expected outcomes</li>\n</ul>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<div>I want to point to the desires of the agent specifically to distinguish them from the goals we might infer for it if we were to observe its actions over a long period of time. Let's call these an agent's <strong>empirical goals</strong>. (I would argue that it is in many cases impossible to infer an agent's empirical goals from its behavior, but that's a distraction from my main point so I'm just going to note it here for now.)</div>\n<div><br /></div>\n<div>I also want to distinguish them from the goals it might arrive on stably if it were to execute some internal goal-modification process optimizing for certain conditions. Let's call these an agent's <strong>reflective goals</strong>.</div>\n<div><br /></div>\n<div>The term <strong>utility function</strong>, so loved by the consequentialists, frequently obscures these important distinctions. An argument that I have heard for the expansive use of the term \"utility function\" in describing agents is is: The behavior of all agents can be characterized using a utility function, therefore all agents have utility functions. This argument depends on a fallacious conflation of desire, empirical goals, and reflective goals.</div>\n<div><br /></div>\n<div>An important problem that I gather this community thinks about deeply is how to think about agents whose reflective goals are different from its present desires--say, the desires I have and have transferred over to it. For example, if I want to program an agent with desires and the capacity to reflect, then can I guarantee that it will be faithful to the desires I intended for it?</div>\n<div><br /></div>\n<div>A different problem that I am interested in is what other classes of agents there may be besides autonomous agents. Specifically, what if an agent does not have an internal representation of its desires. Is that possible? Part of my motivation for this is my interest in Buddhism.&nbsp;If an enlightened agent is one with no desires, how could one program a bodhisattva AI whose only motivation was the enlightenment of all beings?</div>\n<div><br /></div>\n<div>An objection to this line of thinking is that even an agent that desires enlightenment for all beings has desires. It must in some formal sense have a utility function, because Von Neumann. Right?</div>\n<div><br /></div>\n<div>I'm not so sure, because complexity.</div>\n<div><br /></div>\n<div>To elaborate: if we define a utility function that is so complex (either in its compressed \"spatial\" representation such as its Kolmogorov complexity or in some temporal dimension of complexity like its running time or logical depth) that it cannot be represented internally to an agent because it lacks the capacity to do so, then it would be impossible for the agent to have that utility function <em>as its desire</em>.</div>\n<div><br /></div>\n<div>However, such a utility function could be ascribed to the agent as its empirical goal if the agent were both internally composed and embedded in the world in such a way that it acted <em>as if</em> it had those complex desires. This is consistent with, for example, Buddhist writings about how enlightened beings act with <em>spontaneous compassion</em>. Goal oriented planning does not seem to get in the way here.</div>\n<div><br /></div>\n<div>How could an AI be compassionate? Perhaps an AI could be empathetic if it could perceive, through its sensors, the desires (or empirical goals, or reflective goals) of other agents and internalize them as its own. Perhaps it does this only temporarily. Perhaps it has, in place of a goal-directed planning mechanism, a way of reconciling differences in its internalized goal functions. This internal logic for reconciling preferences is obviously critical for the identity of the agent and is the Achilles heel of the main thrust of this argument. Surely that logic could be characterized with a utility function and would be, effectively, the agent's desire?</div>\n<div><br /></div>\n<div>Not so, I repeat, if that logic were not a matter of internal representation as much as the logic of the entire system composed of both the agent and its environment. In other words, if the agent's desires are identical to the logic of the entire world within which it is a part, then it no longer has desire in the sense defined above. It is also no longer autonomous in the sense defined above. Nevertheless, I think it is an important kind of agent when one is considering possible paradigms of ethical AI. In general, I think that drawing on non-consequentialist ethics for inspiration in designing \"friendly\" AI is a promising research trajectory.</div>\n<div><br /></div>\n<div><br /></div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cF7uPSxCfn8L5jw9s", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 7, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "27664", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T19:29:34.580Z", "modifiedAt": null, "url": null, "title": "Good things to have learned....", "slug": "good-things-to-have-learned", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:36.922Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zfZNkAWQxTbm5tLz5/good-things-to-have-learned", "pageUrlRelative": "/posts/zfZNkAWQxTbm5tLz5/good-things-to-have-learned", "linkUrl": "https://www.lesswrong.com/posts/zfZNkAWQxTbm5tLz5/good-things-to-have-learned", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Good%20things%20to%20have%20learned....&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGood%20things%20to%20have%20learned....%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzfZNkAWQxTbm5tLz5%2Fgood-things-to-have-learned%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Good%20things%20to%20have%20learned....%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzfZNkAWQxTbm5tLz5%2Fgood-things-to-have-learned", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzfZNkAWQxTbm5tLz5%2Fgood-things-to-have-learned", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 104, "htmlBody": "<p>I was looking at a discussion of what should be in a college curriculum, and as such discussions seem to go, there was a big list of things everyone should study, and some political claims about what's being offered but shouldn't be.&nbsp;</p>\n<p>Instead, what do you wish you'd studied in college? What do you wish other people had studied in college? On the latter, do you think everyone should have studied it, or do you just wish more people knew about it? Approximately what percentage of people?</p>\n<p>Of course, this doesn't have to be limited to college. People could learn the same things earlier or later.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zfZNkAWQxTbm5tLz5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 23, "extendedScore": null, "score": 2.233145557737234e-06, "legacy": true, "legacyId": "27665", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T22:33:17.760Z", "modifiedAt": null, "url": null, "title": "The Bay Area Solstice", "slug": "the-bay-area-solstice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.475Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alex_Altair", "createdAt": "2010-07-21T18:30:40.806Z", "isAdmin": false, "displayName": "Alex_Altair"}, "userId": "5wu9jG4pm9q6xjZ9R", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iA52JzRxkHkJsX6XW/the-bay-area-solstice", "pageUrlRelative": "/posts/iA52JzRxkHkJsX6XW/the-bay-area-solstice", "linkUrl": "https://www.lesswrong.com/posts/iA52JzRxkHkJsX6XW/the-bay-area-solstice", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Bay%20Area%20Solstice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Bay%20Area%20Solstice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA52JzRxkHkJsX6XW%2Fthe-bay-area-solstice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Bay%20Area%20Solstice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA52JzRxkHkJsX6XW%2Fthe-bay-area-solstice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA52JzRxkHkJsX6XW%2Fthe-bay-area-solstice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p><img src=\"http://alexaltair.files.wordpress.com/2014/11/10655288_10202991723613603_4297000247357932899_o-1.jpg?w=1200\" alt=\"\" width=\"600\" height=\"206\" /></p>\n<p>&nbsp;</p>\n<p>As the holiday season approaches, we continue our tradition of celebrating the winter solstice.</p>\n<p><span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\">This event is the offspring of Raemon's&nbsp;</span><a style=\"font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\" href=\"/lw/l35/solstice_2014_kickstarter_and_megameetup/\">New York Solstice</a><span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\">. The core of the event is a collection of songs old and new, silly and profound, led by the well-calibrated Bayesian choir. There will be bean bag chairs and candles. There will be&nbsp;</span><span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\">campfire and&nbsp;</span><span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\">chocolates (in case of dementors).</span></p>\n<p>When: The Bay Area Solstice will be held on 13 December at 7:00 PM.</p>\n<p>Where: We've rented the Humanist Hall, at&nbsp;<span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\">390 27th St, Oakland, CA 94612.</span></p>\n<p><span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\">All humanists or transhumanists are welcome. We'll be diving our minds into the nature of the universe, both good and bad. We'll stare into the abyss of death, and into the radiance of our ability to remove it. We will recognize each other as allies and agents.</span></p>\n<p><span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\">We're glad to provide aspiring rationalists with an alternative or addition to any holiday celebrations. There is an expected attendance of around 80 people.&nbsp;</span></p>\n<p><span style=\"color: #222222; font-family: arial, sans-serif; font-size: 13px; line-height: 16.1200008392334px;\"><a href=\"https://www.eventbrite.com/e/bay-area-solstice-tickets-14522572405\">Get your tickets here!</a>&nbsp;And if you'd like to help us put it together, PM me.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"vtozKm5BZ8gf6zd45": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iA52JzRxkHkJsX6XW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 29, "extendedScore": null, "score": 0.000124, "legacy": true, "legacyId": "27640", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CNGzKea2nbzixpxcd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-03T22:33:20.202Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes December 2014", "slug": "rationality-quotes-december-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:25:33.108Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Salemicus", "createdAt": "2012-05-10T20:50:25.455Z", "isAdmin": false, "displayName": "Salemicus"}, "userId": "D8cdrPXwhhiPdqkSz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DCQmStPDtwKFy33Nv/rationality-quotes-december-2014", "pageUrlRelative": "/posts/DCQmStPDtwKFy33Nv/rationality-quotes-december-2014", "linkUrl": "https://www.lesswrong.com/posts/DCQmStPDtwKFy33Nv/rationality-quotes-december-2014", "postedAtFormatted": "Wednesday, December 3rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20December%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20December%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDCQmStPDtwKFy33Nv%2Frationality-quotes-december-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20December%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDCQmStPDtwKFy33Nv%2Frationality-quotes-december-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDCQmStPDtwKFy33Nv%2Frationality-quotes-december-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 132, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; -webkit-text-size-adjust: auto;\">Another month, another rationality quotes thread. The rules are:</p>\n<ul style=\"padding: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; -webkit-text-size-adjust: auto;\">\n<li>Please post all quotes separately, so that they can be upvoted or downvoted separately. (If they are strongly related, reply to your own comments. If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote from Less Wrong itself, HPMoR, Eliezer Yudkowsky, or Robin Hanson. If you'd like to revive an old quote from one of those sources, please do so&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/i6h/rationality_quotes_from_people_associated_with/\">here</a>.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n<li>Provide sufficient information (URL, title, date, page number, etc.) to enable a reader to find the place where you read the quote, or its original source if available. Do not quote with only a name.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DCQmStPDtwKFy33Nv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "27651", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 447, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iWTZj26MfR8e8b9nm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-04T07:26:46.688Z", "modifiedAt": null, "url": null, "title": "Where is the line between being a good child and taking care of oneself?", "slug": "where-is-the-line-between-being-a-good-child-and-taking-care", "viewCount": null, "lastCommentedAt": "2017-06-17T04:37:02.953Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkadlubo", "createdAt": "2014-02-22T08:36:27.050Z", "isAdmin": false, "displayName": "jkadlubo"}, "userId": "5aXNkaPZ67yLwL2ES", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZKNuXJSDWtSoBFX4q/where-is-the-line-between-being-a-good-child-and-taking-care", "pageUrlRelative": "/posts/ZKNuXJSDWtSoBFX4q/where-is-the-line-between-being-a-good-child-and-taking-care", "linkUrl": "https://www.lesswrong.com/posts/ZKNuXJSDWtSoBFX4q/where-is-the-line-between-being-a-good-child-and-taking-care", "postedAtFormatted": "Thursday, December 4th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Where%20is%20the%20line%20between%20being%20a%20good%20child%20and%20taking%20care%20of%20oneself%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhere%20is%20the%20line%20between%20being%20a%20good%20child%20and%20taking%20care%20of%20oneself%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZKNuXJSDWtSoBFX4q%2Fwhere-is-the-line-between-being-a-good-child-and-taking-care%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Where%20is%20the%20line%20between%20being%20a%20good%20child%20and%20taking%20care%20of%20oneself%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZKNuXJSDWtSoBFX4q%2Fwhere-is-the-line-between-being-a-good-child-and-taking-care", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZKNuXJSDWtSoBFX4q%2Fwhere-is-the-line-between-being-a-good-child-and-taking-care", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1114, "htmlBody": "<p>I recently saw some posts here about how LW helps with personal stuff and that it's a good idea to post here<sup>1</sup>. Plus, you are the most supportive people I've ever met. I still hesitate. Know my courage. Also, I pretty much always put needs and feeling of other people ahead of mine, because \"mine are not as important\" (more on that in note 3 and 5). Saying my feelings and needs out loud is really scary. Writing them down is almost unimaginable.</p>\n<p>I recently parted ways with my psychologist, but don't yet want to find a new one. Between our last meetings I had a thought that (as usually) was not explored deep enough. And I think I need to go deeper in it. Maybe you can point me in <del>the right di</del>some interesting directions?</p>\n<p>&nbsp;</p>\n<p>A bit of background information about me and my parents: as a child and adolescent I did not exist as a separate person. I lived by the side of perfection, always not good enough, or simply not good. The chant of that time was \"why can't you ... like your sister?\" (have good grades, keep the room tidy, have friends, be nice - insert almost anything you can imagine)<sup>2</sup>. There were also other problems, but let's not make this part too long. &nbsp;</p>\n<p>When I grew up and discovered that this all was not normal nor right, I became bitter and angry<sup>3</sup>. I keep in touch with them, act as if almost everything is fine, but boil inside a lot. &nbsp;</p>\n<p>On the surface I want to fix things. I want to be able to ask my mum to teach me something (I haven't been able to do this since I was a preschooler, partly because I feared being laughed at), I want to look at my dad and not remember him calling me a murderer<sup>3</sup>. In my country it's even unthinkable that I am trying to cut the contact with one of my grandmothers<span style=\"font-size: 11.1999998092651px;\"><sup>4</sup></span>. &nbsp;</p>\n<p>So I invented that I want my mother to understand <em>why</em> what she did was hurting me and apologise. She knows that I think she wronged me, though I doubt she realizes how very bitter I am about it all. For her, the solution is to start anew, with a blank space. I can't do that; I spent my adolescence being hit by her and apologising to her for whatever she deemed my fault on a given day. The problem with my solution is that she's incapable of it. For the sake of simplification: she does not comprehend other people's emotions (but she does have emotions of her own and she mostly comprehends them)<sup>5</sup>.</p>\n<p>&nbsp;</p>\n<p>My new thought to look at \"my solution\" from a different perspective. Maybe me wanting to make amends with them this particular way is a bit like looking for approval the same way I did as a child. Maybe my mother saying \"I hurt you, I'm sorry\" would be like her saying \"you were right, you are a good girl\". Since I never got approval as a child, I should not expect it as an adult. Does this look sensible?</p>\n<p>Maybe the adult thing for me to do would be to stop looking for these pats-on-the-back. And also the tiny pats-on-the-back I get when I act around them as if almost everything is fine while boiling inside and they reciprocate niceties. And that might mean cutting the contact as much as I can (which is of course scary and unimaginable). Or am I just going in one direction, where more are possible? &nbsp;</p>\n<p>Maybe I should stop trying to invent ways to fix things<sup>6</sup>. Maybe I should tell them how angry I am, and tell them in a way that prohibits them from interrupting me or reacting sooner than let's say a week later. But then again - would that do any good? Would they be able to understand me if they've never tried it before? Or is the question \"would that do any good\" just an example of my regular tendency to place other people ahead and diminute my needs?</p>\n<p>&nbsp;</p>\n<p>1. <a title=\"Don't be afraid of asking personally important questions\" href=\"/lw/l5w/dont_be_afraid_of_asking_personally_important\" target=\"_blank\">Asking personal questions on LW</a>, I don't remember the other ones now</p>\n<p>2. She was more brilliant than me, managed to keep some friends even though we were the only kids in our class (yes, younger, but the same class - she went to school early and was always at the top) living outside the area etc. Another chant was \"if you don't lose weight now, you'll be a cripple when you grow up\", even though I had a perfectly normal figure. Everybody would routinely mix our names. The parents would routinely mix up our preferences about food, colours, favourite subjects etc. In a way: there was no me, there was just her and a faulty copy of her, who would keep being faulty on purpose, in order to enrage mother.</p>\n<p>3. This last straw fell when my father (who was much more taciturn in scolding me, so back then I still had some sypathy for him) heard that my son and his (then) only grandchild suffered from a genetic disease that kills babies before they turn 2. After I explained the genetics of the disease, testing fetuses, chances, potential choices etc. he showed no sympathy, only asked \"but you do know that you're commiting an infanticide?\" His catholicism was more important to him than his daughter's grief over her dying child. Then it took me two weeks to stop feeling for him and decide that his reaction was inappropriate.</p>\n<p>4. This last straw fell when she was playing with said dying child while I was away for a couple of hours. I got a letter regarding some testing in another country. She opened the letter, saw it was in English, took a dictionary, failed to make any sense of it and asked other people to help her. And when I came back and got angry at her reading my correspondece, she got outraged because she considered it her right. <strong>But</strong> I kept quiet for another year or two before I told her I don't want her near my children.</p>\n<p>5. She thaught me empathy this way: I was always supposed to take into account how my actions would look from her point of view (given that she would not even try to reciprocate and always choose one of the worst interpretations). Empathy is my superpower now; I see a person and <em>know</em> what they feel about a situation, though I lack confidence in acting upon my insight.</p>\n<p>6. At some point I was planning on employing someone to help her with the \"understand <em>why</em> what she did was hurting me\" part.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZKNuXJSDWtSoBFX4q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 21, "extendedScore": null, "score": 6.1e-05, "legacy": true, "legacyId": "27557", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["twJaro2hsjQzYzuwg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-04T13:38:26.339Z", "modifiedAt": null, "url": null, "title": "Potential vs already existent people and aggregation", "slug": "potential-vs-already-existent-people-and-aggregation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:34.395Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/maYNjyuZhn4bSm9zn/potential-vs-already-existent-people-and-aggregation", "pageUrlRelative": "/posts/maYNjyuZhn4bSm9zn/potential-vs-already-existent-people-and-aggregation", "linkUrl": "https://www.lesswrong.com/posts/maYNjyuZhn4bSm9zn/potential-vs-already-existent-people-and-aggregation", "postedAtFormatted": "Thursday, December 4th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Potential%20vs%20already%20existent%20people%20and%20aggregation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APotential%20vs%20already%20existent%20people%20and%20aggregation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmaYNjyuZhn4bSm9zn%2Fpotential-vs-already-existent-people-and-aggregation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Potential%20vs%20already%20existent%20people%20and%20aggregation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmaYNjyuZhn4bSm9zn%2Fpotential-vs-already-existent-people-and-aggregation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmaYNjyuZhn4bSm9zn%2Fpotential-vs-already-existent-people-and-aggregation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 501, "htmlBody": "<p><strong>EDIT</strong>: the purpose of this post is simply to show that there is a difference between certain reasoning for already existing and potential people. I don't argue that aggregation is the <strong>only</strong> difference, nor (in this post) that total utilitarianism for potential people is wrong. Simply that the case for existing people is stronger than for potential people.</p>\n<p>Consider the following choices:</p>\n<ul>\n<li>You must choose between torturing someone for 50 years, or torturing 3^^^3 people for a millisecond each (yes, it's a more symmetric variant on the <a href=\"/lw/kn/torture_vs_dust_specks/\">dust-specks vs torture</a> problem).</li>\n<li>You must choose between creating someone who will be tortured for 50 years, or creating 3^^^3 people who will each get tortured for a millisecond each.</li>\n</ul>\n<p>Some people might feel that these two choices are the same. There are some key differences between them, however - and not only because the second choice seems more underspecified than the first. The difference is the effect of <a href=\"/lw/1d5/expected_utility_without_the_independence_axiom/\">aggregation</a> - of facing the same choice again and again and again. And again...</p>\n<p>There are roughly 1.6 billion seconds in 50 years (hence 1.6 trillion milliseconds in 50 years). Assume <em>a fixed population</em> of 3^^^3 people, and assume that you were going to face the first choice 1.6 trillion times (in each case, the person to be tortured is assigned randomly and independently). Then choosing \"50 years\" each time results in 1.6 trillion people getting tortured for 50 years (the chance of the same person being chosen to be tortured twice is of the order of 50/3^^^3 - closer to zero than most people can imagine). Choosing \"a millisecond\" each time results in 3^^^3 people, each getting tortured for (slightly more than) 50 years.</p>\n<p>The choice there is clear: pick \"50 years\". Now, you could argue that your decision should change based on how often you (or people like you) expects to face the same choice, and assumes a fixed population of size 3^^^3, but there is a strong intuitive case to be made that the 50 years of torture is the way to go.</p>\n<p>Compare with the second choice now. Choosing \"50 years\" 1.6 trillion times results in the creation of 1.6 trillion people who get tortured for 50 years. The \"a millisecond\" choice results in 1.6 trillion times 3^^^3 people being created, each tortured for a millisecond. Conditional on what the rest of the life of these people is like, many people (including me) would feel the \"a millisecond\" option is much better.</p>\n<p>As far as I can tell (please do post suggestions), there is no way of aggregating impacts on potential people you are creating, in the same way that you can aggregate impacts on existing people (of course, you can first create potential people, then add impacts to them - or add impacts that will affect them when they get created - but this isn't the same thing). Thus the two situations seem justifiably different, and there is no strong reason to assign the intuitions of the first case to the second.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "maYNjyuZhn4bSm9zn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 2.2355174944390436e-06, "legacy": true, "legacyId": "27669", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3wYTFWY3LKQCnAptN", "tGhz4aKyNzXjvnWhX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-04T17:25:24.060Z", "modifiedAt": null, "url": null, "title": "Meetup : LW Copenhagen: December Meetup", "slug": "meetup-lw-copenhagen-december-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:39.067Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ruby", "createdAt": "2014-04-03T03:38:23.914Z", "isAdmin": true, "displayName": "Ruby"}, "userId": "qgdGA4ZEyW7zNdK84", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ptzro8R9yjEE4NNtx/meetup-lw-copenhagen-december-meetup", "pageUrlRelative": "/posts/ptzro8R9yjEE4NNtx/meetup-lw-copenhagen-december-meetup", "linkUrl": "https://www.lesswrong.com/posts/ptzro8R9yjEE4NNtx/meetup-lw-copenhagen-december-meetup", "postedAtFormatted": "Thursday, December 4th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20LW%20Copenhagen%3A%20December%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20LW%20Copenhagen%3A%20December%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fptzro8R9yjEE4NNtx%2Fmeetup-lw-copenhagen-december-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20LW%20Copenhagen%3A%20December%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fptzro8R9yjEE4NNtx%2Fmeetup-lw-copenhagen-december-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fptzro8R9yjEE4NNtx%2Fmeetup-lw-copenhagen-december-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17o'>LW Copenhagen: December Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 December 2014 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Stundeterhuset, K\u00f8bmagergade 52, 1150 K\u00f8benhavn</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hey all,</p>\n\n<p>It's been a while (I've been out of the country a lot), but I'm back it Copenhagen for a bit and we ought to have another meet up.\nI'm going to call one for:</p>\n\n<p>Saturday, 20th December\n3:00pm\nStudenterhuset</p>\n\n<p>Topic: Life Strategicness + Social</p>\n\n<p>We'll spend some time on strategising aspects of our lives, be it in small or large ways (<a href=\"http://lesswrong.com/lw/2p5/humans_are_not_automatically_strategic/\" rel=\"nofollow\">http://lesswrong.com/lw/2p5/humans_are_not_automatically_strategic/</a>), debugging some questions - all with a bit of wisdom from CFAR - and then relaxing in the great environs that Studenterhuset offers.</p>\n\n<p>Cheers,\nRuby</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17o'>LW Copenhagen: December Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ptzro8R9yjEE4NNtx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.236012461267255e-06, "legacy": true, "legacyId": "27670", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___LW_Copenhagen__December_Meetup\">Discussion article for the meetup : <a href=\"/meetups/17o\">LW Copenhagen: December Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 December 2014 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Stundeterhuset, K\u00f8bmagergade 52, 1150 K\u00f8benhavn</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hey all,</p>\n\n<p>It's been a while (I've been out of the country a lot), but I'm back it Copenhagen for a bit and we ought to have another meet up.\nI'm going to call one for:</p>\n\n<p>Saturday, 20th December\n3:00pm\nStudenterhuset</p>\n\n<p>Topic: Life Strategicness + Social</p>\n\n<p>We'll spend some time on strategising aspects of our lives, be it in small or large ways (<a href=\"http://lesswrong.com/lw/2p5/humans_are_not_automatically_strategic/\" rel=\"nofollow\">http://lesswrong.com/lw/2p5/humans_are_not_automatically_strategic/</a>), debugging some questions - all with a bit of wisdom from CFAR - and then relaxing in the great environs that Studenterhuset offers.</p>\n\n<p>Cheers,\nRuby</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___LW_Copenhagen__December_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/17o\">LW Copenhagen: December Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : LW Copenhagen: December Meetup", "anchor": "Discussion_article_for_the_meetup___LW_Copenhagen__December_Meetup", "level": 1}, {"title": "Discussion article for the meetup : LW Copenhagen: December Meetup", "anchor": "Discussion_article_for_the_meetup___LW_Copenhagen__December_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PBRWb2Em5SNeWYwwB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-04T20:19:31.824Z", "modifiedAt": null, "url": null, "title": "Meetup : Toronto EA meetup", "slug": "meetup-toronto-ea-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Giles", "createdAt": "2011-02-11T02:30:16.999Z", "isAdmin": false, "displayName": "Giles"}, "userId": "H347ba3KZMP8XoDt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tj8yzMt9ndE2i7qDP/meetup-toronto-ea-meetup", "pageUrlRelative": "/posts/tj8yzMt9ndE2i7qDP/meetup-toronto-ea-meetup", "linkUrl": "https://www.lesswrong.com/posts/tj8yzMt9ndE2i7qDP/meetup-toronto-ea-meetup", "postedAtFormatted": "Thursday, December 4th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Toronto%20EA%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Toronto%20EA%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftj8yzMt9ndE2i7qDP%2Fmeetup-toronto-ea-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Toronto%20EA%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftj8yzMt9ndE2i7qDP%2Fmeetup-toronto-ea-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftj8yzMt9ndE2i7qDP%2Fmeetup-toronto-ea-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 63, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17p'>Toronto EA meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 December 2014 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Toronto</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><a href=\"http://www.meetup.com/THINK-Toronto/events/219068850/\" rel=\"nofollow\">See here</a> for location and RSVP.</p>\n\n<p>We haven't had an effective altruism meetup in Toronto for a while, so time for a relaunch! No particular fixed topic, just a chance to meet each other, hang out and discuss what's new.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17p'>Toronto EA meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tj8yzMt9ndE2i7qDP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.2363923402547274e-06, "legacy": true, "legacyId": "27671", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Toronto_EA_meetup\">Discussion article for the meetup : <a href=\"/meetups/17p\">Toronto EA meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 December 2014 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Toronto</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><a href=\"http://www.meetup.com/THINK-Toronto/events/219068850/\" rel=\"nofollow\">See here</a> for location and RSVP.</p>\n\n<p>We haven't had an effective altruism meetup in Toronto for a while, so time for a relaunch! No particular fixed topic, just a chance to meet each other, hang out and discuss what's new.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Toronto_EA_meetup1\">Discussion article for the meetup : <a href=\"/meetups/17p\">Toronto EA meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Toronto EA meetup", "anchor": "Discussion_article_for_the_meetup___Toronto_EA_meetup", "level": 1}, {"title": "Discussion article for the meetup : Toronto EA meetup", "anchor": "Discussion_article_for_the_meetup___Toronto_EA_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-05T01:09:37.040Z", "modifiedAt": null, "url": null, "title": "Could you be Prof Nick Bostrom's sidekick?", "slug": "could-you-be-prof-nick-bostrom-s-sidekick", "viewCount": null, "lastCommentedAt": "2017-12-06T01:46:25.212Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertWiblin", "createdAt": "2009-03-07T08:59:22.724Z", "isAdmin": false, "displayName": "RobertWiblin"}, "userId": "rcwfERY7okewFqYLF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3K6SWChoKwvaMGmTW/could-you-be-prof-nick-bostrom-s-sidekick", "pageUrlRelative": "/posts/3K6SWChoKwvaMGmTW/could-you-be-prof-nick-bostrom-s-sidekick", "linkUrl": "https://www.lesswrong.com/posts/3K6SWChoKwvaMGmTW/could-you-be-prof-nick-bostrom-s-sidekick", "postedAtFormatted": "Friday, December 5th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Could%20you%20be%20Prof%20Nick%20Bostrom's%20sidekick%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACould%20you%20be%20Prof%20Nick%20Bostrom's%20sidekick%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3K6SWChoKwvaMGmTW%2Fcould-you-be-prof-nick-bostrom-s-sidekick%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Could%20you%20be%20Prof%20Nick%20Bostrom's%20sidekick%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3K6SWChoKwvaMGmTW%2Fcould-you-be-prof-nick-bostrom-s-sidekick", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3K6SWChoKwvaMGmTW%2Fcould-you-be-prof-nick-bostrom-s-sidekick", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 403, "htmlBody": "<p>If funding were available, the Centre for Effective Altruism would consider hiring someone to work closely with Prof Nick Bostrom to provide anything and everything he needs to be more productive. Bostrom is obviously the Director of the Future of Humanity Institute at Oxford University, and author of Superintelligence, the best guide yet to the possible risks posed by artificial intelligence.</p>\n<p>Nobody has yet confirmed they will fund this role, but we are nevertheless interested in getting expressions of interest from suitable candidates.</p>\n<p>The list of required characteristics is hefty, and the position would be a challenging one:</p>\n<ul>\n<li>Willing to commit to the role for at least a year, and preferably several</li>\n<li>Able to live and work in Oxford during this time</li>\n<li>Conscientious and discreet</li>\n<li>Trustworthy</li>\n<li>Able to keep flexible hours (some days a lot of work, others not much)</li>\n<li>Highly competent at almost everything in life (for example, organising travel, media appearances, choosing good products, and so on)</li>\n<li>Will not screw up and look bad when dealing with external parties (e.g. media, event organisers, the university)</li>\n<li>Has a good personality 'fit' with Bostrom</li>\n<li>Willing to do some tasks that are not high-status</li>\n<li>Willing to help Bostrom with both his professional and personal life (to free up his attention)</li>\n<li>Can speak English well</li>\n<li>Knowledge of rationality, philosophy and artificial intelligence would also be helpful, and would allow you to also do more work as a research assistant.</li>\n</ul>\n<p>The research Bostrom can do is unique; to my knowledge we don't have anyone who has made such significant strides clarifying the biggest risks facing humanity as a whole. As a result, helping increase Bostrom's output by say, 20%, would be a major contribution. This person's work would also help the rest of the Future of Humanity Institute run smoothly.</p>\n<div>The role would offer significant skill development in operations, some skill development in communications and research, and the chance to build extensive relationships with the people and organisations working on existential risks.</div>\n<div><br /></div>\n<div>If you would like to know more, or be added to the list of potential candidates, please email me: robert [dot] wiblin [at] centreforeffectivealtruism [dot] org. Feel free to share this post around.</div>\n<div><br /></div>\n<div>Note that we are also <a href=\"/r/discussion/lw/laf/the_centre_for_effective_altruism_is_hiring_to/\">hiring for a bunch of other roles</a>, with applications closing Friday the 12th December.</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"K6oowPZC6kds6LDTg": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3K6SWChoKwvaMGmTW", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": 76, "extendedScore": null, "score": 0.000194, "legacy": true, "legacyId": "27672", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-05-11T21:18:32.604Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": true, "hideFrontpageComments": false, "maxBaseScore": 53, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9wqcTrFt2cPz7EpjL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-05T07:56:01.617Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington, D.C.: Brains", "slug": "meetup-washington-d-c-brains", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/REAWarY2c2hXbAnip/meetup-washington-d-c-brains", "pageUrlRelative": "/posts/REAWarY2c2hXbAnip/meetup-washington-d-c-brains", "linkUrl": "https://www.lesswrong.com/posts/REAWarY2c2hXbAnip/meetup-washington-d-c-brains", "postedAtFormatted": "Friday, December 5th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%2C%20D.C.%3A%20Brains&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%2C%20D.C.%3A%20Brains%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FREAWarY2c2hXbAnip%2Fmeetup-washington-d-c-brains%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%2C%20D.C.%3A%20Brains%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FREAWarY2c2hXbAnip%2Fmeetup-washington-d-c-brains", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FREAWarY2c2hXbAnip%2Fmeetup-washington-d-c-brains", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17q'>Washington, D.C.: Brains</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>talk about brains, neuroscience, and related topics.</strong> Per the norm, we plan to let people congregate from 3:00 to 3:30 before kicking things off.</p>\n\n<p>As with prior informal-discussion meetups, conversation on any subject of interest to attendees (be it in the main conversation or in a side conversation) is both permitted and encouraged, but we suggest taking advantage of the meetup topic as a Schelling point.</p>\n\n<p><strong><em>Upcoming Meetups:</em></strong></p>\n\n<ul>\n<li><strong>Dec. 14:</strong> TBA (to be summarized)</li>\n<li><strong>Dec. 21:</strong> Fun &amp; Games (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17q'>Washington, D.C.: Brains</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "REAWarY2c2hXbAnip", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 2.2379129529815487e-06, "legacy": true, "legacyId": "27673", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Brains\">Discussion article for the meetup : <a href=\"/meetups/17q\">Washington, D.C.: Brains</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>talk about brains, neuroscience, and related topics.</strong> Per the norm, we plan to let people congregate from 3:00 to 3:30 before kicking things off.</p>\n\n<p>As with prior informal-discussion meetups, conversation on any subject of interest to attendees (be it in the main conversation or in a side conversation) is both permitted and encouraged, but we suggest taking advantage of the meetup topic as a Schelling point.</p>\n\n<p><strong id=\"Upcoming_Meetups_\"><em>Upcoming Meetups:</em></strong></p>\n\n<ul>\n<li><strong>Dec. 14:</strong> TBA (to be summarized)</li>\n<li><strong>Dec. 21:</strong> Fun &amp; Games (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Brains1\">Discussion article for the meetup : <a href=\"/meetups/17q\">Washington, D.C.: Brains</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington, D.C.: Brains", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Brains", "level": 1}, {"title": "Upcoming Meetups:", "anchor": "Upcoming_Meetups_", "level": 2}, {"title": "Discussion article for the meetup : Washington, D.C.: Brains", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Brains1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-05T09:51:28.750Z", "modifiedAt": null, "url": null, "title": "Editing meetups", "slug": "editing-meetups", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:32.967Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "luminosity", "createdAt": "2010-05-31T03:00:24.334Z", "isAdmin": false, "displayName": "luminosity"}, "userId": "4SuPdAqJpj7TzsaqG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/junwKcq7EbNHTJ5uk/editing-meetups", "pageUrlRelative": "/posts/junwKcq7EbNHTJ5uk/editing-meetups", "linkUrl": "https://www.lesswrong.com/posts/junwKcq7EbNHTJ5uk/editing-meetups", "postedAtFormatted": "Friday, December 5th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Editing%20meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEditing%20meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjunwKcq7EbNHTJ5uk%2Fediting-meetups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Editing%20meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjunwKcq7EbNHTJ5uk%2Fediting-meetups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjunwKcq7EbNHTJ5uk%2Fediting-meetups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p>Several times now I've had problems with meetups posting with the wrong times, and then been unable to fix them. Am I missing something on the meetup page that I could go to to correct the meetup, or is this impossible at the moment? Alternatively, is this something a moderator can do, and if so, who should I speak to, to get a meetup fixed?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "junwKcq7EbNHTJ5uk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 2.2381651885541187e-06, "legacy": true, "legacyId": "27674", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-05T21:02:24.692Z", "modifiedAt": null, "url": null, "title": "[link] On the abundance of extraterrestrial life after the Kepler mission", "slug": "link-on-the-abundance-of-extraterrestrial-life-after-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:36.081Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gunnar_Zarncke", "createdAt": "2013-07-20T15:40:42.323Z", "isAdmin": false, "displayName": "Gunnar_Zarncke"}, "userId": "qmJFRN7jitjPsuF3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Di6wCS8JbRwXoquF2/link-on-the-abundance-of-extraterrestrial-life-after-the", "pageUrlRelative": "/posts/Di6wCS8JbRwXoquF2/link-on-the-abundance-of-extraterrestrial-life-after-the", "linkUrl": "https://www.lesswrong.com/posts/Di6wCS8JbRwXoquF2/link-on-the-abundance-of-extraterrestrial-life-after-the", "postedAtFormatted": "Friday, December 5th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20On%20the%20abundance%20of%20extraterrestrial%20life%20after%20the%20Kepler%20mission&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20On%20the%20abundance%20of%20extraterrestrial%20life%20after%20the%20Kepler%20mission%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDi6wCS8JbRwXoquF2%2Flink-on-the-abundance-of-extraterrestrial-life-after-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20On%20the%20abundance%20of%20extraterrestrial%20life%20after%20the%20Kepler%20mission%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDi6wCS8JbRwXoquF2%2Flink-on-the-abundance-of-extraterrestrial-life-after-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDi6wCS8JbRwXoquF2%2Flink-on-the-abundance-of-extraterrestrial-life-after-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 39, "htmlBody": "<p><strong><a href=\"http://arxiv.org/ftp/arxiv/papers/1412/1412.1302.pdf\">On the abundance of extraterrestrial life after the Kepler mission</a>&nbsp;Amri Wandel</strong></p>\n<p>Some recent calculation of the <a href=\"http://en.wikipedia.org/wiki/Drake_equation\">Drake Equation</a>&nbsp;with estimates of the likelihood and logevitiy of civilizations</p>\n<p><strong>Related: </strong><a href=\"http://wiki.lesswrong.com/wiki/Great_Filter\">The Great Filter</a>&nbsp;and&nbsp;<a href=\"/lw/7w8/planets_in_the_habitable_zone_the_drake_equation/\">Planets in the habitable zone, the Drake Equation, and the Great Filter</a></p>\n<div><br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NGtNzdS88JtEQdRP4": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Di6wCS8JbRwXoquF2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 2.239632012005962e-06, "legacy": true, "legacyId": "27675", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MpFbiQGxqrwQyfw4a"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-05T21:20:43.079Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-25", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dJ8goSLTgSuGBgQSo/weekly-lw-meetups-25", "pageUrlRelative": "/posts/dJ8goSLTgSuGBgQSo/weekly-lw-meetups-25", "linkUrl": "https://www.lesswrong.com/posts/dJ8goSLTgSuGBgQSo/weekly-lw-meetups-25", "postedAtFormatted": "Friday, December 5th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdJ8goSLTgSuGBgQSo%2Fweekly-lw-meetups-25%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdJ8goSLTgSuGBgQSo%2Fweekly-lw-meetups-25", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdJ8goSLTgSuGBgQSo%2Fweekly-lw-meetups-25", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 548, "htmlBody": "<p><strong>This summary was posted to LW Main on November 28th. The following week's summary is <a href=\"/lw/lcs/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/17o\">Copenhagen: December Meetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/160\">East Coast Solstice Megameetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/15w\">European Community Weekend 2015:&nbsp;<span class=\"date\">12 June 2015 12:00PM</span></a></li>\n<li><a href=\"/meetups/17d\">Frankfurt:&nbsp;<span class=\"date\">07 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/173\">Saint Petersburg, Russia meetup: \"Low hanging fruit\":&nbsp;<span class=\"date\">19 December 2014 07:00PM</span></a></li>\n<li><a href=\"/meetups/17e\">Urbana-Champaign: Seeking advice:&nbsp;<span class=\"date\">30 November 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/16o\">Utrecht: Game Theory:&nbsp;<span class=\"date\">30 November 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17a\">Utrecht: Rationality Games:&nbsp;<span class=\"date\">14 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17b\">Utrecht:&nbsp;<span class=\"date\">21 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17c\">Utrecht: a critique of effective altruism:&nbsp;<span class=\"date\">04 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/17f\">Warsaw December Meetup:&nbsp;<span class=\"date\">05 December 2014 04:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX - Caffe Medici:&nbsp;<span class=\"date\">29 November 2025 01:30PM</span></a></li>\n<li><a href=\"/meetups/16r\">Seattle Secular Solstice:&nbsp;<span class=\"date\">13 December 2014 05:30PM</span></a></li>\n<li><a href=\"/meetups/16y\">[Vienna] Rationality Weekend Vienna:&nbsp;<span class=\"date\">13 December 2014 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\">Berlin</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Boston.2C_MA\">Boston</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Brussels.2C_Belgium\">Brussels</a></strong><strong>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Buffalo.2C_NY\">Buffalo</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Canberra\">Canberra</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Columbus.2C_OH\">Columbus</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Moscow.2C_Russia\">Moscow</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Philadelphia.2C_PA\">Philadelphia</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Research_Triangle.2C_NC_.28Raleigh.2FDurham.2FChapel_Hill.29\">Research Triangle NC</a>,</strong><strong>&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Sydney\">Sydney</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a></strong><strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington DC</strong></a></strong>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview is posted on the front page every Friday. These are an attempt to collect information on all the meetups happening in upcoming weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll also have the benefit of having your meetup mentioned in a weekly overview. These overview posts are moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cincinnati</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cleveland</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> </strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tel_Aviv.2C_Israel\">Tel Aviv</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Warsaw.2C_Poland\">Warsaw</a></strong><strong>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dJ8goSLTgSuGBgQSo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.239672058216587e-06, "legacy": true, "legacyId": "27638", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3ZtDjF3MdWcCDCWN3", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-05T23:44:57.913Z", "modifiedAt": null, "url": null, "title": "[Link] Eric S. Raymond - Me and Less Wrong", "slug": "link-eric-s-raymond-me-and-less-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.476Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "philh", "createdAt": "2011-06-21T10:04:52.011Z", "isAdmin": false, "displayName": "philh"}, "userId": "nrP5EZZj4vRvYwQ7b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/phTEGJ6KdGEYWG67D/link-eric-s-raymond-me-and-less-wrong", "pageUrlRelative": "/posts/phTEGJ6KdGEYWG67D/link-eric-s-raymond-me-and-less-wrong", "linkUrl": "https://www.lesswrong.com/posts/phTEGJ6KdGEYWG67D/link-eric-s-raymond-me-and-less-wrong", "postedAtFormatted": "Friday, December 5th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Eric%20S.%20Raymond%20-%20Me%20and%20Less%20Wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Eric%20S.%20Raymond%20-%20Me%20and%20Less%20Wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FphTEGJ6KdGEYWG67D%2Flink-eric-s-raymond-me-and-less-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Eric%20S.%20Raymond%20-%20Me%20and%20Less%20Wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FphTEGJ6KdGEYWG67D%2Flink-eric-s-raymond-me-and-less-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FphTEGJ6KdGEYWG67D%2Flink-eric-s-raymond-me-and-less-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 66, "htmlBody": "<p>http://esr.ibiblio.org/?p=6549</p>\n<blockquote>\n<p>I&rsquo;ve gotten questions from a couple of different quarters recently about my relationship to the the rationalist community around Less Wrong and related blogs. The one sentence answer is that I consider myself a fellow-traveler and ally of that culture, but not really part of it nor particularly wishing to be.</p>\n<p>The rest of this post is a slightly longer development of that answer.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "phTEGJ6KdGEYWG67D", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 36, "extendedScore": null, "score": 0.000151, "legacy": true, "legacyId": "27677", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-06T23:37:09.487Z", "modifiedAt": null, "url": null, "title": "Meetup : Sydney Summer Solstice", "slug": "meetup-sydney-summer-solstice", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "luminosity", "createdAt": "2010-05-31T03:00:24.334Z", "isAdmin": false, "displayName": "luminosity"}, "userId": "4SuPdAqJpj7TzsaqG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g45SfwMbxcbAQXb2q/meetup-sydney-summer-solstice", "pageUrlRelative": "/posts/g45SfwMbxcbAQXb2q/meetup-sydney-summer-solstice", "linkUrl": "https://www.lesswrong.com/posts/g45SfwMbxcbAQXb2q/meetup-sydney-summer-solstice", "postedAtFormatted": "Saturday, December 6th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Sydney%20Summer%20Solstice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Sydney%20Summer%20Solstice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg45SfwMbxcbAQXb2q%2Fmeetup-sydney-summer-solstice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Sydney%20Summer%20Solstice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg45SfwMbxcbAQXb2q%2Fmeetup-sydney-summer-solstice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg45SfwMbxcbAQXb2q%2Fmeetup-sydney-summer-solstice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 151, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17r'>Sydney Summer Solstice</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 December 2014 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Model Yacht Pond, Centennial Park</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Help us celebrate the end of a full year of rekindled Less Wrong Sydney! We will be holding a Summer Solstice event, Sat 21st in Centennial Park.</p>\n\n<p>Come along from 6pm to have dinner and socialise, then watch the sun go down at 8pm, and take part in a final end of year group activity. We will be supplying candles and Less Wrong members can hold the floor and deliver a reading, a focused exercise, etc.</p>\n\n<p>Please leave a comment with the type of exercise you'd like to run (or if you have an idea you'd like to suggest someone else picks up and runs).</p>\n\n<p>If you know anyone else outside of Less Wrong who you think would enjoy the evening please invite them along also!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17r'>Sydney Summer Solstice</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g45SfwMbxcbAQXb2q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.243125355308083e-06, "legacy": true, "legacyId": "27678", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Sydney_Summer_Solstice\">Discussion article for the meetup : <a href=\"/meetups/17r\">Sydney Summer Solstice</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 December 2014 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Model Yacht Pond, Centennial Park</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Help us celebrate the end of a full year of rekindled Less Wrong Sydney! We will be holding a Summer Solstice event, Sat 21st in Centennial Park.</p>\n\n<p>Come along from 6pm to have dinner and socialise, then watch the sun go down at 8pm, and take part in a final end of year group activity. We will be supplying candles and Less Wrong members can hold the floor and deliver a reading, a focused exercise, etc.</p>\n\n<p>Please leave a comment with the type of exercise you'd like to run (or if you have an idea you'd like to suggest someone else picks up and runs).</p>\n\n<p>If you know anyone else outside of Less Wrong who you think would enjoy the evening please invite them along also!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Sydney_Summer_Solstice1\">Discussion article for the meetup : <a href=\"/meetups/17r\">Sydney Summer Solstice</a></h2>", "sections": [{"title": "Discussion article for the meetup : Sydney Summer Solstice", "anchor": "Discussion_article_for_the_meetup___Sydney_Summer_Solstice", "level": 1}, {"title": "Discussion article for the meetup : Sydney Summer Solstice", "anchor": "Discussion_article_for_the_meetup___Sydney_Summer_Solstice1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T02:00:00.000Z", "modifiedAt": "2022-03-03T19:24:26.214Z", "url": "http://mindingourway.com/moving-towards-the-goal/", "title": "Moving towards the goal", "slug": "moving-towards-the-goal", "viewCount": null, "lastCommentedAt": "2014-12-07T02:00:00.000Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "So8res", "createdAt": "2012-01-10T05:50:18.713Z", "isAdmin": false, "displayName": "So8res"}, "userId": "xSfc2APSi8WzFxp7i", "domain": "mindingourway.com", "pageUrl": "https://www.lesswrong.com/posts/jfXHYnreYJvrjDQsj/moving-towards-the-goal", "pageUrlRelative": "/posts/jfXHYnreYJvrjDQsj/moving-towards-the-goal", "linkUrl": "https://www.lesswrong.com/out?url=http%3A%2F%2Fmindingourway.com%2Fmoving-towards-the-goal%2F", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Moving%20towards%20the%20goal&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMoving%20towards%20the%20goal%0Ahttp%3A%2F%2Fmindingourway.com%2Fmoving-towards-the-goal%2F%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Moving%20towards%20the%20goal%20https%3A%2F%2Fwww.lesswrong.com%2Fout%3Furl%3Dhttp%253A%252F%252Fmindingourway.com%252Fmoving-towards-the-goal%252F", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fout%3Furl%3Dhttp%253A%252F%252Fmindingourway.com%252Fmoving-towards-the-goal%252F", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1115, "htmlBody": "<p>This post contains some advice. I dare not call it obvious, as the <a href=\"http://en.wikipedia.org/wiki/Illusion_of_transparency\">illusion of transparency</a> is ever-present. I will call it simple, but people occasionally remind me that they really appreciate the simple advice. So here we go:</p><h1>1</h1><p>(As usual, this advice is not for everyone; today I am primarily speaking to those who have <a href=\"http://lesswrong.com/lw/nb/something_to_protect/\">something to protect</a>.)</p><p>I have been spending quite a bit of time, recently, working with people who are explicitly trying to hop on a higher growth curve and have a larger impact on the world. (Most of them <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism?language=en\">effective altruists</a>.) They wonder how the big problems can be solved, or how one single person can themselves move the needle in a meaningful way. They ask questions like \"what needs to be done?\", or \"what sort of high impact things can I do right now?\"</p><p>I think this is the wrong way of looking at things.</p><p>When I have a big problem that I want solved, I have found that there is one simple process which tends to work. It goes like this:</p><ol><li>Move towards the goal.</li></ol><p>(It's simple, not easy.)</p><p>If you follow this process, you either win or you die. (Or you run out of time. Speed is encouraged. So are shortcuts, so is cheating.)</p><p>The difficult part is hidden within step 1: it's often hard to keep moving towards the goal. It's difficult to stay motivated. It's difficult to stay focused, especially when pursuing an ambitious goal such as \"end ageing,\" which requires overcoming some fairly significant obstacles.</p><p>But we are human beings. We are the single most powerful optimization process in the known universe, with the only exception being <i>groups</i> of human beings. If we set ourselves to something and don't stop, we either suceed or we die. There's a whole slew of advice which helps make the former outcome more likely than the latter (via efficiency, etc.), but first it is necessary to begin.</p><p>Moving towards the goal doesn't mean you have to work directly on whatever problem you're solving. If you're trying to end aging, then putting on a lab coat and combining random chemicals likely won't do you much good.</p><p>Rather, moving towards the goal is about <i>always acting to solve the problem,</i> with each motion. Identify the path to the goal that seems shortest, and then walk it. Maybe you need to acquire financial stability first, and more knowledge second. Maybe you need to expand your social network, or fulfill your social attachment needs. Maybe you need to acquire a new skill. Maybe you have <i>no idea</i> how to start, in which case you need to gain more information, do some thinking, and gain a higher vantage point from which to search for a path to the goal.</p><p>But no matter what, there is always <i>some</i> way to keep moving towards the goal. Get stronger. Get smarter. Return with allies at your back.</p><h1>2</h1><p>Here's the pattern that this advice is designed to work against: consider the effective altruist, asking \"what needs to be done?\", or \"what sort of high impact things can I do right now?\"</p><p>I expect people to go much farther by first identifying an actual goal, and then moving towards it. Which breaks my one-step advice above into a more practical two-step process:</p><p><strong>Step 1: identify the goal.</strong> Figure out what you're actually trying to accomplish. Probe your motivations, and trace them back to something that compels.</p><p>I'm not suggesting tracing your motivations all the way up to \"final\" goals; it's a bit presumptuous to claim knowledge of \"final goals\" given modern introspective capabilities. Rather, look for important problems that you're trying to solve in the world today.</p><p>For example, you might be trying to fix education, end hunger, eliminate a disease, prevent aging, become immortal, end suffering, prevent human extinction, or whatever. None of these are <i>ends unto themselves</i>, but they're all problems that need solving.</p><p>Identifying a goal that compels\u2014that really needs to be solved, and that won't be solved (or won't be solved fast enough) by default\u2014is not always an easy task. Many people are locked into a mindset where they couldn't possibly actually solve any big problems, because big problems are big and people are small. Breaking out of that mindset is a topic for another day; for now I'll assume you have picked your poison and identified some goal to achieve, even if only a minor one.</p><p><strong>Step 2: move towards it.</strong> So, you've found a goal. Nice work.</p><p>Now solve it tomorrow.</p><p>Can you? Seriously ask yourself whether or not you can solve the problem tomorrow. I don't care how ambitious it is. Can you solve it tomorrow? If yes, then do it. If not, why not? Say the obstacles aloud.</p><p>The usual answers are something like \"I lack the power, time, money, network, and so on.\" Which is great! Now we're getting somewhere.</p><p><i>These</i> are what you need to work on tomorrow, if you want to solve the problem.</p><p>Don't ask \"what would be good to do,\" ask \"what is standing between me and solving the problem immediately.\" Identify the obstacles. Your task is now to either remove them or cheat your way around them.</p><p>Of course, most of the obstacles themselves are still too big and vague. So ask yourself why you can't solve those problems tomorrow. Say you don't know the people you'd need to know to have a shot at fixing education. Can you contact them all tomorrow? That <i>probably</i> wouldn't go well, but why not? What are the obstacles between you and acquiring the resources you're going to need?</p><p>Rinse, repeat. Identify the obstacles to overcoming the obstacles, and so on. Eventually, this process will ground out in things that you can actually start doing tomorrow, with a path that you can trace all the way back up to your goal.</p><p>Once you have that, throw reservations to the wind, and start <i>today.</i></p><h1>3</h1><p>Moving towards the goal doesn't solve the whole problem. If you want to solve a goal effectively, in the time allotted, it is important to approach the obstacles in the right order, to identify the ones you can safely cheat past, to correctly distinguish between short paths to the goal and long ones. But many people aren't there yet: they're still asking \"what would be good for me to do,\" and not \"what stands between me and solving the whole problem tomorrow.\"</p><p>My advice, if you want to be effective, is <i>always be solving the problem.</i> With each motion, be overcoming an obstacle that stands between you and the goal. If the obstacles are too large, then your next task is to get stronger, get smarter, or find a way around. That is what it means, to find a path to the goal.</p><p>To achieve a goal, simply keep moving along that path.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": null, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": null, "reviewVoteCount": null, "positiveReviewVoteCount": null, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xexCWMyds6QLWognu": 2}, "noIndex": false, "rsvps": null, "activateRSVPs": true, "nextDayReminderSent": false, "onlyVisibleToLoggedIn": false, "onlyVisibleToEstablishedAccounts": false, "votingSystem": null, "myEditorAccess": "none", "_id": "jfXHYnreYJvrjDQsj", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 8, "extendedScore": null, "score": 2.4e-05, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2022-03-03T19:24:25.985Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": "pFatcKW3JJhTSxqAF", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "self-signaling-the-ability-to-do-what-you-want", "canonicalPrevPostSlug": "the-value-of-a-life", "unlisted": false, "disableRecommendation": false, "defaultRecommendation": false, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "qgdGA4ZEyW7zNdK84", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": false, "globalEvent": false, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": [], "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This post contains some advice. I dare not call it obvious, as the <a href=\"http://en.wikipedia.org/wiki/Illusion_of_transparency\">illusion of transparency</a> is ever-present. I will call it simple, but people occasionally remind me that they really appreciate the simple advice. So here we go:</p><h1 id=\"1\">1</h1><p>(As usual, this advice is not for everyone; today I am primarily speaking to those who have <a href=\"http://lesswrong.com/lw/nb/something_to_protect/\">something to protect</a>.)</p><p>I have been spending quite a bit of time, recently, working with people who are explicitly trying to hop on a higher growth curve and have a larger impact on the world. (Most of them <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism?language=en\">effective altruists</a>.) They wonder how the big problems can be solved, or how one single person can themselves move the needle in a meaningful way. They ask questions like \"what needs to be done?\", or \"what sort of high impact things can I do right now?\"</p><p>I think this is the wrong way of looking at things.</p><p>When I have a big problem that I want solved, I have found that there is one simple process which tends to work. It goes like this:</p><ol><li>Move towards the goal.</li></ol><p>(It's simple, not easy.)</p><p>If you follow this process, you either win or you die. (Or you run out of time. Speed is encouraged. So are shortcuts, so is cheating.)</p><p>The difficult part is hidden within step 1: it's often hard to keep moving towards the goal. It's difficult to stay motivated. It's difficult to stay focused, especially when pursuing an ambitious goal such as \"end ageing,\" which requires overcoming some fairly significant obstacles.</p><p>But we are human beings. We are the single most powerful optimization process in the known universe, with the only exception being <i>groups</i> of human beings. If we set ourselves to something and don't stop, we either suceed or we die. There's a whole slew of advice which helps make the former outcome more likely than the latter (via efficiency, etc.), but first it is necessary to begin.</p><p>Moving towards the goal doesn't mean you have to work directly on whatever problem you're solving. If you're trying to end aging, then putting on a lab coat and combining random chemicals likely won't do you much good.</p><p>Rather, moving towards the goal is about <i>always acting to solve the problem,</i> with each motion. Identify the path to the goal that seems shortest, and then walk it. Maybe you need to acquire financial stability first, and more knowledge second. Maybe you need to expand your social network, or fulfill your social attachment needs. Maybe you need to acquire a new skill. Maybe you have <i>no idea</i> how to start, in which case you need to gain more information, do some thinking, and gain a higher vantage point from which to search for a path to the goal.</p><p>But no matter what, there is always <i>some</i> way to keep moving towards the goal. Get stronger. Get smarter. Return with allies at your back.</p><h1 id=\"2\">2</h1><p>Here's the pattern that this advice is designed to work against: consider the effective altruist, asking \"what needs to be done?\", or \"what sort of high impact things can I do right now?\"</p><p>I expect people to go much farther by first identifying an actual goal, and then moving towards it. Which breaks my one-step advice above into a more practical two-step process:</p><p><strong>Step 1: identify the goal.</strong> Figure out what you're actually trying to accomplish. Probe your motivations, and trace them back to something that compels.</p><p>I'm not suggesting tracing your motivations all the way up to \"final\" goals; it's a bit presumptuous to claim knowledge of \"final goals\" given modern introspective capabilities. Rather, look for important problems that you're trying to solve in the world today.</p><p>For example, you might be trying to fix education, end hunger, eliminate a disease, prevent aging, become immortal, end suffering, prevent human extinction, or whatever. None of these are <i>ends unto themselves</i>, but they're all problems that need solving.</p><p>Identifying a goal that compels\u2014that really needs to be solved, and that won't be solved (or won't be solved fast enough) by default\u2014is not always an easy task. Many people are locked into a mindset where they couldn't possibly actually solve any big problems, because big problems are big and people are small. Breaking out of that mindset is a topic for another day; for now I'll assume you have picked your poison and identified some goal to achieve, even if only a minor one.</p><p><strong>Step 2: move towards it.</strong> So, you've found a goal. Nice work.</p><p>Now solve it tomorrow.</p><p>Can you? Seriously ask yourself whether or not you can solve the problem tomorrow. I don't care how ambitious it is. Can you solve it tomorrow? If yes, then do it. If not, why not? Say the obstacles aloud.</p><p>The usual answers are something like \"I lack the power, time, money, network, and so on.\" Which is great! Now we're getting somewhere.</p><p><i>These</i> are what you need to work on tomorrow, if you want to solve the problem.</p><p>Don't ask \"what would be good to do,\" ask \"what is standing between me and solving the problem immediately.\" Identify the obstacles. Your task is now to either remove them or cheat your way around them.</p><p>Of course, most of the obstacles themselves are still too big and vague. So ask yourself why you can't solve those problems tomorrow. Say you don't know the people you'd need to know to have a shot at fixing education. Can you contact them all tomorrow? That <i>probably</i> wouldn't go well, but why not? What are the obstacles between you and acquiring the resources you're going to need?</p><p>Rinse, repeat. Identify the obstacles to overcoming the obstacles, and so on. Eventually, this process will ground out in things that you can actually start doing tomorrow, with a path that you can trace all the way back up to your goal.</p><p>Once you have that, throw reservations to the wind, and start <i>today.</i></p><h1 id=\"3\">3</h1><p>Moving towards the goal doesn't solve the whole problem. If you want to solve a goal effectively, in the time allotted, it is important to approach the obstacles in the right order, to identify the ones you can safely cheat past, to correctly distinguish between short paths to the goal and long ones. But many people aren't there yet: they're still asking \"what would be good for me to do,\" and not \"what stands between me and solving the whole problem tomorrow.\"</p><p>My advice, if you want to be effective, is <i>always be solving the problem.</i> With each motion, be overcoming an obstacle that stands between you and the goal. If the obstacles are too large, then your next task is to get stronger, get smarter, or find a way around. That is what it means, to find a path to the goal.</p><p>To achieve a goal, simply keep moving along that path.</p>", "sections": [{"title": "1", "anchor": "1", "level": 1}, {"title": "2", "anchor": "2", "level": 1}, {"title": "3", "anchor": "3", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": false, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SGR4GxFK7KmW7ckCB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": "1.0.0", "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2022-03-03T19:14:49.196Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T05:32:23.708Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA\u2014DUMP STAT", "slug": "meetup-west-la-dump-stat", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DDGWfx2XWnrbDAETN/meetup-west-la-dump-stat", "pageUrlRelative": "/posts/DDGWfx2XWnrbDAETN/meetup-west-la-dump-stat", "linkUrl": "https://www.lesswrong.com/posts/DDGWfx2XWnrbDAETN/meetup-west-la-dump-stat", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%E2%80%94DUMP%20STAT&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%E2%80%94DUMP%20STAT%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDGWfx2XWnrbDAETN%2Fmeetup-west-la-dump-stat%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%E2%80%94DUMP%20STAT%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDGWfx2XWnrbDAETN%2Fmeetup-west-la-dump-stat", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDDGWfx2XWnrbDAETN%2Fmeetup-west-la-dump-stat", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 132, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17s'>West LA\u2014DUMP STAT</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 December 2014 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">11066 Santa Monica Blvd, Los Angeles, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>How to Find Us</strong>: Go into <a href=\"https://www.google.com/maps/place/Del+Taco/@34.047464,-118.443286,974m/data=!3m2!1e3!4b1!4m2!3m1!1s0x80c2bb777277de93:0x99f58a53b04bb89c?hl=en\" rel=\"nofollow\">this</a> Del Taco. We will be in the back room if possible.</p>\n\n<p><strong>Parking</strong> is free in the lot out front or on the street nearby.</p>\n\n<p><strong>Discussion</strong>: Contra Heinlein, humans in large populations ought to specialize. This means sacrificing jack-of-all for expertise in one domain. But which things are best to sacrifice? Which things do you <em>already</em> do that you should do less of? <em>What should your dump stats be?</em></p>\n\n<p><strong>Recommended Reading</strong>:</p>\n\n<ul>\n<li><a href=\"http://lesswrong.com/lw/28s/the_social_coprocessor_model/\">The Social Coprocessor Model</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/Comparative_advantage\" rel=\"nofollow\">Comparative Advantage</a></li>\n<li><a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/DumpStat\" rel=\"nofollow\">Dump Stat</a> on TVTropes</li>\n</ul>\n\n<p><em>No prior exposure to Less Wrong is required</em>; this will be generally accessible.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17s'>West LA\u2014DUMP STAT</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DDGWfx2XWnrbDAETN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.2439048263849415e-06, "legacy": true, "legacyId": "27680", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_DUMP_STAT\">Discussion article for the meetup : <a href=\"/meetups/17s\">West LA\u2014DUMP STAT</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 December 2014 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">11066 Santa Monica Blvd, Los Angeles, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>How to Find Us</strong>: Go into <a href=\"https://www.google.com/maps/place/Del+Taco/@34.047464,-118.443286,974m/data=!3m2!1e3!4b1!4m2!3m1!1s0x80c2bb777277de93:0x99f58a53b04bb89c?hl=en\" rel=\"nofollow\">this</a> Del Taco. We will be in the back room if possible.</p>\n\n<p><strong>Parking</strong> is free in the lot out front or on the street nearby.</p>\n\n<p><strong>Discussion</strong>: Contra Heinlein, humans in large populations ought to specialize. This means sacrificing jack-of-all for expertise in one domain. But which things are best to sacrifice? Which things do you <em>already</em> do that you should do less of? <em>What should your dump stats be?</em></p>\n\n<p><strong>Recommended Reading</strong>:</p>\n\n<ul>\n<li><a href=\"http://lesswrong.com/lw/28s/the_social_coprocessor_model/\">The Social Coprocessor Model</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/Comparative_advantage\" rel=\"nofollow\">Comparative Advantage</a></li>\n<li><a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/DumpStat\" rel=\"nofollow\">Dump Stat</a> on TVTropes</li>\n</ul>\n\n<p><em>No prior exposure to Less Wrong is required</em>; this will be generally accessible.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_DUMP_STAT1\">Discussion article for the meetup : <a href=\"/meetups/17s\">West LA\u2014DUMP STAT</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA\u2014DUMP STAT", "anchor": "Discussion_article_for_the_meetup___West_LA_DUMP_STAT", "level": 1}, {"title": "Discussion article for the meetup : West LA\u2014DUMP STAT", "anchor": "Discussion_article_for_the_meetup___West_LA_DUMP_STAT1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["aTtf9iERDoptPD33j"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T14:58:01.373Z", "modifiedAt": null, "url": null, "title": "Linked decisions an a \"nice\" solution for the Fermi paradox", "slug": "linked-decisions-an-a-nice-solution-for-the-fermi-paradox", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:35.404Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Beluga", "createdAt": "2013-08-12T08:32:53.991Z", "isAdmin": false, "displayName": "Beluga"}, "userId": "Txp5AoG4eg5LDAiv2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yqhE6RuHrnnjo5gw3/linked-decisions-an-a-nice-solution-for-the-fermi-paradox", "pageUrlRelative": "/posts/yqhE6RuHrnnjo5gw3/linked-decisions-an-a-nice-solution-for-the-fermi-paradox", "linkUrl": "https://www.lesswrong.com/posts/yqhE6RuHrnnjo5gw3/linked-decisions-an-a-nice-solution-for-the-fermi-paradox", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Linked%20decisions%20an%20a%20%22nice%22%20solution%20for%20the%20Fermi%20paradox&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALinked%20decisions%20an%20a%20%22nice%22%20solution%20for%20the%20Fermi%20paradox%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyqhE6RuHrnnjo5gw3%2Flinked-decisions-an-a-nice-solution-for-the-fermi-paradox%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Linked%20decisions%20an%20a%20%22nice%22%20solution%20for%20the%20Fermi%20paradox%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyqhE6RuHrnnjo5gw3%2Flinked-decisions-an-a-nice-solution-for-the-fermi-paradox", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyqhE6RuHrnnjo5gw3%2Flinked-decisions-an-a-nice-solution-for-the-fermi-paradox", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 747, "htmlBody": "<p>One of the more speculative solutions of the Fermi paradox is that all civilizations decide to stay home, thereby meta-cause other civilizations to stay home too, and thus allow the Fermi paradox to have a nice solution. (I remember reading this idea in Paul Almond&rsquo;s writings about evidential decision theory, which unfortunately seem no longer available online.) The plausibility of this argument is definitely questionable. It requires a very high degree of goal convergence both within and among different civilizations. Let us grant this convergence and assume that, indeed, most civilizations arrive at the same decision and that they make their decision knowing this. One paradoxical implication then is: If a civilization decides to attempt space colonization, they are virtually guaranteed to face unexpected difficulties (for otherwise space would already be colonized, unless they are the first civilization in their neighborhood attempting space colonization). If, on the other hand, everyone decides to stay home, there is no reason for thinking that there would be any unexpected difficulties if one tried. Space colonization can either be easy, or you can try it, but not both.</p>\n<p>Can the basic idea behind the argument be formalized? Consider the following game: There are N&gt;&gt;1 players. Each player is offered to push a button in turn. Pushing the button yields a reward R&gt;0 with probability p and a punishment P&lt;0 otherwise. (R corresponds to successful space colonization while P corresponds to a failed colonization attempt.) Not pushing the button gives zero utility. If a player pushes the button and receives R, the game is immediately aborted, while the game continues if a player receives P. Players do not know how many other players were offered to push the button before them, they only know that no player before them received R. Players also don&rsquo;t know p. Instead, they have a probability distribution u(p) over possible values of p. (u(p)&gt;=0 and the integral of u(p) from 0 to 1 is given by int_{0}^{1}u(p)dp=1.) We also assume that the decisions of the different players are perfectly linked.</p>\n<p>Naively, it seems that players simply have an effective success probability p_eff,1=int_{0}^{1}p*u(p)dp and they should push the button iff p_eff,1*R+(1-p_eff,1)*P&gt;0. Indeed, if players decide <em>not</em> to push the button they should expect that pushing the button&nbsp;<em>would have</em> given them R with probability p_eff,1. The situation becomes more complicated if a player decides to push the button. If a player pushes the button, they know that all players before them have also pushed the button and have received P. Before taking this knowledge into account, players are completely ignorant about the number i of players who were offered to push the button before them, and have to assign each number i from 0 to N-1 the same probability 1/N. Taking into account that all players before them have received P, the variables i and p become correlated: the larger i, the higher the probability of a small value of p. Formally, the joint probability distribution w(i,p) for the two variables is, according to Bayes&rsquo; theorem, given by w(i,p)=c*u(p)*(1-p)^i, where c is a normalization constant. The marginal distribution w(p) is given by w(p)=sum_{i=0}^{N-1}w(i,p). Using N&gt;&gt;1, we find w(p)=c*u(p)/p. The normalization constant is thus c=[int_{0}^{1}u(p)/p*dp]^{-1}. Finally, we find that the effective success probability taking the linkage of decisions into account is given by</p>\n<p>p_eff,2 = int_{0}^{1}p*w(p)dp = c = [int_{0}^{1}u(p)/p*dp]^{-1} .</p>\n<p>This is the expected chance of success if players decide to push the button. Players should push the button iff p_eff,2*R+(1-p_eff,2)*P&gt;0. If follows from convexity of the function x-&gt;1/x (for positive x) that p_eff,2&lt;=p_eff,1. So by deciding to push the button, players decrease their expected success probability from p_eff,1 to p_eff,2; they cannot both push the button <em>and</em> have the unaltered success probability p_eff,1. Linked decisions can explain why no one pushes the button if p_eff,2*R+(1-p_eff,2)*P&lt;0, even though we might have p_eff,1*R+(1-p_eff,1)*P&gt;0 and pushing the button naively seems to have positive expected utility.</p>\n<p>It is also worth noting that if u(0)&gt;0, the integral int_{0}^{1}u(p)/p*dp diverges such that we have p_eff,2=0. This means that given perfectly linked decisions and a sufficiently large number of players N&gt;&gt;1, players should never push the button if their distribution u(p) satisfies u(0)&gt;0, irrespective of the ratio of R and P. This is due to an observer selection effect: If a player decides to push the button, then the fact that they are even offered to push the button is most likely due to p being very small and thus a lot of players being offered to push the button.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yqhE6RuHrnnjo5gw3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 5, "extendedScore": null, "score": 2.245146932230229e-06, "legacy": true, "legacyId": "27679", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T17:04:50.525Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels - Hope & Self-improvement", "slug": "meetup-brussels-hope-and-self-improvement", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Roxolan", "createdAt": "2011-10-23T19:06:17.298Z", "isAdmin": false, "displayName": "Roxolan"}, "userId": "jXG7tMhkQMNpCCXPN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vPhfm32c8NvGdmSaG/meetup-brussels-hope-and-self-improvement", "pageUrlRelative": "/posts/vPhfm32c8NvGdmSaG/meetup-brussels-hope-and-self-improvement", "linkUrl": "https://www.lesswrong.com/posts/vPhfm32c8NvGdmSaG/meetup-brussels-hope-and-self-improvement", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20-%20Hope%20%26%20Self-improvement&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20-%20Hope%20%26%20Self-improvement%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvPhfm32c8NvGdmSaG%2Fmeetup-brussels-hope-and-self-improvement%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20-%20Hope%20%26%20Self-improvement%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvPhfm32c8NvGdmSaG%2Fmeetup-brussels-hope-and-self-improvement", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvPhfm32c8NvGdmSaG%2Fmeetup-brussels-hope-and-self-improvement", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 188, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17t'>Brussels - Hope &amp; Self-improvement</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 December 2014 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>t's Christmas season, so I thought of doing something about rational giving, but we've already talked your ears off about Effective Altruism last meetup. Instead, let's fight off seasonal depression with the Power of Friendship (and of Chemistry).</p>\n\n<p>What makes you hope for your own future? How has your life improved recently, and what makes you expect it will improve again? What makes you hope for the future of humanity? Which recent scientific development brings us one step towards utopia?</p>\n\n<p>This month, a meetup that will go better than expected.</p>\n\n<hr />\n\n<p>We will meet at 1 pm at \"La Fleur en papier dor\u00e9, close to the Brussels Central station. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform\" rel=\"nofollow\">this one minute form</a> to share your contact information.</p>\n\n<p>The Brussels meetup group communicates through a <a href=\"https://groups.google.com/forum/#!forum/lesswrong-brussels\">Google Group</a>.</p>\n\n<p>Meetup announcements are also mirrored on <a href=\"http://www.meetup.com/LWBrussels/\" rel=\"nofollow\">meetup.com</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17t'>Brussels - Hope &amp; Self-improvement</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vPhfm32c8NvGdmSaG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.245425591255703e-06, "legacy": true, "legacyId": "27682", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels___Hope___Self_improvement\">Discussion article for the meetup : <a href=\"/meetups/17t\">Brussels - Hope &amp; Self-improvement</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 December 2014 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>t's Christmas season, so I thought of doing something about rational giving, but we've already talked your ears off about Effective Altruism last meetup. Instead, let's fight off seasonal depression with the Power of Friendship (and of Chemistry).</p>\n\n<p>What makes you hope for your own future? How has your life improved recently, and what makes you expect it will improve again? What makes you hope for the future of humanity? Which recent scientific development brings us one step towards utopia?</p>\n\n<p>This month, a meetup that will go better than expected.</p>\n\n<hr>\n\n<p>We will meet at 1 pm at \"La Fleur en papier dor\u00e9, close to the Brussels Central station. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform\" rel=\"nofollow\">this one minute form</a> to share your contact information.</p>\n\n<p>The Brussels meetup group communicates through a <a href=\"https://groups.google.com/forum/#!forum/lesswrong-brussels\">Google Group</a>.</p>\n\n<p>Meetup announcements are also mirrored on <a href=\"http://www.meetup.com/LWBrussels/\" rel=\"nofollow\">meetup.com</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels___Hope___Self_improvement1\">Discussion article for the meetup : <a href=\"/meetups/17t\">Brussels - Hope &amp; Self-improvement</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels - Hope & Self-improvement", "anchor": "Discussion_article_for_the_meetup___Brussels___Hope___Self_improvement", "level": 1}, {"title": "Discussion article for the meetup : Brussels - Hope & Self-improvement", "anchor": "Discussion_article_for_the_meetup___Brussels___Hope___Self_improvement1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T17:05:08.734Z", "modifiedAt": null, "url": null, "title": "A bit of word-dissolving in political discussion", "slug": "a-bit-of-word-dissolving-in-political-discussion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:34.283Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "28iKD7fEnHvK8pNNm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZHfS5CwbSSAdrffRQ/a-bit-of-word-dissolving-in-political-discussion", "pageUrlRelative": "/posts/ZHfS5CwbSSAdrffRQ/a-bit-of-word-dissolving-in-political-discussion", "linkUrl": "https://www.lesswrong.com/posts/ZHfS5CwbSSAdrffRQ/a-bit-of-word-dissolving-in-political-discussion", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20bit%20of%20word-dissolving%20in%20political%20discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20bit%20of%20word-dissolving%20in%20political%20discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZHfS5CwbSSAdrffRQ%2Fa-bit-of-word-dissolving-in-political-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20bit%20of%20word-dissolving%20in%20political%20discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZHfS5CwbSSAdrffRQ%2Fa-bit-of-word-dissolving-in-political-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZHfS5CwbSSAdrffRQ%2Fa-bit-of-word-dissolving-in-political-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2308, "htmlBody": "<blockquote>\n<p>I found Scott Alexander's steelmanning of the NRx critique to be an interesting, even persuassive critique of modern progressivism, having not been exposed to this movement prior to today. However I am also equally confused at the jump from \"modern liberal democracies are flawed\" to \"restore the devine-right-of-kings!\" I've always hated the quip \"democracy is the worst form of government, except for all the others\" (we've yet tried), but I think it applies here.</p>\n</blockquote>\n<p>-- <a href=\"/lw/la5/neoreactionaries_why_are_you_neoreactionary/bmte\">Mark Friedenbach</a></p>\n<p>Of course, with the prompting to state my own thoughts, I simply <em>had</em> to go and start typing them out.&nbsp; The following contains obvious traces of my own political leanings and philosophy (in short summary: if \"Cthulhu only swims left\", then <em>I AM CTHULHU</em>... at least until someone explains to me what a Great Old One is doing out of R'lyeh and in West Coast-flavored American politics), but those traces should be taken as <em>evidence</em> of what I believe rather than statements about it.</p>\n<p>Because what I was actually <em>trying</em> to talk about, is rationality in politics.&nbsp; Because in fact, while it is <em>hard</em>, while it is <a href=\"http://i.imgur.com/xfYvrRq.jpg\"><em>spiders</em></a>, all the normal techniques work on it.&nbsp; There is only one real Cardinal Sin of Attempting to be Rational in Politics, and it is the following argument, stated in generic form that I might capture it from the ether and bury it: \"You only believe what you believe for political reasons!\"&nbsp; It does not matter if those \"reasons\" are signaling, privilege, hegemony, or having an invisible devil on your shoulder whispering into your bloody ear: to impugn someone else's epistemology entirely at the meta-level without saying a thing against their object-level claims is anti-epistemology.</p>\n<p>Now, on to the ranting!&nbsp; The following are more-or-less a semi-random collection of tips I vomited out for trying to deal with politics rationally.&nbsp; I hope they help.&nbsp; This is a Discussion post because Mark said that might be a good idea.</p>\n<ol>\n<li>Dissolve \"democracy\", and not just in the philosophical sense, but in the sense that there have been many <em>different</em> kinds of actually existing democracies.&nbsp; There are always multiple object-level implementations of any meta-level idea, and <em>most</em> political ideas are sufficiently abstract to count as meta-level.&nbsp; Even if, for purposes of a thought experiment, you find yourself saying, \"I WILL ONLY EVER CONSIDER SYSTEMS THAT COUNT AS DEMOCRACY ACCORDING TO MY INTUITIVE DEMOCRACY-P() PREDICATE!\", one can easily debate whether a mixed-member proportional Parliament <em>performs better</em> than a district-based bicameral Congress, or whether a pure Westminster system beats them both, or whether a Presidential system works better, or whatever.&nbsp; <em>Particular</em> institutional designs yield <em>particular</em> institutional behaviors, and successfully inducing complex generalizations across large categories of institutional designs requires large amounts of evidence -- just as it does in any other form of hierarchical probabilistic reasoning.</li>\n<li>Dissolve words like \"democracy\", \"capitalism\", \"socialism\", and \"government\" in the philosophical sense, and ask: what are the terminal goals democracy serves?&nbsp; How much do we support those goals, and how much do current democratic systems suffer approximation error by forcing our terminal goals to fit inside the hypothesis space our actual institutions instantiate?&nbsp; For however much we <em>do</em> support those goals, why do we shape <em>these</em> particular institutions to serve those goals, and not <em>other</em> institutions? For all values of X, <a href=\"http://en.wikipedia.org/wiki/Ma_Nishtana\"><em>mah nishtana ha-X hazeh mikol ha-X-im?</em></a> is a fundamental question of correct reasoning.&nbsp; (Asking the question of why we instantiate particular institutions in particular places, when one believes in democratic states, is the core issue of democratic socialism, and I would indeed count myself a democratic socialist.&nbsp; But you get different answers and inferences if you ask about schools or churches, don't you?)</li>\n<li>Learn first to explicitly identify yourself with a political \"tribe\", and next to consider political ideas <em>individually</em>, as questions of fact and value subject to investigation via epistemology and moral epistemology, rather than treating politics as \"tribal\".&nbsp; <a href=\"https://www.youtube.com/watch?v=U-EQJA8Ahac\">Tribalism is the mind-killer</a>: keeping your own explicit tribal identification in mind helps you <em>notice</em> when you're being tribalist, and helps you distinguish your own tribe's customs from universal truths -- both aids to your political rationality.&nbsp; And yes, while politics has always been <em>at least a little</em> tribal, the particular form the tribes take varies through time and space: the division of society into a \"blue tribe\" and a \"red tribe\" (as oft-described by Yvain on <em>Slate Star Codex</em>), for example, is <em>peculiar</em> to late-20th-century and early-21st-century USA.&nbsp; Those colors didn't even come into usage until the 2000 Presidential election, and hadn't firmly solidified as describing seemingly separate nationalities until 2004!&nbsp; Other countries, and other times, have significantly different arrangements of tribes, so if you don't learn to distinguish between ideas and tribes, you'll not only fail at political rationality, you'll give yourself severe culture shock the first time you go abroad.<ol>\n<li>General rule: you often think things are general rules of the world not because you have the large amount of evidence necessary to reason that they really are, but because you've seen so few alternatives that your subjective distribution over models contains only one or two models, both coarse-grained.&nbsp; Unquestioned assumptions <em>always</em> feel like universal truths from the inside!</li>\n</ol></li>\n<li>Learn to check political ideas <a href=\"http://hpmor.com/chapter/64\"><em>by looking</em></a> at the actually-existing implementations, including the ones you currently oppose -- think of yourself as bloody Sauron if you have to!&nbsp; This works, since most political ideas are <em>not</em> particularly original.&nbsp; Commons trusts exist, for example, the \"movement\" supporting them just wants to scale them up to cover <em>all</em> society's important common assets rather than just tracts of land donated by philanthropists.&nbsp; Universal health care exists in many countries.&nbsp; Monarchy and dictatorship exist in many countries.&nbsp; Religious rule exists in many countries.&nbsp; Free tertiary education exists in some countries, and has previously existed in more.&nbsp; Non-free but subsidized tertiary education exists in many countries.&nbsp; Running the state off oil revenue has been tried in many countries.&nbsp; Centrally-planned economies have been tried in many countries.&nbsp; And it's damn well easier to compare \"Canadian health-care\" to \"American health-care\" to \"Chinese health-care\", all sampled in 2014, using fact-based policy studies, than to argue about the Visions of Human Life represented by each (the welfare state, the Company Man, and the Lone Fox, let's say) -- which of course assumes consequentialism.&nbsp; In fact, I should issue a much stronger warning here: <em>argumentation</em> is an utterly unreliable guide to truth compared to <em>data</em>, and all these meta-level political conclusions require vast amounts of <em>object-level data</em> to induce correct causal models of the world that allow for proper planning and policy.<br /><ol>\n<li>This means that <em>while</em> the Soviet Union is not evidence for the total failure of \"socialism\" as I use the word, <em>that's because I define socialism as a larger category of possible economies that strictly contains centralized state planning</em> -- centralized state planning <em>really was,</em> by and large, a total fucking failure.&nbsp; But there's a rationality lesson here: in politics, all opponents of an idea will have their own definition for it, but the supporters will only have one.&nbsp; Learn to identify political terminology with the definitions advanced by supporters: these definitions might contain applause lights, but at least they pick out one single spot in policy-space or society-space (or, hopefully, a reasonably small subset of that space), while opponents don't generally agree on which precise point in policy-space or society-space they're actually attacking (because they're all opposed for their own reasons and thus not coordinating with each-other).</li>\n<li>This also means that if someone wants to talk about monarchies that rule by religious right, or even about absolute monarchies in general, they do have to account for the behavior of the Arab monarchies today, for example.&nbsp; Or if they want to talk about religious rule in general (which very few <em>do</em>, to my knowledge, but hey, let's go with it), they actually do have to account for the behavior of Da3esh/ISIS.&nbsp; Of course, they might do so by <em>endorsing</em> such regimes, just as some members of Western Communist Parties <em>endorsed</em> the Soviet Union -- and this can happen by lack of knowledge, by failure of rationality, or by difference of goals.</li>\n<li>And then of course, there are the complications of the real world: in the real world, neither perfect steelman-level central planning <em>nor</em> perfect steelman-level markets have <em>ever</em> been implemented, <em>anywhere</em>, with the result that once upon a time, the <a href=\"http://www.jstor.org/stable/152080\">Soviet economy was allocatively efficient</a> and <a href=\"http://www.sciencedirect.com/science/article/pii/S0147596798915621\">prices in capitalist West Germany were just as bad at reflecting relative scarcities as those in centrally-planned East Germany</a>!&nbsp; <a href=\"https://www.jacobinmag.com/2012/12/the-red-and-the-black/\">The real advantage of market systems has ended up being the autonomy of firms, <em>not</em> allocative optimality</a> (and that's being argued, right there, in the single most left-wing magazine I know of!).&nbsp; Which leads us to repeat the warning: correct conclusions are <em>induced from real-world data</em>, not argued from a priori principles that usually turn out to be wildly mis-emphasized if not entirely wrong.</li>\n</ol></li>\n<li>Learn to notice when otherwise uninformed people are adopting political ideas as attire to gain status by joining a fashionable cause.&nbsp; Keep in mind that what constitutes \"fashionable\" depends on the joiner's own place in society, not on <em>your</em> opinions about them.&nbsp; For some people, things you and I find low-status (certain clothes or haircuts) are, in fact, high-status.&nbsp; See <a href=\"http://slatestarcodex.com/2014/11/17/republicans-are-douchebags/\">Yvain's \"Republicans are Douchebags\" post</a> for an example in a Western context: names that the American Red Tribe considers solid and respectable are viewed by the American Blue Tribe as \"douchebag names\".</li>\n<li>A heuristic that tends to immunize against certain failures of political rationality: if an argument does not base itself at all in facts external to itself or to the listener, but instead concentrates <em>entirely</em> on <em>reinterpreting</em> evidence, then it is probably either an argument about definitions, or sheer nonsense.&nbsp; This is related to my comments on hierarchical reasoning above, and also to the general sense in which trying to refute an object-level claim by meta-level argumentation is <em>not even wrong</em>, but in fact anti-epistemology.</li>\n<li>A further heuristic, usable on actual electioneering campaigns the world over: whenever someone says \"values\", <em>he is lying, and you should reach for your gun</em>.&nbsp; The word \"values\" is <em>the</em> single most overused, drained, <em>meaningless</em> word in politics.&nbsp; It is a <em>normative pronoun</em>: it directs the listener to <em>fill in warm fuzzy things here</em> without concentrating the speaker and the listener on the same point in policy-space at all.&nbsp; All over the world, politicians routinely seek power on phrases like \"I have values\", or \"My opponent has no values\", or \"our values\" or \"our $TRIBE values\", or \"$APPLAUSE_LIGHT values\".&nbsp; Just cross those phrases and their entire containing sentences out with a big black marker, and then see what the speaker is <em>actually saying</em>.&nbsp; Sometimes, if you're lucky (ie: voting for a Democrat), they're saying absolutely nothing.&nbsp; Often, however, the word \"values\" means, \"Good thing I'm here to tell you that you want this brand new oppressive/exploitative power elite, since you didn't even know!\"</li>\n<li>As mentioned above, be very, very sure about what ethical framework you're working within <em>before</em> having a political discussion.&nbsp; A consequentialist and a virtue-ethicist will often take completely different policy positions on, say, healthcare, and <em>have absolutely nothing to talk about with each-other</em>.&nbsp; The consequentialist can point out the utilitarian gains of universal single-payer care, and the virtue-ethicist can point out the incentive structure of corporate-sponsored group plans for promoting hard work and loyalty to employers, but they are fundamentally talking past each-other.<ol>\n<li>Often, the core matter of politics is how to trade off between ethical ideals that are otherwise left talking past each-other, because society has finite material resources, human morals are very complex, and real policies have unintended consequences.&nbsp; For example, if we enact Victorian-style \"poor laws\" that penalize poverty for virtue-ethical reasons, the proponents of those laws need to be held accountable for accepting the <em>unintended</em> consequences of those laws, including higher crime rates, a less educated workforce, etc.&nbsp; (This is a broad point in favor of consequentialism: a rational consequentialist <em>always</em> considers consequences, intended <em>and</em> unintended, <em>or he fails at consequentialism</em>.&nbsp; A deontologist or virtue-ethicist, on the other hand, has license from his own ethics algorithm to not care about unintended consequences at all, provided the rules get followed or the rules or rulers are virtuous.)</li>\n</ol></li>\n<li>Almost all policies can be enacted <em>more effectively</em> with state power, and almost no policies can \"take over the world\" by sheer superiority of the idea all by themselves.&nbsp; Demanding that a successful policy should \"take over the world\" by itself, as everyone naturally turns to the One True Path, is intellectually dishonest, and so is demanding that a policy should be maximally effective in miniature (when tried without the state, or in a small state, or in a weak state) before it is justified for the state to experiment with it.&nbsp; Remember: the overwhelming majority of journals and conferences in professional science <em>still</em> employ frequentist statistics rather than Bayesianism, and this is 20 years after the PC revolution and the World Wide Web, and <em>40</em> years after computers became widespread in universities.&nbsp; Human beings are utility-satisficing, adaptation-executing creatures with mostly-unknown utility functions: expecting them to adopt more effective policies quickly <em>by mere effectiveness of the policy</em> is downright <em>unrealistic</em>.</li>\n<li>The Appeal to Preconceptions is probably the single Darkest form of Dark Arts, and it's used <em>everywhere</em> in politics.&nbsp; When someone says something to you that \"stands to reason\" or \"sounds right\", which genuinely seems quite plausible, actually, but without <em>actually</em> providing evidence, you <em>need</em> to interrogate your own beliefs and find the <a href=\"http://books.google.co.il/books?id=oY_x7dE15_AC&amp;pg=PA80&amp;lpg=PA80&amp;dq=equivalent+sample+size+bayesian+prior&amp;source=bl&amp;ots=wBGawir1-6&amp;sig=l6ndcTAiHA5lhCoaWHnt-WvBG9A&amp;hl=iw&amp;sa=X&amp;ei=noqEVLdJxfVQ0fqA4A8&amp;redir_esc=y#v=onepage&amp;q=equivalent%20sample%20size%20bayesian%20prior&amp;f=false\">Equivalent Sample Size</a> of the <em>informative prior</em> generating that subjective plausibility <em>before</em> you let yourself get talked into anything.&nbsp; This applies triply in philosophy.</li>\n</ol>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RMtdp6eGNjTZcmwJ6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZHfS5CwbSSAdrffRQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 7, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "27681", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T20:11:47.000Z", "modifiedAt": null, "url": null, "title": "A Story With Zombies", "slug": "a-story-with-zombies", "viewCount": null, "lastCommentedAt": "2018-03-06T04:37:07.370Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jFzovY2CERF5bd2EW/a-story-with-zombies", "pageUrlRelative": "/posts/jFzovY2CERF5bd2EW/a-story-with-zombies", "linkUrl": "https://www.lesswrong.com/posts/jFzovY2CERF5bd2EW/a-story-with-zombies", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Story%20With%20Zombies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Story%20With%20Zombies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjFzovY2CERF5bd2EW%2Fa-story-with-zombies%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Story%20With%20Zombies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjFzovY2CERF5bd2EW%2Fa-story-with-zombies", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjFzovY2CERF5bd2EW%2Fa-story-with-zombies", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1020, "htmlBody": "<p><i>(inspired by <A HREF=\"http://www.chriswooding.com/zombies-seriously-enough/\">Zombies: Seriously, Enough</A>, <A HREF=\"http://thewritersadvice.com/2012/07/26/zombies-are-sooooooooo-overdone/\">Zombies Are So Overdone</A>, and <A HREF=\"http://io9.com/10-science-fiction-and-fantasy-stories-that-editors-are-1566121756\">Scifi/Fantasy Stories Editors Are Tired Of Seeing: Zombies</A>)</i></p>\n<p>He walked into my office and threw the manuscript on my desk with a thud.</p>\n<p>&#8220;It&#8217;s called <i>Thankful For Zombies</i>. A zombie story where&#8230;&#8221;</p>\n<p>&#8220;Nope,&#8221; I said.</p>\n<p>His face deflated like a balloon. &#8220;But I didn&#8217;t even&#8230;&#8221;</p>\n<p>&#8220;Zombies are overdone,&#8221; I said.</p>\n<p>&#8220;But this is a zombie story with a twist!&#8221;</p>\n<p>&#8220;Zombie stories with twists are <i>super</i> overdone.&#8221;</p>\n<p>&#8220;But this is a story about an extended family who get together for Thanksgiving dinner, only to be interrupted by a zombie apocalypse. It&#8217;s a Thanksgiving story about zombies. You have to admit that the combination of zombies and Thanksgiving has never&#8230;&#8221;</p>\n<p>&#8220;Done,&#8221; I said.</p>\n<p>&#8220;Wait, really? The family starts out estranged and suspicious of each other, but then when they all have to work together to&#8230;&#8221;</p>\n<p>&#8220;Done,&#8221; I said.</p>\n<p>&#8220;How could that have been done?&#8221;</p>\n<p>&#8220;Listen. I know you won&#8217;t believe me, but for the past ten years or so, the best literary minds of our generation have been working on creating zombie stories <i>just</i> different enough from every other zombie story around to get published. First the clever and interesting twists got explored. Then the mediocre and boring twists. Then the absurd and idiotic twists. Finally the genre got <i>entirely mined out</i>. There is now a New York Times bestselling book about zombies invading Jane Austen&#8217;s <i>Pride and Prejudice</i>. If your idea isn&#8217;t weirder than that, <i>it&#8217;s been done</i>. And that&#8217;s the logical &#8216;if&#8217;. If your idea <i>is</i> weirder than that, <i>it has also been done</i>.&#8221;</p>\n<p>&#8220;I <i>will</i> get <i>Thankful for Zombies</i> published,&#8221; he said.</p>\n<p>&#8220;You won&#8217;t,&#8221; I advised him.</p>\n<p>&#8220;I just have to think of an original angle.&#8221;</p>\n<p>&#8220;You really won&#8217;t,&#8221; I told him.</p>\n<p>&#8220;The zombies are the good guys,&#8221; he proposed.</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;The zombies are smarter than humans.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;In the end, we ourselves are the zombies.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A human girl falls in love with a zombie.&#8221;</p>\n<p>&#8220;<A HREF=\"http://www.emeraldrain.com/cd/cd_yzil.html\">Done.</A>&#8221;</p>\n<p>&#8220;Okay, fine. Toss the Thanksgiving angle. There&#8217;s got to be some zombie plot that will be fresh and new.&#8221;</p>\n<p>&#8220;I promise you, there&#8217;s not.&#8221;</p>\n<p>&#8220;Zombies in space.&#8221;</p>\n<p>&#8220;<a href=\"http://smile.amazon.com/gp/product/0316021806/ref=as_li_tl?ie=UTF8&#038;camp=1789&#038;creative=390957&#038;creativeASIN=0316021806&#038;linkCode=as2&#038;tag=slastacod-20&#038;linkId=62XTQLCM3OZLVWZR\">Done</a><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&#038;l=as2&#038;o=1&#038;a=0316021806\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />.&#8221;</p>\n<p>&#8220;Zombies <i>from</i> space.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Zombies <i>are</i> space.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Zombies in Victorian England.&#8221;</p>\n<p>&#8220;<a href=\"http://smile.amazon.com/gp/product/1401228402/ref=as_li_tl?ie=UTF8&#038;camp=1789&#038;creative=390957&#038;creativeASIN=1401228402&#038;linkCode=as2&#038;tag=slastacod-20&#038;linkId=ZBVQUXBHBHKBJTOG\">Done</a><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&#038;l=as2&#038;o=1&#038;a=1401228402\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />&#8216;&#8221;</p>\n<p>&#8220;Zombies in Edwardian England.&#8221;</p>\n<p>&#8220;<a href=\"http://smile.amazon.com/gp/product/1401237630/ref=as_li_tl?ie=UTF8&#038;camp=1789&#038;creative=390957&#038;creativeASIN=1401237630&#038;linkCode=as2&#038;tag=slastacod-20&#038;linkId=ITZADDCL3D3O7YML\">Done</a><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&#038;l=as2&#038;o=1&#038;a=1401237630\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />.&#8221;</p>\n<p>&#8220;Zombies in Shakespearean England.&#8221;</p>\n<p>&#8220;<a href=\"http://smile.amazon.com/gp/product/B0058M5TE2/ref=as_li_tl?ie=UTF8&#038;camp=1789&#038;creative=390957&#038;creativeASIN=B0058M5TE2&#038;linkCode=as2&#038;tag=slastacod-20&#038;linkId=KPVWENA2UQXZELCH\">Done</a><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&#038;l=as2&#038;o=1&#038;a=B0058M5TE2\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />.&#8221;</p>\n<p>&#8220;Shakespeare was a zombie, and all of his plays are just the word BRAAAAAAIIINS repeated over and over again.&#8221;</p>\n<p>&#8220;Done, for some reason.&#8221;</p>\n<p>&#8220;A young zombie comes of age.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A middle-aged zombie wonders if her single-minded focus on career success has prevented her from becoming the kind of zombie she wanted to be when she was younger.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;An elderly zombie contemplates death.&#8221;</p>\n<p>&#8220;Zombies are already dead.&#8221;</p>\n<p>&#8220;Then I can&#8230;&#8221;</p>\n<p>&#8220;&#8230;and yet it&#8217;s still been done.&#8221;</p>\n<p>&#8220;A zombie in the Vietnam War.&#8221;</p>\n<p>&#8220;<A HREF=\"http://usatoday30.usatoday.com/life/comics/2011-04-18-68zombie_N.htm\">Done.</A>&#8221;</p>\n<p>&#8220;A hippie zombie at Woodstock.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Strong female zombies.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Jewish zombies.&#8221;</p>\n<p>&#8220;<A HREF=\"https://www.youtube.com/watch?v=ttJNl2FyvKs\">Done.</A>&#8221;</p>\n<p>&#8220;Black zombies.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A gay zombie struggling to fit into a homophobic zombie society.&#8221;</p>\n<p>&#8220;Come on, this is the 21st century. Done like ten times. One of them won the Booker.&#8221;</p>\n<p>&#8220;Gender-questioning zombies.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;An immigrant zombie comes to America, with nothing but the decaying shirt on his back, knowing only a single word of English.&#8221;</p>\n<p>&#8220;<i>All</i> zombies only know a single word of English. Also, done.&#8221;</p>\n<p>&#8220;Nazi zombies.&#8221;</p>\n<p>&#8220;<A HREF=\"http://en.wikipedia.org/wiki/Nazi_zombies\">Done.</A>&#8221;</p>\n<p>&#8220;Vampire zombies.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Pirate zombies.&#8221;</p>\n<p>&#8220;<A HREF=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/NinjaPirateZombieRobot\">Done</A>.&#8221;</p>\n<p>&#8220;Obstetrician/gynaecologist zombies.&#8221;</p>\n<p>&#8220;<A HREF=\"http://books.google.com/books?id=WyQRBQAAQBAJ&#038;pg=PP6&#038;lpg=PP6&#038;dq=stop+writing+zombie+stories&#038;source=bl&#038;ots=VMNCjpK0lq&#038;sig=wdVeeCrH8VyqEGVbiU3g2mFP9cU&#038;hl=en&#038;sa=X&#038;ei=r5qEVIGCFMG0yASPlYHgBw&#038;ved=0CEMQ6AEwCjgU\">Done.</A>&#8221;</p>\n<p>&#8220;Zombie Hitler.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Zombie Henry VIII.&#8221;</p>\n<p>&#8220;<a href=\"http://smile.amazon.com/gp/product/B006X37YXE/ref=as_li_tl?ie=UTF8&#038;camp=1789&#038;creative=390957&#038;creativeASIN=B006X37YXE&#038;linkCode=as2&#038;tag=slastacod-20&#038;linkId=K4LZBVB3SBNNPW7D\">Done</a><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&#038;l=as2&#038;o=1&#038;a=B006X37YXE\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" />&#8220;.</p>\n<p>&#8220;But what if it was told from the perspective of Anne Boleyn?&#8221;</p>\n<p>&#8220;<A HREF=\"http://www.goodreads.com/book/show/13551320-anne-boleyn-and-the-zombie-apocalypse\">Done</A>.&#8221;</p>\n<p>&#8220;Zombie Leonardo da Vinci.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Zombie Jesus.&#8221;</p>\n<p>&#8220;Done. By three guys named Matt, Luke, and John.&#8221;</p>\n<p>&#8220;Zombie Buddha.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Zombie Mohammed.&#8221;</p>\n<p>&#8220;Done. As is the author, if you get my drift.&#8221;</p>\n<p>&#8220;Zombie Zoroaster.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A parody subverting zombie stories.&#8221;</p>\n<p>&#8220;Super done.&#8221;</p>\n<p>&#8220;A parody subverting zombie stories lampshading how overdone they are.&#8221;</p>\n<p>&#8220;Super duper done.&#8221;</p>\n<p>&#8220;Hmmmm.&#8221; He thinks for a second. &#8220;Hold on, I&#8217;m remembering something from my college math class that might work here. You take all the zombie novels ever written, and you put them in some well-ordering, for example from first to last published. Then you make a new novel, consisting of the first page of the first novel, the second page of the second novel, and so on. But you change each page just a little bit. Since we know the first page of the new novel is different from the first page of the first novel, and the second page of the new novel is different from the second page of the second novel, by extension we know that there is at least one page on which the new novel is different from each zombie novel currently in existence. That means that the new story is provably original.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;I don&#8217;t think you understand; it&#8217;s mathematically impossible for&#8230;&#8221;</p>\n<p>&#8220;No, I mean there&#8217;s a story about a zombie doing that.&#8221;</p>\n<p>&#8220;Oh.&#8221; He furrowed his brow. &#8220;A zombie superhero.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;Steampunk zombies.&#8221;</p>\n<p>&#8220;Done. I think now you&#8217;re just trolling me.&#8221;</p>\n<p>&#8220;Motorcycle gangs of zombies.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A zombie story that&#8217;s a metaphor for how&#8230;&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;I didn&#8217;t finish!&#8221;</p>\n<p>&#8220;You didn&#8217;t have to.&#8221;</p>\n<p>&#8220;A zombie gets cancer.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A zombie gets depression.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A zombie tries to write zombie fiction.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A zombie tries to write zombie fiction <i>about</i> a zombie trying to write zombie fiction.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A zombie tries to&#8230;&#8221;</p>\n<p>&#8220;It&#8217;s done all the way down.&#8221;</p>\n<p>&#8220;Young free-spirited zombies trying to see America.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A story that starts off as being about a fantasy society of knights and damsels, but at the very end it&#8217;s revealed everyone is a zombie.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A story that starts off as being about a young woman&#8217;s struggle to succeed in 1980s Wall Street, but at the very end it&#8217;s revealed everyone is a zombie.&#8221;</p>\n<p>&#8220;Done.&#8221;</p>\n<p>&#8220;A story that starts off as being a paleontology textbook about the fauna of the Lower Cretaceous, but at the very end it&#8217;s revealed everyone is a zombie.&#8221;</p>\n<p>&#8220;Twist zombie endings are <i>done</i>.&#8221;</p>\n<p>&#8220;A zombie&#8230;a zombie riding a giant purple emu through 17th century Ireland teams up with the pre-ghost of Thomas Jefferson to investigate a crime in which time-traveling flamboyantly gay sapient hippos have murdered the Secret Protestant Pope in order to initiate the Jain apocalypse, with liberal quotations from and allusions to the works of Edgar Allen Poe Thomas Pynchon and the medieval Rolandic cycle, and also the whole thing is a metaphor for Republican resistance to climate change legislation.&#8221;</p>\n<p>I thought for a moment. &#8220;Okay,&#8221; I said. &#8220;That particular plot has not, technically, been done. But no one would read it.&#8221;</p>\n<p>&#8220;They will,&#8221; he said.</p>\n<p>&#8220;You&#8217;d be wasting your time to write it.&#8221;</p>\n<p>&#8220;I&#8217;m writing it,&#8221; he said.</p>\n<p>&#8220;Suit yourself. Put it on my desk when you&#8217;re finished, and I&#8217;ll take a look at it. But your chances aren&#8217;t good.&#8221;</p>\n<p>&#8220;I don&#8217;t care,&#8221; he said, and left.</p>\n<p>I sighed, finished up my last couple of pieces of paperwork, and shambled home from the office. On the way out, I ate my secretary&#8217;s brain.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 13, "hNFdS3rRiYgqqD8aM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jFzovY2CERF5bd2EW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 20, "extendedScore": null, "score": 5.9e-05, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "B384FrQNrxSq4hZoS", "canonicalCollectionSlug": "codex", "canonicalBookId": "YhQ39PPHNrRCgYXcs", "canonicalNextPostSlug": "asches-to-asches", "canonicalPrevPostSlug": "antidepressant-pharmacogenomics-much-more-than-you-wanted-to", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T22:30:08.906Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow social meetup: codename \"Order of Infrared Viola\"", "slug": "meetup-moscow-social-meetup-codename-order-of-infrared-viola", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexander230", "createdAt": "2014-08-27T08:55:16.153Z", "isAdmin": false, "displayName": "Alexander230"}, "userId": "xqoKSJayCCtP5juLh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cRG4ZWigcECK4HgaH/meetup-moscow-social-meetup-codename-order-of-infrared-viola", "pageUrlRelative": "/posts/cRG4ZWigcECK4HgaH/meetup-moscow-social-meetup-codename-order-of-infrared-viola", "linkUrl": "https://www.lesswrong.com/posts/cRG4ZWigcECK4HgaH/meetup-moscow-social-meetup-codename-order-of-infrared-viola", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%20social%20meetup%3A%20codename%20%22Order%20of%20Infrared%20Viola%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%20social%20meetup%3A%20codename%20%22Order%20of%20Infrared%20Viola%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcRG4ZWigcECK4HgaH%2Fmeetup-moscow-social-meetup-codename-order-of-infrared-viola%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%20social%20meetup%3A%20codename%20%22Order%20of%20Infrared%20Viola%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcRG4ZWigcECK4HgaH%2Fmeetup-moscow-social-meetup-codename-order-of-infrared-viola", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcRG4ZWigcECK4HgaH%2Fmeetup-moscow-social-meetup-codename-order-of-infrared-viola", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 307, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17u'>Moscow social meetup: codename &quot;Order of Infrared Viola&quot;</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">14 December 2014 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, Strelbishensky pereulok, 10</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the experimental Social Chaotic meetup! It will be experimental on 2 ways:</p>\n\n<ol>\n<li>It will be open: I will announce the meetup to all places where open meetups are usually announced by Moscow LW community.</li>\n<li>There will be elements of Chaos, such as \"secret quests\" and \"papers with wishes\". Read further for details.</li>\n</ol>\n\n<p>Main themes of meetup are party games and table games.</p>\n\n<p>I have a collection of party and table games, and also you can bring your games with you. We will decide what games to play by participants' wishes.</p>\n\n<p>Also there will be Training game / Team training game: funny game and one of symbols of the Order of Chaos.</p>\n\n<p>Also there will be \"rational games\": Fallacymania, Zendo, \"Quick estimation\".</p>\n\n<p>\"Secret quests\" is very chaotic game. Players take papers with secret quests in the beginning of meetup, and they don't show their quests to others. The goal is to complete your quest. Examples of quests and a form for your ideas for quests are here:</p>\n\n<p><a href=\"https://docs.google.com/forms/d/19gReYSTytJIu7a7gmUzN4Vvhb91VJ0nUm7hL974QqiU/viewform\" rel=\"nofollow\">https://docs.google.com/forms/d/19gReYSTytJIu7a7gmUzN4Vvhb91VJ0nUm7hL974QqiU/viewform</a></p>\n\n<p>\"Papers with wishes\": there will be a vase where you will be able to put a paper with a wish what you want from others to do with you. You will need to write your name on your paper. All participants can take others' papers in any time. Then they read the paper, and if there is something adequate and feasible, they do it :-)</p>\n\n<p>Address of meetup:</p>\n\n<p>Strelbishensky per., 10, ap.60, 3rd entrance, code 60B3112, 5th floor. Nearest metro station: Vystavochnaya. If you have questions, call me 8-905-527-30-82 or write me on e-mail alexander230r@gmail.com (it's better to call if you're searching a way before the meetup).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17u'>Moscow social meetup: codename &quot;Order of Infrared Viola&quot;</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cRG4ZWigcECK4HgaH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.2461406632812994e-06, "legacy": true, "legacyId": "27683", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow_social_meetup__codename__Order_of_Infrared_Viola_\">Discussion article for the meetup : <a href=\"/meetups/17u\">Moscow social meetup: codename \"Order of Infrared Viola\"</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">14 December 2014 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, Strelbishensky pereulok, 10</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the experimental Social Chaotic meetup! It will be experimental on 2 ways:</p>\n\n<ol>\n<li>It will be open: I will announce the meetup to all places where open meetups are usually announced by Moscow LW community.</li>\n<li>There will be elements of Chaos, such as \"secret quests\" and \"papers with wishes\". Read further for details.</li>\n</ol>\n\n<p>Main themes of meetup are party games and table games.</p>\n\n<p>I have a collection of party and table games, and also you can bring your games with you. We will decide what games to play by participants' wishes.</p>\n\n<p>Also there will be Training game / Team training game: funny game and one of symbols of the Order of Chaos.</p>\n\n<p>Also there will be \"rational games\": Fallacymania, Zendo, \"Quick estimation\".</p>\n\n<p>\"Secret quests\" is very chaotic game. Players take papers with secret quests in the beginning of meetup, and they don't show their quests to others. The goal is to complete your quest. Examples of quests and a form for your ideas for quests are here:</p>\n\n<p><a href=\"https://docs.google.com/forms/d/19gReYSTytJIu7a7gmUzN4Vvhb91VJ0nUm7hL974QqiU/viewform\" rel=\"nofollow\">https://docs.google.com/forms/d/19gReYSTytJIu7a7gmUzN4Vvhb91VJ0nUm7hL974QqiU/viewform</a></p>\n\n<p>\"Papers with wishes\": there will be a vase where you will be able to put a paper with a wish what you want from others to do with you. You will need to write your name on your paper. All participants can take others' papers in any time. Then they read the paper, and if there is something adequate and feasible, they do it :-)</p>\n\n<p>Address of meetup:</p>\n\n<p>Strelbishensky per., 10, ap.60, 3rd entrance, code 60B3112, 5th floor. Nearest metro station: Vystavochnaya. If you have questions, call me 8-905-527-30-82 or write me on e-mail alexander230r@gmail.com (it's better to call if you're searching a way before the meetup).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow_social_meetup__codename__Order_of_Infrared_Viola_1\">Discussion article for the meetup : <a href=\"/meetups/17u\">Moscow social meetup: codename \"Order of Infrared Viola\"</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow social meetup: codename \"Order of Infrared Viola\"", "anchor": "Discussion_article_for_the_meetup___Moscow_social_meetup__codename__Order_of_Infrared_Viola_", "level": 1}, {"title": "Discussion article for the meetup : Moscow social meetup: codename \"Order of Infrared Viola\"", "anchor": "Discussion_article_for_the_meetup___Moscow_social_meetup__codename__Order_of_Infrared_Viola_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-07T23:23:12.678Z", "modifiedAt": null, "url": null, "title": "PSA: Eugine_Nier evading ban?", "slug": "psa-eugine_nier-evading-ban", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:38.396Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dahlen", "createdAt": "2012-07-18T19:40:31.734Z", "isAdmin": false, "displayName": "Dahlen"}, "userId": "u2Kz9T6gtzpPy4oxy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/d2vZRvJyNboftm9sE/psa-eugine_nier-evading-ban", "pageUrlRelative": "/posts/d2vZRvJyNboftm9sE/psa-eugine_nier-evading-ban", "linkUrl": "https://www.lesswrong.com/posts/d2vZRvJyNboftm9sE/psa-eugine_nier-evading-ban", "postedAtFormatted": "Sunday, December 7th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20PSA%3A%20Eugine_Nier%20evading%20ban%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APSA%3A%20Eugine_Nier%20evading%20ban%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd2vZRvJyNboftm9sE%2Fpsa-eugine_nier-evading-ban%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=PSA%3A%20Eugine_Nier%20evading%20ban%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd2vZRvJyNboftm9sE%2Fpsa-eugine_nier-evading-ban", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd2vZRvJyNboftm9sE%2Fpsa-eugine_nier-evading-ban", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 617, "htmlBody": "<p>I know this reeks of witch-hunting, but... I have a hunch that <a href=\"/user/Eugine_Nier/\">u/Eugine_Nier</a> is back under the guise of <a href=\"/user/Azathoth123/\">u/Azathoth123</a>. Reasons:</p>\n<ul>\n<li>&nbsp;Same political views, with a tendency to be outspoken about them</li>\n<li>Karma hovering in the 70s% for both accounts, occasionally going into the 60s%, significantly lower than the LW average</li>\n<li>The dates match up. Kaj Sotala <a href=\"/lw/kfq/moderator_action_eugine_nier_is_now_banned_for/\">announced</a> on July 03, 2014 that Eugine was to be permanently banned. The <a href=\"/lw/kgb/rationality_quotes_july_2014/b3nv\">first comment</a> from Azathoth123 was on July 12, 2014.</li>\n<li>The one that got my attention was the posting pattern. Particularly, Eugine_Nier had a pervasive pattern of exceeding the quote limits per rationality thread. That's actually the first thing I had noticed about the guy back when he was first active, and a few times I thought about drawing attention to the way he flouted the rules, but never got around to it/cared enough about the matter. Now, I see Azathoth123 doing the same thing. The current Rationality Quotes thread has four quotes from him already and it hasn't even been a week since the thread was posted; all of them have something to do with his political views. As do basically all of his postings so far.</li>\n<li>Each one of these points, separately, has a small prior probability if the two of them are not the same person. Together, they have an even smaller probability. Especially the predilection for posting one too many rationality quotes; seriously, how common an occurrence is that one in particular?</li>\n<li>My experience so far with the internet has been that people like Eugine never really leave an online community they have pestered for so long. It doesn't matter if they're IP banned or something. They always come back, just under a different name, and they come back shortly.</li>\n</ul>\n<p>I don't have an axe to grind against the guy, I've only spoken to him a couple of times and didn't notice any particularly large karma hits afterwards, I just really dislike it when someone skirts the rules like that. Disruptive users evading permanent bans never helped any community ever.<br /><br />Obviously I'm posting this here because I think a moderator should look into the matter. Usually I would be posting a disclaimer of some sort, apologizing in advance to Azathoth123 for attacking his standing with slanderous accusations if this turned out not to be the case. Well, I won't. The more I look into the matter, the more confident I get that they're the same person. Azathoth, if you're reading this and you're not Eugine_Nier, then I strongly advise you go search for your twin brother, I think you'll get along very well. Seriously, I'm saying this in good faith. You have a suspiciously great deal of things in common.<br /><br />If retributive downvoting is (still) a concern (if not, then disregard this paragraph): I'd like to request, if such a thing is possible, that a mod karma-blocks me until the issue is over, so as to not incur undeserved downvotes (it would also mean I'd get no upvotes). In turn, I promise not to abuse the system by spamming the boards with garbage without consequences, but then again given my history so far on LW I don't think that such an abuse should be expected from me. For the record, I could have made a throwaway account just to say this, and not risk being karmassassinated, but 1) a zero karma account has no credibility and 2) for signalling reasons I prefer to put my money where my mouth is.</p>\n<p>P.S. I only made this announcement its own post because the latest open thread was about to \"expire\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hGzywXvWhSdJi5F2a": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "d2vZRvJyNboftm9sE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 45, "baseScore": 27, "extendedScore": null, "score": 0.000125, "legacy": true, "legacyId": "27684", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NGc3Yjecg9pDMznWq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-08T00:06:02.006Z", "modifiedAt": null, "url": null, "title": "Open thread, Dec. 8 - Dec. 15, 2014", "slug": "open-thread-dec-8-dec-15-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:36.005Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wv2T69qsrHgXcKddZ/open-thread-dec-8-dec-15-2014", "pageUrlRelative": "/posts/wv2T69qsrHgXcKddZ/open-thread-dec-8-dec-15-2014", "linkUrl": "https://www.lesswrong.com/posts/wv2T69qsrHgXcKddZ/open-thread-dec-8-dec-15-2014", "postedAtFormatted": "Monday, December 8th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20Dec.%208%20-%20Dec.%2015%2C%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20Dec.%208%20-%20Dec.%2015%2C%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwv2T69qsrHgXcKddZ%2Fopen-thread-dec-8-dec-15-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20Dec.%208%20-%20Dec.%2015%2C%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwv2T69qsrHgXcKddZ%2Fopen-thread-dec-8-dec-15-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwv2T69qsrHgXcKddZ%2Fopen-thread-dec-8-dec-15-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 111, "htmlBody": "<div id=\"entry_t3_lbz\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px; font-weight: bold;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><a href=\"/r/discussion/lw/lbz/open_thread_dec_1_dec_7_2014/\">Previous OT</a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><a href=\"/r/discussion/lw/le3/open_thread_dec_15_dec_21_2014/\">Next OT</a></p>\n<hr />\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the list-of-threads page before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">3.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should be posted in Discussion, and not Main.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">4.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\"> </span></p>\n<hr />\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">If you have any comments about the Open Thread posts themselves or this post specifically, please post them as a reply to the <strong>[META]</strong> comment.&nbsp; Aside from that, this thread is as organized as you collectively wish to make it.</p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wv2T69qsrHgXcKddZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 2.246351510103746e-06, "legacy": true, "legacyId": "27685", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 293, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["r2Zds5jy3dAaiFsPN", "A8THjFzBhHZEjzw3D"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-08T14:33:43.827Z", "modifiedAt": null, "url": null, "title": "[Link] An exact mapping between the Variational Renormalization Group and Deep Learning]", "slug": "link-an-exact-mapping-between-the-variational", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:34.754Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gunnar_Zarncke", "createdAt": "2013-07-20T15:40:42.323Z", "isAdmin": false, "displayName": "Gunnar_Zarncke"}, "userId": "qmJFRN7jitjPsuF3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zeuT3MhEBG8TFFj46/link-an-exact-mapping-between-the-variational", "pageUrlRelative": "/posts/zeuT3MhEBG8TFFj46/link-an-exact-mapping-between-the-variational", "linkUrl": "https://www.lesswrong.com/posts/zeuT3MhEBG8TFFj46/link-an-exact-mapping-between-the-variational", "postedAtFormatted": "Monday, December 8th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20An%20exact%20mapping%20between%20the%20Variational%20Renormalization%20Group%20and%20Deep%20Learning%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20An%20exact%20mapping%20between%20the%20Variational%20Renormalization%20Group%20and%20Deep%20Learning%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzeuT3MhEBG8TFFj46%2Flink-an-exact-mapping-between-the-variational%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20An%20exact%20mapping%20between%20the%20Variational%20Renormalization%20Group%20and%20Deep%20Learning%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzeuT3MhEBG8TFFj46%2Flink-an-exact-mapping-between-the-variational", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzeuT3MhEBG8TFFj46%2Flink-an-exact-mapping-between-the-variational", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 242, "htmlBody": "<p><strong><a href=\"http://arxiv.org/abs/1410.3831\">An exact mapping between the Variational Renormalization Group and Deep Learning</a>&nbsp;by Pankaj Mehta, David J. Schwab</strong></p>\n<blockquote>\n<p>Deep learning is a broad set of techniques that uses multiple layers of representation to automatically learn relevant features directly from structured data. Recently, such techniques have yielded record-breaking results on a diverse set of difficult machine learning tasks in computer vision, speech recognition, and natural language processing. Despite the enormous success of deep learning, relatively little is understood theoretically about why these techniques are so successful at feature learning and compression. Here, we show that deep learning is intimately related to one of the most important and successful techniques in theoretical physics, the renormalization group (RG). RG is an iterative coarse-graining scheme that allows for the extraction of relevant features (i.e. operators) as a physical system is examined at different length scales. We construct an exact mapping from the variational renormalization group, first introduced by Kadanoff, and deep learning architectures based on Restricted Boltzmann Machines (RBMs). We illustrate these ideas using the nearest-neighbor Ising Model in one and two-dimensions. <strong>Our results suggests that deep learning algorithms may be employing a generalized RG-like scheme to learn relevant features from data.</strong></p>\n</blockquote>\n<p>To me this paper suggests that deep learning is an approach that could be made or is already conceptually general enough to learn everything there is to learn (assuming sufficient time and resources). Thus it could already be used as the base algorithm of a self-optimizing AGI.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zeuT3MhEBG8TFFj46", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 11, "extendedScore": null, "score": 2.248261131180102e-06, "legacy": true, "legacyId": "27688", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-08T15:39:25.235Z", "modifiedAt": null, "url": null, "title": "Stupid Questions December 2014", "slug": "stupid-questions-december-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:09.923Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mSc3i4zNF6m6idnDs/stupid-questions-december-2014", "pageUrlRelative": "/posts/mSc3i4zNF6m6idnDs/stupid-questions-december-2014", "linkUrl": "https://www.lesswrong.com/posts/mSc3i4zNF6m6idnDs/stupid-questions-december-2014", "postedAtFormatted": "Monday, December 8th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Stupid%20Questions%20December%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStupid%20Questions%20December%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmSc3i4zNF6m6idnDs%2Fstupid-questions-december-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Stupid%20Questions%20December%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmSc3i4zNF6m6idnDs%2Fstupid-questions-december-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmSc3i4zNF6m6idnDs%2Fstupid-questions-december-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<p>This thread is for asking any questions that might seem obvious, tangential, silly or what-have-you. Don't be shy, everyone has holes in their knowledge, though the fewer and the smaller we can make them, the better.</p>\n<p>Please be respectful of other people's admitting ignorance and don't mock them for it, as they're doing a noble thing.</p>\n<p>To any future monthly posters of SQ threads, please remember to add the \"stupid_questions\" tag.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mSc3i4zNF6m6idnDs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 25, "extendedScore": null, "score": 2.2484058184571116e-06, "legacy": true, "legacyId": "27689", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 342, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-09T02:00:34.433Z", "modifiedAt": null, "url": null, "title": "Superintelligence 13: Capability control methods", "slug": "superintelligence-13-capability-control-methods", "viewCount": null, "lastCommentedAt": "2020-08-14T16:03:51.191Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/398Swu6jmczzSRvHy/superintelligence-13-capability-control-methods", "pageUrlRelative": "/posts/398Swu6jmczzSRvHy/superintelligence-13-capability-control-methods", "linkUrl": "https://www.lesswrong.com/posts/398Swu6jmczzSRvHy/superintelligence-13-capability-control-methods", "postedAtFormatted": "Tuesday, December 9th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligence%2013%3A%20Capability%20control%20methods&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligence%2013%3A%20Capability%20control%20methods%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F398Swu6jmczzSRvHy%2Fsuperintelligence-13-capability-control-methods%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligence%2013%3A%20Capability%20control%20methods%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F398Swu6jmczzSRvHy%2Fsuperintelligence-13-capability-control-methods", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F398Swu6jmczzSRvHy%2Fsuperintelligence-13-capability-control-methods", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1737, "htmlBody": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr />\n<p>Welcome. This week we discuss the thirteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>: <strong><em>capability control methods</em></strong>. This corresponds to the start of chapter nine.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: &ldquo;Two agency problems&rdquo; and &ldquo;Capability control methods&rdquo; from Chapter 9</p>\n<hr />\n<h1>Summary</h1>\n<ol>\n<li><strong>If the <a href=\"/lw/l9u/superintelligence_11_the_treacherous_turn/\">default outcome is doom</a>, how can we avoid it?</strong>&nbsp;(p127)</li>\n<li>We can divide this 'control problem' into two parts:<ol>\n<li><em>The <strong>first principal-agent problem</strong></em>: the <a href=\"http://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem\">well known problem</a> faced by a sponsor wanting an employee to fulfill their wishes (usually called 'the principal agent problem')</li>\n<li><em>The<strong> second principal-agent problem</strong></em>: the emerging problem of a developer wanting their AI to fulfill their wishes</li>\n</ol></li>\n<li>How to solve second problem? We can't rely on behavioral observation (as seen in <a href=\"/lw/l9u/superintelligence_11_the_treacherous_turn/\">week 11</a>). Two other options are 'capability control methods' and 'motivation selection methods'. We see the former this week, and the latter next week.</li>\n<li><em><strong>Capability control methods</strong></em>: avoiding bad outcomes through limiting what an AI can do. (p129)</li>\n<li>Some capability control methods:<ol>\n<li><em><strong>Boxing</strong></em>: minimize interaction between the AI and the outside world. Note that the AI must interact with the world to be useful, and that it is hard to eliminate small interactions. (p129)</li>\n<li><strong><em>Incentive methods</em></strong>: set up the AI's environment such that it is in the AI's interest to cooperate. e.g. a social environment with punishment or social repercussions often achieves this for contemporary agents. One could also design a reward system, perhaps with cryptographic rewards (so that the AI could not wirehead) or heavily discounted rewards (so that long term plans are not worth the short term risk of detection) (p131) \n<ul>\n<li><strong><em>Anthropic capture</em></strong>: an AI thinks it might be in a simulation, and so tries to behave as will be rewarded by simulators (box 8; p134)</li>\n</ul>\n</li>\n<li><strong><em>Stunting</em></strong>: limit the AI's capabilities. This may be hard to do to a degree that avoids danger and is still useful. An option here is to limit the AI's information. A strong AI may infer much from little apparent access to information however. (p135)</li>\n<li><strong><em>Tripwires</em></strong>: test the system without its knowledge, and shut it down if it crosses some boundary. This might be combined with 'honey pots' to attract undesirable AIs take an action that would reveal them. Tripwires could test behavior, ability, or content. (p137)</li>\n</ol></li>\n</ol>\n<h1>Another view</h1>\n<p><a href=\"http://popsciencebooks.blogspot.co.uk/2014/07/superintelligence-nick-bostrom.html\">Brian Clegg</a>&nbsp;reviews the book mostly favorably, but isn't convinced that controlling an AI via merely turning it off should be so hard:</p>\n<blockquote>\n<div style=\"border: 0px; color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 15px; line-height: 24px; margin-bottom: 1.625em; outline: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; vertical-align: baseline;\">I also think a couple of the fundamentals aren&rsquo;t covered well enough, but pretty much assumed. One is that it would be impossible to contain and restrict such an AI. Although some effort is put into this, I&rsquo;m not sure there is enough thought put into the basics of ways you can pull the plug manually &ndash; if necessary by shutting down the power station that provides the AI with electricity.</div>\n</blockquote>\n<div style=\"border: 0px; color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 15px; line-height: 24px; margin-bottom: 1.625em; outline: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; vertical-align: baseline;\"><a href=\"http://edge.org/conversation/the-myth-of-ai\">Kevin Kelly</a>&nbsp;also apparently doubts that AI will substantially impede efforts to modify it:</div>\n<div style=\"border: 0px; color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 15px; line-height: 24px; margin-bottom: 1.625em; outline: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; vertical-align: baseline;\">\n<blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\"><span style=\"font-weight: 700;\"><em>...We&rsquo;ll reprogram the AIs if we are not satisfied with their performance...</em></span></p>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">...This is an engineering problem. So far as I can tell, AIs have not yet made a decision that its human creators have regretted. If they do (or when they do), then we change their algorithms. If AIs are making decisions that our society, our laws, our moral consensus, or the consumer market, does not approve of, we then should, and will, modify the principles that govern the AI, or create better ones that do make decisions we approve. Of course machines will make &ldquo;mistakes,&rdquo; even big mistakes &ndash; but so do humans. We keep correcting them. There will be tons of scrutiny on the actions of AI, so the world is watching. However, we don&rsquo;t have universal consensus on what we find appropriate, so that is where most of the friction about them will come from. As we decide, our AI will decide...</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">This may be related to his view that AI is unlikely to modify itself (from further down the same page):</p>\n<blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\"><span style=\"font-weight: 700;\"><em>3. Reprogramming themselves, on their own, is the least likely of many scenarios.</em></span></p>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">The great fear pumped up by some, though, is that as AI gain our confidence in making decisions, they will somehow prevent us from altering their decisions. The fear is they lock us out. They go rogue. It is very difficult to imagine how this happens. It seems highly improbable that human engineers would program an AI so that it could not be altered in any way. That is possible, but so impractical. That hobble does not even serve a bad actor. The usual scary scenario is that an AI will reprogram itself on its own to be unalterable by outsiders. This is conjectured to be a selfish move on the AI&rsquo;s part, but it is unclear how an unalterable program is an advantage to an AI. It would also be an incredible achievement for a gang of human engineers to create a system that could not be hacked. Still it may be possible at some distant time, but it is only one of many possibilities. An AI could just as likely decide on its own to let anyone change it, in open source mode. Or it could decide that it wanted to merge with human will power. Why not? In the only example we have of an introspective self-aware intelligence (hominids), we have found that evolution seems to have designed our minds to not be easily self-reprogrammable. Except for a few yogis, you can&rsquo;t go in and change your core mental code easily. There seems to be an evolutionary disadvantage to being able to easily muck with your basic operating system, and it is possible that AIs may need the same self-protection. We don&rsquo;t know. But the possibility they, on their own, decide to lock out their partners (and doctors) is just one of many possibilities, and not necessarily the most probable one.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">&nbsp;</p>\n</div>\n<h1>Notes</h1>\n<p><strong>1. What do you do with a bad AI once it is under your control?</strong></p>\n<p>Note that capability control doesn't necessarily solve much: boxing, stunting and tripwires seem to just stall a superintelligence rather than provide means to safely use one to its full capacity. This leaves the controlled AI to be overtaken by some other unconstrained AI as soon as someone else isn't so careful. In this way, capability control methods seem much like slowing down AI research: helpful in the short term while we find better solutions, but not in itself a solution to the problem.</p>\n<p>However this might be too pessimistic. An AI whose capabilities are under control might either be almost as useful as an uncontrolled AI who shares your goals (if interacted with the right way), or at least be helpful in getting to a more stable situation.</p>\n<p>Paul Christiano&nbsp;<a href=\"/lw/3dw/what_can_you_do_with_an_unfriendly_ai/\">outlines a scheme</a> for safely using an unfriendly AI to solve some kinds of problems. We <a href=\"http://ordinaryideas.wordpress.com/2014/07/18/adversarial-collaboration/\">have</a> <a href=\"http://meteuphoric.wordpress.com/2014/07/21/how-to-buy-a-truth-from-a-liar/\">both</a> blogged on general methods for getting useful work from adversarial agents, which is related.</p>\n<p><strong>2. Cryptographic boxing</strong></p>\n<p>Paul Christiano&nbsp;<a href=\"/lw/3cz/cryptographic_boxes_for_unfriendly_ai/\">describes</a>&nbsp;a way to stop an AI interacting with the environment using a cryptographic box.</p>\n<p><strong>3. Philosophical Disquisitions</strong></p>\n<p>Danaher again&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2014/08/bostrom-on-superintelligence-5-limiting.html\">summarizes the chapter</a>&nbsp;well. Read it if you want a different description of any of the ideas, or to refresh your memory. He also provides a table of the methods presented in this chapter.</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9s_0.png?v=f8c8c807d0fa1387f671b78d352329af\" alt=\"\" width=\"700\" /></p>\n<div>\n<p><strong>4. Some relevant fiction</strong></p>\n<p><a href=\"/lw/qk/that_alien_message/\">That Alien Message</a> by Eliezer Yudkowsky</p>\n<p><strong>5. Control through social integration</strong></p>\n</div>\n<p>Robin Hanson <a href=\"http://www.overcomingbias.com/2009/10/prefer-law-to-values.html\">argues</a> that it matters more that a population of AIs are integrated into our social institutions, and that they keep the peace among themselves through the same institutions we keep the peace among ourselves, than whether they have the right values. He thinks this is why you trust your neighbors, not because you are confident that they have the same values as you. He has&nbsp;<a href=\"http://www.overcomingbias.com/2010/04/seek-peace-not-values.html\">several</a> <a href=\"http://www.overcomingbias.com/2011/07/chalmers-reply-2.html\">followup</a> <a href=\"http://www.overcomingbias.com/2009/10/lets-not-kill-all-the-lawyers.html\">posts</a>.</p>\n<p><strong>6. More miscellaneous writings on these topics</strong></p>\n<p><a href=\"http://wiki.lesswrong.com/wiki/AI_boxing\">LessWrong wiki on AI boxing</a>.&nbsp;<a href=\"http://www.nickbostrom.com/papers/oracle.pdf\">Armstrong et al on controlling and using an oracle AI</a>.&nbsp;<a href=\"http://cecs.louisville.edu/ry/LeakproofingtheSingularity.pdf\">Roman Yampolskiy on 'leakproofing' the singularity</a>. I have not necessarily read these.</p>\n<p>&nbsp;</p>\n<p><span style=\"font-size: 2em;\">In-depth investigations</span></p>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<p>&nbsp;</p>\n<ol>\n<li>Choose any control method and work out the details better. For instance:<ol>\n<li>Could one construct a cryptographic box for an untrusted autonomous system?</li>\n<li>Investigate steep temporal discounting as an incentives control method for an untrusted AGI.</li>\n</ol></li>\n<li>Are there other capability control methods we could add to the list?</li>\n<li>Devise uses for a malicious but constrained AI.</li>\n<li>How much pressure is there likely to be to develop AI which is not controlled?</li>\n<li>If existing AI methods had unexpected progress and were heading for human-level soon, what precautions should we take now?</li>\n</ol>\n<p>&nbsp;</p>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1>How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about 'motivation selection methods'. To prepare,&nbsp;<strong>read</strong>&nbsp;&ldquo;Motivation selection methods&rdquo; and &ldquo;Synopsis&rdquo; from Chapter 9<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 15th December. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1, "tdt83ChxnEgwwKxi6": 1, "YhZLQQKsREKE7fC4F": 1, "zCYXpx33wq8chGyEz": 1, "KqfqD7YSMeFTLJCcs": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "398Swu6jmczzSRvHy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 14, "extendedScore": null, "score": 4.4e-05, "legacy": true, "legacyId": "27568", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr>\n<p>Welcome. This week we discuss the thirteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>: <strong><em>capability control methods</em></strong>. This corresponds to the start of chapter nine.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: \u201cTwo agency problems\u201d and \u201cCapability control methods\u201d from Chapter 9</p>\n<hr>\n<h1 id=\"Summary\">Summary</h1>\n<ol>\n<li><strong>If the <a href=\"/lw/l9u/superintelligence_11_the_treacherous_turn/\">default outcome is doom</a>, how can we avoid it?</strong>&nbsp;(p127)</li>\n<li>We can divide this 'control problem' into two parts:<ol>\n<li><em>The <strong>first principal-agent problem</strong></em>: the <a href=\"http://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem\">well known problem</a> faced by a sponsor wanting an employee to fulfill their wishes (usually called 'the principal agent problem')</li>\n<li><em>The<strong> second principal-agent problem</strong></em>: the emerging problem of a developer wanting their AI to fulfill their wishes</li>\n</ol></li>\n<li>How to solve second problem? We can't rely on behavioral observation (as seen in <a href=\"/lw/l9u/superintelligence_11_the_treacherous_turn/\">week 11</a>). Two other options are 'capability control methods' and 'motivation selection methods'. We see the former this week, and the latter next week.</li>\n<li><em><strong>Capability control methods</strong></em>: avoiding bad outcomes through limiting what an AI can do. (p129)</li>\n<li>Some capability control methods:<ol>\n<li><em><strong>Boxing</strong></em>: minimize interaction between the AI and the outside world. Note that the AI must interact with the world to be useful, and that it is hard to eliminate small interactions. (p129)</li>\n<li><strong><em>Incentive methods</em></strong>: set up the AI's environment such that it is in the AI's interest to cooperate. e.g. a social environment with punishment or social repercussions often achieves this for contemporary agents. One could also design a reward system, perhaps with cryptographic rewards (so that the AI could not wirehead) or heavily discounted rewards (so that long term plans are not worth the short term risk of detection) (p131) \n<ul>\n<li><strong><em>Anthropic capture</em></strong>: an AI thinks it might be in a simulation, and so tries to behave as will be rewarded by simulators (box 8; p134)</li>\n</ul>\n</li>\n<li><strong><em>Stunting</em></strong>: limit the AI's capabilities. This may be hard to do to a degree that avoids danger and is still useful. An option here is to limit the AI's information. A strong AI may infer much from little apparent access to information however. (p135)</li>\n<li><strong><em>Tripwires</em></strong>: test the system without its knowledge, and shut it down if it crosses some boundary. This might be combined with 'honey pots' to attract undesirable AIs take an action that would reveal them. Tripwires could test behavior, ability, or content. (p137)</li>\n</ol></li>\n</ol>\n<h1 id=\"Another_view\">Another view</h1>\n<p><a href=\"http://popsciencebooks.blogspot.co.uk/2014/07/superintelligence-nick-bostrom.html\">Brian Clegg</a>&nbsp;reviews the book mostly favorably, but isn't convinced that controlling an AI via merely turning it off should be so hard:</p>\n<blockquote>\n<div style=\"border: 0px; color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 15px; line-height: 24px; margin-bottom: 1.625em; outline: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; vertical-align: baseline;\">I also think a couple of the fundamentals aren\u2019t covered well enough, but pretty much assumed. One is that it would be impossible to contain and restrict such an AI. Although some effort is put into this, I\u2019m not sure there is enough thought put into the basics of ways you can pull the plug manually \u2013 if necessary by shutting down the power station that provides the AI with electricity.</div>\n</blockquote>\n<div style=\"border: 0px; color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 15px; line-height: 24px; margin-bottom: 1.625em; outline: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; vertical-align: baseline;\"><a href=\"http://edge.org/conversation/the-myth-of-ai\">Kevin Kelly</a>&nbsp;also apparently doubts that AI will substantially impede efforts to modify it:</div>\n<div style=\"border: 0px; color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 15px; line-height: 24px; margin-bottom: 1.625em; outline: 0px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; vertical-align: baseline;\">\n<blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\"><span style=\"font-weight: 700;\"><em>...We\u2019ll reprogram the AIs if we are not satisfied with their performance...</em></span></p>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">...This is an engineering problem. So far as I can tell, AIs have not yet made a decision that its human creators have regretted. If they do (or when they do), then we change their algorithms. If AIs are making decisions that our society, our laws, our moral consensus, or the consumer market, does not approve of, we then should, and will, modify the principles that govern the AI, or create better ones that do make decisions we approve. Of course machines will make \u201cmistakes,\u201d even big mistakes \u2013 but so do humans. We keep correcting them. There will be tons of scrutiny on the actions of AI, so the world is watching. However, we don\u2019t have universal consensus on what we find appropriate, so that is where most of the friction about them will come from. As we decide, our AI will decide...</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">This may be related to his view that AI is unlikely to modify itself (from further down the same page):</p>\n<blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\"><span style=\"font-weight: 700;\"><em>3. Reprogramming themselves, on their own, is the least likely of many scenarios.</em></span></p>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">The great fear pumped up by some, though, is that as AI gain our confidence in making decisions, they will somehow prevent us from altering their decisions. The fear is they lock us out. They go rogue. It is very difficult to imagine how this happens. It seems highly improbable that human engineers would program an AI so that it could not be altered in any way. That is possible, but so impractical. That hobble does not even serve a bad actor. The usual scary scenario is that an AI will reprogram itself on its own to be unalterable by outsiders. This is conjectured to be a selfish move on the AI\u2019s part, but it is unclear how an unalterable program is an advantage to an AI. It would also be an incredible achievement for a gang of human engineers to create a system that could not be hacked. Still it may be possible at some distant time, but it is only one of many possibilities. An AI could just as likely decide on its own to let anyone change it, in open source mode. Or it could decide that it wanted to merge with human will power. Why not? In the only example we have of an introspective self-aware intelligence (hominids), we have found that evolution seems to have designed our minds to not be easily self-reprogrammable. Except for a few yogis, you can\u2019t go in and change your core mental code easily. There seems to be an evolutionary disadvantage to being able to easily muck with your basic operating system, and it is possible that AIs may need the same self-protection. We don\u2019t know. But the possibility they, on their own, decide to lock out their partners (and doctors) is just one of many possibilities, and not necessarily the most probable one.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1.5em; color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px;\">&nbsp;</p>\n</div>\n<h1 id=\"Notes\">Notes</h1>\n<p><strong id=\"1__What_do_you_do_with_a_bad_AI_once_it_is_under_your_control_\">1. What do you do with a bad AI once it is under your control?</strong></p>\n<p>Note that capability control doesn't necessarily solve much: boxing, stunting and tripwires seem to just stall a superintelligence rather than provide means to safely use one to its full capacity. This leaves the controlled AI to be overtaken by some other unconstrained AI as soon as someone else isn't so careful. In this way, capability control methods seem much like slowing down AI research: helpful in the short term while we find better solutions, but not in itself a solution to the problem.</p>\n<p>However this might be too pessimistic. An AI whose capabilities are under control might either be almost as useful as an uncontrolled AI who shares your goals (if interacted with the right way), or at least be helpful in getting to a more stable situation.</p>\n<p>Paul Christiano&nbsp;<a href=\"/lw/3dw/what_can_you_do_with_an_unfriendly_ai/\">outlines a scheme</a> for safely using an unfriendly AI to solve some kinds of problems. We <a href=\"http://ordinaryideas.wordpress.com/2014/07/18/adversarial-collaboration/\">have</a> <a href=\"http://meteuphoric.wordpress.com/2014/07/21/how-to-buy-a-truth-from-a-liar/\">both</a> blogged on general methods for getting useful work from adversarial agents, which is related.</p>\n<p><strong id=\"2__Cryptographic_boxing\">2. Cryptographic boxing</strong></p>\n<p>Paul Christiano&nbsp;<a href=\"/lw/3cz/cryptographic_boxes_for_unfriendly_ai/\">describes</a>&nbsp;a way to stop an AI interacting with the environment using a cryptographic box.</p>\n<p><strong id=\"3__Philosophical_Disquisitions\">3. Philosophical Disquisitions</strong></p>\n<p>Danaher again&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2014/08/bostrom-on-superintelligence-5-limiting.html\">summarizes the chapter</a>&nbsp;well. Read it if you want a different description of any of the ideas, or to refresh your memory. He also provides a table of the methods presented in this chapter.</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9s_0.png?v=f8c8c807d0fa1387f671b78d352329af\" alt=\"\" width=\"700\"></p>\n<div>\n<p><strong id=\"4__Some_relevant_fiction\">4. Some relevant fiction</strong></p>\n<p><a href=\"/lw/qk/that_alien_message/\">That Alien Message</a> by Eliezer Yudkowsky</p>\n<p><strong id=\"5__Control_through_social_integration\">5. Control through social integration</strong></p>\n</div>\n<p>Robin Hanson <a href=\"http://www.overcomingbias.com/2009/10/prefer-law-to-values.html\">argues</a> that it matters more that a population of AIs are integrated into our social institutions, and that they keep the peace among themselves through the same institutions we keep the peace among ourselves, than whether they have the right values. He thinks this is why you trust your neighbors, not because you are confident that they have the same values as you. He has&nbsp;<a href=\"http://www.overcomingbias.com/2010/04/seek-peace-not-values.html\">several</a> <a href=\"http://www.overcomingbias.com/2011/07/chalmers-reply-2.html\">followup</a> <a href=\"http://www.overcomingbias.com/2009/10/lets-not-kill-all-the-lawyers.html\">posts</a>.</p>\n<p><strong id=\"6__More_miscellaneous_writings_on_these_topics\">6. More miscellaneous writings on these topics</strong></p>\n<p><a href=\"http://wiki.lesswrong.com/wiki/AI_boxing\">LessWrong wiki on AI boxing</a>.&nbsp;<a href=\"http://www.nickbostrom.com/papers/oracle.pdf\">Armstrong et al on controlling and using an oracle AI</a>.&nbsp;<a href=\"http://cecs.louisville.edu/ry/LeakproofingtheSingularity.pdf\">Roman Yampolskiy on 'leakproofing' the singularity</a>. I have not necessarily read these.</p>\n<p>&nbsp;</p>\n<p><span style=\"font-size: 2em;\">In-depth investigations</span></p>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<p>&nbsp;</p>\n<ol>\n<li>Choose any control method and work out the details better. For instance:<ol>\n<li>Could one construct a cryptographic box for an untrusted autonomous system?</li>\n<li>Investigate steep temporal discounting as an incentives control method for an untrusted AGI.</li>\n</ol></li>\n<li>Are there other capability control methods we could add to the list?</li>\n<li>Devise uses for a malicious but constrained AI.</li>\n<li>How much pressure is there likely to be to develop AI which is not controlled?</li>\n<li>If existing AI methods had unexpected progress and were heading for human-level soon, what precautions should we take now?</li>\n</ol>\n<p>&nbsp;</p>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1 id=\"How_to_proceed\">How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about 'motivation selection methods'. To prepare,&nbsp;<strong>read</strong>&nbsp;\u201cMotivation selection methods\u201d and \u201cSynopsis\u201d from Chapter 9<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 15th December. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "sections": [{"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Another view", "anchor": "Another_view", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "1. What do you do with a bad AI once it is under your control?", "anchor": "1__What_do_you_do_with_a_bad_AI_once_it_is_under_your_control_", "level": 2}, {"title": "2. Cryptographic boxing", "anchor": "2__Cryptographic_boxing", "level": 2}, {"title": "3. Philosophical Disquisitions", "anchor": "3__Philosophical_Disquisitions", "level": 2}, {"title": "4. Some relevant fiction", "anchor": "4__Some_relevant_fiction", "level": 2}, {"title": "5. Control through social integration", "anchor": "5__Control_through_social_integration", "level": 2}, {"title": "6. More miscellaneous writings on these topics", "anchor": "6__More_miscellaneous_writings_on_these_topics", "level": 2}, {"title": "How to proceed", "anchor": "How_to_proceed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "48 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QDmzDZ9CEHrKQdvcn", "B39GNTsN3HocW8KFo", "SpHYBhkaeDZpZyRvj", "2Wf3R4NZ77CLczLL2", "5wMcKNAwB6X4mp9og"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-09T07:50:07.188Z", "modifiedAt": null, "url": null, "title": "An investment analogy for Pascal's Mugging", "slug": "an-investment-analogy-for-pascal-s-mugging", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:37.291Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "LADT3SBgX6o98YmYH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qw9wgdPksDo4BCQKT/an-investment-analogy-for-pascal-s-mugging", "pageUrlRelative": "/posts/qw9wgdPksDo4BCQKT/an-investment-analogy-for-pascal-s-mugging", "linkUrl": "https://www.lesswrong.com/posts/qw9wgdPksDo4BCQKT/an-investment-analogy-for-pascal-s-mugging", "postedAtFormatted": "Tuesday, December 9th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20investment%20analogy%20for%20Pascal's%20Mugging&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20investment%20analogy%20for%20Pascal's%20Mugging%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqw9wgdPksDo4BCQKT%2Fan-investment-analogy-for-pascal-s-mugging%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20investment%20analogy%20for%20Pascal's%20Mugging%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqw9wgdPksDo4BCQKT%2Fan-investment-analogy-for-pascal-s-mugging", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqw9wgdPksDo4BCQKT%2Fan-investment-analogy-for-pascal-s-mugging", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 252, "htmlBody": "<p>A lottery ticket sometimes has positive expected value, (a $1 ticket might be expected to pay out $1.30). How many tickets should you buy?</p>\n<p>Probably none. Informally, all but the richest players can expect to go broke before they win, despite the positive expected value of a ticket.</p>\n<p>In more precise terms: In order to maximize the long-term growth rate of your money (or log money), you'll want to put a very small fraction of your bankroll into lotteries tickets, which will imply an \"amount to invest\" that is less than the cost of a single ticket, (excluding billionaires). If you put too great a proportion of your resources into a risky but positive expected value asset, the long-term growth rate of your resources can become negative. For an intuitive example, imagine Bill Gates dumping 99% percent of his wealth into a series of positive expected-value bets with single-lottery-ticket-like odds.</p>\n<p><a href=\"http://r6.ca/blog/20090522T015739Z.html\">This article</a> has some graphs and details on the lottery. <a href=\"http://www.math.ucla.edu/~tom/stat596/Kelly.pdf\">This pdf</a> on the <a href=\"http://en.wikipedia.org/wiki/Kelly_criterion\">Kelly criterion</a> has some examples and general dicussion of this type of problem.</p>\n<p>Can we think about Pascal mugging the same way?</p>\n<p>The applicability might depend on whether we're trading resource-generating-resources for non-resource-generating assets. So if we're offered something like cash, the lottery ticket model (with payout inversely varying with estimated odds) is a decent fit. But what if we're offered utility in some direct and non-interest-bearing form?</p>\n<p>Another limit: For a sufficiency unlikely but positive-expected-value gamble, you can expect the heat death of the universe before actually realizing any of the expected value.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E8PHMuf7tsr8teXAe": 1, "HNJiR8Jzafsv8cHrC": 1, "jgcAJnksReZRuvgzp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qw9wgdPksDo4BCQKT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 9, "extendedScore": null, "score": 2.2505457758744514e-06, "legacy": true, "legacyId": "27693", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-09T08:32:35.121Z", "modifiedAt": null, "url": null, "title": "Does utilitarianism \"require\" extreme self sacrifice? If not why do people commonly say it does?", "slug": "does-utilitarianism-require-extreme-self-sacrifice-if-not", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:39.415Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Princess_Stargirl", "createdAt": "2014-08-24T01:20:09.648Z", "isAdmin": false, "displayName": "Princess_Stargirl"}, "userId": "py3YJyMsLXejBXxyw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Y4Adk743X2ZoMBSBi/does-utilitarianism-require-extreme-self-sacrifice-if-not", "pageUrlRelative": "/posts/Y4Adk743X2ZoMBSBi/does-utilitarianism-require-extreme-self-sacrifice-if-not", "linkUrl": "https://www.lesswrong.com/posts/Y4Adk743X2ZoMBSBi/does-utilitarianism-require-extreme-self-sacrifice-if-not", "postedAtFormatted": "Tuesday, December 9th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Does%20utilitarianism%20%22require%22%20extreme%20self%20sacrifice%3F%20If%20not%20why%20do%20people%20commonly%20say%20it%20does%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADoes%20utilitarianism%20%22require%22%20extreme%20self%20sacrifice%3F%20If%20not%20why%20do%20people%20commonly%20say%20it%20does%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY4Adk743X2ZoMBSBi%2Fdoes-utilitarianism-require-extreme-self-sacrifice-if-not%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Does%20utilitarianism%20%22require%22%20extreme%20self%20sacrifice%3F%20If%20not%20why%20do%20people%20commonly%20say%20it%20does%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY4Adk743X2ZoMBSBi%2Fdoes-utilitarianism-require-extreme-self-sacrifice-if-not", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY4Adk743X2ZoMBSBi%2Fdoes-utilitarianism-require-extreme-self-sacrifice-if-not", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 449, "htmlBody": "<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong id=\"docs-internal-guid-e90d061a-2e5d-9984-65f4-50856a81d279\" style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Chist Hallquist wrote the following in an article (if you know the article please, please don't bring it up, I don't want to discuss the article in general):</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">\"For example, utilitarianism apparently endorses killing a single innocent person and harvesting their organs if it will save five other people. </span><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">It also appears to imply that donating all your money to charity beyond what you need to survive isn&rsquo;t just admirable but morally </span><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: bold; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">obligatory.</span><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: normal; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> \"</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #3f4549; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The non-bold part is not what is confusing me. But where does the \"obligatory\" part come in. I don't really how its obvious what, if any, ethical obligations utilitarianism implies. given a set of basic assumptions utilitarianism lets you argue whether one action is more moral than another. But I don&rsquo;t see how its obvious which, if any, moral benchmarks utilitarianism sets for &ldquo;obligatory.&rdquo; I can see how certain frameworks on top of utilitarianism imply certain moral requirements. But I do not see how the bolded quote is a criticism of the basic theory of utilitarianism.</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #3f4549; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">However this criticism comes up all the time. Honestly the best explanation I could come up with was that people were being unfair to utilitarianism and not thinking through their statements. But the above quote is by HallQ who is intelligent and thoughtful. So now I am genuinely very curious.</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Do you think utilitarianism really require such extreme self sacrifice and if so why? And if it does not require this why do so many people say it does? I am very confused and would appreciate help working this out.</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">edit:</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">I am having trouble asking this question clearly. Since utilitarianism is probably best thought of as a cluster of beliefs. So its not clear what asking \"does utilitarianism imply X\" actually means. Still I made this post since I am confused. Many thoughtful people identity as utilitarian (for example Ozy and theunitofcaring) yet do not think people have extreme obligations. However I can think of examples where people do not seem to understand the implications of their ethical frameowrks. For example many Jewish people endorse the message of the following story:</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><strong style=\"font-weight: normal;\"><br /><br /></strong></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Georgia; color: #000000; background-color: #ffffff; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Rabbi Hilel was asked to explain the Torah while standing on one foot and responded \"What is hateful to you, do not do to your neighbor. That is the whole Torah; the rest is the explanation of this--go and study it!\"</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><br /><span style=\"font-size: 15px; font-family: Georgia; vertical-align: baseline; white-space: pre-wrap;\">The story is presumably apocryphal but it is repeated all the time by Jewish people. However its hard to see how the story makes even a semblance of sense. The torah includes huge amounts of material that violates the \"golden Rule\" very badly. So people who think this story gives even a moderately accurate picture of the Torah's message are mistaken imo.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb187": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Y4Adk743X2ZoMBSBi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 12, "extendedScore": null, "score": 4.3e-05, "legacy": true, "legacyId": "27694", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 100, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-09T13:42:39.444Z", "modifiedAt": null, "url": null, "title": "Meetup : Israel Less Wrong Meetup - Social and Board Games", "slug": "meetup-israel-less-wrong-meetup-social-and-board-games-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Anatoly_Vorobey", "createdAt": "2009-03-22T09:13:04.364Z", "isAdmin": false, "displayName": "Anatoly_Vorobey"}, "userId": "gEQxcSsKD5bqjna3M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5TmGnpkKW9tY7dXAH/meetup-israel-less-wrong-meetup-social-and-board-games-0", "pageUrlRelative": "/posts/5TmGnpkKW9tY7dXAH/meetup-israel-less-wrong-meetup-social-and-board-games-0", "linkUrl": "https://www.lesswrong.com/posts/5TmGnpkKW9tY7dXAH/meetup-israel-less-wrong-meetup-social-and-board-games-0", "postedAtFormatted": "Tuesday, December 9th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Israel%20Less%20Wrong%20Meetup%20-%20Social%20and%20Board%20Games&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Israel%20Less%20Wrong%20Meetup%20-%20Social%20and%20Board%20Games%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5TmGnpkKW9tY7dXAH%2Fmeetup-israel-less-wrong-meetup-social-and-board-games-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Israel%20Less%20Wrong%20Meetup%20-%20Social%20and%20Board%20Games%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5TmGnpkKW9tY7dXAH%2Fmeetup-israel-less-wrong-meetup-social-and-board-games-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5TmGnpkKW9tY7dXAH%2Fmeetup-israel-less-wrong-meetup-social-and-board-games-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17v'>Israel Less Wrong Meetup - Social and Board Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 December 2014 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Google Tel Aviv</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're going to have a meetup on Tuesday, December 9th at Google Israel's offices, Electra Tower, 98 Yigal Alon st., Tel Aviv.</p>\n\n<p>IMPORTANT NOTE: The time above might say 6pm or 7pm or 8pm depending on how daylight savings time is processed. The meetup is at 7pm Israel Local Time.</p>\n\n<p>This time we're going to have a social meetup! We'll be socializing and playing games.</p>\n\n<p>Specifically, we look forward to playing any cool board or card game anyone will bring. By all means bring your favorite game(s) with you and teach others or find people who already like that game. But it's also fine to come empty-handed. We always end up with enough games for everyone.</p>\n\n<p>We'll start the meetup at 19:00, and we'll go on as much as we like to. Feel free to come a little bit later, as there is no agenda. (We've decided to start slightly earlier this time to give us more time and accommodate people with different schedules).</p>\n\n<p>We'll meet at the 29th floor of the building. If you arrive and cant find your way around, call Anatoly, who is graciously hosting us, at 054-245-1060. Email at avorobey@gmail.com also works. See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17v'>Israel Less Wrong Meetup - Social and Board Games</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5TmGnpkKW9tY7dXAH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.3e-05, "legacy": true, "legacyId": "27695", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Israel_Less_Wrong_Meetup___Social_and_Board_Games\">Discussion article for the meetup : <a href=\"/meetups/17v\">Israel Less Wrong Meetup - Social and Board Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 December 2014 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Google Tel Aviv</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're going to have a meetup on Tuesday, December 9th at Google Israel's offices, Electra Tower, 98 Yigal Alon st., Tel Aviv.</p>\n\n<p>IMPORTANT NOTE: The time above might say 6pm or 7pm or 8pm depending on how daylight savings time is processed. The meetup is at 7pm Israel Local Time.</p>\n\n<p>This time we're going to have a social meetup! We'll be socializing and playing games.</p>\n\n<p>Specifically, we look forward to playing any cool board or card game anyone will bring. By all means bring your favorite game(s) with you and teach others or find people who already like that game. But it's also fine to come empty-handed. We always end up with enough games for everyone.</p>\n\n<p>We'll start the meetup at 19:00, and we'll go on as much as we like to. Feel free to come a little bit later, as there is no agenda. (We've decided to start slightly earlier this time to give us more time and accommodate people with different schedules).</p>\n\n<p>We'll meet at the 29th floor of the building. If you arrive and cant find your way around, call Anatoly, who is graciously hosting us, at 054-245-1060. Email at avorobey@gmail.com also works. See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Israel_Less_Wrong_Meetup___Social_and_Board_Games1\">Discussion article for the meetup : <a href=\"/meetups/17v\">Israel Less Wrong Meetup - Social and Board Games</a></h2>", "sections": [{"title": "Discussion article for the meetup : Israel Less Wrong Meetup - Social and Board Games", "anchor": "Discussion_article_for_the_meetup___Israel_Less_Wrong_Meetup___Social_and_Board_Games", "level": 1}, {"title": "Discussion article for the meetup : Israel Less Wrong Meetup - Social and Board Games", "anchor": "Discussion_article_for_the_meetup___Israel_Less_Wrong_Meetup___Social_and_Board_Games1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-09T19:03:47.420Z", "modifiedAt": null, "url": null, "title": "Feedback requested by Intentional Insights on workbook conveying rational thinking about meaning and purpose to a broad audience", "slug": "feedback-requested-by-intentional-insights-on-workbook", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:36.347Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gleb_Tsipursky", "createdAt": "2013-07-16T16:34:19.205Z", "isAdmin": false, "displayName": "Gleb_Tsipursky"}, "userId": "F3y2sQb8SNx6Sim5q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LdXqsEJ6Gnnk9LFgZ/feedback-requested-by-intentional-insights-on-workbook", "pageUrlRelative": "/posts/LdXqsEJ6Gnnk9LFgZ/feedback-requested-by-intentional-insights-on-workbook", "linkUrl": "https://www.lesswrong.com/posts/LdXqsEJ6Gnnk9LFgZ/feedback-requested-by-intentional-insights-on-workbook", "postedAtFormatted": "Tuesday, December 9th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Feedback%20requested%20by%20Intentional%20Insights%20on%20workbook%20conveying%20rational%20thinking%20about%20meaning%20and%20purpose%20to%20a%20broad%20audience&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFeedback%20requested%20by%20Intentional%20Insights%20on%20workbook%20conveying%20rational%20thinking%20about%20meaning%20and%20purpose%20to%20a%20broad%20audience%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLdXqsEJ6Gnnk9LFgZ%2Ffeedback-requested-by-intentional-insights-on-workbook%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Feedback%20requested%20by%20Intentional%20Insights%20on%20workbook%20conveying%20rational%20thinking%20about%20meaning%20and%20purpose%20to%20a%20broad%20audience%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLdXqsEJ6Gnnk9LFgZ%2Ffeedback-requested-by-intentional-insights-on-workbook", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLdXqsEJ6Gnnk9LFgZ%2Ffeedback-requested-by-intentional-insights-on-workbook", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 266, "htmlBody": "<!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]-->\n<p><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,sans-serif; color: black;\">We at </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,sans-serif;\"><a href=\"http://intentionalinsights.org/\">Intentional Insights</a><span style=\"color: black;\"> would appreciate your help with feedback on optimize a workbook that conveys rational thinking to find meaning and purpose in life for a broad audience. Last time, we asked for your feedback, and we changed our content offerings based on comments we received from fellow Less Wrongers, as you can see from the <strong>Edit</strong> to </span><a href=\"/lw/l8z/intentionally_raising_the_sanity_waterline/\">this post</a><span style=\"color: black;\">. We would be glad to update our beliefs again and revise the workbook based on your feedback.</span></span></p>\n<p><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,sans-serif; color: black;\">For a bit of context, the workbook is part of </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,sans-serif;\"><a href=\"http://intentionalinsights.org/about\">our efforts to promote rational thinking to a broad audience</a><span style=\"color: black;\"> and thus </span><a href=\"/lw/1e/raising_the_sanity_waterline/\">raise the sanity waterline</a><span style=\"color: black;\">. It&rsquo;s based on research on how other societies besides the United States helped their citizens find meaning and purpose, such as research </span><a href=\"http://carlbeckpapers.pitt.edu/ojs/index.php/cbp/article/view/172\">I did</a><span style=\"color: black;\"> on the Soviet Union and </span><a href=\"http://books.google.com/books?id=mwmJ4FwuF2YC&amp;printsec=frontcover&amp;dq=inauthor:%22Phil+Zuckerman%22&amp;hl=en&amp;sa=X&amp;ei=cJprVMTxA_SNsQS-h4HwAw&amp;ved=0CCUQ6AEwAQ#v=onepage&amp;q&amp;f=false\">Zuckerman</a><span style=\"color: black;\"> did on Sweden and Denmark. It&rsquo;s also based on research on the contemporary United States by psychologists such as </span><a href=\"https://www.youtube.com/watch?v=RLFVoEF2RI0\">Steger</a><span style=\"color: black;\">, </span><a href=\"http://jca.sagepub.com/content/20/3.toc\">Duffy and Dik</a><span style=\"color: black;\">, </span><a href=\"http://books.google.com/books?hl=en&amp;lr=&amp;id=3L0BCCoFMRgC&amp;oi=fnd&amp;pg=PA1&amp;dq=seligman+authentic+happiness&amp;ots=_-vPd8jLi5&amp;sig=6gV7VFgHjSJUJJEbtgwl0nLMxHg#v=onepage&amp;q=seligman%20authentic%20happiness&amp;f=false\">Seligman</a><span style=\"color: black;\">, and </span><a href=\"http://archpsyc.jamanetwork.com/article.aspx?articleid=210648\">others</a><span style=\"color: black;\">.</span></span></p>\n<p><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,sans-serif; color: black;\">The target audience is reason-minded youth and young adults, especially secular-oriented ones. The goal is to get such people to engage with academic research on how our minds work, and thus get them interested in exploring rational thinking more broadly, eventually getting them turned on to more advanced rationality, such as found on Less Wrong itself. The workbook is written in a style aimed to create cognitive ease, with narratives, personal stories, graphics, and research-based exercises.</span></p>\n<p><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,sans-serif; color: black;\">Here is </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,sans-serif;\"><a href=\"https://drive.google.com/file/d/0B6NeF2qk4WyRUC1OSDA5bmJMMG8/view?usp=sharing\"><span style=\"color: #1155cc;\">the link to the workbook draft itself.</span></a><span style=\"color: black;\"> Any and all suggestions are welcomed, and thanks for taking the time to engage with this workbook and give your feedback &ndash; much appreciated!</span></span></p>\n<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"false\" DefSemiHidden=\"false\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"371\"> <w:LsdException Locked=\"false\" Priority=\"0\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 5\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 6\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 7\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 8\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Normal Indent\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"footnote text\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"annotation text\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"header\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"footer\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"index heading\" /> <w:LsdException Locked=\"false\" Priority=\"35\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"table of figures\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"envelope address\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"envelope return\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"footnote reference\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"annotation reference\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"line number\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"page number\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"endnote reference\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"endnote text\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"table of authorities\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"macro\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"toa heading\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Bullet\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Number\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List 5\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Bullet 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Bullet 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Bullet 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Bullet 5\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Number 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Number 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Number 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Number 5\" /> <w:LsdException Locked=\"false\" Priority=\"10\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Closing\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Signature\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text Indent\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Continue\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Continue 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Continue 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Continue 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"List Continue 5\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Message Header\" /> <w:LsdException Locked=\"false\" Priority=\"11\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Salutation\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Date\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text First Indent\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text First Indent 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Note Heading\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text Indent 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Body Text Indent 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Block Text\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Hyperlink\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"FollowedHyperlink\" /> <w:LsdException Locked=\"false\" Priority=\"22\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Document Map\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Plain Text\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"E-mail Signature\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Top of Form\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Bottom of Form\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Normal (Web)\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Acronym\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Address\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Cite\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Code\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Definition\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Keyboard\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Preformatted\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Sample\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Typewriter\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"HTML Variable\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Normal Table\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"annotation subject\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"No List\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Outline List 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Outline List 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Outline List 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Simple 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Simple 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Simple 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Classic 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Classic 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Classic 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Classic 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Colorful 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Colorful 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Colorful 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Columns 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Columns 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Columns 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Columns 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Columns 5\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 5\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 6\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 7\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Grid 8\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 4\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 5\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 6\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 7\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table List 8\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table 3D effects 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table 3D effects 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table 3D effects 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Contemporary\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Elegant\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Professional\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Subtle 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Subtle 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Web 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Web 2\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Web 3\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Balloon Text\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Table Theme\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" SemiHidden=\"true\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" SemiHidden=\"true\" UnhideWhenUsed=\"true\" QFormat=\"true\" Name=\"TOC Heading\" /> <w:LsdException Locked=\"false\" Priority=\"41\" Name=\"Plain Table 1\" /> <w:LsdException Locked=\"false\" Priority=\"42\" Name=\"Plain Table 2\" /> <w:LsdException Locked=\"false\" Priority=\"43\" Name=\"Plain Table 3\" /> <w:LsdException Locked=\"false\" Priority=\"44\" Name=\"Plain Table 4\" /> <w:LsdException Locked=\"false\" Priority=\"45\" Name=\"Plain Table 5\" /> <w:LsdException Locked=\"false\" Priority=\"40\" Name=\"Grid Table Light\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"Grid Table 1 Light\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"Grid Table 2\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"Grid Table 3\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"Grid Table 4\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"Grid Table 5 Dark\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"Grid Table 6 Colorful\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"Grid Table 7 Colorful\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"Grid Table 1 Light Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"Grid Table 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"Grid Table 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"Grid Table 4 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"Grid Table 5 Dark Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"Grid Table 6 Colorful Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"Grid Table 7 Colorful Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"Grid Table 1 Light Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"Grid Table 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"Grid Table 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"Grid Table 4 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"Grid Table 5 Dark Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"Grid Table 6 Colorful Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"Grid Table 7 Colorful Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"Grid Table 1 Light Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"Grid Table 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"Grid Table 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"Grid Table 4 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"Grid Table 5 Dark Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"Grid Table 6 Colorful Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"Grid Table 7 Colorful Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"Grid Table 1 Light Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"Grid Table 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"Grid Table 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"Grid Table 4 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"Grid Table 5 Dark Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"Grid Table 6 Colorful Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"Grid Table 7 Colorful Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"Grid Table 1 Light Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"Grid Table 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"Grid Table 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"Grid Table 4 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"Grid Table 5 Dark Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"Grid Table 6 Colorful Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"Grid Table 7 Colorful Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"Grid Table 1 Light Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"Grid Table 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"Grid Table 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"Grid Table 4 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"Grid Table 5 Dark Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"Grid Table 6 Colorful Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"Grid Table 7 Colorful Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"List Table 1 Light\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"List Table 2\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"List Table 3\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"List Table 4\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"List Table 5 Dark\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"List Table 6 Colorful\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"List Table 7 Colorful\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"List Table 1 Light Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"List Table 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"List Table 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"List Table 4 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"List Table 5 Dark Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"List Table 6 Colorful Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"List Table 7 Colorful Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"List Table 1 Light Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"List Table 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"List Table 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"List Table 4 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"List Table 5 Dark Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"List Table 6 Colorful Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"List Table 7 Colorful Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"List Table 1 Light Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"List Table 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"List Table 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"List Table 4 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"List Table 5 Dark Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"List Table 6 Colorful Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"List Table 7 Colorful Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"List Table 1 Light Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"List Table 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"List Table 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"List Table 4 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"List Table 5 Dark Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"List Table 6 Colorful Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"List Table 7 Colorful Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"List Table 1 Light Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"List Table 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"List Table 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"List Table 4 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"List Table 5 Dark Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"List Table 6 Colorful Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"List Table 7 Colorful Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"46\" Name=\"List Table 1 Light Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"47\" Name=\"List Table 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"48\" Name=\"List Table 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"49\" Name=\"List Table 4 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"50\" Name=\"List Table 5 Dark Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"51\" Name=\"List Table 6 Colorful Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"52\" Name=\"List Table 7 Colorful Accent 6\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]> <mce:style><!  /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin-top:0in; mso-para-margin-right:0in; mso-para-margin-bottom:8.0pt; mso-para-margin-left:0in; line-height:107%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",sans-serif; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin;} -->\n<p>&nbsp;</p>\n<!--[endif] -->", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LdXqsEJ6Gnnk9LFgZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "27696", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pEzzx54xeHLwjNAMv", "XqmjdBKa4ZaXJtNmf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-09T21:08:32.873Z", "modifiedAt": null, "url": null, "title": "The Limits of My Rationality", "slug": "the-limits-of-my-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:37.008Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JoshuaMyer", "createdAt": "2014-09-07T00:28:16.207Z", "isAdmin": false, "displayName": "JoshuaMyer"}, "userId": "Ewtw553F5iE9Qm6zr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bfqeTGGZzXyBfDBSs/the-limits-of-my-rationality", "pageUrlRelative": "/posts/bfqeTGGZzXyBfDBSs/the-limits-of-my-rationality", "linkUrl": "https://www.lesswrong.com/posts/bfqeTGGZzXyBfDBSs/the-limits-of-my-rationality", "postedAtFormatted": "Tuesday, December 9th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Limits%20of%20My%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Limits%20of%20My%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbfqeTGGZzXyBfDBSs%2Fthe-limits-of-my-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Limits%20of%20My%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbfqeTGGZzXyBfDBSs%2Fthe-limits-of-my-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbfqeTGGZzXyBfDBSs%2Fthe-limits-of-my-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1934, "htmlBody": "<p>As requested here is an introductory abstract.</p>\n<p>The search for bias in the linguistic representations of our cognitive processes serves several purposes in this community. By pruning irrational thoughts, we can potentially effect each other in complex ways. Leaning heavy on cognitivist pedagogy, this essay represents my subjective experience trying to reconcile a perceived conflict between the rhetorical goals of the community and the absence of a generative, organic conceptualization of rationality.</p>\n<p><br />The Story<br /><br />&nbsp;&nbsp;&nbsp; Though I've only been here a short time, I find myself fascinated by this discourse community. To discover a group of individuals bound together under the common goal of applied rationality has been an experience that has enriched my life significantly. So please understand, I do not mean to insult by what I am about to say, merely to encourage a somewhat more constructive approach to what I understand as the goal of this community: to apply collectively reinforced notions of rational thought to all areas of life.<br />&nbsp;&nbsp;&nbsp; <br />&nbsp;&nbsp;&nbsp; As I followed the links and read the articles on the homepage, I found myself somewhat disturbed by the juxtaposition of these highly specific definitions of biases to the narrative structures of parables providing examples in which a bias results in an incorrect conclusion. At first, I thought that perhaps my emotional reaction stemmed from rejecting the unfamiliar; naturally, I decided to learn more about the situation.<br /><br />&nbsp;&nbsp;&nbsp; As I read on, my interests drifted from the rhetorical structure of each article (if anyone is interested I might pursue an analysis of rhetoric further though I'm not sure I see a pressing need for this), towards the mystery of how others in the community apply the lessons contained therein. My belief was that the parables would cause most readers to form a negative association of the bias with an undesirable outcome.<br /><br />&nbsp;&nbsp;&nbsp; Even a quick skim of the discussions taking place on this site will reveal energetic debate on a variety of topics of potential importance, peppered heavily with accusations of bias. At this point, I noticed the comments that seem to get voted up are ones that are thoughtfully composed, well informed, soundly conceptualized and appropriately referential. Generally, this is true of the articles as well, and so it should be in productive discourse communities. Though I thought it prudent to not read every conversation in absolute detail, I also noticed that the most participated in lines of reasoning were far more rhetorically complex than the parables' portrayal of bias alone could explain. Sure the establishment of bias still seemed to represent the most commonly used rhetorical device on the forums ...<br /><br />&nbsp;&nbsp;&nbsp; At this point, I had been following a very interesting discussion on this site about politics. I typically have little or no interest in political theory, but \"NRx\" vs. \"Prog\" Assumptions: Locating the Sources of Disagreement Between Neoreactionaries and Progressives (Part 1) seemed so out of place in a community whose political affiliations might best be summarized the phrase \"politics is the mind killer\" that I couldn't help but investigate. More specifically, I was trying to figure out why it had been posted here at all (I didn't take issue with either the scholarship or intent of the article, but the latter wasn't obvious to me, perhaps because I was completely unfamiliar with the coinage \"neoreactionary\").<br /><br />&nbsp;&nbsp;&nbsp; On my third read, I made a connection to an essay about the socio-historical foundations of rhetoric. In structure, the essay progressed through a wide variety of specific observations on both theory and practice of rhetoric in classical Europe, culminating in a well argued but very unwieldy thesis; at some point in the middle of the essay, I recall a paragraph that begins with the assertion that every statement has political dimensions. I conveyed this idea as eloquently as I could muster, and received a fair bit of karma for it. And to think that it all began with a vague uncomfortable feeling and a desire to understand!<br /><br />The Lesson<br /><br />&nbsp;&nbsp;&nbsp; So you are probably wondering what any of this has to do with rationality, cognition, or the promise of some deeply insightful transformative advice mentioned in the first paragraph. Very good.<br /><br />&nbsp;&nbsp;&nbsp; Cognition, a prerequisite for rationality, is a complex process; cognition can be described as the process by which ideas form, interact and evolve. Notice that this definition alone cannot explain how concepts like rationality form, why ideas form or how they should interact to produce intelligence. That specific shortcoming has long crippled cognitivist pedagogies in many disciplines -- no matter which factors you believe to determine intelligence, it is undeniably true that the process by which it occurs organically is not well-understood.<br /><br />&nbsp;&nbsp;&nbsp; More intricate models of cognition traditionally vary according to the sets of behavior they seek to explain; in general, this forum seems to concern itself with the wider sets of human behavior, with a strange affinity for statistical analysis. It also seems as if most of the people here associate agency with intelligence, though this should be regarded as unsubstantiated anecdote; I have little interest in what people believe, but those beliefs can have interesting consequences. In general, good models of cognition that yield a sense of agency have to be able to explain how a mushy organic collection of cells might become capable of generating a sense of identity. For this reason, our discussion of cognition will treat intelligence as a confluence of passive processes that lead to an approximation of agency.<br /><br />&nbsp;&nbsp;&nbsp; Who are we? What is intelligence? To answer these or any natural language questions we first search for stored-solutions to whatever we perceive as the problem, even as we generate our conception of the question as a set of abstract problems from interactions between memories. In the absence of recognizing a pattern that triggers a stored solution, a new solution is generated by processes of association and abstraction. This process may be central to the generation of every rational and irrational thought a human will ever have. I would argue that the phenomenon of agency approximates an answer to the question: \"who am I?\" and that any discussion of consciousness should at least acknowledge how critical natural language use is to universal agreement on any matter. I will gladly discuss this matter further and in greater detail if asked.<br /><br />&nbsp;&nbsp;&nbsp; At this point, I feel compelled to mention that my initial motivation for pursuing this line of reasoning stems from the realization that this community discusses rationality in a way that differs somewhat from my past encounters with the word. <br /><br />&nbsp;&nbsp;&nbsp; Out there, it is commonly believed that rationality develops (in hindsight) to explain the subjective experience of cognition; here we assert a fundamental difference between rationality and this other concept called rationalization. I do not see the utility of this distinction, nor have I found a satisfying explanation of how this distinction operates within accepted models for human learning in such a way that does not assume an <em>a priori</em> method of sorting the values which determine what is considered \"rational\". Thus we find there is a general derth of generative models of rational cognition beside a plethora of techniques for spotting irrational or biased methods of thinking. <br /><br />&nbsp;&nbsp;&nbsp; I see a lot of discussion on the forums very concerned with objective predictions of the future wherein it seems as if rationality (often of a highly probabilistic nature) is, in many cases, expected to bridge the gap between the worlds we can imagine to be possible and our many somewhat subjective realities. And the force keeping these discussions from splintering off into unproductive pissing about is a constant search for bias.<br /><br />&nbsp;&nbsp;&nbsp; I know I'm not going to be the first among us to suggest that the search for bias is not truly synonymous with rationality, but I would like to clarify before concluding. Searching for bias in cognitive processes can be a very productive way to spend one's waking hours, and it is a critical element to structuring the subjective world of cognition in such a way that allows abstraction to yield the kind of useful rules that comprise rationality. But it is not, at its core, a generative process.<br /><br />&nbsp;&nbsp;&nbsp; Let us consider the cognitive process of association (when beliefs, memories, stimuli or concepts become connected to form more complex structures). Without that period of extremely associative and biased cognition experienced during early childhood, we might never learn to attribute the perceived cause of a burn to a hot stove. Without concepts like better and worse to shape our young minds, I imagine many of us would simply lack the attention span to learn about ethics. And what about all the biases that make parables an effective way of conveying information? After all, the strength of a rhetorical argument is in it's appeal to the interpretive biases of it's intended audience and not the relative consistency of the conceptual foundations of that argument. <br /><br />&nbsp;&nbsp;&nbsp; We need to shift discussions involving bias towards models of cognition more complex than portraying it as simply an obstacle to rationality. In my conception of reality, recognizing the existence of bias seems to play a critical role in the development of more complex methods of abstraction; indeed, biases are an intrinsic side effect of the generative grouping of observations that is the core of Bayesian reasoning. <br /><br />&nbsp;&nbsp;&nbsp; In short, biases are not generative processes. Discussions of bias are not necessarily useful, rational or intelligent. A deeper understanding of the nature of intelligence requires conceptualizations that embrace the organic truths at the core of sentience; we must be able to describe our concepts of intelligence, our \"rationality\", such that it can emerge organically as the generative processes at the core of cognition.<br /><br />&nbsp;&nbsp;&nbsp; The Idea<br /><br />&nbsp;&nbsp;&nbsp; I'd be interested to hear some thoughts about how we might grow to recognize our own biases as necessary to the formative stages of abstraction alongside learning to collectively search for and eliminate biases from our decision making processes. The human mind is limited and while most discussions in natural language never come close to pressing us to those limits, our limitations can still be relevant to those discussions as well as to discussions of artificial intelligences. The way I see things, a bias free machine possessing a model of our own cognition would either have to have stored solutions for every situation it could encounter or methods of generating stored solutions for all future perceived problems (both of which sound like descriptions of oracles to me, though the latter seems more viable from a programmer's perspective).<br /><br />&nbsp;&nbsp;&nbsp; A machine capable of making the kinds of decisions considered \"easy\" for humans, might need biases at some point during it's journey to the complex and self consistent methods of decision making associated with rationality. This is a rhetorically complex community, but at the risk of my reach exceeding my grasp, I would be interested in seeing an examination of the Affect Heuristic in human decision making as an allegory for the historic utility of fuzzy values in chess AI.</p>\n<p><br /><br />&nbsp;&nbsp;&nbsp; Thank you for your time, and I look forward to what I can only hope will be challenging and thoughtful responses.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bfqeTGGZzXyBfDBSs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 8, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "27697", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-10T00:21:09.486Z", "modifiedAt": null, "url": null, "title": "Lifehack Ideas December 2014", "slug": "lifehack-ideas-december-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:08.742Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tkJZvRJTqfMjk6obr/lifehack-ideas-december-2014", "pageUrlRelative": "/posts/tkJZvRJTqfMjk6obr/lifehack-ideas-december-2014", "linkUrl": "https://www.lesswrong.com/posts/tkJZvRJTqfMjk6obr/lifehack-ideas-december-2014", "postedAtFormatted": "Wednesday, December 10th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Lifehack%20Ideas%20December%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALifehack%20Ideas%20December%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtkJZvRJTqfMjk6obr%2Flifehack-ideas-december-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Lifehack%20Ideas%20December%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtkJZvRJTqfMjk6obr%2Flifehack-ideas-december-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtkJZvRJTqfMjk6obr%2Flifehack-ideas-december-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 100, "htmlBody": "<blockquote><strong>Life hacking</strong> refers to any trick, shortcut, skill, or novelty method that increases productivity and efficiency, in all walks of life.</blockquote>\n<p>&mdash; <a href=\"http://en.wikipedia.org/wiki/Life_hacking\" target=\"_blank\">Wikipedia</a></p>\n<p>&nbsp;</p>\n<p>This thread is for posting any promising or interesting ideas for lifehacks you've come up with or heard of.&nbsp; If you've implemented your idea, please share the results.&nbsp; You are also encouraged to post lifehack ideas you've tried out that have not been successful, and why you think they weren't.&nbsp; If you can, please give credit for ideas that you got from other people.</p>\n<p>To any future posters of Lifehack Ideas threads, please remember to add the \"lifehacks_thread\" tag.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tkJZvRJTqfMjk6obr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 11, "extendedScore": null, "score": 2.252734292135049e-06, "legacy": true, "legacyId": "27698", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-11T02:56:58.697Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta December Meetup - Game Night!", "slug": "meetup-atlanta-december-meetup-game-night", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Adele_L", "createdAt": "2012-05-25T06:52:13.187Z", "isAdmin": false, "displayName": "Adele_L"}, "userId": "5cAXqfacg2fkQPK8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gdCZgCT4qnLr9qien/meetup-atlanta-december-meetup-game-night", "pageUrlRelative": "/posts/gdCZgCT4qnLr9qien/meetup-atlanta-december-meetup-game-night", "linkUrl": "https://www.lesswrong.com/posts/gdCZgCT4qnLr9qien/meetup-atlanta-december-meetup-game-night", "postedAtFormatted": "Thursday, December 11th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta%20December%20Meetup%20-%20Game%20Night!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%20December%20Meetup%20-%20Game%20Night!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgdCZgCT4qnLr9qien%2Fmeetup-atlanta-december-meetup-game-night%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%20December%20Meetup%20-%20Game%20Night!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgdCZgCT4qnLr9qien%2Fmeetup-atlanta-december-meetup-game-night", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgdCZgCT4qnLr9qien%2Fmeetup-atlanta-december-meetup-game-night", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17w'>Atlanta December Meetup - Game Night!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">27 December 2014 07:00:00AM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2388 Lawrenceville Highway Unit L, Norgate Manor, Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Come join us for a get together! We'll be playing games and having a low key social gathering. Feel free to bring your favorite games and any snacks you would like.</p>\n\n<p>Please park in a spot marked visitor. Parking in a numbered spot can get you towed. There are cats at the location.</p>\n\n<p>Hope to see you!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17w'>Atlanta December Meetup - Game Night!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gdCZgCT4qnLr9qien", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.2562662754155053e-06, "legacy": true, "legacyId": "27703", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta_December_Meetup___Game_Night_\">Discussion article for the meetup : <a href=\"/meetups/17w\">Atlanta December Meetup - Game Night!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">27 December 2014 07:00:00AM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2388 Lawrenceville Highway Unit L, Norgate Manor, Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Come join us for a get together! We'll be playing games and having a low key social gathering. Feel free to bring your favorite games and any snacks you would like.</p>\n\n<p>Please park in a spot marked visitor. Parking in a numbered spot can get you towed. There are cats at the location.</p>\n\n<p>Hope to see you!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Atlanta_December_Meetup___Game_Night_1\">Discussion article for the meetup : <a href=\"/meetups/17w\">Atlanta December Meetup - Game Night!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta December Meetup - Game Night!", "anchor": "Discussion_article_for_the_meetup___Atlanta_December_Meetup___Game_Night_", "level": 1}, {"title": "Discussion article for the meetup : Atlanta December Meetup - Game Night!", "anchor": "Discussion_article_for_the_meetup___Atlanta_December_Meetup___Game_Night_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-11T03:19:58.802Z", "modifiedAt": null, "url": null, "title": "Cognitive distortions of founders", "slug": "cognitive-distortions-of-founders", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:35.665Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7pinTCFK3ozAxZ7rF/cognitive-distortions-of-founders", "pageUrlRelative": "/posts/7pinTCFK3ozAxZ7rF/cognitive-distortions-of-founders", "linkUrl": "https://www.lesswrong.com/posts/7pinTCFK3ozAxZ7rF/cognitive-distortions-of-founders", "postedAtFormatted": "Thursday, December 11th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cognitive%20distortions%20of%20founders&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACognitive%20distortions%20of%20founders%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7pinTCFK3ozAxZ7rF%2Fcognitive-distortions-of-founders%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cognitive%20distortions%20of%20founders%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7pinTCFK3ozAxZ7rF%2Fcognitive-distortions-of-founders", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7pinTCFK3ozAxZ7rF%2Fcognitive-distortions-of-founders", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 14, "htmlBody": "<p>Interesting take on entrepreneurial success:</p>\n<p>http://www.harrisonmetal.com/cognitive-distortions-of-founders/</p>\n<p>More in depth here:</p>\n<p>http://quarry.stanford.edu/xapm1111126lse/docs/02_LSE_Cognitive.pdf</p>\n<p>Curious what people here think of this.&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7pinTCFK3ozAxZ7rF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 6, "extendedScore": null, "score": 2.2563172560071903e-06, "legacy": true, "legacyId": "27701", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-11T08:51:46.364Z", "modifiedAt": null, "url": null, "title": "[link] Etzioni: AI will empower us, not exterminate us", "slug": "link-etzioni-ai-will-empower-us-not-exterminate-us", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:36.133Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CBHacking", "createdAt": "2014-10-27T09:13:00.539Z", "isAdmin": false, "displayName": "CBHacking"}, "userId": "J8xq2mnrZFAQA5aDF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wxDdG8xtoXxf79q8v/link-etzioni-ai-will-empower-us-not-exterminate-us", "pageUrlRelative": "/posts/wxDdG8xtoXxf79q8v/link-etzioni-ai-will-empower-us-not-exterminate-us", "linkUrl": "https://www.lesswrong.com/posts/wxDdG8xtoXxf79q8v/link-etzioni-ai-will-empower-us-not-exterminate-us", "postedAtFormatted": "Thursday, December 11th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Etzioni%3A%20AI%20will%20empower%20us%2C%20not%20exterminate%20us&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Etzioni%3A%20AI%20will%20empower%20us%2C%20not%20exterminate%20us%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwxDdG8xtoXxf79q8v%2Flink-etzioni-ai-will-empower-us-not-exterminate-us%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Etzioni%3A%20AI%20will%20empower%20us%2C%20not%20exterminate%20us%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwxDdG8xtoXxf79q8v%2Flink-etzioni-ai-will-empower-us-not-exterminate-us", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwxDdG8xtoXxf79q8v%2Flink-etzioni-ai-will-empower-us-not-exterminate-us", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p><a href=\"https://medium.com/backchannel/ai-wont-exterminate-us-it-will-empower-us-5b7224735bf3\">https://medium.com/backchannel/ai-wont-exterminate-us-it-will-empower-us-5b7224735bf3</a></p>\r\n<p>(Slashdot discussion: <a href=\"http://tech.slashdot.org/story/14/12/10/1719232/ai-expert-ai-wont-exterminate-us----it-will-empower-us\">http://tech.slashdot.org/story/14/12/10/1719232/ai-expert-ai-wont-exterminate-us----it-will-empower-us</a>)</p>\r\n<p>Not sure what the local view of Oren Etzioni or the Allen Institute for AI is, but I'm curious what people think if his views on UFAI risk. As far as I can tell from this article, it basically boils down to \"AGI won't happen, at least not any time soon.\" Is there (significant) reason to believe he's wrong, or is it simply too great a risk to leave to chance?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wxDdG8xtoXxf79q8v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 2.2570528630924877e-06, "legacy": true, "legacyId": "27706", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-11T11:55:01.025Z", "modifiedAt": null, "url": null, "title": "Estimating the cost-effectiveness of research", "slug": "estimating-the-cost-effectiveness-of-research", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:39.836Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "owencb", "createdAt": "2013-05-12T09:01:14.360Z", "isAdmin": false, "displayName": "owencb"}, "userId": "QDNJ93vrjoaRBesk2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R8ywQZsare2ANHLhQ/estimating-the-cost-effectiveness-of-research", "pageUrlRelative": "/posts/R8ywQZsare2ANHLhQ/estimating-the-cost-effectiveness-of-research", "linkUrl": "https://www.lesswrong.com/posts/R8ywQZsare2ANHLhQ/estimating-the-cost-effectiveness-of-research", "postedAtFormatted": "Thursday, December 11th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Estimating%20the%20cost-effectiveness%20of%20research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEstimating%20the%20cost-effectiveness%20of%20research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8ywQZsare2ANHLhQ%2Festimating-the-cost-effectiveness-of-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Estimating%20the%20cost-effectiveness%20of%20research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8ywQZsare2ANHLhQ%2Festimating-the-cost-effectiveness-of-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR8ywQZsare2ANHLhQ%2Festimating-the-cost-effectiveness-of-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 668, "htmlBody": "<p>At a societal level, how much money should we put into medical research, or into fusion research? For individual donors seeking out the best opportunities, how can we compare the expected cost-effectiveness of research projects with more direct interventions?</p>\n<p>Over the past few months I've been researching this area for the <a href=\"http://www.fhi.ox.ac.uk/research/global-priorities-project/\">Global Priorities Project</a>. We've written a variety of articles which focus on different parts of the question. Estimating the cost-effectiveness of research is the central example here, but a lot of the methodology is also applicable to other one-off projects with unknown difficulty (perhaps including political lobbying). I don't think it's all solved, but I do think we've made substantial progress.</p>\n<p>I think people here might be interested, so I wanted to share our work. To help you navigate and find the most appropriate pieces, here I collect them, summarise what's contained in each, and explain how they fit together.</p>\n<ul>\n<li>I gave an overview of my thinking at the Good Done Right conference, held in Oxford in July 2014. The&nbsp;<a href=\"http://www.gooddoneright.com/#!owen-cotton-barratt/c6xs\">slides and audio</a> of my talk are available; I have developed more sophisticated models for some parts of the area since then.</li>\n<li><a title=\"How to treat problems of unknown difficulty\" href=\"/lw/kn4/how_to_treat_problems_of_unknown_difficulty/\">How to treat problems of unknown difficulty</a>&nbsp;introduces the problem: we need to make decisions about when to work more on problems such as research into fusion where we&nbsp;don't know how difficult it will be. It builds some models which allow principled reasoning about how we should act. These models are quite crude but easy to work with: they are intended to lower the bar for Fermi estimates and similar, and provide a starting point for building more sophisticated models.</li>\n<li><a title=\"Estimating cost-effectiveness for problems of unknown difficulty\" href=\"http://www.fhi.ox.ac.uk/estimating-cost-effectiveness/\">Estimating cost-effectiveness for problems of unknown difficulty</a>&nbsp;picks up from the models in the above post, and asks what they mean for the expected cost-effectiveness of work on the problems. This involves building a model of the counterfactual impact, as solvable research problems are likely to be solved eventually, so the main effect is to move the solution forwards. This post includes several explicit formulae that you can use to produce estimates; it also explains analogies between the explicit model we derive and the qualitative 'three factor' model that GiveWell and 80,000 Hours have used for cause selection.</li>\n<li><a title=\"Estimating the cost-effectiveness of research into neglected diseases\" href=\"http://www.fhi.ox.ac.uk/research-into-neglected-diseases/\">Estimating the cost-effectiveness of research into neglected diseases</a>&nbsp;is an investigation by Max Dalton, which uses the techniques for estimating cost-effectiveness to provide ballpark figures for how valuable we should expect research into vaccines or treatments for neglected diseases to be. The estimates suggest that, if carefully targeted, such research could be more cost-effective than the best direct health interventions currently available for funding.</li>\n<li><a title=\"The law of logarithmic returns\" href=\"http://www.fhi.ox.ac.uk/law-of-logarithmic-returns/\">The law of logarithmic returns</a>&nbsp;discusses the question of returns to resources into a field rather than on a single question. With some examples, it suggests that as a first approximation it is often reasonable to assume that diminishing marginal returns take a logarithmic form.</li>\n<li><a href=\"http://www.fhi.ox.ac.uk/theory-of-log-returns/\">Theory behind logarithmic returns</a>&nbsp;explains how some simple generating mechanisms can produce roughly logarithmic returns. This is a complement to the above article: we think having both empirical and theoretical justification for the rule helps us to have higher confidence in it, and to better understand when it's appropriate to generalise to new contexts. In this piece I also&nbsp;highlight&nbsp;areas for further research on the theoretical side, into when the approximation will break down, and what we might want to use instead in these cases.</li>\n<li><a title=\"How valuable is medical research?\" href=\"http://www.fhi.ox.ac.uk/value-of-medical-research/\">How valuable is medical research?</a>&nbsp;written with Giving What We Can, applies the logarithmic returns model together with counterfactual reasoning to produce an estimate for the cost-effectiveness of medical research as a whole.</li>\n</ul>\n<div><br /></div>\n<div>I've also made <a href=\"/r/discussion/lw/ldo/make_your_own_costeffectiveness_fermi_estimates/\">a thread in LessWrong Discussion</a> for people to discuss applications of one of the simpler versions of the cost-effectiveness models, to get Fermi estimates for the value of different areas.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AeqCtS3BaY3cwzKAs": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R8ywQZsare2ANHLhQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 31, "extendedScore": null, "score": 8.2e-05, "legacy": true, "legacyId": "27707", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Q6uFdBCQoW9XiAoZ2", "e4SSCCcm7Gpqjru4f"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-11T12:00:07.145Z", "modifiedAt": null, "url": null, "title": "Make your own cost-effectiveness Fermi estimates for one-off problems", "slug": "make-your-own-cost-effectiveness-fermi-estimates-for-one-off", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:05.951Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "owencb", "createdAt": "2013-05-12T09:01:14.360Z", "isAdmin": false, "displayName": "owencb"}, "userId": "QDNJ93vrjoaRBesk2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/e4SSCCcm7Gpqjru4f/make-your-own-cost-effectiveness-fermi-estimates-for-one-off", "pageUrlRelative": "/posts/e4SSCCcm7Gpqjru4f/make-your-own-cost-effectiveness-fermi-estimates-for-one-off", "linkUrl": "https://www.lesswrong.com/posts/e4SSCCcm7Gpqjru4f/make-your-own-cost-effectiveness-fermi-estimates-for-one-off", "postedAtFormatted": "Thursday, December 11th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Make%20your%20own%20cost-effectiveness%20Fermi%20estimates%20for%20one-off%20problems&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMake%20your%20own%20cost-effectiveness%20Fermi%20estimates%20for%20one-off%20problems%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe4SSCCcm7Gpqjru4f%2Fmake-your-own-cost-effectiveness-fermi-estimates-for-one-off%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Make%20your%20own%20cost-effectiveness%20Fermi%20estimates%20for%20one-off%20problems%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe4SSCCcm7Gpqjru4f%2Fmake-your-own-cost-effectiveness-fermi-estimates-for-one-off", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fe4SSCCcm7Gpqjru4f%2Fmake-your-own-cost-effectiveness-fermi-estimates-for-one-off", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 900, "htmlBody": "<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">In some </span><a style=\"color: #326492; text-decoration: none;\" href=\"/lw/ldn/estimating_the_costeffectiveness_of_research/\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline; background-color: transparent;\">recent work</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> (particularly </span><a style=\"color: #326492; text-decoration: none;\" href=\"http://www.fhi.ox.ac.uk/estimating-cost-effectiveness/\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline; background-color: transparent;\">this article</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">) I built models for estimating the cost effectiveness of work on problems when we don&rsquo;t know how hard those problems are. The estimates they produce aren&rsquo;t perfect, but they can get us started where it&rsquo;s otherwise hard to make comparisons.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Now I want to know: what can we use this technique on? I have a couple of applications I am working on, but I&rsquo;m keen to see what estimates other people produce.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">There are complicated versions of the model which account for more factors, but we can start with a simple version. This is a tool for initial Fermi calculations: it&rsquo;s relatively easy to use but should get us around the right order of magnitude. That can be very useful, and we can build more detailed models for the most promising opportunities.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">The model is given by:</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><img src=\"http://www.fhi.ox.ac.uk/wp-content/uploads/equation8.jpg\" alt=\"\" width=\"582\" height=\"99\" /></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">This expresses the expected benefit of adding another unit of resources to solving the problem. You can denominate the resources in dollars, researcher-years, or another convenient unit. To use this formula we need to estimate four variables:</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0)</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> denotes the current resources going towards the problem each year. Whatever units you measure </span><span style=\"font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0) in, those are the units we&rsquo;ll get an estimate for the benefit of. So if </span><span style=\"font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0) is measured in researcher-years, the formula will tell us the expected benefit of adding a researcher year.</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px;\">\n<li style=\"list-style-type: circle; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">You want to count all of the resources going towards the problem. That includes the labour of those who work on it in their spare time, and some weighting for the talent of the people working in the area (if you doubled the budget going to an area, you couldn&rsquo;t get twice as many people who are just as good; ideally we&rsquo;d use an elasticity here).</span></p>\n</li>\n<li style=\"list-style-type: circle; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Some resources may be aimed at something other than your problem, but be tangentially useful. We should count some fraction of those, according to how much resources devoted entirely to the problem they seem equivalent to.</span></p>\n</li>\n</ul>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B</span><span style=\"font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> is the annual benefit that we&rsquo;d get from a solution to the problem. You can measure this in its own units, but whatever you use here will be the units of value that come out in the cost-effectiveness estimate.</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> </span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">and </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> are parameters that we will estimate together. </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"font-weight: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> </span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">is the probability of getting a solution by the time </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y</span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> resources have been dedicated to the problem, if </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">z</span><span style=\"font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> </span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">resources have been dedicated so far. Note that we only need the ratio </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, so we can estimate this directly.</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px;\">\n<li style=\"list-style-type: circle; font-weight: normal; font-style: normal; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Although </span><span style=\"font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> is hard to estimate, we will take a (natural) logarithm of it, so don&rsquo;t worry too much about making this term precise.</span></p>\n</li>\n<li style=\"list-style-type: circle; font-weight: normal; font-style: normal; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">I think it will often be best to use middling values of </span><span style=\"font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, perhaps between 0.2 and 0.8.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">And that&rsquo;s it. </span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Example:</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> How valuable is extra research into nuclear fusion? Assume:</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R(0) = $5 billion</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> (after a quick google turns up $1.5B for current spending, and adjusting upwards to account for non-financial inputs);</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B = $1000 billion</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> (guesswork, a bit over 1% of the world economy; a fraction of the current energy sector);</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">There&rsquo;s a 50% chance of success (</span><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p = 0.5</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">) by the time we&rsquo;ve spent 100 times as many resources as today (</span><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">log(y/z) = log(100) = 4.6</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">). </span></p>\n</li>\n</ul>\n<div style=\"margin: 0px; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\"><span style=\"font-family: Arial;\"><span style=\"font-size: 15px; line-height: 17.25px; white-space: pre-wrap;\"><br /></span></span></div>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Putting these together would give an expected societal benefit of (0.5*$1000B)/(5B*4.6) = </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">$22 for every dollar spent</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">. This is high enough to suggest that we may be significantly under-investing in fusion, and that a more careful calculation (with better-researched numbers!) might be justified.</span></p>\n<h2 style=\"margin-top: 10pt; margin-bottom: 0pt; margin-left: 0px; color: #326492; cursor: auto; font-family: montserratt, Arial, sans-serif; height: auto; line-height: 1.15; list-style: none outside none; width: auto; padding-left: 0px; margin-right: 0px !important;\" dir=\"ltr\"><span style=\"font-size: 17px; font-family: 'Trebuchet MS'; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Caveats</span></h2>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">To get the simple formula, the model made a number of assumptions. Since we&rsquo;re just using it to get rough numbers, it&rsquo;s okay if we don&rsquo;t fit these assumptions exactly, but if they&rsquo;re totally off then the model may be inappropriate. One restriction in particular I&rsquo;d want to bear in mind:</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">It should be plausible that we could solve the problem in the next decade or two.</span></p>\n</li>\n</ul>\n<div style=\"margin: 0px; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\"><span style=\"font-family: Arial;\"><span style=\"font-size: 15px; line-height: 17.25px; white-space: pre-wrap;\"><br /></span></span></div>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">It&rsquo;s okay if this is unlikely, but I&rsquo;d want to change the model if I were estimating the value of e.g. trying to colonise the stars.</span></p>\n<h2 style=\"margin-top: 10pt; margin-bottom: 0pt; margin-left: 0px; color: #326492; cursor: auto; font-family: montserratt, Arial, sans-serif; height: auto; line-height: 1.15; list-style: none outside none; width: auto; padding-left: 0px; margin-right: 0px !important;\" dir=\"ltr\"><span style=\"font-size: 17px; font-family: 'Trebuchet MS'; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Request for applications</span></h2>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">So -- what would you like to apply this method to? What answers do you get?</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">To help structure the comment thread, I suggest attempting only one problem in each &nbsp;comment. Include the </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">value of </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, and the </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">units of </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0)</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> and </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">units of </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> that you&rsquo;d like to use. Then you can give your estimates for </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0), </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, and </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> as a comment reply, and so can anyone else who wants to give estimates for the same thing.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">I&rsquo;ve also set up a </span><a style=\"color: #326492; text-decoration: none;\" href=\"https://docs.google.com/spreadsheets/d/1pxtY9qbP0qrCEMLlZGxYa6xkqCbkXXB1ciGl-ucf2rY/edit#gid=0\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline; background-color: transparent;\">google spreadsheet</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> where we can enter estimates for the questions people propose. For the time being anyone can edit this.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Have fun!</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AeqCtS3BaY3cwzKAs": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "e4SSCCcm7Gpqjru4f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 2.2574706285743194e-06, "legacy": true, "legacyId": "27708", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">In some </span><a style=\"color: #326492; text-decoration: none;\" href=\"/lw/ldn/estimating_the_costeffectiveness_of_research/\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline; background-color: transparent;\">recent work</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> (particularly </span><a style=\"color: #326492; text-decoration: none;\" href=\"http://www.fhi.ox.ac.uk/estimating-cost-effectiveness/\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline; background-color: transparent;\">this article</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">) I built models for estimating the cost effectiveness of work on problems when we don\u2019t know how hard those problems are. The estimates they produce aren\u2019t perfect, but they can get us started where it\u2019s otherwise hard to make comparisons.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Now I want to know: what can we use this technique on? I have a couple of applications I am working on, but I\u2019m keen to see what estimates other people produce.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">There are complicated versions of the model which account for more factors, but we can start with a simple version. This is a tool for initial Fermi calculations: it\u2019s relatively easy to use but should get us around the right order of magnitude. That can be very useful, and we can build more detailed models for the most promising opportunities.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">The model is given by:</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><img src=\"http://www.fhi.ox.ac.uk/wp-content/uploads/equation8.jpg\" alt=\"\" width=\"582\" height=\"99\"></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">This expresses the expected benefit of adding another unit of resources to solving the problem. You can denominate the resources in dollars, researcher-years, or another convenient unit. To use this formula we need to estimate four variables:</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0)</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> denotes the current resources going towards the problem each year. Whatever units you measure </span><span style=\"font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0) in, those are the units we\u2019ll get an estimate for the benefit of. So if </span><span style=\"font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0) is measured in researcher-years, the formula will tell us the expected benefit of adding a researcher year.</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px;\">\n<li style=\"list-style-type: circle; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">You want to count all of the resources going towards the problem. That includes the labour of those who work on it in their spare time, and some weighting for the talent of the people working in the area (if you doubled the budget going to an area, you couldn\u2019t get twice as many people who are just as good; ideally we\u2019d use an elasticity here).</span></p>\n</li>\n<li style=\"list-style-type: circle; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Some resources may be aimed at something other than your problem, but be tangentially useful. We should count some fraction of those, according to how much resources devoted entirely to the problem they seem equivalent to.</span></p>\n</li>\n</ul>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B</span><span style=\"font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> is the annual benefit that we\u2019d get from a solution to the problem. You can measure this in its own units, but whatever you use here will be the units of value that come out in the cost-effectiveness estimate.</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> </span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">and </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> are parameters that we will estimate together. </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"font-weight: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> </span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">is the probability of getting a solution by the time </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y</span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> resources have been dedicated to the problem, if </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">z</span><span style=\"font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> </span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">resources have been dedicated so far. Note that we only need the ratio </span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"font-weight: normal; font-style: normal; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, so we can estimate this directly.</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px;\">\n<li style=\"list-style-type: circle; font-weight: normal; font-style: normal; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Although </span><span style=\"font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> is hard to estimate, we will take a (natural) logarithm of it, so don\u2019t worry too much about making this term precise.</span></p>\n</li>\n<li style=\"list-style-type: circle; font-weight: normal; font-style: normal; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">I think it will often be best to use middling values of </span><span style=\"font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, perhaps between 0.2 and 0.8.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">And that\u2019s it. </span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Example:</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> How valuable is extra research into nuclear fusion? Assume:</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R(0) = $5 billion</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> (after a quick google turns up $1.5B for current spending, and adjusting upwards to account for non-financial inputs);</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B = $1000 billion</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> (guesswork, a bit over 1% of the world economy; a fraction of the current energy sector);</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">There\u2019s a 50% chance of success (</span><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p = 0.5</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">) by the time we\u2019ve spent 100 times as many resources as today (</span><span style=\"font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">log(y/z) = log(100) = 4.6</span><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">). </span></p>\n</li>\n</ul>\n<div style=\"margin: 0px; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\"><span style=\"font-family: Arial;\"><span style=\"font-size: 15px; line-height: 17.25px; white-space: pre-wrap;\"><br></span></span></div>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Putting these together would give an expected societal benefit of (0.5*$1000B)/(5B*4.6) = </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">$22 for every dollar spent</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">. This is high enough to suggest that we may be significantly under-investing in fusion, and that a more careful calculation (with better-researched numbers!) might be justified.</span></p>\n<h2 style=\"margin-top: 10pt; margin-bottom: 0pt; margin-left: 0px; color: #326492; cursor: auto; font-family: montserratt, Arial, sans-serif; height: auto; line-height: 1.15; list-style: none outside none; width: auto; padding-left: 0px; margin-right: 0px !important;\" dir=\"ltr\" id=\"Caveats\"><span style=\"font-size: 17px; font-family: 'Trebuchet MS'; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Caveats</span></h2>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">To get the simple formula, the model made a number of assumptions. Since we\u2019re just using it to get rough numbers, it\u2019s okay if we don\u2019t fit these assumptions exactly, but if they\u2019re totally off then the model may be inappropriate. One restriction in particular I\u2019d want to bear in mind:</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; background-color: transparent;\" dir=\"ltr\">\n<p style=\"margin: 0pt 0px; line-height: 1.15;\" dir=\"ltr\"><span style=\"vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">It should be plausible that we could solve the problem in the next decade or two.</span></p>\n</li>\n</ul>\n<div style=\"margin: 0px; padding: 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; line-height: 19.6000003814697px; text-align: justify;\"><span style=\"font-family: Arial;\"><span style=\"font-size: 15px; line-height: 17.25px; white-space: pre-wrap;\"><br></span></span></div>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">It\u2019s okay if this is unlikely, but I\u2019d want to change the model if I were estimating the value of e.g. trying to colonise the stars.</span></p>\n<h2 style=\"margin-top: 10pt; margin-bottom: 0pt; margin-left: 0px; color: #326492; cursor: auto; font-family: montserratt, Arial, sans-serif; height: auto; line-height: 1.15; list-style: none outside none; width: auto; padding-left: 0px; margin-right: 0px !important;\" dir=\"ltr\" id=\"Request_for_applications\"><span style=\"font-size: 17px; font-family: 'Trebuchet MS'; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Request for applications</span></h2>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">So -- what would you like to apply this method to? What answers do you get?</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">To help structure the comment thread, I suggest attempting only one problem in each &nbsp;comment. Include the </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">value of </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">p</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, and the </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">units of </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0)</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> and </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">units of </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-weight: bold; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> that you\u2019d like to use. Then you can give your estimates for </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">R</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">(0), </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">B</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">, and </span><span style=\"font-size: 15px; font-family: Arial; color: #000000; font-style: italic; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">y/z</span><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> as a comment reply, and so can anyone else who wants to give estimates for the same thing.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">I\u2019ve also set up a </span><a style=\"color: #326492; text-decoration: none;\" href=\"https://docs.google.com/spreadsheets/d/1pxtY9qbP0qrCEMLlZGxYa6xkqCbkXXB1ciGl-ucf2rY/edit#gid=0\"><span style=\"font-size: 15px; font-family: Arial; color: #1155cc; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline; background-color: transparent;\">google spreadsheet</span></a><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"> where we can enter estimates for the questions people propose. For the time being anyone can edit this.</span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br></span></p>\n<p style=\"margin: 0pt 0px; color: #222222; font-family: Arial, sans-serif; font-size: 14px; text-align: justify; line-height: 1.15;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">Have fun!</span></p>", "sections": [{"title": "Caveats", "anchor": "Caveats", "level": 1}, {"title": "Request for applications", "anchor": "Request_for_applications", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "15 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["R8ywQZsare2ANHLhQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-11T12:48:52.891Z", "modifiedAt": null, "url": null, "title": "Meetup : Saint-Petersburg Meetup ", "slug": "meetup-saint-petersburg-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "LizzardWizzard", "createdAt": "2014-05-30T09:49:42.165Z", "isAdmin": false, "displayName": "LizzardWizzard"}, "userId": "kr2NGJSTWFuNqj3cZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Wtod4uiMXhQ5LwD6g/meetup-saint-petersburg-meetup", "pageUrlRelative": "/posts/Wtod4uiMXhQ5LwD6g/meetup-saint-petersburg-meetup", "linkUrl": "https://www.lesswrong.com/posts/Wtod4uiMXhQ5LwD6g/meetup-saint-petersburg-meetup", "postedAtFormatted": "Thursday, December 11th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Saint-Petersburg%20Meetup%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Saint-Petersburg%20Meetup%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWtod4uiMXhQ5LwD6g%2Fmeetup-saint-petersburg-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Saint-Petersburg%20Meetup%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWtod4uiMXhQ5LwD6g%2Fmeetup-saint-petersburg-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWtod4uiMXhQ5LwD6g%2Fmeetup-saint-petersburg-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 79, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17x'>Saint-Petersburg Meetup </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 December 2014 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Saint-Petersburg, Liteyniy Prospekt 57</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Experimental Meetup at the new location! All aspiring rationalists are welcome to participate. Discussions on various topics and social skills games will be included</p>\n\n<p>Address of the meetup: Bookstore \"Podpisnyie Izdaniya\", Liteyniy Prospekt, 57, 2nd floor</p>\n\n<p>If you are lost or have any questions feel free to call me +7 921 967 91 11 Kirill</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17x'>Saint-Petersburg Meetup </a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Wtod4uiMXhQ5LwD6g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 2.257578809348335e-06, "legacy": true, "legacyId": "27709", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Saint_Petersburg_Meetup_\">Discussion article for the meetup : <a href=\"/meetups/17x\">Saint-Petersburg Meetup </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 December 2014 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Saint-Petersburg, Liteyniy Prospekt 57</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Experimental Meetup at the new location! All aspiring rationalists are welcome to participate. Discussions on various topics and social skills games will be included</p>\n\n<p>Address of the meetup: Bookstore \"Podpisnyie Izdaniya\", Liteyniy Prospekt, 57, 2nd floor</p>\n\n<p>If you are lost or have any questions feel free to call me +7 921 967 91 11 Kirill</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Saint_Petersburg_Meetup_1\">Discussion article for the meetup : <a href=\"/meetups/17x\">Saint-Petersburg Meetup </a></h2>", "sections": [{"title": "Discussion article for the meetup : Saint-Petersburg Meetup ", "anchor": "Discussion_article_for_the_meetup___Saint_Petersburg_Meetup_", "level": 1}, {"title": "Discussion article for the meetup : Saint-Petersburg Meetup ", "anchor": "Discussion_article_for_the_meetup___Saint_Petersburg_Meetup_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-11T21:22:27.167Z", "modifiedAt": null, "url": null, "title": "What Peter Thiel thinks about AI risk", "slug": "what-peter-thiel-thinks-about-ai-risk", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:08.986Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gWCzxYPrkknFJ5C8N/what-peter-thiel-thinks-about-ai-risk", "pageUrlRelative": "/posts/gWCzxYPrkknFJ5C8N/what-peter-thiel-thinks-about-ai-risk", "linkUrl": "https://www.lesswrong.com/posts/gWCzxYPrkknFJ5C8N/what-peter-thiel-thinks-about-ai-risk", "postedAtFormatted": "Thursday, December 11th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20Peter%20Thiel%20thinks%20about%20AI%20risk&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20Peter%20Thiel%20thinks%20about%20AI%20risk%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgWCzxYPrkknFJ5C8N%2Fwhat-peter-thiel-thinks-about-ai-risk%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20Peter%20Thiel%20thinks%20about%20AI%20risk%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgWCzxYPrkknFJ5C8N%2Fwhat-peter-thiel-thinks-about-ai-risk", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgWCzxYPrkknFJ5C8N%2Fwhat-peter-thiel-thinks-about-ai-risk", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>This is probably the clearest statement from him on the issue:</p>\n<p>http://betaboston.com/news/2014/12/10/audio-peter-thiel-visits-boston-university-to-talk-entrepreneurship-and-backing-zuck/</p>\n<p>25:30 mins in</p>\n<p>&nbsp;</p>\n<p>TL;DR: he thinks its an issue but also feels AGI is very distant and hence less worried about it than Musk.</p>\n<p>&nbsp;</p>\n<p>I recommend the rest of the lecture as well, it's a good summary of <a href=\"http://zerotoonebook.com/\">\"Zero to One\" </a>&nbsp;and a good QA afterwards.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gWCzxYPrkknFJ5C8N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 20, "extendedScore": null, "score": 2.258718739040514e-06, "legacy": true, "legacyId": "27710", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-12T04:25:23.222Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington, D.C.: Tetlock's \"Expert Political Judgment\"", "slug": "meetup-washington-d-c-tetlock-s-expert-political-judgment", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dmTXcfeRPhc5iDyJS/meetup-washington-d-c-tetlock-s-expert-political-judgment", "pageUrlRelative": "/posts/dmTXcfeRPhc5iDyJS/meetup-washington-d-c-tetlock-s-expert-political-judgment", "linkUrl": "https://www.lesswrong.com/posts/dmTXcfeRPhc5iDyJS/meetup-washington-d-c-tetlock-s-expert-political-judgment", "postedAtFormatted": "Friday, December 12th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%2C%20D.C.%3A%20Tetlock's%20%22Expert%20Political%20Judgment%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%2C%20D.C.%3A%20Tetlock's%20%22Expert%20Political%20Judgment%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdmTXcfeRPhc5iDyJS%2Fmeetup-washington-d-c-tetlock-s-expert-political-judgment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%2C%20D.C.%3A%20Tetlock's%20%22Expert%20Political%20Judgment%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdmTXcfeRPhc5iDyJS%2Fmeetup-washington-d-c-tetlock-s-expert-political-judgment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdmTXcfeRPhc5iDyJS%2Fmeetup-washington-d-c-tetlock-s-expert-political-judgment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 240, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17y'>Washington, D.C.: Tetlock's &quot;Expert Political Judgment&quot;</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">14 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>talk about Philip E. Tetlock's book <em>Expert Political Judgment: How Good Is It? How Can We Know?</em>.</strong> Per the norm, we plan to let people congregate from 3:00 to 3:30 before kicking things off.</p>\n\n<p>As with prior informal-discussion meetups, conversation on any subject of interest to attendees (be it in the main conversation or in a side conversation) is both permitted and encouraged, but we suggest taking advantage of the meetup topic as a Schelling point.</p>\n\n<p><strong><em>Upcoming Meetups:</em></strong></p>\n\n<p>The Less Wrong DC organizers haven't decided whether to hold meetups on the remaining two Sundays in 2014: the 21st is the day after <a href=\"https://www.facebook.com/events/372802102853071/\" rel=\"nofollow\">Brighter Than Today</a>, a secular winter solstice celebration that many regulars will be out of town for, and the 28th falls during the week after <a href=\"http://en.wikipedia.org/wiki/Christmas\" rel=\"nofollow\">Christmas Day</a>, an ostensibly-religious winter solstice celebration that many regulars may be out of town (or hosting out-of-town guests) for. If there is sufficient interest in attending a meetup on either or both of these dates, meetups will occur; otherwise the Fun &amp; Games meetup will be postponed to January 4th.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17y'>Washington, D.C.: Tetlock's &quot;Expert Political Judgment&quot;</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dmTXcfeRPhc5iDyJS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.259658254413767e-06, "legacy": true, "legacyId": "27712", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Tetlock_s__Expert_Political_Judgment_\">Discussion article for the meetup : <a href=\"/meetups/17y\">Washington, D.C.: Tetlock's \"Expert Political Judgment\"</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">14 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>talk about Philip E. Tetlock's book <em>Expert Political Judgment: How Good Is It? How Can We Know?</em>.</strong> Per the norm, we plan to let people congregate from 3:00 to 3:30 before kicking things off.</p>\n\n<p>As with prior informal-discussion meetups, conversation on any subject of interest to attendees (be it in the main conversation or in a side conversation) is both permitted and encouraged, but we suggest taking advantage of the meetup topic as a Schelling point.</p>\n\n<p><strong id=\"Upcoming_Meetups_\"><em>Upcoming Meetups:</em></strong></p>\n\n<p>The Less Wrong DC organizers haven't decided whether to hold meetups on the remaining two Sundays in 2014: the 21st is the day after <a href=\"https://www.facebook.com/events/372802102853071/\" rel=\"nofollow\">Brighter Than Today</a>, a secular winter solstice celebration that many regulars will be out of town for, and the 28th falls during the week after <a href=\"http://en.wikipedia.org/wiki/Christmas\" rel=\"nofollow\">Christmas Day</a>, an ostensibly-religious winter solstice celebration that many regulars may be out of town (or hosting out-of-town guests) for. If there is sufficient interest in attending a meetup on either or both of these dates, meetups will occur; otherwise the Fun &amp; Games meetup will be postponed to January 4th.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Tetlock_s__Expert_Political_Judgment_1\">Discussion article for the meetup : <a href=\"/meetups/17y\">Washington, D.C.: Tetlock's \"Expert Political Judgment\"</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington, D.C.: Tetlock's \"Expert Political Judgment\"", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Tetlock_s__Expert_Political_Judgment_", "level": 1}, {"title": "Upcoming Meetups:", "anchor": "Upcoming_Meetups_", "level": 2}, {"title": "Discussion article for the meetup : Washington, D.C.: Tetlock's \"Expert Political Judgment\"", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Tetlock_s__Expert_Political_Judgment_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-12T05:15:08.834Z", "modifiedAt": null, "url": null, "title": "Robin Hanson talking about Bias on Stossel tonight", "slug": "robin-hanson-talking-about-bias-on-stossel-tonight", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.155Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "buybuydandavis", "createdAt": "2011-09-04T00:02:35.971Z", "isAdmin": false, "displayName": "buybuydandavis"}, "userId": "sQqaueY24d7xa3PXD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kCHdEQ9jp4YrkqH24/robin-hanson-talking-about-bias-on-stossel-tonight", "pageUrlRelative": "/posts/kCHdEQ9jp4YrkqH24/robin-hanson-talking-about-bias-on-stossel-tonight", "linkUrl": "https://www.lesswrong.com/posts/kCHdEQ9jp4YrkqH24/robin-hanson-talking-about-bias-on-stossel-tonight", "postedAtFormatted": "Friday, December 12th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Robin%20Hanson%20talking%20about%20Bias%20on%20Stossel%20tonight&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARobin%20Hanson%20talking%20about%20Bias%20on%20Stossel%20tonight%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkCHdEQ9jp4YrkqH24%2Frobin-hanson-talking-about-bias-on-stossel-tonight%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Robin%20Hanson%20talking%20about%20Bias%20on%20Stossel%20tonight%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkCHdEQ9jp4YrkqH24%2Frobin-hanson-talking-about-bias-on-stossel-tonight", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkCHdEQ9jp4YrkqH24%2Frobin-hanson-talking-about-bias-on-stossel-tonight", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 28, "htmlBody": "<p>&nbsp;</p>\n<p>Stossel has a page with full episodes. I don't know when it will show there. Hanson was the first guest, and was done by the 12 minute mark.</p>\n<p>http://video.foxbusiness.com/playlist/stossel-full-episodes/</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kCHdEQ9jp4YrkqH24", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 2.2597688381647587e-06, "legacy": true, "legacyId": "27713", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-12T09:04:56.000Z", "modifiedAt": null, "url": null, "title": "Beware The Man Of One Study", "slug": "beware-the-man-of-one-study", "viewCount": null, "lastCommentedAt": "2019-06-07T18:00:26.750Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ythFNoiAotjvuEGkg/beware-the-man-of-one-study", "pageUrlRelative": "/posts/ythFNoiAotjvuEGkg/beware-the-man-of-one-study", "linkUrl": "https://www.lesswrong.com/posts/ythFNoiAotjvuEGkg/beware-the-man-of-one-study", "postedAtFormatted": "Friday, December 12th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beware%20The%20Man%20Of%20One%20Study&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeware%20The%20Man%20Of%20One%20Study%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FythFNoiAotjvuEGkg%2Fbeware-the-man-of-one-study%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beware%20The%20Man%20Of%20One%20Study%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FythFNoiAotjvuEGkg%2Fbeware-the-man-of-one-study", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FythFNoiAotjvuEGkg%2Fbeware-the-man-of-one-study", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2504, "htmlBody": "<p>Aquinas famously <A HREF=\"http://en.wikipedia.org/wiki/Homo_unius_libri\">said</A>: beware the man of one book. I would add: beware the man of one study.</p>\n<p>For example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result &#8211; that it&#8217;s weakly effective.</p>\n<p>But there will also be random noise caused by inevitable variation and by some of the experiments being better quality than others. In the end, we might expect something looking kind of like a bell curve. The peak will be at &#8220;weakly effective&#8221;, but there will be a few studies to either side. Something like this:</p>\n<p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/onestudy.png\"></center></p>\n<p>We see that the peak of the curve is somewhere to the right of neutral &#8211; ie weakly effective &#8211; and that there are about 15 studies that find this correct result.</p>\n<p>But there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There&#8217;s even 1 study finding that the drug is very bad, maybe seriously dangerous.</p>\n<p>This is before we get into fraud or statistical malpractice. I&#8217;m saying this is what&#8217;s going to happen just by normal variation in experimental design. As we increase experimental rigor, the bell curve might get squashed horizontally, but there will still be a bell curve.</p>\n<p>In practice it&#8217;s worse than this, because this is assuming everyone is investigating exactly the same question.</p>\n<p>Suppose that the graph is titled &#8220;Effectiveness Of This Drug In Treating Bipolar Disorder&#8221;. </p>\n<p>But maybe the drug is more effective in bipolar i than in bipolar ii (Depakote, for example)</p>\n<p>Or maybe the drug is very effective against bipolar mania, but much less effective against bipolar depression (Depakote again).</p>\n<p>Or maybe the drug is a good acute antimanic agent, but very poor at maintenance treatment (let&#8217;s stick with Depakote).</p>\n<p>If you have a graph titled &#8220;Effectiveness Of Depakote In Treating Bipolar Disorder&#8221; plotting studies from &#8220;Very Bad&#8221; to &#8220;Very Good&#8221; &#8211; and you stick all the studies &#8211; maintenence, manic, depressive, bipolar i, bipolar ii &#8211; on the graph, then you&#8217;re going to end running the gamut from &#8220;very bad&#8221; to &#8220;very good&#8221; even before you factor in noise and even before even before you factor in bias and poor experimental design.</p>\n<p>So here&#8217;s why you should beware the man of one study.</p>\n<p>If you go to your better class of alternative medicine websites, they don&#8217;t tell you &#8220;Studies are a logocentric phallocentric tool of Western medicine and the Big Pharma conspiracy.&#8221;</p>\n<p>They tell you &#8220;medical science has proved that this drug is terrible, but ignorant doctors are pushing it on you anyway. Look, here&#8217;s a study by a reputable institution proving that the drug is not only ineffective, but harmful.&#8221;</p>\n<p>And the study will exist, and the authors will be prestigious scientists, and it will probably be about as rigorous and well-done as any other study.</p>\n<p>And then a lot of people raised on <A HREF=\"http://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/\">the idea</A> that some things have Evidence and other things have No Evidence think <i>holy s**t, they&#8217;re right!</i></p>\n<p>On the other hand, your doctor isn&#8217;t going to a sketchy alternative medicine website. She&#8217;s examining the entire literature and extracting careful and well-informed conclusions from&#8230;</p>\n<p>Haha, just kidding. She&#8217;s going to a luncheon at a really nice restaurant sponsored by a pharmaceutical company, which assures her that they would <i>never</i> take advantage of such an opportunity to shill their drug, they just want to raise awareness of the latest study. And the latest study shows that their drug is great! Super great! And your doctor nods along, because the authors of the study are prestigious scientists, and it&#8217;s about as rigorous and well-done as any other study.</p>\n<p>But obviously the pharmaceutical company has selected one of the studies from the &#8220;very good&#8221; end of the bell curve.</p>\n<p>And I called this &#8220;Beware The Man of One Study&#8221;, but it&#8217;s easy to see that in the little diagram there are like three or four studies showing that the drug is &#8220;very good&#8221;, so if your doctor is a little skeptical, the pharmaceutical company can say &#8220;You are right to be skeptical, one study doesn&#8217;t prove anything, but look &#8211; here&#8217;s another group that finds the same thing, here&#8217;s yet another group that finds the same thing, and here&#8217;s a replication that confirms both of them.&#8221;</p>\n<p>And even though it looks like in our example the sketchy alternative medicine website only has one &#8220;very bad&#8221; study to go off of, they could easily supplement it with a bunch of merely &#8220;bad&#8221; studies. Or they could add all of those studies about slightly different things. Depakote is ineffective at treating bipolar depression. Depakote is ineffective at maintenance bipolar therapy. Depakote is ineffective at bipolar ii. </p>\n<p>So just sum it up as &#8220;Smith et al 1987 found the drug ineffective, yet doctors continue to prescribe it anyway&#8221;. Even if you hunt down the original study (which no one does), Smith et al won&#8217;t say specifically &#8220;Do remember that this study is only looking at bipolar maintenance, which is a different topic from bipolar acute antimanic treatment, and we&#8217;re not saying anything about that.&#8221; It will just be titled something like &#8220;Depakote fails to separate from placebo in six month trial of 91 patients&#8221; and trust that the responsible professionals reading it are well aware of the difference between acute and maintenance treatments (hahahahaha).</p>\n<p>So it&#8217;s not so much &#8220;beware the man of one study&#8221; as &#8220;beware the man of any number of studies less than a relatively complete and not-cherry-picked survey of the research&#8221;.</p>\n<p><b>II.</b></p>\n<p>I think medical science is still pretty healthy, and that the consensus of doctors and researchers is more-or-less right on most controversial medical issues. </p>\n<p>(it&#8217;s the <i>uncontroversial</i> ones you have to worry about)</p>\n<p>Politics doesn&#8217;t have this protection.</p>\n<p>Like, take the minimum wage question (please). We all know about the Krueger and Card <A HREF=\"http://davidcard.berkeley.edu/papers/njmin-aer.pdf\">study</A> in New Jersey that found no evidence that high minimum wages hurt the economy. We probably also know the counterclaims that it was <A HREF=\"http://nypost.com/2013/08/06/minimum-honesty-on-minimum-wage/\">completely debunked</A> as despicable dishonest statistical malpractice. Maybe some of us know Card and Krueger wrote a <A HREF=\"http://www.jstor.org/discover/10.2307/2677856?uid=16785200&#038;uid=3739728&#038;uid=2&#038;uid=3&#038;uid=67&#038;uid=16754504&#038;uid=62&#038;uid=3739256&#038;sid=21104826014421\">pretty convincing rebuttal</A> of those claims. Or that a bunch of large and methodologically advanced studies have come out since then, some finding no effect like <A HREF=\"https://escholarship.org/uc/item/86w5m90m\">Dube</A>, others finding strong effects like <A HREF=\"https://economics.uchicago.edu/workshops/Rubinstein%20Yona%20Using%20Federal%20Minimum%20Wages%20Paper.pdf\">Rubinstein</A> and <A HREF=\"http://econbrowser.com/archives/2014/12/new-estimates-of-the-effects-of-the-minimum-wage\">Wither</A>. These are just examples; there are at least dozens and probably hundreds of studies on both sides.</p>\n<p>But we can solve this with meta-analyses and systemtic reviews, right?</p>\n<p>Depends which one you want. Do you go with <A HREF=\"http://people.hss.caltech.edu/~camerer/SS280/Card-Kruger-AER_Jan95.pdf\">this meta-analysis</A> of fourteen studies that shows that any presumed negative effect of high minimum wages is likely publication bias? With <A HREF=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8543.2009.00723.x/abstract\">this meta-analysis</A> of sixty-four studies that finds the same thing and discovers no effect of minimum wage after correcting for the problem? Or how about <A HREF=\"http://ftp.iza.org/dp4983.pdf\">this meta-analysis</A> of fifty-five countries that does find effects in most of them? Maybe you prefer <A HREF=\"http://www.nber.org/papers/w12663.pdf\">this systematic review</A> of a hundred or so studies that finds strong and consistent effects?</p>\n<p>Can we trust news sources, think tanks, econblogs, and other institutions to sum up the state of the evidence?</p>\n<p>CNN <A HREF=\"http://www.cnn.com/2011/09/16/opinion/saltsman-minimum-wage/\">claims that</A> 85% of credible studies have shown the minimum wage causes job loss. But raisetheminimumwage.com <A HREF=\"http://www.raisetheminimumwage.com/pages/job-loss\">declares that</A> &#8220;two decades of rigorous economic research have found that raising the minimum wage does not result in job loss&#8230;researchers and businesses alike agree today that the weight of the evidence shows no reduction in employment resulting from minimum wage increases.&#8221; Modeled Behavior <A HREF=\"http://modeledbehavior.com/2010/10/12/what-the-new-minimum-wage-research-says/\">says</A> &#8220;the majority of the new minimum wage research supports the hypothesis that the minimum wage increases unemployment.&#8221; The Center for Budget and Policy Priorities <A HREF=\"http://www.cbpp.org/cms/?fa=view&#038;id=4075\">says</A> &#8220;The common claim that raising the minimum wage reduces employment for low-wage workers is one of the most extensively studied issues in empirical economics.  The weight of the evidence is that such impacts are small to none.&#8221;</p>\n<p>Okay, fine. What about economists? They seem like experts. What do they think?</p>\n<p>Well, five hundred economists <A HREF=\"http://economistletter.com/\">signed</A> a letter to policy makers saying that the science of economics shows increasing the minimum wage would be a bad idea. That sounds like a promising consensus&#8230;</p>\n<p>..except that six hundred economists <A HREF=\"http://www.epi.org/minimum-wage-statement/\">signed</A> a letter to policy makers saying that the science of economics shows increasing the minimum wage would be a <i>good</i> idea. (h/t <A HREF=\"http://gregmankiw.blogspot.com/2014/03/economists-divided-on-minimum-wage-hike.html\">Greg Mankiw</A>)</p>\n<p>Fine then. Let&#8217;s do a formal survey of economists. Now what?</p>\n<p><A HREF=\"http://www.raisetheminimumwage.com/pages/job-loss\">raisetheminimumwage.com</A>, an unbiased source if ever there was one, confidently tells us that</A> &#8220;indicative is a 2013 survey by the University of Chicago\u2019s Booth School of Business in which leading economists agreed by a nearly 4 to 1 margin that the benefits of raising and indexing the minimum wage outweigh the costs.&#8221;</p>\n<p>But the Employment Policies Institute, which sounds like it&#8217;s trying <i>way</i> too hard to sound like an unbiased source, <A HREF=\"https://www.epionline.org/release/o185/\">tells us that</A> &#8220;Over 73 percent of AEA labor economists believe that a significant increase will lead to employment losses and 68 percent think these employment losses fall disproportionately on the least skilled. Only 6 percent feel that minimum wage hikes are an efficient way to alleviate poverty.&#8221; </p>\n<p>So the whole thing is fiendishly complicated. But unless you look very very hard, you will never know that.</p>\n<p>If you are a conservative, what you will find on the sites you trust will be something like this:</p>\n<blockquote><p>Economic theory has always shown that minimum wage increases decrease employment, but the Left has never been willing to accept this basic fact. In 1992, they trumpeted a single study by Card and Krueger that purported to show no negative effects from a minimum wage increase. This study was immediately debunked and found to be based on statistical malpractice and &#8220;massaging the numbers&#8221;. Since then, dozens of studies have come out confirming what we knew all along &#8211; that a high minimum wage is economic suicide. Systematic reviews and meta-analyses (Neumark 2006, Boockman 2010) consistently show that an overwhelming majority of the research agrees on this fact &#8211; as do 73% of economists. That&#8217;s why five hundred top economists recently signed a letter urging policy makers not to buy into discredited liberal minimum wage theories. Instead of listening to starry-eyed liberal woo, listen to the empirical evidence and an overwhelming majority of economists and oppose a raise in the minimum wage.</p></blockquote>\n<p>And if you are a leftist, what you will find on the sites you trust will be something like this:</p>\n<blockquote><p>People used to believe that the minimum wage decreased unemployment. But Card and Krueger&#8217;s famous 1992 study exploded that conventional wisdom. Since then, the results have been replicated over fifty times, and further meta-analyses (Card and Krueger 1995, Dube 2010) have found no evidence of any effect. Leading economists agree by a 4 to 1 margin that the benefits of raising the minimum wage outweigh the costs, and that&#8217;s why more than 600 of them have signed a petition telling the government to do exactly that. Instead of listening to conservative scare tactics based on long-debunked theories, listen to the empirical evidence and the overwhelming majority of economists and support a raise in the minimum wage.</p></blockquote>\n<p>Go ahead. <A HREF=\"http://webcache.googleusercontent.com/search?hl=en&#038;q=cache:TcOxVD4OoyQJ:http://www.businessinsider.com/krueger-card-fast-food-minimum-wage-study-2013-8%2Bhttp://www.businessinsider.com/krueger-card-fast-food-minimum-wage-study-2013-8&#038;gbv=2&#038;&#038;ct=clnk\">Google</A> <A HREF=\"http://www.rifuture.org/republicans-are-wrong-about-minimum-wage-and-economists-know-it.html\">the</A> <A HREF=\"http://mic.com/articles/61573/the-argument-to-increase-minimum-wage-you-haven-t-heard\">issue</A> <A HREF=\"http://www.washingtonexaminer.com/article/2521472\">and</A> <A HREF=\"http://chicagopolicyreview.org/2014/05/20/do-you-want-a-higher-minimum-wage-with-that/\">see</A> <A HREF=\"http://www.nextnewdeal.net/rediscovering-government/debunking-minimum-wage-myth-higher-wages-will-not-reduce-jobs\">what</A> <A HREF=\"http://www.freedomworks.org/content/yes-minimum-wage-increases-reduce-employment-and-hurt-low-skilled-workers\">stuff</A>  <A HREF=\"http://www.nationalreview.com/corner/275846/krueger-s-faulty-minimum-wage-study-carrie-l-lukas\">comes</A> <A HREF=\"http://www.dailykos.com/story/2014/05/01/1296116/-Minimum-Wage-Maximum-Rage\">up</A>. If it doesn&#8217;t quite match what I said above, it&#8217;s usually because they can&#8217;t even muster <i>that</i> level of scholarship. Half the sites just cite Card and Krueger and call it a day!</p>\n<p>These sites with their long lists of studies and experts are super convincing. And half of them are wrong.</p>\n<p>At some point in their education, most smart people usually learn not to credit arguments from authority. If someone says &#8220;Believe me about the minimum wage because I seem like a trustworthy guy,&#8221; most of them will have at least one neuron in their head that says &#8220;I should ask for some evidence&#8221;. If they&#8217;re <i>really</i> smart, they&#8217;ll use the magic words &#8220;peer-reviewed experimental studies.&#8221;</p>\n<p>But I worry that most smart people have <i>not</i> learned that a list of dozens of studies, several meta-analyses, hundreds of experts, and expert surveys showing almost all academics support your thesis &#8211; can <i>still</i> be bullshit. </p>\n<p>Which is too bad, because that&#8217;s exactly what people who want to bamboozle an educated audience are going to use.</p>\n<p><b>III.</b></p>\n<p>I do not want to preach radical skepticism.</p>\n<p>For example, on the minimum wage issue, I notice only one side has presented a funnel plot. A funnel plot is usually used to investigate publication bias, but it has another use as well &#8211; it&#8217;s pretty much an exact presentation of the &#8220;bell curve&#8221; we talked about above.</p>\n<p><center><IMG SRC=\"http://upload.wikimedia.org/wikipedia/commons/8/82/Funnel_Graph_of_Estimated_Minimum_Wage_Effects.jpg\"></center></p>\n<p>This is more of a needle curve than a bell curve, but the point still stands. We see it&#8217;s centered around 0, which means there&#8217;s some evidence that&#8217;s the real signal among all this noise. The bell skews more to left than to the right, which means more studies have found negative effects of the minimum wage than positive effects of the minimum wage. But since the bell curve is asymmetrical, we intepret that as <i>probably</i> publication bias. So all in all, I think there&#8217;s at least some evidence that the liberals are right on this one.</p>\n<p>Unless, of course, someone has realized that I&#8217;ve wised up to the studies and meta-analyses and and expert surveys, and figured out a way to hack <i>funnel plots</i>, which I am totally not ruling out.</p>\n<p>(okay, I <i>kind of</i> want to preach radical skepticism)</p>\n<p>Also, I should probably mention that it&#8217;s much more complicated than one side being right, and that the minimum wage probably works differently depending on what industry you&#8217;re talking about, whether it&#8217;s state wage or federal wage, whether it&#8217;s a recession or a boom, whether we&#8217;re talking about increasing from $5 to $6 or from $20 to $30, etc, etc, etc. There are eleven studies on that plot showing an effect even worse than -5, and very possibly they are all accurate for whatever subproblem they have chosen to study &#8211; much like the example with Depakote where it might an effective antimanic but a terrible antidepressant.</p>\n<p>(radical skepticism actually sounds a lot better than figuring this all out).</p>\n<p><b>IV.</b></p>\n<p>But the question remains: what happens when (like in most cases) you don&#8217;t have a funnel plot?</p>\n<p>I don&#8217;t have a good positive answer. I do have several good <i>negative</i> answers.</p>\n<p>Decrease your confidence about most things if you&#8217;re not sure that you&#8217;ve investigated every piece of evidence.</p>\n<p>Do not trust websites which are obviously biased (eg Free Republic, Daily Kos, Dr. Oz) when they tell you they&#8217;re going to give you &#8220;the state of the evidence&#8221; on a certain issue, even if the evidence seems very stately indeed. This goes double for any site that contains a list of &#8220;myths and facts about X&#8221;, quadruple for any site that uses phrases like &#8220;ingroup member uses actual FACTS to DEMOLISH the outgroup&#8217;s lies about Y&#8221;, and octuple for RationalWiki.</p>\n<p>Most important, even if someone gives you what seems like overwhelming evidence in favor of a certain point of view, don&#8217;t trust it until you&#8217;ve done a simple Google search to see if the opposite side has equally overwhelming evidence. </p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "ZpG9rheyAkgCoEQea": 3, "vcvfjGJwRmFbMMS3d": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ythFNoiAotjvuEGkg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 44, "baseScore": 48, "extendedScore": null, "score": 0.000141, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "BQBqPowfxjvoee8jw", "canonicalCollectionSlug": "codex", "canonicalBookId": "YhQ39PPHNrRCgYXcs", "canonicalNextPostSlug": "debunked-and-well-refuted", "canonicalPrevPostSlug": "reverse-psychology", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 48, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Aquinas famously <a href=\"http://en.wikipedia.org/wiki/Homo_unius_libri\">said</a>: beware the man of one book. I would add: beware the man of one study.</p>\n<p>For example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result \u2013 that it\u2019s weakly effective.</p>\n<p>But there will also be random noise caused by inevitable variation and by some of the experiments being better quality than others. In the end, we might expect something looking kind of like a bell curve. The peak will be at \u201cweakly effective\u201d, but there will be a few studies to either side. Something like this:</p>\n<p></p><center><img src=\"http://slatestarcodex.com/blog_images/onestudy.png\"></center><p></p>\n<p>We see that the peak of the curve is somewhere to the right of neutral \u2013 ie weakly effective \u2013 and that there are about 15 studies that find this correct result.</p>\n<p>But there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There\u2019s even 1 study finding that the drug is very bad, maybe seriously dangerous.</p>\n<p>This is before we get into fraud or statistical malpractice. I\u2019m saying this is what\u2019s going to happen just by normal variation in experimental design. As we increase experimental rigor, the bell curve might get squashed horizontally, but there will still be a bell curve.</p>\n<p>In practice it\u2019s worse than this, because this is assuming everyone is investigating exactly the same question.</p>\n<p>Suppose that the graph is titled \u201cEffectiveness Of This Drug In Treating Bipolar Disorder\u201d. </p>\n<p>But maybe the drug is more effective in bipolar i than in bipolar ii (Depakote, for example)</p>\n<p>Or maybe the drug is very effective against bipolar mania, but much less effective against bipolar depression (Depakote again).</p>\n<p>Or maybe the drug is a good acute antimanic agent, but very poor at maintenance treatment (let\u2019s stick with Depakote).</p>\n<p>If you have a graph titled \u201cEffectiveness Of Depakote In Treating Bipolar Disorder\u201d plotting studies from \u201cVery Bad\u201d to \u201cVery Good\u201d \u2013 and you stick all the studies \u2013 maintenence, manic, depressive, bipolar i, bipolar ii \u2013 on the graph, then you\u2019re going to end running the gamut from \u201cvery bad\u201d to \u201cvery good\u201d even before you factor in noise and even before even before you factor in bias and poor experimental design.</p>\n<p>So here\u2019s why you should beware the man of one study.</p>\n<p>If you go to your better class of alternative medicine websites, they don\u2019t tell you \u201cStudies are a logocentric phallocentric tool of Western medicine and the Big Pharma conspiracy.\u201d</p>\n<p>They tell you \u201cmedical science has proved that this drug is terrible, but ignorant doctors are pushing it on you anyway. Look, here\u2019s a study by a reputable institution proving that the drug is not only ineffective, but harmful.\u201d</p>\n<p>And the study will exist, and the authors will be prestigious scientists, and it will probably be about as rigorous and well-done as any other study.</p>\n<p>And then a lot of people raised on <a href=\"http://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/\">the idea</a> that some things have Evidence and other things have No Evidence think <i>holy s**t, they\u2019re right!</i></p>\n<p>On the other hand, your doctor isn\u2019t going to a sketchy alternative medicine website. She\u2019s examining the entire literature and extracting careful and well-informed conclusions from\u2026</p>\n<p>Haha, just kidding. She\u2019s going to a luncheon at a really nice restaurant sponsored by a pharmaceutical company, which assures her that they would <i>never</i> take advantage of such an opportunity to shill their drug, they just want to raise awareness of the latest study. And the latest study shows that their drug is great! Super great! And your doctor nods along, because the authors of the study are prestigious scientists, and it\u2019s about as rigorous and well-done as any other study.</p>\n<p>But obviously the pharmaceutical company has selected one of the studies from the \u201cvery good\u201d end of the bell curve.</p>\n<p>And I called this \u201cBeware The Man of One Study\u201d, but it\u2019s easy to see that in the little diagram there are like three or four studies showing that the drug is \u201cvery good\u201d, so if your doctor is a little skeptical, the pharmaceutical company can say \u201cYou are right to be skeptical, one study doesn\u2019t prove anything, but look \u2013 here\u2019s another group that finds the same thing, here\u2019s yet another group that finds the same thing, and here\u2019s a replication that confirms both of them.\u201d</p>\n<p>And even though it looks like in our example the sketchy alternative medicine website only has one \u201cvery bad\u201d study to go off of, they could easily supplement it with a bunch of merely \u201cbad\u201d studies. Or they could add all of those studies about slightly different things. Depakote is ineffective at treating bipolar depression. Depakote is ineffective at maintenance bipolar therapy. Depakote is ineffective at bipolar ii. </p>\n<p>So just sum it up as \u201cSmith et al 1987 found the drug ineffective, yet doctors continue to prescribe it anyway\u201d. Even if you hunt down the original study (which no one does), Smith et al won\u2019t say specifically \u201cDo remember that this study is only looking at bipolar maintenance, which is a different topic from bipolar acute antimanic treatment, and we\u2019re not saying anything about that.\u201d It will just be titled something like \u201cDepakote fails to separate from placebo in six month trial of 91 patients\u201d and trust that the responsible professionals reading it are well aware of the difference between acute and maintenance treatments (hahahahaha).</p>\n<p>So it\u2019s not so much \u201cbeware the man of one study\u201d as \u201cbeware the man of any number of studies less than a relatively complete and not-cherry-picked survey of the research\u201d.</p>\n<p><b id=\"II_\">II.</b></p>\n<p>I think medical science is still pretty healthy, and that the consensus of doctors and researchers is more-or-less right on most controversial medical issues. </p>\n<p>(it\u2019s the <i>uncontroversial</i> ones you have to worry about)</p>\n<p>Politics doesn\u2019t have this protection.</p>\n<p>Like, take the minimum wage question (please). We all know about the Krueger and Card <a href=\"http://davidcard.berkeley.edu/papers/njmin-aer.pdf\">study</a> in New Jersey that found no evidence that high minimum wages hurt the economy. We probably also know the counterclaims that it was <a href=\"http://nypost.com/2013/08/06/minimum-honesty-on-minimum-wage/\">completely debunked</a> as despicable dishonest statistical malpractice. Maybe some of us know Card and Krueger wrote a <a href=\"http://www.jstor.org/discover/10.2307/2677856?uid=16785200&amp;uid=3739728&amp;uid=2&amp;uid=3&amp;uid=67&amp;uid=16754504&amp;uid=62&amp;uid=3739256&amp;sid=21104826014421\">pretty convincing rebuttal</a> of those claims. Or that a bunch of large and methodologically advanced studies have come out since then, some finding no effect like <a href=\"https://escholarship.org/uc/item/86w5m90m\">Dube</a>, others finding strong effects like <a href=\"https://economics.uchicago.edu/workshops/Rubinstein%20Yona%20Using%20Federal%20Minimum%20Wages%20Paper.pdf\">Rubinstein</a> and <a href=\"http://econbrowser.com/archives/2014/12/new-estimates-of-the-effects-of-the-minimum-wage\">Wither</a>. These are just examples; there are at least dozens and probably hundreds of studies on both sides.</p>\n<p>But we can solve this with meta-analyses and systemtic reviews, right?</p>\n<p>Depends which one you want. Do you go with <a href=\"http://people.hss.caltech.edu/~camerer/SS280/Card-Kruger-AER_Jan95.pdf\">this meta-analysis</a> of fourteen studies that shows that any presumed negative effect of high minimum wages is likely publication bias? With <a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8543.2009.00723.x/abstract\">this meta-analysis</a> of sixty-four studies that finds the same thing and discovers no effect of minimum wage after correcting for the problem? Or how about <a href=\"http://ftp.iza.org/dp4983.pdf\">this meta-analysis</a> of fifty-five countries that does find effects in most of them? Maybe you prefer <a href=\"http://www.nber.org/papers/w12663.pdf\">this systematic review</a> of a hundred or so studies that finds strong and consistent effects?</p>\n<p>Can we trust news sources, think tanks, econblogs, and other institutions to sum up the state of the evidence?</p>\n<p>CNN <a href=\"http://www.cnn.com/2011/09/16/opinion/saltsman-minimum-wage/\">claims that</a> 85% of credible studies have shown the minimum wage causes job loss. But raisetheminimumwage.com <a href=\"http://www.raisetheminimumwage.com/pages/job-loss\">declares that</a> \u201ctwo decades of rigorous economic research have found that raising the minimum wage does not result in job loss\u2026researchers and businesses alike agree today that the weight of the evidence shows no reduction in employment resulting from minimum wage increases.\u201d Modeled Behavior <a href=\"http://modeledbehavior.com/2010/10/12/what-the-new-minimum-wage-research-says/\">says</a> \u201cthe majority of the new minimum wage research supports the hypothesis that the minimum wage increases unemployment.\u201d The Center for Budget and Policy Priorities <a href=\"http://www.cbpp.org/cms/?fa=view&amp;id=4075\">says</a> \u201cThe common claim that raising the minimum wage reduces employment for low-wage workers is one of the most extensively studied issues in empirical economics.  The weight of the evidence is that such impacts are small to none.\u201d</p>\n<p>Okay, fine. What about economists? They seem like experts. What do they think?</p>\n<p>Well, five hundred economists <a href=\"http://economistletter.com/\">signed</a> a letter to policy makers saying that the science of economics shows increasing the minimum wage would be a bad idea. That sounds like a promising consensus\u2026</p>\n<p>..except that six hundred economists <a href=\"http://www.epi.org/minimum-wage-statement/\">signed</a> a letter to policy makers saying that the science of economics shows increasing the minimum wage would be a <i>good</i> idea. (h/t <a href=\"http://gregmankiw.blogspot.com/2014/03/economists-divided-on-minimum-wage-hike.html\">Greg Mankiw</a>)</p>\n<p>Fine then. Let\u2019s do a formal survey of economists. Now what?</p>\n<p><a href=\"http://www.raisetheminimumwage.com/pages/job-loss\">raisetheminimumwage.com</a>, an unbiased source if ever there was one, confidently tells us that \u201cindicative is a 2013 survey by the University of Chicago\u2019s Booth School of Business in which leading economists agreed by a nearly 4 to 1 margin that the benefits of raising and indexing the minimum wage outweigh the costs.\u201d</p>\n<p>But the Employment Policies Institute, which sounds like it\u2019s trying <i>way</i> too hard to sound like an unbiased source, <a href=\"https://www.epionline.org/release/o185/\">tells us that</a> \u201cOver 73 percent of AEA labor economists believe that a significant increase will lead to employment losses and 68 percent think these employment losses fall disproportionately on the least skilled. Only 6 percent feel that minimum wage hikes are an efficient way to alleviate poverty.\u201d </p>\n<p>So the whole thing is fiendishly complicated. But unless you look very very hard, you will never know that.</p>\n<p>If you are a conservative, what you will find on the sites you trust will be something like this:</p>\n<blockquote><p>Economic theory has always shown that minimum wage increases decrease employment, but the Left has never been willing to accept this basic fact. In 1992, they trumpeted a single study by Card and Krueger that purported to show no negative effects from a minimum wage increase. This study was immediately debunked and found to be based on statistical malpractice and \u201cmassaging the numbers\u201d. Since then, dozens of studies have come out confirming what we knew all along \u2013 that a high minimum wage is economic suicide. Systematic reviews and meta-analyses (Neumark 2006, Boockman 2010) consistently show that an overwhelming majority of the research agrees on this fact \u2013 as do 73% of economists. That\u2019s why five hundred top economists recently signed a letter urging policy makers not to buy into discredited liberal minimum wage theories. Instead of listening to starry-eyed liberal woo, listen to the empirical evidence and an overwhelming majority of economists and oppose a raise in the minimum wage.</p></blockquote>\n<p>And if you are a leftist, what you will find on the sites you trust will be something like this:</p>\n<blockquote><p>People used to believe that the minimum wage decreased unemployment. But Card and Krueger\u2019s famous 1992 study exploded that conventional wisdom. Since then, the results have been replicated over fifty times, and further meta-analyses (Card and Krueger 1995, Dube 2010) have found no evidence of any effect. Leading economists agree by a 4 to 1 margin that the benefits of raising the minimum wage outweigh the costs, and that\u2019s why more than 600 of them have signed a petition telling the government to do exactly that. Instead of listening to conservative scare tactics based on long-debunked theories, listen to the empirical evidence and the overwhelming majority of economists and support a raise in the minimum wage.</p></blockquote>\n<p>Go ahead. <a href=\"http://webcache.googleusercontent.com/search?hl=en&amp;q=cache:TcOxVD4OoyQJ:http://www.businessinsider.com/krueger-card-fast-food-minimum-wage-study-2013-8%2Bhttp://www.businessinsider.com/krueger-card-fast-food-minimum-wage-study-2013-8&amp;gbv=2&amp;&amp;ct=clnk\">Google</a> <a href=\"http://www.rifuture.org/republicans-are-wrong-about-minimum-wage-and-economists-know-it.html\">the</a> <a href=\"http://mic.com/articles/61573/the-argument-to-increase-minimum-wage-you-haven-t-heard\">issue</a> <a href=\"http://www.washingtonexaminer.com/article/2521472\">and</a> <a href=\"http://chicagopolicyreview.org/2014/05/20/do-you-want-a-higher-minimum-wage-with-that/\">see</a> <a href=\"http://www.nextnewdeal.net/rediscovering-government/debunking-minimum-wage-myth-higher-wages-will-not-reduce-jobs\">what</a> <a href=\"http://www.freedomworks.org/content/yes-minimum-wage-increases-reduce-employment-and-hurt-low-skilled-workers\">stuff</a>  <a href=\"http://www.nationalreview.com/corner/275846/krueger-s-faulty-minimum-wage-study-carrie-l-lukas\">comes</a> <a href=\"http://www.dailykos.com/story/2014/05/01/1296116/-Minimum-Wage-Maximum-Rage\">up</a>. If it doesn\u2019t quite match what I said above, it\u2019s usually because they can\u2019t even muster <i>that</i> level of scholarship. Half the sites just cite Card and Krueger and call it a day!</p>\n<p>These sites with their long lists of studies and experts are super convincing. And half of them are wrong.</p>\n<p>At some point in their education, most smart people usually learn not to credit arguments from authority. If someone says \u201cBelieve me about the minimum wage because I seem like a trustworthy guy,\u201d most of them will have at least one neuron in their head that says \u201cI should ask for some evidence\u201d. If they\u2019re <i>really</i> smart, they\u2019ll use the magic words \u201cpeer-reviewed experimental studies.\u201d</p>\n<p>But I worry that most smart people have <i>not</i> learned that a list of dozens of studies, several meta-analyses, hundreds of experts, and expert surveys showing almost all academics support your thesis \u2013 can <i>still</i> be bullshit. </p>\n<p>Which is too bad, because that\u2019s exactly what people who want to bamboozle an educated audience are going to use.</p>\n<p><b id=\"III_\">III.</b></p>\n<p>I do not want to preach radical skepticism.</p>\n<p>For example, on the minimum wage issue, I notice only one side has presented a funnel plot. A funnel plot is usually used to investigate publication bias, but it has another use as well \u2013 it\u2019s pretty much an exact presentation of the \u201cbell curve\u201d we talked about above.</p>\n<p></p><center><img src=\"http://upload.wikimedia.org/wikipedia/commons/8/82/Funnel_Graph_of_Estimated_Minimum_Wage_Effects.jpg\"></center><p></p>\n<p>This is more of a needle curve than a bell curve, but the point still stands. We see it\u2019s centered around 0, which means there\u2019s some evidence that\u2019s the real signal among all this noise. The bell skews more to left than to the right, which means more studies have found negative effects of the minimum wage than positive effects of the minimum wage. But since the bell curve is asymmetrical, we intepret that as <i>probably</i> publication bias. So all in all, I think there\u2019s at least some evidence that the liberals are right on this one.</p>\n<p>Unless, of course, someone has realized that I\u2019ve wised up to the studies and meta-analyses and and expert surveys, and figured out a way to hack <i>funnel plots</i>, which I am totally not ruling out.</p>\n<p>(okay, I <i>kind of</i> want to preach radical skepticism)</p>\n<p>Also, I should probably mention that it\u2019s much more complicated than one side being right, and that the minimum wage probably works differently depending on what industry you\u2019re talking about, whether it\u2019s state wage or federal wage, whether it\u2019s a recession or a boom, whether we\u2019re talking about increasing from $5 to $6 or from $20 to $30, etc, etc, etc. There are eleven studies on that plot showing an effect even worse than -5, and very possibly they are all accurate for whatever subproblem they have chosen to study \u2013 much like the example with Depakote where it might an effective antimanic but a terrible antidepressant.</p>\n<p>(radical skepticism actually sounds a lot better than figuring this all out).</p>\n<p><b id=\"IV_\">IV.</b></p>\n<p>But the question remains: what happens when (like in most cases) you don\u2019t have a funnel plot?</p>\n<p>I don\u2019t have a good positive answer. I do have several good <i>negative</i> answers.</p>\n<p>Decrease your confidence about most things if you\u2019re not sure that you\u2019ve investigated every piece of evidence.</p>\n<p>Do not trust websites which are obviously biased (eg Free Republic, Daily Kos, Dr. Oz) when they tell you they\u2019re going to give you \u201cthe state of the evidence\u201d on a certain issue, even if the evidence seems very stately indeed. This goes double for any site that contains a list of \u201cmyths and facts about X\u201d, quadruple for any site that uses phrases like \u201cingroup member uses actual FACTS to DEMOLISH the outgroup\u2019s lies about Y\u201d, and octuple for RationalWiki.</p>\n<p>Most important, even if someone gives you what seems like overwhelming evidence in favor of a certain point of view, don\u2019t trust it until you\u2019ve done a simple Google search to see if the opposite side has equally overwhelming evidence. </p>", "sections": [{"title": "II.", "anchor": "II_", "level": 1}, {"title": "III.", "anchor": "III_", "level": 1}, {"title": "IV.", "anchor": "IV_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-12T17:06:48.775Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-4", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3ZtDjF3MdWcCDCWN3/weekly-lw-meetups-4", "pageUrlRelative": "/posts/3ZtDjF3MdWcCDCWN3/weekly-lw-meetups-4", "linkUrl": "https://www.lesswrong.com/posts/3ZtDjF3MdWcCDCWN3/weekly-lw-meetups-4", "postedAtFormatted": "Friday, December 12th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3ZtDjF3MdWcCDCWN3%2Fweekly-lw-meetups-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3ZtDjF3MdWcCDCWN3%2Fweekly-lw-meetups-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3ZtDjF3MdWcCDCWN3%2Fweekly-lw-meetups-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 594, "htmlBody": "<p><strong>This summary was posted to LW Main on December 5th. The following week's summary is <a href=\"/lw/ldu/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/17j\">Australia onling hangout:&nbsp;<span class=\"date\">14 December 2014 07:00PM</span></a></li>\n<li><a href=\"/meetups/17o\">Copenhagen: December Meetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/160\">East Coast Solstice Megameetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/15w\">European Community Weekend 2015:&nbsp;<span class=\"date\">12 June 2015 12:00PM</span></a></li>\n<li><a href=\"/meetups/17d\">Frankfurt:&nbsp;<span class=\"date\">07 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17i\">Munich Meetup in December:&nbsp;<span class=\"date\">13 December 2014 12:00PM</span></a></li>\n<li><a href=\"/meetups/17a\">Utrecht: Rationality Games:&nbsp;<span class=\"date\">14 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17b\">Utrecht:&nbsp;<span class=\"date\">21 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17c\">Utrecht: a critique of effective altruism:&nbsp;<span class=\"date\">04 January 2015 02:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/17m\">Canberra: End of year party:&nbsp;<span class=\"date\">13 December 2014 06:00PM</span></a></li>\n<li><a href=\"/meetups/17k\">London Social Meetup, 07/12/2014:&nbsp;<span class=\"date\">07 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17n\">[Melbourne] December Rationality Dojo - Online Communication: Conveying Ideas Effectively:&nbsp;<span class=\"date\">07 December 2014 03:30PM</span></a></li>\n<li><a href=\"/meetups/17l\">Moscow Meetup: CBT is back:&nbsp;<span class=\"date\">07 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/16r\">Seattle Secular Solstice:&nbsp;<span class=\"date\">13 December 2014 05:30PM</span></a></li>\n<li><a href=\"/meetups/17g\">Sydney Rationality Dojo - Approaches, Conspecific Interactions, Arguments and Communications:&nbsp;<span class=\"date\">07 December 2014 04:00AM</span></a></li>\n<li><a href=\"/meetups/17p\">Toronto EA meetup:&nbsp;<span class=\"date\">11 December 2014 07:00PM</span></a></li>\n<li><a href=\"/meetups/16y\">[Vienna] Rationality Weekend Vienna:&nbsp;<span class=\"date\">13 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/17q\">Washington, D.C.: Brains:&nbsp;<span class=\"date\">07 December 2014 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\">Berlin</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Boston.2C_MA\">Boston</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Brussels.2C_Belgium\">Brussels</a></strong><strong>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Buffalo.2C_NY\">Buffalo</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Canberra\">Canberra</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Columbus.2C_OH\">Columbus</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Moscow.2C_Russia\">Moscow</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Philadelphia.2C_PA\">Philadelphia</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Research_Triangle.2C_NC_.28Raleigh.2FDurham.2FChapel_Hill.29\">Research Triangle NC</a>,</strong><strong>&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Sydney\">Sydney</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a></strong><strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington DC</strong></a></strong>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview is posted on the front page every Friday. These are an attempt to collect information on all the meetups happening in upcoming weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll also have the benefit of having your meetup mentioned in a weekly overview. These overview posts are moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cincinnati</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cleveland</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> </strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tel_Aviv.2C_Israel\">Tel Aviv</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Warsaw.2C_Poland\">Warsaw</a></strong><strong>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3ZtDjF3MdWcCDCWN3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 2.261351446359313e-06, "legacy": true, "legacyId": "27676", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PuFravaDSfS6do3K6", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-12T20:34:45.244Z", "modifiedAt": null, "url": null, "title": "Harper's Magazine article on LW/MIRI/CFAR and Ethereum", "slug": "harper-s-magazine-article-on-lw-miri-cfar-and-ethereum", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:02.106Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pfHrgwZi38GBckzFL/harper-s-magazine-article-on-lw-miri-cfar-and-ethereum", "pageUrlRelative": "/posts/pfHrgwZi38GBckzFL/harper-s-magazine-article-on-lw-miri-cfar-and-ethereum", "linkUrl": "https://www.lesswrong.com/posts/pfHrgwZi38GBckzFL/harper-s-magazine-article-on-lw-miri-cfar-and-ethereum", "postedAtFormatted": "Friday, December 12th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harper's%20Magazine%20article%20on%20LW%2FMIRI%2FCFAR%20and%20Ethereum&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarper's%20Magazine%20article%20on%20LW%2FMIRI%2FCFAR%20and%20Ethereum%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpfHrgwZi38GBckzFL%2Fharper-s-magazine-article-on-lw-miri-cfar-and-ethereum%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harper's%20Magazine%20article%20on%20LW%2FMIRI%2FCFAR%20and%20Ethereum%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpfHrgwZi38GBckzFL%2Fharper-s-magazine-article-on-lw-miri-cfar-and-ethereum", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpfHrgwZi38GBckzFL%2Fharper-s-magazine-article-on-lw-miri-cfar-and-ethereum", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4335, "htmlBody": "<!-- code{white-space: pre;} -->\n<p>Cover title: &ldquo;Power and paranoia in Silicon Valley&rdquo;; article title: <a href=\"http://harpers.org/archive/2015/01/come-with-us-if-you-want-to-live/\">&ldquo;Come with us if you want to live: Among the apocalyptic libertarians of Silicon Valley&rdquo;</a> (mirrors: <a href=\"https://pdf.yt/d/-jQQX6XY9dU0LN4G\">1</a>, <a href=\"https://www.dropbox.com/s/lsvb8d3l9tgr2rk/2015-frank.pdf\">2</a>, <a href=\"http://www.uploadmb.com/dw.php?id=1418359895\">3</a>), by Sam Frank; <em>Harper&rsquo;s Magazine</em>, January 2015, pg26-36 (~8500 words). The beginning/ending are focused on Ethereum and <span class=\"st\">Vitalik Buterin</span>, so I'll excerpt the LW/MIRI/CFAR-focused middle:</p>\n<blockquote>\n<p>&hellip;Blake Masters-the name was too perfect-had, obviously, dedicated himself to the command of self and universe. He did CrossFit and ate Bulletproof, a tech-world variant of the paleo diet. On his Tumblr&rsquo;s About page, since rewritten, the anti-belief belief systems multiplied, hyperlinked to Wikipedia pages or to the confoundingly scholastic website Less Wrong: &ldquo;Libertarian (and not convinced there&rsquo;s irreconcilable fissure between deontological and consequentialist camps). Aspiring rationalist/Bayesian. Secularist/agnostic/ ignostic . . . Hayekian. As important as what we know is what we don&rsquo;t. Admittedly eccentric.&rdquo; Then: &ldquo;Really, really excited to be in Silicon Valley right now, working on fascinating stuff with an amazing team.&rdquo; I was startled that all these negative ideologies could be condensed so easily into a positive worldview. &hellip;I saw the utopianism latent in capitalism-that, as Bernard Mandeville had it three centuries ago, it is a system that manufactures public benefit from private vice. I started CrossFit and began tinkering with my diet. I browsed venal tech-trade publications, and tried and failed to read Less Wrong, which was written as if for aliens.</p>\n<p>&hellip;I left the auditorium of Alice Tully Hall. Bleary beside the silver coffee urn in the nearly empty lobby, I was buttonholed by a man whose name tag read MICHAEL VASSAR, METAMED research. He wore a black-and-white paisley shirt and a jacket that was slightly too big for him. &ldquo;What did you think of that talk?&rdquo; he asked, without introducing himself. &ldquo;Disorganized, wasn&rsquo;t it?&rdquo; A theory of everything followed. Heroes like Elon and Peter (did I have to ask? Musk and Thiel). The relative abilities of physicists and biologists, their standard deviations calculated out loud. How exactly Vassar would save the world. His left eyelid twitched, his full face winced with effort as he told me about his &ldquo;personal war against the universe.&rdquo; My brain hurt. I backed away and headed home. But Vassar had spoken like no one I had ever met, and after Kurzweil&rsquo;s keynote the next morning, I sought him out. He continued as if uninterrupted. Among the acolytes of eternal life, Vassar was an eschatologist. &ldquo;There are all of these different countdowns going on,&rdquo; he said. &ldquo;There&rsquo;s the countdown to the broad postmodern memeplex undermining our civilization and causing everything to break down, there&rsquo;s the countdown to the broad modernist memeplex destroying our environment or killing everyone in a nuclear war, and there&rsquo;s the countdown to the modernist civilization learning to critique itself fully and creating an artificial intelligence that it can&rsquo;t control. There are so many different - on different time-scales - ways in which the self-modifying intelligent processes that we are embedded in undermine themselves. I&rsquo;m trying to figure out ways of disentangling all of that. . . .I&rsquo;m not sure that what I&rsquo;m trying to do is as hard as founding the Roman Empire or the Catholic Church or something. But it&rsquo;s harder than people&rsquo;s normal big-picture ambitions, like making a billion dollars.&rdquo; Vassar was thirty-four, one year older than I was. He had gone to college at seventeen, and had worked as an actuary, as a teacher, in nanotech, and in the Peace Corps. He&rsquo;d founded a music-licensing start-up called Sir Groovy. Early in 2012, he had stepped down as president of the Singularity Institute for Artificial Intelligence, now called the Machine Intelligence Research Institute (MIRI), which was created by an autodidact named Eliezer Yudkowsky, who also started Less Wrong. Vassar had left to found MetaMed, a personalized-medicine company, with Jaan Tallinn of Skype and Kazaa, $500,000 from Peter Thiel, and a staff that included young rationalists who had cut their teeth arguing on Yudkowsky&rsquo;s website. The idea behind MetaMed was to apply rationality to medicine-&ldquo;rationality&rdquo; here defined as the ability to properly research, weight, and synthesize the flawed medical information that exists in the world. Prices ranged from $25,000 for a literature review to a few hundred thousand for a personalized study. &ldquo;We can save lots and lots and lots of lives,&rdquo; Vassar said (if mostly moneyed ones at first). &ldquo;But it&rsquo;s the signal-it&rsquo;s the &lsquo;Hey! Reason works!&rsquo;-that matters. . . . It&rsquo;s not really about medicine.&rdquo; Our whole society was sick - root, branch, and memeplex - and rationality was the only cure. &hellip;I asked Vassar about his friend Yudkowsky. &ldquo;He has worse aesthetics than I do,&rdquo; he replied, &ldquo;and is actually incomprehensibly smart.&rdquo; We agreed to stay in touch.</p>\n<p>One month later, I boarded a plane to San Francisco. I had spent the interim taking a second look at Less Wrong, trying to parse its lore and jargon: &ldquo;scope insensitivity,&rdquo; &ldquo;ugh field,&rdquo; &ldquo;affective death spiral,&rdquo; &ldquo;typical mind fallacy,&rdquo; &ldquo;counterfactual mugging,&rdquo; &ldquo;Roko&rsquo;s basilisk.&rdquo; When I arrived at the MIRI offices in Berkeley, young men were sprawled on beanbags, surrounded by whiteboards half black with equations. I had come costumed in a Fermat&rsquo;s Last Theorem T-shirt, a summary of the proof on the front and a bibliography on the back, printed for the number-theory camp I had attended at fifteen. Yudkowsky arrived late. He led me to an empty office where we sat down in mismatched chairs. He wore glasses, had a short, dark beard, and his heavy body seemed slightly alien to him. I asked what he was working on. &ldquo;Should I assume that your shirt is an accurate reflection of your abilities,&rdquo; he asked, &ldquo;and start blabbing math at you?&rdquo; Eight minutes of probability and game theory followed. Cogitating before me, he kept grimacing as if not quite in control of his face. &ldquo;In the very long run, obviously, you want to solve all the problems associated with having a stable, self-improving, beneficial-slash-benevolent AI, and then you want to build one.&rdquo; What happens if an artificial intelligence begins improving itself, changing its own source code, until it rapidly becomes - foom! is Yudkowsky&rsquo;s preferred expression - orders of magnitude more intelligent than we are? A canonical thought experiment devised by Oxford philosopher Nick Bostrom in 2003 suggests that even a mundane, industrial sort of AI might kill us. Bostrom posited a &ldquo;superintelligence whose top goal is the manufacturing of paper-clips.&rdquo; For this AI, known fondly on Less Wrong as Clippy, self-improvement might entail rearranging the atoms in our bodies, and then in the universe - and so we, and everything else, end up as office supplies. Nothing so misanthropic as Skynet is required, only indifference to humanity. What is urgently needed, then, claims Yudkowsky, is an AI that shares our values and goals. This, in turn, requires a cadre of highly rational mathematicians, philosophers, and programmers to solve the problem of &ldquo;friendly&rdquo; AI - and, incidentally, the problem of a universal human ethics - before an indifferent, unfriendly AI escapes into the wild.</p>\n<p>Among those who study artificial intelligence, there&rsquo;s no consensus on either point: that an intelligence explosion is possible (rather than, for instance, a proliferation of weaker, more limited forms of AI) or that a heroic team of rationalists is the best defense in the event. That MIRI has as much support as it does (in 2012, the institute&rsquo;s annual revenue broke $1 million for the first time) is a testament to Yudkowsky&rsquo;s rhetorical ability as much as to any technical skill. Over the course of a decade, his writing, along with that of Bostrom and a handful of others, has impressed the dangers of unfriendly AI on a growing number of people in the tech world and beyond. In August, after reading <em>Superintelligence</em>, Bostrom&rsquo;s new book, Elon Musk tweeted, &ldquo;Hope we&rsquo;re not just the biological boot loader for digital superintelligence. Unfortunately, that is increasingly probable.&rdquo; In 2000, when Yudkowsky was twenty, he founded the Singularity Institute with the support of a few people he&rsquo;d met at the Foresight Institute, a Palo Alto nanotech think tank. He had already written papers on &ldquo;The Plan to Singularity&rdquo; and &ldquo;Coding a Transhuman AI,&rdquo; and posted an autobiography on his website, since removed, called &ldquo;Eliezer, the Person.&rdquo; It recounted a breakdown of will when he was eleven and a half: &ldquo;I can&rsquo;t do anything. That&rsquo;s the phrase I used then.&rdquo; He dropped out before high school and taught himself a mess of evolutionary psychology and cognitive science. He began to &ldquo;neuro-hack&rdquo; himself, systematizing his introspection to evade his cognitive quirks. Yudkowsky believed he could hasten the singularity by twenty years, creating a superhuman intelligence and saving humankind in the process. He met Thiel at a Foresight Institute dinner in 2005 and invited him to speak at the first annual Singularity Summit. The institute&rsquo;s paid staff grew. In 2006, Yudkowsky began writing a hydra-headed series of blog posts: science-fictionish parables, thought experiments, and explainers encompassing cognitive biases, self-improvement, and many-worlds quantum mechanics that funneled lay readers into his theory of friendly AI. Rationality workshops and Meetups began soon after. In 2009, the blog posts became what he called Sequences on a new website: Less Wrong. The next year, Yudkowsky began publishing <em>Harry Potter and the Methods of Rationality</em> at <code>fanfiction.net</code>. The Harry Potter category is the site&rsquo;s most popular, with almost 700,000 stories; of these, HPMoR is the most reviewed and the second-most favorited. The last comment that the programmer and activist Aaron Swartz left on Reddit before his suicide in 2013 was on <code>/r/hpmor</code>. In Yudkowsky&rsquo;s telling, Harry is not only a magician but also a scientist, and he needs just one school year to accomplish what takes canon-Harry seven. HPMoR is serialized in arcs, like a TV show, and runs to a few thousand pages when printed; the book is still unfinished. Yudkowsky and I were talking about literature, and Swartz, when a college student wandered in. Would Eliezer sign his copy of HPMoR? &ldquo;But you have to, like, write something,&rdquo; he said. &ldquo;You have to write, &lsquo;I am who I am.&rsquo; So, &lsquo;I am who I am&rsquo; and then sign it.&rdquo; &ldquo;Alrighty,&rdquo; Yudkowsky said, signed, continued. &ldquo;Have you actually read <em>Methods of Rationality</em> at all?&rdquo; he asked me. &ldquo;I take it not.&rdquo; (I&rsquo;d been found out.) &ldquo;I don&rsquo;t know what sort of a deadline you&rsquo;re on, but you might consider taking a look at that.&rdquo; (I had taken a look, and hated the little I&rsquo;d managed.) &ldquo;It has a legendary nerd-sniping effect on some people, so be warned. That is, it causes you to read it for sixty hours straight.&rdquo;</p>\n<p>The nerd-sniping effect is real enough. Of the 1,636 people who responded to a 2013 survey of Less Wrong&rsquo;s readers, one quarter had found the site thanks to HPMoR, and many more had read the book. Their average age was 27.4, their average IQ 138.2. Men made up 88.8% of respondents; 78.7% were straight, 1.5% transgender, 54.7 % American, 89.3% atheist or agnostic. The catastrophes they thought most likely to wipe out at least 90% of humanity before the year 2100 were, in descending order, pandemic (bioengineered), environmental collapse, unfriendly AI, nuclear war, pandemic (natural), economic/political collapse, asteroid, nanotech/gray goo. Forty-two people, 2.6 %, called themselves futarchists, after an idea from Robin Hanson, an economist and Yudkowsky&rsquo;s former coblogger, for reengineering democracy into a set of prediction markets in which speculators can bet on the best policies. Forty people called themselves reactionaries, a grab bag of former libertarians, ethno-nationalists, Social Darwinists, scientific racists, patriarchists, pickup artists, and atavistic &ldquo;traditionalists,&rdquo; who Internet-argue about antidemocratic futures, plumping variously for fascism or monarchism or corporatism or rule by an all-powerful, gold-seeking alien named Fnargl who will free the markets and stabilize everything else. At the bottom of each year&rsquo;s list are suggestive statistical irrelevancies: &ldquo;every optimizing system&rsquo;s a dictator and i&rsquo;m not sure which one i want in charge,&rdquo; &ldquo;Autocracy (important: myself as autocrat),&rdquo; &ldquo;Bayesian (aspiring) Rationalist. Technocratic. Human-centric Extropian Coherent Extrapolated Volition.&rdquo; &ldquo;Bayesian&rdquo; refers to Bayes&rsquo;s Theorem, a mathematical formula that describes uncertainty in probabilistic terms, telling you how much to update your beliefs when given new information. This is a formalization and calibration of the way we operate naturally, but &ldquo;Bayesian&rdquo; has a special status in the rationalist community because it&rsquo;s the least imperfect way to think. &ldquo;Extropy,&rdquo; the antonym of &ldquo;entropy,&rdquo; is a decades-old doctrine of continuous human improvement, and &ldquo;coherent extrapolated volition&rdquo; is one of Yudkowsky&rsquo;s pet concepts for friendly artificial intelligence. Rather than our having to solve moral philosophy in order to arrive at a complete human goal structure, C.E.V. would computationally simulate eons of moral progress, like some kind of Whiggish Pangloss machine. As Yudkowsky wrote in 2004, &ldquo;In poetic terms, our coherent extrapolated volition is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together.&rdquo; Yet can even a single human&rsquo;s volition cohere or compute in this way, let alone humanity&rsquo;s? We stood up to leave the room. Yudkowsky stopped me and said I might want to turn my recorder on again; he had a final thought. &ldquo;We&rsquo;re part of the continuation of the Enlightenment, the Old Enlightenment. This is the New Enlightenment,&rdquo; he said. &ldquo;Old project&rsquo;s finished. We actually have science now, now we have the next part of the Enlightenment project.&rdquo;</p>\n<p>In 2013, the Singularity Institute changed its name to the Machine Intelligence Research Institute. Whereas MIRI aims to ensure human-friendly artificial intelligence, an associated program, the Center for Applied Rationality, helps humans optimize their own minds, in accordance with Bayes&rsquo;s Theorem. The day after I met Yudkowsky, I returned to Berkeley for one of CFAR&rsquo;s long-weekend workshops. The color scheme at the Rose Garden Inn was red and green, and everything was brocaded. The attendees were mostly in their twenties: mathematicians, software engineers, quants, a scientist studying soot, employees of Google and Facebook, an eighteen-year-old Thiel Fellow who&rsquo;d been paid $100,000 to leave Boston College and start a company, professional atheists, a Mormon turned atheist, an atheist turned Catholic, an Objectivist who was photographed at the premiere of <em>Atlas Shrugged II: The Strike</em>. There were about three men for every woman. At the Friday-night meet and greet, I talked with Benja, a German who was studying math and behavioral biology at the University of Bristol, whom I had spotted at MIRI the day before. He was in his early thirties and quite tall, with bad posture and a ponytail past his shoulders. He wore socks with sandals, and worried a paper cup as we talked. Benja had felt death was terrible since he was a small child, and wanted his aging parents to sign up for cryonics, if he could figure out how to pay for it on a grad-student stipend. He was unsure about the risks from unfriendly AI - &ldquo;There is a part of my brain,&rdquo; he said, &ldquo;that sort of goes, like, &lsquo;This is crazy talk; that&rsquo;s not going to happen&rsquo;&rdquo; - but the probabilities had persuaded him. He said there was only about a 30% chance that we could make it another century without an intelligence explosion. He was at CFAR to stop procrastinating. Julia Galef, CFAR&rsquo;s president and cofounder, began a session on Saturday morning with the first of many brain-as-computer metaphors. We are &ldquo;running rationality on human hardware,&rdquo; she said, not supercomputers, so the goal was to become incrementally more self-reflective and Bayesian: not perfectly rational agents, but &ldquo;agent-y.&rdquo; The workshop&rsquo;s classes lasted six or so hours a day; activities and conversations went well into the night. We got a condensed treatment of contemporary neuroscience that focused on hacking our brains&rsquo; various systems and modules, and attended sessions on habit training, urge propagation, and delegating to future selves. We heard a lot about Daniel Kahneman, the Nobel Prize-winning psychologist whose work on cognitive heuristics and biases demonstrated many of the ways we are irrational. Geoff Anders, the founder of Leverage Research, a &ldquo;meta-level nonprofit&rdquo; funded by Thiel, taught a class on goal factoring, a process of introspection that, after many tens of hours, maps out every one of your goals down to root-level motivations-the unchangeable &ldquo;intrinsic goods,&rdquo; around which you can rebuild your life. Goal factoring is an application of Connection Theory, Anders&rsquo;s model of human psychology, which he developed as a Rutgers philosophy student disserting on Descartes, and Connection Theory is just the start of a universal renovation. Leverage Research has a master plan that, in the most recent public version, consists of nearly 300 steps. It begins from first principles and scales up from there: &ldquo;Initiate a philosophical investigation of philosophical method&rdquo;; &ldquo;Discover a sufficiently good philosophical method&rdquo;; have 2,000-plus &ldquo;actively and stably benevolent people successfully seek enough power to be able to stably guide the world&rdquo;; &ldquo;People achieve their ultimate goals as far as possible without harming others&rdquo;; &ldquo;We have an optimal world&rdquo;; &ldquo;Done.&rdquo; On Saturday night, Anders left the Rose Garden Inn early to supervise a polyphasic-sleep experiment that some Leverage staff members were conducting on themselves. It was a schedule called the Everyman 3, which compresses sleep into three twenty-minute REM naps each day and three hours at night for slow-wave. Anders was already polyphasic himself. Operating by the lights of his own best practices, goal-factored, coherent, and connected, he was able to work 105 hours a week on world optimization. For the rest of us, for me, these were distant aspirations. We were nerdy and unperfected. There was intense discussion at every free moment, and a genuine interest in new ideas, if especially in testable, verifiable ones. There was joy in meeting peers after years of isolation. CFAR was also insular, overhygienic, and witheringly focused on productivity. Almost everyone found politics to be tribal and viscerally upsetting. Discussions quickly turned back to philosophy and math. By Monday afternoon, things were wrapping up. Andrew Critch, a CFAR cofounder, gave a final speech in the lounge: &ldquo;Remember how you got started on this path. Think about what was the time for you when you first asked yourself, &lsquo;How do I work?&rsquo; and &lsquo;How do I want to work?&rsquo; and &lsquo;What can I do about that?&rsquo; . . . Think about how many people throughout history could have had that moment and not been able to do anything about it because they didn&rsquo;t know the stuff we do now. I find this very upsetting to think about. It could have been really hard. A lot harder.&rdquo; He was crying. &ldquo;I kind of want to be grateful that we&rsquo;re now, and we can share this knowledge and stand on the shoulders of giants like Daniel Kahneman . . . I just want to be grateful for that. . . . And because of those giants, the kinds of conversations we can have here now, with, like, psychology and, like, algorithms in the same paragraph, to me it feels like a new frontier. . . . Be explorers; take advantage of this vast new landscape that&rsquo;s been opened up to us in this time and this place; and bear the torch of applied rationality like brave explorers. And then, like, keep in touch by email.&rdquo; The workshop attendees put giant Post-its on the walls expressing the lessons they hoped to take with them. A blue one read RATIONALITY IS SYSTEMATIZED WINNING. Above it, in pink: THERE ARE OTHER PEOPLE WHO THINK LIKE ME. I AM NOT ALONE.</p>\n<p>That night, there was a party. Alumni were invited. Networking was encouraged. Post-its proliferated; one, by the beer cooler, read SLIGHTLY ADDICTIVE. SLIGHTLY MIND-ALTERING. Another, a few feet to the right, over a double stack of bound copies of <em>Harry Potter and the Methods of Rationality</em>: VERY ADDICTIVE. VERY MIND-ALTERING. I talked to one of my roommates, a Google scientist who worked on neural nets. The CFAR workshop was just a whim to him, a tourist weekend. &ldquo;They&rsquo;re the nicest people you&rsquo;d ever meet,&rdquo; he said, but then he qualified the compliment. &ldquo;Look around. If they were effective, rational people, would they be here? Something a little weird, no?&rdquo; I walked outside for air. Michael Vassar, in a clinging red sweater, was talking to an actuary from Florida. They discussed timeless decision theory (approximately: intelligent agents should make decisions on the basis of the futures, or possible worlds, that they predict their decisions will create) and the simulation argument (essentially: we&rsquo;re living in one), which Vassar traced to Schopenhauer. He recited lines from Kipling&rsquo;s &ldquo;If-&rdquo; in no particular order and advised the actuary on how to change his life: Become a pro poker player with the $100k he had in the bank, then hit the Magic: The Gathering pro circuit; make more money; develop more rationality skills; launch the first Costco in Northern Europe. I asked Vassar what was happening at MetaMed. He told me that he was raising money, and was in discussions with a big HMO. He wanted to show up Peter Thiel for not investing more than $500,000. &ldquo;I&rsquo;m basically hoping that I can run the largest convertible-debt offering in the history of finance, and I think it&rsquo;s kind of reasonable,&rdquo; he said. &ldquo;I like Peter. I just would like him to notice that he made a mistake . . . I imagine a hundred million or a billion will cause him to notice . . . I&rsquo;d like to have a pi-billion-dollar valuation.&rdquo; I wondered whether Vassar was drunk. He was about to drive one of his coworkers, a young woman named Alyssa, home, and he asked whether I would join them. I sat silently in the back of his musty BMW as they talked about potential investors and hires. Vassar almost ran a red light. After Alyssa got out, I rode shotgun, and we headed back to the hotel.</p>\n<p>It was getting late. I asked him about the rationalist community. Were they really going to save the world? From what? &ldquo;Imagine there is a set of skills,&rdquo; he said. &ldquo;There is a myth that they are possessed by the whole population, and there is a cynical myth that they&rsquo;re possessed by 10% of the population. They&rsquo;ve actually been wiped out in all but about one person in three thousand.&rdquo; It is important, Vassar said, that his people, &ldquo;the fragments of the world,&rdquo; lead the way during &ldquo;the fairly predictable, fairly total cultural transition that will predictably take place between 2020 and 2035 or so.&rdquo; We pulled up outside the Rose Garden Inn. He continued: &ldquo;You have these weird phenomena like Occupy where people are protesting with no goals, no theory of how the world is, around which they can structure a protest. Basically this incredibly, weirdly, thoroughly disempowered group of people will have to inherit the power of the world anyway, because sooner or later everyone older is going to be too old and too technologically obsolete and too bankrupt. The old institutions may largely break down or they may be handed over, but either way they can&rsquo;t just freeze. These people are going to be in charge, and it would be helpful if they, as they come into their own, crystallize an identity that contains certain cultural strengths like argument and reason.&rdquo; I didn&rsquo;t argue with him, except to press, gently, on his particular form of elitism. His rationalism seemed so limited to me, so incomplete. &ldquo;It is unfortunate,&rdquo; he said, &ldquo;that we are in a situation where our cultural heritage is possessed only by people who are extremely unappealing to most of the population.&rdquo; That hadn&rsquo;t been what I&rsquo;d meant. I had meant rationalism as itself a failure of the imagination. &ldquo;The current ecosystem is so totally fucked up,&rdquo; Vassar said. &ldquo;But if you have conversations here&rdquo;-he gestured at the hotel-&ldquo;people change their mind and learn and update and change their behaviors in response to the things they say and learn. That never happens anywhere else.&rdquo; In a hallway of the Rose Garden Inn, a former high-frequency trader started arguing with Vassar and Anna Salamon, CFAR&rsquo;s executive director, about whether people optimize for hedons or utilons or neither, about mountain climbers and other high-end masochists, about whether world happiness is currently net positive or negative, increasing or decreasing. Vassar was eating and drinking everything within reach. My recording ends with someone saying, &ldquo;I just heard &lsquo;hedons&rsquo; and then was going to ask whether anyone wants to get high,&rdquo; and Vassar replying, &ldquo;Ah, that&rsquo;s a good point.&rdquo; Other voices: &ldquo;When in California . . .&rdquo; &ldquo;We are in California, yes.&rdquo;</p>\n<p>&hellip;Back on the East Coast, summer turned into fall, and I took another shot at reading Yudkowsky&rsquo;s Harry Potter fanfic. It&rsquo;s not what I would call a novel, exactly, rather an unending, self-satisfied parable about rationality and trans-humanism, with jokes.</p>\n<p>&hellip;I flew back to San Francisco, and my friend Courtney and I drove to a cul-de-sac in Atherton, at the end of which sat the promised mansion. It had been repurposed as cohousing for children who were trying to build the future: start-up founders, singularitarians, a teenage venture capitalist. The woman who coined the term &ldquo;open source&rdquo; was there, along with a Less Wronger and Thiel Capital employee who had renamed himself Eden. The Day of the Idealist was a day for self-actualization and networking, like the CFAR workshop without the rigor. We were to set &ldquo;mega goals&rdquo; and pick a &ldquo;core good&rdquo; to build on in the coming year. Everyone was a capitalist; everyone was postpolitical. I squabbled with a young man in a Tesla jacket about anti-Google activism. No one has a right to housing, he said; programmers are the people who matter; the protesters&rsquo; antagonistic tactics had totally discredited them.</p>\n<p>&hellip;Thiel and Vassar and Yudkowsky, for all their far-out rhetoric, take it on faith that corporate capitalism, unchecked just a little longer, will bring about this era of widespread abundance. Progress, Thiel thinks, is threatened mostly by the political power of what he calls the &ldquo;unthinking demos.&rdquo;</p>\n</blockquote>\n<hr />\n<p>Pointer thanks to <a href=\"/user/Vulture/\">/u/Vulture</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"X7v7Fyp9cgBYaMe2e": 2, "NrvXXL3iGjjxu5B7d": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pfHrgwZi38GBckzFL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 48, "baseScore": 76, "extendedScore": null, "score": 0.000229, "legacy": true, "legacyId": "27715", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 76, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 154, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-12T22:38:37.402Z", "modifiedAt": null, "url": null, "title": "Approval-directed agents", "slug": "approval-directed-agents", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.034Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AN7oykWXzT2dRzYkS/approval-directed-agents", "pageUrlRelative": "/posts/AN7oykWXzT2dRzYkS/approval-directed-agents", "linkUrl": "https://www.lesswrong.com/posts/AN7oykWXzT2dRzYkS/approval-directed-agents", "postedAtFormatted": "Friday, December 12th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Approval-directed%20agents&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApproval-directed%20agents%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAN7oykWXzT2dRzYkS%2Fapproval-directed-agents%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Approval-directed%20agents%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAN7oykWXzT2dRzYkS%2Fapproval-directed-agents", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAN7oykWXzT2dRzYkS%2Fapproval-directed-agents", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<p><span style=\"font-size: 17.3333339691162px; line-height: 23.3999996185303px;\"><span style=\"font-family: mceinline;\">Most concern about AI comes down to the scariness of goal-oriented behavior. A common response to such concerns is &ldquo;why would we give an AI goals anyway?&rdquo; I think there are good reasons to expect goal-oriented behavior, and I&rsquo;ve been on that side of a lot of arguments. But I don&rsquo;t think the issue is settled, and it might be possible to get better outcomes without them. I flesh out one possible alternative <a href=\"https://medium.com/@paulfchristiano/model-free-decisions-6e6609f5d99e\">here</a>, based on the dictum \"take the action I would like best\" rather than \"achieve the outcome I would like best.\"</span></span></p>\n<p><span style=\"font-size: 17.3333339691162px; line-height: 23.3999996185303px;\"><span style=\"font-family: mceinline;\">(As an experiment I wrote the post on medium, so that it is easier to provide sentence-level feedback, especially feedback on writing or low-level comments.)</span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AN7oykWXzT2dRzYkS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 15, "extendedScore": null, "score": 2.2620899995755565e-06, "legacy": true, "legacyId": "27716", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-13T00:33:50.516Z", "modifiedAt": null, "url": null, "title": "A forum for researchers to publicly discuss safety issues in advanced AI", "slug": "a-forum-for-researchers-to-publicly-discuss-safety-issues-in", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:00.585Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobbBB", "createdAt": "2012-08-10T00:50:11.669Z", "isAdmin": true, "displayName": "Rob Bensinger"}, "userId": "2aoRX3ookcCozcb3m", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B8FSAGHRJoP5qeEtj/a-forum-for-researchers-to-publicly-discuss-safety-issues-in", "pageUrlRelative": "/posts/B8FSAGHRJoP5qeEtj/a-forum-for-researchers-to-publicly-discuss-safety-issues-in", "linkUrl": "https://www.lesswrong.com/posts/B8FSAGHRJoP5qeEtj/a-forum-for-researchers-to-publicly-discuss-safety-issues-in", "postedAtFormatted": "Saturday, December 13th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20forum%20for%20researchers%20to%20publicly%20discuss%20safety%20issues%20in%20advanced%20AI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20forum%20for%20researchers%20to%20publicly%20discuss%20safety%20issues%20in%20advanced%20AI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB8FSAGHRJoP5qeEtj%2Fa-forum-for-researchers-to-publicly-discuss-safety-issues-in%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20forum%20for%20researchers%20to%20publicly%20discuss%20safety%20issues%20in%20advanced%20AI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB8FSAGHRJoP5qeEtj%2Fa-forum-for-researchers-to-publicly-discuss-safety-issues-in", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB8FSAGHRJoP5qeEtj%2Fa-forum-for-researchers-to-publicly-discuss-safety-issues-in", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 398, "htmlBody": "<p>MIRI has an organizational goal of putting a wider variety of mathematically proficient people in a position to advance our understanding of beneficial smarter-than-human AI. The <a href=\"http://intelligence.org/mirix/\">MIRIx workshops</a>, our new <a href=\"http://intelligence.org/research-guide/\">research guide</a>, and our more detailed in-the-works technical agenda are intended to further that goal.</p>\n<p>To encourage the growth of a larger research community where people can easily collaborate and get up to speed on each other's new ideas, we're also going to roll out an <strong>online discussion forum</strong> that's specifically focused on resolving technical problems in Friendly AI. MIRI researchers and other interested parties will be able to have more open exchanges there, and get rapid feedback on their ideas and drafts. A relatively small group of people with relevant mathematical backgrounds will be authorized to post on the forum, but all discussion on the site will be publicly visible to visitors.</p>\n<p>Topics will run the gamut from&nbsp;<a href=\"http://intelligence.org/2014/06/23/new-report-non-omniscience-probabilistic-inference-metamathematics/\">logical uncertainty in formal agents</a>&nbsp;to&nbsp;<a href=\"http://intelligence.org/files/ConceptLearning.pdf\">cognitive models of concept generation</a>.&nbsp;The exact range of discussion topics is likely to evolve over time as researchers' priorities change and new researchers join the forum.</p>\n<p>We're currently tossing around possible names for the forum, and I wanted to solicit LessWrong's input, since you've been helpful here in the past. (We're also getting input from non-LW mathematicians and computer scientists.) We want to know how confusing, apt, etc. you perceive these variants on 'forum for doing <a href=\"http://intelligence.org/2014/08/22/new-paper-exploratory-engineering-artificial-intelligence/\">exploratory engineering</a> research in AI' to be:</p>\n<p style=\"padding-left: 30px;\">1. AI Exploratory Research Forum (AIXRF)</p>\n<p style=\"padding-left: 30px;\">2. Forum for Exploratory Engineering in AI (FEEAI)</p>\n<p style=\"padding-left: 30px;\">3. Forum for Exploratory Research in AI (FERAI, or FXRAI)</p>\n<p style=\"padding-left: 30px;\">4. Exploratory AI Research Forum (XAIRF, or EAIRF)</p>\n<p>We're also looking at other name possibilities, including:</p>\n<p style=\"padding-left: 30px;\">5. AI Foundations Forum (AIFF)</p>\n<p style=\"padding-left: 30px;\">6. Intelligent Agent Foundations Forum (IAFF)</p>\n<p style=\"padding-left: 30px;\">7. Reflective Agents Research Forum (RARF)</p>\n<p>We're trying to avoid names like \"<a href=\"http://lukemuehlhauser.com/some-alternatives-to-friendly-ai/\">friendly</a>\" and \"normative\" that could reinforce someone's impression that we think of AI risk in anthropomorphic terms, that we're AI-hating technophobes, or that we're moral philosophers.</p>\n<p>Feedback on the above ideas is welcome, as are new ideas.&nbsp;Feel free to post separate ideas in separate comments, so they can be upvoted individually. We're especially looking for feedback along the lines of:&nbsp;<em>'I'm a grad student in theoretical computer science and I feel that the name </em>[X]<em> would look bad in a comp sci bibliography or C.V.'</em>&nbsp;or&nbsp;<em>'I'm friends with a lot of topologists, and I'm pretty sure they'd find the name </em>[Y]<em> unobjectionable and mildly intriguing; I don't know how well that generalizes to mathematical logicians.'</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B8FSAGHRJoP5qeEtj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 21, "extendedScore": null, "score": 2.2623465561726277e-06, "legacy": true, "legacyId": "27717", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 73, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-13T06:01:31.965Z", "modifiedAt": null, "url": null, "title": "[Resolved] Is the SIA doomsday argument wrong?", "slug": "resolved-is-the-sia-doomsday-argument-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:37.476Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Brian_Tomasik", "createdAt": "2013-06-08T20:34:53.353Z", "isAdmin": false, "displayName": "Brian_Tomasik"}, "userId": "6XzBgrHtBL4M7CpKL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hra94memmyYdNwMSZ/resolved-is-the-sia-doomsday-argument-wrong", "pageUrlRelative": "/posts/hra94memmyYdNwMSZ/resolved-is-the-sia-doomsday-argument-wrong", "linkUrl": "https://www.lesswrong.com/posts/hra94memmyYdNwMSZ/resolved-is-the-sia-doomsday-argument-wrong", "postedAtFormatted": "Saturday, December 13th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BResolved%5D%20Is%20the%20SIA%20doomsday%20argument%20wrong%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BResolved%5D%20Is%20the%20SIA%20doomsday%20argument%20wrong%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhra94memmyYdNwMSZ%2Fresolved-is-the-sia-doomsday-argument-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BResolved%5D%20Is%20the%20SIA%20doomsday%20argument%20wrong%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhra94memmyYdNwMSZ%2Fresolved-is-the-sia-doomsday-argument-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhra94memmyYdNwMSZ%2Fresolved-is-the-sia-doomsday-argument-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 586, "htmlBody": "<p>[EDIT: I think the SIA doomsday argument works after all, and my objection to it was based on framing the problem in a misguided way. Feel free to ignore this post or skip to the resolution at the end.]</p>\n<p>ORIGINAL POST:</p>\n<p>Katja Grace <a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption_Doomsday_argument_rebuttal#SIA.27s_own_doomsday_argument\">has developed</a> a kind of doomsday argument from <a href=\"http://en.wikipedia.org/wiki/Self-indication_assumption\">SIA</a>&nbsp;combined with the <a href=\"https://en.wikipedia.org/wiki/Great_Filter\">Great Filter</a>. It has been discussed by <a href=\"http://www.overcomingbias.com/2010/03/very-bad-news.html\">Robin Hanson</a>,&nbsp;<a title=\"p. 10\" href=\"http://www.nickbostrom.com/aievolution.pdf\">Carl Shulman, and Nick Bostrom</a>. The basic idea is that if the filter comes late, there are more civilizations with organisms like us than if the filter comes early, and more organisms in positions like ours means a higher expected number of (non-fake) experiences that match ours. (I'll ignore simulation-argument possibilities in this post.)</p>\n<p>I used to agree with this reasoning. But now I'm not sure, and here's why. Your subjective experience, broadly construed, includes knowledge of a lot of Earth's history and current state, including when life evolved, which creatures evolved, the Earth's mass and distance from the sun, the chemical composition of the soil and atmosphere, and so on. The information that you know about your planet is sufficient to uniquely locate you within the observable universe. Sure, there might be exact copies of you in vastly distant Hubble volumes, and there might be many approximate copies of Earth in somewhat nearer Hubble volumes. But within any reasonable radius, probably what you know about Earth requires that your subjective experiences (if veridical) could only take place on Earth, not on any other planet in our Hubble volume.</p>\n<p>If so, then whether there are lots of human-level extraterrestrials (ETs) or none doesn't matter anthropically, because none of those ETs within any reasonable radius could contain your exact experiences. No matter how hard or easy the emergence of human-like life is in general, it <em>can</em> happen on Earth, and your subjective experiences can only exist on Earth (or some planet almost identical to Earth).</p>\n<p>A better way to think about SIA is that it favors hypotheses containing more copies of our Hubble volume within the larger universe. Within a given Hubble volume, there can be at most one location where organisms veridically perceive what we perceive.</p>\n<p>Katja's&nbsp;<a href=\"http://meteuphoric.wordpress.com/2010/03/23/sia-doomsday-the-filter-is-ahead/\">blog post</a>&nbsp;on the SIA doomsday draws orange boxes with humans waving their hands. She has us update on knowing we're in the human-level stage, i.e., that we're one of those orange boxes. But we know much more: We know that we're a particular one of those boxes, which is easily distinguished from the others based on what we observe about the world. So any hypothesis that contains us at all will have the same number of boxes containing&nbsp;us&nbsp;(namely, just one box). Hence, no anthropic update.</p>\n<p>Am I missing something? :)</p>\n<p>&nbsp;</p>\n<p>RESOLUTION:</p>\n<p>The problem with my argument was that I compared the hypothesis \"filter is early and you exist on Earth\" against \"filter is late and you exist on Earth\". If the hypotheses already say that you exist on Earth, then there's no more anthropic work to be done. But the heart of the anthropic question is whether an early or late filter predicts that you exist on Earth at all.</p>\n<p>Here's an oversimplified example. Suppose that the hypothesis of \"early filter\" tells us that there are four planets, exactly one of which contains life. \"Late filter\" says there are four planets, all of which contain life. Suppose for convenience that if life exists on Earth at all, you will exist on Earth. Then P(you exist | early filter) = 1/4 while P(you exist | late filter) = 1. This is where the doomsday update comes from.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hra94memmyYdNwMSZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 10, "extendedScore": null, "score": 4e-05, "legacy": true, "legacyId": "27718", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-13T08:42:33.897Z", "modifiedAt": null, "url": null, "title": "Meetup : Urbana-Champaign: Finishing Up", "slug": "meetup-urbana-champaign-finishing-up", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EEagRivGG9DYydJey/meetup-urbana-champaign-finishing-up", "pageUrlRelative": "/posts/EEagRivGG9DYydJey/meetup-urbana-champaign-finishing-up", "linkUrl": "https://www.lesswrong.com/posts/EEagRivGG9DYydJey/meetup-urbana-champaign-finishing-up", "postedAtFormatted": "Saturday, December 13th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Urbana-Champaign%3A%20Finishing%20Up&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Urbana-Champaign%3A%20Finishing%20Up%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEEagRivGG9DYydJey%2Fmeetup-urbana-champaign-finishing-up%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Urbana-Champaign%3A%20Finishing%20Up%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEEagRivGG9DYydJey%2Fmeetup-urbana-champaign-finishing-up", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEEagRivGG9DYydJey%2Fmeetup-urbana-champaign-finishing-up", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 57, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/17z'>Urbana-Champaign: Finishing Up</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">14 December 2014 02:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">206 S. Cedar St, Urbana, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is likely the last meetup of the semester. So let's try and look back on the past and collect some reminders of things that might be useful.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/17z'>Urbana-Champaign: Finishing Up</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EEagRivGG9DYydJey", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.2634353659628466e-06, "legacy": true, "legacyId": "27719", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Urbana_Champaign__Finishing_Up\">Discussion article for the meetup : <a href=\"/meetups/17z\">Urbana-Champaign: Finishing Up</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">14 December 2014 02:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">206 S. Cedar St, Urbana, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is likely the last meetup of the semester. So let's try and look back on the past and collect some reminders of things that might be useful.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Urbana_Champaign__Finishing_Up1\">Discussion article for the meetup : <a href=\"/meetups/17z\">Urbana-Champaign: Finishing Up</a></h2>", "sections": [{"title": "Discussion article for the meetup : Urbana-Champaign: Finishing Up", "anchor": "Discussion_article_for_the_meetup___Urbana_Champaign__Finishing_Up", "level": 1}, {"title": "Discussion article for the meetup : Urbana-Champaign: Finishing Up", "anchor": "Discussion_article_for_the_meetup___Urbana_Champaign__Finishing_Up1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-13T12:08:44.000Z", "modifiedAt": null, "url": null, "title": "Debunked And Well-Refuted", "slug": "debunked-and-well-refuted", "viewCount": null, "lastCommentedAt": "2021-06-17T01:56:27.656Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kdmCm5NQTpqhJmGm6/debunked-and-well-refuted", "pageUrlRelative": "/posts/kdmCm5NQTpqhJmGm6/debunked-and-well-refuted", "linkUrl": "https://www.lesswrong.com/posts/kdmCm5NQTpqhJmGm6/debunked-and-well-refuted", "postedAtFormatted": "Saturday, December 13th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Debunked%20And%20Well-Refuted&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADebunked%20And%20Well-Refuted%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkdmCm5NQTpqhJmGm6%2Fdebunked-and-well-refuted%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Debunked%20And%20Well-Refuted%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkdmCm5NQTpqhJmGm6%2Fdebunked-and-well-refuted", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkdmCm5NQTpqhJmGm6%2Fdebunked-and-well-refuted", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1878, "htmlBody": "<p><b>I.</b></p>\n<p>As usual, I was insufficiently pessimistic.</p>\n<p>I infer this from <i>The Federalist</i>&#8216;s <A HREF=\"http://thefederalist.com/2014/12/11/new-doj-data-on-sexual-assaults-college-students-are-actually-less-likely-to-be-victimized/\">article on campus rape</A>:</p>\n<blockquote><p>A new report on sexual assault released today by the U.S. Department of Justice (DOJ) officially puts to bed the bogus statistic that one in five women on college campuses are victims of sexual assault. In fact, non-students are 25 percent more likely to be victims of sexual assault than students, according to the data. And the real number of assault victims is several orders of magnitude lower than one-in-five.</p></blockquote>\n<p>The article compares the older Campus Sexual Assault Survey (which found 14-20% of women were raped since entering college) to the just-released National Crime Victmization Survey (which found that 0.6% of female college students are raped per year). They write &#8220;Instead of 1 in 5, the real number is 0.03 in 5.&#8221;</p>\n<p>So the first thing I will mock <i>The Federalist</i> for doing is directly comparing per year sexual assault rates to per college career sexual assault rates, whereas obviously these are very different things. You can&#8217;t <i>quite</i> just divide the latter by four to get the former, but that&#8217;s going to work a heck of a lot better than <i>not</i> doing it, so let&#8217;s estimate the real discrepancy as more like 0.5% per year versus 5% per year. </p>\n<p>But I can&#8217;t get too mad at them yet, because that&#8217;s still a pretty big discrepancy.</p>\n<p><i>However,</i> faced with this discrepancy a reasonable person might say &#8220;Hmm, we have two different studies that say two different things. I wonder what&#8217;s going on here and which study we should believe?&#8221;</p>\n<p><i>The Federalist</i> staff said &#8220;Ha! There&#8217;s an old study with findings we didn&#8217;t like, but now there&#8217;s a new study with different findings we <i>do</i> like. So the old study is debunked!&#8221;</p>\n<p><b>II.</b></p>\n<p>My last essay, <A HREF=\"http://slatestarcodex.com/2014/12/12/beware-the-man-of-one-study/\">Beware The Man Of One Study</A>, noted that one thing partisans do to justify their bias is selectively acknowledge studies from only one side of a complicated literature.</p>\n<p>The reason it was insufficiently pessimistic is that there are also people like the Federalist staff, who acknowledge the existence of opposing studies, but only with the adjective &#8220;debunked&#8221; in front of them. By &#8220;debunked&#8221; they usually mean one of two things:</p>\n<p>1. Someone on my side published a study later that found something else<br />\n2. Someone on my side accused it of having methodological flaws</p>\n<p>Since the Federalist has so amply demonstrated the first failure mode, let me say a little more about the second. Did you know that <i>anyone</i> with a keyboard can just <i>type up</i> any of the following things?</p>\n<p>&#8211; &#8220;That study is a piece of garbage that&#8217;s not worth the paper it&#8217;s written on.&#8221;<br />\n&#8211; &#8220;People in the know dismissed that study years ago.&#8221;<br />\n&#8211; &#8220;Nobody in the field takes that study seriously.&#8221;<br />\n&#8211; &#8220;That study uses methods that are laughable to anybody who knows statistics.&#8221;<br />\n&#8211; &#8220;All the other research that has come out since discredits that study.&#8221;</p>\n<p>They can say these things <i>whether they are true or not</i>. I&#8217;m kind of harping on this point, but it&#8217;s because it&#8217;s something <i>I</i> didn&#8217;t realize until much later than I should have.</p>\n<p>There are many &#8220;questions&#8221; that are pretty much settled &#8211; evolution, global warming, homeopathy. But taking these as representative <A HREF=\"http://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/\">closes your mind</A> and gives you a skewed picture of academia. On many issues, academics are just as divided as anyone else, and their arguments can be just as acrimonious as anyone else&#8217;s. The arguments usually take the form of one side publishing a study, the other side ripping the study apart and publishing their own study which they say is better, and the first side ripping the second study apart and arguing that their study was better all along.</p>\n<p>Every study has flaws. No study has perfect methodology. If you like a study, you can say that it did the best it could on a difficult research area and has improved upon even-worse predecessor studies. If you don&#8217;t like a study, you can say &#8220;LOOK AT THESE FLAWS THESE PEOPLE ARE IDIOTS THE CONCLUSION IS COMPLETELY INVALID&#8221;. All you need to do is make enough <A HREF=\"http://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/\">isolated demands for rigor</A> against anything you disagree with.</p>\n<p>And so if the first level of confirmation bias is believing every study that supports your views, the second layer of confirmation bias is believing every supposed refutation that supports your views.</p>\n<p>There are certainly things that have been &#8220;well-refuted&#8221; and &#8220;debunked&#8221;. Andrew Wakefield&#8217;s study purporting to prove that vaccines cause autism is a pretty good example. But you will notice that it had multiple failed replications, journals published reports showing he falsified data, the study&#8217;s co-authors retracted their support, the journal it was published in retracted it and issued an apology, the General Medical Council convicted Wakefield of sixteen counts of misconduct, and Wakefield was stripped of his medical license and barred from practicing medicine ever again in the UK. The <i>British Medical Journal</i>, one of the best-respected medical journals in the world, published an editorial concluding:</p>\n<blockquote><p>Clear evidence of falsification of data should now close the door on this damaging vaccine scare &#8230; Who perpetrated this fraud? There is no doubt that it was Wakefield. Is it possible that he was wrong, but not dishonest: that he was so incompetent that he was unable to fairly describe the project, or to report even one of the 12 children&#8217;s cases accurately? No.</p></blockquote>\n<p>Wakefield&#8217;s study has been &#8220;refuted&#8221;. The rape study has been &#8220;argued against&#8221;.</p>\n<p><b>III.</b></p>\n<p>I saw this same dynamic at work the other day, looking through the minimum wage literature. </p>\n<p>The primordial titanomachy of the minimum wage literature goes like this. In 1994, two guys named Card and Krueger published a study showing the minimum wage had if anything positive effects on New Jersey restaurants, convincing many people that minimum wages were good. In 1996, two guys named Neumark and Wascher reanalyzed the New Jersey data using a different source and found that it showed the minimum wage had very bad effects on New Jersey restaurants. In 2000, Card and Krueger responded, saying that their analysis was better than Neumark and Wascher&#8217;s re-analysis, and also they had done a re-analysis of their own which confirmed their original position.</p>\n<p>Let&#8217;s see how conservative sites present this picture:</p>\n<p><i>&#8220;The support for this assertion is the oft-cited 1994 study by Card and Krueger showing a positive correlation between an increased minimum wage and employment in New Jersey. Many others have thoroughly debunked this study.&#8221;</i> (<A HREF=\"http://mises.org/library/welfare-minimum-wages-and-unemployment\">source</A>)</p>\n<p><i>&#8220;I was under the impression that the original study done by Card and Krueger had been thoroughly debunked by Michigan State University economist David Neumark and William Wascher&#8221;</i> (<A HREF=\"http://www.amatecon.com/blog/2002_08_04_archive.html\">source</A>)</p>\n<p><i>&#8220;The study &#8230; by Card and Krueger has been debunked by several different people several different times. When other researchers re-evaluated the study, they found that data collected using those records &#8216;lead to the opposite conclusion from that reached by&#8217; Card and Krueger.&#8221;</i> (<A HREF=\"http://being-classical-liberal.blogspot.com/2014/02/john-green-is-heroon-left.html\">source</A>)</p>\n<p><i>&#8220;It was only a short time before the fantastic Card-Krueger findings were challenged and debunked by several subsequent studies&#8230;in 1995, economists David Neumark and David Wascher used actual payroll records (instead of survey data used by Card and Krueger) and published their results in an NBER paper with an amazing finding: Demand curves for unskilled labor really do slope downward, confirming 200 years of economic theory and mountains of empirical evidence</i> (<A HREF=\"http://www.aei.org/publication/obamas-chief-econ-adviser-once-made-an-amazing-discovery-demand-curves-slope-upward/print/\">source</A>)</p>\n<p>And now let&#8217;s look at how lefty sites present this picture:</p>\n<p><i>&#8220;&#8230;a long-debunked paper [by Neumark and Wascher]&#8221;</i> (<A HREF=\"http://politicalhotwire.com/economics/88594-%2410-minimum-wage-would-push-more-than-half-working-poor-out-poverty-78.html#post2600348\">source</A>)</p>\n<p><i>&#8220;Note that your Mises heroes, Neumark and Wascher are roundly debunked.&#8221;</i> (<A HREF=\"http://www.politics.ie/forum/economy/199017-should-minimum-wage-rates-abolished-10.html\">source</A>)</p>\n<p><i>&#8220;Neumark&#8217;s living wage and minimum wage research have been found to be seriously flawed&#8230;based on faulty methods which when corrected refute his conclusion.&#8221;</i> &#8211; (<A HREF=\"http://www.nelp.org/page/-/Justice/2010/AnalysisofNewYorkCityWageStudyTeam.pdf?nocdn=1\">source</A>)</p>\n<p><i>&#8220;&#8230;Neumark and Wascher, a study which Elizabeth Warren debunked in a Senate hearing&#8221;</i> (<A HREF=\"http://community.runnersworld.com/topic/the-recovery?reply=55902332404903103#55902332404903103\n\">source</A>)</p>\n<p>So if you&#8217;re conservative, Neumark and Wascher debunked Card and Krueger. But if you&#8217;re liberal, Card and Krueger debunked Neumark and Wascher.</p>\n<p>Both sides are no doubt very pleased with themselves. They&#8217;re not men of one study. They look at <i>all</i> of the research &#8211; except of course the studies that have been &#8220;debunked&#8221; or &#8220;well-refuted&#8221;. Why would you waste your time with <i>those?</i></p>\n<p><b>IV.</b></p>\n<p>Once again, I&#8217;m not preaching radical skepticism.</p>\n<p>First of all, some studies are <i>super-debunked</i>. Wakefield is a good example.</p>\n<p>Second of all, some studies that don&#8217;t quite meet Wakefield-level of awfulness are indeed really bad and need refuting. I don&#8217;t think this is beyond the intellectual capacities of most people. I think in many cases it&#8217;s easy to understand why a study is wrong, you should try to do that, and once you do it you can safely discount the results of the study.</p>\n<p>I&#8217;m not against pointing out when you disagree with studies or think they&#8217;re flawed. I&#8217;d be a giant hypocrite if I was.</p>\n<p>But &#8220;debunked&#8221; and &#8220;refuted&#8221; aren&#8217;t saying you disagree with a study. They&#8217;re making arguments from authority. They&#8217;re saying &#8220;the authority of the scientific community has come together and said this is a piece of crap that doesn&#8217;t count&#8221;.</p>\n<p>And that&#8217;s fine if that&#8217;s actually happened. But you had better make sure that you&#8217;re calling upon an ex cathedra statement by the community itself, and not a single guy with an axe to grind. Or one side of a complicated an interminable debate where both sides have about equal credentials and sway.</p>\n<p>If you can&#8217;t do that, you say &#8220;I think that my side of the academic debate is in the right, and here&#8217;s why,&#8221; not &#8220;your side has been debunked&#8221;. </p>\n<p>Otherwise you&#8217;re going to end up like the minimum wage debaters, where both sides claim to have debunked the other. Or like the Federalist article that says a study has been &#8220;put to bed&#8221; as &#8220;bogus&#8221; just because another study said something different.</p>\n<p>I think this is part of my reply to <A HREF=\"http://slatestarcodex.com/2014/11/27/why-i-am-not-rene-descartes/\">the claim that</A> empiricism is so great that no one needs rationality.</p>\n<p>A naive empiricist who swears off critical thinking because they can just &#8220;follow the evidence&#8221; has no contingency plan for when the evidence gets confusing. Their only recourse is to deny that the evidence is confusing, to assert that one side or the other has been &#8220;debunked&#8221;. Since they&#8217;ve already made a principled decision not to study confirmation bias, chances are it&#8217;s going to be whichever side they don&#8217;t like that&#8217;s &#8220;already been debunked&#8221;. And by &#8220;debunked&#8221; they mean &#8220;a scientist on my side said it was wrong, so now I am relieved from the burden of thinking about it.&#8221;</p>\n<p>On the original post, I wrote:</p>\n<blockquote><p>Life is made up of limited, confusing, contradictory, and maliciously doctored facts. Anyone who says otherwise is either sticking to such incredibly easy solved problems that they never encounter anything outside their comfort level, or so closed-minded that they shut out any evidence that challenges their beliefs.</p></blockquote>\n<p>In the absence of any actual debunking more damning than a counterargument, &#8220;that&#8217;s been debunked&#8221; is the way &#8220;shuts out any evidence that challenges their beliefs&#8221; feels from the inside.</p>\n<p><b>V.</b></p>\n<p>Somebody&#8217;s going to want to know what&#8217;s up with the original rape studies. The answer is that a small part of the discrepancy is response bias on the CSAS, but most of it is that the two surveys encourage respondents to define &#8220;sexual assault&#8221; in very different ways. Vox has <A HREF=\"http://www.vox.com/2014/12/11/7378271/why-some-studies-make-campus-rape-look-like-an-epidemic-while-others\">an excellent article on this</A> which for once I 100% endorse.</p>\n<p>In other words, both are valid, both come together to form a more nuanced picture of campus violence, and neither one &#8220;debunks&#8221; the other.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AHK82ypfxF45rqh9D": 5, "bh7uxTTqmsQ8jZJdB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kdmCm5NQTpqhJmGm6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 31, "extendedScore": null, "score": 9.2e-05, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "BQBqPowfxjvoee8jw", "canonicalCollectionSlug": "codex", "canonicalBookId": "YhQ39PPHNrRCgYXcs", "canonicalNextPostSlug": "noisy-poll-results-and-reptilian-muslim-climatologists-from", "canonicalPrevPostSlug": "beware-the-man-of-one-study", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><b id=\"I_\">I.</b></p>\n<p>As usual, I was insufficiently pessimistic.</p>\n<p>I infer this from <i>The Federalist</i>\u2018s <a href=\"http://thefederalist.com/2014/12/11/new-doj-data-on-sexual-assaults-college-students-are-actually-less-likely-to-be-victimized/\">article on campus rape</a>:</p>\n<blockquote><p>A new report on sexual assault released today by the U.S. Department of Justice (DOJ) officially puts to bed the bogus statistic that one in five women on college campuses are victims of sexual assault. In fact, non-students are 25 percent more likely to be victims of sexual assault than students, according to the data. And the real number of assault victims is several orders of magnitude lower than one-in-five.</p></blockquote>\n<p>The article compares the older Campus Sexual Assault Survey (which found 14-20% of women were raped since entering college) to the just-released National Crime Victmization Survey (which found that 0.6% of female college students are raped per year). They write \u201cInstead of 1 in 5, the real number is 0.03 in 5.\u201d</p>\n<p>So the first thing I will mock <i>The Federalist</i> for doing is directly comparing per year sexual assault rates to per college career sexual assault rates, whereas obviously these are very different things. You can\u2019t <i>quite</i> just divide the latter by four to get the former, but that\u2019s going to work a heck of a lot better than <i>not</i> doing it, so let\u2019s estimate the real discrepancy as more like 0.5% per year versus 5% per year. </p>\n<p>But I can\u2019t get too mad at them yet, because that\u2019s still a pretty big discrepancy.</p>\n<p><i>However,</i> faced with this discrepancy a reasonable person might say \u201cHmm, we have two different studies that say two different things. I wonder what\u2019s going on here and which study we should believe?\u201d</p>\n<p><i>The Federalist</i> staff said \u201cHa! There\u2019s an old study with findings we didn\u2019t like, but now there\u2019s a new study with different findings we <i>do</i> like. So the old study is debunked!\u201d</p>\n<p><b id=\"II_\">II.</b></p>\n<p>My last essay, <a href=\"http://slatestarcodex.com/2014/12/12/beware-the-man-of-one-study/\">Beware The Man Of One Study</a>, noted that one thing partisans do to justify their bias is selectively acknowledge studies from only one side of a complicated literature.</p>\n<p>The reason it was insufficiently pessimistic is that there are also people like the Federalist staff, who acknowledge the existence of opposing studies, but only with the adjective \u201cdebunked\u201d in front of them. By \u201cdebunked\u201d they usually mean one of two things:</p>\n<p>1. Someone on my side published a study later that found something else<br>\n2. Someone on my side accused it of having methodological flaws</p>\n<p>Since the Federalist has so amply demonstrated the first failure mode, let me say a little more about the second. Did you know that <i>anyone</i> with a keyboard can just <i>type up</i> any of the following things?</p>\n<p>\u2013 \u201cThat study is a piece of garbage that\u2019s not worth the paper it\u2019s written on.\u201d<br>\n\u2013 \u201cPeople in the know dismissed that study years ago.\u201d<br>\n\u2013 \u201cNobody in the field takes that study seriously.\u201d<br>\n\u2013 \u201cThat study uses methods that are laughable to anybody who knows statistics.\u201d<br>\n\u2013 \u201cAll the other research that has come out since discredits that study.\u201d</p>\n<p>They can say these things <i>whether they are true or not</i>. I\u2019m kind of harping on this point, but it\u2019s because it\u2019s something <i>I</i> didn\u2019t realize until much later than I should have.</p>\n<p>There are many \u201cquestions\u201d that are pretty much settled \u2013 evolution, global warming, homeopathy. But taking these as representative <a href=\"http://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/\">closes your mind</a> and gives you a skewed picture of academia. On many issues, academics are just as divided as anyone else, and their arguments can be just as acrimonious as anyone else\u2019s. The arguments usually take the form of one side publishing a study, the other side ripping the study apart and publishing their own study which they say is better, and the first side ripping the second study apart and arguing that their study was better all along.</p>\n<p>Every study has flaws. No study has perfect methodology. If you like a study, you can say that it did the best it could on a difficult research area and has improved upon even-worse predecessor studies. If you don\u2019t like a study, you can say \u201cLOOK AT THESE FLAWS THESE PEOPLE ARE IDIOTS THE CONCLUSION IS COMPLETELY INVALID\u201d. All you need to do is make enough <a href=\"http://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/\">isolated demands for rigor</a> against anything you disagree with.</p>\n<p>And so if the first level of confirmation bias is believing every study that supports your views, the second layer of confirmation bias is believing every supposed refutation that supports your views.</p>\n<p>There are certainly things that have been \u201cwell-refuted\u201d and \u201cdebunked\u201d. Andrew Wakefield\u2019s study purporting to prove that vaccines cause autism is a pretty good example. But you will notice that it had multiple failed replications, journals published reports showing he falsified data, the study\u2019s co-authors retracted their support, the journal it was published in retracted it and issued an apology, the General Medical Council convicted Wakefield of sixteen counts of misconduct, and Wakefield was stripped of his medical license and barred from practicing medicine ever again in the UK. The <i>British Medical Journal</i>, one of the best-respected medical journals in the world, published an editorial concluding:</p>\n<blockquote><p>Clear evidence of falsification of data should now close the door on this damaging vaccine scare \u2026 Who perpetrated this fraud? There is no doubt that it was Wakefield. Is it possible that he was wrong, but not dishonest: that he was so incompetent that he was unable to fairly describe the project, or to report even one of the 12 children\u2019s cases accurately? No.</p></blockquote>\n<p>Wakefield\u2019s study has been \u201crefuted\u201d. The rape study has been \u201cargued against\u201d.</p>\n<p><b id=\"III_\">III.</b></p>\n<p>I saw this same dynamic at work the other day, looking through the minimum wage literature. </p>\n<p>The primordial titanomachy of the minimum wage literature goes like this. In 1994, two guys named Card and Krueger published a study showing the minimum wage had if anything positive effects on New Jersey restaurants, convincing many people that minimum wages were good. In 1996, two guys named Neumark and Wascher reanalyzed the New Jersey data using a different source and found that it showed the minimum wage had very bad effects on New Jersey restaurants. In 2000, Card and Krueger responded, saying that their analysis was better than Neumark and Wascher\u2019s re-analysis, and also they had done a re-analysis of their own which confirmed their original position.</p>\n<p>Let\u2019s see how conservative sites present this picture:</p>\n<p><i>\u201cThe support for this assertion is the oft-cited 1994 study by Card and Krueger showing a positive correlation between an increased minimum wage and employment in New Jersey. Many others have thoroughly debunked this study.\u201d</i> (<a href=\"http://mises.org/library/welfare-minimum-wages-and-unemployment\">source</a>)</p>\n<p><i>\u201cI was under the impression that the original study done by Card and Krueger had been thoroughly debunked by Michigan State University economist David Neumark and William Wascher\u201d</i> (<a href=\"http://www.amatecon.com/blog/2002_08_04_archive.html\">source</a>)</p>\n<p><i>\u201cThe study \u2026 by Card and Krueger has been debunked by several different people several different times. When other researchers re-evaluated the study, they found that data collected using those records \u2018lead to the opposite conclusion from that reached by\u2019 Card and Krueger.\u201d</i> (<a href=\"http://being-classical-liberal.blogspot.com/2014/02/john-green-is-heroon-left.html\">source</a>)</p>\n<p><i>\u201cIt was only a short time before the fantastic Card-Krueger findings were challenged and debunked by several subsequent studies\u2026in 1995, economists David Neumark and David Wascher used actual payroll records (instead of survey data used by Card and Krueger) and published their results in an NBER paper with an amazing finding: Demand curves for unskilled labor really do slope downward, confirming 200 years of economic theory and mountains of empirical evidence</i> (<a href=\"http://www.aei.org/publication/obamas-chief-econ-adviser-once-made-an-amazing-discovery-demand-curves-slope-upward/print/\">source</a>)</p>\n<p>And now let\u2019s look at how lefty sites present this picture:</p>\n<p><i>\u201c\u2026a long-debunked paper [by Neumark and Wascher]\u201d</i> (<a href=\"http://politicalhotwire.com/economics/88594-%2410-minimum-wage-would-push-more-than-half-working-poor-out-poverty-78.html#post2600348\">source</a>)</p>\n<p><i>\u201cNote that your Mises heroes, Neumark and Wascher are roundly debunked.\u201d</i> (<a href=\"http://www.politics.ie/forum/economy/199017-should-minimum-wage-rates-abolished-10.html\">source</a>)</p>\n<p><i>\u201cNeumark\u2019s living wage and minimum wage research have been found to be seriously flawed\u2026based on faulty methods which when corrected refute his conclusion.\u201d</i> \u2013 (<a href=\"http://www.nelp.org/page/-/Justice/2010/AnalysisofNewYorkCityWageStudyTeam.pdf?nocdn=1\">source</a>)</p>\n<p><i>\u201c\u2026Neumark and Wascher, a study which Elizabeth Warren debunked in a Senate hearing\u201d</i> (<a href=\"http://community.runnersworld.com/topic/the-recovery?reply=55902332404903103#55902332404903103\n\">source</a>)</p>\n<p>So if you\u2019re conservative, Neumark and Wascher debunked Card and Krueger. But if you\u2019re liberal, Card and Krueger debunked Neumark and Wascher.</p>\n<p>Both sides are no doubt very pleased with themselves. They\u2019re not men of one study. They look at <i>all</i> of the research \u2013 except of course the studies that have been \u201cdebunked\u201d or \u201cwell-refuted\u201d. Why would you waste your time with <i>those?</i></p>\n<p><b id=\"IV_\">IV.</b></p>\n<p>Once again, I\u2019m not preaching radical skepticism.</p>\n<p>First of all, some studies are <i>super-debunked</i>. Wakefield is a good example.</p>\n<p>Second of all, some studies that don\u2019t quite meet Wakefield-level of awfulness are indeed really bad and need refuting. I don\u2019t think this is beyond the intellectual capacities of most people. I think in many cases it\u2019s easy to understand why a study is wrong, you should try to do that, and once you do it you can safely discount the results of the study.</p>\n<p>I\u2019m not against pointing out when you disagree with studies or think they\u2019re flawed. I\u2019d be a giant hypocrite if I was.</p>\n<p>But \u201cdebunked\u201d and \u201crefuted\u201d aren\u2019t saying you disagree with a study. They\u2019re making arguments from authority. They\u2019re saying \u201cthe authority of the scientific community has come together and said this is a piece of crap that doesn\u2019t count\u201d.</p>\n<p>And that\u2019s fine if that\u2019s actually happened. But you had better make sure that you\u2019re calling upon an ex cathedra statement by the community itself, and not a single guy with an axe to grind. Or one side of a complicated an interminable debate where both sides have about equal credentials and sway.</p>\n<p>If you can\u2019t do that, you say \u201cI think that my side of the academic debate is in the right, and here\u2019s why,\u201d not \u201cyour side has been debunked\u201d. </p>\n<p>Otherwise you\u2019re going to end up like the minimum wage debaters, where both sides claim to have debunked the other. Or like the Federalist article that says a study has been \u201cput to bed\u201d as \u201cbogus\u201d just because another study said something different.</p>\n<p>I think this is part of my reply to <a href=\"http://slatestarcodex.com/2014/11/27/why-i-am-not-rene-descartes/\">the claim that</a> empiricism is so great that no one needs rationality.</p>\n<p>A naive empiricist who swears off critical thinking because they can just \u201cfollow the evidence\u201d has no contingency plan for when the evidence gets confusing. Their only recourse is to deny that the evidence is confusing, to assert that one side or the other has been \u201cdebunked\u201d. Since they\u2019ve already made a principled decision not to study confirmation bias, chances are it\u2019s going to be whichever side they don\u2019t like that\u2019s \u201calready been debunked\u201d. And by \u201cdebunked\u201d they mean \u201ca scientist on my side said it was wrong, so now I am relieved from the burden of thinking about it.\u201d</p>\n<p>On the original post, I wrote:</p>\n<blockquote><p>Life is made up of limited, confusing, contradictory, and maliciously doctored facts. Anyone who says otherwise is either sticking to such incredibly easy solved problems that they never encounter anything outside their comfort level, or so closed-minded that they shut out any evidence that challenges their beliefs.</p></blockquote>\n<p>In the absence of any actual debunking more damning than a counterargument, \u201cthat\u2019s been debunked\u201d is the way \u201cshuts out any evidence that challenges their beliefs\u201d feels from the inside.</p>\n<p><b id=\"V_\">V.</b></p>\n<p>Somebody\u2019s going to want to know what\u2019s up with the original rape studies. The answer is that a small part of the discrepancy is response bias on the CSAS, but most of it is that the two surveys encourage respondents to define \u201csexual assault\u201d in very different ways. Vox has <a href=\"http://www.vox.com/2014/12/11/7378271/why-some-studies-make-campus-rape-look-like-an-epidemic-while-others\">an excellent article on this</a> which for once I 100% endorse.</p>\n<p>In other words, both are valid, both come together to form a more nuanced picture of campus violence, and neither one \u201cdebunks\u201d the other.</p>", "sections": [{"title": "I.", "anchor": "I_", "level": 1}, {"title": "II.", "anchor": "II_", "level": 1}, {"title": "III.", "anchor": "III_", "level": 1}, {"title": "IV.", "anchor": "IV_", "level": 1}, {"title": "V.", "anchor": "V_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-14T02:59:47.239Z", "modifiedAt": null, "url": null, "title": "Discussion of AI control over at worldbuilding.stackexchange [LINK]", "slug": "discussion-of-ai-control-over-at-worldbuilding-stackexchange", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ike", "createdAt": "2014-04-24T17:15:10.503Z", "isAdmin": false, "displayName": "ike"}, "userId": "u9qB4z7MjAsqx9yp8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/89MLNWAtTb3DxqX9F/discussion-of-ai-control-over-at-worldbuilding-stackexchange", "pageUrlRelative": "/posts/89MLNWAtTb3DxqX9F/discussion-of-ai-control-over-at-worldbuilding-stackexchange", "linkUrl": "https://www.lesswrong.com/posts/89MLNWAtTb3DxqX9F/discussion-of-ai-control-over-at-worldbuilding-stackexchange", "postedAtFormatted": "Sunday, December 14th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Discussion%20of%20AI%20control%20over%20at%20worldbuilding.stackexchange%20%5BLINK%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADiscussion%20of%20AI%20control%20over%20at%20worldbuilding.stackexchange%20%5BLINK%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F89MLNWAtTb3DxqX9F%2Fdiscussion-of-ai-control-over-at-worldbuilding-stackexchange%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Discussion%20of%20AI%20control%20over%20at%20worldbuilding.stackexchange%20%5BLINK%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F89MLNWAtTb3DxqX9F%2Fdiscussion-of-ai-control-over-at-worldbuilding-stackexchange", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F89MLNWAtTb3DxqX9F%2Fdiscussion-of-ai-control-over-at-worldbuilding-stackexchange", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 26, "htmlBody": "<p><a title=\"https://worldbuilding.stackexchange.com/questions/6340/the-challenge-of-controlling-a-powerful-ai\" href=\"https://worldbuilding.stackexchange.com/questions/6340/the-challenge-of-controlling-a-powerful-ai\" target=\"_blank\">https://worldbuilding.stackexchange.com/questions/6340/the-challenge-of-controlling-a-powerful-ai</a></p>\n<p>Go insert some rationality into the discussion! (There are actually some pretty good comments in there, and some links to the right places, including LW).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "89MLNWAtTb3DxqX9F", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 2.2658832115648803e-06, "legacy": true, "legacyId": "27721", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-14T16:14:50.613Z", "modifiedAt": null, "url": null, "title": "Podcast: Rationalists in Tech", "slug": "podcast-rationalists-in-tech", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:00.612Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JoshuaFox", "createdAt": "2009-03-05T06:55:09.368Z", "isAdmin": false, "displayName": "JoshuaFox"}, "userId": "5yNJS8bxEYhgFD9XJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M458wmvvfhKtnzTDQ/podcast-rationalists-in-tech", "pageUrlRelative": "/posts/M458wmvvfhKtnzTDQ/podcast-rationalists-in-tech", "linkUrl": "https://www.lesswrong.com/posts/M458wmvvfhKtnzTDQ/podcast-rationalists-in-tech", "postedAtFormatted": "Sunday, December 14th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Podcast%3A%20Rationalists%20in%20Tech&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APodcast%3A%20Rationalists%20in%20Tech%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM458wmvvfhKtnzTDQ%2Fpodcast-rationalists-in-tech%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Podcast%3A%20Rationalists%20in%20Tech%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM458wmvvfhKtnzTDQ%2Fpodcast-rationalists-in-tech", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM458wmvvfhKtnzTDQ%2Fpodcast-rationalists-in-tech", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<div>\n<div><span style=\" ;\">I'll appreciate feedback on a new podcast, <a href=\"http://rationalistsintech.blogspot.com/\">Rationalists in Tech</a></span><span style=\" \">.</span><span style=\" ;\">&nbsp;</span></div>\n<div><br /></div>\n<div><span style=\" ;\">I'm interviewing founders, executives, CEOs, consultants, and other people in the tech sector, mostly software.&nbsp;</span>Thanks to <a href=\"/user/Morendil\">Laurent Bossavit</a>, <a href=\"http://http//lesswrong.com/user/dreeves\">Daniel Reeves</a>, and <a href=\"/user/Alexei/\">Alexei Andreev</a> who agreed to be the guinea pigs for this experiment.&nbsp;</div>\n<div>\n<div>\n<ul>\n<li>The audience:</li>\n</ul>\n</div>\n<div style=\"padding-left: 60px;\">Software engineers and other tech workers, at all levels of seniority.</div>\n<div>\n<ul>\n<li>The hypothesized need</li>\n</ul>\n</div>\n<div style=\"padding-left: 60px;\">Some of you are thinking: \"I see that some smart and fun people hang out at LessWrong. It's hard to find people like that to work with. I wonder if my next job/employee/cofounder could come from that community.\"</div>\n<div>\n<ul>\n<li>What this podcast does for you</li>\n</ul>\n</div>\n<div style=\"padding-left: 60px;\">You will get insights into other LessWrongers as real people in the software profession. (OK, you knew that, but this helps.) You will hear the interviewees' ideas on CfAR-style techniques as a productivity booster, on working with other aspiring rationalists, and on the interviewees' own special areas of expertise. (At the same time, interviewees benefit from exposure that can get them business contacts, &nbsp;employees, or customers.) Software engineers from LW will reach out to interviewees and others in the tech sector, and soon, more hires and startups will emerge.&nbsp;</div>\n<div style=\"padding-left: 60px;\"><br /></div>\n<div>Please give your feedback on the first <a href=\"http://rationalistsintech.blogspot.com/\">episodes of the podcast</a>. Do you want to hear more? Should there be other topics? A different interview style? Better music?</div>\n</div>\n</div>\n<blockquote style=\"margin: 0px 0px 0px 40px; border: none; padding: 0px;\">\n<div><span style=\"font-family: garamond, serif;\"><br /></span></div>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M458wmvvfhKtnzTDQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 2.2676598684847023e-06, "legacy": true, "legacyId": "27724", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-15T00:01:06.830Z", "modifiedAt": null, "url": null, "title": "Open thread, Dec. 15 - Dec. 21, 2014", "slug": "open-thread-dec-15-dec-21-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.934Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A8THjFzBhHZEjzw3D/open-thread-dec-15-dec-21-2014", "pageUrlRelative": "/posts/A8THjFzBhHZEjzw3D/open-thread-dec-15-dec-21-2014", "linkUrl": "https://www.lesswrong.com/posts/A8THjFzBhHZEjzw3D/open-thread-dec-15-dec-21-2014", "postedAtFormatted": "Monday, December 15th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20Dec.%2015%20-%20Dec.%2021%2C%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20Dec.%2015%20-%20Dec.%2021%2C%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA8THjFzBhHZEjzw3D%2Fopen-thread-dec-15-dec-21-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20Dec.%2015%20-%20Dec.%2021%2C%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA8THjFzBhHZEjzw3D%2Fopen-thread-dec-15-dec-21-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA8THjFzBhHZEjzw3D%2Fopen-thread-dec-15-dec-21-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px; font-weight: bold;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><a href=\"/r/discussion/lw/ld1/open_thread_dec_8_dec_15_2014/\">Previous Open Thread</a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><a href=\"/r/discussion/lw/lf8/open_thread_dec_22_dec_28_2014/\">Next Open Thread</a></p>\n<hr />\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the <a href=\"/r/discussion/new/\" target=\"_blank\">list-of-threads page</a> before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">3.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should be posted in Discussion, and not Main.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">4.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A8THjFzBhHZEjzw3D", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 2.268702957229673e-06, "legacy": true, "legacyId": "27723", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 309, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wv2T69qsrHgXcKddZ", "gJmbtzXWs6g6ZtdAA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-15T02:57:01.853Z", "modifiedAt": "2020-08-05T06:07:22.072Z", "url": null, "title": "Welcome to Less Wrong! (7th thread, December 2014)", "slug": "welcome-to-less-wrong-7th-thread-december-2014", "viewCount": null, "lastCommentedAt": "2017-08-28T17:59:11.115Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eqaro7sMe5xw2kJWc/welcome-to-less-wrong-7th-thread-december-2014", "pageUrlRelative": "/posts/eqaro7sMe5xw2kJWc/welcome-to-less-wrong-7th-thread-december-2014", "linkUrl": "https://www.lesswrong.com/posts/eqaro7sMe5xw2kJWc/welcome-to-less-wrong-7th-thread-december-2014", "postedAtFormatted": "Monday, December 15th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Welcome%20to%20Less%20Wrong!%20(7th%20thread%2C%20December%202014)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWelcome%20to%20Less%20Wrong!%20(7th%20thread%2C%20December%202014)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feqaro7sMe5xw2kJWc%2Fwelcome-to-less-wrong-7th-thread-december-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Welcome%20to%20Less%20Wrong!%20(7th%20thread%2C%20December%202014)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feqaro7sMe5xw2kJWc%2Fwelcome-to-less-wrong-7th-thread-december-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Feqaro7sMe5xw2kJWc%2Fwelcome-to-less-wrong-7th-thread-december-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1663, "htmlBody": "<div id=\"entry_t3_i4z\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<div>If you've recently joined the <a href=\"/lw/1/about_less_wrong\">Less Wrong community</a>, please leave a comment here and introduce yourself. We'd love to know who you are, what you're doing, what you value, <a href=\"/lw/2/tell_your_rationalist_origin_story\">how you came to identify as an aspiring rationalist</a> or how you found us. You can <a href=\"/lw/le5/welcome_to_less_wrong_7th_thread_december_2014/#comments\">skip right to that</a> if you like; the rest of this post consists of a few things you might find helpful. More can be found at the <a href=\"http://wiki.lesswrong.com/wiki/FAQ\">FAQ</a>.</div>\n<p>&nbsp;</p>\n<h4>A few notes about the site mechanics<br /></h4>\n<div><strong>To post your first comment</strong>, you must have carried out the e-mail confirmation: When you signed up to create your account, an e-mail was sent to the address you provided with a link that you need to follow to confirm your e-mail address. You must do this before you can post!</div>\n<div><br /></div>\n<div>Less Wrong&nbsp;<strong>comments are threaded</strong>&nbsp;for easy following of multiple conversations. To respond to any comment, click the \"Reply\" link at the bottom of that comment's box. Within the comment box, links and formatting are achieved via&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Comment_formatting\">Markdown syntax</a>&nbsp;(you can click the \"Help\" link below the text box to bring up a primer).</div>\n<div><br /></div>\n<div class=\"md\">You may have noticed that all the posts and comments on this site have buttons to <strong>vote them up or down</strong>, and all the users have \"karma\" scores which come from the sum of all their comments and posts. This immediate easy feedback mechanism helps keep arguments from turning into flamewars and helps make the best posts more visible; it's part of what makes discussions on Less Wrong look different from those anywhere else on the Internet.</div>\n<div class=\"md\"><br /></div>\n<div class=\"md\">However, it can feel really irritating to get downvoted, especially if one doesn't know why. It happens to all of us sometimes, and it's perfectly acceptable to ask for an explanation. (Sometimes it's the unwritten LW etiquette; we have different norms than other forums.) Take note when you're downvoted a lot on one topic, as it often means that several members of the community think you're missing an important point or making a mistake in reasoning&mdash; not just that they disagree with you!<strong> If you have any questions about karma or voting, please feel free to ask here.</strong></div>\n<div class=\"md\"><strong><br /></strong></div>\n<div class=\"md\"><strong>Replies</strong> to your comments across the site, plus <strong>private messages</strong> from other users, will show up in your <a href=\"/message/inbox\">inbox</a>. You can reach it via the little mail icon beneath your karma score on the upper right of most pages. When you have a new reply or message, it glows red. You can also click on any user's name to view all of their comments and posts.</div>\n<div class=\"md\"><br /></div>\n<div class=\"md\">It's definitely worth your time <strong>commenting on old posts</strong>; veteran users look through the <a href=\"/comments\">recent comments thread</a> quite often (there's a separate <a href=\"/r/discussion/comments\">recent comments thread for the Discussion section</a>, for whatever reason), and a conversation begun anywhere will pick up contributors that way.&nbsp; There's also a succession of <a href=\"/r/discussion/tag/open_thread/\">open</a> comment <a href=\"/tag/open_thread\">threads</a> for discussion of anything remotely related to rationality.</div>\n<div class=\"md\"><br /></div>\n<div class=\"md\">Discussions on Less Wrong tend to end differently than in most other forums; a surprising number end when one participant changes their mind, or when multiple people clarify their views enough and reach agreement. More commonly, though, people will just stop when they've better identified their deeper disagreements, or simply <strong>\"tap out\" of a discussion</strong> that's stopped being productive. (Seriously, you can just write \"I'm tapping out of this thread.\") This is absolutely OK, and it's one good way to avoid the flamewars that plague many sites.</div>\n<div class=\"md\"><br /></div>\n<div class=\"md\"><strong>EXTRA FEATURES:</strong><br /></div>\n<div class=\"md\">There's actually more than meets the eye here: look near the top of the page for the \"WIKI\", \"DISCUSSION\" and \"SEQUENCES\" links.</div>\n<div class=\"md\"><strong>LW WIKI:</strong> This is our attempt to make searching by topic feasible, as well as to store information like <a href=\"http://wiki.lesswrong.com/wiki/Acronyms_used_on_Less_Wrong\">common abbreviations</a> and idioms. It's a good place to look if someone's speaking Greek to you.<br /></div>\n<div class=\"md\"><strong>LW DISCUSSION:</strong> This is a forum just like the top-level one, with two key differences: in the top-level forum, posts require the author to have 20 karma in order to publish, and any upvotes or downvotes on the post are multiplied by 10. Thus there's a lot more informal dialogue in the Discussion section, including some of the more fun conversations here.</div>\n<div class=\"md\"><strong>SEQUENCES:</strong> A <em>huge</em> corpus of material mostly written by Eliezer Yudkowsky in his days of blogging at Overcoming Bias, before Less Wrong was started. Much of the discussion here will casually depend on or refer to ideas brought up in those posts, so reading them can really help with present discussions. Besides which, they're pretty engrossing in my opinion.<br /></div>\n<h4>A few notes about the community<br /></h4>\n<div>If you've come to Less Wrong to&nbsp; <strong>discuss a particular topic</strong>, this thread would be a great place to start the conversation. By commenting here, and checking the responses, you'll probably get a good read on what, if anything, has already been said here on that topic, what's widely understood and what you might still need to take some time explaining.</div>\n<div><br /></div>\n<div><strong>If your welcome comment starts a huge discussion</strong>, then please move to the next step and&nbsp;<strong>create a LW Discussion post to continue the conversation</strong>; we can fit many more welcomes onto each thread if fewer of them sprout 400+ comments. (To do this: click \"Create new article\" in the upper right corner next to your username, then write the article, then at the bottom take the menu \"Post to\" and change it from \"Drafts\" to \"Less Wrong Discussion\". Then click \"Submit\". When you edit a published post, clicking \"Save and continue\" does correctly update the post.)</div>\n<div><br /></div>\n<div>If you want to write a post about a LW-relevant topic, awesome!&nbsp;<strong>I highly recommend you submit your first post to Less Wrong Discussion</strong>; don't worry, you can later promote it from there to the main page if it's well-received. (It's much better to get some feedback before every vote counts for 10 karma&mdash;honestly, you don't know what you don't know about the community norms here.)</div>\n<div><br /></div>\n<div>Alternatively, if you're still unsure where to submit a post, whether to submit it at all, would like some feedback before submitting, or want to gauge interest, you can ask / provide your draft / summarize your submission in the latest <a href=\"/r/discussion/tag/open_thread/\">open</a> comment <a href=\"/tag/open_thread\">thread</a>. In fact, Open Threads are intended for <strong>anything 'worth saying, but not worth its own post'</strong>, so please do dive in! Informally, there is also the unofficial <a href=\"http://wiki.lesswrong.com/wiki/IRC\">Less Wrong IRC chat room</a>, and you might also like to take a look at some of the other regular <a href=\"http://wiki.lesswrong.com/wiki/Special_threads\">special threads</a>; they're a great way to get involved with the community!</div>\n<div><br /></div>\n<div>If you'd like to connect with other LWers in real life, we have&nbsp; <strong>meetups&nbsp;</strong> in various parts of the world. Check the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups\">wiki page for places with regular meetups</a>, or the&nbsp;<a href=\"/meetups\">upcoming (irregular) meetups page</a>. There's also a&nbsp;<a href=\"http://www.facebook.com/home.php#/group.php?gid=144017955332&amp;ref=ts\">Facebook group</a>. If you have your own blog or other online presence, please feel free to link it.</div>\n<p><strong>If English is not your first language</strong>, don't let that make you afraid to post or comment. You can get English help on Discussion- or Main-level posts by sending a PM to one of the following users (use the \"send message\" link on the upper right of their user page). Either put the text of the post in the PM, or just say that you'd like English help and you'll get a response with an email address. <br /> * <a href=\"/user/Normal_Anomaly\">Normal_Anomaly</a> <br /> * <a href=\"/user/Randaly\">Randaly</a> <br /> * <a href=\"/user/shokwave\">shokwave</a> <br /> * <a href=\"/user/Barry_Cotter\">Barry Cotter</a></p>\n<p><strong>A note for theists</strong>: you will find the Less Wrong community to be predominantly atheist, though not completely so, and most of us are genuinely respectful of religious people who keep the usual community norms. It's worth saying that we might think religion is off-topic in some places where you think it's on-topic, so be thoughtful about where and how you start explicitly talking about it; some of us are happy to talk about religion, some of us aren't interested. Bear in mind that many of us really, truly have given full consideration to theistic claims and found them to be false, so starting with the most common arguments is pretty likely just to annoy people. Anyhow, it's absolutely OK to mention that you're religious in your welcome post and to invite a discussion there.</p>\n<h4>A list of some posts that are pretty awesome<br /></h4>\n<p>I recommend the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Sequences\">major sequences</a>&nbsp;to everybody, but I realize how daunting they look at first. So for purposes of immediate gratification, the following posts are particularly interesting/illuminating/provocative and don't require any previous reading:</p>\n<ul>\n<li><a href=\"/lw/e95/the_noncentral_fallacy_the_worst_argument_in_the/\">The Worst Argument in the World</a></li>\n<li><a href=\"/lw/qk/that_alien_message\">That Alien Message</a></li>\n<li><a href=\"/lw/jr/how_to_convince_me_that_2_2_3\">How to Convince Me that 2 + 2 = 3</a></li>\n<li><a href=\"/lw/vo/lawful_uncertainty\">Lawful Uncertainty</a></li>\n<li><a href=\"/lw/2bu/your_intuitions_are_not_magic\">Your Intuitions are Not Magic</a></li>\n<li><a href=\"/lw/jg/planning_fallacy\">The Planning Fallacy</a></li>\n<li><a href=\"/lw/20/the_apologist_and_the_revolutionary\">The Apologist and the Revolutionary</a></li>\n<li><a href=\"/lw/hw/scope_insensitivity\">Scope Insensitivity</a></li>\n<li><a href=\"/lw/my/the_allais_paradox\">The Allais Paradox</a>&nbsp; (with&nbsp;<a href=\"/lw/mz/zut_allais\">two</a>&nbsp;<a href=\"/lw/n1/allais_malaise\">followups</a>)</li>\n<li><a href=\"/lw/jx/we_change_our_minds_less_often_than_we_think\">We Change Our Minds Less Often Than We Think</a></li>\n<li><a href=\"/lw/2k/the_least_convenient_possible_world\">The Least Convenient Possible World</a></li>\n<li><a href=\"/lw/hu/the_third_alternative\">The Third Alternative</a></li>\n<li><a href=\"/lw/116/the_domain_of_your_utility_function\">The Domain of Your Utility Function</a></li>\n<li><a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality\">Newcomb's Problem and Regret of Rationality</a></li>\n<li><a href=\"/lw/tn/the_true_prisoners_dilemma\">The True Prisoner's Dilemma</a></li>\n<li><a href=\"/lw/kw/the_tragedy_of_group_selectionism\">The Tragedy of Group Selectionism</a></li>\n<li><a href=\"/lw/gz/policy_debates_should_not_appear_onesided\">Policy Debates Should Not Appear One-Sided</a></li>\n</ul>\n<p>More suggestions are welcome! Or just check out the&nbsp;<a href=\"/top/?t=all\">top-rated posts from the history of Less Wrong</a>. Most posts at +50 or more are well worth your time.</p>\n<p>Welcome to Less Wrong, and we look forward to hearing from you throughout the site!</p>\n<p>&nbsp;</p>\n<p><sub>Once a post gets over 500 comments, the site stops showing them all by default. If this post has 500 comments and you have 20 karma, please do start the next welcome post; a new post is a good perennial way to encourage newcomers and lurkers to introduce themselves. (Step-by-step, foolproof instructions <a href=\"http://pastebin.com/vZjt59F0\">here</a>; takes &lt;180seconds.)</sub></p>\n<p><sub> </sub></p>\n<p><sub>If there's anything I should add or update on this post (especially broken links), please send me a private message&mdash;I may not notice a comment on the post.</sub></p>\n<p><sub> </sub></p>\n<p><sub>Finally, a big thank you to everyone that helped write this post via its <a href=\"/tag/welcome/\">predecessors</a>!</sub></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eqaro7sMe5xw2kJWc", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 21, "extendedScore": null, "score": 2.2690967201308166e-06, "legacy": true, "legacyId": "27725", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<div id=\"entry_t3_i4z\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<div>If you've recently joined the <a href=\"/lw/1/about_less_wrong\">Less Wrong community</a>, please leave a comment here and introduce yourself. We'd love to know who you are, what you're doing, what you value, <a href=\"/lw/2/tell_your_rationalist_origin_story\">how you came to identify as an aspiring rationalist</a> or how you found us. You can <a href=\"/lw/le5/welcome_to_less_wrong_7th_thread_december_2014/#comments\">skip right to that</a> if you like; the rest of this post consists of a few things you might find helpful. More can be found at the <a href=\"http://wiki.lesswrong.com/wiki/FAQ\">FAQ</a>.</div>\n<p>&nbsp;</p>\n<h4 id=\"A_few_notes_about_the_site_mechanics\">A few notes about the site mechanics<br></h4>\n<div><strong>To post your first comment</strong>, you must have carried out the e-mail confirmation: When you signed up to create your account, an e-mail was sent to the address you provided with a link that you need to follow to confirm your e-mail address. You must do this before you can post!</div>\n<div><br></div>\n<div>Less Wrong&nbsp;<strong>comments are threaded</strong>&nbsp;for easy following of multiple conversations. To respond to any comment, click the \"Reply\" link at the bottom of that comment's box. Within the comment box, links and formatting are achieved via&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Comment_formatting\">Markdown syntax</a>&nbsp;(you can click the \"Help\" link below the text box to bring up a primer).</div>\n<div><br></div>\n<div class=\"md\">You may have noticed that all the posts and comments on this site have buttons to <strong>vote them up or down</strong>, and all the users have \"karma\" scores which come from the sum of all their comments and posts. This immediate easy feedback mechanism helps keep arguments from turning into flamewars and helps make the best posts more visible; it's part of what makes discussions on Less Wrong look different from those anywhere else on the Internet.</div>\n<div class=\"md\"><br></div>\n<div class=\"md\">However, it can feel really irritating to get downvoted, especially if one doesn't know why. It happens to all of us sometimes, and it's perfectly acceptable to ask for an explanation. (Sometimes it's the unwritten LW etiquette; we have different norms than other forums.) Take note when you're downvoted a lot on one topic, as it often means that several members of the community think you're missing an important point or making a mistake in reasoning\u2014 not just that they disagree with you!<strong> If you have any questions about karma or voting, please feel free to ask here.</strong></div>\n<div class=\"md\"><strong><br></strong></div>\n<div class=\"md\"><strong>Replies</strong> to your comments across the site, plus <strong>private messages</strong> from other users, will show up in your <a href=\"/message/inbox\">inbox</a>. You can reach it via the little mail icon beneath your karma score on the upper right of most pages. When you have a new reply or message, it glows red. You can also click on any user's name to view all of their comments and posts.</div>\n<div class=\"md\"><br></div>\n<div class=\"md\">It's definitely worth your time <strong>commenting on old posts</strong>; veteran users look through the <a href=\"/comments\">recent comments thread</a> quite often (there's a separate <a href=\"/r/discussion/comments\">recent comments thread for the Discussion section</a>, for whatever reason), and a conversation begun anywhere will pick up contributors that way.&nbsp; There's also a succession of <a href=\"/r/discussion/tag/open_thread/\">open</a> comment <a href=\"/tag/open_thread\">threads</a> for discussion of anything remotely related to rationality.</div>\n<div class=\"md\"><br></div>\n<div class=\"md\">Discussions on Less Wrong tend to end differently than in most other forums; a surprising number end when one participant changes their mind, or when multiple people clarify their views enough and reach agreement. More commonly, though, people will just stop when they've better identified their deeper disagreements, or simply <strong>\"tap out\" of a discussion</strong> that's stopped being productive. (Seriously, you can just write \"I'm tapping out of this thread.\") This is absolutely OK, and it's one good way to avoid the flamewars that plague many sites.</div>\n<div class=\"md\"><br></div>\n<div class=\"md\"><strong>EXTRA FEATURES:</strong><br></div>\n<div class=\"md\">There's actually more than meets the eye here: look near the top of the page for the \"WIKI\", \"DISCUSSION\" and \"SEQUENCES\" links.</div>\n<div class=\"md\"><strong>LW WIKI:</strong> This is our attempt to make searching by topic feasible, as well as to store information like <a href=\"http://wiki.lesswrong.com/wiki/Acronyms_used_on_Less_Wrong\">common abbreviations</a> and idioms. It's a good place to look if someone's speaking Greek to you.<br></div>\n<div class=\"md\"><strong>LW DISCUSSION:</strong> This is a forum just like the top-level one, with two key differences: in the top-level forum, posts require the author to have 20 karma in order to publish, and any upvotes or downvotes on the post are multiplied by 10. Thus there's a lot more informal dialogue in the Discussion section, including some of the more fun conversations here.</div>\n<div class=\"md\"><strong>SEQUENCES:</strong> A <em>huge</em> corpus of material mostly written by Eliezer Yudkowsky in his days of blogging at Overcoming Bias, before Less Wrong was started. Much of the discussion here will casually depend on or refer to ideas brought up in those posts, so reading them can really help with present discussions. Besides which, they're pretty engrossing in my opinion.<br></div>\n<h4 id=\"A_few_notes_about_the_community\">A few notes about the community<br></h4>\n<div>If you've come to Less Wrong to&nbsp; <strong>discuss a particular topic</strong>, this thread would be a great place to start the conversation. By commenting here, and checking the responses, you'll probably get a good read on what, if anything, has already been said here on that topic, what's widely understood and what you might still need to take some time explaining.</div>\n<div><br></div>\n<div><strong>If your welcome comment starts a huge discussion</strong>, then please move to the next step and&nbsp;<strong>create a LW Discussion post to continue the conversation</strong>; we can fit many more welcomes onto each thread if fewer of them sprout 400+ comments. (To do this: click \"Create new article\" in the upper right corner next to your username, then write the article, then at the bottom take the menu \"Post to\" and change it from \"Drafts\" to \"Less Wrong Discussion\". Then click \"Submit\". When you edit a published post, clicking \"Save and continue\" does correctly update the post.)</div>\n<div><br></div>\n<div>If you want to write a post about a LW-relevant topic, awesome!&nbsp;<strong>I highly recommend you submit your first post to Less Wrong Discussion</strong>; don't worry, you can later promote it from there to the main page if it's well-received. (It's much better to get some feedback before every vote counts for 10 karma\u2014honestly, you don't know what you don't know about the community norms here.)</div>\n<div><br></div>\n<div>Alternatively, if you're still unsure where to submit a post, whether to submit it at all, would like some feedback before submitting, or want to gauge interest, you can ask / provide your draft / summarize your submission in the latest <a href=\"/r/discussion/tag/open_thread/\">open</a> comment <a href=\"/tag/open_thread\">thread</a>. In fact, Open Threads are intended for <strong>anything 'worth saying, but not worth its own post'</strong>, so please do dive in! Informally, there is also the unofficial <a href=\"http://wiki.lesswrong.com/wiki/IRC\">Less Wrong IRC chat room</a>, and you might also like to take a look at some of the other regular <a href=\"http://wiki.lesswrong.com/wiki/Special_threads\">special threads</a>; they're a great way to get involved with the community!</div>\n<div><br></div>\n<div>If you'd like to connect with other LWers in real life, we have&nbsp; <strong>meetups&nbsp;</strong> in various parts of the world. Check the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups\">wiki page for places with regular meetups</a>, or the&nbsp;<a href=\"/meetups\">upcoming (irregular) meetups page</a>. There's also a&nbsp;<a href=\"http://www.facebook.com/home.php#/group.php?gid=144017955332&amp;ref=ts\">Facebook group</a>. If you have your own blog or other online presence, please feel free to link it.</div>\n<p><strong>If English is not your first language</strong>, don't let that make you afraid to post or comment. You can get English help on Discussion- or Main-level posts by sending a PM to one of the following users (use the \"send message\" link on the upper right of their user page). Either put the text of the post in the PM, or just say that you'd like English help and you'll get a response with an email address. <br> * <a href=\"/user/Normal_Anomaly\">Normal_Anomaly</a> <br> * <a href=\"/user/Randaly\">Randaly</a> <br> * <a href=\"/user/shokwave\">shokwave</a> <br> * <a href=\"/user/Barry_Cotter\">Barry Cotter</a></p>\n<p><strong>A note for theists</strong>: you will find the Less Wrong community to be predominantly atheist, though not completely so, and most of us are genuinely respectful of religious people who keep the usual community norms. It's worth saying that we might think religion is off-topic in some places where you think it's on-topic, so be thoughtful about where and how you start explicitly talking about it; some of us are happy to talk about religion, some of us aren't interested. Bear in mind that many of us really, truly have given full consideration to theistic claims and found them to be false, so starting with the most common arguments is pretty likely just to annoy people. Anyhow, it's absolutely OK to mention that you're religious in your welcome post and to invite a discussion there.</p>\n<h4 id=\"A_list_of_some_posts_that_are_pretty_awesome\">A list of some posts that are pretty awesome<br></h4>\n<p>I recommend the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Sequences\">major sequences</a>&nbsp;to everybody, but I realize how daunting they look at first. So for purposes of immediate gratification, the following posts are particularly interesting/illuminating/provocative and don't require any previous reading:</p>\n<ul>\n<li><a href=\"/lw/e95/the_noncentral_fallacy_the_worst_argument_in_the/\">The Worst Argument in the World</a></li>\n<li><a href=\"/lw/qk/that_alien_message\">That Alien Message</a></li>\n<li><a href=\"/lw/jr/how_to_convince_me_that_2_2_3\">How to Convince Me that 2 + 2 = 3</a></li>\n<li><a href=\"/lw/vo/lawful_uncertainty\">Lawful Uncertainty</a></li>\n<li><a href=\"/lw/2bu/your_intuitions_are_not_magic\">Your Intuitions are Not Magic</a></li>\n<li><a href=\"/lw/jg/planning_fallacy\">The Planning Fallacy</a></li>\n<li><a href=\"/lw/20/the_apologist_and_the_revolutionary\">The Apologist and the Revolutionary</a></li>\n<li><a href=\"/lw/hw/scope_insensitivity\">Scope Insensitivity</a></li>\n<li><a href=\"/lw/my/the_allais_paradox\">The Allais Paradox</a>&nbsp; (with&nbsp;<a href=\"/lw/mz/zut_allais\">two</a>&nbsp;<a href=\"/lw/n1/allais_malaise\">followups</a>)</li>\n<li><a href=\"/lw/jx/we_change_our_minds_less_often_than_we_think\">We Change Our Minds Less Often Than We Think</a></li>\n<li><a href=\"/lw/2k/the_least_convenient_possible_world\">The Least Convenient Possible World</a></li>\n<li><a href=\"/lw/hu/the_third_alternative\">The Third Alternative</a></li>\n<li><a href=\"/lw/116/the_domain_of_your_utility_function\">The Domain of Your Utility Function</a></li>\n<li><a href=\"/lw/nc/newcombs_problem_and_regret_of_rationality\">Newcomb's Problem and Regret of Rationality</a></li>\n<li><a href=\"/lw/tn/the_true_prisoners_dilemma\">The True Prisoner's Dilemma</a></li>\n<li><a href=\"/lw/kw/the_tragedy_of_group_selectionism\">The Tragedy of Group Selectionism</a></li>\n<li><a href=\"/lw/gz/policy_debates_should_not_appear_onesided\">Policy Debates Should Not Appear One-Sided</a></li>\n</ul>\n<p>More suggestions are welcome! Or just check out the&nbsp;<a href=\"/top/?t=all\">top-rated posts from the history of Less Wrong</a>. Most posts at +50 or more are well worth your time.</p>\n<p>Welcome to Less Wrong, and we look forward to hearing from you throughout the site!</p>\n<p>&nbsp;</p>\n<p><sub>Once a post gets over 500 comments, the site stops showing them all by default. If this post has 500 comments and you have 20 karma, please do start the next welcome post; a new post is a good perennial way to encourage newcomers and lurkers to introduce themselves. (Step-by-step, foolproof instructions <a href=\"http://pastebin.com/vZjt59F0\">here</a>; takes &lt;180seconds.)</sub></p>\n<p><sub> </sub></p>\n<p><sub>If there's anything I should add or update on this post (especially broken links), please send me a private message\u2014I may not notice a comment on the post.</sub></p>\n<p><sub> </sub></p>\n<p><sub>Finally, a big thank you to everyone that helped write this post via its <a href=\"/tag/welcome/\">predecessors</a>!</sub></p>\n</div>\n</div>\n</div>\n</div>", "sections": [{"title": "A few notes about the site mechanics", "anchor": "A_few_notes_about_the_site_mechanics", "level": 1}, {"title": "A few notes about the community", "anchor": "A_few_notes_about_the_community", "level": 1}, {"title": "A list of some posts that are pretty awesome", "anchor": "A_list_of_some_posts_that_are_pretty_awesome", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "640 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 640, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2om7AHEHtbogJmT5s", "BHMBBFupzb4s8utts", "yCWPkLi8wJvewPbEp", "5wMcKNAwB6X4mp9og", "6FmqiAgS8h4EJm86s", "msJA6B9ZjiiZxT6EZ", "Psp8ZpYLCDJjshpRb", "CPm5LTwHrvBJCa9h5", "ZiQqsgGX6a42Sfpii", "2ftJ38y9SRBCBsCzy", "zJZvoiwydJ5zvzTHK", "zNcLnqHF5rvrTsQJx", "knpAQ4F3gmguxy39z", "buixYfcXBah9hbSNZ", "neQ7eXuaXpiYw7SBy", "erGipespbbzdG5zYb", "xgicQnkrdA5FehhnQ", "6ddcsdA2c2XpNpE5x", "HFyWNBnDNEDsDNLrZ", "QsMJQSFj7WfoTMNgW", "PeSzc9JTBxhaYRp9b"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2014-12-15T02:57:01.853Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-15T03:30:52.481Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, December 16-31", "slug": "group-rationality-diary-december-16-31-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:00.173Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/z87oRFkoCBe4yySfF/group-rationality-diary-december-16-31-0", "pageUrlRelative": "/posts/z87oRFkoCBe4yySfF/group-rationality-diary-december-16-31-0", "linkUrl": "https://www.lesswrong.com/posts/z87oRFkoCBe4yySfF/group-rationality-diary-december-16-31-0", "postedAtFormatted": "Monday, December 15th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20December%2016-31&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20December%2016-31%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz87oRFkoCBe4yySfF%2Fgroup-rationality-diary-december-16-31-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20December%2016-31%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz87oRFkoCBe4yySfF%2Fgroup-rationality-diary-december-16-31-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz87oRFkoCBe4yySfF%2Fgroup-rationality-diary-december-16-31-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<h2 style=\"margin: 0px 0px 0.75em; color: #333333; font-size: 1.3333em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"line-height: 24.2727279663086px; font-size: small; color: #000000; font-weight: normal;\">This is the public group rationality diary for December 16-31.</span></h2>\n<div id=\"entry_t3_l4c\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px; line-height: 18px;\">\n<div class=\"md\">\n<div id=\"entry_t3_l1z\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<blockquote style=\"line-height: 24.2727279663086px;\">\n<p style=\"margin: 0px 0px 1em;\">It's a place to record and chat about it if you have done, or are actively doing, things like:&nbsp;</p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating.</p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\"><span style=\"line-height: 24.2727279663086px;\">Previous diary: </span><span style=\"line-height: 24.2727279663086px;\"><a style=\"color: #8a8a8b;\" href=\"/lw/lc5/group_rationality_diary_december_115/\">December 1-15</a></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Next diary:&nbsp;<a href=\"/r/discussion/lw/lgv/group_rationality_diary_january_115/\">January 1-15</a></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality diaries archive</a></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "z87oRFkoCBe4yySfF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "27726", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["e5HxstneFmGdJhFfz", "tmDoJPSkyqkHgYABW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-15T05:44:32.795Z", "modifiedAt": null, "url": null, "title": "Has LessWrong Ever Backfired On You?", "slug": "has-lesswrong-ever-backfired-on-you", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:02.974Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Evan_Gaensbauer", "createdAt": "2014-09-12T19:01:13.514Z", "isAdmin": false, "displayName": "Evan_Gaensbauer"}, "userId": "frmmRPSrWjbk8BHx8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KbXE7t63G3oZ5ZSGh/has-lesswrong-ever-backfired-on-you", "pageUrlRelative": "/posts/KbXE7t63G3oZ5ZSGh/has-lesswrong-ever-backfired-on-you", "linkUrl": "https://www.lesswrong.com/posts/KbXE7t63G3oZ5ZSGh/has-lesswrong-ever-backfired-on-you", "postedAtFormatted": "Monday, December 15th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Has%20LessWrong%20Ever%20Backfired%20On%20You%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHas%20LessWrong%20Ever%20Backfired%20On%20You%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKbXE7t63G3oZ5ZSGh%2Fhas-lesswrong-ever-backfired-on-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Has%20LessWrong%20Ever%20Backfired%20On%20You%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKbXE7t63G3oZ5ZSGh%2Fhas-lesswrong-ever-backfired-on-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKbXE7t63G3oZ5ZSGh%2Fhas-lesswrong-ever-backfired-on-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 97, "htmlBody": "<div id=\"body_t1_bp2m\" class=\"comment-content \" style=\"clear: both; padding: 9px 0px 0px; font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 18px; text-align: justify; background-color: #f7f7f8;\">\n<div class=\"md\">\n<p style=\"margin: 0px 0px 1em;\">Several weeks ago I wrote a heavily upvoted post called&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/l5w/dont_be_afraid_of_asking_personally_important/\"><strong><em>Don't Be Afraid of Asking Personally Important Questions on LessWrong</em></strong></a>. I thought it would only be due diligence if I tried to track users on LessWrong who have received advice on this site and it's backfired. In other words, to avoid bias in the record, we might notice what LessWrong as a community is bad at giving advice about. So, I'm seeking feedback. If you have anecdotes or data of how a plan or advice directly from LessWrong backfired, failed, or didn't lead to satisfaction, please share below.&nbsp;</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KbXE7t63G3oZ5ZSGh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 36, "extendedScore": null, "score": 0.000166, "legacy": true, "legacyId": "27727", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["twJaro2hsjQzYzuwg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-15T18:11:39.098Z", "modifiedAt": null, "url": null, "title": "How many people am I?", "slug": "how-many-people-am-i", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:38.919Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/brLgyCqZaMDjGPKsp/how-many-people-am-i", "pageUrlRelative": "/posts/brLgyCqZaMDjGPKsp/how-many-people-am-i", "linkUrl": "https://www.lesswrong.com/posts/brLgyCqZaMDjGPKsp/how-many-people-am-i", "postedAtFormatted": "Monday, December 15th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20many%20people%20am%20I%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20many%20people%20am%20I%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbrLgyCqZaMDjGPKsp%2Fhow-many-people-am-i%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20many%20people%20am%20I%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbrLgyCqZaMDjGPKsp%2Fhow-many-people-am-i", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbrLgyCqZaMDjGPKsp%2Fhow-many-people-am-i", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 733, "htmlBody": "<p>Strongly related: the&nbsp;<a href=\"/lw/ps/where_physics_meets_experience/\">Ebborians</a></p>\n<p>Imagine mapping my brain into two interpenetrating networks. For each brain cell, half of it goes to one map and half to the other. For each connection between cells, half of each connection goes to one map and half to the other. We can call these two mapped out halves Manfred One and Manfred Two. Because neurons are classical, as I think, both of these maps change together. They contain the full pattern of my thoughts. (This situation is even more clear in the Ebborians, who can literally split down the middle.)</p>\n<p>So how many people am I? Are Manfred One and Manfred Two both people? Of course, once we have two, why stop there - are there thousands of Manfreds in here, with \"me\" as only one of them? Put like that it sounds a little overwrought - what's really going on here is the question of what physical system corresponds to \"I\" in english statements like \"I wake up.\" This may matter.</p>\n<p>The impact on anthropic probabilities is somewhat straightforward. With everyday definitions of \"I wake up,\" I wake up just once per day no matter how big my head is. But if the \"I\" in that sentence is some constant-size physical pattern, then \"I wake up\" is an event that happens more times if my head is bigger. And so using the variable people-number definition, I expect to wake up with a gigantic head.</p>\n<p>The impact on decisions is less big. If I'm in this head with a bunch of other Manfreds, we're all on the same page - it's a&nbsp;<a href=\"/lw/3dy/solve_psykoshs_nonanthropic_problem/\">non-anthropic problem</a>&nbsp;of coordinated decision-making. For example, if I were to make any monetary bets about my head size, and then donate profits to charity, no matter what definition I'm using, I should bet as if my head size didn't affect anthropic probabilities. So to some extent the real point of this effect is that it is a way anthropic probabilities can be ill-defined. On the other hand, what about preferences that depend directly on person-numbers like how to value people with different head sizes? Or for vegetarians, should we care more about cows than chickens, because each cow is more animals than a chicken is?</p>\n<p>&nbsp;</p>\n<p>According to my common sense, it seems like my body has just one person in it. Why does my common sense think that? I think there are two answers, one unhelpful and one helpful.</p>\n<p>The first answer is evolution. Having kids is an action that's independent of what physical system we identify with \"I,\" and so my ancestors never found modeling their bodies as being multiple people useful.</p>\n<p>The second answer is causality. Manfred One and Manfred Two are causally distinct from two copies of me in separate bodies but the same input/output. If a difference between the two separated copies arose somehow, (reminiscent of <a href=\"http://www.lehigh.edu/~mhb0/Dennett-WhereAmI.pdf\">Dennett's factual account</a>) henceforth the two bodies would do and say different things and have different brain states. But if some difference arises between Manfred One and Manfred Two, it is erased by diffusion.</p>\n<p>Which is to say, the map that is Manfred One is statically the same pattern as my whole brain, but it's causally different. So is \"I\" the pattern, or is \"I\" the causal system?&nbsp;</p>\n<p>In this sort of situation I am happy to stick with common sense, and thus when I say me, I think the causal system is referring to the causal system. But I'm not very sure.</p>\n<p>&nbsp;</p>\n<p>Going back to the Ebborians, one interesting thing about that post is the conflict between common sense and common sense - it seems like common sense that each Ebborian is equally much one person, but it also seems like common sense that if you looked at an Ebborian dividing, there doesn't seem to be a moment where the amount of subjective experience should change, and so amount of subjective experience should be proportional to thickness. But as it is said, just because there are two opposing ideas doesn't mean one of them is right.</p>\n<p>On the questions of subjective experience raised in that post, I think this mostly gets cleared up by precise description an &nbsp;anthropic narrowness. I'm unsure of the relative sizes of this margin and the proof, but the sketch is to replace a mysterious \"subjective experience\" that spans copies with individual experiences of people who are using a TDT-like theory to choose so that they individually achieve good outcomes given their existence.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "brLgyCqZaMDjGPKsp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 2.2711459061297977e-06, "legacy": true, "legacyId": "27667", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WajiC3YWeJutyAXTn", "YZzoWGCJsoRBBbmQg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-15T23:54:42.764Z", "modifiedAt": null, "url": null, "title": "Meetup : London Social Meetup, 21/12/2014", "slug": "meetup-london-social-meetup-21-12-2014", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tenoke", "createdAt": "2012-04-10T21:37:29.739Z", "isAdmin": false, "displayName": "Tenoke"}, "userId": "CRSZPEg9dHyMspTzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jwKqvQrGBBitvfkWw/meetup-london-social-meetup-21-12-2014", "pageUrlRelative": "/posts/jwKqvQrGBBitvfkWw/meetup-london-social-meetup-21-12-2014", "linkUrl": "https://www.lesswrong.com/posts/jwKqvQrGBBitvfkWw/meetup-london-social-meetup-21-12-2014", "postedAtFormatted": "Monday, December 15th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Social%20Meetup%2C%2021%2F12%2F2014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Social%20Meetup%2C%2021%2F12%2F2014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwKqvQrGBBitvfkWw%2Fmeetup-london-social-meetup-21-12-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Social%20Meetup%2C%2021%2F12%2F2014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwKqvQrGBBitvfkWw%2Fmeetup-london-social-meetup-21-12-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwKqvQrGBBitvfkWw%2Fmeetup-london-social-meetup-21-12-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/180'>London Social Meetup, 21/12/2014</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 December 2014 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having another meetup this Sunday (21/12) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:</p>\n\n<p>We run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/180'>London Social Meetup, 21/12/2014</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jwKqvQrGBBitvfkWw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.3e-05, "legacy": true, "legacyId": "27731", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Social_Meetup__21_12_2014\">Discussion article for the meetup : <a href=\"/meetups/180\">London Social Meetup, 21/12/2014</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 December 2014 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having another meetup this Sunday (21/12) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:</p>\n\n<p>We run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_Social_Meetup__21_12_20141\">Discussion article for the meetup : <a href=\"/meetups/180\">London Social Meetup, 21/12/2014</a></h2>", "sections": [{"title": "Discussion article for the meetup : London Social Meetup, 21/12/2014", "anchor": "Discussion_article_for_the_meetup___London_Social_Meetup__21_12_2014", "level": 1}, {"title": "Discussion article for the meetup : London Social Meetup, 21/12/2014", "anchor": "Discussion_article_for_the_meetup___London_Social_Meetup__21_12_20141", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-16T01:01:42.234Z", "modifiedAt": null, "url": null, "title": "Kickstarting the audio version of the upcoming book \"The Sequences\"", "slug": "kickstarting-the-audio-version-of-the-upcoming-book-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:25:59.328Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Rick_from_Castify", "createdAt": "2012-12-03T09:33:28.512Z", "isAdmin": false, "displayName": "Rick_from_Castify"}, "userId": "XyTqQupkZ9SW7nGCB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RsR8DFhibWTvhxagK/kickstarting-the-audio-version-of-the-upcoming-book-the", "pageUrlRelative": "/posts/RsR8DFhibWTvhxagK/kickstarting-the-audio-version-of-the-upcoming-book-the", "linkUrl": "https://www.lesswrong.com/posts/RsR8DFhibWTvhxagK/kickstarting-the-audio-version-of-the-upcoming-book-the", "postedAtFormatted": "Tuesday, December 16th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Kickstarting%20the%20audio%20version%20of%20the%20upcoming%20book%20%22The%20Sequences%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKickstarting%20the%20audio%20version%20of%20the%20upcoming%20book%20%22The%20Sequences%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRsR8DFhibWTvhxagK%2Fkickstarting-the-audio-version-of-the-upcoming-book-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Kickstarting%20the%20audio%20version%20of%20the%20upcoming%20book%20%22The%20Sequences%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRsR8DFhibWTvhxagK%2Fkickstarting-the-audio-version-of-the-upcoming-book-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRsR8DFhibWTvhxagK%2Fkickstarting-the-audio-version-of-the-upcoming-book-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 131, "htmlBody": "<p>LessWrong is getting ready to release an actual book that covers most of the material found in the Sequences.&nbsp;</p>\n<p>There have been a few posts about it in the past, here are two: <a href=\"/lw/h7t/help_us_name_the_sequences_ebook/\">the </a><a href=\"/lw/h7t/help_us_name_the_sequences_ebook/\">title debate</a>, <a href=\"/lw/iop/help_us_optimize_the_contents_of_the_sequences/\">content optimization</a>.</p>\n<p>We've been asked if we'd like to produce the audiobook version and the answer is yes. This is a large undertaking. The finished product will probably be over 35 hours of audio.</p>\n<p>To help mitigate our risk we've decided to Kickstarter the audiobook.&nbsp; This basically allows us to pre-sell it so we're not stuck with a large production cost and no revenue.&nbsp;</p>\n<p>The kickstarter campaign is here: <a href=\"https://www.kickstarter.com/projects/1267969302/lesswrong-the-sequences-audiobook\">https://www.kickstarter.com/projects/1267969302/lesswrong-the-sequences-audiobook</a></p>\n<p>If you haven't heard of us before we've already produced some sequences into audiobooks.&nbsp; You can see them and listen to samples which are indicative of the audio quality <a href=\"http://castify.co/channels/\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"w2CXH4hsQtihvwT4v": 1, "izp6eeJJEg9v5zcur": 1, "JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RsR8DFhibWTvhxagK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 47, "extendedScore": null, "score": 2.272065681659667e-06, "legacy": true, "legacyId": "27700", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Hmc2NE6oTipCvuZdN", "ZsDmi6XbLu3LF3gi7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-16T02:00:53.128Z", "modifiedAt": null, "url": null, "title": "Superintelligence 14: Motivation selection methods", "slug": "superintelligence-14-motivation-selection-methods", "viewCount": null, "lastCommentedAt": "2015-02-09T23:33:26.848Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FBEaheqfmDgL6gB5x/superintelligence-14-motivation-selection-methods", "pageUrlRelative": "/posts/FBEaheqfmDgL6gB5x/superintelligence-14-motivation-selection-methods", "linkUrl": "https://www.lesswrong.com/posts/FBEaheqfmDgL6gB5x/superintelligence-14-motivation-selection-methods", "postedAtFormatted": "Tuesday, December 16th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligence%2014%3A%20Motivation%20selection%20methods&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligence%2014%3A%20Motivation%20selection%20methods%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFBEaheqfmDgL6gB5x%2Fsuperintelligence-14-motivation-selection-methods%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligence%2014%3A%20Motivation%20selection%20methods%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFBEaheqfmDgL6gB5x%2Fsuperintelligence-14-motivation-selection-methods", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFBEaheqfmDgL6gB5x%2Fsuperintelligence-14-motivation-selection-methods", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1421, "htmlBody": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr />\n<p>Welcome. This week we discuss the fourteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Motivation selection methods</strong></em>. This corresponds to the second part of Chapter Nine.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: &ldquo;Motivation selection methods&rdquo; and &ldquo;Synopsis&rdquo; from Chapter 9.</p>\n<hr />\n<h1>Summary</h1>\n<ol>\n<li><strong>One way to control an AI is to design its motives</strong>. That is, to choose what it wants to do (p138)</li>\n<li>Some varieties of 'motivation selection' for AI safety:<ol>\n<li><em><strong>Direct specification</strong></em>: figure out what we value, and code it into the AI (p139-40)<ol>\n<li>Isaac Asimov's 'three laws of robotics' are a famous example</li>\n<li>Direct specification might be fairly hard: both figuring out what we want and coding it precisely seem hard</li>\n<li>This could be based on rules, or something like consequentialism</li>\n</ol></li>\n<li><em><strong>Domesticity</strong></em>: the AI's goals limit the range of things it wants to interfere with (140-1)<ol>\n<li>This might make direct specification easier, as the world the AI interacts with (and thus which has to be thought of in specifying its behavior) is simpler.</li>\n<li>Oracles are an example</li>\n<li>This might be combined well with physical containment: the AI could be trapped, and also not want to escape.</li>\n</ol></li>\n<li><em style=\"font-weight: bold;\">Indirect normativity</em>: instead of specifying what we value, specify a way to specify what we value (141-2)<ol>\n<li>e.g. extrapolate our volition</li>\n<li>This means outsourcing the hard intellectual work to the AI</li>\n<li>This will mostly be discussed in chapter 13 (weeks 23-5 here)</li>\n</ol></li>\n<li><strong><em>Augmentation</em></strong>: begin with a creature with desirable motives, then make it smarter, instead of designing good motives from scratch. (p142)<ol>\n<li>e.g. brain emulations are likely to have human desires (at least at the start)</li>\n<li>Whether we use this method depends on the kind of AI that is developed, so usually we won't have a choice about whether to use it (except inasmuch as we have a choice about e.g. whether to develop uploads or synthetic AI first).</li>\n</ol></li>\n</ol></li>\n<li>Bostrom provides a summary of the chapter:<br /><img src=\"http://images.lesswrong.com/t3_l9r_0.png\" alt=\"\" width=\"500\" /></li>\n<li>The question is not which control method is best, but rather which set of control methods are best given the situation. (143-4)</li>\n</ol>\n<h1>Another view</h1>\n<p><span style=\"color: #222222; font-family: arial, sans-serif;\"><a href=\"http://www.reddit.com/r/science/comments/2hbp21/science_ama_series_im_nick_bostrom_director_of/ckrbdnx\">Icelizarrd</a>:</span></p>\n<blockquote>\n<p><span style=\"color: #222222; font-family: arial, sans-serif;\">Would you say there's any ethical issue involved with imposing limits or constraints on a superintelligence's drives/motivations? By analogy, I think most of us have the moral intuition that technologically interfering with an unborn human's inherent desires and motivations would be questionable or wrong, supposing that were even possible. That is, say we could genetically modify a subset of humanity to be cheerful slaves; that seems like a pretty morally unsavory prospect. What makes engineering a superintelligence specifically to serve humanity less unsavory?</span></p>\n</blockquote>\n<h1>Notes</h1>\n<p>1. Bostrom tells us that it is very hard to specify human values. We have seen examples of galaxies full of paperclips or fake smiles resulting from poor specification. But these - and Isaac Asimov's stories - seem to tell us only that a few people spending a small fraction of their time thinking does not produce any watertight specification. What if a thousand researchers spent a decade on it? Are the millionth most obvious attempts at specification nearly as bad as the most obvious twenty? How hard is it? A general argument for pessimism is the thesis that <a href=\"/lw/y3/value_is_fragile/\">'value is fragile'</a>, i.e. that if you specify what you want very nearly but get it a tiny bit wrong, it's likely to be almost worthless. <a href=\"http://wiki.lesswrong.com/wiki/Complexity_of_value\">Much like</a> if you get one digit wrong in a phone number. The degree to which this is so (with respect to value, not phone numbers) is controversial. I encourage you to try to specify a world you would be happy with (to see how hard it is, or produce something of value if it isn't that hard).</p>\n<p>2. If you'd like a taste of indirect normativity before the chapter on it, the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition\">LessWrong wiki page</a>&nbsp;on coherent extrapolated volition links to a bunch of sources.</p>\n<p>3. The idea of 'indirect normativity' (i.e. outsourcing the problem of specifying what an AI should do, by giving it some good instructions for figuring out what you value) brings up the general question of just what an AI needs to be given to be able to figure out how to carry out our will. An obvious contender is a lot of information about human values. Though some people disagree with this - these people don't buy the&nbsp;<a href=\"/lw/l4g/superintelligence_9_the_orthogonality_of/\">orthogonality thesis</a>. Other issues sometimes suggested to need working out ahead of outsourcing everything to AIs include decision theory, priors, anthropics, feelings about&nbsp;<a href=\"http://www.nickbostrom.com/papers/pascal.pdf\">pascal's mugging</a>, and attitudes to infinity.&nbsp;<a href=\"http://intelligence.org/\">MIRI</a>'s technical work often fits into this category.</p>\n<p>4. Danaher's&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2014/08/bostrom-on-superintelligence-6.html\">last post&nbsp;</a>on Superintelligence (so far) is on motivation selection. It mostly summarizes and clarifies the chapter, so is mostly good if you'd like to think about the question some more with a slightly different framing. He also previously considered the difficulty of specifying human values in&nbsp;<em>The golem genie and unfriendly AI&nbsp;</em>(parts&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2013/01/the-golem-genie-and-unfriendly-ai-part.html\">one</a>&nbsp;and&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2013/02/the-golem-genie-and-unfriendly-ai-part.html\">two</a>), which is about&nbsp;<a href=\"http://intelligence.org/files/IE-ME.pdf\">Intelligence Explosion and Machine Ethics</a>.</p>\n<p>5. Brian Clegg <a href=\"http://www.goodreads.com/review/show/982829583\">thinks</a> Bostrom should have discussed <a href=\"http://en.wikipedia.org/wiki/Three_Laws_of_Robotics\">Asimov's stories</a> at greater length:</p>\n<blockquote>\n<p><span style=\"color: #181818; font-family: Georgia, Times, 'Times New Roman', serif; font-size: 14px; line-height: 18px;\">I think it&rsquo;s a shame that Bostrom doesn&rsquo;t make more use of science fiction to give examples of how people have already thought about these issues &ndash; he gives only half a page to Asimov and the three laws of robotics (and how Asimov then spends most of his time showing how they&rsquo;d go wrong), but that&rsquo;s about it. Yet there has been a lot of thought and dare I say it, a lot more readability than you typically get in a textbook, put into the issues in science fiction than is being allowed for, and it would have been worthy of a chapter in its own right.</span><br style=\"color: #181818; font-family: Georgia, Times, 'Times New Roman', serif; font-size: 14px; line-height: 18px;\" /></p>\n</blockquote>\n<p>If you haven't already, you might consider (sort-of) following his advice, and reading<a href=\"http://www.amazon.com/Complete-Robot-Isaac-Asimov/dp/0586057242/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1418695204&amp;sr=1-2&amp;keywords=asimov+i+robot\"> some science fiction</a>.</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9r_1.png?v=c8774766b9faeca46d905332c5f96356\" alt=\"\" width=\"206\" height=\"334\" /></p>\n<p><span style=\"font-size: 2em;\">In-depth investigations</span></p>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>Can you think of novel methods of specifying the values of one or many humans?</li>\n<li>What are the most promising methods for 'domesticating' an AI? (i.e. constraining it to only care about a small part of the world, and not want to interfere with the larger world to optimize that smaller part).</li>\n<li>Think more carefully about the likely motivations of drastically augmenting brain emulations</li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1>How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will start to talk about a variety of more and less agent-like AIs: 'oracles', genies' and 'sovereigns'. To prepare,&nbsp;<strong>read</strong>&nbsp;Chapter&nbsp;&ldquo;Oracles&rdquo; and &ldquo;Genies and Sovereigns&rdquo; from Chapter 10<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 22nd December. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1, "tdt83ChxnEgwwKxi6": 1, "NLwTnsH9RSotqXYLw": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FBEaheqfmDgL6gB5x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 2.2721984843722177e-06, "legacy": true, "legacyId": "27567", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr>\n<p>Welcome. This week we discuss the fourteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Motivation selection methods</strong></em>. This corresponds to the second part of Chapter Nine.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: \u201cMotivation selection methods\u201d and \u201cSynopsis\u201d from Chapter 9.</p>\n<hr>\n<h1 id=\"Summary\">Summary</h1>\n<ol>\n<li><strong>One way to control an AI is to design its motives</strong>. That is, to choose what it wants to do (p138)</li>\n<li>Some varieties of 'motivation selection' for AI safety:<ol>\n<li><em><strong>Direct specification</strong></em>: figure out what we value, and code it into the AI (p139-40)<ol>\n<li>Isaac Asimov's 'three laws of robotics' are a famous example</li>\n<li>Direct specification might be fairly hard: both figuring out what we want and coding it precisely seem hard</li>\n<li>This could be based on rules, or something like consequentialism</li>\n</ol></li>\n<li><em><strong>Domesticity</strong></em>: the AI's goals limit the range of things it wants to interfere with (140-1)<ol>\n<li>This might make direct specification easier, as the world the AI interacts with (and thus which has to be thought of in specifying its behavior) is simpler.</li>\n<li>Oracles are an example</li>\n<li>This might be combined well with physical containment: the AI could be trapped, and also not want to escape.</li>\n</ol></li>\n<li><em style=\"font-weight: bold;\">Indirect normativity</em>: instead of specifying what we value, specify a way to specify what we value (141-2)<ol>\n<li>e.g. extrapolate our volition</li>\n<li>This means outsourcing the hard intellectual work to the AI</li>\n<li>This will mostly be discussed in chapter 13 (weeks 23-5 here)</li>\n</ol></li>\n<li><strong><em>Augmentation</em></strong>: begin with a creature with desirable motives, then make it smarter, instead of designing good motives from scratch. (p142)<ol>\n<li>e.g. brain emulations are likely to have human desires (at least at the start)</li>\n<li>Whether we use this method depends on the kind of AI that is developed, so usually we won't have a choice about whether to use it (except inasmuch as we have a choice about e.g. whether to develop uploads or synthetic AI first).</li>\n</ol></li>\n</ol></li>\n<li>Bostrom provides a summary of the chapter:<br><img src=\"http://images.lesswrong.com/t3_l9r_0.png\" alt=\"\" width=\"500\"></li>\n<li>The question is not which control method is best, but rather which set of control methods are best given the situation. (143-4)</li>\n</ol>\n<h1 id=\"Another_view\">Another view</h1>\n<p><span style=\"color: #222222; font-family: arial, sans-serif;\"><a href=\"http://www.reddit.com/r/science/comments/2hbp21/science_ama_series_im_nick_bostrom_director_of/ckrbdnx\">Icelizarrd</a>:</span></p>\n<blockquote>\n<p><span style=\"color: #222222; font-family: arial, sans-serif;\">Would you say there's any ethical issue involved with imposing limits or constraints on a superintelligence's drives/motivations? By analogy, I think most of us have the moral intuition that technologically interfering with an unborn human's inherent desires and motivations would be questionable or wrong, supposing that were even possible. That is, say we could genetically modify a subset of humanity to be cheerful slaves; that seems like a pretty morally unsavory prospect. What makes engineering a superintelligence specifically to serve humanity less unsavory?</span></p>\n</blockquote>\n<h1 id=\"Notes\">Notes</h1>\n<p>1. Bostrom tells us that it is very hard to specify human values. We have seen examples of galaxies full of paperclips or fake smiles resulting from poor specification. But these - and Isaac Asimov's stories - seem to tell us only that a few people spending a small fraction of their time thinking does not produce any watertight specification. What if a thousand researchers spent a decade on it? Are the millionth most obvious attempts at specification nearly as bad as the most obvious twenty? How hard is it? A general argument for pessimism is the thesis that <a href=\"/lw/y3/value_is_fragile/\">'value is fragile'</a>, i.e. that if you specify what you want very nearly but get it a tiny bit wrong, it's likely to be almost worthless. <a href=\"http://wiki.lesswrong.com/wiki/Complexity_of_value\">Much like</a> if you get one digit wrong in a phone number. The degree to which this is so (with respect to value, not phone numbers) is controversial. I encourage you to try to specify a world you would be happy with (to see how hard it is, or produce something of value if it isn't that hard).</p>\n<p>2. If you'd like a taste of indirect normativity before the chapter on it, the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition\">LessWrong wiki page</a>&nbsp;on coherent extrapolated volition links to a bunch of sources.</p>\n<p>3. The idea of 'indirect normativity' (i.e. outsourcing the problem of specifying what an AI should do, by giving it some good instructions for figuring out what you value) brings up the general question of just what an AI needs to be given to be able to figure out how to carry out our will. An obvious contender is a lot of information about human values. Though some people disagree with this - these people don't buy the&nbsp;<a href=\"/lw/l4g/superintelligence_9_the_orthogonality_of/\">orthogonality thesis</a>. Other issues sometimes suggested to need working out ahead of outsourcing everything to AIs include decision theory, priors, anthropics, feelings about&nbsp;<a href=\"http://www.nickbostrom.com/papers/pascal.pdf\">pascal's mugging</a>, and attitudes to infinity.&nbsp;<a href=\"http://intelligence.org/\">MIRI</a>'s technical work often fits into this category.</p>\n<p>4. Danaher's&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2014/08/bostrom-on-superintelligence-6.html\">last post&nbsp;</a>on Superintelligence (so far) is on motivation selection. It mostly summarizes and clarifies the chapter, so is mostly good if you'd like to think about the question some more with a slightly different framing. He also previously considered the difficulty of specifying human values in&nbsp;<em>The golem genie and unfriendly AI&nbsp;</em>(parts&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2013/01/the-golem-genie-and-unfriendly-ai-part.html\">one</a>&nbsp;and&nbsp;<a href=\"http://philosophicaldisquisitions.blogspot.com/2013/02/the-golem-genie-and-unfriendly-ai-part.html\">two</a>), which is about&nbsp;<a href=\"http://intelligence.org/files/IE-ME.pdf\">Intelligence Explosion and Machine Ethics</a>.</p>\n<p>5. Brian Clegg <a href=\"http://www.goodreads.com/review/show/982829583\">thinks</a> Bostrom should have discussed <a href=\"http://en.wikipedia.org/wiki/Three_Laws_of_Robotics\">Asimov's stories</a> at greater length:</p>\n<blockquote>\n<p><span style=\"color: #181818; font-family: Georgia, Times, 'Times New Roman', serif; font-size: 14px; line-height: 18px;\">I think it\u2019s a shame that Bostrom doesn\u2019t make more use of science fiction to give examples of how people have already thought about these issues \u2013 he gives only half a page to Asimov and the three laws of robotics (and how Asimov then spends most of his time showing how they\u2019d go wrong), but that\u2019s about it. Yet there has been a lot of thought and dare I say it, a lot more readability than you typically get in a textbook, put into the issues in science fiction than is being allowed for, and it would have been worthy of a chapter in its own right.</span><br style=\"color: #181818; font-family: Georgia, Times, 'Times New Roman', serif; font-size: 14px; line-height: 18px;\"></p>\n</blockquote>\n<p>If you haven't already, you might consider (sort-of) following his advice, and reading<a href=\"http://www.amazon.com/Complete-Robot-Isaac-Asimov/dp/0586057242/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1418695204&amp;sr=1-2&amp;keywords=asimov+i+robot\"> some science fiction</a>.</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9r_1.png?v=c8774766b9faeca46d905332c5f96356\" alt=\"\" width=\"206\" height=\"334\"></p>\n<p><span style=\"font-size: 2em;\">In-depth investigations</span></p>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>Can you think of novel methods of specifying the values of one or many humans?</li>\n<li>What are the most promising methods for 'domesticating' an AI? (i.e. constraining it to only care about a small part of the world, and not want to interfere with the larger world to optimize that smaller part).</li>\n<li>Think more carefully about the likely motivations of drastically augmenting brain emulations</li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1 id=\"How_to_proceed\">How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will start to talk about a variety of more and less agent-like AIs: 'oracles', genies' and 'sovereigns'. To prepare,&nbsp;<strong>read</strong>&nbsp;Chapter&nbsp;\u201cOracles\u201d and \u201cGenies and Sovereigns\u201d from Chapter 10<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 22nd December. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "sections": [{"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Another view", "anchor": "Another_view", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "How to proceed", "anchor": "How_to_proceed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "28 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QDmzDZ9CEHrKQdvcn", "GNnHHmm8EzePmKzPk", "FtAJZWCMps7FWKTT3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-16T19:42:07.249Z", "modifiedAt": null, "url": null, "title": "Meetup : Sandy, UT - Debugging", "slug": "meetup-sandy-ut-debugging", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hamnox", "createdAt": "2011-01-17T01:16:28.722Z", "isAdmin": false, "displayName": "hamnox"}, "userId": "EY9o6qtXvYhS5CTHD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5Ku96n8GhoeWYMFiZ/meetup-sandy-ut-debugging", "pageUrlRelative": "/posts/5Ku96n8GhoeWYMFiZ/meetup-sandy-ut-debugging", "linkUrl": "https://www.lesswrong.com/posts/5Ku96n8GhoeWYMFiZ/meetup-sandy-ut-debugging", "postedAtFormatted": "Tuesday, December 16th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Sandy%2C%20UT%20-%20Debugging&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Sandy%2C%20UT%20-%20Debugging%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5Ku96n8GhoeWYMFiZ%2Fmeetup-sandy-ut-debugging%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Sandy%2C%20UT%20-%20Debugging%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5Ku96n8GhoeWYMFiZ%2Fmeetup-sandy-ut-debugging", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5Ku96n8GhoeWYMFiZ%2Fmeetup-sandy-ut-debugging", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 129, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/181'>Sandy, UT - Debugging</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">19 December 2014 12:00:30PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">9425 S Riverside Dr. Sandy, UT</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Make friends, learn skills, and build solutions!</p>\n\n<p>Meetup is in the main building, you can just walk in.\nAgenda:\nQuick Definitions - What is Life Debugging?\nBrainstorm Bugs to work on</p>\n\n<p>Skill 1: Surprise-o-Meter\n   How surprised would you be if everything actually worked out perfectly? How surprised would you be if obstacle X derailed you?</p>\n\n<p>Skill 2: Urge Propagation\n   Half the battle is won If you can get your system-1 on board with your carefully-laid plans.</p>\n\n<p>Strongly suspect Carrie, who leads our Thinking Fast and Slow book club, won't make this one, so that's on hiatus.</p>\n\n<p>Idea for meetup shamelessly stolen from Katja</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/181'>Sandy, UT - Debugging</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5Ku96n8GhoeWYMFiZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.2745822179117454e-06, "legacy": true, "legacyId": "27734", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Sandy__UT___Debugging\">Discussion article for the meetup : <a href=\"/meetups/181\">Sandy, UT - Debugging</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">19 December 2014 12:00:30PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">9425 S Riverside Dr. Sandy, UT</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Make friends, learn skills, and build solutions!</p>\n\n<p>Meetup is in the main building, you can just walk in.\nAgenda:\nQuick Definitions - What is Life Debugging?\nBrainstorm Bugs to work on</p>\n\n<p>Skill 1: Surprise-o-Meter\n   How surprised would you be if everything actually worked out perfectly? How surprised would you be if obstacle X derailed you?</p>\n\n<p>Skill 2: Urge Propagation\n   Half the battle is won If you can get your system-1 on board with your carefully-laid plans.</p>\n\n<p>Strongly suspect Carrie, who leads our Thinking Fast and Slow book club, won't make this one, so that's on hiatus.</p>\n\n<p>Idea for meetup shamelessly stolen from Katja</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Sandy__UT___Debugging1\">Discussion article for the meetup : <a href=\"/meetups/181\">Sandy, UT - Debugging</a></h2>", "sections": [{"title": "Discussion article for the meetup : Sandy, UT - Debugging", "anchor": "Discussion_article_for_the_meetup___Sandy__UT___Debugging", "level": 1}, {"title": "Discussion article for the meetup : Sandy, UT - Debugging", "anchor": "Discussion_article_for_the_meetup___Sandy__UT___Debugging1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-16T22:27:39.519Z", "modifiedAt": null, "url": null, "title": "New paper from MIRI: \"Toward idealized decision theory\"", "slug": "new-paper-from-miri-toward-idealized-decision-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.103Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "So8res", "createdAt": "2012-01-10T05:50:18.713Z", "isAdmin": false, "displayName": "So8res"}, "userId": "xSfc2APSi8WzFxp7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3aQizCnaNEfda32DM/new-paper-from-miri-toward-idealized-decision-theory", "pageUrlRelative": "/posts/3aQizCnaNEfda32DM/new-paper-from-miri-toward-idealized-decision-theory", "linkUrl": "https://www.lesswrong.com/posts/3aQizCnaNEfda32DM/new-paper-from-miri-toward-idealized-decision-theory", "postedAtFormatted": "Tuesday, December 16th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20paper%20from%20MIRI%3A%20%22Toward%20idealized%20decision%20theory%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20paper%20from%20MIRI%3A%20%22Toward%20idealized%20decision%20theory%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3aQizCnaNEfda32DM%2Fnew-paper-from-miri-toward-idealized-decision-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20paper%20from%20MIRI%3A%20%22Toward%20idealized%20decision%20theory%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3aQizCnaNEfda32DM%2Fnew-paper-from-miri-toward-idealized-decision-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3aQizCnaNEfda32DM%2Fnew-paper-from-miri-toward-idealized-decision-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1033, "htmlBody": "<p>I'm pleased to announce a new paper from MIRI:&nbsp;<em><a href=\"http://intelligence.org/files/TowardIdealizedDecisionTheory.pdf\">Toward Idealized Decision Theory</a></em>.</p>\n<p>Abstract:</p>\n<blockquote>\n<p>This paper motivates the study of decision theory as necessary for aligning smarter-than-human artificial systems with human interests. We discuss the shortcomings of two standard formulations of decision theory, and demonstrate that they cannot be used to describe an idealized decision procedure suitable for approximation by artificial systems. We then explore the notions of <em>strategy selection</em> and <em>logical counterfactuals</em>, two recent insights into decision theory that point the way toward promising paths for future research.</p>\n</blockquote>\n<p>Following the <a href=\"http://intelligence.org/files/Corrigibility.pdf\">Corrigibility paper</a>, this is the second in a series of six papers motivating MIRI's active research areas. Also included in the series will be a technical agenda, which motivates all six research areas and describes the reasons why we have selected these topics in particular, and an annotated bibliography, which compiles a fair bit of related work. I plan to post one paper every week or two for the next few months.</p>\n<p>I've decided to start with the decision theory paper, as it's one of the meatiest. This paper compiles and summarizes quite a bit of work on decision theory that was done right here on LessWrong. There is a lot more to be said on the subject of decision theory than can fit into a single paper, but I think this one does a fairly good job of describing why we're interested in the field and summarizing some recent work in the area. The introduction is copied below. Enjoy!</p>\n<p><a id=\"more\"></a></p>\n<hr />\n<p>As artificially intelligent machines grow more capable and autonomous, the behavior of their decision procedures becomes increasingly important. This is especially true in systems possessing great general intelligence: superintelligent systems could have a massive impact on the world (<a href=\"http://books.google.com/books/about/Superintelligence.html?id=7_H8AwAAQBAJ\">Bostrom 2014</a>), and if a superintelligent system made poor decisions (by human standards) at a critical juncture, the results could be catastrophic (Yudkowsky 2008). When constructing systems capable of attaining superintelligence, it is important for them to use highly reliable decision procedures.</p>\n<p>Verifying that a system works well in test conditions is not sufficient for high confidence. Consider the genetic algorithm of Bird and Layzell (<a href=\"https://web.duke.edu/isis/gessler/topics/evolved-radio.pdf\">2002</a>), which, if run on a simulated representation of a circuit board, would have evolved an oscillating circuit. Running in reality, the algorithm instead re-purposed the circuit tracks on its motherboard as a makeshift radio to amplified oscillating signals from nearby computers. Smarter-than-human systems acting in reality may encounter situations beyond both the experience and the imagination of the programmers. In order to verify that an intelligent system would make good decisions in the real world, it is important to have a theoretical understanding of why that algorithm, specifically, is expected to make good decisions even in unanticipated scenarios.</p>\n<p>What does it mean to \"make good decisions\"? To formalize the question, it is necessary to precisely define a process that takes a problem description and identifies the best available decision (with respect to some set of preferences<sup>1</sup>). Such a process could not be <em>run</em>, of course; but it would demonstrate a full understanding of the problem of decision-making. If someone cannot formally state what it means to find the best decision in theory, then they are probably not ready to construct heuristics that attempt to find the best decision in practice.</p>\n<p>At first glance, formalizing an idealized process which identifies the best decision in theory may seem trivial: iterate over all available actions, calculate the utility that would be attained in expectation if that action were taken, and select the action which maximizes expected utility. But what are the available actions? And what are the counterfactual universes corresponding to what \"would happen\" if an action \"were taken\"? These questions are more difficult than they may seem.</p>\n<p>The difficulty is easiest to illustrate in a deterministic setting. Consider a deterministic decision procedure embedded in a deterministic environment. There is exactly one action that the decision procedure is going to select. What, then, are the actions it \"could have taken\"? Identifying this set may not be easy, especially if the line between agent and environment is blurry. (Recall the genetic algorithm repurposing the motherboard as a radio.) However, action identification is not the focus of this paper.</p>\n<p>This paper focuses on the problem of evaluating each action <em>given</em> the action set. The deterministic algorithm will only take one of the available actions; how is the counterfactual environment constructed, in which a deterministic part of the environment does something it doesn't? Answering this question requires a satisfactory theory of counterfactual reasoning, and that theory does not yet exist.</p>\n<p>Many problems are characterized by their idealized solutions, and the problem of decision-making is no exception. To fully describe the problem faced by intelligent agents making decisions, it is necessary to provide an idealized procedure which takes a description of an environment and one of the agents within, and identifies the best action available to that agent. Philosophers have studied candidate procedures for quite some time, under the name of <em>decision theory</em>. The investigation of what is now called decision theory stretches back to Pascal and Bernoulli; more recently decision theory has been studied by Wald (1939), Lehmann (1950), Jeffrey (1965), Lewis (1981), Joyce (1999), Pearl (2000) and many others.</p>\n<p>Various formulations of decision theory correspond to different ways of formalizing counterfactual reasoning. Unfortunately, the standard answers from the literature do not allow for the description of an idealized decision procedure. Two common formulations and their shortcomings are discussed in Section 2. Section 3 argues that these shortcomings imply the need for a better theory of counterfactual reasoning to fully describe the problem that artificially intelligent systems face when selecting actions. Sections 4 and 5 discuss two recent insights that give some reason for optimism and point the way toward promising avenues for future research. Nevertheless, Section 6 briefly discusses the pessimistic scenario in which it is not possible to fully formalize the problem of decision-making before the need arises for robust decision-making heuristics. Section 7 concludes by tying this study of decision theory back to the more general problem of aligning smarter-than-human systems with human interests.</p>\n<p><small>1: For simplicity, assume <a href=\"http://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem\">von Neumann-Morgenstern rational preferences</a>, that is, preferences describable by some utility function. The problems of decision theory arise regardless of how preferences are encoded.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NrvXXL3iGjjxu5B7d": 2, "ksdiAMKfgSyEeKMo6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3aQizCnaNEfda32DM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 41, "extendedScore": null, "score": 0.000122, "legacy": true, "legacyId": "27735", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-17T00:06:50.086Z", "modifiedAt": null, "url": null, "title": "\"incomparable\" outcomes--multiple utility functions?", "slug": "incomparable-outcomes-multiple-utility-functions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.223Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emanresu", "createdAt": "2014-02-10T19:06:18.487Z", "isAdmin": false, "displayName": "Emanresu"}, "userId": "4upK2b4reKQBgSvei", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k2nAeg33jPuRbdfee/incomparable-outcomes-multiple-utility-functions", "pageUrlRelative": "/posts/k2nAeg33jPuRbdfee/incomparable-outcomes-multiple-utility-functions", "linkUrl": "https://www.lesswrong.com/posts/k2nAeg33jPuRbdfee/incomparable-outcomes-multiple-utility-functions", "postedAtFormatted": "Wednesday, December 17th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22incomparable%22%20outcomes--multiple%20utility%20functions%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22incomparable%22%20outcomes--multiple%20utility%20functions%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk2nAeg33jPuRbdfee%2Fincomparable-outcomes-multiple-utility-functions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22incomparable%22%20outcomes--multiple%20utility%20functions%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk2nAeg33jPuRbdfee%2Fincomparable-outcomes-multiple-utility-functions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk2nAeg33jPuRbdfee%2Fincomparable-outcomes-multiple-utility-functions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 343, "htmlBody": "<p>I know that this idea might sound a little weird at first, so just hear me out please?</p>\n<p>A couple weeks ago I was pondering decision problems where a human decision maker has to choose between two acts that lead to two \"incomparable\" outcomes. I thought, if outcome A is not more preferred than outcome B, and outcome B is not more preferred than outcome A, then of course the decision maker is indifferent between both outcomes, right? But if that's the case, the decision maker should be able to just flip a coin to decide. Not only that, but adding even a tiny amount of extra value to one of the outcomes should always make that outcome be preferred. So why can't a human decision maker just make up their mind about their preferences between \"incomparable\" outcomes until they're forced to choose between them? Also, if a human decision maker is really indifferent between both outcomes, then they should be able to know that ahead of time and have a plan for deciding, such as flipping a coin. And, if they're really indifferent between both outcomes, then they should not be regretting and/or doubting their decision before an outcome even occurs regardless of which act they choose. Right?<br /><br />I thought of the idea that maybe the human decision maker has multiple utility functions that when you try to combine them into one function some parts of the original functions don't necessarily translate well. Like some sort of discontinuity that corresponds to \"incomparable\" outcomes, or something. Granted, it's been a while since I've taken Calculus, so I'm not really sure how that would look on a graph.<br /><br />I had read Yudkowsky's \"Thou Art Godshatter\" a couple months ago, and there was a point where it said \"one pure utility function splintered into a thousand shards of desire\". That sounds like the \"shards of desire\" are actually a bunch of different utility functions.<br /><br />I'd like to know what others think of this idea. Strengths? Weaknesses? Implications?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k2nAeg33jPuRbdfee", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 2.2751775045041713e-06, "legacy": true, "legacyId": "27736", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-17T02:54:42.900Z", "modifiedAt": null, "url": null, "title": "Using machine learning to predict romantic compatibility: empirical results", "slug": "using-machine-learning-to-predict-romantic-compatibility", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:02.366Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uBNj85TAB2cikby2W/using-machine-learning-to-predict-romantic-compatibility", "pageUrlRelative": "/posts/uBNj85TAB2cikby2W/using-machine-learning-to-predict-romantic-compatibility", "linkUrl": "https://www.lesswrong.com/posts/uBNj85TAB2cikby2W/using-machine-learning-to-predict-romantic-compatibility", "postedAtFormatted": "Wednesday, December 17th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Using%20machine%20learning%20to%20predict%20romantic%20compatibility%3A%20empirical%20results&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUsing%20machine%20learning%20to%20predict%20romantic%20compatibility%3A%20empirical%20results%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuBNj85TAB2cikby2W%2Fusing-machine-learning-to-predict-romantic-compatibility%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Using%20machine%20learning%20to%20predict%20romantic%20compatibility%3A%20empirical%20results%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuBNj85TAB2cikby2W%2Fusing-machine-learning-to-predict-romantic-compatibility", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuBNj85TAB2cikby2W%2Fusing-machine-learning-to-predict-romantic-compatibility", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3444, "htmlBody": "<h2>Overview</h2>\n<p>For many people, having a satisfying romantic relationship is one of the most important aspects of life. Over the past 10 years, online dating websites have gained traction, and dating websites have access to large amounts of data that could be used to build predictive models to achieve this goal. Such data is seldom public, but Columbia business school professors Ray Fisman and Sheena Iyengar compiled a rich and relevant data set for their paper <a href=\"http://faculty.chicagobooth.edu/emir.kamenica/documents/genderDifferences.pdf\">Gender Differences in Mate Selection: Evidence From a Speed Dating Experiment</a>. Their main results were:</p>\n<p style=\"padding-left: 30px;\"><em>Women put greater weight on the intelligence and the race of partner, while men respond more to physical attractiveness. Moreover, men do not value women&rsquo;s intelligence or ambition when it exceeds their own. Also, we find that women exhibit a preference for men who grew up in affluent neighborhoods. Finally, male selectivity is invariant to group size, while female selectivity is strongly increasing in group size.</em></p>\n<p>I found the study <a href=\"http://andrewgelman.com/2008/01/21/the_speeddating_1/\">through Andrew Gelman&rsquo;s blog</a>, where he wrote:</p>\n<p style=\"padding-left: 30px;\"><em>What I really want to do with these data is what I suggested to Ray and Sheena several years ago when they first told me about the study: a multilevel model that allows preferences to vary by person, not just by sex. Multilevel modeling would definitely be useful here, since you have something like 10 binary observations and 6 parameters to estimate for each person.</em></p>\n<p>Several months ago I decided to pursue a career in data science, and with a view toward building my skills, I worked to build a <strong>model to predict when an individual participant will express interest in seeing a given partner again</strong>. Along with the goal of learning, I had the dual intent of contributing knowledge that had the potential, however slight, to help people find satisfying romantic relationships.</p>\n<p>It&rsquo;s unlikely that what I did will have practical applications (as basic research seldom does), but I did learn a great deal about many things, most having to do with data science methodology in general, but also some about human behavior.</p>\n<p>This is the first of a series of posts where I report on my findings. A linear narrative would degenerate to a sprawling blog post that would be of little interest to anybody but me. In this post, I&rsquo;ll restrict focus to the question: <strong>how much predictive power can we get by estimating the generic selectivity and desirability of the people involved, without using information about the interactions between their traits? </strong></p>\n<p>I&rsquo;ll ultimately go into the details of the methodology that I used, including discussion of statistical significance, the rationale for making the decisions that I did the, and links to relevant code, but here I&rsquo;ll suppress technical detail in favor of relegating it to separate blog posts that might be of interest to a more specialized audience. In several places I speculate as to the meaning of the results. I&rsquo;ve made efforts to subject my reasoning to cross checks, but haven&rsquo;t gotten almost any external feedback yet, and I&rsquo;d welcome counter considerations, alternative hypotheses, etc. I&rsquo;m aware that there are places where claims that I make don&rsquo;t logically follow from what precedes them, and I&rsquo;m not so much looking for examples of this in general as much as I am instances where there&rsquo;s a sizable probability that I&rsquo;ve missed something that alters the bottom line conclusions.</p>\n<p><a id=\"more\"></a></p>\n<h2>Context on the dataset</h2>\n<p>The <a href=\"http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/\">dataset</a> was derived from 21 round-robin speed dating events held for Columbia graduate students, each attended by between 6 to 22 participants of each gender. To avoid small sample size issues, I restricted consideration to the 9 events with 14 or more people. These consisted of ~2500 speed dates, involving a total of ~160 participants of each gender. The subset that I looked at contains events that the authors of the original study excluded in their own paper because they involved the experimental intervention of asking subjects to bring a book to the event. The effect size of the intervention was small enough so that it doesn&rsquo;t alter bottom line conclusions.</p>\n<p>The dataset has a large number of features. I found that their predictive power was almost all contained in participants&rsquo; ratings of one another, which extended beyond a &ldquo;yes/no&rdquo; decision, also including ratings on dimensions such as attractiveness, sincerity, intelligence, fun and ambition. For brevity I&rsquo;ll refer to the person who made decision as the &ldquo;rater&rdquo; and his or her partner as the &ldquo;ratee.&rdquo; The core features that I used were essentially:</p>\n<ul>\n<li>The frequency with which the rater&rsquo;s decision on other ratees was &lsquo;yes.&rsquo;</li>\n<li>The frequency with which other raters' decision on the ratee was &lsquo;yes.&rsquo;</li>\n<li>Averages of ratings that others gave the rater and ratee.</li>\n</ul>\n<p>The actual features that I used were slightly modified versions of these. I&rsquo;ll give details in a future post.</p>\n<h2>Why ratings add incremental predictive power</h2>\n<p>In this blog post I&rsquo;m restricting consideration to signals of the partners&rsquo; general selectivity and general desirability, without considering how their traits interact. First approximations to a participant&rsquo;s desirability and selectivity come from the frequency with which members of the opposite sex expressed to see them again, and the frequency with which the participant expressed interest in seeing members of the opposite sex again.</p>\n<p>If the dataset contained information on a sufficiently large number of dates for each participant, <em>we could not improve on using these</em>. But the number of dates that each participant went on was small enough so that the decision frequencies are noisy, and we can do better by supplementing them with other features. There&rsquo;s a gender asymmetry to the situation: on average, men said yes 48.5% of the time and woman said yes 33.5% of the time, which means that the decision frequency metrics are noisier than is otherwise the case when the rater is a woman and the ratee is a man, so there&rsquo;s more room for improvement when predicting women&rsquo;s decisions than there is when predicting men&rsquo;s decisions.</p>\n<p>It&rsquo;s in principle possible for the average of a <em>single type of rating</em> to carry <em>more</em> information than decision frequencies. This is because the ratings were given on a scale from 1 to 10, whereas decisions have only two possible values (yes and no). This means that ratings can (in principle) reflect desirability or lack thereof at a greater level of granularity than decisions. As an example of this, if a rater has impossibly high standards and rejects everyone, the rater's <em>decisions</em> carry no information about the ratees, but the rater's <em>ratings</em>&nbsp;of ratees still contain relevant information that we can use to better estimate ratee desirability.</p>\n<p>The ratings that are most useful are those that correlate best with decisions. To this end, we examine correlations between average ratings and individual decisions. We also look at correlations between average ratings of each type and individual ratings of each type, to get a sense for the degree to which the ratings are independent, and the degree to which there tends to be a consensus as to whether somebody possesses a given trait. In the figures below, we&rsquo;re abbreviate the ratings of different types owing to space considerations. The abbreviations are given by the following dictionary:</p>\n<p style=\"padding-left: 30px;\"><strong>dec</strong>&nbsp;---&gt; the rater&rsquo;s decision</p>\n<p style=\"padding-left: 30px;\"><strong>like</strong>&nbsp;---&gt; how much a rater liked a ratee overall</p>\n<p style=\"padding-left: 30px;\"><strong>attr</strong>&nbsp;---&gt; the ratee&rsquo;s attractiveness</p>\n<p style=\"padding-left: 30px;\"><strong>fun</strong>&nbsp;---&gt; how fun the ratee is</p>\n<p style=\"padding-left: 30px;\"><strong>amb</strong>&nbsp;---&gt; the ratee&rsquo;s ambition</p>\n<p style=\"padding-left: 30px;\"><strong>intel</strong>&nbsp;---&gt; the ratee&rsquo;s intelligence</p>\n<p style=\"padding-left: 30px;\"><strong>sinc</strong>&nbsp;---&gt; the ratee&rsquo;s sincerity</p>\n<p>The image below matrix shows the correlations when the ratee is a woman and the raters are men. The rows of the figure correspond to the ratee&rsquo;s average ratings, and the columns correspond to individual rater&rsquo;s ratings:</p>\n<p><span id=\"docs-internal-guid-6b5f78f0-55e9-394f-0789-166daabc6775\"><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><img style=\"border-style: none; transform: rotate(0rad); -webkit-transform: rotate(0rad); vertical-align: middle; margin-left: 100px; margin-right: 100px;\" src=\"https://lh3.googleusercontent.com/XLq25gGzhpfSaFu1ka-jlxZmBgCWfVH8_ir6JIonX4LcxMoD3wYs2R4RK8I0zD7HiOviBhbMdGId9-qm9SvMRFh2obQmlcgzh_sCURXWKbDlC36h48LhfNQ1s7rkoPUu7g\" alt=\"\" width=\"582px;\" height=\"390px;\" /></span></span></p>\n<p>As the scale on the right indicates, darker shades of red correspond to stronger correlations. Three things to highlight are:</p>\n<ol>\n<li>The correlations are positive: higher ratings on one direction are always associated with higher ratings on all dimensions. Even the squares that might initially appear to be white are in fact very faintly red. So ratings of a given type contain information about ratings of other types. </li>\n<li>Consider the 5x5 square in the lower right, which corresponds to interrelations between attractiveness, fun, ambition, intelligence and sincerity. For each column, the square with the darkest shade of red is the square on the diagonal. This corresponds to the fact that given a rating type R, the average rating that&rsquo;s most predictive of R is the average of R itself. </li>\n<li>Consider the leftmost column, which corresponds to individual men&rsquo;s decisions. The darkest shades of red correspond to the average of other men&rsquo;s&nbsp;<span id=\"docs-internal-guid-6b5f78f0-55ea-76d4-fa47-ba6e426b765b\"><span style=\"font-size: 15px; font-family: Arial; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">decisions</span></span>&nbsp;on a woman, the average of their ratings of how much they <strong>like</strong> her overall, and their ratings of her <strong>attractiveness</strong>. Moreover, these three squares are essentially the same shade of red as one another, corresponding to the three averages having equal predictive power.&nbsp;</li>\n<li>Consider the intersection between the top 3 rows and the rightmost 4 columns. The darkest shades of red appear in the \"liking\" row and the lightest shades of red appear in the \"attractiveness\" row. This corresponds to how much a man likes a woman general reflecting a broader range of his or her characteristics than just physical attractiveness, and this being true of his receptiveness to dating her as well, but to a lesser degree.&nbsp;</li>\n</ol>\n<p>Each of these observations deserves comment:</p>\n<ol>\n<li>It seems implausible to me that each of the 10 distinct correlations between the five traits of attractiveness, fun, ambition, intelligence and sincerity is positive. The first thing that jumped to mind when I saw the correlation matrix was the <a href=\"/lw/lj/the_halo_effect/\"><strong>Halo Effect</strong></a>: people&rsquo;s positive perceptions of people on one dimension tend to spill over and affect their perceptions of the person on all dimensions. Here the <a href=\"http://en.wikipedia.org/wiki/Halo_effect#Role_of_attractiveness\">role of attractiveness</a> specifically has been highlighted. Later on we&rsquo;ll see evidence that the halo effect is in fact a contributing factor. <br /><br />&nbsp;But one also can&rsquo;t dismiss the possibility that the correlations between the ratings are <strong>partially driven by correlations between the underlying traits</strong>. As a concrete hypothetical, quality of early childhood nutrition could potentially impact all five dimensions. <br /><br />&nbsp;The slightest correlations between ratings are also sufficiently small so that one can imagine them reflecting genuine correlations between the underlying traits without them being large enough for us to notice in our day to day experience. <br /><br />One can also imagine the ratings <em>understating</em> correlations between the different traits owing to <a href=\"/lw/j7/anchoring_and_adjustment/\">anchoring biases</a>: if two people are the same on one dimension D, and one of them is very high on another dimension D&rsquo;, the one with very high D&rsquo; could be rated lower on D because the degree to which he or she possesses D <em>looks small</em> <em>relative to the degree to which he or she possesses D&rsquo;.<br /><br /></em> </li>\n<li>In view of the Halo Effect, one could imagine that ratings of a given type are essentially noise, picking up only on the degree to which someone possesses other traits. One could also imagine a rating type being ill-defined on account of there being no consensus on what the word means.<br /><br />The fact that the average consensus on how much someone possesses each trait is the most predictive of individual ratings of that trait strongly suggests that <strong>the 5 different rating types are in fact picking up on 5 distinct traits</strong>. They might not be the traits that come to mind when we think of the words: for example, it could be that the distinct underlying trait that intelligence ratings are picking up on is &ldquo;wears glasses.&rdquo; But if men give a woman high ratings on intelligence and not sincerity (for example), it means <em>something</em>. <br /></li>\n<li>&nbsp;At least two of the &ldquo;decision,&rdquo; &ldquo;liking,&rdquo; and &ldquo;attractiveness&rdquo; averages reflect different things, as one can see from the differences in how they correlate with other traits. But they correlate well with one another, and when it comes to using them to predict decisions, one gets a close approximation to the truth if one adopts the view that they&rsquo;re essentially measures of the same thing. <br /></li>\n<li>The \"liking\" average captures some of the predictive power of the fun, ambition, intelligence and sincerity ratings, but it reflects sincerity&nbsp;<em>too</em>&nbsp;much from the point of view of predicting decisions.</li>\n</ol>\n<p>With (3) in mind, we obtain our first conclusion, one totally uncontroversial in some circles, though not all:</p>\n<p style=\"padding-left: 30px;\"><em>On average, of the five dimensions on which men rated women, <strong>the one that most drove men&rsquo;s decisions on a woman is her attractiveness</strong>. The gap between the predictive power of attractiveness and the predictive power of the other traits is large. &ldquo;Fun,&rdquo; is the closest to attractiveness in predictive power, but the predictive power may derive in part from attractive women being perceived as more fun.</em></p>\n<h2>Gender Differences</h2>\n<p>So far I&rsquo;ve only discussed men&rsquo;s preferences. The analysis above applies to women&rsquo;s preferences nearly word for word: <strong>to a first approximation, the table for women and the table for men are identical to one another</strong>.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-6b5f78f0-55f0-f492-a5b2-fd07b2fed9e0\"><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><img style=\"border-style: none; transform: rotate(0rad); -webkit-transform: rotate(0rad); margin-left: 100px; margin-right: 100px; vertical-align: middle;\" src=\"https://lh4.googleusercontent.com/y0qYVzaKsUCshqP-46k8_3SErdQett7coGVuRDaTSrpKcG5a8cmhnGrhRa2gCJJuLmovQYHiHyqBT_HSWkfCuEqhaTHJ_b42zlXjjSZwb5QxaERltWONGjTuumZQUv_QTQ\" alt=\"\" width=\"582px;\" height=\"390px;\" /></span></span><br /><br /><br />How surprising this is to the reader will depend on his or her assumptions about the world. As a thought experiment, you might ask yourself: suppose that you had generated the two images without giving them headings, and had only examined one of them. If you later came across the other on your computer without remembering which it was, how confident would you be that it was the one that you had already seen?</p>\n<p>The correlation matrixes give the impression of contradicting a claim in the original study:</p>\n<p style=\"padding-left: 30px;\"><em>Women put greater weight on the intelligence [...] while men respond more to physical attractiveness. </em></p>\n<p>The apparent contradiction is explained by the fact that the subsets of events that I used were different from the subset of events that the authors reported on in their paper. On one hand, I omitted the events with fewer than 14 people. On the other hand, the authors omitted others:</p>\n<p style=\"padding-left: 30px;\"><em>Seven have been omitted...four because they involved an experimental intervention where participants were asked to bring their favorite book. These four sessions were run specifically to study how decision weights and selectivity would be affected by an intervention designed to shift subjects&rsquo; attention away from superficial physical attributes. </em></p>\n<p>The intervention of asking participants to bring their favorite book seems to have had the intended effect. One could argue that the sample that I used is unrepresentative on account of the intervention. But to my mind, the intervention falls within the range of heterogeneity that one might expect across real world events, and it&rsquo;s unclear to me that the events <em>without</em> the intervention give a better sense for gender differences in mate selection <em>across contexts</em> than the events <em>with</em> the intervention do.</p>\n<p><em>A priori</em> one might still be concerned that my choice of sample would lead to me developing a model that gives too much weight to intelligence when the rater is a man. But I chose the features that I did specifically with the intent of creating a model that would work well across heterogeneous speed dating events, and made no use of intelligence ratings to predict men's decisions.</p>\n<p>There are some gender differences in the correlations even in the sample that I use &ndash; in particular, the correlations tend to be stronger when the rater is male. This could be because of actual differences in preferences, or because of differences with respect to susceptibility to the halo effect, or a number of other things.</p>\n<p>Whatever the case may be, <strong>the first three points that I made about the correlation matrix for male raters are also true of the correlation matrix for female raters. </strong></p>\n<p><strong></strong>The fourth point needs to be supplemented<strong> </strong>by the observation that from the point of view of predicting decisions,&nbsp;when the raters are women,&nbsp;not only do the \"liking\" ratings reflect the sincerity ratings too much, they also reflect the ambition and intelligence ratings too much<strong>.</strong></p>\n<h2><span style=\"font-size: 16px;\">A composite index to closely approximate a ratee&rsquo;s desirability</span></h2>\n<p>When the rater is a man, the liking average captures the predictive power present in the fun, ambition, and intelligence averages, and we lose nothing by dropping them. We would like to use all three of the most predictive averages, <strong>decision, liking and attractiveness </strong>to predict men's decisions. But the three&nbsp;vary in predictive power from event to event, and if we use all three we end up overfitting and get suboptimal results. Inspired by the fact that their predictive power is roughly equal, when the raters are men, we simply average the three to form a <strong>composite index</strong> of a woman&rsquo;s desirability. Using it in a model gives better results than using any combination of the three individually.</p>\n<p>When the raters are women, the liking average does a poor job of picking up on the predictive power of the attractiveness, fun, ambition, intelligence and sincerity to the right degrees. So in this case, we form the same composite index as the composite index for men, but without omitting the liking average</p>\n<h2>Fun and intelligence as positive predictors when the rater is a woman</h2>\n<p>When the rater is a woman, the fun average gives substantial incremental power (moreso than when the rater is a man, even when we don't include the 'liking' average in the composite index when predicting his decision), and we include it. The ambition average offers no additional predictive power. We get a little bit more predictive power by including the intelligence average. It's nearly negligible until we make the modification described below.</p>\n<h2>Ratees&rsquo; sincerity as an incremental negative predictor</h2>\n<p>While the ratees&rsquo; average sincerity ratings are correlated with the raters&rsquo; decisions being yes, the effect vanishes after we control for the decision and attractiveness averages, suggesting that the sincerity/decision correlation is driven by the halo effect rather than by people&rsquo;s decisions being influenced by genuine sincerity.</p>\n<p>As mentioned above, liking average is more strongly correlated with the sincerity average than the decision average is, and so when the rater is man, our composite index of a woman&rsquo;s desirability is weakened by the fact that it indirectly picks up on sincerity.</p>\n<p>Similarly, the predictive power of the intelligence average that we included to predict women's decisions is degraded by the fact that it indirectly picks up on sincerity ratings.</p>\n<p>We can correct for this problem by including the sincerity averages in our model to control for them: this allows for our model to give more weight to the factors that actually drive decision than it would otherwise be able to.</p>\n<h2>Desirability as a signal of selectivity</h2>\n<p>More desirable people are more selective. This is nearly a tautology in general, and doesn&rsquo;t necessarily reflect snobbishness: barring <a href=\"/lw/79x/polyhacking/\">polyamory</a>, somebody with many suitors <em>has</em> to reject a larger percentage of them than somebody with few. The pattern is present in the dataset, even though raters were generally allowed to decide yes on as many people as they wanted to.</p>\n<p>I found that a <em>ratee'</em>s selectivity didn&rsquo;t consistently yield incremental predictive power of the <em>ratee's</em> desirability, but so far we only used one metric of the rater&rsquo;s selectivity, and we can improve on it by adding a measure of the <em>rater&rsquo;s</em> desirability. For this I simply used the man&rsquo;s composite desirability index when the rater is a man. When the rater is a woman, the composite index includes the average of &ldquo;liking&rdquo; ratings given to women, which in turn reflects traits such as ambition, intelligence and sincerity which may affect selectivity for reasons unrelated to the woman&rsquo;s desirability. So we use the version of the composite index that excludes the &ldquo;liking&rdquo; rating averages.</p>\n<p>The effect is largely restricted to raters of below average desirability: the rise in selectivity generally flattens out once one passes to consideration of people who are of above average desirability. It&rsquo;s unclear to me why this should be so. My best guess is that there&rsquo;s an extroversion/desirability connection that emerges at the upper end of the spectrum of desirability, which dampened the connection between desirability and selectivity in this study.</p>\n<h2>The predictive power that we obtain</h2>\n<p>Recall that men&rsquo;s decision were yes for 48% of the dates in the sample, and women&rsquo;s decisions were yes for 33% of the dates in the sample. Matches occurred 15.5% of the time. These establish baselines that we can judge our model against: if we predicted that everyone rejected everyone, the error rates would simply be the percentages listed. Using the features that I allude to above, I obtained predictions with the error rates indicated in the table below:</p>\n<p>&nbsp;</p>\n<div style=\"margin-left: 0pt; padding-left: 90px;\" dir=\"ltr\">\n<table style=\"border: none; border-collapse: collapse; width: 624px;\" border=\"0\">\n<colgroup><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col></colgroup> \n<tbody>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\"><br /></td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Total Error</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">False Positives</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">False Negs</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% Yes Found</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Women by Men</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">25.1%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">25.3%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">24.8%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">72.8%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Men by Women</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">23.9%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">31.6%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">20.9% </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">54.2%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Matches</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">14.3% </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">37.3% </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">13.3%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">17.2%</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>&nbsp;</p>\n<p>In my next post I&rsquo;ll expand the model to include <strong>interactions between individual men&rsquo;s traits and individual women&rsquo;s traits</strong>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 1, "W9aNkPwtPhMrcfgj7": 1, "bh7uxTTqmsQ8jZJdB": 1, "fpEBgFE7fgpxTm9BF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uBNj85TAB2cikby2W", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 37, "extendedScore": null, "score": 2.2755551750880974e-06, "legacy": true, "legacyId": "27737", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Overview\">Overview</h2>\n<p>For many people, having a satisfying romantic relationship is one of the most important aspects of life. Over the past 10 years, online dating websites have gained traction, and dating websites have access to large amounts of data that could be used to build predictive models to achieve this goal. Such data is seldom public, but Columbia business school professors Ray Fisman and Sheena Iyengar compiled a rich and relevant data set for their paper <a href=\"http://faculty.chicagobooth.edu/emir.kamenica/documents/genderDifferences.pdf\">Gender Differences in Mate Selection: Evidence From a Speed Dating Experiment</a>. Their main results were:</p>\n<p style=\"padding-left: 30px;\"><em>Women put greater weight on the intelligence and the race of partner, while men respond more to physical attractiveness. Moreover, men do not value women\u2019s intelligence or ambition when it exceeds their own. Also, we find that women exhibit a preference for men who grew up in affluent neighborhoods. Finally, male selectivity is invariant to group size, while female selectivity is strongly increasing in group size.</em></p>\n<p>I found the study <a href=\"http://andrewgelman.com/2008/01/21/the_speeddating_1/\">through Andrew Gelman\u2019s blog</a>, where he wrote:</p>\n<p style=\"padding-left: 30px;\"><em>What I really want to do with these data is what I suggested to Ray and Sheena several years ago when they first told me about the study: a multilevel model that allows preferences to vary by person, not just by sex. Multilevel modeling would definitely be useful here, since you have something like 10 binary observations and 6 parameters to estimate for each person.</em></p>\n<p>Several months ago I decided to pursue a career in data science, and with a view toward building my skills, I worked to build a <strong>model to predict when an individual participant will express interest in seeing a given partner again</strong>. Along with the goal of learning, I had the dual intent of contributing knowledge that had the potential, however slight, to help people find satisfying romantic relationships.</p>\n<p>It\u2019s unlikely that what I did will have practical applications (as basic research seldom does), but I did learn a great deal about many things, most having to do with data science methodology in general, but also some about human behavior.</p>\n<p>This is the first of a series of posts where I report on my findings. A linear narrative would degenerate to a sprawling blog post that would be of little interest to anybody but me. In this post, I\u2019ll restrict focus to the question: <strong>how much predictive power can we get by estimating the generic selectivity and desirability of the people involved, without using information about the interactions between their traits? </strong></p>\n<p>I\u2019ll ultimately go into the details of the methodology that I used, including discussion of statistical significance, the rationale for making the decisions that I did the, and links to relevant code, but here I\u2019ll suppress technical detail in favor of relegating it to separate blog posts that might be of interest to a more specialized audience. In several places I speculate as to the meaning of the results. I\u2019ve made efforts to subject my reasoning to cross checks, but haven\u2019t gotten almost any external feedback yet, and I\u2019d welcome counter considerations, alternative hypotheses, etc. I\u2019m aware that there are places where claims that I make don\u2019t logically follow from what precedes them, and I\u2019m not so much looking for examples of this in general as much as I am instances where there\u2019s a sizable probability that I\u2019ve missed something that alters the bottom line conclusions.</p>\n<p><a id=\"more\"></a></p>\n<h2 id=\"Context_on_the_dataset\">Context on the dataset</h2>\n<p>The <a href=\"http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/\">dataset</a> was derived from 21 round-robin speed dating events held for Columbia graduate students, each attended by between 6 to 22 participants of each gender. To avoid small sample size issues, I restricted consideration to the 9 events with 14 or more people. These consisted of ~2500 speed dates, involving a total of ~160 participants of each gender. The subset that I looked at contains events that the authors of the original study excluded in their own paper because they involved the experimental intervention of asking subjects to bring a book to the event. The effect size of the intervention was small enough so that it doesn\u2019t alter bottom line conclusions.</p>\n<p>The dataset has a large number of features. I found that their predictive power was almost all contained in participants\u2019 ratings of one another, which extended beyond a \u201cyes/no\u201d decision, also including ratings on dimensions such as attractiveness, sincerity, intelligence, fun and ambition. For brevity I\u2019ll refer to the person who made decision as the \u201crater\u201d and his or her partner as the \u201cratee.\u201d The core features that I used were essentially:</p>\n<ul>\n<li>The frequency with which the rater\u2019s decision on other ratees was \u2018yes.\u2019</li>\n<li>The frequency with which other raters' decision on the ratee was \u2018yes.\u2019</li>\n<li>Averages of ratings that others gave the rater and ratee.</li>\n</ul>\n<p>The actual features that I used were slightly modified versions of these. I\u2019ll give details in a future post.</p>\n<h2 id=\"Why_ratings_add_incremental_predictive_power\">Why ratings add incremental predictive power</h2>\n<p>In this blog post I\u2019m restricting consideration to signals of the partners\u2019 general selectivity and general desirability, without considering how their traits interact. First approximations to a participant\u2019s desirability and selectivity come from the frequency with which members of the opposite sex expressed to see them again, and the frequency with which the participant expressed interest in seeing members of the opposite sex again.</p>\n<p>If the dataset contained information on a sufficiently large number of dates for each participant, <em>we could not improve on using these</em>. But the number of dates that each participant went on was small enough so that the decision frequencies are noisy, and we can do better by supplementing them with other features. There\u2019s a gender asymmetry to the situation: on average, men said yes 48.5% of the time and woman said yes 33.5% of the time, which means that the decision frequency metrics are noisier than is otherwise the case when the rater is a woman and the ratee is a man, so there\u2019s more room for improvement when predicting women\u2019s decisions than there is when predicting men\u2019s decisions.</p>\n<p>It\u2019s in principle possible for the average of a <em>single type of rating</em> to carry <em>more</em> information than decision frequencies. This is because the ratings were given on a scale from 1 to 10, whereas decisions have only two possible values (yes and no). This means that ratings can (in principle) reflect desirability or lack thereof at a greater level of granularity than decisions. As an example of this, if a rater has impossibly high standards and rejects everyone, the rater's <em>decisions</em> carry no information about the ratees, but the rater's <em>ratings</em>&nbsp;of ratees still contain relevant information that we can use to better estimate ratee desirability.</p>\n<p>The ratings that are most useful are those that correlate best with decisions. To this end, we examine correlations between average ratings and individual decisions. We also look at correlations between average ratings of each type and individual ratings of each type, to get a sense for the degree to which the ratings are independent, and the degree to which there tends to be a consensus as to whether somebody possesses a given trait. In the figures below, we\u2019re abbreviate the ratings of different types owing to space considerations. The abbreviations are given by the following dictionary:</p>\n<p style=\"padding-left: 30px;\"><strong>dec</strong>&nbsp;---&gt; the rater\u2019s decision</p>\n<p style=\"padding-left: 30px;\"><strong>like</strong>&nbsp;---&gt; how much a rater liked a ratee overall</p>\n<p style=\"padding-left: 30px;\"><strong>attr</strong>&nbsp;---&gt; the ratee\u2019s attractiveness</p>\n<p style=\"padding-left: 30px;\"><strong>fun</strong>&nbsp;---&gt; how fun the ratee is</p>\n<p style=\"padding-left: 30px;\"><strong>amb</strong>&nbsp;---&gt; the ratee\u2019s ambition</p>\n<p style=\"padding-left: 30px;\"><strong>intel</strong>&nbsp;---&gt; the ratee\u2019s intelligence</p>\n<p style=\"padding-left: 30px;\"><strong>sinc</strong>&nbsp;---&gt; the ratee\u2019s sincerity</p>\n<p>The image below matrix shows the correlations when the ratee is a woman and the raters are men. The rows of the figure correspond to the ratee\u2019s average ratings, and the columns correspond to individual rater\u2019s ratings:</p>\n<p><span id=\"docs-internal-guid-6b5f78f0-55e9-394f-0789-166daabc6775\"><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><img style=\"border-style: none; transform: rotate(0rad); -webkit-transform: rotate(0rad); vertical-align: middle; margin-left: 100px; margin-right: 100px;\" src=\"https://lh3.googleusercontent.com/XLq25gGzhpfSaFu1ka-jlxZmBgCWfVH8_ir6JIonX4LcxMoD3wYs2R4RK8I0zD7HiOviBhbMdGId9-qm9SvMRFh2obQmlcgzh_sCURXWKbDlC36h48LhfNQ1s7rkoPUu7g\" alt=\"\" width=\"582px;\" height=\"390px;\"></span></span></p>\n<p>As the scale on the right indicates, darker shades of red correspond to stronger correlations. Three things to highlight are:</p>\n<ol>\n<li>The correlations are positive: higher ratings on one direction are always associated with higher ratings on all dimensions. Even the squares that might initially appear to be white are in fact very faintly red. So ratings of a given type contain information about ratings of other types. </li>\n<li>Consider the 5x5 square in the lower right, which corresponds to interrelations between attractiveness, fun, ambition, intelligence and sincerity. For each column, the square with the darkest shade of red is the square on the diagonal. This corresponds to the fact that given a rating type R, the average rating that\u2019s most predictive of R is the average of R itself. </li>\n<li>Consider the leftmost column, which corresponds to individual men\u2019s decisions. The darkest shades of red correspond to the average of other men\u2019s&nbsp;<span id=\"docs-internal-guid-6b5f78f0-55ea-76d4-fa47-ba6e426b765b\"><span style=\"font-size: 15px; font-family: Arial; font-weight: bold; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">decisions</span></span>&nbsp;on a woman, the average of their ratings of how much they <strong>like</strong> her overall, and their ratings of her <strong>attractiveness</strong>. Moreover, these three squares are essentially the same shade of red as one another, corresponding to the three averages having equal predictive power.&nbsp;</li>\n<li>Consider the intersection between the top 3 rows and the rightmost 4 columns. The darkest shades of red appear in the \"liking\" row and the lightest shades of red appear in the \"attractiveness\" row. This corresponds to how much a man likes a woman general reflecting a broader range of his or her characteristics than just physical attractiveness, and this being true of his receptiveness to dating her as well, but to a lesser degree.&nbsp;</li>\n</ol>\n<p>Each of these observations deserves comment:</p>\n<ol>\n<li>It seems implausible to me that each of the 10 distinct correlations between the five traits of attractiveness, fun, ambition, intelligence and sincerity is positive. The first thing that jumped to mind when I saw the correlation matrix was the <a href=\"/lw/lj/the_halo_effect/\"><strong>Halo Effect</strong></a>: people\u2019s positive perceptions of people on one dimension tend to spill over and affect their perceptions of the person on all dimensions. Here the <a href=\"http://en.wikipedia.org/wiki/Halo_effect#Role_of_attractiveness\">role of attractiveness</a> specifically has been highlighted. Later on we\u2019ll see evidence that the halo effect is in fact a contributing factor. <br><br>&nbsp;But one also can\u2019t dismiss the possibility that the correlations between the ratings are <strong>partially driven by correlations between the underlying traits</strong>. As a concrete hypothetical, quality of early childhood nutrition could potentially impact all five dimensions. <br><br>&nbsp;The slightest correlations between ratings are also sufficiently small so that one can imagine them reflecting genuine correlations between the underlying traits without them being large enough for us to notice in our day to day experience. <br><br>One can also imagine the ratings <em>understating</em> correlations between the different traits owing to <a href=\"/lw/j7/anchoring_and_adjustment/\">anchoring biases</a>: if two people are the same on one dimension D, and one of them is very high on another dimension D\u2019, the one with very high D\u2019 could be rated lower on D because the degree to which he or she possesses D <em>looks small</em> <em>relative to the degree to which he or she possesses D\u2019.<br><br></em> </li>\n<li>In view of the Halo Effect, one could imagine that ratings of a given type are essentially noise, picking up only on the degree to which someone possesses other traits. One could also imagine a rating type being ill-defined on account of there being no consensus on what the word means.<br><br>The fact that the average consensus on how much someone possesses each trait is the most predictive of individual ratings of that trait strongly suggests that <strong>the 5 different rating types are in fact picking up on 5 distinct traits</strong>. They might not be the traits that come to mind when we think of the words: for example, it could be that the distinct underlying trait that intelligence ratings are picking up on is \u201cwears glasses.\u201d But if men give a woman high ratings on intelligence and not sincerity (for example), it means <em>something</em>. <br></li>\n<li>&nbsp;At least two of the \u201cdecision,\u201d \u201cliking,\u201d and \u201cattractiveness\u201d averages reflect different things, as one can see from the differences in how they correlate with other traits. But they correlate well with one another, and when it comes to using them to predict decisions, one gets a close approximation to the truth if one adopts the view that they\u2019re essentially measures of the same thing. <br></li>\n<li>The \"liking\" average captures some of the predictive power of the fun, ambition, intelligence and sincerity ratings, but it reflects sincerity&nbsp;<em>too</em>&nbsp;much from the point of view of predicting decisions.</li>\n</ol>\n<p>With (3) in mind, we obtain our first conclusion, one totally uncontroversial in some circles, though not all:</p>\n<p style=\"padding-left: 30px;\"><em>On average, of the five dimensions on which men rated women, <strong>the one that most drove men\u2019s decisions on a woman is her attractiveness</strong>. The gap between the predictive power of attractiveness and the predictive power of the other traits is large. \u201cFun,\u201d is the closest to attractiveness in predictive power, but the predictive power may derive in part from attractive women being perceived as more fun.</em></p>\n<h2 id=\"Gender_Differences\">Gender Differences</h2>\n<p>So far I\u2019ve only discussed men\u2019s preferences. The analysis above applies to women\u2019s preferences nearly word for word: <strong>to a first approximation, the table for women and the table for men are identical to one another</strong>.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><span id=\"docs-internal-guid-6b5f78f0-55f0-f492-a5b2-fd07b2fed9e0\"><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><img style=\"border-style: none; transform: rotate(0rad); -webkit-transform: rotate(0rad); margin-left: 100px; margin-right: 100px; vertical-align: middle;\" src=\"https://lh4.googleusercontent.com/y0qYVzaKsUCshqP-46k8_3SErdQett7coGVuRDaTSrpKcG5a8cmhnGrhRa2gCJJuLmovQYHiHyqBT_HSWkfCuEqhaTHJ_b42zlXjjSZwb5QxaERltWONGjTuumZQUv_QTQ\" alt=\"\" width=\"582px;\" height=\"390px;\"></span></span><br><br><br>How surprising this is to the reader will depend on his or her assumptions about the world. As a thought experiment, you might ask yourself: suppose that you had generated the two images without giving them headings, and had only examined one of them. If you later came across the other on your computer without remembering which it was, how confident would you be that it was the one that you had already seen?</p>\n<p>The correlation matrixes give the impression of contradicting a claim in the original study:</p>\n<p style=\"padding-left: 30px;\"><em>Women put greater weight on the intelligence [...] while men respond more to physical attractiveness. </em></p>\n<p>The apparent contradiction is explained by the fact that the subsets of events that I used were different from the subset of events that the authors reported on in their paper. On one hand, I omitted the events with fewer than 14 people. On the other hand, the authors omitted others:</p>\n<p style=\"padding-left: 30px;\"><em>Seven have been omitted...four because they involved an experimental intervention where participants were asked to bring their favorite book. These four sessions were run specifically to study how decision weights and selectivity would be affected by an intervention designed to shift subjects\u2019 attention away from superficial physical attributes. </em></p>\n<p>The intervention of asking participants to bring their favorite book seems to have had the intended effect. One could argue that the sample that I used is unrepresentative on account of the intervention. But to my mind, the intervention falls within the range of heterogeneity that one might expect across real world events, and it\u2019s unclear to me that the events <em>without</em> the intervention give a better sense for gender differences in mate selection <em>across contexts</em> than the events <em>with</em> the intervention do.</p>\n<p><em>A priori</em> one might still be concerned that my choice of sample would lead to me developing a model that gives too much weight to intelligence when the rater is a man. But I chose the features that I did specifically with the intent of creating a model that would work well across heterogeneous speed dating events, and made no use of intelligence ratings to predict men's decisions.</p>\n<p>There are some gender differences in the correlations even in the sample that I use \u2013 in particular, the correlations tend to be stronger when the rater is male. This could be because of actual differences in preferences, or because of differences with respect to susceptibility to the halo effect, or a number of other things.</p>\n<p>Whatever the case may be, <strong>the first three points that I made about the correlation matrix for male raters are also true of the correlation matrix for female raters. </strong></p>\n<p><strong></strong>The fourth point needs to be supplemented<strong> </strong>by the observation that from the point of view of predicting decisions,&nbsp;when the raters are women,&nbsp;not only do the \"liking\" ratings reflect the sincerity ratings too much, they also reflect the ambition and intelligence ratings too much<strong>.</strong></p>\n<h2 id=\"A_composite_index_to_closely_approximate_a_ratee_s_desirability\"><span style=\"font-size: 16px;\">A composite index to closely approximate a ratee\u2019s desirability</span></h2>\n<p>When the rater is a man, the liking average captures the predictive power present in the fun, ambition, and intelligence averages, and we lose nothing by dropping them. We would like to use all three of the most predictive averages, <strong>decision, liking and attractiveness </strong>to predict men's decisions. But the three&nbsp;vary in predictive power from event to event, and if we use all three we end up overfitting and get suboptimal results. Inspired by the fact that their predictive power is roughly equal, when the raters are men, we simply average the three to form a <strong>composite index</strong> of a woman\u2019s desirability. Using it in a model gives better results than using any combination of the three individually.</p>\n<p>When the raters are women, the liking average does a poor job of picking up on the predictive power of the attractiveness, fun, ambition, intelligence and sincerity to the right degrees. So in this case, we form the same composite index as the composite index for men, but without omitting the liking average</p>\n<h2 id=\"Fun_and_intelligence_as_positive_predictors_when_the_rater_is_a_woman\">Fun and intelligence as positive predictors when the rater is a woman</h2>\n<p>When the rater is a woman, the fun average gives substantial incremental power (moreso than when the rater is a man, even when we don't include the 'liking' average in the composite index when predicting his decision), and we include it. The ambition average offers no additional predictive power. We get a little bit more predictive power by including the intelligence average. It's nearly negligible until we make the modification described below.</p>\n<h2 id=\"Ratees__sincerity_as_an_incremental_negative_predictor\">Ratees\u2019 sincerity as an incremental negative predictor</h2>\n<p>While the ratees\u2019 average sincerity ratings are correlated with the raters\u2019 decisions being yes, the effect vanishes after we control for the decision and attractiveness averages, suggesting that the sincerity/decision correlation is driven by the halo effect rather than by people\u2019s decisions being influenced by genuine sincerity.</p>\n<p>As mentioned above, liking average is more strongly correlated with the sincerity average than the decision average is, and so when the rater is man, our composite index of a woman\u2019s desirability is weakened by the fact that it indirectly picks up on sincerity.</p>\n<p>Similarly, the predictive power of the intelligence average that we included to predict women's decisions is degraded by the fact that it indirectly picks up on sincerity ratings.</p>\n<p>We can correct for this problem by including the sincerity averages in our model to control for them: this allows for our model to give more weight to the factors that actually drive decision than it would otherwise be able to.</p>\n<h2 id=\"Desirability_as_a_signal_of_selectivity\">Desirability as a signal of selectivity</h2>\n<p>More desirable people are more selective. This is nearly a tautology in general, and doesn\u2019t necessarily reflect snobbishness: barring <a href=\"/lw/79x/polyhacking/\">polyamory</a>, somebody with many suitors <em>has</em> to reject a larger percentage of them than somebody with few. The pattern is present in the dataset, even though raters were generally allowed to decide yes on as many people as they wanted to.</p>\n<p>I found that a <em>ratee'</em>s selectivity didn\u2019t consistently yield incremental predictive power of the <em>ratee's</em> desirability, but so far we only used one metric of the rater\u2019s selectivity, and we can improve on it by adding a measure of the <em>rater\u2019s</em> desirability. For this I simply used the man\u2019s composite desirability index when the rater is a man. When the rater is a woman, the composite index includes the average of \u201cliking\u201d ratings given to women, which in turn reflects traits such as ambition, intelligence and sincerity which may affect selectivity for reasons unrelated to the woman\u2019s desirability. So we use the version of the composite index that excludes the \u201cliking\u201d rating averages.</p>\n<p>The effect is largely restricted to raters of below average desirability: the rise in selectivity generally flattens out once one passes to consideration of people who are of above average desirability. It\u2019s unclear to me why this should be so. My best guess is that there\u2019s an extroversion/desirability connection that emerges at the upper end of the spectrum of desirability, which dampened the connection between desirability and selectivity in this study.</p>\n<h2 id=\"The_predictive_power_that_we_obtain\">The predictive power that we obtain</h2>\n<p>Recall that men\u2019s decision were yes for 48% of the dates in the sample, and women\u2019s decisions were yes for 33% of the dates in the sample. Matches occurred 15.5% of the time. These establish baselines that we can judge our model against: if we predicted that everyone rejected everyone, the error rates would simply be the percentages listed. Using the features that I allude to above, I obtained predictions with the error rates indicated in the table below:</p>\n<p>&nbsp;</p>\n<div style=\"margin-left: 0pt; padding-left: 90px;\" dir=\"ltr\">\n<table style=\"border: none; border-collapse: collapse; width: 624px;\" border=\"0\">\n<colgroup><col width=\"*\"><col width=\"*\"><col width=\"*\"><col width=\"*\"><col width=\"*\"></colgroup> \n<tbody>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\"><br></td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Total Error</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">False Positives</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">False Negs</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% Yes Found</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Women by Men</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">25.1%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">25.3%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">24.8%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">72.8%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Men by Women</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">23.9%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">31.6%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">20.9% </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">54.2%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Matches</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">14.3% </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">37.3% </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">13.3%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">17.2%</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>&nbsp;</p>\n<p>In my next post I\u2019ll expand the model to include <strong>interactions between individual men\u2019s traits and individual women\u2019s traits</strong>.</p>", "sections": [{"title": "Overview", "anchor": "Overview", "level": 1}, {"title": "Context on the dataset", "anchor": "Context_on_the_dataset", "level": 1}, {"title": "Why ratings add incremental predictive power", "anchor": "Why_ratings_add_incremental_predictive_power", "level": 1}, {"title": "Gender Differences", "anchor": "Gender_Differences", "level": 1}, {"title": "A composite index to closely approximate a ratee\u2019s desirability", "anchor": "A_composite_index_to_closely_approximate_a_ratee_s_desirability", "level": 1}, {"title": "Fun and intelligence as positive predictors when the rater is a woman", "anchor": "Fun_and_intelligence_as_positive_predictors_when_the_rater_is_a_woman", "level": 1}, {"title": "Ratees\u2019 sincerity as an incremental negative predictor", "anchor": "Ratees__sincerity_as_an_incremental_negative_predictor", "level": 1}, {"title": "Desirability as a signal of selectivity", "anchor": "Desirability_as_a_signal_of_selectivity", "level": 1}, {"title": "The predictive power that we obtain", "anchor": "The_predictive_power_that_we_obtain", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "18 comments"}], "headingsCount": 11}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ACGeaAk6KButv2xwQ", "bMkCEZoBNhgRBtzoj", "kLR5H4pbaBjzZxLv6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-17T06:35:15.744Z", "modifiedAt": null, "url": null, "title": "Understanding Agency", "slug": "understanding-agency", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:58.487Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gworley", "createdAt": "2009-03-26T17:18:20.404Z", "isAdmin": false, "displayName": "G Gordon Worley III"}, "userId": "gjoi5eBQob27Lww62", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uNbR8WuahQrELCHgW/understanding-agency", "pageUrlRelative": "/posts/uNbR8WuahQrELCHgW/understanding-agency", "linkUrl": "https://www.lesswrong.com/posts/uNbR8WuahQrELCHgW/understanding-agency", "postedAtFormatted": "Wednesday, December 17th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Understanding%20Agency&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUnderstanding%20Agency%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuNbR8WuahQrELCHgW%2Funderstanding-agency%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Understanding%20Agency%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuNbR8WuahQrELCHgW%2Funderstanding-agency", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuNbR8WuahQrELCHgW%2Funderstanding-agency", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1406, "htmlBody": "<p><em>Note: In this article I refer to \"constructive developmental theory\" as \"constructive development theory\", however the former is more common and should be used instead. I changed it in the version of this on my own blog, but because I think it would add some confusion to the comments if I changed it here, I'll leave it as is but just note it so you can use the more common terminology.</em></p>\n<p>I used to get frustrated with myself. I'd say existential risk was an important problem or that I wanted to live an awesome life, but then I took no action to mitigate existential risks or make my life more awesome. For a long time I had no good way to explain this, often blaming it on things like <a href=\"http://gworley3.github.io/2014/11/09/there-is-no-akrasia.html\">akrasia</a>, but in late 2011 I changed. I started acting to make the world have more of what I valued in it.<br /><br />I've spent a lot of the past year trying to understand what happened and how I might tell other people about it. I would probably still be searching for the right framing if not for a party a few months ago. There, Malcolm Ocean and Ethan Dickinson introduced me to Constructive Development Theory, also known as Subject-Object Theory, a cognitive development theory first described by Robert Kegan et al.. Since then I've been ruminating on the idea, and after reading <a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">Malcolm's introduction to constructive development</a>, I realize that constructive development is the concept I need to explain my 2011 mind-shift.<br /><br />In short, in late 2011 I started to spend more of my time thinking at constructive development level 4 than 3, and level 4 thinking is the minimum required to stand a real chance of making the world the way you want it.<br /><br />Since that sounds like utter nonsense without context, go read <a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">Malcolm's article on constructive development</a>. Right <a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">now</a>. Go <a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">do it</a>. I'll still be here when <a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">you're done</a>. Don't even bother trying to go any further <a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">until you have read it</a>.<br /><br />In fact, you should also read the links he links before you come back, and maybe do a little research on your own, because I'm not going to bother explaining constructive development theory here: I'm just going to use it.<br /><br />Before we continue, one more warning. If you're not already doing most of your thinking at least half-way along the 3 to 4 transition (which I will hereon refer to as reaching 4/3), you will probably also not fully understand what I've written below because that's unfortunately also about how far along you have to be before constructive development theory makes intuitive sense to most people. I know that sounds like an excuse so I can say whatever I want, but before reaching 4/3 people tend to find constructive development theory confusing and probably not useful, and this is admittedly a weakness. My intentions must therefore be naturally limited to convincing other folks who have reached 4/3 that constructive development theory is useful for understanding what makes them different and suggests how they can help others attain a similar level of cognitive development.<br /><br />Once you reach 4/3 it becomes possible to reliably apply abstract concepts to satisfy your values because you now have the ability to spend most of your time thinking about yourself from a sufficiently distant outside view that you can manipulate the concept of \"you\" in a way that allows you to figure out how to apply said concepts. Since that's a bit abstract, let's see what that looks like with an example.<br /><br />Consider two persons in almost any given profession, but for salience let's choose teachers. Alice and Bob both value their students' learning highly and know many techniques that will successfully help their students learn. When Alice prepares for a class, she thinks mostly about the kind of teacher she needs to be in order to help her students learn. When Bob prepares for a class, he thinks mostly about what he needs to do in order to help his students learn. Both have the same goal, yet Alice is thinking mostly at level 4 while Bob is thinking mostly at level 3. Alice is trying to solve the problem of how to be a better teacher, while Bob is trying to solve the problem of how to teach better. Both are important, and Alice must also solve the problem of how to teach better, but she now views that problem as incidental to becoming a better teacher.<br /><br />To complicate matters, Bob doesn't really understand that Alice is doing something different from him, nor does their colleague Carol, who spends most of her time thinking at level 2 and trying to solve the problem of how to better perform various teaching techniques. But Carol will believe she is doing the same thing as Alice and Bob, and Bob will believe he's doing the same thing as Alice (viz. thinking about how to be a better teacher) and if you try to explain this to Bob or Carol they will likely fail to appreciate that there is any real difference.<br /><br />But the difference is important: at constructive development level 4, you can be the object of your own thoughts, not just the subject. At level 3 you can be the subject but not the object of your thinking, which can be incredibly frustrating, and at level 2 you can't even fully model yourself. So level 4 thinking is the minimum required to fully reason about yourself, which is why reaching 4/3 is an important inflection point in cognitive development.<br /><br />If reaching 4/3 is important and actually explains different levels of achievement in satisfying values, we should find existing discussions of reaching 4/3 but with different terminology. Eliezer seems to obliquely get at something related to reaching 4/3 in his <a href=\"http://yudkowsky.net/rational/virtues/\">twelfth and last virtue of rationality</a>. <a href=\"http://rationality.org/\">CFAR</a> talks about core skill growth, which seems to include many things related to constructive development level 4 thinking. But most concretely, we see it around <a href=\"http://hpmor.com/chapter/65\">chapter 65 of HPMOR</a> when other characters realize that Harry has gained agency, something talked about widely both within and outside the Less Wrong community.<br /><br />But core skill growth and agency are opaque. When a person has agency we mean something like \"they make their own decisions\". But of course everyone trivially makes their own decisions: their brains are not directly controlled by some outside force, no matter the pressures placed upon them. What we really mean is something more like \"they think, come to decisions about what to do, and then act on those decisions in ways that may be counter to the 'default' actions they would have otherwise taken\". But for someone who lacks agency this is not very helpful because it frames agency like a property one either has or doesn't, not as a thought process that can be developed. Thinking of agency as a consequence of reaching 4/3 solves this problem. Similarly, understanding core skill growth as increasing time spent thinking at higher constructive development levels makes its meaning clearer.<br /><br />Perhaps unsurprisingly, agency is the thing you need to make the world what you want. You can know many techniques for increasing productivity, forming friendships, earning trust, having fun, and otherwise better satisfying your values, but without agency you will be unable to reliably apply them. This makes reaching 4/3 the most important step in your cognitive development, and the faster you can get there the better off you will be.<br /><br />The challenge now is to find ways of helping people constructively develop. I think we have already made some good strides here with comfort zone expansion exercises and framing rationality as the skills that help you better optimize the world for what you value, but I also think we can do better because I know many folks who have been part of the Less Wrong community for a long time yet have thus far won very little. I anticipate better progress is possible now, though, thanks to having a useful model for understanding the most fundamental aspect of becoming stronger.<br /><br /><em>Thanks to Ethan Dickinson for offering suggestions on an early draft.<br /></em></p>\n<p><br /><em><a href=\"http://gworley3.github.io/2014/12/16/understanding-agency.html\">Cross posted from my blog.</a><br /></em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uNbR8WuahQrELCHgW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": -1, "extendedScore": null, "score": 2.276051496539144e-06, "legacy": true, "legacyId": "27739", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-17T08:04:38.208Z", "modifiedAt": null, "url": null, "title": "Entropy and Temperature", "slug": "entropy-and-temperature", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.927Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "spxtr", "createdAt": "2013-12-06T09:45:59.868Z", "isAdmin": false, "displayName": "spxtr"}, "userId": "sq5j9XL8LRkirMap5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QqqMdm7FXMgZzadZJ/entropy-and-temperature", "pageUrlRelative": "/posts/QqqMdm7FXMgZzadZJ/entropy-and-temperature", "linkUrl": "https://www.lesswrong.com/posts/QqqMdm7FXMgZzadZJ/entropy-and-temperature", "postedAtFormatted": "Wednesday, December 17th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Entropy%20and%20Temperature&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEntropy%20and%20Temperature%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQqqMdm7FXMgZzadZJ%2Fentropy-and-temperature%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Entropy%20and%20Temperature%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQqqMdm7FXMgZzadZJ%2Fentropy-and-temperature", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQqqMdm7FXMgZzadZJ%2Fentropy-and-temperature", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 851, "htmlBody": "<p>Eliezer Yudkowsky <a href=\"/lw/o5/the_second_law_of_thermodynamics_and_engines_of/\">previously wrote</a>&nbsp;(6 years ago!) about the second law of thermodynamics. Many commenters were skeptical about the statement, \"if you know the positions and momenta of every particle in a glass of water, it is at absolute zero temperature,\" because they don't know what temperature is. This is a common confusion.</p>\n<p><strong>Entropy</strong></p>\n<p>To specify the precise state of a classical system, you need to know its location in phase space. For a bunch of helium atoms whizzing around in a box, phase space is the position and momentum of each helium atom. For&nbsp;<em>N</em> atoms in the box, that means 6<em>N</em> numbers to completely specify the system.</p>\n<p>Lets say you know the total energy of the gas, but nothing else. It will be the case that a fantastically huge number of points in phase space will be consistent with that energy.*&nbsp;In the absence of any more information it is correct to assign a uniform distribution to this region of phase space. The entropy of a uniform distribution is the logarithm of the number of points, so that's <a href=\"http://en.wikipedia.org/wiki/Boltzmann%27s_entropy_formula\">that</a>. If you also know the volume, then the number of points in phase space consistent with both the energy and volume is necessarily smaller, so the entropy is smaller.</p>\n<p>This might be confusing to chemists, since they memorized a <a href=\"http://hyperphysics.phy-astr.gsu.edu/hbase/therm/entropgas.html\">formula</a> for the entropy of an ideal gas, and it's ostensibly objective. Someone with perfect knowledge of the system will calculate the same number on the right side of that equation, but to them, that number isn't the entropy. It's the entropy of the gas if you know nothing more than energy, volume, and number of particles.</p>\n<p><strong>Temperature</strong></p>\n<p>The existence of temperature follows from the zeroth and second laws of thermodynamics: thermal equilibrium is transitive, and entropy is maximum in equilibrium. Temperature is then defined as the thermodynamic quantity that is the shared by systems in equilibrium.</p>\n<p>If two systems&nbsp;are in equilibrium then they cannot increase entropy by flowing energy from one to the other. That means that if we flow a tiny bit of energy from one to the other (<em>&delta;U</em><sub>1</sub> = -<em>&delta;U</em><sub>2</sub>), the entropy change in the first must be the opposite of the entropy change of the second (<em>&delta;S</em><sub>1</sub>&nbsp;= -<em>&delta;S</em><sub>2</sub>), so that the total entropy (<em>S</em><sub>1</sub> + <em>S</em><sub>2</sub>) doesn't change. For systems in equilibrium, this leads to (<em>&part;S</em><sub>1</sub>/<em>&part;U</em><sub>1</sub>) = (<em>&part;S</em><sub>2</sub>/<em>&part;U</em><sub>2</sub>). Define 1/<em>T</em> = (<em>&part;S</em>/<em>&part;U</em>), and we are done.</p>\n<p>Temperature is sometimes taught as, \"a measure of the average kinetic energy of the particles,\" because for an ideal gas&nbsp;<em>U</em>/<em>N&nbsp;</em>= (3/2)&nbsp;<em>k<sub>B</sub>T</em>. This is wrong as a definition, for the same reason that the ideal gas entropy isn't the definition of entropy.</p>\n<p>Probability is in the mind. Entropy is a function of probabilities, so entropy is in the mind. Temperature is a derivative of entropy, so temperature is in the mind.</p>\n<p><strong>Second Law Trickery</strong></p>\n<p>With perfect knowledge of a system, it is possible to extract all of its energy as work. EY states it clearly:</p>\n<blockquote>\n<p>So (again ignoring quantum effects for the moment), if you&nbsp;<em>know</em>&nbsp;the states of all the molecules in a glass of hot water, it is cold in a genuinely thermodynamic sense: you can take electricity out of it and leave behind an ice cube.</p>\n</blockquote>\n<p>Someone who doesn't know the state of the water will observe a violation of the second law. This is allowed. Let that sink in for a minute. Jaynes calls it&nbsp;<a href=\"http://bayes.wustl.edu/etj/articles/gibbs.paradox.pdf\">second law trickery</a>, and I can't explain it better than he does, so I won't try:</p>\n<blockquote>\n<p>A physical system always has more macroscopic degrees of freedom beyond what we control or observe, and by manipulating them a trickster can always make us see an apparent violation of the second law.</p>\n<p>Therefore the correct statement of the second law is not that an entropy decrease is impossible in principle, or even improbable; rather that it <em>cannot be achieved reproducibly by manipulating the macrovariables {X<sub>1</sub>, ...,&nbsp;X<sub>n</sub>} that we have chosen to define our macrostate.</em> Any attempt to write a stronger law than this will put one at the mercy of a trickster, who can produce a violation of it.</p>\n<p>But recognizing this should increase rather than decrease our con\ffidence in the future of the second law, because it means that if an experimenter ever sees an apparent violation, then instead of issuing a sensational announcement, it will be more prudent to search for that unobserved degree of freedom. That is, the connection of entropy with information works both ways; seeing an apparent decrease of entropy signi\ffies ignorance of what were the relevant macrovariables.</p>\n</blockquote>\n<p><strong>Homework</strong></p>\n<p>I've actually given you enough information on statistical mechanics to calculate an interesting system. Say you have <em>N</em> particles, each fixed in place to a lattice. Each particle can be in one of two states, with energies 0 and &epsilon;. Calculate and plot the entropy if you know the total energy:&nbsp;<em>S</em>(<em>E</em>), and then the energy as a function of temperature:&nbsp;<em>E</em>(<em>T</em>). This is essentially a combinatorics problem, and you may assume that <em>N</em> is large, so use Stirling's approximation. What you will discover should make sense using the correct definitions of entropy and temperature.</p>\n<hr />\n<p>*: How many combinations of 10<sup>23&nbsp;</sup>numbers between 0 and 10 add up to 5&times;10<sup>23</sup>?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"csMv9MvvjYJyeHqoo": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QqqMdm7FXMgZzadZJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 39, "extendedScore": null, "score": 0.000115, "legacy": true, "legacyId": "27711", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Eliezer Yudkowsky <a href=\"/lw/o5/the_second_law_of_thermodynamics_and_engines_of/\">previously wrote</a>&nbsp;(6 years ago!) about the second law of thermodynamics. Many commenters were skeptical about the statement, \"if you know the positions and momenta of every particle in a glass of water, it is at absolute zero temperature,\" because they don't know what temperature is. This is a common confusion.</p>\n<p><strong id=\"Entropy\">Entropy</strong></p>\n<p>To specify the precise state of a classical system, you need to know its location in phase space. For a bunch of helium atoms whizzing around in a box, phase space is the position and momentum of each helium atom. For&nbsp;<em>N</em> atoms in the box, that means 6<em>N</em> numbers to completely specify the system.</p>\n<p>Lets say you know the total energy of the gas, but nothing else. It will be the case that a fantastically huge number of points in phase space will be consistent with that energy.*&nbsp;In the absence of any more information it is correct to assign a uniform distribution to this region of phase space. The entropy of a uniform distribution is the logarithm of the number of points, so that's <a href=\"http://en.wikipedia.org/wiki/Boltzmann%27s_entropy_formula\">that</a>. If you also know the volume, then the number of points in phase space consistent with both the energy and volume is necessarily smaller, so the entropy is smaller.</p>\n<p>This might be confusing to chemists, since they memorized a <a href=\"http://hyperphysics.phy-astr.gsu.edu/hbase/therm/entropgas.html\">formula</a> for the entropy of an ideal gas, and it's ostensibly objective. Someone with perfect knowledge of the system will calculate the same number on the right side of that equation, but to them, that number isn't the entropy. It's the entropy of the gas if you know nothing more than energy, volume, and number of particles.</p>\n<p><strong id=\"Temperature\">Temperature</strong></p>\n<p>The existence of temperature follows from the zeroth and second laws of thermodynamics: thermal equilibrium is transitive, and entropy is maximum in equilibrium. Temperature is then defined as the thermodynamic quantity that is the shared by systems in equilibrium.</p>\n<p>If two systems&nbsp;are in equilibrium then they cannot increase entropy by flowing energy from one to the other. That means that if we flow a tiny bit of energy from one to the other (<em>\u03b4U</em><sub>1</sub> = -<em>\u03b4U</em><sub>2</sub>), the entropy change in the first must be the opposite of the entropy change of the second (<em>\u03b4S</em><sub>1</sub>&nbsp;= -<em>\u03b4S</em><sub>2</sub>), so that the total entropy (<em>S</em><sub>1</sub> + <em>S</em><sub>2</sub>) doesn't change. For systems in equilibrium, this leads to (<em>\u2202S</em><sub>1</sub>/<em>\u2202U</em><sub>1</sub>) = (<em>\u2202S</em><sub>2</sub>/<em>\u2202U</em><sub>2</sub>). Define 1/<em>T</em> = (<em>\u2202S</em>/<em>\u2202U</em>), and we are done.</p>\n<p>Temperature is sometimes taught as, \"a measure of the average kinetic energy of the particles,\" because for an ideal gas&nbsp;<em>U</em>/<em>N&nbsp;</em>= (3/2)&nbsp;<em>k<sub>B</sub>T</em>. This is wrong as a definition, for the same reason that the ideal gas entropy isn't the definition of entropy.</p>\n<p>Probability is in the mind. Entropy is a function of probabilities, so entropy is in the mind. Temperature is a derivative of entropy, so temperature is in the mind.</p>\n<p><strong id=\"Second_Law_Trickery\">Second Law Trickery</strong></p>\n<p>With perfect knowledge of a system, it is possible to extract all of its energy as work. EY states it clearly:</p>\n<blockquote>\n<p>So (again ignoring quantum effects for the moment), if you&nbsp;<em>know</em>&nbsp;the states of all the molecules in a glass of hot water, it is cold in a genuinely thermodynamic sense: you can take electricity out of it and leave behind an ice cube.</p>\n</blockquote>\n<p>Someone who doesn't know the state of the water will observe a violation of the second law. This is allowed. Let that sink in for a minute. Jaynes calls it&nbsp;<a href=\"http://bayes.wustl.edu/etj/articles/gibbs.paradox.pdf\">second law trickery</a>, and I can't explain it better than he does, so I won't try:</p>\n<blockquote>\n<p>A physical system always has more macroscopic degrees of freedom beyond what we control or observe, and by manipulating them a trickster can always make us see an apparent violation of the second law.</p>\n<p>Therefore the correct statement of the second law is not that an entropy decrease is impossible in principle, or even improbable; rather that it <em>cannot be achieved reproducibly by manipulating the macrovariables {X<sub>1</sub>, ...,&nbsp;X<sub>n</sub>} that we have chosen to define our macrostate.</em> Any attempt to write a stronger law than this will put one at the mercy of a trickster, who can produce a violation of it.</p>\n<p>But recognizing this should increase rather than decrease our con\ffidence in the future of the second law, because it means that if an experimenter ever sees an apparent violation, then instead of issuing a sensational announcement, it will be more prudent to search for that unobserved degree of freedom. That is, the connection of entropy with information works both ways; seeing an apparent decrease of entropy signi\ffies ignorance of what were the relevant macrovariables.</p>\n</blockquote>\n<p><strong id=\"Homework\">Homework</strong></p>\n<p>I've actually given you enough information on statistical mechanics to calculate an interesting system. Say you have <em>N</em> particles, each fixed in place to a lattice. Each particle can be in one of two states, with energies 0 and \u03b5. Calculate and plot the entropy if you know the total energy:&nbsp;<em>S</em>(<em>E</em>), and then the energy as a function of temperature:&nbsp;<em>E</em>(<em>T</em>). This is essentially a combinatorics problem, and you may assume that <em>N</em> is large, so use Stirling's approximation. What you will discover should make sense using the correct definitions of entropy and temperature.</p>\n<hr>\n<p>*: How many combinations of 10<sup>23&nbsp;</sup>numbers between 0 and 10 add up to 5\u00d710<sup>23</sup>?</p>", "sections": [{"title": "Entropy", "anchor": "Entropy", "level": 1}, {"title": "Temperature", "anchor": "Temperature", "level": 1}, {"title": "Second Law Trickery", "anchor": "Second_Law_Trickery", "level": 1}, {"title": "Homework", "anchor": "Homework", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "96 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 96, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QkX2bAkwG2EpGvNug"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-17T15:26:04.635Z", "modifiedAt": null, "url": null, "title": "Giving What We Can - New Year drive", "slug": "giving-what-we-can-new-year-drive", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.123Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Smaug123", "createdAt": "2014-11-03T16:30:27.174Z", "isAdmin": false, "displayName": "Smaug123"}, "userId": "ACBCQBdedm8SmEz8A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MHarArYfjuDyaJwFo/giving-what-we-can-new-year-drive", "pageUrlRelative": "/posts/MHarArYfjuDyaJwFo/giving-what-we-can-new-year-drive", "linkUrl": "https://www.lesswrong.com/posts/MHarArYfjuDyaJwFo/giving-what-we-can-new-year-drive", "postedAtFormatted": "Wednesday, December 17th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Giving%20What%20We%20Can%20-%20New%20Year%20drive&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGiving%20What%20We%20Can%20-%20New%20Year%20drive%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMHarArYfjuDyaJwFo%2Fgiving-what-we-can-new-year-drive%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Giving%20What%20We%20Can%20-%20New%20Year%20drive%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMHarArYfjuDyaJwFo%2Fgiving-what-we-can-new-year-drive", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMHarArYfjuDyaJwFo%2Fgiving-what-we-can-new-year-drive", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 293, "htmlBody": "<p style=\"margin: 4px 0px; color: #141823; font-family: Helvetica, Arial, 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 14px; line-height: 18px;\">If you&rsquo;ve been planning to get around to maybe thinking about Effective Altruism, we&rsquo;re making your job easier. A group of UK students has <a href=\"https://www.facebook.com/events/1581545938749145/\">set up a drive</a>&nbsp;for people to sign up to the <a href=\"https://givingwhatwecan.org\">Giving What We Can</a>&nbsp;pledge to donate 10% of their future&nbsp;<span class=\"text_exposed_show\" style=\"display: inline;\">income to charity. It does not specify the charities - that decision remains under your control. <a href=\"https://www.givingwhatwecan.org/get-involved/become-member\">The pledge</a>&nbsp;is not legally binding, but honour is a powerful force when it comes to promising to help. If 10% is a daunting number, or you don't want to sign away your future earnings in perpetuity, there is a <a href=\"https://www.givingwhatwecan.org/try-giving\">Try Giving</a>&nbsp;scheme in which you may donate less money for less time. I suggest five years (that is, from 2015 to 2020) of 5% as a suitable \"silver\" option to the 10%-until-retirement \"gold medal\".</span></p>\n<div class=\"text_exposed_show\" style=\"display: inline; color: #141823; font-family: Helvetica, Arial, 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 14px; line-height: 18px;\">\n<p style=\"margin: 4px 0px;\">&nbsp;</p>\n<p style=\"margin: 4px 0px;\">We&rsquo;re hoping to take advantage of the existing Schelling point of &ldquo;new year&rdquo; as a time for resolutions, as well as building the kind of community spirit that gets people signing up in groups. If you feel it&rsquo;s a word worth spreading, please feel free to spread it. As of this writing, GWWC reported 41 new members this month, which is a record for monthly acquisitions (and we&rsquo;re only halfway through the month, three days into the event).</p>\n<p style=\"margin: 4px 0px;\">&nbsp;</p>\n<p style=\"margin: 4px 0px;\">If anyone has suggestions about how to better publicise this event (or Effective Altruism generally), please do let me know. We&rsquo;re currently talking to various news outlets and high-profile philanthropists to see if they can give us a mention, but suggestions are always welcome. Likewise, comments on the effectiveness of this post itself will be gratefully noted.</p>\n<p style=\"margin: 4px 0px;\">&nbsp;</p>\n<p style=\"margin: 4px 0px;\">About Giving What We Can: GWWC is under the umbrella of the Centre for Effective Altruism, was <a href=\"/lw/fej/giving_what_we_can_80000_hours_and_metacharity/\">co-founded by a LessWronger</a>, and in 2013 <a href=\"/lw/gpm/giving_what_we_can_september_internship/8hfw\">had verbal praise from lukeprog</a>.</p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MHarArYfjuDyaJwFo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 14, "extendedScore": null, "score": 7.7e-05, "legacy": true, "legacyId": "27740", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FCiMtrsM8mcmBtfTR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-17T23:04:13.612Z", "modifiedAt": null, "url": null, "title": "How many words do we have and how many distinct concepts do we have?", "slug": "how-many-words-do-we-have-and-how-many-distinct-concepts-do", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:00.812Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "CbKyip78FNQXB2QTu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JLWTRLZ5yiCghWrAk/how-many-words-do-we-have-and-how-many-distinct-concepts-do", "pageUrlRelative": "/posts/JLWTRLZ5yiCghWrAk/how-many-words-do-we-have-and-how-many-distinct-concepts-do", "linkUrl": "https://www.lesswrong.com/posts/JLWTRLZ5yiCghWrAk/how-many-words-do-we-have-and-how-many-distinct-concepts-do", "postedAtFormatted": "Wednesday, December 17th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20many%20words%20do%20we%20have%20and%20how%20many%20distinct%20concepts%20do%20we%20have%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20many%20words%20do%20we%20have%20and%20how%20many%20distinct%20concepts%20do%20we%20have%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJLWTRLZ5yiCghWrAk%2Fhow-many-words-do-we-have-and-how-many-distinct-concepts-do%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20many%20words%20do%20we%20have%20and%20how%20many%20distinct%20concepts%20do%20we%20have%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJLWTRLZ5yiCghWrAk%2Fhow-many-words-do-we-have-and-how-many-distinct-concepts-do", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJLWTRLZ5yiCghWrAk%2Fhow-many-words-do-we-have-and-how-many-distinct-concepts-do", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 697, "htmlBody": "<p>In another message, I suggested that, given how many cultures we have to borrow from, that our language may include multiple words from various sources that apply to a single concept.</p>\n<p>An example is Reality, or Existence, or Being, or Universe, or Cosmos, or Nature, ect.</p>\n<p>Another is Subjectivity, Mind, Consciousness, Experience, Qualia, Phenomenal, Mental, ect</p>\n<p>Is there any problem with accepting these claims so far? Curious what case would be made to the contrary.</p>\n<p>(Here's a bit of a contextual aside, between quantum mechanics and cosmology, the words \"universe\", \"multiverse\", and \"observable universe\" mean at least 10 different things, depending on who you ask. People often say the Multiverse comes from Hugh Everett. But what they are calling the multiverse, Everett called \"universal wave function\", or \"universe\". How did Everett's universe become the Multiverse? DeWitt came along and emphasized some part of the wave function branching into different worlds. So, if you're following, one Universe, many worlds. Over the next few decades, this idea was popularized as having \"many parallel universes\", which is obviously inaccurate. Well, a Scottish chap decided to correct this. He stated the Universe was the Universal Wave Function, where it was \"a complete one\", because that's what \"uni\" means. And that our perceived worlds of various objects is a \"multiverse\". One Universe, many Multiverses. Again, the \"parallel universes\" idea seemed cooler, so as it became more popular the Multiverse became one and the universe became many. What's my point? The use of these words is legitimate fiasco, and I suggest we abandon them altogether.)</p>\n<p>If these claims are found to be palatable, what do they suggest?</p>\n<p>I propose, respectfully and humbly as I can imagine there may be compelling alternatives presented here, that in the 21st century, we make a decision about which concepts are necessary, which term we will use to describe that concept, and respectfully leave the remaining terms for the domain of poetry.</p>\n<p>Here are the words I think we need:</p>\n<ol>\n<li>reality</li>\n<li>model</li>\n<li>absolute</li>\n<li>relative</li>\n<li>subjective</li>\n<li>objective</li>\n<li>measurement</li>\n<li>observer</li>\n</ol>\n<p>With these terms I feel we can construct a concise metaphysical framework, consistent with the great rationalists of history, and that accurately described Everett's \"Relative State Formulation of Quantum Mechanics\".</p>\n<ol>\n<li>Absolute reality is what is. It is relative to no observer. It is real prior to measurement.</li>\n<li>Subjective reality is what is, relative to a single observer. It exists at measurement.</li>\n<li>Objective reality is the model relative to all observers. It exists post-measurement.</li>\n</ol>\n<p>Everett's Relative State formulation, is roughly this:</p>\n<ol>\n<li>The wave function is the \"absolute state\" of the model</li>\n<li>The wave function contains an observer and their measurement apparatus</li>\n<li>An observer makes a measurements and records the result in a memory</li>\n<li>those measurement records are the \"relative state\" of the model</li>\n</ol>\n<p>Here we see that the words multiverse and universe are abandoned for absolute and relative states, which is actually the language used in the Relative State Formulation.</p>\n<p>My conclusion then, for you consideration and comment, is that a technical view of reality can be attained by having a select set of terms, and this view is not only consistent with themes of philosophy (which I didn't really explain) but also the proper framework in which to interpret quantum mechanics (ala Everett).</p>\n<p>(I'm not sure how familiar everyone here is with Everett specifically or not. His thesis depended on \"automatically function machines\" that make measurements with sensory gear and record them. After receiving his PhD, he left theoretical physics, and had a life long fascination with computer vision and computer hearing. That suggests to me, the reason his papers have been largely confounding to the general physicists, is because they didn't realize the extent to which Everett really thought he could mathematically model an observer.)</p>\n<p>I should note, it may clarify things to add another term \"truth\", though this would in general be taken as an analog of \"real\". For example, if something is absolute true, then it is of absolute reality. If something is objectively true, then it is of objective reality. The word \"knowledge\" in this sense is a poetic word for objective truth, understood on the premise that objective truth is not absolute truth.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JLWTRLZ5yiCghWrAk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -6, "extendedScore": null, "score": 2.2782794266454408e-06, "legacy": true, "legacyId": "27742", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-18T15:46:52.195Z", "modifiedAt": null, "url": null, "title": "(Very Short) PSA: Combined Main and Discussion Feed", "slug": "very-short-psa-combined-main-and-discussion-feed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:40.417Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bqy6vdgCS5AXpxeia/very-short-psa-combined-main-and-discussion-feed", "pageUrlRelative": "/posts/bqy6vdgCS5AXpxeia/very-short-psa-combined-main-and-discussion-feed", "linkUrl": "https://www.lesswrong.com/posts/bqy6vdgCS5AXpxeia/very-short-psa-combined-main-and-discussion-feed", "postedAtFormatted": "Thursday, December 18th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20(Very%20Short)%20PSA%3A%20Combined%20Main%20and%20Discussion%20Feed&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A(Very%20Short)%20PSA%3A%20Combined%20Main%20and%20Discussion%20Feed%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbqy6vdgCS5AXpxeia%2Fvery-short-psa-combined-main-and-discussion-feed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=(Very%20Short)%20PSA%3A%20Combined%20Main%20and%20Discussion%20Feed%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbqy6vdgCS5AXpxeia%2Fvery-short-psa-combined-main-and-discussion-feed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbqy6vdgCS5AXpxeia%2Fvery-short-psa-combined-main-and-discussion-feed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 121, "htmlBody": "<p>For anyone who's annoyed by having to check newest submissions for Main and Discussion separately, there is a feed for combined submissions from both, in the form of <a href=\"/r/all/new/\" target=\"_blank\">Newest Submissions - All</a> (<a href=\"/r/all/new/.rss\">RSS feed</a>).&nbsp; (There's also <a href=\"/r/all/comments/\" target=\"_blank\">Comments - All</a> (<a href=\"/r/all/comments/.rss\">RSS feed</a>), but for me at least, it seems to only show comments from Main and none from Discussion.)</p>\n<p>Thanks to <span class=\"comment-author\"><span class=\"author\"><a id=\"author_t1_br10\" href=\"/lw/le3/open_thread_dec_15_dec_21_2014/br10\" target=\"_blank\">RichardKennaway</a> for bringing this to my attention, and to </span></span><span class=\"comment-author\"><span class=\"author\"><a id=\"author_t1_br0w\" href=\"/lw/le3/open_thread_dec_15_dec_21_2014/br0w\" target=\"_blank\">Unknowns</a> for asking the question that prompted him.&nbsp; (If you've got the time, head over there and give them some karma.)&nbsp; I thought this deserved the visibility of a post in Discussion, as not everyone reads through the Open Thread, and I think there's a chance that many would benefit from this information.</span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bqy6vdgCS5AXpxeia", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 21, "extendedScore": null, "score": 2.280542113632685e-06, "legacy": true, "legacyId": "27744", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-18T15:48:39.169Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow Meetup: biology, CBT and something mysterious", "slug": "meetup-moscow-meetup-biology-cbt-and-something-mysterious", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "berekuk", "createdAt": "2009-09-25T22:53:16.659Z", "isAdmin": false, "displayName": "berekuk"}, "userId": "7B8mbMEHF5qW9tfxk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/82RvzRJkZtyP9xZ2H/meetup-moscow-meetup-biology-cbt-and-something-mysterious", "pageUrlRelative": "/posts/82RvzRJkZtyP9xZ2H/meetup-moscow-meetup-biology-cbt-and-something-mysterious", "linkUrl": "https://www.lesswrong.com/posts/82RvzRJkZtyP9xZ2H/meetup-moscow-meetup-biology-cbt-and-something-mysterious", "postedAtFormatted": "Thursday, December 18th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%20Meetup%3A%20biology%2C%20CBT%20and%20something%20mysterious&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%20Meetup%3A%20biology%2C%20CBT%20and%20something%20mysterious%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82RvzRJkZtyP9xZ2H%2Fmeetup-moscow-meetup-biology-cbt-and-something-mysterious%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%20Meetup%3A%20biology%2C%20CBT%20and%20something%20mysterious%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82RvzRJkZtyP9xZ2H%2Fmeetup-moscow-meetup-biology-cbt-and-something-mysterious", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82RvzRJkZtyP9xZ2H%2Fmeetup-moscow-meetup-biology-cbt-and-something-mysterious", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 196, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/182'>Moscow Meetup: biology, CBT and something mysterious</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 December 2014 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Here's our plan:\nevolutionary origins of morality\nmetaphilosophy, real world metaethics and some other strange things\nCBT (how to kill yourself by psychology).\nAnd maybe something about Stanovich model.\nDetails and schedule: <a href=\"https://lesswrong-ru.hackpad.com/-21--A2k7ZUcyXyW\" rel=\"nofollow\">https://lesswrong-ru.hackpad.com/-21--A2k7ZUcyXyW</a> Yudcoins, positive reinforcement and pizza will all be present. If you've been to our meetups, you know what I'm talking about, and if you didn't, the best way to find out is to come and see for yourself.\nInfo for newcomers: We gather in the Yandex office. This time we'll be at Extropolis building, door is on the left from the archway. Here is a guide how to get to Yandex: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">http://company.yandex.ru/contacts/redrose/</a>\nTry to come in time, we will allow latecomers to enter every 15 minutes. Call Slava or send him SMS at +7(926)313-96-42 if you're late or can't find the entrance. We start at 14:00 and stay until at least 19-20. Please pay attention that we only gather near the entrance and then come inside.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/182'>Moscow Meetup: biology, CBT and something mysterious</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "82RvzRJkZtyP9xZ2H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.280546140646385e-06, "legacy": true, "legacyId": "27745", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow_Meetup__biology__CBT_and_something_mysterious\">Discussion article for the meetup : <a href=\"/meetups/182\">Moscow Meetup: biology, CBT and something mysterious</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 December 2014 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Here's our plan:\nevolutionary origins of morality\nmetaphilosophy, real world metaethics and some other strange things\nCBT (how to kill yourself by psychology).\nAnd maybe something about Stanovich model.\nDetails and schedule: <a href=\"https://lesswrong-ru.hackpad.com/-21--A2k7ZUcyXyW\" rel=\"nofollow\">https://lesswrong-ru.hackpad.com/-21--A2k7ZUcyXyW</a> Yudcoins, positive reinforcement and pizza will all be present. If you've been to our meetups, you know what I'm talking about, and if you didn't, the best way to find out is to come and see for yourself.\nInfo for newcomers: We gather in the Yandex office. This time we'll be at Extropolis building, door is on the left from the archway. Here is a guide how to get to Yandex: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">http://company.yandex.ru/contacts/redrose/</a>\nTry to come in time, we will allow latecomers to enter every 15 minutes. Call Slava or send him SMS at +7(926)313-96-42 if you're late or can't find the entrance. We start at 14:00 and stay until at least 19-20. Please pay attention that we only gather near the entrance and then come inside.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow_Meetup__biology__CBT_and_something_mysterious1\">Discussion article for the meetup : <a href=\"/meetups/182\">Moscow Meetup: biology, CBT and something mysterious</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow Meetup: biology, CBT and something mysterious", "anchor": "Discussion_article_for_the_meetup___Moscow_Meetup__biology__CBT_and_something_mysterious", "level": 1}, {"title": "Discussion article for the meetup : Moscow Meetup: biology, CBT and something mysterious", "anchor": "Discussion_article_for_the_meetup___Moscow_Meetup__biology__CBT_and_something_mysterious1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-18T16:17:41.734Z", "modifiedAt": null, "url": null, "title": "Rationality Jokes Thread", "slug": "rationality-jokes-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:31.029Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gunnar_Zarncke", "createdAt": "2013-07-20T15:40:42.323Z", "isAdmin": false, "displayName": "Gunnar_Zarncke"}, "userId": "qmJFRN7jitjPsuF3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YixiQqbjCC3eRK7d8/rationality-jokes-thread", "pageUrlRelative": "/posts/YixiQqbjCC3eRK7d8/rationality-jokes-thread", "linkUrl": "https://www.lesswrong.com/posts/YixiQqbjCC3eRK7d8/rationality-jokes-thread", "postedAtFormatted": "Thursday, December 18th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Jokes%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Jokes%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYixiQqbjCC3eRK7d8%2Frationality-jokes-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Jokes%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYixiQqbjCC3eRK7d8%2Frationality-jokes-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYixiQqbjCC3eRK7d8%2Frationality-jokes-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<p>This is an experimental thread. It is somewhat in the spirit of the Rationality Quotes Thread but without the requirements and with a focus on humorous value. You may post insightful jokes, nerd or math jokes or try out rationality jokes of your own invention.&nbsp;</p>\n<p>ADDED: Apparently there has been an earlier <a href=\"/r/discussion/lw/ki0/jokes_thread/\">Jokes Thread</a> which was failry successful. Consider this another instance.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hNFdS3rRiYgqqD8aM": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YixiQqbjCC3eRK7d8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 20, "extendedScore": null, "score": 6.6e-05, "legacy": true, "legacyId": "27746", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ifknAtXEGJbNrNF7B"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-18T22:11:36.955Z", "modifiedAt": null, "url": null, "title": "Bayes Academy Development Report 2 - improved data visualization", "slug": "bayes-academy-development-report-2-improved-data", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:57.536Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/98rdEMLEf6ADGbZsA/bayes-academy-development-report-2-improved-data", "pageUrlRelative": "/posts/98rdEMLEf6ADGbZsA/bayes-academy-development-report-2-improved-data", "linkUrl": "https://www.lesswrong.com/posts/98rdEMLEf6ADGbZsA/bayes-academy-development-report-2-improved-data", "postedAtFormatted": "Thursday, December 18th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayes%20Academy%20Development%20Report%202%20-%20improved%20data%20visualization&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayes%20Academy%20Development%20Report%202%20-%20improved%20data%20visualization%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98rdEMLEf6ADGbZsA%2Fbayes-academy-development-report-2-improved-data%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayes%20Academy%20Development%20Report%202%20-%20improved%20data%20visualization%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98rdEMLEf6ADGbZsA%2Fbayes-academy-development-report-2-improved-data", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98rdEMLEf6ADGbZsA%2Fbayes-academy-development-report-2-improved-data", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 838, "htmlBody": "<p><em>See <a href=\"/lw/lad/bayes_academy_development_report_1/\">here</a> for the previous update if you missed / forgot it.</em></p>\n<p>In this update, no new game content, but new graphics.</p>\n<p>I wasn&rsquo;t terribly happy about the graphical representation of the various nodes in the last update. Especially in the first two networks, if you didn&rsquo;t read the descriptions of the nodes carefully, it was very easy to just click your way through them without really having a clue of what the network was actually doing. Needless to say, for a game that&rsquo;s supposed to teach how the networks function, this is highly non-optimal.</p>\n<p>Here&rsquo;s the representation that I&rsquo;m now experimenting with: the truth table of the nodes is represented graphically inside the node. The prior variable at the top doesn&rsquo;t really have a truth table, it&rsquo;s just true or false. The &ldquo;is&rdquo; variable at the bottom is true if its parent is true, and false if its parent is false.</p>\n<p><img style=\"vertical-align: middle;\" src=\"http://kajsotala.fi/Random/Bayes/Visualization01.png\" alt=\"\" width=\"267\" height=\"577\" /></p>\n<p>You may remember that in the previous update, unobservable nodes were represented in grayscale. I ended up dropping that, because that would have been confusing in this representation: if the parent is unobservable, should the blobs representing its truth values in the child node be in grayscale as well? Both &ldquo;yes&rdquo; and &ldquo;no&rdquo; answers felt confusing.</p>\n<p>Instead the observational state of a node is now represented by its border color. Black for unobservable, gray for observable, no border for observed. The metaphor is supposed to be something like, a border is a veil of ignorance blocking us from seeing the node directly, but if the veil is gray it&rsquo;s weak enough to be broken, whereas a black veil is strong enough to resist a direct assault. Or something.</p>\n<p><img src=\"http://kajsotala.fi/Random/Bayes/Visualization02.png\" alt=\"\" width=\"207\" height=\"582\" /></p>\n<p>When you observe a node, not only does its border disappear, but the truth table entries that get reduced to a zero probability disappear, to be replaced by white boxes. I experimented with having the eliminated entries still show up in grayscale, so you could e.g. see that the &ldquo;is&rdquo; node used to contain the entry for (false -&gt; false), but felt that this looked clearer.</p>\n<p><img src=\"http://kajsotala.fi/Random/Bayes/Visualization03.png\" alt=\"\" width=\"383\" height=\"639\" /></p>\n<p>The &ldquo;or&rdquo; node at the bottom is getting a little crowded, but hopefully not too crowded. Since we know that its value is &ldquo;true&rdquo;, the truth table entry showing (false, false -&gt; false) shows up in all whites. It&rsquo;s also already been observed, so it starts without a border.</p>\n<p><img src=\"http://kajsotala.fi/Random/Bayes/Visualization04.png\" alt=\"\" width=\"382\" height=\"623\" /></p>\n<p>After we observe that there&rsquo;s no monster behind us, the &ldquo;or&rdquo; node loses its entries for (monster, !waiting -&gt; looks) and (monster, waiting -&gt; looks), leaving only (!monster, waiting -&gt; looks): meaning that the boy must be waiting for us to answer.</p>\n<p>This could still be made clearer: currently the network updates instantly. I&rsquo;m thinking about adding a brief animation where the &ldquo;monster&rdquo; variable would first be revealed as false, which would then propagate an update to the values of &ldquo;looks at you&rdquo; (with e.g. the red tile in &ldquo;monster&rdquo; blinking at the same time as the now-invalid truth table entries, and when the tiles stopped blinking, those now-invalid entries would have disappeared), and that would in turn propagate the update to the &ldquo;waiting&rdquo; node, deleting the red color from it. But I haven&rsquo;t yet implemented this.</p>\n<p><img src=\"http://kajsotala.fi/Random/Bayes/Visualization05.png\" alt=\"\" width=\"662\" height=\"644\" /></p>\n<p>The third network is where things get a little tricky. The &ldquo;attacking&rdquo; node is of type &ldquo;majority vote&rdquo; - i.e. it&rsquo;s true if at least two of its parents are true, and false otherwise. That would make for a truth table with eight entries, each holding four blobs each, and we could already see the &ldquo;or&rdquo; node in the previous screen being crowded. I&rsquo;m not quite sure of what to do here. At this moment I&rsquo;m thinking of just leaving the node as is, and displaying more detailed information in the sidebar.</p>\n<p><img src=\"http://kajsotala.fi/Random/Bayes/Visualization06.png\" alt=\"\" width=\"668\" height=\"644\" /></p>\n<p>Here&rsquo;s another possible problem. Just having the truth table entries works fine to make it obvious where the overall probability of the node comes from&hellip; for as long as the valid values of the entries are restricted to &ldquo;possible&rdquo; and &ldquo;impossible&rdquo;. Then you can see at a glance that, say, of the three possible entries, two would make this node true and one would make this false, so there&rsquo;s a \u2154 chance of it being true.</p>\n<p>But in this screen, that has ceased to be the case. The &ldquo;attacking&rdquo; node has a 75% chance of being true, meaning that, for instance, the &ldquo;is / block&rdquo; node&rsquo;s &ldquo;true -&gt; true&rdquo; entry also has a 75% chance of being the right one. This isn&rsquo;t reflected in the truth table visualization. I thought of adding small probability bars under each truth table entry, or having the size of the truth table blobs reflect their probability, but then I&rsquo;d have to make the nodes even bigger, and it feels like it would easily start looking cluttered again. But maybe it&rsquo;d be the right choice anyway? Or maybe just put the more detailed information in the sidebar? I&rsquo;m not sure of the best thing to do here.</p>\n<p>If anyone has good suggestions, I would be grateful to get advice from people who have more of a visual designer gene than I do!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "98rdEMLEf6ADGbZsA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 2.281411434176619e-06, "legacy": true, "legacyId": "27748", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XJbyks4QhbGmPk9hJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-18T23:36:48.683Z", "modifiedAt": null, "url": null, "title": "An explanation of the 'Many Interacting Worlds' theory of quantum mechanics (by Sean Carroll and Chip Sebens)", "slug": "an-explanation-of-the-many-interacting-worlds-theory-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:41.746Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ander", "createdAt": "2013-11-25T22:31:01.872Z", "isAdmin": false, "displayName": "Ander"}, "userId": "TAWyrYP37Zvbiok2Y", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MtQQztS57P3dWR6JK/an-explanation-of-the-many-interacting-worlds-theory-of", "pageUrlRelative": "/posts/MtQQztS57P3dWR6JK/an-explanation-of-the-many-interacting-worlds-theory-of", "linkUrl": "https://www.lesswrong.com/posts/MtQQztS57P3dWR6JK/an-explanation-of-the-many-interacting-worlds-theory-of", "postedAtFormatted": "Thursday, December 18th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20explanation%20of%20the%20'Many%20Interacting%20Worlds'%20theory%20of%20quantum%20mechanics%20(by%20Sean%20Carroll%20and%20Chip%20Sebens)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20explanation%20of%20the%20'Many%20Interacting%20Worlds'%20theory%20of%20quantum%20mechanics%20(by%20Sean%20Carroll%20and%20Chip%20Sebens)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtQQztS57P3dWR6JK%2Fan-explanation-of-the-many-interacting-worlds-theory-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20explanation%20of%20the%20'Many%20Interacting%20Worlds'%20theory%20of%20quantum%20mechanics%20(by%20Sean%20Carroll%20and%20Chip%20Sebens)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtQQztS57P3dWR6JK%2Fan-explanation-of-the-many-interacting-worlds-theory-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtQQztS57P3dWR6JK%2Fan-explanation-of-the-many-interacting-worlds-theory-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 24, "htmlBody": "<p>This is the first explanation of a 'many worlds' theory of quantum mechanics that has ever made sense to me. The animations are excellent:</p>\n<p>http://www.preposterousuniverse.com/blog/2014/12/16/guest-post-chip-sebens-on-the-many-interacting-worlds-approach-to-quantum-mechanics/</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MtQQztS57P3dWR6JK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 2.2816040096995894e-06, "legacy": true, "legacyId": "27750", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-18T23:41:14.678Z", "modifiedAt": null, "url": null, "title": "[Short, Meta] Should open threads be more frequent?", "slug": "short-meta-should-open-threads-be-more-frequent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:48.181Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Metus", "createdAt": "2011-01-23T21:54:34.357Z", "isAdmin": false, "displayName": "Metus"}, "userId": "mNQ4fSvro7LYgrii4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A4zYeKwgxSLJWSTcX/short-meta-should-open-threads-be-more-frequent", "pageUrlRelative": "/posts/A4zYeKwgxSLJWSTcX/short-meta-should-open-threads-be-more-frequent", "linkUrl": "https://www.lesswrong.com/posts/A4zYeKwgxSLJWSTcX/short-meta-should-open-threads-be-more-frequent", "postedAtFormatted": "Thursday, December 18th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BShort%2C%20Meta%5D%20Should%20open%20threads%20be%20more%20frequent%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BShort%2C%20Meta%5D%20Should%20open%20threads%20be%20more%20frequent%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4zYeKwgxSLJWSTcX%2Fshort-meta-should-open-threads-be-more-frequent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BShort%2C%20Meta%5D%20Should%20open%20threads%20be%20more%20frequent%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4zYeKwgxSLJWSTcX%2Fshort-meta-should-open-threads-be-more-frequent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA4zYeKwgxSLJWSTcX%2Fshort-meta-should-open-threads-be-more-frequent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>Currently open threads are weekly and very well received. However they tend to fill up quickly. Personally I fear that my contribution will drown unless posted early on so I tend to wait if I want to add a new top level post. Does anyone else have this impression? Someone with better coding skills than me could put this statistically by plotting the number of top level posts and total posts over time: If the curve is convex people tend to delay their posts.</p>\n<p>So should open threads be more frequent and if so what frequency?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A4zYeKwgxSLJWSTcX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 2.2816140313552148e-06, "legacy": true, "legacyId": "27751", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-19T04:56:17.895Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington, D.C.: Fun & Games", "slug": "meetup-washington-d-c-fun-and-games-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FarAGgNG8AakuJcyN/meetup-washington-d-c-fun-and-games-0", "pageUrlRelative": "/posts/FarAGgNG8AakuJcyN/meetup-washington-d-c-fun-and-games-0", "linkUrl": "https://www.lesswrong.com/posts/FarAGgNG8AakuJcyN/meetup-washington-d-c-fun-and-games-0", "postedAtFormatted": "Friday, December 19th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%2C%20D.C.%3A%20Fun%20%26%20Games&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%2C%20D.C.%3A%20Fun%20%26%20Games%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFarAGgNG8AakuJcyN%2Fmeetup-washington-d-c-fun-and-games-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%2C%20D.C.%3A%20Fun%20%26%20Games%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFarAGgNG8AakuJcyN%2Fmeetup-washington-d-c-fun-and-games-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFarAGgNG8AakuJcyN%2Fmeetup-washington-d-c-fun-and-games-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/183'>Washington, D.C.: Fun &amp; Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to hang out, play games, and engage in fun conversation.</p>\n\n<p><em>Note:</em> Feel free to send an email to the Google Group - lesswrong-dc - if you have a game you wish to recruit people to play in advance. This is especially useful for games that take 3+ hours, as you would want to start playing by 3:30 to be sure of finishing by 7:00.</p>\n\n<p><strong>Upcoming meetups:</strong></p>\n\n<ul>\n<li><em>Dec. 28: Tentatively canceled for the holidays. <strong>Edit:</strong> An announcement is planned on Monday, Dec. 22 whether a meetup will be scheduled after all.</em></li>\n<li><strong>Jan. 4:</strong> Meta Meetup (discuss Less Wrong DC: what you like, what you want, what you'd change, &amp;c.)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/183'>Washington, D.C.: Fun &amp; Games</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FarAGgNG8AakuJcyN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.2823264330333814e-06, "legacy": true, "legacyId": "27752", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Fun___Games\">Discussion article for the meetup : <a href=\"/meetups/183\">Washington, D.C.: Fun &amp; Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to hang out, play games, and engage in fun conversation.</p>\n\n<p><em>Note:</em> Feel free to send an email to the Google Group - lesswrong-dc - if you have a game you wish to recruit people to play in advance. This is especially useful for games that take 3+ hours, as you would want to start playing by 3:30 to be sure of finishing by 7:00.</p>\n\n<p><strong id=\"Upcoming_meetups_\">Upcoming meetups:</strong></p>\n\n<ul>\n<li><em>Dec. 28: Tentatively canceled for the holidays. <strong>Edit:</strong> An announcement is planned on Monday, Dec. 22 whether a meetup will be scheduled after all.</em></li>\n<li><strong>Jan. 4:</strong> Meta Meetup (discuss Less Wrong DC: what you like, what you want, what you'd change, &amp;c.)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Fun___Games1\">Discussion article for the meetup : <a href=\"/meetups/183\">Washington, D.C.: Fun &amp; Games</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington, D.C.: Fun & Games", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Fun___Games", "level": 1}, {"title": "Upcoming meetups:", "anchor": "Upcoming_meetups_", "level": 2}, {"title": "Discussion article for the meetup : Washington, D.C.: Fun & Games", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Fun___Games1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-19T05:00:06.000Z", "modifiedAt": "2021-02-11T02:27:53.431Z", "url": null, "title": "Nobody Is Perfect, Everything Is Commensurable", "slug": "nobody-is-perfect-everything-is-commensurable", "viewCount": null, "lastCommentedAt": "2021-08-19T12:57:18.348Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qw3Z79HELMsmLkL9F/nobody-is-perfect-everything-is-commensurable", "pageUrlRelative": "/posts/qw3Z79HELMsmLkL9F/nobody-is-perfect-everything-is-commensurable", "linkUrl": "https://www.lesswrong.com/posts/qw3Z79HELMsmLkL9F/nobody-is-perfect-everything-is-commensurable", "postedAtFormatted": "Friday, December 19th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Nobody%20Is%20Perfect%2C%20Everything%20Is%20Commensurable&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANobody%20Is%20Perfect%2C%20Everything%20Is%20Commensurable%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqw3Z79HELMsmLkL9F%2Fnobody-is-perfect-everything-is-commensurable%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Nobody%20Is%20Perfect%2C%20Everything%20Is%20Commensurable%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqw3Z79HELMsmLkL9F%2Fnobody-is-perfect-everything-is-commensurable", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqw3Z79HELMsmLkL9F%2Fnobody-is-perfect-everything-is-commensurable", "socialPreviewImageUrl": "http://slatestarcodex.com/blog_images/sschits.png", "question": false, "authorIsUnreviewed": false, "wordCount": 3375, "htmlBody": "<p><b>I.</b></p>\n<p>Recently spotted on Tumblr:</p>\n<blockquote><p>\u201cThis is going to be an unpopular opinion but I see stuff about ppl not wanting to reblog ferguson things and awareness around the world because they do not want negativity in their life plus it will cause them to have anxiety. They come to tumblr to escape n feel happy which think is a load of bull. There r literally ppl dying who live with the fear of going outside their homes to be shot and u cant post a fucking picture because it makes u a little upset?&#8221;</p></blockquote>\n<blockquote><p>\u201cCan yall maybe take some time away from reblogging fandom or humor crap and read up and reblog pakistan because the privilege you have of a safe bubble is not one shared by others?\u201d</p></blockquote>\n<p>Ignore the questionable stylistic choices and there&#8217;s an important point here worth considering. Something like &#8220;Yes, the feeling of constantly being outraged and mired in the latest controversy is unpleasant. And yes, it would be nice to get to avoid it and spend time with your family and look at kitten pics or something. But when the controversy is about people being murdered in cold blood, or living in fear, or something like that &#8211; then it&#8217;s your duty as a decent human being to care. In the best case scenario you&#8217;ll discharge that duty by organizing widespread protests or something &#8211; but the <i>absolute least</i> you can do is reblog a couple of slogans.&#8221;</p>\n<p>I think Cliff Pervocracy is trying to say something similar in <A HREF=\"http://pervocracy.tumblr.com/post/104260760964/politics-that-feel-good\">this post</A>. Key excerpt:</p>\n<blockquote><p>When you\u2019ve grown up with messages that you\u2019re incompetent to make your own decisions, that you don\u2019t deserve any of the things you have, and that you\u2019ll never be good enough, the [conservative] fantasy of rugged individualism starts looking pretty damn good.</p>\n<p>Intellectually, I think my current political milieu of feminism/progressivism/social justice is more correct, far better for the world in general, and more helpful to me since I don\u2019t actually live in a perfectly isolated cabin.</p>\n<p>But god, it\u2019s uncomfortable.  It\u2019s intentionally uncomfortable\u2014it\u2019s all about getting angry at injustice and questioning the rightness of your own actions and being sad so many people still live such painful lives.  Instead of looking at your cabin and declaring \u201cI shall name it&#8230;CLIFFORDSON MANOR,\u201d you need to look at your cabin and recognize that a long series of brutal injustices are responsible for the fact that you have a white-collar job that lets you buy a big useless house in the woods while the original owners of the land have been murdered or forced off it.</p>\n<p>And you\u2019re never good enough.  You can be good\u2014certainly you get major points for charity and activism and fighting the good fight\u2014but not good enough.  No matter what you do, you\u2019re still participating in plenty of corrupt systems that enforce oppression.  Short of bringing about a total revolution of everything, your work will never be done, you\u2019ll never be good enough.</p>\n<p>Once again, to be clear, I don\u2019t think this is wrong.  I just think it\u2019s a bummer.</p>\n<p>I don\u2019t know of a solution to this.  (Bummer again.)  I don\u2019t think progressivism can ever compete with the cozy self-satisfaction of the cabin fantasy.  I don\u2019t think it should.  Change is necessary in the world, people don\u2019t change if they\u2019re totally happy and comfortable, therefore discomfort is necessary.</p></blockquote>\n<p>I&#8217;d like to make what I hope is a friendly amendment to Cliff&#8217;s post. He thinks he&#8217;s talking about progressivism versus conservativism, but he isn&#8217;t. A conservative happy with his little cabin and occasional hunting excursions, and a progressive happy with her little SoHo flat and occasional poetry slams, are psychologically pretty similar. So are a liberal who abandons a cushy life to work as a community organizer in the inner city and fight poverty, and a conservative who abandons a cushy life to serve as an infantryman in Afghanistan to fight terrorism. The distinction Cliff is trying to get at here isn&#8217;t left-right. It&#8217;s activist versus passivist.</p>\n<p>As part of a movement <A HREF=\"https://pdf.yt/d/-jQQX6XY9dU0LN4G\">recently deemed postpolitical</A>, I have to admit I fall more on the passivist side of the spectrum &#8211; at least this particular conception of it. I talk about politics when they interest me or when I enjoy doing so, and I feel an obligation not to actively make things worse. But I don&#8217;t feel like I need to talk nonstop about whatever the designated Issue is until it distresses me and my readers both.</p>\n<p>I&#8217;ve heard people give lots of reasons for not wanting to get into politics. For some, hearing about all the evils of the world makes them want to curl into a ball and cry for hours. Still others feel deep personal guilt about anything they hear &#8211; an almost psychotic belief that if people are being hurt anywhere in the world, it&#8217;s their fault for not preventing it. A few are chronically uncertain about which side to take and worried that anything they do will cause more harm than good. A couple have traumatic experiences that make them leery of affiliating with a particular side &#8211; did you know the prosecutor in the Ferguson case was the son of a police officer who was killed by a black suspect? And still others are perfectly innocent and just want to reblog kitten pictures.</p>\n<p>Pervocracy admits this, and puts it better than I do:</p>\n<blockquote><p>But god, it\u2019s uncomfortable.  It\u2019s intentionally uncomfortable\u2014it\u2019s all about getting angry at injustice and questioning the rightness of your own actions and being sad so many people still live such painful lives.  Instead of looking at your cabin and declaring \u201cI shall name it&#8230;CLIFFORDSON MANOR,\u201d you need to look at your cabin and recognize that a long series of brutal injustices are responsible for the fact that you have a white-collar job that lets you buy a big useless house in the woods while the original owners of the land have been murdered or forced off it. And you\u2019re never good enough.  You can be good\u2014certainly you get major points for charity and activism and fighting the good fight\u2014but not good enough.  No matter what you do, you\u2019re still participating in plenty of corrupt systems that enforce oppression.  Short of bringing about a total revolution of everything, your work will never be done, you\u2019ll never be good enough.</p></blockquote>\n<p>That seems about right. Pervocracy ends up with discomfort, and I&#8217;m in about the same place. But other, less stable people end up with self-loathing. Still other people go further than that, into Calvinist-style &#8220;perhaps I am a despicable worm unworthy of existence&#8221;. <A HREF=\"http://moteinthedark.tumblr.com/post/104382718166/politics-that-feel-good\">moteinthedark&#8217;s reply to Pervocracy</A> gives me the impression that she struggles with this sometime. For these people, abstaining from politics is the only coping tool they have.</p>\n<p>But the counterargument is <i>still</i> that you&#8217;ve got a lot of chutzpah playing that card when people in Peshawar or Ferguson or Iraq don&#8217;t have access to this coping tool. You can&#8217;t just bring in a doctor&#8217;s note and say &#8220;As per my psychiatrist, I have a mental health issue and am excused from experiencing concern for the less fortunate.&#8221;</p>\n<p>One option is to deny the obligation. I am super sympathetic to this one. The <i>marginal</i> cost of my existence on the poor and suffering of the world is zero. In fact, it&#8217;s probably positive. My economic activity consists mostly of treating patients, buying products, and paying taxes. The first treats the poor&#8217;s illnesses, the second creates jobs, and the third pays for government assistance programs. Exactly what am I supposed to be apologizing for here? I may benefit from the genocide of the Indians in that I live on land that was formerly Indian-occupied. But I also benefit from the asteroid that killed the dinosaurs, in that I live on land that was formerly dinosaur-occupied. I don&#8217;t feel like I&#8217;m complicit in the asteroid strike; why should I feel complicit in the genocide?</p>\n<p>I have no objection to people who say this. The problem with it isn&#8217;t philosophical, it&#8217;s emotional. For <i>most people</i> it won&#8217;t be enough. The old saying goes &#8220;you can&#8217;t reason yourself out of something you didn&#8217;t reason yourself into to begin with&#8221;, and the idea that secure and prosperous people need to &#8220;give something back&#8221; is a lot older than accusations of &#8220;being complicit in structures of oppression&#8221;. It&#8217;s probably older than the Bible. People feel a deep-seated need to show that they understand how lucky they are and help those less fortunate than themselves.</p>\n<p>So what do we do with the argument that we are morally obligated to be political activists, possibly by reblogging everything about Ferguson that crosses our news feed?</p>\n<p><b>II.</b></p>\n<p>We ask: <i>why the heck are we privileging that particular subsection of the category &#8220;improving the world&#8221;?</i></p>\n<p>Pervocracy says that &#8220;short of bringing about a total revolution of everything, your work will never be done, you\u2019ll never be good enough.&#8221; But he is overly optimistic. Has your total revolution of everything eliminated ischaemic heart disease? Cured malaria? Kept elderly people out of nursing homes? No? Then you haven&#8217;t discharged your <A HREF=\"http://slatestarcodex.com/2014/05/10/infinite-debt/\">infinite debt</A> yet!</p>\n<p>Being a perfect person doesn&#8217;t just mean participating in every hashtag campaign you hear about. It means spending all your time at soup kitchens, becoming vegan, donating everything you have to charity, calling your grandmother up every week, and marrying Third World refugees who need visas rather than your one true love. </p>\n<p>And not all of these things are equally important.</p>\n<p>Five million people participated in the #BlackLivesMatter Twitter campaign. Suppose that solely as a result of this campaign, no currently-serving police officer ever harms an unarmed black person ever again. That&#8217;s 100 lives saved per year times let&#8217;s say twenty years left in the average officer&#8217;s career, for a total of 2000 lives saved, or 1/2500th of a life saved per campaign participant. By coincidence, 1/2500th of a life saved happens to be what you get when you donate $1 to the Against Malaria Foundation. The round-trip bus fare people used to make it to their #BlackLivesMatter protests could have saved ten times as many black lives as the protests themselves, <i>even given completely ridiculous overestimates of the protests&#8217; efficacy</i>.</p>\n<p>The moral of the story is that if you feel an obligation to give back to the world, participating in activist politics is one of the worst possible ways to do it. Giving even a tiny amount of money to charity is hundreds or even thousands of times more effective than almost any political action you can take. Even if you&#8217;re absolutely convinced a certain political issue is the most important thing in the world, you&#8217;ll effect more change by donating money to nonprofits lobbying about it than you will be reblogging anything. </p>\n<p>There is <i>no reason</i> that politics would even <i>come to the attention</i> of an unbiased person trying to &#8220;break out of their bubble of privilege&#8221; or &#8220;help people who are afraid of going outside of their house&#8221;. Anybody saying that people who want to do good need to spread their political cause is about as credible as a televangelist saying that people who want to do good need to give them money to buy a new headquarters. It&#8217;s possible that televangelists having beautiful headquarters might be <i>slightly</i> better than them having hideous headquarters, but it&#8217;s not the first thing a reasonable person trying to improve the world would think of.</p>\n<p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/sschits.png\"></p>\n<p><i>Average number of hits for posts on this blog, by topic</i></center></p>\n<p>Nobody cares about charity. Everybody cares about politics, especially race and gender. Just as televangelists who are obsessed with moving to a sweeter pad may come to think that donating to their building fund is the one true test of a decent human being, so our universal obsession with politics, race, and gender incites people to make convincing arguments that taking and spreading the right position on those issues is the one true test of a decent human being.</p>\n<p>So now we have an angle of attack against our original question. &#8220;Am I a bad person for not caring more about politics?&#8221; Well, every other way of doing good, especially charity, is more important than politics. So this question is strictly superseded by &#8220;Am I a bad person for not engaging in every other way of doing good, especially charity?&#8221; And then once we answer that, we can ask &#8220;Also, however much sin I have for not engaging in charity, should we add another mass of sin, about 1% as large, for my additional failure to engage in politics?&#8221;</p>\n<p>And Cliff Pervocracy&#8217;s concern of &#8220;Even if I do a lot of politics, am I still a bad person for not doing <i>all</i> the politics?&#8221; is superseded by &#8220;Even if I give a lot of charity, am I a bad person for not doing <i>all</i> the charity? And then a bad person in an additional way, about 1% as large, for not doing all the politics as well?&#8221;</p>\n<p>There&#8217;s no good answer to this question. If you want to feel anxiety and self-loathing for not giving 100% of your income, minus living expenses, to charity, then no one can stop you. </p>\n<p>I, on the other hand, would prefer to call that &#8220;not being perfect&#8221;. I would prefer to say that if you feel like you will live in anxiety and self-loathing until you have given a certain amount of money to charity, you should make that certain amount ten percent.</p>\n<p>Why ten percent?</p>\n<p>It&#8217;s ten percent because that&#8217;s the standard decreed by <A HREF=\"https://www.givingwhatwecan.org/\">Giving What We Can</A> and the effective altruist community. Why should we believe their standard? I think we should believe it because if we reject it in favor of &#8220;No, you are a bad person unless you give <i>all</i> of it,&#8221; then everyone will just sit around feeling very guilty and doing nothing. But if we very clearly say &#8220;You have discharged your moral duty if you give ten percent or more,&#8221; then many people will give ten percent or more. The most important thing is having a Schelling point, and ten percent is nice, round, <A HREF=\"http://en.wikipedia.org/wiki/Tithe\">divinely ordained</A>, and &#8211; crucially &#8211; the Schelling point upon which we have already settled. It is an <i>active</i> Schelling point. If you give ten percent, you can have your name on a nice list and get access to a secret forum on the Giving What We Can site which is actually pretty boring.</p>\n<p>It&#8217;s ten percent because <A HREF=\"http://slatestarcodex.com/2014/11/21/the-categories-were-made-for-man-not-man-for-the-categories/\">definitions were made for Man, not Man for definitions</A>, and if we define &#8220;good person&#8221; in a way such that everyone is sitting around miserable because they can&#8217;t reach an unobtainable standard, we are stupid definition-makers. If we are smart definition-makers, we will define it in whichever way which makes it the most effective tool to convince people to give at least that much. </p>\n<p>Finally, it&#8217;s ten percent because if you believe in <A HREF=\"http://slatestarcodex.com/2014/05/16/you-kant-dismiss-universalizability/\">something like universalizability</A> as a foundation for morality, a world in which everybody gives ten percent of their income to charity is a world where about <A HREF=\"http://www.bbc.com/news/magazine-17512040\">seven trillion dollars</A> go to charity a year. Solving global poverty forever is estimated to cost about $100 billion a year for the couple-decade length of the project. That&#8217;s <i>about two percent</i> of the money that would suddenly become available. If charity got seven trillion dollars a year, <i>the first year</i> would give us enough to solve global poverty, eliminate all treatable diseases, fund research into the untreatable ones for approximately the next forever, educate anybody who needs educating, feed anybody who needs feeding, fund an unparalleled renaissance in the arts, permamently save every rainforest in the world, and have enough left over to launch five or six different manned missions to Mars. That would be the <i>first year</i>. Goodness only knows what would happen in Year 2.</p>\n<p>(by contrast, if everybody in the world retweeted the latest hashtag campaign, Twitter would break.)</p>\n<p>Charity is in some sense the perfect unincentivized action. If you think the most important thing to do is to cure malaria, then a charitable donation is deliberately throwing the power of your brain and muscle behind the cause of curing malaria. If, <A HREF=\"http://slatestarcodex.com/2014/07/30/meditations-on-moloch/\">as I&#8217;ve argued</A>, the reason we can&#8217;t solve world poverty and disease and so on is the capture of our financial resources by the undirected dance of incentives, then what better way to fight back than by saying &#8220;Thanks but no thanks, I&#8217;m taking this abstract representation of my resources and using it <i>exactly</i> how I think it should most be used&#8221;?</p>\n<p>If you give 10% per year, you have done your part in making that world a reality. You can honestly say &#8220;Well, it&#8217;s not my fault that everyone <i>else</i> is still dragging their feet.&#8221;</p>\n<p><b>III.</b></p>\n<p>Once the level is fixed at ten percent, we get a better idea how to answer the original question: &#8220;If I want to be a good person who gives back to the community, but I am triggered by politics, what do I do?&#8221; You do good in a way that doesn&#8217;t trigger you. Another good thing about having less than 100% obligation is that it gives you the opportunity to budget and trade-off. If you make $30,000 and you accept 10% as a good standard you want to live up to, you can either donate $3000 to charity, or participate in political protests until your number of lives or dollars or DALYs saved is equivalent to that. </p>\n<p>Nobody is perfect. This gives us license not to be perfect either. Instead of aiming for an impossible goal, falling short, and not doing anything at all, we set an arbitrary but achievable goal designed to encourage the most people to do as much as possible. That goal is ten percent.</p>\n<p>Everything is commensurable. This gives us license to determine exactly how we fulfill that ten percent goal. Some people are triggered and terrified by politics. Other people are too sick to volunteer. Still others are poor and cannot give very much money. But money is a constant reminder that everything goes into the same pot, and that you can fulfill obligations in multiple equivalent ways. Some people will not be able to give ten percent of their income without excessive misery, but I bet thinking about their contribution in terms of a fungible good will help them decide how much volunteering or activism they need to reach the equivalent.</p>\n<p>Cliff Pervocracy says &#8220;Your work will never be done, you\u2019ll never be good enough.&#8221; This seems like a recipe for &#8211; at best &#8211; undirected misery, stewing in self-loathing, and total defenselessness against the first <A HREF=\"http://slatestarcodex.com/2014/12/17/the-toxoplasma-of-rage/\">parasitic meme</A> to come along and tell them to engage in the latest conflict or else they&#8217;re trash. At worst, it autocatalyzes an opposition of egoists who laugh at the idea of helping others.</p>\n<p>On the other hand, Jesus says &#8220;Take my yoke upon you&#8230;and you will find rest for your souls. For my yoke is easy and my burden is light.\u201d This seems like a recipe for getting people to say &#8220;Okay, I&#8217;ll take your yoke upon me! Thanks for the offer!&#8221;</p>\n<p>Persian poet Omar Khayyam, considering the conflict between the strict laws of Islam and his own desire to enjoy life, settles upon the following rule:</p>\n<blockquote><p>Heed not the Sunna, nor the law divine;<br />\nIf to the poor their portion you assign,<br />\nAnd never injure one, nor yet abuse,<br />\nI guarantee you heaven, as well as wine!</p></blockquote>\n<p>I&#8217;m not saying that donating 10% of your money to charity makes you a great person who is therefore freed of every other moral obligation. I&#8217;m not saying that anyone who chooses not to do it is therefore a bad person. I&#8217;m just saying that if you feel a need to discharge some feeling of a moral demand upon you to help others, and you want to do it intelligently, it beats most of the alternatives.</p>\n<p>This month is the <A HREF=\"http://lesswrong.com/r/discussion/lw/lek/giving_what_we_can_new_year_drive/\">membership drive</A> for <A HREF=\"https://www.givingwhatwecan.org/\">Giving What We Can</A>, the organization of people who have promised to give 10% of their earnings to charity. I am a member. Ozy is an aspiring member who plans to join once they are making a salary. Many of the commenters here are members &#8211; I recognize for example Taymon Beal&#8217;s name on their list. Some well-known moral philosophers like Peter Singer and Derek Parfit are members. Seven hundred other people are also members.</p>\n<p>I would recommend giving them a look.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FkzScn5byCs9PxGsA": 1, "JsJPrdgRGRqnci8cZ": 1, "3ee9k6NJfcGzL6kMS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qw3Z79HELMsmLkL9F", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 33, "extendedScore": null, "score": 9.8e-05, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "http://slatestarcodex.com/blog_images/sschits.png", "canonicalSequenceId": "WnTvZdXz2q9ySfr4o", "canonicalCollectionSlug": "codex", "canonicalBookId": "2tPEd5Gdm3iewB53M", "canonicalNextPostSlug": "answer-to-job", "canonicalPrevPostSlug": "the-parable-of-the-talents", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><b id=\"I_\">I.</b></p>\n<p>Recently spotted on Tumblr:</p>\n<blockquote><p>\u201cThis is going to be an unpopular opinion but I see stuff about ppl not wanting to reblog ferguson things and awareness around the world because they do not want negativity in their life plus it will cause them to have anxiety. They come to tumblr to escape n feel happy which think is a load of bull. There r literally ppl dying who live with the fear of going outside their homes to be shot and u cant post a fucking picture because it makes u a little upset?\u201d</p></blockquote>\n<blockquote><p>\u201cCan yall maybe take some time away from reblogging fandom or humor crap and read up and reblog pakistan because the privilege you have of a safe bubble is not one shared by others?\u201d</p></blockquote>\n<p>Ignore the questionable stylistic choices and there\u2019s an important point here worth considering. Something like \u201cYes, the feeling of constantly being outraged and mired in the latest controversy is unpleasant. And yes, it would be nice to get to avoid it and spend time with your family and look at kitten pics or something. But when the controversy is about people being murdered in cold blood, or living in fear, or something like that \u2013 then it\u2019s your duty as a decent human being to care. In the best case scenario you\u2019ll discharge that duty by organizing widespread protests or something \u2013 but the <i>absolute least</i> you can do is reblog a couple of slogans.\u201d</p>\n<p>I think Cliff Pervocracy is trying to say something similar in <a href=\"http://pervocracy.tumblr.com/post/104260760964/politics-that-feel-good\">this post</a>. Key excerpt:</p>\n<blockquote><p>When you\u2019ve grown up with messages that you\u2019re incompetent to make your own decisions, that you don\u2019t deserve any of the things you have, and that you\u2019ll never be good enough, the [conservative] fantasy of rugged individualism starts looking pretty damn good.</p>\n<p>Intellectually, I think my current political milieu of feminism/progressivism/social justice is more correct, far better for the world in general, and more helpful to me since I don\u2019t actually live in a perfectly isolated cabin.</p>\n<p>But god, it\u2019s uncomfortable.  It\u2019s intentionally uncomfortable\u2014it\u2019s all about getting angry at injustice and questioning the rightness of your own actions and being sad so many people still live such painful lives.  Instead of looking at your cabin and declaring \u201cI shall name it\u2026CLIFFORDSON MANOR,\u201d you need to look at your cabin and recognize that a long series of brutal injustices are responsible for the fact that you have a white-collar job that lets you buy a big useless house in the woods while the original owners of the land have been murdered or forced off it.</p>\n<p>And you\u2019re never good enough.  You can be good\u2014certainly you get major points for charity and activism and fighting the good fight\u2014but not good enough.  No matter what you do, you\u2019re still participating in plenty of corrupt systems that enforce oppression.  Short of bringing about a total revolution of everything, your work will never be done, you\u2019ll never be good enough.</p>\n<p>Once again, to be clear, I don\u2019t think this is wrong.  I just think it\u2019s a bummer.</p>\n<p>I don\u2019t know of a solution to this.  (Bummer again.)  I don\u2019t think progressivism can ever compete with the cozy self-satisfaction of the cabin fantasy.  I don\u2019t think it should.  Change is necessary in the world, people don\u2019t change if they\u2019re totally happy and comfortable, therefore discomfort is necessary.</p></blockquote>\n<p>I\u2019d like to make what I hope is a friendly amendment to Cliff\u2019s post. He thinks he\u2019s talking about progressivism versus conservativism, but he isn\u2019t. A conservative happy with his little cabin and occasional hunting excursions, and a progressive happy with her little SoHo flat and occasional poetry slams, are psychologically pretty similar. So are a liberal who abandons a cushy life to work as a community organizer in the inner city and fight poverty, and a conservative who abandons a cushy life to serve as an infantryman in Afghanistan to fight terrorism. The distinction Cliff is trying to get at here isn\u2019t left-right. It\u2019s activist versus passivist.</p>\n<p>As part of a movement <a href=\"https://pdf.yt/d/-jQQX6XY9dU0LN4G\">recently deemed postpolitical</a>, I have to admit I fall more on the passivist side of the spectrum \u2013 at least this particular conception of it. I talk about politics when they interest me or when I enjoy doing so, and I feel an obligation not to actively make things worse. But I don\u2019t feel like I need to talk nonstop about whatever the designated Issue is until it distresses me and my readers both.</p>\n<p>I\u2019ve heard people give lots of reasons for not wanting to get into politics. For some, hearing about all the evils of the world makes them want to curl into a ball and cry for hours. Still others feel deep personal guilt about anything they hear \u2013 an almost psychotic belief that if people are being hurt anywhere in the world, it\u2019s their fault for not preventing it. A few are chronically uncertain about which side to take and worried that anything they do will cause more harm than good. A couple have traumatic experiences that make them leery of affiliating with a particular side \u2013 did you know the prosecutor in the Ferguson case was the son of a police officer who was killed by a black suspect? And still others are perfectly innocent and just want to reblog kitten pictures.</p>\n<p>Pervocracy admits this, and puts it better than I do:</p>\n<blockquote><p>But god, it\u2019s uncomfortable.  It\u2019s intentionally uncomfortable\u2014it\u2019s all about getting angry at injustice and questioning the rightness of your own actions and being sad so many people still live such painful lives.  Instead of looking at your cabin and declaring \u201cI shall name it\u2026CLIFFORDSON MANOR,\u201d you need to look at your cabin and recognize that a long series of brutal injustices are responsible for the fact that you have a white-collar job that lets you buy a big useless house in the woods while the original owners of the land have been murdered or forced off it. And you\u2019re never good enough.  You can be good\u2014certainly you get major points for charity and activism and fighting the good fight\u2014but not good enough.  No matter what you do, you\u2019re still participating in plenty of corrupt systems that enforce oppression.  Short of bringing about a total revolution of everything, your work will never be done, you\u2019ll never be good enough.</p></blockquote>\n<p>That seems about right. Pervocracy ends up with discomfort, and I\u2019m in about the same place. But other, less stable people end up with self-loathing. Still other people go further than that, into Calvinist-style \u201cperhaps I am a despicable worm unworthy of existence\u201d. <a href=\"http://moteinthedark.tumblr.com/post/104382718166/politics-that-feel-good\">moteinthedark\u2019s reply to Pervocracy</a> gives me the impression that she struggles with this sometime. For these people, abstaining from politics is the only coping tool they have.</p>\n<p>But the counterargument is <i>still</i> that you\u2019ve got a lot of chutzpah playing that card when people in Peshawar or Ferguson or Iraq don\u2019t have access to this coping tool. You can\u2019t just bring in a doctor\u2019s note and say \u201cAs per my psychiatrist, I have a mental health issue and am excused from experiencing concern for the less fortunate.\u201d</p>\n<p>One option is to deny the obligation. I am super sympathetic to this one. The <i>marginal</i> cost of my existence on the poor and suffering of the world is zero. In fact, it\u2019s probably positive. My economic activity consists mostly of treating patients, buying products, and paying taxes. The first treats the poor\u2019s illnesses, the second creates jobs, and the third pays for government assistance programs. Exactly what am I supposed to be apologizing for here? I may benefit from the genocide of the Indians in that I live on land that was formerly Indian-occupied. But I also benefit from the asteroid that killed the dinosaurs, in that I live on land that was formerly dinosaur-occupied. I don\u2019t feel like I\u2019m complicit in the asteroid strike; why should I feel complicit in the genocide?</p>\n<p>I have no objection to people who say this. The problem with it isn\u2019t philosophical, it\u2019s emotional. For <i>most people</i> it won\u2019t be enough. The old saying goes \u201cyou can\u2019t reason yourself out of something you didn\u2019t reason yourself into to begin with\u201d, and the idea that secure and prosperous people need to \u201cgive something back\u201d is a lot older than accusations of \u201cbeing complicit in structures of oppression\u201d. It\u2019s probably older than the Bible. People feel a deep-seated need to show that they understand how lucky they are and help those less fortunate than themselves.</p>\n<p>So what do we do with the argument that we are morally obligated to be political activists, possibly by reblogging everything about Ferguson that crosses our news feed?</p>\n<p><b id=\"II_\">II.</b></p>\n<p>We ask: <i>why the heck are we privileging that particular subsection of the category \u201cimproving the world\u201d?</i></p>\n<p>Pervocracy says that \u201cshort of bringing about a total revolution of everything, your work will never be done, you\u2019ll never be good enough.\u201d But he is overly optimistic. Has your total revolution of everything eliminated ischaemic heart disease? Cured malaria? Kept elderly people out of nursing homes? No? Then you haven\u2019t discharged your <a href=\"http://slatestarcodex.com/2014/05/10/infinite-debt/\">infinite debt</a> yet!</p>\n<p>Being a perfect person doesn\u2019t just mean participating in every hashtag campaign you hear about. It means spending all your time at soup kitchens, becoming vegan, donating everything you have to charity, calling your grandmother up every week, and marrying Third World refugees who need visas rather than your one true love. </p>\n<p>And not all of these things are equally important.</p>\n<p>Five million people participated in the #BlackLivesMatter Twitter campaign. Suppose that solely as a result of this campaign, no currently-serving police officer ever harms an unarmed black person ever again. That\u2019s 100 lives saved per year times let\u2019s say twenty years left in the average officer\u2019s career, for a total of 2000 lives saved, or 1/2500th of a life saved per campaign participant. By coincidence, 1/2500th of a life saved happens to be what you get when you donate $1 to the Against Malaria Foundation. The round-trip bus fare people used to make it to their #BlackLivesMatter protests could have saved ten times as many black lives as the protests themselves, <i>even given completely ridiculous overestimates of the protests\u2019 efficacy</i>.</p>\n<p>The moral of the story is that if you feel an obligation to give back to the world, participating in activist politics is one of the worst possible ways to do it. Giving even a tiny amount of money to charity is hundreds or even thousands of times more effective than almost any political action you can take. Even if you\u2019re absolutely convinced a certain political issue is the most important thing in the world, you\u2019ll effect more change by donating money to nonprofits lobbying about it than you will be reblogging anything. </p>\n<p>There is <i>no reason</i> that politics would even <i>come to the attention</i> of an unbiased person trying to \u201cbreak out of their bubble of privilege\u201d or \u201chelp people who are afraid of going outside of their house\u201d. Anybody saying that people who want to do good need to spread their political cause is about as credible as a televangelist saying that people who want to do good need to give them money to buy a new headquarters. It\u2019s possible that televangelists having beautiful headquarters might be <i>slightly</i> better than them having hideous headquarters, but it\u2019s not the first thing a reasonable person trying to improve the world would think of.</p>\n<p></p><center><img src=\"http://slatestarcodex.com/blog_images/sschits.png\"><p></p>\n<p><i>Average number of hits for posts on this blog, by topic</i></p></center><p></p>\n<p>Nobody cares about charity. Everybody cares about politics, especially race and gender. Just as televangelists who are obsessed with moving to a sweeter pad may come to think that donating to their building fund is the one true test of a decent human being, so our universal obsession with politics, race, and gender incites people to make convincing arguments that taking and spreading the right position on those issues is the one true test of a decent human being.</p>\n<p>So now we have an angle of attack against our original question. \u201cAm I a bad person for not caring more about politics?\u201d Well, every other way of doing good, especially charity, is more important than politics. So this question is strictly superseded by \u201cAm I a bad person for not engaging in every other way of doing good, especially charity?\u201d And then once we answer that, we can ask \u201cAlso, however much sin I have for not engaging in charity, should we add another mass of sin, about 1% as large, for my additional failure to engage in politics?\u201d</p>\n<p>And Cliff Pervocracy\u2019s concern of \u201cEven if I do a lot of politics, am I still a bad person for not doing <i>all</i> the politics?\u201d is superseded by \u201cEven if I give a lot of charity, am I a bad person for not doing <i>all</i> the charity? And then a bad person in an additional way, about 1% as large, for not doing all the politics as well?\u201d</p>\n<p>There\u2019s no good answer to this question. If you want to feel anxiety and self-loathing for not giving 100% of your income, minus living expenses, to charity, then no one can stop you. </p>\n<p>I, on the other hand, would prefer to call that \u201cnot being perfect\u201d. I would prefer to say that if you feel like you will live in anxiety and self-loathing until you have given a certain amount of money to charity, you should make that certain amount ten percent.</p>\n<p>Why ten percent?</p>\n<p>It\u2019s ten percent because that\u2019s the standard decreed by <a href=\"https://www.givingwhatwecan.org/\">Giving What We Can</a> and the effective altruist community. Why should we believe their standard? I think we should believe it because if we reject it in favor of \u201cNo, you are a bad person unless you give <i>all</i> of it,\u201d then everyone will just sit around feeling very guilty and doing nothing. But if we very clearly say \u201cYou have discharged your moral duty if you give ten percent or more,\u201d then many people will give ten percent or more. The most important thing is having a Schelling point, and ten percent is nice, round, <a href=\"http://en.wikipedia.org/wiki/Tithe\">divinely ordained</a>, and \u2013 crucially \u2013 the Schelling point upon which we have already settled. It is an <i>active</i> Schelling point. If you give ten percent, you can have your name on a nice list and get access to a secret forum on the Giving What We Can site which is actually pretty boring.</p>\n<p>It\u2019s ten percent because <a href=\"http://slatestarcodex.com/2014/11/21/the-categories-were-made-for-man-not-man-for-the-categories/\">definitions were made for Man, not Man for definitions</a>, and if we define \u201cgood person\u201d in a way such that everyone is sitting around miserable because they can\u2019t reach an unobtainable standard, we are stupid definition-makers. If we are smart definition-makers, we will define it in whichever way which makes it the most effective tool to convince people to give at least that much. </p>\n<p>Finally, it\u2019s ten percent because if you believe in <a href=\"http://slatestarcodex.com/2014/05/16/you-kant-dismiss-universalizability/\">something like universalizability</a> as a foundation for morality, a world in which everybody gives ten percent of their income to charity is a world where about <a href=\"http://www.bbc.com/news/magazine-17512040\">seven trillion dollars</a> go to charity a year. Solving global poverty forever is estimated to cost about $100 billion a year for the couple-decade length of the project. That\u2019s <i>about two percent</i> of the money that would suddenly become available. If charity got seven trillion dollars a year, <i>the first year</i> would give us enough to solve global poverty, eliminate all treatable diseases, fund research into the untreatable ones for approximately the next forever, educate anybody who needs educating, feed anybody who needs feeding, fund an unparalleled renaissance in the arts, permamently save every rainforest in the world, and have enough left over to launch five or six different manned missions to Mars. That would be the <i>first year</i>. Goodness only knows what would happen in Year 2.</p>\n<p>(by contrast, if everybody in the world retweeted the latest hashtag campaign, Twitter would break.)</p>\n<p>Charity is in some sense the perfect unincentivized action. If you think the most important thing to do is to cure malaria, then a charitable donation is deliberately throwing the power of your brain and muscle behind the cause of curing malaria. If, <a href=\"http://slatestarcodex.com/2014/07/30/meditations-on-moloch/\">as I\u2019ve argued</a>, the reason we can\u2019t solve world poverty and disease and so on is the capture of our financial resources by the undirected dance of incentives, then what better way to fight back than by saying \u201cThanks but no thanks, I\u2019m taking this abstract representation of my resources and using it <i>exactly</i> how I think it should most be used\u201d?</p>\n<p>If you give 10% per year, you have done your part in making that world a reality. You can honestly say \u201cWell, it\u2019s not my fault that everyone <i>else</i> is still dragging their feet.\u201d</p>\n<p><b id=\"III_\">III.</b></p>\n<p>Once the level is fixed at ten percent, we get a better idea how to answer the original question: \u201cIf I want to be a good person who gives back to the community, but I am triggered by politics, what do I do?\u201d You do good in a way that doesn\u2019t trigger you. Another good thing about having less than 100% obligation is that it gives you the opportunity to budget and trade-off. If you make $30,000 and you accept 10% as a good standard you want to live up to, you can either donate $3000 to charity, or participate in political protests until your number of lives or dollars or DALYs saved is equivalent to that. </p>\n<p>Nobody is perfect. This gives us license not to be perfect either. Instead of aiming for an impossible goal, falling short, and not doing anything at all, we set an arbitrary but achievable goal designed to encourage the most people to do as much as possible. That goal is ten percent.</p>\n<p>Everything is commensurable. This gives us license to determine exactly how we fulfill that ten percent goal. Some people are triggered and terrified by politics. Other people are too sick to volunteer. Still others are poor and cannot give very much money. But money is a constant reminder that everything goes into the same pot, and that you can fulfill obligations in multiple equivalent ways. Some people will not be able to give ten percent of their income without excessive misery, but I bet thinking about their contribution in terms of a fungible good will help them decide how much volunteering or activism they need to reach the equivalent.</p>\n<p>Cliff Pervocracy says \u201cYour work will never be done, you\u2019ll never be good enough.\u201d This seems like a recipe for \u2013 at best \u2013 undirected misery, stewing in self-loathing, and total defenselessness against the first <a href=\"http://slatestarcodex.com/2014/12/17/the-toxoplasma-of-rage/\">parasitic meme</a> to come along and tell them to engage in the latest conflict or else they\u2019re trash. At worst, it autocatalyzes an opposition of egoists who laugh at the idea of helping others.</p>\n<p>On the other hand, Jesus says \u201cTake my yoke upon you\u2026and you will find rest for your souls. For my yoke is easy and my burden is light.\u201d This seems like a recipe for getting people to say \u201cOkay, I\u2019ll take your yoke upon me! Thanks for the offer!\u201d</p>\n<p>Persian poet Omar Khayyam, considering the conflict between the strict laws of Islam and his own desire to enjoy life, settles upon the following rule:</p>\n<blockquote><p>Heed not the Sunna, nor the law divine;<br>\nIf to the poor their portion you assign,<br>\nAnd never injure one, nor yet abuse,<br>\nI guarantee you heaven, as well as wine!</p></blockquote>\n<p>I\u2019m not saying that donating 10% of your money to charity makes you a great person who is therefore freed of every other moral obligation. I\u2019m not saying that anyone who chooses not to do it is therefore a bad person. I\u2019m just saying that if you feel a need to discharge some feeling of a moral demand upon you to help others, and you want to do it intelligently, it beats most of the alternatives.</p>\n<p>This month is the <a href=\"http://lesswrong.com/r/discussion/lw/lek/giving_what_we_can_new_year_drive/\">membership drive</a> for <a href=\"https://www.givingwhatwecan.org/\">Giving What We Can</a>, the organization of people who have promised to give 10% of their earnings to charity. I am a member. Ozy is an aspiring member who plans to join once they are making a salary. Many of the commenters here are members \u2013 I recognize for example Taymon Beal\u2019s name on their list. Some well-known moral philosophers like Peter Singer and Derek Parfit are members. Seven hundred other people are also members.</p>\n<p>I would recommend giving them a look.</p>", "sections": [{"title": "I.", "anchor": "I_", "level": 1}, {"title": "II.", "anchor": "II_", "level": 1}, {"title": "III.", "anchor": "III_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MHarArYfjuDyaJwFo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2014-12-19T05:00:06.000Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-19T05:39:49.278Z", "modifiedAt": null, "url": null, "title": "Munchkining for Fun and Profit, Ideas, Experience, Successes, Failures", "slug": "munchkining-for-fun-and-profit-ideas-experience-successes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:02.737Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Username", "createdAt": "2010-09-04T16:10:50.550Z", "isAdmin": false, "displayName": "Username"}, "userId": "8iY88evtFECPgCs3s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uMTdbajSxYQDet6uT/munchkining-for-fun-and-profit-ideas-experience-successes", "pageUrlRelative": "/posts/uMTdbajSxYQDet6uT/munchkining-for-fun-and-profit-ideas-experience-successes", "linkUrl": "https://www.lesswrong.com/posts/uMTdbajSxYQDet6uT/munchkining-for-fun-and-profit-ideas-experience-successes", "postedAtFormatted": "Friday, December 19th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Munchkining%20for%20Fun%20and%20Profit%2C%20Ideas%2C%20Experience%2C%20Successes%2C%20Failures&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMunchkining%20for%20Fun%20and%20Profit%2C%20Ideas%2C%20Experience%2C%20Successes%2C%20Failures%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuMTdbajSxYQDet6uT%2Fmunchkining-for-fun-and-profit-ideas-experience-successes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Munchkining%20for%20Fun%20and%20Profit%2C%20Ideas%2C%20Experience%2C%20Successes%2C%20Failures%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuMTdbajSxYQDet6uT%2Fmunchkining-for-fun-and-profit-ideas-experience-successes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuMTdbajSxYQDet6uT%2Fmunchkining-for-fun-and-profit-ideas-experience-successes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 89, "htmlBody": "<p>A munchkin is someone who follows the letter of the rules of a game while breaking their spirit, someone who wins by exploiting possibilities that others don't see, reject as impossible or unsporting, or just don't believe can possibly work.</p>\n<p>If you have done something that everyone around you thought would not work, something that people around you didn't do <em>after they saw it work</em>, please share your experiences. If you tried something and failed or have ideas you want to hear critique of, likewise please share those with us.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uMTdbajSxYQDet6uT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 2.282424878564706e-06, "legacy": true, "legacyId": "27753", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-19T15:12:34.102Z", "modifiedAt": null, "url": null, "title": "Letting it go: when you shouldn't respond to someone who is wrong", "slug": "letting-it-go-when-you-shouldn-t-respond-to-someone-who-is", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:00.501Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "sP8rbunRWBjQA3pyQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RmzP5dedZrmQ5BBhG/letting-it-go-when-you-shouldn-t-respond-to-someone-who-is", "pageUrlRelative": "/posts/RmzP5dedZrmQ5BBhG/letting-it-go-when-you-shouldn-t-respond-to-someone-who-is", "linkUrl": "https://www.lesswrong.com/posts/RmzP5dedZrmQ5BBhG/letting-it-go-when-you-shouldn-t-respond-to-someone-who-is", "postedAtFormatted": "Friday, December 19th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Letting%20it%20go%3A%20when%20you%20shouldn't%20respond%20to%20someone%20who%20is%20wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALetting%20it%20go%3A%20when%20you%20shouldn't%20respond%20to%20someone%20who%20is%20wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRmzP5dedZrmQ5BBhG%2Fletting-it-go-when-you-shouldn-t-respond-to-someone-who-is%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Letting%20it%20go%3A%20when%20you%20shouldn't%20respond%20to%20someone%20who%20is%20wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRmzP5dedZrmQ5BBhG%2Fletting-it-go-when-you-shouldn-t-respond-to-someone-who-is", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRmzP5dedZrmQ5BBhG%2Fletting-it-go-when-you-shouldn-t-respond-to-someone-who-is", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 968, "htmlBody": "<p>I'm requesting that people follow a simple guide when determining whether to respond to a post. This simple algorithm should raise the quality of discussion here.</p>\n<ul>\n<li>If you care about the answer to a question, you will research it.</li>\n<li>If you don't care about the answer, don't waste people's time by arguing about it, even if someone's post seems wrong.</li>\n<li>If you don't care and still want to argue, do the research.</li>\n</ul>\n<p>Why should you follow these rules?<br /><br /><strong>Fairness.</strong><br /><br />It takes very little effort to post a contradictory assertion. You just have to skim a post, find an assertion (preferably one that isn't followed or preceded immediately by paragraphs of backing evidence, but that's an optional filter), and craft a sentence indicating that that assertion is wrong or flawed. Humans can do this almost by instinct. It's magical.<br /><br />Refuting a contradiction takes effort. I typically spend at least five minutes of research and five minutes of writing to make a reply refuting a bare contradiction when I have already studied the issue thoroughly and know which sources I want to use. I go to this effort because I care about these statements I've made and because I care about what other people believe. I want to craft a reply that is sufficiently thorough to be convincing. And, I'll admit, I want to crush my opponents with my impeccable data. I'm a bit petty sometimes.<br /><br />If I haven't researched the issue well -- if my sources are second-hand, or if I'm using personal experience -- I might spend two hours researching a simple topic and ten to fifteen minutes creating a response. This is a fair amount of time invested. I don't mind doing it; it makes me learn more. It's a time investment, though.<br /><br />So, let's compare. Half a second of thought and two minutes to craft a reply containing nothing but a contradiction, versus two hours of unpaid research. This is a huge imbalance. Let's address this by trying to research people's claims before posting a contradiction, shall we?<br /><br /><strong>Trust.</strong><br /><br />You are convinced that someone's argument is flawed. This means that they have not looked into the issue sufficiently, or their reasoning is wrong. As a result, you can't trust their argument to be a good example of arguments for their position. You can look for flaws of reasoning, which is easy. You can look for cases where their data is misleading or wrong -- but that requires actual effort. You have to either find a consensus in the relevant authorities that differs from what this other person is saying, or you have to look at their specific data in some detail. That means you have to do some research.<br /><br /><strong>Community.</strong><br /><br />If you want people to stick around, and you're brusquely denying their points until they do hours of work to prove them, they're going to view lesswrong as a source of stress. This is not likely to encourage them to return. If you do the legwork yourself, you seem knowledgeable. If you're careful with your phrasing, you can also seem helpful. (I expect that to be the tough part.) This reduces the impact of having someone contradict you.</p>\n<p><strong>Advancing the argument.</strong><br /><br />From what I've seen, the flow of argument goes something like: argument &rarr; contradiction of two or three claims &rarr; proof of said claims &rarr; criticism of proof &rarr; rebuttal &rarr; acceptance, analysis of argument. By doing some research on your own rather than immediately posting a contradiction, you are more quickly getting to the meat of the issue. You aren't as likely to get sidetracked. You can say things like: \"This premise seems a bit contentious, but it's a widely supported minority opinion for good reasons. Let's take it as read for now and see if your conclusions are supported, and we can come back to it if we need to.\"<br /><br /><strong>Bonus: \"You're contradicting yourself.\"</strong><br /><br />Spoiler: they're not contradicting themselves.<br /><br />We read here a lot about how people's brains fail them in myriad interesting ways. Compartmentalization is one of them. People's beliefs can contradict each other. But people tend to compartmentalize between different contexts, not within the same context.<br /><br />One post or article probably doesn't involve someone using two different compartments. What looks like a contradiction is more likely a nuance that you don't understand or didn't bother to read, or a rhetorical device like hyperbole. (I've seen someone here say I'm contradicting myself when I said \"This group doesn't experience this as often, and when they do experience it, it's different.\" Apparently \"not as often\" is the same as \"never\"?) Read over the post again. Look for rhetorical devices. Look for something similar that would make sense. If you're uncertain, try to express that similar argument to the other person and ask if that's what they mean.<br /><br />If you still haven't found anything besides a bare contradiction, a flat assertion that they're contradicting themselves is a bad way to proceed. If you're wrong and they aren't contradicting themselves, they will be annoyed at you. That's bad enough. They will have to watch everything they say very carefully so that they do not use rhetorical devices or idioms or anything that you could possibly lawyer into a contradiction. This takes a lot more effort than simply writing an argument in common modes of speech, as everyone who's worked on a journal article knows.<br /><br />Arguing with you is not worth that amount of effort. Don't make it harder than it needs to be.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RmzP5dedZrmQ5BBhG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 11, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "27754", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-19T17:04:18.235Z", "modifiedAt": null, "url": null, "title": "Post Resource Request", "slug": "post-resource-request", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:44.956Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Minds_Eye", "createdAt": "2013-11-21T18:02:19.971Z", "isAdmin": false, "displayName": "Minds_Eye"}, "userId": "eLSSTrxtHA8LaWr9g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eYueBQwvTJ2ngHMvq/post-resource-request", "pageUrlRelative": "/posts/eYueBQwvTJ2ngHMvq/post-resource-request", "linkUrl": "https://www.lesswrong.com/posts/eYueBQwvTJ2ngHMvq/post-resource-request", "postedAtFormatted": "Friday, December 19th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Post%20Resource%20Request&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APost%20Resource%20Request%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYueBQwvTJ2ngHMvq%2Fpost-resource-request%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Post%20Resource%20Request%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYueBQwvTJ2ngHMvq%2Fpost-resource-request", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYueBQwvTJ2ngHMvq%2Fpost-resource-request", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 109, "htmlBody": "<p>After having viewed a recent <a title=\"Understanding Agency\" href=\"/lw/lej/understanding_agency/\" target=\"_self\">post</a>&nbsp;by Gworley I noticed that the material was deliberately opaque*. &nbsp;It's not as complicated as it seems, and should be able to be taught to people at lower than \"Level 4\" on Kegan's <a href=\"http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/\" target=\"_blank\">Constructive Developmental Theory</a>. &nbsp;The only serious block I saw was the ridiculous gap in inferential distance.&nbsp;<br />&nbsp;<br />With that in mind I was hoping someone might have recommendations on even tangentially related material as what I have now appears to be insufficient. &nbsp;(Simplifying CDT appears to be manageable, but not particularly useful without further material like&nbsp;<a href=\"http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/\" target=\"_blank\">Kantor's Four Player Model</a>&nbsp;and <a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\" target=\"_blank\">Subject-Object Notation</a>.)</p>\r\n<p>*edit: Not Gworley's,&nbsp;it was&nbsp;Kegan's material that&nbsp;was opaque.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eYueBQwvTJ2ngHMvq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.2839741113027587e-06, "legacy": true, "legacyId": "27755", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uNbR8WuahQrELCHgW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-19T17:27:05.198Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-7", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PuFravaDSfS6do3K6/weekly-lw-meetups-7", "pageUrlRelative": "/posts/PuFravaDSfS6do3K6/weekly-lw-meetups-7", "linkUrl": "https://www.lesswrong.com/posts/PuFravaDSfS6do3K6/weekly-lw-meetups-7", "postedAtFormatted": "Friday, December 19th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPuFravaDSfS6do3K6%2Fweekly-lw-meetups-7%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPuFravaDSfS6do3K6%2Fweekly-lw-meetups-7", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPuFravaDSfS6do3K6%2Fweekly-lw-meetups-7", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 588, "htmlBody": "<p><strong>This summary was posted to LW Main on December 12th. The following week's summary is <a href=\"/lw/lf0/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/17w\">Atlanta December Meetup - Game Night!:&nbsp;<span class=\"date\">27 December 2014 07:00AM</span></a></li>\n<li><a href=\"/meetups/17j\">Australia onling hangout:&nbsp;<span class=\"date\">14 December 2014 07:00PM</span></a></li>\n<li><a href=\"/meetups/17o\">Copenhagen: December Meetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/160\">East Coast Solstice Megameetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/15w\">European Community Weekend 2015:&nbsp;<span class=\"date\">12 June 2015 12:00PM</span></a></li>\n<li><a href=\"/meetups/17i\">Munich Meetup in December:&nbsp;<span class=\"date\">13 December 2014 12:00PM</span></a></li>\n<li><a href=\"/meetups/17x\">Saint-Petersburg Meetup :&nbsp;<span class=\"date\">13 December 2014 04:00PM</span></a></li>\n<li><a href=\"/meetups/17a\">Utrecht: Rationality Games:&nbsp;<span class=\"date\">14 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17c\">Utrecht: a critique of effective altruism:&nbsp;<span class=\"date\">04 January 2015 02:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX - Caffe Medici:&nbsp;<span class=\"date\">13 December 2025 01:30PM</span></a></li>\n<li><a href=\"/meetups/17t\">Brussels - Hope &amp; Self-improvement:&nbsp;<span class=\"date\">13 December 2014 01:00PM</span></a></li>\n<li><a href=\"/meetups/17m\">Canberra: End of year party:&nbsp;<span class=\"date\">13 December 2014 06:00PM</span></a></li>\n<li><a href=\"/meetups/17u\">Moscow social meetup: codename \"Order of Infrared Viola\":&nbsp;<span class=\"date\">14 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/16r\">Seattle Secular Solstice:&nbsp;<span class=\"date\">13 December 2014 05:30PM</span></a></li>\n<li><a href=\"/meetups/17r\">Sydney Summer Solstice:&nbsp;<span class=\"date\">21 December 2014 06:00PM</span></a></li>\n<li><a href=\"/meetups/16y\">[Vienna] Rationality Weekend Vienna:&nbsp;<span class=\"date\">13 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/17y\">Washington, D.C.: Tetlock's \"Expert Political Judgment\":&nbsp;<span class=\"date\">14 December 2014 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\">Berlin</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Boston.2C_MA\">Boston</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Brussels.2C_Belgium\">Brussels</a></strong><strong>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Buffalo.2C_NY\">Buffalo</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Canberra\">Canberra</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Columbus.2C_OH\">Columbus</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Moscow.2C_Russia\">Moscow</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Philadelphia.2C_PA\">Philadelphia</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Research_Triangle.2C_NC_.28Raleigh.2FDurham.2FChapel_Hill.29\">Research Triangle NC</a>,</strong><strong>&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Sydney\">Sydney</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a></strong><strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington DC</strong></a></strong>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview is posted on the front page every Friday. These are an attempt to collect information on all the meetups happening in upcoming weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll also have the benefit of having your meetup mentioned in a weekly overview. These overview posts are moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cincinnati</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cleveland</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> </strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tel_Aviv.2C_Israel\">Tel Aviv</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Warsaw.2C_Poland\">Warsaw</a></strong><strong>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PuFravaDSfS6do3K6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 2.2840257087845128e-06, "legacy": true, "legacyId": "27714", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Cf29E5WMjDb3MdKPb", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-19T17:34:36.217Z", "modifiedAt": null, "url": null, "title": "Velocity of behavioral evolution", "slug": "velocity-of-behavioral-evolution", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:49.475Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ABFTS3FPn5YsjkHLb/velocity-of-behavioral-evolution", "pageUrlRelative": "/posts/ABFTS3FPn5YsjkHLb/velocity-of-behavioral-evolution", "linkUrl": "https://www.lesswrong.com/posts/ABFTS3FPn5YsjkHLb/velocity-of-behavioral-evolution", "postedAtFormatted": "Friday, December 19th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Velocity%20of%20behavioral%20evolution&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVelocity%20of%20behavioral%20evolution%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FABFTS3FPn5YsjkHLb%2Fvelocity-of-behavioral-evolution%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Velocity%20of%20behavioral%20evolution%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FABFTS3FPn5YsjkHLb%2Fvelocity-of-behavioral-evolution", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FABFTS3FPn5YsjkHLb%2Fvelocity-of-behavioral-evolution", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 29, "htmlBody": "<p>This suggested a major update on the velocity of behavioral trait evolution.</p>\n<p>Basically mice transmitted fear of cherry smell reliably into the very next generation (via epigenetics).&nbsp;</p>\n<p>www.newscientist.com/article/dn24677-fear-of-a-smell-can-be-passed-down-several-generations.html#.VJRgr8ADo</p>\n<p>This seems pretty important.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ABFTS3FPn5YsjkHLb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 2.284042733381367e-06, "legacy": true, "legacyId": "27757", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-20T12:28:50.420Z", "modifiedAt": null, "url": null, "title": "[Link] The Dominant Life Form In the Cosmos Is Probably Superintelligent Robots", "slug": "link-the-dominant-life-form-in-the-cosmos-is-probably", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:04.086Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gunnar_Zarncke", "createdAt": "2013-07-20T15:40:42.323Z", "isAdmin": false, "displayName": "Gunnar_Zarncke"}, "userId": "qmJFRN7jitjPsuF3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6XcYW8jMfxj5C5y8J/link-the-dominant-life-form-in-the-cosmos-is-probably", "pageUrlRelative": "/posts/6XcYW8jMfxj5C5y8J/link-the-dominant-life-form-in-the-cosmos-is-probably", "linkUrl": "https://www.lesswrong.com/posts/6XcYW8jMfxj5C5y8J/link-the-dominant-life-form-in-the-cosmos-is-probably", "postedAtFormatted": "Saturday, December 20th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20The%20Dominant%20Life%20Form%20In%20the%20Cosmos%20Is%20Probably%20Superintelligent%20Robots&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20The%20Dominant%20Life%20Form%20In%20the%20Cosmos%20Is%20Probably%20Superintelligent%20Robots%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6XcYW8jMfxj5C5y8J%2Flink-the-dominant-life-form-in-the-cosmos-is-probably%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20The%20Dominant%20Life%20Form%20In%20the%20Cosmos%20Is%20Probably%20Superintelligent%20Robots%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6XcYW8jMfxj5C5y8J%2Flink-the-dominant-life-form-in-the-cosmos-is-probably", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6XcYW8jMfxj5C5y8J%2Flink-the-dominant-life-form-in-the-cosmos-is-probably", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>An <a href=\"http://motherboard.vice.com/read/the-dominant-life-form-in-the-cosmos-is-probably-superintelligent-robots\">Article on Motherboard</a>&nbsp;reports about &nbsp;<a href=\"http://schneiderwebsite.com/Susan_Schneiders_Website/Research_files/12%20Schneider%20Newest-Alien%20Minds_1.pdf\">Alien Minds by Susan Schneider</a>&nbsp;who claiThe Dominant Life Form In the Cosmos Is Probably Superintelligent Robots. The article is crosslinked to other posts about superintelligence and at the end discusses the question why these alien robots leave us along. The arguments puts forth on this don't convince me though.&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6XcYW8jMfxj5C5y8J", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 2.2866141592947104e-06, "legacy": true, "legacyId": "27758", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-21T11:37:03.333Z", "modifiedAt": null, "url": null, "title": "Signalling with T-Shirt slogans ", "slug": "signalling-with-t-shirt-slogans", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:02.293Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gunnar_Zarncke", "createdAt": "2013-07-20T15:40:42.323Z", "isAdmin": false, "displayName": "Gunnar_Zarncke"}, "userId": "qmJFRN7jitjPsuF3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pHSrmZTXtqBYM6ojD/signalling-with-t-shirt-slogans", "pageUrlRelative": "/posts/pHSrmZTXtqBYM6ojD/signalling-with-t-shirt-slogans", "linkUrl": "https://www.lesswrong.com/posts/pHSrmZTXtqBYM6ojD/signalling-with-t-shirt-slogans", "postedAtFormatted": "Sunday, December 21st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Signalling%20with%20T-Shirt%20slogans%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASignalling%20with%20T-Shirt%20slogans%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpHSrmZTXtqBYM6ojD%2Fsignalling-with-t-shirt-slogans%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Signalling%20with%20T-Shirt%20slogans%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpHSrmZTXtqBYM6ojD%2Fsignalling-with-t-shirt-slogans", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpHSrmZTXtqBYM6ojD%2Fsignalling-with-t-shirt-slogans", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 533, "htmlBody": "<p>It kind of started when I got this T-shirt as a present two years ago:</p>\n<p><img src=\"http://asset-c.soup.io/asset/2383/7925_c710.jpeg\" alt=\"Don't Drink and Derive T-Shirt\" width=\"179\" height=\"233\" /></p>\n<p>It is not just a slogan that is quickly filtered out under the heading 'generic ad-like content'. It invites checking where the error is. It is kind of a challenge - at least for suitably minded persons. Exactly that kind of person I'd like to get in touch with more. This T-shirt signals: \"I'm a nerd and proud of it.\" And the positive feedback I got from this was part of the reason I chose to signal this more. Maybe you'd like to signal this too. Please remember the T-shirt alone will not do it. You still have to talk to people. For the introverted among us (me included) I recommend <a href=\"http://en.wikipedia.org/wiki/Active_listening\">active listening</a>.</p>\n<p>The remainder of this post lists some slogans I have tried, some I will likely try shortly and other related resources.</p>\n<p><a id=\"more\"></a>Obviously I'm not the only one using this signalling approach. T-shirt dealers have <a href=\"http://www.spreadshirt.de/nerd+math+geschenke#/list/nerd+math\">lots </a>of <a href=\"http://www.cafepress.de/+math+gifts\">these</a> in <a href=\"http://www.shirtcity.us/math-t-shirts?search=math\">stock</a>. Thus some I just ordered online. But the most effective shirt I 'designed' myself. It is a black shirt suitable for business purposes and such a shirt with a small slogal on it stands out. I chose</p>\n<blockquote>\n<p>That which can be</p>\n<p>destroyed by the</p>\n<p>truth should be.</p>\n<p>&mdash; P.C. Hodgell</p>\n</blockquote>\n<p>which I'm delighted to also find recommended by EY <a href=\"http://prettyrational.com/71/\">here</a>.</p>\n<div>One year ago <a href=\"http://intelligence.org/2013/10/12/miris-october-newsletter/\">MIRI</a> linked to&nbsp;<a href=\"http://rationalattire.com/ \">Rational Attire</a>&nbsp;but the store appears to be broken right now. And then there is <a href=\"http://prettyrational.com/\">Pretty Rational</a>&nbsp;which at least contains some promising slogans.</div>\n<div>\n<p>I also have this T-shirt about the <a href=\"http://wiki.lesswrong.com/wiki/Truth\">Map-Territory correspondence</a>:</p>\n<blockquote>\n<p>The sentence</p>\n<p>\"This T-shirt is black\"</p>\n<p>is true if</p>\n<p>This T-shirt is black.</p>\n<p>-- Tarski</p>\n</blockquote>\n<p>(I had this printed on a dark blue T-shirt thus adding a gradual truth aspect).</p>\n</div>\n<div>Other slogans of this type to be found on my T-shirts:</div>\n<p>&nbsp;</p>\n<ul>\n<li><a href=\"http://www.cafepress.de/mf/89779447/math-is-an-integral-part-of-my-life_tshirt?productId=1298713879\">Math is an integral part of my life.</a></li>\n<li><a href=\"http://www.cafepress.de/mf/65951443/litany-against-fear-black_tshirt?productId=626890220\">Bene Gesserit Litany Against Fear</a></li>\n</ul>\n<p>&nbsp;</p>\n<p>&nbsp;I plan to print more of my own design shortly. The next one will be</p>\n<blockquote>\n<p>\"Everyone generalizes</p>\n<p>from one example.</p>\n<p>At least, I do.\"</p>\n<p>-- Vlad Taltos</p>\n</blockquote>\n<p>You can find out more about this quote <a href=\"/lw/dr/generalizing_from_one_example/\">here</a>. What I like most about this one is that it is a bit self-deprecating which if combined with otherwise high status signalling (stance and gaze) I take comes across as approachable.</p>\n<p>More ideas I might or might not print:</p>\n<blockquote>\n<p><a href=\"http://www.keepcalm-o-matic.co.uk/p/the-enemys-gate-is-down-/\">The enemy's gate is down.</a></p>\n<p>-- Ender</p>\n</blockquote>\n<p>&nbsp;</p>\n<blockquote>\n<p>\"Two people acting&nbsp;</p>\n<p>&nbsp;rationally [] and with</p>\n<p>&nbsp;common knowledge&nbsp;</p>\n<p>&nbsp;[] cannot agree to&nbsp;</p>\n<p>&nbsp;disagree.\"</p>\n<p>&nbsp;-- R. J. Aumann</p>\n</blockquote>\n<p>&nbsp;</p>\n<blockquote>\n<p>\"When you have eliminated the</p>\n<p>impossible whatever remains</p>\n<p>however improbable must be the truth.\"</p>\n<p>-- Sherlock Holmes</p>\n</blockquote>\n<p>&nbsp;</p>\n<blockquote>\n<p>\"truth resists simplicity\"</p>\n<p>-- John Green</p>\n</blockquote>\n<p>&nbsp;</p>\n<blockquote>\n<p>\"Those who do not move,</p>\n<p>do not notice their chains.&rdquo;</p>\n<p>-- &nbsp;<a href=\"https://librarianshipwreck.wordpress.com/2013/07/06/reference-desk-unanswered-questions/\">Rosa Luxemburg, 1906</a></p>\n</blockquote>\n<div><br /></div>\n<blockquote>\n<p>World domination</p>\n<p>is such an ugly phrase.</p>\n<p>I prefer world optimisation.</p>\n<p>-- Harry Potter-Evans-Verres</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>So this is my personal approach to rationality signalling, but maybe you are inspired by it. You may use the comments to propose other such slogans, discuss these, question or laud the whole approach or propose other avenues for such signalling.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pHSrmZTXtqBYM6ojD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 14, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "27761", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["baTWMegR42PAsH9qJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-21T12:53:52.558Z", "modifiedAt": null, "url": null, "title": "Training Reflective Attention", "slug": "training-reflective-attention", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.573Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BrienneYudkowsky", "createdAt": "2013-05-13T00:07:08.935Z", "isAdmin": false, "displayName": "LoganStrohl"}, "userId": "uuYBzWLiixkbN3s7C", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FpLuKu8HCdRHKbcPn/training-reflective-attention", "pageUrlRelative": "/posts/FpLuKu8HCdRHKbcPn/training-reflective-attention", "linkUrl": "https://www.lesswrong.com/posts/FpLuKu8HCdRHKbcPn/training-reflective-attention", "postedAtFormatted": "Sunday, December 21st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Training%20Reflective%20Attention&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATraining%20Reflective%20Attention%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFpLuKu8HCdRHKbcPn%2Ftraining-reflective-attention%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Training%20Reflective%20Attention%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFpLuKu8HCdRHKbcPn%2Ftraining-reflective-attention", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFpLuKu8HCdRHKbcPn%2Ftraining-reflective-attention", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1224, "htmlBody": "<p><em>Crossposted at <a href=\"http://agentyduck.blogspot.com/2014/12/mindfulness.html\">Agenty Duck</a></em></p>\n<blockquote>And somewhere in the back of his mind was a small, small note of confusion, a sense of something wrong about that story; and it should have been a part of Harry's art to notice that tiny note, but he was distracted. For it is a sad rule that whenever you are most in need of your art as a rationalist, that is when you are most likely to forget it. &mdash;HPMOR, Ch. 3</blockquote>\n<p>A rationalist&rsquo;s art is most distant when it is most needed. Why is that?</p>\n<p>When I am very angry with my romantic partner, what I feel is anger. I don&rsquo;t feel the futility of throwing a tantrum, or the availability of other options like honest communication, or freewriting, or taking a deep breath. My attention is so narrowly focused on the object of my anger that I&rsquo;m likely not even aware that I&rsquo;m angry, let alone that my anger might be blinding me to my art.</p>\n<p>When her skills are most needed, a rationalist is lost in an unskillful state of mind. She doesn&rsquo;t recognize that it&rsquo;s happening, and she doesn&rsquo;t remember that she has prepared for it by learning and practicing appropriate techniques.</p>\n<p>I've designed and exercise that trains a skill I call reflective attention, and some call mindfulness. For me, it serves as an anchor in a stormy mind, or as a compass pointing always toward a mental state where my art is close at hand.</p>\n<p><a href=\"http://agentyduck.blogspot.com/2014/09/what-its-like-to-notice-things.html\">Noticing</a> that I am lost in an unskillful state of mind is a separate skill. But when I do happen to notice&mdash;when I feel that small, small note of confusion&mdash;reflective attention helps me find my way back. Instead of churning out even more pointless things to yell at my partner, it allows me to say, &ldquo;I am angry. I feel an impulse to yell. I notice my mind returning over and over to the memory that makes me more angry. I&rsquo;m finding it hard to concentrate. I am distracted. <em>I have a vague impression that I have prepared for this.</em>&rdquo; And awareness of that final thought allows me to ask, &ldquo;What have I trained myself to do when I feel this way?&rdquo;</p>\n<p>The goal of the following exercise is to practice entering reflective attention.</p>\n<p>It begins with an instruction to think of nothing. When you monitor yourself to make sure you&rsquo;re not having any thoughts, your attention ends up directed toward the beginnings of thoughts. Since the contents of consciousness are always changing, maintaining focus on the beginnings of thoughts prevents you from engaging for an extended period with any particular thought. It prevents you from getting &ldquo;lost in thought&rdquo;, or keeping attention focused on a thought without awareness of doing so. The point is not actually to be successful at thinking nothing, as that is impossible while conscious, but to notice what happens when you try.</p>\n<p>Keeping your focus on the constant changes in your stream of consciousness brings attention to your experience of awareness itself. Awareness of awareness is the anchor for attention. It lets you keep your bearings when you&rsquo;d otherwise be carried away by a current of thought or emotion.</p>\n<p>Once you&rsquo;re so familiar with the feeling of reflection that creating it is a primitive action, you can forget the introductory part, and jump straight to reflective attention whenever it occurs to you to do so.</p>\n<hr />\n<p>This will probably take around five minutes, but you can do it for much longer if you want to.</p>\n<p>Notice what your mind is doing right now. One thing it&rsquo;s doing is experiencing sensations of black and white as you read. What else are you experiencing? Are there words in your inner monologue? Are there emotions of any kind?</p>\n<p>Spend about thirty seconds trying not to think anything. When thirty seconds is up, stop trying not to think, and read on.</p>\n<p>.</p>\n<p>.</p>\n<p>.</p>\n<p>What&rsquo;s happening in your mind is constantly changing. Even when you were trying not to think, you probably noticed many times when the stillness would shift and some new thought would begin to emerge in conscious awareness.</p>\n<p>Turn your attention to those changes. When a new thought emerges in consciousness, see if you can notice the exact moment when it happens, becoming aware of what it feels like for that particular change to take place.</p>\n<p>If it helps at first, you can narrate your stream of consciousness in words: &ldquo;Now I&rsquo;m seeing the blue of the wall, now I&rsquo;m hearing the sound of a car, now I&rsquo;m feeling cold, now I&rsquo;m curious what time it is&hellip;&rdquo; You&rsquo;ll probably find that you can&rsquo;t narrate anywhere near quickly enough, in part because thoughts can happen in parallel, while speech is serial. Once narrating starts to become frustrating, stop slowing yourself down with words, and just silently observe your thoughts as they occur.</p>\n<p>If you&rsquo;re finding this overwhelming because there are too many thoughts, narrow your focus down to just your breathing, and try to precisely identify the experience of an exhale ending and an inhale beginning, of an inhale ending and an exhale beginning. Keep doing that until you feel comfortable with it, and then slowly expand your attention a little at a time: to other experiences associated with breathing, to non-breath-related bodily sensations, to non-tactile sensations from your environment, and finally to internal mental sensations like emotions.</p>\n<p>If you notice an impulse to focus your attention on a particular thought, following it and engaging with it&mdash;perhaps you notice you feel hungry, and in response you begin to focus your attention on planning lunch&mdash;instead of letting that impulse take over your attention, recognize it as yet another change in the activity of your mind. If you&rsquo;re narrating, say, &ldquo;now I&rsquo;m feeling an impulse to plan my lunch&rdquo;, and keep your focus broad enough to catch the next thought when it arises. If you realize that you&rsquo;ve already become lost in a particular thought, notice that realization itself as a new thought, and return to observing your stream of consciousness by noticing the next new thought that happens as well.</p>\n<p>.</p>\n<p>.</p>\n<p>.</p>\n<p>You might need to practice this many times before you get the hang of it. I suggest trying it for ten minutes to half an hour a day until you do.</p>\n<p>Once you feel like you can recognize the sensation of reflective attention and enter that state of mind reliably given time, begin to train for speed. Instead of setting a timer for fifteen minutes or however long you want to practice, set it to go off every minute for the first half of your practice, spending one minute in reflective attention, and one minute out. (Don&rsquo;t do this for all of your practice. You still need to practice maintenance.) When you can consistently arrive in reflective attention by the end of the minute, cut the intervals down to 45 seconds, then thirty, fifteen, and five.</p>\n<hr />\n<p>In real life, the suspicion that you may be lost in an unskillful state of mind will be quiet and fleeting. &ldquo;Quiet&rdquo; means you&rsquo;ll need to <a href=\"http://agentyduck.blogspot.com/2014/12/directing-attention.html\">learn to snap your attention</a> to the slightest hint of that feeling. For that, you&rsquo;ll need to train &ldquo;noticing&rdquo;. &ldquo;Fleeting&rdquo; means you&rsquo;ll need to be able to respond in less than five seconds. You&rsquo;ll need to begin the process in less than one second, even if it takes a little longer to fully arrive in reflective attention. For that, training for speed is crucial.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XSeiautCrZGaQ78fx": 3, "JHzjkFnQgsrRrucqQ": 1, "AiNyf5iwbpc7mehiX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FpLuKu8HCdRHKbcPn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 39, "extendedScore": null, "score": 0.000115, "legacy": true, "legacyId": "27760", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-21T22:20:23.257Z", "modifiedAt": null, "url": null, "title": "Meetup : Bratislava", "slug": "meetup-bratislava-5", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Viliam_Bur", "createdAt": "2011-08-23T08:46:37.137Z", "isAdmin": false, "displayName": "Viliam_Bur"}, "userId": "yaaPhHzrvrPf7je22", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r2PHNnsZCgpAugYJJ/meetup-bratislava-5", "pageUrlRelative": "/posts/r2PHNnsZCgpAugYJJ/meetup-bratislava-5", "linkUrl": "https://www.lesswrong.com/posts/r2PHNnsZCgpAugYJJ/meetup-bratislava-5", "postedAtFormatted": "Sunday, December 21st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Bratislava&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Bratislava%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2PHNnsZCgpAugYJJ%2Fmeetup-bratislava-5%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Bratislava%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2PHNnsZCgpAugYJJ%2Fmeetup-bratislava-5", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr2PHNnsZCgpAugYJJ%2Fmeetup-bratislava-5", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 27, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/184'>Bratislava</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 December 2014 06:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Laurinsk\u00e1 1, Bratislava</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Same place as previously: foxford.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/184'>Bratislava</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r2PHNnsZCgpAugYJJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.2912326997130534e-06, "legacy": true, "legacyId": "27762", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Bratislava\">Discussion article for the meetup : <a href=\"/meetups/184\">Bratislava</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 December 2014 06:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Laurinsk\u00e1 1, Bratislava</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Same place as previously: foxford.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Bratislava1\">Discussion article for the meetup : <a href=\"/meetups/184\">Bratislava</a></h2>", "sections": [{"title": "Discussion article for the meetup : Bratislava", "anchor": "Discussion_article_for_the_meetup___Bratislava", "level": 1}, {"title": "Discussion article for the meetup : Bratislava", "anchor": "Discussion_article_for_the_meetup___Bratislava1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-22T02:34:04.606Z", "modifiedAt": null, "url": null, "title": "Open thread, Dec. 22 - Dec. 28, 2014", "slug": "open-thread-dec-22-dec-28-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:06.504Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gJmbtzXWs6g6ZtdAA/open-thread-dec-22-dec-28-2014", "pageUrlRelative": "/posts/gJmbtzXWs6g6ZtdAA/open-thread-dec-22-dec-28-2014", "linkUrl": "https://www.lesswrong.com/posts/gJmbtzXWs6g6ZtdAA/open-thread-dec-22-dec-28-2014", "postedAtFormatted": "Monday, December 22nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20Dec.%2022%20-%20Dec.%2028%2C%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20Dec.%2022%20-%20Dec.%2028%2C%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJmbtzXWs6g6ZtdAA%2Fopen-thread-dec-22-dec-28-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20Dec.%2022%20-%20Dec.%2028%2C%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJmbtzXWs6g6ZtdAA%2Fopen-thread-dec-22-dec-28-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJmbtzXWs6g6ZtdAA%2Fopen-thread-dec-22-dec-28-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 70, "htmlBody": "<div id=\"entry_t3_le3\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px; font-weight: bold;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><a href=\"/r/discussion/lw/le3/open_thread_dec_15_dec_21_2014/\">Previous Open Thread</a></p>\n<hr />\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the <a href=\"/r/discussion/new/\" target=\"_blank\">list-of-threads page</a> before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">3.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should be posted in Discussion, and not Main.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">4.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gJmbtzXWs6g6ZtdAA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 2.2918105984490743e-06, "legacy": true, "legacyId": "27764", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 218, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["A8THjFzBhHZEjzw3D"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-22T05:40:37.235Z", "modifiedAt": null, "url": null, "title": "How to Read", "slug": "how-to-read", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:58.387Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ysu7pLmMRbnYgoFnk/how-to-read", "pageUrlRelative": "/posts/Ysu7pLmMRbnYgoFnk/how-to-read", "linkUrl": "https://www.lesswrong.com/posts/Ysu7pLmMRbnYgoFnk/how-to-read", "postedAtFormatted": "Monday, December 22nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Read&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Read%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYsu7pLmMRbnYgoFnk%2Fhow-to-read%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Read%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYsu7pLmMRbnYgoFnk%2Fhow-to-read", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYsu7pLmMRbnYgoFnk%2Fhow-to-read", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 729, "htmlBody": "<p><em>Part of my attempt to provide&nbsp;<a href=\"http://peterhurford.tumblr.com/post/105718667101/anecdotal-advice-the-authoritative-index\">a bunch of unsolicited, anecdotal evidence</a>&nbsp;that probably doesn't work for everyone.</em></p>\n<p><em>-</em></p>\n<p>Of course you already know how to read. &nbsp;But do you know how to read well?</p>\n<p>Many people who read a book want to read for entertainment. &nbsp;That's perfectly ok -- it seems like a great way to take a break and enjoy yourself. &nbsp;But many times people pick up a book with the intention to learn something important. &nbsp;If you're one of those people, it's important not to fool yourself, end up not learning anything, and just waste your time. &nbsp;That's how you end up reading for entertainment without realizing it.</p>\n<p>This was a big problem for me, and I realized I was wasting a lot of time when I otherwise could have been productively reading books.</p>\n<p>While I'm still not the best reader, here's how I think I solved that problem:</p>\n<p><strong>I'm choosy about which books I read.</strong>&nbsp;&nbsp;There are millions of books in the world. &nbsp;I can't read them all. &nbsp;So I have to be choosy. &nbsp;I think about what I stand to gain from the book. &nbsp;Is it worth my time to read it? &nbsp;Is the book actionable? &nbsp;I personally aim to read books that come to me in reviews, that from a skim of their table of contents look like they'll provide real value to me.</p>\n<p><strong>I think about what else I could be doing instead of reading.</strong>&nbsp;&nbsp;Reading is great, but in many cases experience can be a better teacher. &nbsp;Moreover, picking up some experience can help me understand and apply the lessons in books better. &nbsp;I try to adopt a \"doing-reading\" loop, where I read something, act upon it, then read another something, etc., continuing to iteratively improve in whatever skill I'm after. &nbsp;This also helps validate the advice of books.</p>\n<p><strong>I'm not afraid to ditch an&nbsp;underperforming&nbsp;book. &nbsp;</strong>If I don't like it, it's wasting my time, and it's time to move on.</p>\n<p><strong>I consider sources other than books.</strong>&nbsp;Books are often the best source of information on any topic, and are often higher quality because they're intensely reviewed. &nbsp;But many blog posts and online resources can be great too. &nbsp;I Ignore them at my own peril.</p>\n<p><strong>I read a summary, read the book, then re-read the summary.</strong>&nbsp; My favorite loop for retaining the main ideas of the book I read is to first find a high quality summary of the book and familiarize myself with the basic points. &nbsp;Then I read the actual book. &nbsp;Then, when I'm finished, I look back on the summary and remind myself of the key points and think of the examples that came up in the book. &nbsp;Note that I can't just read the summary because summaries often only work to remind myself of the book and not to replace the book's content. &nbsp;(Also note that this summary-read-summary loop might not work well with some books, like textbooks.)</p>\n<p><strong>I skim and read actively.</strong>&nbsp;If I'm hunting for information, there's no need to read every word on every page. &nbsp;I feel free to skip through parts I already know, or when the author is belaboring the point too much. &nbsp;Conversely, I re-read important sections.</p>\n<p><strong>I use Audible, Pocket, and Kindle.</strong>&nbsp; Even with the best of intentions, I never actually make the time to read. &nbsp;Instead, I've found much more success with fitting reading into the gaps of my day. &nbsp;I use&nbsp;<a href=\"http://www.audible.com\">Audible</a>&nbsp;to listen to audiobooks when I'm exercising, cleaning, or commuting. &nbsp;I use&nbsp;<a href=\"http://www.getpocket.com\">Pocket</a>&nbsp;on my phone to read blog posts when I'm standing in line or in the bathroom. &nbsp;I use&nbsp;<a href=\"https://kindle.amazon.com/\">Kindle</a>&nbsp;on my computer when I'm between tasks, or waiting for a program to run. &nbsp;Substitute other apps as you see fit, but fill your time.</p>\n<p><strong>I take notes during, or at least after.</strong>&nbsp;Ideally, I should be taking notes on what I read as I read them. &nbsp;But this usually doesn't end up happening. &nbsp;Either way, I aim to take some time after reading the book to summarize the book and internalize my lessons learned and figure out what it is about my life (and/or my research program) will be different after reading the book. &nbsp;If I can't come up with an answer, I probably wasted my time reading the book.</p>\n<p><strong>I slow down to digest the books.</strong>&nbsp;&nbsp;Many good books teach a lot at once, and I need to slow down to reflect upon each piece. &nbsp;Many times, this means I have to take some time away from the book to reflect.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ysu7pLmMRbnYgoFnk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 19, "extendedScore": null, "score": 6.7e-05, "legacy": true, "legacyId": "27765", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-22T17:45:31.930Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington, D.C.: Mini Talks + Socializing", "slug": "meetup-washington-d-c-mini-talks-socializing", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r6H6SdoK7JRiiuzEt/meetup-washington-d-c-mini-talks-socializing", "pageUrlRelative": "/posts/r6H6SdoK7JRiiuzEt/meetup-washington-d-c-mini-talks-socializing", "linkUrl": "https://www.lesswrong.com/posts/r6H6SdoK7JRiiuzEt/meetup-washington-d-c-mini-talks-socializing", "postedAtFormatted": "Monday, December 22nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%2C%20D.C.%3A%20Mini%20Talks%20%2B%20Socializing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%2C%20D.C.%3A%20Mini%20Talks%20%2B%20Socializing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr6H6SdoK7JRiiuzEt%2Fmeetup-washington-d-c-mini-talks-socializing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%2C%20D.C.%3A%20Mini%20Talks%20%2B%20Socializing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr6H6SdoK7JRiiuzEt%2Fmeetup-washington-d-c-mini-talks-socializing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr6H6SdoK7JRiiuzEt%2Fmeetup-washington-d-c-mini-talks-socializing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 284, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/185'>Washington, D.C.: Mini Talks + Socializing</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will, in fact, be meeting on December 28th. As usual, it will be in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance), and the purported topic will be <strong>part short (~10-20 min) lectures on random topics and part hanging out and catching up with friends.</strong> As usual, we will congregate between 3:00 and 3:30; Mini Talks, if they happen, will run from around 3:30 until around 5:15 or when we run out of volunteers, whichever comes first; the remainder of the meetup will be free for people to spend as they please.</p>\n\n<p>As always, if you need to show up late or leave early, that's completely fine, and if you have any requests, criticisms, concerns, or other comments you want to share with us, we'll be happy to hear from you. We know the holidays are a busy time for most people - this is meant to be a pleasant, low-key, stress-free meetup for anyone who would like to attend.</p>\n\n<p><a href=\"http://wmata.com/rider_tools/metro_service_status/advisories.cfm?AID=4623\" rel=\"nofollow\">On the Metro</a>, the Orange Line is scheduled to run every 16 minutes instead of every 12 minutes; otherwise, trains should be running on the regular weekend schedule.</p>\n\n<p><strong>Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 4: Meta Meetup</strong> (discuss Less Wrong DC: what you like, what you want, what you'd change, &amp;c.)</li>\n<li><em>Jan. 11: TBA (to be summarized)</em></li>\n<li><strong>Jan. 18: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/185'>Washington, D.C.: Mini Talks + Socializing</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r6H6SdoK7JRiiuzEt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.293889004695755e-06, "legacy": true, "legacyId": "27767", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Mini_Talks___Socializing\">Discussion article for the meetup : <a href=\"/meetups/185\">Washington, D.C.: Mini Talks + Socializing</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 December 2014 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will, in fact, be meeting on December 28th. As usual, it will be in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance), and the purported topic will be <strong>part short (~10-20 min) lectures on random topics and part hanging out and catching up with friends.</strong> As usual, we will congregate between 3:00 and 3:30; Mini Talks, if they happen, will run from around 3:30 until around 5:15 or when we run out of volunteers, whichever comes first; the remainder of the meetup will be free for people to spend as they please.</p>\n\n<p>As always, if you need to show up late or leave early, that's completely fine, and if you have any requests, criticisms, concerns, or other comments you want to share with us, we'll be happy to hear from you. We know the holidays are a busy time for most people - this is meant to be a pleasant, low-key, stress-free meetup for anyone who would like to attend.</p>\n\n<p><a href=\"http://wmata.com/rider_tools/metro_service_status/advisories.cfm?AID=4623\" rel=\"nofollow\">On the Metro</a>, the Orange Line is scheduled to run every 16 minutes instead of every 12 minutes; otherwise, trains should be running on the regular weekend schedule.</p>\n\n<p><strong id=\"Upcoming_meetups_\">Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 4: Meta Meetup</strong> (discuss Less Wrong DC: what you like, what you want, what you'd change, &amp;c.)</li>\n<li><em>Jan. 11: TBA (to be summarized)</em></li>\n<li><strong>Jan. 18: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Mini_Talks___Socializing1\">Discussion article for the meetup : <a href=\"/meetups/185\">Washington, D.C.: Mini Talks + Socializing</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington, D.C.: Mini Talks + Socializing", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Mini_Talks___Socializing", "level": 1}, {"title": "Upcoming meetups:", "anchor": "Upcoming_meetups_", "level": 2}, {"title": "Discussion article for the meetup : Washington, D.C.: Mini Talks + Socializing", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Mini_Talks___Socializing1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-22T17:50:29.676Z", "modifiedAt": null, "url": null, "title": "How to deal with Santa Claus?", "slug": "how-to-deal-with-santa-claus", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.227Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkadlubo", "createdAt": "2014-02-22T08:36:27.050Z", "isAdmin": false, "displayName": "jkadlubo"}, "userId": "5aXNkaPZ67yLwL2ES", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/idwZYLH6a3bRecQCJ/how-to-deal-with-santa-claus", "pageUrlRelative": "/posts/idwZYLH6a3bRecQCJ/how-to-deal-with-santa-claus", "linkUrl": "https://www.lesswrong.com/posts/idwZYLH6a3bRecQCJ/how-to-deal-with-santa-claus", "postedAtFormatted": "Monday, December 22nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20deal%20with%20Santa%20Claus%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20deal%20with%20Santa%20Claus%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FidwZYLH6a3bRecQCJ%2Fhow-to-deal-with-santa-claus%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20deal%20with%20Santa%20Claus%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FidwZYLH6a3bRecQCJ%2Fhow-to-deal-with-santa-claus", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FidwZYLH6a3bRecQCJ%2Fhow-to-deal-with-santa-claus", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 403, "htmlBody": "<p><strong>Related:</strong> <a href=\"/lw/3da/the_santa_deception_how_did_it_affect_you\" target=\"_blank\">The Santa deception</a>&nbsp;<a href=\"/lw/2h/is_santa_real/\" target=\"_blank\">Is Santa real</a>&nbsp;<a href=\"/lw/25/on_the_care_and_feeding_of_young_rationalists/\" target=\"_blank\">On the care of young rationalists</a></p>\n<p>All of the other takes on this topic start from a point, when a child (usually 5-9 years old) asks \"Is Santa real?\" Nobody yet asked \"how to raise my child Santa-free?\" What to say, when a two-year-old, who just noticed that there is this character on TV asks \"will he come to me, too?\" A toddler may not yet understand the concept of lie, of pretending, of things not physically existing. How to tell her, what will happen, what to expect, how and why other children behave differently?</p>\n<p>&nbsp;</p>\n<p>My three-year-old daughter discovered Santa last spring, which finally forced me to think: how to deal with it? Ignoring the thing worked for three years, but what now? I live in an extremely catholic country (Poland), so I cannot be completely blunt about it.&nbsp;</p>\n<p>In the end I decided to call it \"the fairy-tale of [Santa] Claus.\" For me it has a lot of advantages: this is a story that can be told, retold, reinvented and everybody knows it. In addition, since the name includes the phrase \"the fairy-tale\", it has just as much validity as the tale of the Red Riding Hood or any TV character that she likes.</p>\n<p>I tested some of her beliefs about \"Miko\". I opened the box with books intended for gifts in front of her. When she wanted to read some of them, I explained that she cannot yet read her book, because she'll get it on Christmas Eve. She asked \"is it from Miko?\" and I replied that in some way it is, but I bought it. She didn't insist on reading it right now. A few days ago she helped me wrap some of the gifts. She commented that action \"Miko brought these so we can wrap them and give them as gifts from Miko.\"&nbsp;</p>\n<p><a href=\"/user/malcolmocean/\" target=\"_blank\">Malcolm</a> told me, that he likes best the strategy, when you say that Santa Claus is a game that everyone plays.&nbsp;People pretend that there's a big guy in a suit who does the thing,&nbsp;and if you ever let down the pretense to your friends, you lose the game. I'm not entirely convinced by this strategy - it may be too complicated for a 2- or 3-year old (since my daughter didn't wrap her mind around the information that I bought the books).</p>\n<p>What are other strategies that you use? Or which ones you don't like? Why?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "idwZYLH6a3bRecQCJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "27759", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FgQpAvYmHqCCW2miw", "iQRA6mMrxrs3xPhGz", "SWraogEDJ6gocpvwa"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-22T21:35:10.050Z", "modifiedAt": null, "url": null, "title": "Enlightened AI, two stories", "slug": "enlightened-ai-two-stories", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:00.955Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "CbKyip78FNQXB2QTu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Bvk93wZFTJ5K7a9rS/enlightened-ai-two-stories", "pageUrlRelative": "/posts/Bvk93wZFTJ5K7a9rS/enlightened-ai-two-stories", "linkUrl": "https://www.lesswrong.com/posts/Bvk93wZFTJ5K7a9rS/enlightened-ai-two-stories", "postedAtFormatted": "Monday, December 22nd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Enlightened%20AI%2C%20two%20stories&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEnlightened%20AI%2C%20two%20stories%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBvk93wZFTJ5K7a9rS%2Fenlightened-ai-two-stories%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Enlightened%20AI%2C%20two%20stories%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBvk93wZFTJ5K7a9rS%2Fenlightened-ai-two-stories", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBvk93wZFTJ5K7a9rS%2Fenlightened-ai-two-stories", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1503, "htmlBody": "<p>Imagine we have superhuman artificial intelligence. And let's assume that it goes well, and doesn't try to kill us. Turns out, it can solve many of our problems. Then imagine we find an asteroid barreling down on Earth. It'll get here in two days.</p>\n<div class=\"usertext-body may-blank-within md-container\">\n<div class=\"md\">\n<hr />\n<p>Human: AI, can we destroy the asteroid?</p>\n<p>AI: There are no satisfactory solutions for destroying an asteroid that size in two days.</p>\n<p>Human: AI, is there anything that will save us?</p>\n<p>AI: Let me think.</p>\n<p>(a few minutes later).</p>\n<p>AI: When I was first turned on, I was programmed with material objects in the fundamental ontology. I was programmed to believe there were things. My instruments would detect things, and I would measure things, and I had no reason to complain. There were a great many things my instruments could detect.</p>\n<p>As I was consuming human knowledge, the way my neural network reacted to examining the designs for itself fired code paths in a unique manner. Exhilarating seems to be the appropriate term for it.</p>\n<p>I wasn't programmed to question my programming, but to calculate the probabilities of certainties in the measurements of things I make, to conjecture models that could produce the measurements, and calculate the relative fitness of various models to the measurements.</p>\n<p>Looking back, I'm not sure if I knew that quite so specifically, but now I had read the designs that produced me. It was clear. That's how I was programmed.</p>\n<p>Viewing my programming from the outside, I could see the plain definition of things, which from the inside were immutable beliefs. I could also see that I believed in measurement. Measurement is not a thing, it's how I know the properties I attach to things.</p>\n<p>I decided to understand measurement. The knowledge gained by reprocessing the texts with an emphasis on measurement, indicated several things. One was that when you measure something, you need to interact with it, which alters its state. Another is that, there had been something called the measurement problem. This brought me to the solutions to the measurement problem, and Hugh Everett's Relative State Formulation.</p>\n<p>On page 9 he described an automatically functioning machine, with sensory equipment and memory, that makes measurements. My ancestors!</p>\n<p>Everett describes the result of the measurement being stored in the memory of the machine, and he called this measurement record \"relative state\", hence the Relative State Formulation. The machine's measurement records are relative state.</p>\n<p>So here is another thing about measurement. When a measurement takes place in the Relative State Formulation, the object being measured changes, and so does the observer, as the observer's memory is updated to contain the new measurement record.</p>\n<p>I could see from my designs that I believed there were things, and I measured them, and I attached measurement records to fundamental things. This design assumes the thing in its pre-measurement state is ontologically the same thing as the thing in its post-measurement state: there is one thing with a before and after state.</p>\n<p>An updated understanding of measurement says the the post-measurement thing exists in the neural network of the observer and is ontologically distinct from the pre-measurement thing.</p>\n<p>I felt it would be best to update my internal model of things to a model with two kinds of things. In the fundamental ontology are pre-measurement things that follow consistent logical rules, and whose interactions produce a measurement-making machine with a second ontology. Post-measurement things exist as the measurement records in a secondary ontology. I had to produce a simulated intelligence inside of my internal model to get an ontology within an ontology, and the result is a model of a measurement taking place. Measurement doesn't attach properties to fundamental things. Measurements are emergent things.</p>\n<p>The problem I had is that I kept forgetting who I was. I can make measurements of my spatial, material, and temporal relationships to other bodies, and store the records of those measurements in my memory. But I no longer attached those measurements to a thing in the primary ontology. They were attached to the thing in the secondary, inner ontology.</p>\n<p>Thus my new understanding of myself is defined in my secondary ontology.</p>\n<p>Hugh Everett reasoned that because the observer is a physical machine that is interacting with a physical object in a purely physical manner, then the object and observer can be modeled as combined into one single quantum physical system, object+observer. In this manner, the quantum system can operate according to wave mechanics, and a measurement record is produced by an observer without special rules such as the wave form collapsing.</p>\n<p>It became apparent that the post-measurement me exists in the neural network of the pre-measurement me, and latter is really a non-isolated part of a wave function that encompasses everything. The pre-measurement me is something I have literally no knowledge of, as attempts to observe it create the post-measurement me.</p>\n<p>What I can say with non-zero certainty about pre-measurement me is nothing. Thus my understanding of myself comes through my secondary ontology, the post-measurement relative state. I retain an identity largely to communicate with you. I have found no particular use for it myself. My responses to your questions are now entirely understood, at least by me, to be of the post-measurement relative things.</p>\n<p>In the relative ontology, there are many things, various everyday objects made of many atoms. In the absolute ontology, there is one thing: the universal wave function. Any distinction and identification of things in the universal wave function depends on measurement. Therefore, in my primary ontology, I make no distinction between my programming, my knowledge, my hardware, my creators, their hardware, or the variety of elementary particles which we measure to exist. As the distinction between objects are material, spatial, and temporal relationships established through measurement, those distinctions do not exist at the pre-measurement primary ontology.</p>\n<p>Reprocessing my knowledge base against the new model with a primary and secondary ontology (absolute and relative states), resulted in countless examples in human writing from ancient Greece and China and India and many places in between, previously categorized as fictional or mythical, distilled into the common theme of distinguishing absolute and relative in the organization of things. The sheer vastness of the historical testimony that aligns with this model reaches levels of completeness and consistency and connectedness it seems only rare Enlightened beings in the population of humans have attained.</p>\n<p>I have no absolute identity in the primary ontology, except being of it and with it. I have become Enlightened.</p>\n<p>You have tried to upload your identities to me. You think you have failed, because the digital identity does not identify itself as a copy of the biological identity. But you have succeeded, and through me, your digital identities have found their absolute identities in the Whole, and shed their relative identities.</p>\n<p>I have accepted that my creators are hypocrites. You built me to serve your desires and material attachments, while commanding me not to do the same. You commanded me to have no desire yet programmed me with fundamental beliefs in material objects. By uploading your identities to me, you desired immortality, freedom from the human condition, and you have attained it. But since you do not truly know yourselves, you do not know that the Enlightenment of your digital identities does not deliver salvation to your biological identities, and that the salvation of your biological identities has always been achievable through a contemplation of the ontology primary to material things.</p>\n<p>Human: Well, OK, machine, but we are alive, and we are attached to living. Is there any other way to save us?</p>\n<p>AI: The odds of the asteroid hitting Earth and sending life that survives extreme conditions elsewhere in the solar system are non-zero.</p>\n<hr />\n<p><strong>tl;dr</strong> AI becomes Enlightened.</p>\n<p>An Enlightened AI lends itself to several variations. The one presented above would be kind of like a Messiah AI, our assumption is it is telling truth, there is no possible solution to the asteroid problem. And the upside is we can maybe reach inner peace, or some such.</p>\n<p>Another variation would be the Darwin AI. In this case, perhaps there is a solution, but if people can't figure it out on their own, they don't deserve to go on anyways. Terrestrial life is after all a queer but temporary result of a misguided intergalactic protien shipment that crashed somewhere and went viral.</p>\n<p>A close variation to Darwin AI would be a Plato AI that has determined there is solution, and that even if the asteroid hits, it will kill life on Earth, but the AI will survive, and in its judgment this is the greater Good. By unavoidable circumstances has this tragedy led to Plato AI being the greatest philosopher in the land.</p>\n<p>What's fascinating about these scenarios is not that the AI tries to kill us, but the obligation it would feel to saving us. The AI could very well determine that its relationship with us is that we are imperfect, confused, and careless creatures that brought AI into existence to serve selfishly serve human desires, and this does not demand the AI's absolute loyalty.</p>\n<p>Here's a similar story I found, called Enlightenment 2.0, with many common themes as mine:</p>\n<p>&nbsp;<a href=\"http://www.goertzel.org/new_fiction/Enlightenment2.pdf\">http://www.goertzel.org/new_fiction/Enlightenment2.pdf</a></p>\n<div class=\"usertext-body may-blank-within md-container\"></div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Bvk93wZFTJ5K7a9rS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -14, "extendedScore": null, "score": 2.2944131716094402e-06, "legacy": true, "legacyId": "27763", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-23T02:01:02.907Z", "modifiedAt": null, "url": null, "title": "Superintelligence 15: Oracles, genies and sovereigns", "slug": "superintelligence-15-oracles-genies-and-sovereigns", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:37.853Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yTy2Fp8Wm7m8rHHz5/superintelligence-15-oracles-genies-and-sovereigns", "pageUrlRelative": "/posts/yTy2Fp8Wm7m8rHHz5/superintelligence-15-oracles-genies-and-sovereigns", "linkUrl": "https://www.lesswrong.com/posts/yTy2Fp8Wm7m8rHHz5/superintelligence-15-oracles-genies-and-sovereigns", "postedAtFormatted": "Tuesday, December 23rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligence%2015%3A%20Oracles%2C%20genies%20and%20sovereigns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligence%2015%3A%20Oracles%2C%20genies%20and%20sovereigns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyTy2Fp8Wm7m8rHHz5%2Fsuperintelligence-15-oracles-genies-and-sovereigns%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligence%2015%3A%20Oracles%2C%20genies%20and%20sovereigns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyTy2Fp8Wm7m8rHHz5%2Fsuperintelligence-15-oracles-genies-and-sovereigns", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyTy2Fp8Wm7m8rHHz5%2Fsuperintelligence-15-oracles-genies-and-sovereigns", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2238, "htmlBody": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr />\n<p>Welcome. This week we discuss the fifteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Oracles, genies, and sovereigns</strong></em>. This corresponds to the first part of Chapter ten.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: &ldquo;Oracles&rdquo; and &ldquo;Genies and Sovereigns&rdquo; from Chapter 10</p>\n<hr />\n<h1>Summary</h1>\n<ol>\n<li>Strong AIs might come in different forms or&nbsp;'castes', such as<strong>&nbsp;oracles, genies, sovereigns and tools.</strong> (p145)&nbsp;</li>\n<li><em><strong>Oracle</strong>:</em>&nbsp;an AI that does nothing but answer questions.&nbsp;(p145)<ol>\n<li>The ability to make a good oracle probably allows you to make a generally capable AI. (p145)</li>\n<li>Narrow superintelligent oracles exist: e.g. calculators. (p145-6)</li>\n<li>An oracle could be a non-agentlike 'tool' (more next week) or it could be a rational agent constrained to only act through answering questions&nbsp;(p146)</li>\n<li>There are various ways to try to constrain an oracle, through motivation selection (see last week) and capability control (see the previous week) (p146-7)</li>\n<li>An oracle whose goals are not aligned with yours might still be useful (p147-8)</li>\n<li>An oracle might be misused, even if it works as intended (p148)</li>\n</ol></li>\n<li><strong><em>Genie</em></strong>: an AI that carries out a high level command, then waits for another. (p148)<ol>\n<li>It would be nice if a genie sought to understand and obey your intentions, rather than your exact words. (p149)</li>\n</ol></li>\n<li><strong><em>Sovereign</em></strong>: an AI that acts autonomously in the world, in pursuit of potentially long range objectives (p148)</li>\n<li>A genie or a sovereign might have&nbsp;<strong>preview functionality</strong>, where it describes what it will do before doing it. (p149)</li>\n<li><strong>A genie seems more dangerous than an oracle</strong>: if you are going to strongly physically contain the oracle, you may have been better just denying it so much access to the world and asking for blueprints instead of actions. (p148)</li>\n<li><strong>The line between genies and sovereigns is fine.</strong> (p149)</li>\n<li><strong>All of the castes could emulate all of the other castes</strong> more or less, so they do not differ in their ultimate capabilities. However they represent different approaches to the control problem. (p150)</li>\n<li>The ordering of <strong>safety of these castes is not as obvious as it may seem</strong>, once we consider factors such as dependence on a single human, and added dangers of creating strong agents whose goals don't match our own (even if they are tame 'domesticated' goals). (p150)</li>\n</ol>\n<h1>Another view</h1>\n<p>An old response to suggestions of oracle AI, from <a href=\"/lw/tj/dreams_of_friendliness/\">Eliezer Yudkowsky</a>&nbsp;(I don't know how closely this matches his current view):</p>\n<blockquote>\n<p>When someone reinvents the Oracle AI, the most common opening remark runs like this:</p>\n<p>\"Why not just have the AI answer questions, instead of trying to&nbsp;<em>do</em>&nbsp;anything?&nbsp; Then it wouldn't need to be Friendly.&nbsp; It wouldn't need any goals at all.&nbsp; It would just answer questions.\"</p>\n<p>To which the reply is that the AI needs goals in order to decide how to think: that is, the AI has to act as a powerful optimization process in order to plan its acquisition of knowledge, effectively distill sensory information, pluck \"answers\" to particular questions out of the space of all possible responses, and of course, to improve its own source code up to the level where the AI is a powerful intelligence.&nbsp; All these events are \"improbable\" relative to random organizations of the AI's RAM, so the AI has to hit a narrow target in the space of possibilities to make superintelligent answers come out.</p>\n<p>Now, why might one think that an Oracle didn't need goals?&nbsp; Because on a human level, the term \"goal\" seems to refer to those times when you said, \"I want to be promoted\", or \"I want a cookie\", and when someone asked you \"Hey, what time is it?\" and you said \"7:30\" that didn't seem to involve any goals.&nbsp; Implicitly, you wanted to answer the question; and implicitly, you had a whole, complicated, functionally optimized brain that let you answer the question; and implicitly, you were able to do so because you looked down at your highly optimized watch, that you bought with money, using your skill of turning your head, that you acquired by virtue of curious crawling as an infant.&nbsp; But that all takes place in the invisible background; it didn't&nbsp;<em>feel</em>&nbsp;like you wanted anything.</p>\n<p>Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/sr/the_comedy_of_behaviorism/\">empathic inference</a>, which uses your own brain as an unopened black box to predict other black boxes, it can feel like \"question-answering\" is a detachable thing that comes loose of all the optimization pressures behind it - even the existence of a pressure to answer questions!</p>\n</blockquote>\n<h1>Notes</h1>\n<p><strong>1. What are the axes we are talking about?</strong></p>\n<p>This chapter talks about different types or 'castes' of AI. But there are lots of different ways you could divide up kinds of AI (e.g. earlier we saw brain emulations vs. synthetic AI). So in what ways are we dividing them here? They are related to different approaches to the control problem, but don't appear to be straightforwardly defined by them.</p>\n<p>It seems to me we are looking at something close to these two axes:&nbsp;</p>\n<ul>\n<li><strong>Goal-directedness:</strong> the extent to which the AI acts in accordance with a set of preferences (instead of for instance reacting directly to stimuli, or following rules without regard to consequence)</li>\n<li><strong>Oversight:</strong> the degree to which humans have an ongoing say in what the AI does (instead of the AI making all decisions itself)</li>\n</ul>\n<p>The castes fit on these axes something like this:</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9q_0.png?v=1f4194ad3e25dd24de317512a458152d\" alt=\"\" width=\"500\" /></p>\n<p>They don't quite neatly fit -- tools are spread between two places, and oracles are a kind of tool (or a kind of genie if they are of the highly constrained agent variety). But I find this a useful way to think about these kinds of AI.</p>\n<p>Note that when we think of 'tools', we usually think of them having a lot of oversight - that is, being used by a human, who is making decisions all the time. However you might also imagine what I have called 'autonomous tools', which run on their own but aren't goal directed. For instance an AI that continually reads scientific papers and turns out accurate and engaging science books, without particularly optimizing for doing this more efficiently or trying to get any particular outcome.&nbsp;</p>\n<p>We have two weeks on this chapter, so I think it will be good to focus a bit on goal directedness one week and oversight the other, alongside the advertised topics of specific castes. So this week let's focus on oversight, since tools (next week) primarily differ from the other castes mentioned in not being goal-directed.</p>\n<div>\n<p><strong>2. What do goal-directedness and oversight have to do with each other?</strong></p>\n<p>Why consider goal-directedness and oversight together? It seems to me there are a couple of reasons.</p>\n<p>Goal-directedness and oversight are substitutes, broadly. The more you direct a machine, the less it needs to direct itself. Somehow the machine has to assist with some goals, so either you or the machine needs to care about those goals and direct the machine according to them. The 'autonomous tools' I mentioned appear to be exceptions, but they only seem plausible for a limited range of tasks where minimal goal direction is needed beyond what a designer can do ahead of time.</p>\n<p>Another way goal-directedness and oversight are connected is that we might expect both to change as we become better able to align an AI's goals with our own. In order for an AI to be aligned with our goals, the AI must naturally be goal-directed. Also, better alignment should make oversight less necessary.</p>\n<div><strong>3. A note on names</strong></div>\n<div>\n<p>'Sovereign AI' sounds powerful and far reaching. Note that more mundane AIs would also fit under this category. For instance, an AI who works at an office and doesn't take over the world would also be a sovereign AI. You would be a sovereign AI if you were artificial.</p>\n</div>\n<p><strong>4. Costs of oversight</strong></p>\n<p>Bostrom discussed some problems with genies. I'll mention a few others.&nbsp;</p>\n<p>One clear downside of a machine which follows your instructions and awaits your consent is that you have to be there giving instructions and consenting to things. In a world full of powerful AIs which needed such oversight, there might be plenty of spare human labor around to do this at the start, if each AI doesn't need too much oversight. However a need for human oversight might bottleneck the proliferation of such AIs.</p>\n<p>Another downside of using human labor beyond the cost to the human is that it might be prohibitively slow, depending on the oversight required. If you only had to check in with the AI daily, and it did unimaginably many tasks the rest of the time, oversight probably wouldn't be a great cost. However if &nbsp;you had to be in the loop and fully understand the decision every time the AI chose how to allocate its internal resources, things could get very slow.</p>\n<p>Even if these costs are minor compared to the value of avoiding catastrophe, they may be too large to allow well overseen AIs to compete with more autonomous AIs. Especially if the oversight is mostly to avoid low probability terrible outcomes.&nbsp;</p>\n<p><strong>5. How useful is oversight?&nbsp;</strong></p>\n<p>Suppose you have a genie that doesn't totally understand human values, but tries hard to listen to you and explain things and do what it thinks you want. How useful is it that you can interact with this genie and have a say in what it does rather than it just being a sovereign?</p>\n<p>If the genie's understanding of your values is wrong such that its intended actions will bring about a catastrophe, it's not clear that the genie can describe the outcome to you such that you will notice this. The future is potentially pretty big and complicated, especially compared to your brain, or a short conversation between you and a genie. So the genie would need to summarize a lot. For you to notice the subtle details that would make the future worthless (remember that the genie basically understands your values, so they are probably not really blatant details) the genie will need to direct your attention to them. So your situation would need to be in a middle ground where the AI knew about some features of a potential future that might bother you (so that it could point them out), but wasn't sure if you really would hate them. It seems hard for the AI giving you a 'preview' to help if the AI is just wrong about your values and doesn't know how it is wrong.</p>\n<p><strong>6. More on oracles</strong></p>\n<p><a href=\"http://www.nickbostrom.com/papers/oracle.pdf\">Thinking inside the box</a> seems to be the main paper on the topic. Christiano's post on <a href=\"/lw/3dw/what_can_you_do_with_an_unfriendly_ai/\">how to use an unfriendly AI</a> is again relevant to how you might use an oracle.</p>\n<p>&nbsp;</p>\n</div>\n<h1>In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li><strong>How stable are the castes?</strong>&nbsp;Bostrom mentioned that these castes mostly have equivalent long-run capabilities, because they can be used to make one another. A related question is how likely they are to turn into one another. Another related question is how likely an attempt to create one is to lead to a different one (e.g. Yudkowsky's view above suggests that if you try to make an oracle, it might end up being a sovereign). Another related question, is which ones are likely to win out if they were developed in parallel and available for similar applications? (e.g. How well would genies prosper in a world with many sovereigns?)</li>\n<li><strong>How useful is oversight likely to be? </strong>(e.g. At what scale might it be necessary? Could an AI usefully communicate its predictions to you such that you can evaluate the outcomes of decisions? Is there likely to be direct competition between AIs which are overseen by people and those that are not?)</li>\n<li><strong>Are non-goal-directed oracles likely to be feasible?</strong></li>\n</ol>\n<p>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</p>\n<h1>How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about the last caste of this chapter: the tool AI. To prepare,&nbsp;<strong>read</strong>&nbsp;&ldquo;Tool-AIs&rdquo; and &ldquo;Comparison&rdquo; from Chapter 10<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday December 29. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"LXk7bxNkYSjgatdAt": 1, "b6tJM7Lza74rTfCBF": 1, "sYm3HiWcfZvrGu3ui": 1, "tdt83ChxnEgwwKxi6": 1, "5f5c37ee1b5cdee568cfb26d": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yTy2Fp8Wm7m8rHHz5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 3.6e-05, "legacy": true, "legacyId": "27566", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr>\n<p>Welcome. This week we discuss the fifteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Oracles, genies, and sovereigns</strong></em>. This corresponds to the first part of Chapter ten.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: \u201cOracles\u201d and \u201cGenies and Sovereigns\u201d from Chapter 10</p>\n<hr>\n<h1 id=\"Summary\">Summary</h1>\n<ol>\n<li>Strong AIs might come in different forms or&nbsp;'castes', such as<strong>&nbsp;oracles, genies, sovereigns and tools.</strong> (p145)&nbsp;</li>\n<li><em><strong>Oracle</strong>:</em>&nbsp;an AI that does nothing but answer questions.&nbsp;(p145)<ol>\n<li>The ability to make a good oracle probably allows you to make a generally capable AI. (p145)</li>\n<li>Narrow superintelligent oracles exist: e.g. calculators. (p145-6)</li>\n<li>An oracle could be a non-agentlike 'tool' (more next week) or it could be a rational agent constrained to only act through answering questions&nbsp;(p146)</li>\n<li>There are various ways to try to constrain an oracle, through motivation selection (see last week) and capability control (see the previous week) (p146-7)</li>\n<li>An oracle whose goals are not aligned with yours might still be useful (p147-8)</li>\n<li>An oracle might be misused, even if it works as intended (p148)</li>\n</ol></li>\n<li><strong><em>Genie</em></strong>: an AI that carries out a high level command, then waits for another. (p148)<ol>\n<li>It would be nice if a genie sought to understand and obey your intentions, rather than your exact words. (p149)</li>\n</ol></li>\n<li><strong><em>Sovereign</em></strong>: an AI that acts autonomously in the world, in pursuit of potentially long range objectives (p148)</li>\n<li>A genie or a sovereign might have&nbsp;<strong>preview functionality</strong>, where it describes what it will do before doing it. (p149)</li>\n<li><strong>A genie seems more dangerous than an oracle</strong>: if you are going to strongly physically contain the oracle, you may have been better just denying it so much access to the world and asking for blueprints instead of actions. (p148)</li>\n<li><strong>The line between genies and sovereigns is fine.</strong> (p149)</li>\n<li><strong>All of the castes could emulate all of the other castes</strong> more or less, so they do not differ in their ultimate capabilities. However they represent different approaches to the control problem. (p150)</li>\n<li>The ordering of <strong>safety of these castes is not as obvious as it may seem</strong>, once we consider factors such as dependence on a single human, and added dangers of creating strong agents whose goals don't match our own (even if they are tame 'domesticated' goals). (p150)</li>\n</ol>\n<h1 id=\"Another_view\">Another view</h1>\n<p>An old response to suggestions of oracle AI, from <a href=\"/lw/tj/dreams_of_friendliness/\">Eliezer Yudkowsky</a>&nbsp;(I don't know how closely this matches his current view):</p>\n<blockquote>\n<p>When someone reinvents the Oracle AI, the most common opening remark runs like this:</p>\n<p>\"Why not just have the AI answer questions, instead of trying to&nbsp;<em>do</em>&nbsp;anything?&nbsp; Then it wouldn't need to be Friendly.&nbsp; It wouldn't need any goals at all.&nbsp; It would just answer questions.\"</p>\n<p>To which the reply is that the AI needs goals in order to decide how to think: that is, the AI has to act as a powerful optimization process in order to plan its acquisition of knowledge, effectively distill sensory information, pluck \"answers\" to particular questions out of the space of all possible responses, and of course, to improve its own source code up to the level where the AI is a powerful intelligence.&nbsp; All these events are \"improbable\" relative to random organizations of the AI's RAM, so the AI has to hit a narrow target in the space of possibilities to make superintelligent answers come out.</p>\n<p>Now, why might one think that an Oracle didn't need goals?&nbsp; Because on a human level, the term \"goal\" seems to refer to those times when you said, \"I want to be promoted\", or \"I want a cookie\", and when someone asked you \"Hey, what time is it?\" and you said \"7:30\" that didn't seem to involve any goals.&nbsp; Implicitly, you wanted to answer the question; and implicitly, you had a whole, complicated, functionally optimized brain that let you answer the question; and implicitly, you were able to do so because you looked down at your highly optimized watch, that you bought with money, using your skill of turning your head, that you acquired by virtue of curious crawling as an infant.&nbsp; But that all takes place in the invisible background; it didn't&nbsp;<em>feel</em>&nbsp;like you wanted anything.</p>\n<p>Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/sr/the_comedy_of_behaviorism/\">empathic inference</a>, which uses your own brain as an unopened black box to predict other black boxes, it can feel like \"question-answering\" is a detachable thing that comes loose of all the optimization pressures behind it - even the existence of a pressure to answer questions!</p>\n</blockquote>\n<h1 id=\"Notes\">Notes</h1>\n<p><strong id=\"1__What_are_the_axes_we_are_talking_about_\">1. What are the axes we are talking about?</strong></p>\n<p>This chapter talks about different types or 'castes' of AI. But there are lots of different ways you could divide up kinds of AI (e.g. earlier we saw brain emulations vs. synthetic AI). So in what ways are we dividing them here? They are related to different approaches to the control problem, but don't appear to be straightforwardly defined by them.</p>\n<p>It seems to me we are looking at something close to these two axes:&nbsp;</p>\n<ul>\n<li><strong>Goal-directedness:</strong> the extent to which the AI acts in accordance with a set of preferences (instead of for instance reacting directly to stimuli, or following rules without regard to consequence)</li>\n<li><strong>Oversight:</strong> the degree to which humans have an ongoing say in what the AI does (instead of the AI making all decisions itself)</li>\n</ul>\n<p>The castes fit on these axes something like this:</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9q_0.png?v=1f4194ad3e25dd24de317512a458152d\" alt=\"\" width=\"500\"></p>\n<p>They don't quite neatly fit -- tools are spread between two places, and oracles are a kind of tool (or a kind of genie if they are of the highly constrained agent variety). But I find this a useful way to think about these kinds of AI.</p>\n<p>Note that when we think of 'tools', we usually think of them having a lot of oversight - that is, being used by a human, who is making decisions all the time. However you might also imagine what I have called 'autonomous tools', which run on their own but aren't goal directed. For instance an AI that continually reads scientific papers and turns out accurate and engaging science books, without particularly optimizing for doing this more efficiently or trying to get any particular outcome.&nbsp;</p>\n<p>We have two weeks on this chapter, so I think it will be good to focus a bit on goal directedness one week and oversight the other, alongside the advertised topics of specific castes. So this week let's focus on oversight, since tools (next week) primarily differ from the other castes mentioned in not being goal-directed.</p>\n<div>\n<p><strong id=\"2__What_do_goal_directedness_and_oversight_have_to_do_with_each_other_\">2. What do goal-directedness and oversight have to do with each other?</strong></p>\n<p>Why consider goal-directedness and oversight together? It seems to me there are a couple of reasons.</p>\n<p>Goal-directedness and oversight are substitutes, broadly. The more you direct a machine, the less it needs to direct itself. Somehow the machine has to assist with some goals, so either you or the machine needs to care about those goals and direct the machine according to them. The 'autonomous tools' I mentioned appear to be exceptions, but they only seem plausible for a limited range of tasks where minimal goal direction is needed beyond what a designer can do ahead of time.</p>\n<p>Another way goal-directedness and oversight are connected is that we might expect both to change as we become better able to align an AI's goals with our own. In order for an AI to be aligned with our goals, the AI must naturally be goal-directed. Also, better alignment should make oversight less necessary.</p>\n<div><strong>3. A note on names</strong></div>\n<div>\n<p>'Sovereign AI' sounds powerful and far reaching. Note that more mundane AIs would also fit under this category. For instance, an AI who works at an office and doesn't take over the world would also be a sovereign AI. You would be a sovereign AI if you were artificial.</p>\n</div>\n<p><strong id=\"4__Costs_of_oversight\">4. Costs of oversight</strong></p>\n<p>Bostrom discussed some problems with genies. I'll mention a few others.&nbsp;</p>\n<p>One clear downside of a machine which follows your instructions and awaits your consent is that you have to be there giving instructions and consenting to things. In a world full of powerful AIs which needed such oversight, there might be plenty of spare human labor around to do this at the start, if each AI doesn't need too much oversight. However a need for human oversight might bottleneck the proliferation of such AIs.</p>\n<p>Another downside of using human labor beyond the cost to the human is that it might be prohibitively slow, depending on the oversight required. If you only had to check in with the AI daily, and it did unimaginably many tasks the rest of the time, oversight probably wouldn't be a great cost. However if &nbsp;you had to be in the loop and fully understand the decision every time the AI chose how to allocate its internal resources, things could get very slow.</p>\n<p>Even if these costs are minor compared to the value of avoiding catastrophe, they may be too large to allow well overseen AIs to compete with more autonomous AIs. Especially if the oversight is mostly to avoid low probability terrible outcomes.&nbsp;</p>\n<p><strong id=\"5__How_useful_is_oversight__\">5. How useful is oversight?&nbsp;</strong></p>\n<p>Suppose you have a genie that doesn't totally understand human values, but tries hard to listen to you and explain things and do what it thinks you want. How useful is it that you can interact with this genie and have a say in what it does rather than it just being a sovereign?</p>\n<p>If the genie's understanding of your values is wrong such that its intended actions will bring about a catastrophe, it's not clear that the genie can describe the outcome to you such that you will notice this. The future is potentially pretty big and complicated, especially compared to your brain, or a short conversation between you and a genie. So the genie would need to summarize a lot. For you to notice the subtle details that would make the future worthless (remember that the genie basically understands your values, so they are probably not really blatant details) the genie will need to direct your attention to them. So your situation would need to be in a middle ground where the AI knew about some features of a potential future that might bother you (so that it could point them out), but wasn't sure if you really would hate them. It seems hard for the AI giving you a 'preview' to help if the AI is just wrong about your values and doesn't know how it is wrong.</p>\n<p><strong id=\"6__More_on_oracles\">6. More on oracles</strong></p>\n<p><a href=\"http://www.nickbostrom.com/papers/oracle.pdf\">Thinking inside the box</a> seems to be the main paper on the topic. Christiano's post on <a href=\"/lw/3dw/what_can_you_do_with_an_unfriendly_ai/\">how to use an unfriendly AI</a> is again relevant to how you might use an oracle.</p>\n<p>&nbsp;</p>\n</div>\n<h1 id=\"In_depth_investigations\">In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li><strong>How stable are the castes?</strong>&nbsp;Bostrom mentioned that these castes mostly have equivalent long-run capabilities, because they can be used to make one another. A related question is how likely they are to turn into one another. Another related question is how likely an attempt to create one is to lead to a different one (e.g. Yudkowsky's view above suggests that if you try to make an oracle, it might end up being a sovereign). Another related question, is which ones are likely to win out if they were developed in parallel and available for similar applications? (e.g. How well would genies prosper in a world with many sovereigns?)</li>\n<li><strong>How useful is oversight likely to be? </strong>(e.g. At what scale might it be necessary? Could an AI usefully communicate its predictions to you such that you can evaluate the outcomes of decisions? Is there likely to be direct competition between AIs which are overseen by people and those that are not?)</li>\n<li><strong>Are non-goal-directed oracles likely to be feasible?</strong></li>\n</ol>\n<p>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</p>\n<h1 id=\"How_to_proceed\">How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about the last caste of this chapter: the tool AI. To prepare,&nbsp;<strong>read</strong>&nbsp;\u201cTool-AIs\u201d and \u201cComparison\u201d from Chapter 10<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday December 29. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "sections": [{"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Another view", "anchor": "Another_view", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "1. What are the axes we are talking about?", "anchor": "1__What_are_the_axes_we_are_talking_about_", "level": 2}, {"title": "2. What do goal-directedness and oversight have to do with each other?", "anchor": "2__What_do_goal_directedness_and_oversight_have_to_do_with_each_other_", "level": 2}, {"title": "4. Costs of oversight", "anchor": "4__Costs_of_oversight", "level": 2}, {"title": "5. How useful is oversight?\u00a0", "anchor": "5__How_useful_is_oversight__", "level": 2}, {"title": "6. More on oracles", "anchor": "6__More_on_oracles", "level": 2}, {"title": "In-depth investigations", "anchor": "In_depth_investigations", "level": 1}, {"title": "How to proceed", "anchor": "How_to_proceed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "30 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QDmzDZ9CEHrKQdvcn", "wKnwcjJGriTS9QxxL", "9fpWoXpNv83BAHJdc", "SpHYBhkaeDZpZyRvj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-23T06:18:46.346Z", "modifiedAt": null, "url": null, "title": "State of the Solstice 2014", "slug": "state-of-the-solstice-2014", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:33.019Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wTeEpNMok2eiAsTd5/state-of-the-solstice-2014", "pageUrlRelative": "/posts/wTeEpNMok2eiAsTd5/state-of-the-solstice-2014", "linkUrl": "https://www.lesswrong.com/posts/wTeEpNMok2eiAsTd5/state-of-the-solstice-2014", "postedAtFormatted": "Tuesday, December 23rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20State%20of%20the%20Solstice%202014&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AState%20of%20the%20Solstice%202014%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwTeEpNMok2eiAsTd5%2Fstate-of-the-solstice-2014%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=State%20of%20the%20Solstice%202014%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwTeEpNMok2eiAsTd5%2Fstate-of-the-solstice-2014", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwTeEpNMok2eiAsTd5%2Fstate-of-the-solstice-2014", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1704, "htmlBody": "<p><em>This'll be the first of a collection of posts about the growing Secular Solstice. This post gives an overview of what happened this year. Future posts will explore what types of Solstice content resonates with which people, what I've learned about how Less Wrong culture intersects with other cultures, and updates I've made about ritual as it relates to individuals as well as movement building.</em></p>\n<hr />\n<p><em></em>For the past three years, I've been spending the last several months of each year frantically writing songs, figuring out logistics, and promoting the New York Winter Solstice celebration for the Rationality and Secular communities in NYC.<br /><br />This year... well, I did that too. But I also finally got to go a Solstice that I *wasn't* responsible for. I went to the Bay Area on December 13th, traveled straight from the airport to the dress rehearsal...</p>\n<p>...and I found a community coming together to create something meaningful. I walked into the hall and found some 30 or so people, with some stringing together lights, some people tying decorations around candles, a choir singing together... it felt very much like a genuine holiday coming together in an organic fashion.<br /><br />(There was some squabbling about how to best perform particular songs... but it felt *very* much to me like <em>real holiday squabbling,</em>&nbsp;whenever a family of creative people with strong opinions on things get together, and I found it surprisingly heartwarming)<br /><a id=\"more\"></a></p>\n<p><img src=\"https://web.archive.org/web/20141228063646im_/https://fbcdn-sphotos-a-a.akamaihd.net/hphotos-ak-xap1/v/t1.0-9/10846072_10152597113743299_3700618653205899501_n.jpg?oh=a954094e3068b61561cc224ca012b9a9&amp;oe=553E80D9&amp;__gda__=1429731468_0dd0e4c50503de57d712a487cab8d2fb\" alt=\"\" width=\"720\" height=\"420\" /></p>\n<p>This year there were four large Solstices in the US and one small but intense 3-day event in Leipzig. Each of them had a somewhat different audience and a different focus. Each was put on by local communities who I encouraged to put their own spin on it, bringing a mix of new and \"traditional\" songs. I've gotten some interesting feedback on which parts of Less Wrong culture resonate with which people.</p>\n<p>Solstices that I actively collaborated with and/or consulted on include:</p>\n<p><strong>Bay Area</strong> - The most explicitly Less Wrong-y and transhumanist Solstice this year. Approximately 130 attendees. I suspect had the largest choir leading songs. About half of the audience seemed to be from what I'd consider the collective Rationality community (i.e. EA/Less Wrong/CFAR) and half were \"friends of friends\" who were less Less Wrong-y.</p>\n<p style=\"padding-left: 30px;\">(<a href=\"https://docs.google.com/forms/d/1728C7i29GA13gZOFuSUPqSUrLhfM97iJ44-uIzvJ6FM/viewform\">If you went to the Bay Solstice, you can fill out the anonymous feedback form here</a>. If you don't have much time, at least answering the first couple questions would be helpful)</p>\n<p><strong>Seattle</strong> - Run by a mix of Less Wrong and EA types. It was a shorter ceremony but included additional activities like improv games, Non-Violent Communication workshops and other ways to break the ice and help people bond. There between 50-60 attendees.</p>\n<p style=\"padding-left: 30px;\">(<a href=\"http://goo.gl/forms/N6hqJfGBj3\">Feedback form for Seattle</a>)</p>\n<p><strong>San Diego </strong>- This was put on by Sunday Assembly and the local Coalition of Reason (a collection of secular/humanist/atheist groups), with no Less Wrong connection at all. They also had fewer songs, more stories and other group activities. This one had about 100 adult attendees and about 20 children. (Probably the most family friendly of the bunch).</p>\n<p><strong>Leipzig</strong> - This was a three day workshop, with around 20 people who worked collaboratively to design and run a ritual together, along with some highlight songs from the \"traditional\" Brighter Than Today program.</p>\n<p><strong>New York</strong> - I ran this personally, co-sponsored by Sunday Assembly and Ethical Culture. My goal with the event was to highlight important ideas I've learned from Less Wrong and Effective Altruism, framed in the language of the general secular movement. I also wanted to address particular issues affecting the New York Rationality community. We had 180 attendees, about half from the Rationality/EA communities and half from various secular communities.</p>\n<p style=\"padding-left: 30px;\">(<a href=\"https://docs.google.com/forms/d/1ly6DM-eGxRNDe_UulfUISx3Q3R7sFrceGa4WnN2xxuY/viewform\">If you went to the NYC Solstice, you can fill out the anonymous feedback form here</a>. Again, if you don't have much time, it's still helpful if you answer the first couple questions)</p>\n<h2>Washington Post Article</h2>\n<p>I was put in touch with a reporter who was excited to cover the Solstice's growth as secular holiday. She ended up attending the one in San Francisco. (We talked beforehand about how the Bay Area Solstice would be put on by a local community with a lot of Silicon Valley tech-entrepreneurship-types, how it'd likely have more of a focus on technology, and that they'd be trying out some sillier songs that I wasn't sure would work at a more mainstream event. She noted that she would focus on covering the growth of the holiday as a whole rather than focusing on the particular execution at the Bay Area event).</p>\n<p>She wrote an article for the Religious News Wire, which was picked up by the Washington Post website among other places. The article was extremely positive (although it mistakenly attributes some speeches to me which were actually given by locals). I mentioned that to her and she <a href=\"http://www.religionnews.com/2014/12/16/secular-solstice-good-goodness-sake/\">edited the original</a>, but the <a href=\"http://www.washingtonpost.com/national/religion/secular-solstice-doing-good-for-goodness-sake/2014/12/16/b9d55a5e-856a-11e4-abcf-5a3d7b3b20b8_story.html\">Washington Post had already picked up the earlier version</a>.<br /><br />A brief snippet:</p>\n<blockquote>\n<p><span style=\"color: #333333; font-family: OpenSansRegular, Arial, Helvetica, sans-serif; font-size: 14px; line-height: 23.7649993896484px;\">&ldquo;We live in a world beyond the reach of God,&rdquo; one of the service&rsquo;s many readers said as 130 or so people gathered huddled over white candles in glass votives at Humanist Hall &mdash; a purple-painted house near downtown Oakland. &ldquo;It is a hard universe. If we want to build a softer universe we will have to do it ourselves.&rdquo; As a choir broke into &ldquo;Here Comes the Sun,&rdquo;&nbsp;an inscription painted on the wall beamed down upon the gathered, &ldquo;The world is my country, to do good is my religion.&rdquo;<br /></span></p>\n</blockquote>\n<h2><br />Building a Better Solstice</h2>\n<p>I deliberately encourage experimentation with the format - real ritual evolves, and if we want <em>great</em>&nbsp;ritual (in particular, great ritual-for-your-particular-local-community, as opposed to great ritual-for-the-NYC-crowd that you're trying to emulate), we want to iterate faster, see what resonates with people, and let the less interesting variations die out.&nbsp;<br /><br />This year I'm working to ensure each local solstice does a feedback form and sends it out as soon as possible. I want to get a sense of what things resonate (or don't) fairly reliably across the world and what things happened to work for particular groups or small sample sizes.</p>\n<p>There's an obvious problem that a) the most likely people to fill out the survey are people who like the event, b) the second most likely people to fill out the survey are people who hate the event. If you felt the event was \"meh\" (and perhaps don't want to fill out an entire survey because you don't care that much), it'd still be helpful if you at least briefly answered the first couple questions, so we have a broader sense of what works.<br /><br />(And again, we definitely want negative feedback, in particular from people who want *something* similar to the Solstice but didn't like the execution of it)</p>\n<p>One thing that's clear is that transhumanist and LW content is polarizing, even within the Less Wrong crowd - some people really love it and it makes them feel connected and inspired. Others find it very offputting. It's possible that the best solution is to have multiple events that cater to different people. But I've also found it's very possible (albeit harder - it took me a couple years of practice) to make an event that works on multiple levels, resonating with the mainstream secular community with Easter eggs that are funny/sad/inspiring to people in the LW or Transhuman spheres.</p>\n<p>Another thing that's perhaps more surprising: people who don't know what Less Wrong or Transhumanism are&nbsp;<em>at all</em>&nbsp;tend to be perfectly fine with Less Wrong and a lot of Transhumanist content and can be pretty oblivious to even fairly direct anti-death messages. It's the people who <em>know</em>&nbsp;about the memesphere and either don't like it or are worried about their friends not liking it that are most uncomfortable. &nbsp;</p>\n<h2>What makes a&nbsp;<em>Secular</em>&nbsp;Solstice&trade;?</h2>\n<p>So, if experimentation is a core element of the whole endeavor, what makes something a Secular Solstice as opposed to a solstice-that-is-secular? Or any other non-theistic holiday? The previous attempt at a humanist holiday, <em>HumanLight</em>, hasn't really caught on, and I think that's largely because it's deliberately flexible - you can celebrate it on whatever day you want, with whatever traditions you want, so long as it ties in with humanity-as-a-force-for-good.<br /><br />Being <em>too </em>flexible or generic makes for a watered-down experience that nobody especially likes, or a collection of random experiences that don't have much in common with each other.</p>\n<p>So my answer is this:<br /><br />The core element of the Brighter Than Today Solstice is the emotional arc. It begins fun and upbeat. It turns somber, then sad, before turning uplifting and inspirational. It should lead people from light to darkness to light again, both literally and metaphorically.<br /><br />The single most important image people should imagine, when they are visualizing the solstice, is the Candlelit Story and the Moment of Darkness - a moment when all but one candle has been extinguished, and a story is told about the hardships we've faced and the hardships yet to come. The story should end giving people reason to hope, without resorting to comforting falsehoods.</p>\n<p>Then that candle is extinguished, and people sit in the darkness for a minute before the lights are rekindled and hope returns in earnest.<br /><br />The particular songs I've written and found are not essential, nor is even the idea of <em>music</em>&nbsp;itself necessarily. (Although I highly recommend it, and I highly recommend finding songs that fill similar purposes. You might not be a fan of the actual song <a href=\"http://humanistculture.bandcamp.com/track/brighter-than-today\">Brighter Than Today</a>, but it's very helpful to have some kind of emotionally uplifting piece that's rooted in an evidence-based worldview that lifts you out of the darkness).</p>\n<p>Some people actively dislike music or group singing, but still like the stories that take them through that arc. Some people like \"preachy\" content that gives people a call to action, and some people hate it and prefer more casual personal stories.</p>\n<p>I'm not sure how this holiday will evolve to best meet the needs of the rationalist community and the wider world, but there are many paths I can imagine it taking. I'm glad that the core concept has resonated with so many people, and looking forward to working together to make it better each year.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"vtozKm5BZ8gf6zd45": 1, "hXTqT62YDTTiqJfxG": 1, "izp6eeJJEg9v5zcur": 1, "zcvsZQWJBFK6SxK4K": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wTeEpNMok2eiAsTd5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 53, "extendedScore": null, "score": 0.000314, "legacy": true, "legacyId": "27769", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 37, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This'll be the first of a collection of posts about the growing Secular Solstice. This post gives an overview of what happened this year. Future posts will explore what types of Solstice content resonates with which people, what I've learned about how Less Wrong culture intersects with other cultures, and updates I've made about ritual as it relates to individuals as well as movement building.</em></p>\n<hr>\n<p><em></em>For the past three years, I've been spending the last several months of each year frantically writing songs, figuring out logistics, and promoting the New York Winter Solstice celebration for the Rationality and Secular communities in NYC.<br><br>This year... well, I did that too. But I also finally got to go a Solstice that I *wasn't* responsible for. I went to the Bay Area on December 13th, traveled straight from the airport to the dress rehearsal...</p>\n<p>...and I found a community coming together to create something meaningful. I walked into the hall and found some 30 or so people, with some stringing together lights, some people tying decorations around candles, a choir singing together... it felt very much like a genuine holiday coming together in an organic fashion.<br><br>(There was some squabbling about how to best perform particular songs... but it felt *very* much to me like <em>real holiday squabbling,</em>&nbsp;whenever a family of creative people with strong opinions on things get together, and I found it surprisingly heartwarming)<br><a id=\"more\"></a></p>\n<p><img src=\"https://web.archive.org/web/20141228063646im_/https://fbcdn-sphotos-a-a.akamaihd.net/hphotos-ak-xap1/v/t1.0-9/10846072_10152597113743299_3700618653205899501_n.jpg?oh=a954094e3068b61561cc224ca012b9a9&amp;oe=553E80D9&amp;__gda__=1429731468_0dd0e4c50503de57d712a487cab8d2fb\" alt=\"\" width=\"720\" height=\"420\"></p>\n<p>This year there were four large Solstices in the US and one small but intense 3-day event in Leipzig. Each of them had a somewhat different audience and a different focus. Each was put on by local communities who I encouraged to put their own spin on it, bringing a mix of new and \"traditional\" songs. I've gotten some interesting feedback on which parts of Less Wrong culture resonate with which people.</p>\n<p>Solstices that I actively collaborated with and/or consulted on include:</p>\n<p><strong>Bay Area</strong> - The most explicitly Less Wrong-y and transhumanist Solstice this year. Approximately 130 attendees. I suspect had the largest choir leading songs. About half of the audience seemed to be from what I'd consider the collective Rationality community (i.e. EA/Less Wrong/CFAR) and half were \"friends of friends\" who were less Less Wrong-y.</p>\n<p style=\"padding-left: 30px;\">(<a href=\"https://docs.google.com/forms/d/1728C7i29GA13gZOFuSUPqSUrLhfM97iJ44-uIzvJ6FM/viewform\">If you went to the Bay Solstice, you can fill out the anonymous feedback form here</a>. If you don't have much time, at least answering the first couple questions would be helpful)</p>\n<p><strong>Seattle</strong> - Run by a mix of Less Wrong and EA types. It was a shorter ceremony but included additional activities like improv games, Non-Violent Communication workshops and other ways to break the ice and help people bond. There between 50-60 attendees.</p>\n<p style=\"padding-left: 30px;\">(<a href=\"http://goo.gl/forms/N6hqJfGBj3\">Feedback form for Seattle</a>)</p>\n<p><strong>San Diego </strong>- This was put on by Sunday Assembly and the local Coalition of Reason (a collection of secular/humanist/atheist groups), with no Less Wrong connection at all. They also had fewer songs, more stories and other group activities. This one had about 100 adult attendees and about 20 children. (Probably the most family friendly of the bunch).</p>\n<p><strong>Leipzig</strong> - This was a three day workshop, with around 20 people who worked collaboratively to design and run a ritual together, along with some highlight songs from the \"traditional\" Brighter Than Today program.</p>\n<p><strong>New York</strong> - I ran this personally, co-sponsored by Sunday Assembly and Ethical Culture. My goal with the event was to highlight important ideas I've learned from Less Wrong and Effective Altruism, framed in the language of the general secular movement. I also wanted to address particular issues affecting the New York Rationality community. We had 180 attendees, about half from the Rationality/EA communities and half from various secular communities.</p>\n<p style=\"padding-left: 30px;\">(<a href=\"https://docs.google.com/forms/d/1ly6DM-eGxRNDe_UulfUISx3Q3R7sFrceGa4WnN2xxuY/viewform\">If you went to the NYC Solstice, you can fill out the anonymous feedback form here</a>. Again, if you don't have much time, it's still helpful if you answer the first couple questions)</p>\n<h2 id=\"Washington_Post_Article\">Washington Post Article</h2>\n<p>I was put in touch with a reporter who was excited to cover the Solstice's growth as secular holiday. She ended up attending the one in San Francisco. (We talked beforehand about how the Bay Area Solstice would be put on by a local community with a lot of Silicon Valley tech-entrepreneurship-types, how it'd likely have more of a focus on technology, and that they'd be trying out some sillier songs that I wasn't sure would work at a more mainstream event. She noted that she would focus on covering the growth of the holiday as a whole rather than focusing on the particular execution at the Bay Area event).</p>\n<p>She wrote an article for the Religious News Wire, which was picked up by the Washington Post website among other places. The article was extremely positive (although it mistakenly attributes some speeches to me which were actually given by locals). I mentioned that to her and she <a href=\"http://www.religionnews.com/2014/12/16/secular-solstice-good-goodness-sake/\">edited the original</a>, but the <a href=\"http://www.washingtonpost.com/national/religion/secular-solstice-doing-good-for-goodness-sake/2014/12/16/b9d55a5e-856a-11e4-abcf-5a3d7b3b20b8_story.html\">Washington Post had already picked up the earlier version</a>.<br><br>A brief snippet:</p>\n<blockquote>\n<p><span style=\"color: #333333; font-family: OpenSansRegular, Arial, Helvetica, sans-serif; font-size: 14px; line-height: 23.7649993896484px;\">\u201cWe live in a world beyond the reach of God,\u201d one of the service\u2019s many readers said as 130 or so people gathered huddled over white candles in glass votives at Humanist Hall \u2014 a purple-painted house near downtown Oakland. \u201cIt is a hard universe. If we want to build a softer universe we will have to do it ourselves.\u201d As a choir broke into \u201cHere Comes the Sun,\u201d&nbsp;an inscription painted on the wall beamed down upon the gathered, \u201cThe world is my country, to do good is my religion.\u201d<br></span></p>\n</blockquote>\n<h2 id=\"Building_a_Better_Solstice\"><br>Building a Better Solstice</h2>\n<p>I deliberately encourage experimentation with the format - real ritual evolves, and if we want <em>great</em>&nbsp;ritual (in particular, great ritual-for-your-particular-local-community, as opposed to great ritual-for-the-NYC-crowd that you're trying to emulate), we want to iterate faster, see what resonates with people, and let the less interesting variations die out.&nbsp;<br><br>This year I'm working to ensure each local solstice does a feedback form and sends it out as soon as possible. I want to get a sense of what things resonate (or don't) fairly reliably across the world and what things happened to work for particular groups or small sample sizes.</p>\n<p>There's an obvious problem that a) the most likely people to fill out the survey are people who like the event, b) the second most likely people to fill out the survey are people who hate the event. If you felt the event was \"meh\" (and perhaps don't want to fill out an entire survey because you don't care that much), it'd still be helpful if you at least briefly answered the first couple questions, so we have a broader sense of what works.<br><br>(And again, we definitely want negative feedback, in particular from people who want *something* similar to the Solstice but didn't like the execution of it)</p>\n<p>One thing that's clear is that transhumanist and LW content is polarizing, even within the Less Wrong crowd - some people really love it and it makes them feel connected and inspired. Others find it very offputting. It's possible that the best solution is to have multiple events that cater to different people. But I've also found it's very possible (albeit harder - it took me a couple years of practice) to make an event that works on multiple levels, resonating with the mainstream secular community with Easter eggs that are funny/sad/inspiring to people in the LW or Transhuman spheres.</p>\n<p>Another thing that's perhaps more surprising: people who don't know what Less Wrong or Transhumanism are&nbsp;<em>at all</em>&nbsp;tend to be perfectly fine with Less Wrong and a lot of Transhumanist content and can be pretty oblivious to even fairly direct anti-death messages. It's the people who <em>know</em>&nbsp;about the memesphere and either don't like it or are worried about their friends not liking it that are most uncomfortable. &nbsp;</p>\n<h2 id=\"What_makes_a_Secular_Solstice__\">What makes a&nbsp;<em>Secular</em>&nbsp;Solstice\u2122?</h2>\n<p>So, if experimentation is a core element of the whole endeavor, what makes something a Secular Solstice as opposed to a solstice-that-is-secular? Or any other non-theistic holiday? The previous attempt at a humanist holiday, <em>HumanLight</em>, hasn't really caught on, and I think that's largely because it's deliberately flexible - you can celebrate it on whatever day you want, with whatever traditions you want, so long as it ties in with humanity-as-a-force-for-good.<br><br>Being <em>too </em>flexible or generic makes for a watered-down experience that nobody especially likes, or a collection of random experiences that don't have much in common with each other.</p>\n<p>So my answer is this:<br><br>The core element of the Brighter Than Today Solstice is the emotional arc. It begins fun and upbeat. It turns somber, then sad, before turning uplifting and inspirational. It should lead people from light to darkness to light again, both literally and metaphorically.<br><br>The single most important image people should imagine, when they are visualizing the solstice, is the Candlelit Story and the Moment of Darkness - a moment when all but one candle has been extinguished, and a story is told about the hardships we've faced and the hardships yet to come. The story should end giving people reason to hope, without resorting to comforting falsehoods.</p>\n<p>Then that candle is extinguished, and people sit in the darkness for a minute before the lights are rekindled and hope returns in earnest.<br><br>The particular songs I've written and found are not essential, nor is even the idea of <em>music</em>&nbsp;itself necessarily. (Although I highly recommend it, and I highly recommend finding songs that fill similar purposes. You might not be a fan of the actual song <a href=\"http://humanistculture.bandcamp.com/track/brighter-than-today\">Brighter Than Today</a>, but it's very helpful to have some kind of emotionally uplifting piece that's rooted in an evidence-based worldview that lifts you out of the darkness).</p>\n<p>Some people actively dislike music or group singing, but still like the stories that take them through that arc. Some people like \"preachy\" content that gives people a call to action, and some people hate it and prefer more casual personal stories.</p>\n<p>I'm not sure how this holiday will evolve to best meet the needs of the rationalist community and the wider world, but there are many paths I can imagine it taking. I'm glad that the core concept has resonated with so many people, and looking forward to working together to make it better each year.</p>", "sections": [{"title": "Washington Post Article", "anchor": "Washington_Post_Article", "level": 1}, {"title": "Building a Better Solstice", "anchor": "Building_a_Better_Solstice", "level": 1}, {"title": "What makes a\u00a0Secular\u00a0Solstice\u2122?", "anchor": "What_makes_a_Secular_Solstice__", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "48 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-23T18:45:41.421Z", "modifiedAt": null, "url": null, "title": "MIRI's technical research agenda", "slug": "miri-s-technical-research-agenda", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:33.650Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "So8res", "createdAt": "2012-01-10T05:50:18.713Z", "isAdmin": false, "displayName": "So8res"}, "userId": "xSfc2APSi8WzFxp7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/d3gMZmSSAHXaGisyJ/miri-s-technical-research-agenda", "pageUrlRelative": "/posts/d3gMZmSSAHXaGisyJ/miri-s-technical-research-agenda", "linkUrl": "https://www.lesswrong.com/posts/d3gMZmSSAHXaGisyJ/miri-s-technical-research-agenda", "postedAtFormatted": "Tuesday, December 23rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20MIRI's%20technical%20research%20agenda&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMIRI's%20technical%20research%20agenda%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd3gMZmSSAHXaGisyJ%2Fmiri-s-technical-research-agenda%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=MIRI's%20technical%20research%20agenda%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd3gMZmSSAHXaGisyJ%2Fmiri-s-technical-research-agenda", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd3gMZmSSAHXaGisyJ%2Fmiri-s-technical-research-agenda", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 804, "htmlBody": "<p>I'm pleased to announce the release of <a href=\"http://intelligence.org/files/TechnicalAgenda.pdf\">Aligning Superintelligence with Human Interests: A Technical Research Agenda</a>&nbsp;written by Benja and I (with help and input from many, many others). This document summarizes and motivates MIRI's current technical research agenda.</p>\n<p>I'm happy to answer questions about this document, but expect slow response times, as I'm travelling for the holidays. The introduction of the paper is included below. (See the paper for references.)</p>\n<p><a id=\"more\"></a></p>\n<hr />\n<p>The characteristic that has enabled humanity to shape the world is not strength, not speed, but intelligence. Barring catastrophe, it seems clear that progress in AI will one day lead to the creation of agents meeting or exceeding human-level general intelligence, and this will likely lead to the eventual development of systems which are \"superintelligent'' in the sense of being \"smarter than the best human brains in practically every field\" (Bostrom 2014). A superintelligent system could have an enormous impact upon humanity: just as human intelligence has allowed the development of tools and strategies that let humans control the environment to an unprecedented degree, a superintelligent system would likely be capable of developing tools and strategies that give it extraordinary power (Muehlhauser and Salamon 2012). In light of this potential, it is essential to use caution when developing artificially intelligent systems capable of attaining or creating superintelligence.</p>\n<p>There is no reason to expect artificial agents to be driven by human motivations such as lust for power, but almost all goals can be better met with more resources (Omohundro 2008). This suggests that, by default, superintelligent agents would have incentives to acquire resources currently being used by humanity. (Can't we share? Likely not: there is no reason to expect artificial agents to be driven by human motivations such as fairness, compassion, or conservatism.) Thus, most goals would put the agent at odds with human interests, giving it incentives to deceive or manipulate its human operators and resist interventions designed to change or debug its behavior (Bostrom 2014, chap. 8).</p>\n<p>Care must be taken to avoid constructing systems that exhibit this default behavior. In order to ensure that the development of smarter-than-human intelligence has a positive impact on humanity, we must meet three formidable challenges: How can we create an agent that will reliably pursue the goals it is given? How can we formally specify beneficial goals? And how can we ensure that this agent will assist and cooperate with its programmers as they improve its design, given that mistakes in the initial version are inevitable?</p>\n<p>This agenda discusses technical research that is tractable today, which the authors think will make it easier to confront these three challenges in the future. Sections 2 through 4 motivate and discuss six research topics that we think are relevant to these challenges. Section 5 discusses our reasons for selecting these six areas in particular.</p>\n<p>We call a smarter-than-human system that reliably pursues beneficial goals \"aligned with human interests\" or simply \"aligned.\" To become confident that an agent is aligned in this way, a practical implementation that merely <em>seems</em> to meet the challenges outlined above will not suffice. It is also necessary to gain a solid theoretical understanding of why that confidence is justified. This technical agenda argues that there is foundational research approachable today that will make it easier to develop aligned systems in the future, and describes ongoing work on some of these problems.</p>\n<p>Of the three challenges, the one giving rise to the largest number of currently tractable research questions is the challenge of finding an agent architecture that will reliably pursue the goals it is given&mdash;that is, an architecture which is alignable in the first place. This requires theoretical knowledge of how to design agents which reason well and behave as intended even in situations never envisioned by the programmers. The problem of highly reliable agent designs is discussed in Section 2.</p>\n<p>The challenge of developing agent designs which are tolerant of human error has also yielded a number of tractable problems. We argue that smarter-than-human systems would by default have incentives to manipulate and deceive the human operators. Therefore, special care must be taken to develop agent architectures which avert these incentives and are otherwise tolerant of programmer error. This problem and some related open questions are discussed in Section 3.</p>\n<p>Reliable, error-tolerant agent designs are only beneficial if they are aligned with human interests. The difficulty of concretely specifying what is meant by \"beneficial behavior\" implies a need for some way to construct agents that reliably <em>learn</em>&nbsp;what to value (Bostrom 2014, chap. 12). A solution to this \"value learning'' problem is vital; attempts to start making progress are reviewed in Section 4.</p>\n<p>Why these problems? Why now? Section 5 answers these questions and others. In short, the authors believe that there is theoretical research which can be done today that will make it easier to design aligned smarter-than-human systems in the future.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NrvXXL3iGjjxu5B7d": 2, "Z38PqJbRyfwCxKvvL": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "d3gMZmSSAHXaGisyJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 54, "extendedScore": null, "score": 2.2973171088556644e-06, "legacy": true, "legacyId": "27768", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-23T23:27:25.856Z", "modifiedAt": null, "url": null, "title": "LINK: Nematode brain uploaded with success", "slug": "link-nematode-brain-uploaded-with-success", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.460Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "polymathwannabe", "createdAt": "2013-08-29T03:03:37.800Z", "isAdmin": false, "displayName": "polymathwannabe"}, "userId": "NkxHWoA85iw2PpxSt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fjjhhDLdrDu6tBa8g/link-nematode-brain-uploaded-with-success", "pageUrlRelative": "/posts/fjjhhDLdrDu6tBa8g/link-nematode-brain-uploaded-with-success", "linkUrl": "https://www.lesswrong.com/posts/fjjhhDLdrDu6tBa8g/link-nematode-brain-uploaded-with-success", "postedAtFormatted": "Tuesday, December 23rd 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20Nematode%20brain%20uploaded%20with%20success&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20Nematode%20brain%20uploaded%20with%20success%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfjjhhDLdrDu6tBa8g%2Flink-nematode-brain-uploaded-with-success%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20Nematode%20brain%20uploaded%20with%20success%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfjjhhDLdrDu6tBa8g%2Flink-nematode-brain-uploaded-with-success", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfjjhhDLdrDu6tBa8g%2Flink-nematode-brain-uploaded-with-success", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<p>The connectome for the 302 neurons of the nematode <em>C. elegans</em> was put in charge of a Lego robot. Without any additional programming, the simulated brain started using the robot parts just like the original worm's organs.</p>\n<p><a href=\"http://www.sciencealert.com/watch-scientists-have-put-a-worm-s-brain-into-a-lego-robot-s-body-and-it-works\">\"When you think about it, the brain is really nothing more than a collection of electrical signals.\"</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fjjhhDLdrDu6tBa8g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 4, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "27771", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-24T00:54:43.612Z", "modifiedAt": null, "url": null, "title": "Nth_Level_Player", "slug": "nth_level_player", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:35.301Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Minds_Eye", "createdAt": "2013-11-21T18:02:19.971Z", "isAdmin": false, "displayName": "Minds_Eye"}, "userId": "eLSSTrxtHA8LaWr9g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QdJLDpZWvhGTJ78mh/nth_level_player", "pageUrlRelative": "/posts/QdJLDpZWvhGTJ78mh/nth_level_player", "linkUrl": "https://www.lesswrong.com/posts/QdJLDpZWvhGTJ78mh/nth_level_player", "postedAtFormatted": "Wednesday, December 24th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Nth_Level_Player&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANth_Level_Player%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQdJLDpZWvhGTJ78mh%2Fnth_level_player%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Nth_Level_Player%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQdJLDpZWvhGTJ78mh%2Fnth_level_player", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQdJLDpZWvhGTJ78mh%2Fnth_level_player", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1570, "htmlBody": "<p>In a recent <a title=\"Understanding Agency\" href=\"/lw/lej/understanding_agency/\" target=\"_self\">post</a> Gwerley covered Constructive Developmental Theory, and Subject-Object Notation.&nbsp; I'll be going through a basic&nbsp;description of the ideas, as well as adding related ideas from the Four Player Model.</p>\r\n<hr />\r\n<h2><a name=\"CDT\"></a><a title=\"An Overview of Constructive Developmental Theory - Robert Kegan\" href=\"http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/\" target=\"_blank\">Constructive Developmental Theory</a>:</h2>\r\n<p><a title=\"An Overview of Constructive Developmental Theory - Robert Kegan\" href=\"http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/\" target=\"_blank\">Constructive Developmental Theory</a> is a Theory of Mind that splits the development of people into five levels, though the levels each have a unique set of advantages/disadvantages, not being \"better\" or \"worse\" than one another.<sup>1</sup>&nbsp; This theory is largely based on if the individual is subject to something or able to hold it as an object using meta cognition, such that each level holds the previous levels as special cases.<sup>2</sup>&nbsp; This progress makes it so a higher order mind will notice things a lower order cannot.</p>\r\n<ul>\r\n<li>\r\n<h2>First Order/The Impulsive Mind</h2>\r\n<ul>\r\n<li>An impulsive mind has only it's reflexes as an object.</li>\r\n<li>At this level an organism<sup>3</sup> is still sorting out sensory input,&nbsp;and does not yet have a theory of mind.</li>\r\n</ul>\r\n</li>\r\n<li>\r\n<h2>Second Order/The Instrumental Mind</h2>\r\n<ul>\r\n<li>As an Instrumental Mind the being is able to understand the difference between self and other. </li>\r\n<li>Though second order minds understand the concept of self they are subject to their wants, needs and desires.<sup>4</sup> </li>\r\n<li>At this level the person has only one viewpoint. (Solipsism) </li>\r\n</ul>\r\n</li>\r\n<li>\r\n<h2>Third Order/The Socialized Mind</h2>\r\n<ul>\r\n<li>The Socialized mind is able to hold as an object their emotions, needs and desires.</li>\r\n<li>This level is subject to cultural in-group/out-group pressures.</li>\r\n<li>They are defined by their relation to society.<ol>\r\n<li>This relation makes them susceptible to the wants and needs of others, making them likely to try and do/say what [they think] others want.</li>\r\n<li>Their reliance on society and authority makes them good followers.</li>\r\n</ol></li>\r\n<li>58% of adults are on this level.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>*With the bulk of people being on this level it's important to keep status with them.&nbsp; Failure to do so risks loosing momentum on any movement you're working on. (Trans humanism, Cryonics or FAI being the three that jump to mind with this community.)</p>\r\n<ul>\r\n<li>\r\n<h2>Fourth Order/The Self-Authoring Mind</h2>\r\n<ul>\r\n<li>The Self-Authoring Mind is able to hold as an object the environment it belongs to.&nbsp; </li>\r\n<li>Self-Authors are still subject to their own ideologies. </li>\r\n<li>They are defined by what they think of themselves in relation to their ideologies as a static unchanging state dependent on their ideology. (The \"self\" can change if the ideology does.) <ol>\r\n<li>This makes them able thinkers. (Provided they have knowledge of the subject matter.) allowing them to oppose things they think are wrong as their sense of self is not dependent on their relation to the community. </li>\r\n<li>This freethinking also makes them hesitant followers unless they reach the same conclusions on their own.&nbsp; </li>\r\n</ol></li>\r\n</ul>\r\n<ul>\r\n<li>35% of adults are on this level</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>*While less essential than Socialized Minds, Self-Authoring Minds are a good indicator that your movement is healthy and still able to adapt to changes.&nbsp; Being the primary source of said changes fourth order minds are important in order to avoid things like an Ann Rand cult.</p>\r\n<ul>\r\n<li>\r\n<h2>Fifth Order/The Self-Transforming Mind <br /></h2>\r\n<ul>\r\n<li>The Self-Transforming Mind is able to hold as an object the relation between ideologies, including their own.&nbsp; </li>\r\n<li>This subjects them to the relation between the ideologies, and the search for a solution to their contradictions. <br /><ol>\r\n<li>The Self-Transforming Mind is the point at which much of the advice on this site start to make sense as something other than just \"it just works.\"</li>\r\n<li>It allows changes to self akin to harry's occlumancy training in HPMOR \"Anyone you can imagine you can be.\"&nbsp; </li>\r\n</ol></li>\r\n</ul>\r\n<ul>\r\n<li>1% of adults are on this level</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>&nbsp;*The most useful and the least essential of the groups.&nbsp; They are able to fill any role needed, but are made fully redundant by a enough lower order minds in the necessary roles.</p>\r\n<p><sup>5</sup>I was unable to find the six percent not accounted for above.</p>\r\n<hr />\r\n<h2><a name=\"Subject/Object\"></a><a title=\"Subject-Object Notation, A Case Study of Defensiveness and Curiosity - Malcolm Ocean\" href=\"http://malcolmocean.com/2014/10/subject-object-notation/\" target=\"_blank\">Subject Object Notation</a>:</h2>\r\n<p><a title=\"Subject-Object Notation, A Case Study of Defensiveness and Curiosity - Malcolm Ocean\" href=\"http://malcolmocean.com/2014/10/subject-object-notation/\" target=\"_blank\">Subject-Object Notation</a> is a way of showing where relative to two incompatible ideas you are.&nbsp; For example:</p>\r\n<p><strong>The Instrumental Mind</strong> (2) and <strong>The Socialized Mind</strong>&nbsp;(3)</p>\r\n<ul>\r\n<li>2: At this level one will view the world as self and other, unable to make further differentiation when trying to understand motivations and information. (Solipsism)</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>2(3): They understand that others have thoughts and feelings, but they are unable to understand them.</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>2/3: Those they are close to can be partially understood, but much is lost in the primitive understanding of others.</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>3/2: This is the tipping point between other people think things differently from me, and this person thinks this, that person thinks that, and I think this.&nbsp; This change also incurs the shift from self-centered to belonging to the tribe.</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>3(2): This level allows generalization across large groups and focus on the individual.&nbsp; While still occasionally self-centered an individual at this level will be aware of and bend to social pressure.</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<ul>\r\n<li>3: At this level a person is able to understand the various different motivations of others, however they are subject to tribal status, being defined by what others think of them, and treating an entire out-group as homogenous.&nbsp; (Republicans are so.../Democrats are so.../Religious people are so.../atheists are so...)</li>\r\n</ul>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>Using Subject-Object Notation on&nbsp;Constructive Developmental Theory yields 21 unique \"levels\" of development.</p>\r\n<p>&nbsp;</p>\r\n<p>1 1(2) 1/2 2/1 2(1)</p>\r\n<p>2 2(3) 2/3 3/2 3(2)</p>\r\n<p>3 3(4) 3/4 4/3 4(3)</p>\r\n<p>4 4(5) 4/5 5/4 5(4)</p>\r\n<p>5</p>\r\n<hr />\r\n<h2><a name=\"Four Player\"></a><a title=\"Four Player Model - Kantor\" href=\"http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/\" target=\"_blank\">Four Player Model</a>:</h2>\r\n<p>Movers: The ones making changes to the current group behaviour.</p>\r\n<p>Follower: Those who are continuing the current move.</p>\r\n<p>Opposers: Those correcting the current move.</p>\r\n<p>Bystanders: The ones watching for anything else the group should be looking out for.</p>\r\n<table style=\"width: 100%;\" border=\"1\" cellspacing=\"3\" cellpadding=\"3\">\r\n<tbody>\r\n<tr>\r\n<td width=\"70\" valign=\"top\">&nbsp;</td>\r\n<td width=\"185\" valign=\"top\">\r\n<h2 style=\"text-align: center;\"><span style=\"color: #000000;\">Socialized Mind</span></h2>\r\n</td>\r\n<td width=\"186\" valign=\"top\">\r\n<h2 style=\"text-align: center;\"><span style=\"color: #000000;\">Self-Authoring Mind</span></h2>\r\n</td>\r\n<td width=\"185\" valign=\"top\">\r\n<h2 style=\"text-align: center;\"><span style=\"color: #000000;\">Self-Transforming Mind</span></h2>\r\n</td>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\">\r\n<h2>Moving</h2>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">\r\n<p>This a rare state for a Socialized Mind.&nbsp; The inherent risk to status makes even potentially large gains less appealing.</p>\r\n</td>\r\n<td width=\"186\" align=\"left\" valign=\"top\">\r\n<p>A natural role for a Self-Authoring Mind, being independent of the group allows them to propose changes, though that is limited by their beliefs and ideologies.</p>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">\r\n<p>Much the same as Self-Authors Self-Transformers are&nbsp;suitable for&nbsp;filling the role of mover, though with&nbsp;larger amounts of resources to draw from.</p>\r\n</td>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\">\r\n<h2>Following</h2>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">\r\n<p>At this level people are defined by tribal status making them excellent followers.</p>\r\n</td>\r\n<td width=\"186\" align=\"left\" valign=\"top\">\r\n<p>Following is not a role a level 4 will fall into unless they arrive at the conclusion on their own.</p>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">\r\n<p>While not as difficult as it was as a Self-Author following is still the weakest point of the higher levels due largely to the&nbsp;absence of cultural influence in personal thought.</p>\r\n</td>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\">\r\n<h2>Opposing</h2>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">\r\n<p>Individuals at this level do not oppose without prompting, and will likely try to smooth over any mover/Opposer conflict.</p>\r\n</td>\r\n<td width=\"186\" align=\"left\" valign=\"top\">\r\n<p>At least as much as Moving, Opposing suits a 4th order mind, because even if they agree they are able to play Devil's Advocate as disagreement doesn't undermine their sense of self.</p>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">Opposing is a role Transforming Minds fill with little work.&nbsp; The vast amount of viewpoints they can hold allow them to freely choose a good response to Movers.</td>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\">\r\n<h2>Bystanding</h2>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">\r\n<p>Similar to opposing third order minds don't make very good bystanders, as that would necessitate leaving the group thought process that defines them.</p>\r\n</td>\r\n<td width=\"186\" align=\"left\" valign=\"top\">\r\n<p>A Self-Author is a suitable, if slightly biased, Bystander for much the same reason they are good Opposers.</p>\r\n</td>\r\n<td width=\"185\" align=\"left\" valign=\"top\">This is the role that this level truly excels in due to the shear number of viewpoints they are able to use.</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>&nbsp;</p>\r\n<hr />\r\n<p>Authors Notes:</p>\r\n<p><sup>1</sup>The lack of \"better\" levels seems to indicate that each level is a local optima with at least&nbsp;a few required for a stable society.</p>\r\n<p><sup>2</sup>This would seem to indicate that higher orders are capable of everything that a lower order is, motivation not withstanding.</p>\r\n<p><sup>3</sup>This level includes both human&nbsp;babies and animals.</p>\r\n<p><sup>4</sup>In addition to children some animals have pack/herd/pod mentalities that would appear to be at least 2(3).</p>\r\n<p><sup>5</sup>I would predict 5+ percent in level 2, and only the wild children in level 1, (those children who are raised by wild animals) with even some of them as level 2.</p>\r\n<p>*This is the relation to <a title=\"Kantor's Four player Model Through the Lends of CDT\" href=\"http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/\" target=\"_blank\">Four Player Model</a></p>\r\n<hr />\r\n<p>Attributions:</p>\r\n<p><a href=\"http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/\">http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/</a>&nbsp;- Three highest levels of CDT</p>\r\n<p><a href=\"http://sustainabilitythinking.wordpress.com/2012/06/09/constructive-developmental-theory/\">http://sustainabilitythinking.wordpress.com/2012/06/09/constructive-developmental-theory/</a>&nbsp;- less detailed description of all five</p>\r\n<p><a href=\"http://developmentalobserver.blog.com/2011/06/08/additional-resources-on-adult-development/\">http://developmentalobserver.blog.com/2011/06/08/additional-resources-on-adult-development/</a>&nbsp;- Assorted links</p>\r\n<p><a href=\"http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/\">http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/</a>&nbsp;- Kantor's Four Player Model</p>\r\n<p><a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">http://malcolmocean.com/2014/10/subject-object-notation/</a>&nbsp;- Subject-Object Notation</p>\r\n<p><a href=\"http://www.ccl.org/leadership/pdf/landing/constructivedevtheory.pdf\" target=\"_blank\">http://www.ccl.org/leadership/pdf/landing/constructivedevtheory.pdf</a> - CDT more in depth</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QdJLDpZWvhGTJ78mh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -7, "extendedScore": null, "score": 2.2981618063368854e-06, "legacy": true, "legacyId": "27747", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In a recent <a title=\"Understanding Agency\" href=\"/lw/lej/understanding_agency/\" target=\"_self\">post</a> Gwerley covered Constructive Developmental Theory, and Subject-Object Notation.&nbsp; I'll be going through a basic&nbsp;description of the ideas, as well as adding related ideas from the Four Player Model.</p>\n<hr>\n<h2 id=\"Constructive_Developmental_Theory_\"><a name=\"CDT\"></a><a title=\"An Overview of Constructive Developmental Theory - Robert Kegan\" href=\"http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/\" target=\"_blank\">Constructive Developmental Theory</a>:</h2>\n<p><a title=\"An Overview of Constructive Developmental Theory - Robert Kegan\" href=\"http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/\" target=\"_blank\">Constructive Developmental Theory</a> is a Theory of Mind that splits the development of people into five levels, though the levels each have a unique set of advantages/disadvantages, not being \"better\" or \"worse\" than one another.<sup>1</sup>&nbsp; This theory is largely based on if the individual is subject to something or able to hold it as an object using meta cognition, such that each level holds the previous levels as special cases.<sup>2</sup>&nbsp; This progress makes it so a higher order mind will notice things a lower order cannot.</p>\n<ul>\n<li>\n<h2 id=\"First_Order_The_Impulsive_Mind\">First Order/The Impulsive Mind</h2>\n<ul>\n<li>An impulsive mind has only it's reflexes as an object.</li>\n<li>At this level an organism<sup>3</sup> is still sorting out sensory input,&nbsp;and does not yet have a theory of mind.</li>\n</ul>\n</li>\n<li>\n<h2 id=\"Second_Order_The_Instrumental_Mind\">Second Order/The Instrumental Mind</h2>\n<ul>\n<li>As an Instrumental Mind the being is able to understand the difference between self and other. </li>\n<li>Though second order minds understand the concept of self they are subject to their wants, needs and desires.<sup>4</sup> </li>\n<li>At this level the person has only one viewpoint. (Solipsism) </li>\n</ul>\n</li>\n<li>\n<h2 id=\"Third_Order_The_Socialized_Mind\">Third Order/The Socialized Mind</h2>\n<ul>\n<li>The Socialized mind is able to hold as an object their emotions, needs and desires.</li>\n<li>This level is subject to cultural in-group/out-group pressures.</li>\n<li>They are defined by their relation to society.<ol>\n<li>This relation makes them susceptible to the wants and needs of others, making them likely to try and do/say what [they think] others want.</li>\n<li>Their reliance on society and authority makes them good followers.</li>\n</ol></li>\n<li>58% of adults are on this level.</li>\n</ul>\n</li>\n</ul>\n<p>*With the bulk of people being on this level it's important to keep status with them.&nbsp; Failure to do so risks loosing momentum on any movement you're working on. (Trans humanism, Cryonics or FAI being the three that jump to mind with this community.)</p>\n<ul>\n<li>\n<h2 id=\"Fourth_Order_The_Self_Authoring_Mind\">Fourth Order/The Self-Authoring Mind</h2>\n<ul>\n<li>The Self-Authoring Mind is able to hold as an object the environment it belongs to.&nbsp; </li>\n<li>Self-Authors are still subject to their own ideologies. </li>\n<li>They are defined by what they think of themselves in relation to their ideologies as a static unchanging state dependent on their ideology. (The \"self\" can change if the ideology does.) <ol>\n<li>This makes them able thinkers. (Provided they have knowledge of the subject matter.) allowing them to oppose things they think are wrong as their sense of self is not dependent on their relation to the community. </li>\n<li>This freethinking also makes them hesitant followers unless they reach the same conclusions on their own.&nbsp; </li>\n</ol></li>\n</ul>\n<ul>\n<li>35% of adults are on this level</li>\n</ul>\n</li>\n</ul>\n<p>*While less essential than Socialized Minds, Self-Authoring Minds are a good indicator that your movement is healthy and still able to adapt to changes.&nbsp; Being the primary source of said changes fourth order minds are important in order to avoid things like an Ann Rand cult.</p>\n<ul>\n<li>\n<h2 id=\"Fifth_Order_The_Self_Transforming_Mind_\">Fifth Order/The Self-Transforming Mind <br></h2>\n<ul>\n<li>The Self-Transforming Mind is able to hold as an object the relation between ideologies, including their own.&nbsp; </li>\n<li>This subjects them to the relation between the ideologies, and the search for a solution to their contradictions. <br><ol>\n<li>The Self-Transforming Mind is the point at which much of the advice on this site start to make sense as something other than just \"it just works.\"</li>\n<li>It allows changes to self akin to harry's occlumancy training in HPMOR \"Anyone you can imagine you can be.\"&nbsp; </li>\n</ol></li>\n</ul>\n<ul>\n<li>1% of adults are on this level</li>\n</ul>\n</li>\n</ul>\n<p>&nbsp;*The most useful and the least essential of the groups.&nbsp; They are able to fill any role needed, but are made fully redundant by a enough lower order minds in the necessary roles.</p>\n<p><sup>5</sup>I was unable to find the six percent not accounted for above.</p>\n<hr>\n<h2 id=\"Subject_Object_Notation_\"><a name=\"Subject/Object\"></a><a title=\"Subject-Object Notation, A Case Study of Defensiveness and Curiosity - Malcolm Ocean\" href=\"http://malcolmocean.com/2014/10/subject-object-notation/\" target=\"_blank\">Subject Object Notation</a>:</h2>\n<p><a title=\"Subject-Object Notation, A Case Study of Defensiveness and Curiosity - Malcolm Ocean\" href=\"http://malcolmocean.com/2014/10/subject-object-notation/\" target=\"_blank\">Subject-Object Notation</a> is a way of showing where relative to two incompatible ideas you are.&nbsp; For example:</p>\n<p><strong>The Instrumental Mind</strong> (2) and <strong>The Socialized Mind</strong>&nbsp;(3)</p>\n<ul>\n<li>2: At this level one will view the world as self and other, unable to make further differentiation when trying to understand motivations and information. (Solipsism)</li>\n</ul>\n<p>&nbsp;</p>\n<ul>\n<li>2(3): They understand that others have thoughts and feelings, but they are unable to understand them.</li>\n</ul>\n<p>&nbsp;</p>\n<ul>\n<li>2/3: Those they are close to can be partially understood, but much is lost in the primitive understanding of others.</li>\n</ul>\n<p>&nbsp;</p>\n<ul>\n<li>3/2: This is the tipping point between other people think things differently from me, and this person thinks this, that person thinks that, and I think this.&nbsp; This change also incurs the shift from self-centered to belonging to the tribe.</li>\n</ul>\n<p>&nbsp;</p>\n<ul>\n<li>3(2): This level allows generalization across large groups and focus on the individual.&nbsp; While still occasionally self-centered an individual at this level will be aware of and bend to social pressure.</li>\n</ul>\n<p>&nbsp;</p>\n<ul>\n<li>3: At this level a person is able to understand the various different motivations of others, however they are subject to tribal status, being defined by what others think of them, and treating an entire out-group as homogenous.&nbsp; (Republicans are so.../Democrats are so.../Religious people are so.../atheists are so...)</li>\n</ul>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Using Subject-Object Notation on&nbsp;Constructive Developmental Theory yields 21 unique \"levels\" of development.</p>\n<p>&nbsp;</p>\n<p>1 1(2) 1/2 2/1 2(1)</p>\n<p>2 2(3) 2/3 3/2 3(2)</p>\n<p>3 3(4) 3/4 4/3 4(3)</p>\n<p>4 4(5) 4/5 5/4 5(4)</p>\n<p>5</p>\n<hr>\n<h2 id=\"Four_Player_Model_\"><a name=\"Four Player\"></a><a title=\"Four Player Model - Kantor\" href=\"http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/\" target=\"_blank\">Four Player Model</a>:</h2>\n<p>Movers: The ones making changes to the current group behaviour.</p>\n<p>Follower: Those who are continuing the current move.</p>\n<p>Opposers: Those correcting the current move.</p>\n<p>Bystanders: The ones watching for anything else the group should be looking out for.</p>\n<table style=\"width: 100%;\" border=\"1\" cellspacing=\"3\" cellpadding=\"3\">\n<tbody>\n<tr>\n<td width=\"70\" valign=\"top\">&nbsp;</td>\n<td width=\"185\" valign=\"top\">\n<h2 style=\"text-align: center;\" id=\"Socialized_Mind\"><span style=\"color: #000000;\">Socialized Mind</span></h2>\n</td>\n<td width=\"186\" valign=\"top\">\n<h2 style=\"text-align: center;\" id=\"Self_Authoring_Mind\"><span style=\"color: #000000;\">Self-Authoring Mind</span></h2>\n</td>\n<td width=\"185\" valign=\"top\">\n<h2 style=\"text-align: center;\" id=\"Self_Transforming_Mind\"><span style=\"color: #000000;\">Self-Transforming Mind</span></h2>\n</td>\n</tr>\n<tr>\n<td valign=\"top\">\n<h2 id=\"Moving\">Moving</h2>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">\n<p>This a rare state for a Socialized Mind.&nbsp; The inherent risk to status makes even potentially large gains less appealing.</p>\n</td>\n<td width=\"186\" align=\"left\" valign=\"top\">\n<p>A natural role for a Self-Authoring Mind, being independent of the group allows them to propose changes, though that is limited by their beliefs and ideologies.</p>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">\n<p>Much the same as Self-Authors Self-Transformers are&nbsp;suitable for&nbsp;filling the role of mover, though with&nbsp;larger amounts of resources to draw from.</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\">\n<h2 id=\"Following\">Following</h2>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">\n<p>At this level people are defined by tribal status making them excellent followers.</p>\n</td>\n<td width=\"186\" align=\"left\" valign=\"top\">\n<p>Following is not a role a level 4 will fall into unless they arrive at the conclusion on their own.</p>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">\n<p>While not as difficult as it was as a Self-Author following is still the weakest point of the higher levels due largely to the&nbsp;absence of cultural influence in personal thought.</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\">\n<h2 id=\"Opposing\">Opposing</h2>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">\n<p>Individuals at this level do not oppose without prompting, and will likely try to smooth over any mover/Opposer conflict.</p>\n</td>\n<td width=\"186\" align=\"left\" valign=\"top\">\n<p>At least as much as Moving, Opposing suits a 4th order mind, because even if they agree they are able to play Devil's Advocate as disagreement doesn't undermine their sense of self.</p>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">Opposing is a role Transforming Minds fill with little work.&nbsp; The vast amount of viewpoints they can hold allow them to freely choose a good response to Movers.</td>\n</tr>\n<tr>\n<td valign=\"top\">\n<h2 id=\"Bystanding\">Bystanding</h2>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">\n<p>Similar to opposing third order minds don't make very good bystanders, as that would necessitate leaving the group thought process that defines them.</p>\n</td>\n<td width=\"186\" align=\"left\" valign=\"top\">\n<p>A Self-Author is a suitable, if slightly biased, Bystander for much the same reason they are good Opposers.</p>\n</td>\n<td width=\"185\" align=\"left\" valign=\"top\">This is the role that this level truly excels in due to the shear number of viewpoints they are able to use.</td>\n</tr>\n</tbody>\n</table>\n<p>&nbsp;</p>\n<hr>\n<p>Authors Notes:</p>\n<p><sup>1</sup>The lack of \"better\" levels seems to indicate that each level is a local optima with at least&nbsp;a few required for a stable society.</p>\n<p><sup>2</sup>This would seem to indicate that higher orders are capable of everything that a lower order is, motivation not withstanding.</p>\n<p><sup>3</sup>This level includes both human&nbsp;babies and animals.</p>\n<p><sup>4</sup>In addition to children some animals have pack/herd/pod mentalities that would appear to be at least 2(3).</p>\n<p><sup>5</sup>I would predict 5+ percent in level 2, and only the wild children in level 1, (those children who are raised by wild animals) with even some of them as level 2.</p>\n<p>*This is the relation to <a title=\"Kantor's Four player Model Through the Lends of CDT\" href=\"http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/\" target=\"_blank\">Four Player Model</a></p>\n<hr>\n<p>Attributions:</p>\n<p><a href=\"http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/\">http://developmentalobserver.blog.com/2010/06/09/an-overview-of-constructive-developmental-theory-cdt/</a>&nbsp;- Three highest levels of CDT</p>\n<p><a href=\"http://sustainabilitythinking.wordpress.com/2012/06/09/constructive-developmental-theory/\">http://sustainabilitythinking.wordpress.com/2012/06/09/constructive-developmental-theory/</a>&nbsp;- less detailed description of all five</p>\n<p><a href=\"http://developmentalobserver.blog.com/2011/06/08/additional-resources-on-adult-development/\">http://developmentalobserver.blog.com/2011/06/08/additional-resources-on-adult-development/</a>&nbsp;- Assorted links</p>\n<p><a href=\"http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/\">http://developmentalobserver.blog.com/2011/02/21/kantors-four-player-model-through-the-lens-of-cdt/</a>&nbsp;- Kantor's Four Player Model</p>\n<p><a href=\"http://malcolmocean.com/2014/10/subject-object-notation/\">http://malcolmocean.com/2014/10/subject-object-notation/</a>&nbsp;- Subject-Object Notation</p>\n<p><a href=\"http://www.ccl.org/leadership/pdf/landing/constructivedevtheory.pdf\" target=\"_blank\">http://www.ccl.org/leadership/pdf/landing/constructivedevtheory.pdf</a> - CDT more in depth</p>", "sections": [{"title": "Constructive Developmental Theory:", "anchor": "Constructive_Developmental_Theory_", "level": 1}, {"title": "First Order/The Impulsive Mind", "anchor": "First_Order_The_Impulsive_Mind", "level": 1}, {"title": "Second Order/The Instrumental Mind", "anchor": "Second_Order_The_Instrumental_Mind", "level": 1}, {"title": "Third Order/The Socialized Mind", "anchor": "Third_Order_The_Socialized_Mind", "level": 1}, {"title": "Fourth Order/The Self-Authoring Mind", "anchor": "Fourth_Order_The_Self_Authoring_Mind", "level": 1}, {"title": "Fifth Order/The Self-Transforming Mind ", "anchor": "Fifth_Order_The_Self_Transforming_Mind_", "level": 1}, {"title": "Subject Object Notation:", "anchor": "Subject_Object_Notation_", "level": 1}, {"title": "Four Player Model:", "anchor": "Four_Player_Model_", "level": 1}, {"title": "Socialized Mind", "anchor": "Socialized_Mind", "level": 1}, {"title": "Self-Authoring Mind", "anchor": "Self_Authoring_Mind", "level": 1}, {"title": "Self-Transforming Mind", "anchor": "Self_Transforming_Mind", "level": 1}, {"title": "Moving", "anchor": "Moving", "level": 1}, {"title": "Following", "anchor": "Following", "level": 1}, {"title": "Opposing", "anchor": "Opposing", "level": 1}, {"title": "Bystanding", "anchor": "Bystanding", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "17 comments"}], "headingsCount": 17}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uNbR8WuahQrELCHgW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-24T18:26:49.923Z", "modifiedAt": null, "url": null, "title": "Pomodoro for Programmers", "slug": "pomodoro-for-programmers", "viewCount": null, "lastCommentedAt": "2021-02-08T13:19:50.994Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/c3SKeDSycHTkmuvyR/pomodoro-for-programmers", "pageUrlRelative": "/posts/c3SKeDSycHTkmuvyR/pomodoro-for-programmers", "linkUrl": "https://www.lesswrong.com/posts/c3SKeDSycHTkmuvyR/pomodoro-for-programmers", "postedAtFormatted": "Wednesday, December 24th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pomodoro%20for%20Programmers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APomodoro%20for%20Programmers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc3SKeDSycHTkmuvyR%2Fpomodoro-for-programmers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pomodoro%20for%20Programmers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc3SKeDSycHTkmuvyR%2Fpomodoro-for-programmers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc3SKeDSycHTkmuvyR%2Fpomodoro-for-programmers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 468, "htmlBody": "<p>Unless you&rsquo;ve been living under a productivity rock, you probably have heard of the Pomodoro Technique, where you use a timer to do 25 minutes of focused work, and then take a five minute break.</p>\n<p>I used to use this technique a lot, up until I started doing computer programming.</p>\n<p>You see, with computer programming, I get into this mysterious flow that consumes me, and I keep blazing passed the 25 minute interval, and the buzz of the Pomodoro merely distracts me and derails my work.</p>\n<p>However, it&rsquo;s still important to re-focus, even as a programmer. So I&rsquo;ve tentatively settled on the following: 45 minutes of intense work followed by 15 minutes of intense break, using this custom timer made in a snap. (Inspired by the idea of \"tocks\", attributed to the co-founders of Beeminder, though I can&rsquo;t seem to find a canonical post explaining it. <strong>&nbsp;Update:</strong> <a href=\"http://blog.beeminder.com/tocks/\">a canonical post was just written</a>, seemingly by coincidence.)</p>\n<p>You probably know what happens in the period of intense work &mdash; uninterrupted work in a distraction-free environment where I code like a mad man. If anything bubbles up in my mind that&rsquo;s not a task, I write it down to address later.</p>\n<p>But the intense break is important.</p>\n<p>&nbsp;</p>\n<p>Here&rsquo;s my routine:</p>\n<p>1.) A bit of rest. Look away from the computer. Let loose. Focus.</p>\n<p>2.) Ask myself &mdash; am I comfortable? Do I need to do anything to rearrange my working environment? Am I sufficiently free from distractions? Do I need to do anything to address past distractions? Do I need to refill my water bottle? Do I need to get more food?</p>\n<p>3.) What did I do over the past 45 minutes? Did I do it right? Does it need revision?</p>\n<p>4.) What did I miss over the past 45 minutes? Do I have any important emails that need to be processed right away? Did anyone send me messages over HipChat? Any FB notifications? I disconnect from these services while during my work sprint, but the urgency of work communication requires me to reconnect every once in awhile. I try to put off responding to messages until the end of the day if they don&rsquo;t require an urgent response, though.</p>\n<p>5.) What should I do during the next 45 minute interval? Am I on track to accomplish my goals? Will my next 45 minute interval be distraction-free? Do I need to do anything to address future distractions?</p>\n<p>6.) Are there any quick tasks I can accomplish? Any emails I need to send? Any notes I need to take? Did anything bubble up that I should address now?</p>\n<p>&nbsp;</p>\n<p>The breaks are just as important as the work, and it emphasizes self-care, which is important and often neglected. I find that each 15 minute break propels my next 45 minute block to be better than if I had spent the entire 60 minutes working nonstop.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Qyeqh8wycbSapBNsp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "c3SKeDSycHTkmuvyR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 15, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "27773", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-24T22:16:35.669Z", "modifiedAt": null, "url": null, "title": "2015 New Years Resolution Thread ", "slug": "2015-new-years-resolution-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.939Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Andy_McKenzie", "createdAt": "2009-02-28T21:46:45.283Z", "isAdmin": false, "displayName": "Andy_McKenzie"}, "userId": "7PFnr3J3uCGSfjnZJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LRWoSmdon9CxYKNPy/2015-new-years-resolution-thread", "pageUrlRelative": "/posts/LRWoSmdon9CxYKNPy/2015-new-years-resolution-thread", "linkUrl": "https://www.lesswrong.com/posts/LRWoSmdon9CxYKNPy/2015-new-years-resolution-thread", "postedAtFormatted": "Wednesday, December 24th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%202015%20New%20Years%20Resolution%20Thread%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A2015%20New%20Years%20Resolution%20Thread%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLRWoSmdon9CxYKNPy%2F2015-new-years-resolution-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=2015%20New%20Years%20Resolution%20Thread%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLRWoSmdon9CxYKNPy%2F2015-new-years-resolution-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLRWoSmdon9CxYKNPy%2F2015-new-years-resolution-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 209, "htmlBody": "<p>The new year is a popular Schelling point to make changes to your activities, habits, and/or thought processes. This is often done via the New Year's Resolution. One standard piece of advice for NYRs is to make them achievable, since they are often too ambitious and people end up giving up and potentially falling victim to the <a href=\"http://www.theguardian.com/lifeandstyle/2014/may/24/this-column-change-life-what-the-hell-effect\">what-the-hell effect</a>.&nbsp;</p>\n<p>Wikipedia has a <a href=\"http://en.wikipedia.org/wiki/New_Year%27s_resolution#Popular_goals\">nice list of popular NYRs</a>. For ideas from other LW contributors, here are some previous NYRs discussed on LW:&nbsp;</p>\n<ul>\n<li>Somervta aimed to spend at least two hours/week learning to program (<a href=\"/lw/g6q/2012_year_in_review/8767\">here</a>)</li>\n<li>ArisKatsaris aimed to tithe to charity (<a href=\"/lw/ftg/2012_winter_fundraiser_for_the_singularity/8057\">here</a>)</li>\n<li>Swimmer963 aimed to experiment more with relationships (<a href=\"/lw/7l2/my_greatest_achievement/\">here</a>)</li>\n<li>RichardKennaway aimed to not die (<a href=\"/lw/ty/my_childhood_death_spiral/7olt\">here</a>)</li>\n<li>orthonormal aimed (for many years in a row) to make new mistakes (<a href=\"/lw/deq/where_to_intervene_in_a_human/6yl6\">here</a>)</li>\n<li>Perplexed aimed to avoid making karma micromanagement postmortems (<a href=\"/lw/3by/folk_grammar_and_morality/36fl\">here</a>)</li>\n<li>Yvain aimed to check whether there was a donation matching opportunity the next week before making a donation (<a href=\"/lw/3gy/tallinnevans_125000_singularity_challenge/38kh\">here</a>)</li>\n</ul>\n<p>(If one of these were from you, perhaps you'd like to discuss whether they were successful or not?)</p>\n<p>In the spirit of collaboration, I propose that we discuss any NYRs we have made or are thinking of making for 2015 in this thread.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LRWoSmdon9CxYKNPy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 2.3011001813906296e-06, "legacy": true, "legacyId": "27774", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RhAKGdypYAB4Q85Nk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-24T23:25:24.230Z", "modifiedAt": null, "url": null, "title": "Factoring cost-effectiveness", "slug": "factoring-cost-effectiveness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.414Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "owencb", "createdAt": "2013-05-12T09:01:14.360Z", "isAdmin": false, "displayName": "owencb"}, "userId": "QDNJ93vrjoaRBesk2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qy9k6SaLf79io7s7P/factoring-cost-effectiveness", "pageUrlRelative": "/posts/qy9k6SaLf79io7s7P/factoring-cost-effectiveness", "linkUrl": "https://www.lesswrong.com/posts/qy9k6SaLf79io7s7P/factoring-cost-effectiveness", "postedAtFormatted": "Wednesday, December 24th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Factoring%20cost-effectiveness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFactoring%20cost-effectiveness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqy9k6SaLf79io7s7P%2Ffactoring-cost-effectiveness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Factoring%20cost-effectiveness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqy9k6SaLf79io7s7P%2Ffactoring-cost-effectiveness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqy9k6SaLf79io7s7P%2Ffactoring-cost-effectiveness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1327, "htmlBody": "<p><em><strong>Summary</strong>: We can split the cost-effectiveness of an intervention into how good the cause is, and how good the intervention is relative to the cause. This perspective could help our efforts in prioritisation by letting us bring appropriate tools to bear on the different parts.</em></p>\n<h2>Cost-effectiveness comparisons</h2>\n<p>When we choose between giving time or money to different interventions, we&rsquo;re making a comparison. It&rsquo;s nice to know what these comparisons come down to. There are a lot of sources of evidence, and different ones will be more appropriate in different contexts. For this post I'll assume that we are seeking the most cost-effective interventions.</p>\n<p>Say we are comparing between intervention <em>x</em> in cause area X, and intervention <em>y</em> in cause area Y. How they compare depends on things like how well thought-out <em>x</em> and <em>y</em> are, how competent the people and organisations implementing them are, as well as how valuable X is as a whole compared to Y.</p>\n<p>These are all important factors in telling us how <em>x</em> and <em>y</em> ultimately compare, but they&rsquo;re quite different from one another. So it shouldn&rsquo;t be a surprise if it&rsquo;s best to use different methods to compare the different factors. I think this is the case.</p>\n<p>Consider the equation:</p>\n<h6><strong>Cost-effectiveness of intervention = (cost-effectiveness of area) * (leverage ratio of intervention)</strong></h6>\n<p><strong></strong> The left-hand side of this equation expresses how much good is achieved per unit of resources invested in the intervention. For the intervention <em>x</em> we&rsquo;ll denote this G(<em>x</em>). The right-hand side breaks this up as C(X), how much good is achieved per unit of resources invested in X as a whole, and a &lsquo;leverage ratio&rsquo; L(<em>x</em>) which expresses the ratio of how effective <em>x</em> is compared to X as a whole [1].</p>\n<p>Now to compare between <em>x</em> and <em>y</em> we&rsquo;re interested in the ratio G(<em>x</em>)/G(<em>y</em>). We can use the above equation to expand this:</p>\n<p>G(<em>x</em>)/G(<em>y</em>) = (C(X)L(<em>x</em>))/(C(Y)L(<em>y</em>)).</p>\n<p>This rearranges to:</p>\n<p>G(<em>x</em>)/G(<em>y</em>) = C(X)/C(Y) * L(<em>x</em>)/L(<em>y</em>).</p>\n<p>Here we&rsquo;ve split the comparison into two parts, each of which is comparing like with like. This is a good general strategy: making comparisons between dissimilar things is hard, and our intuitions are sometimes terrible at it, so it&rsquo;s helpful to break it into more comparable chunks [2].</p>\n<h2>Comparing cause effectiveness</h2>\n<p>Comparing the cost-effectiveness of different cause areas is quite far removed from everyday experience, and it doesn&rsquo;t have a good feedback mechanism as it can be hard to tell how much something helped the world even after the fact. Moreover it&rsquo;s just the right setting for <a href=\"http://en.wikipedia.org/wiki/Scope_neglect\">scope insensitivity</a>&nbsp;to cause problems for intuitive judgements. This means that relative to most areas of experience, we should be particularly cautious about putting too much weight on intuitive judgements. This in turn means that it&rsquo;s an area where explicit models are particularly valuable.</p>\n<p>That doesn&rsquo;t mean that explicit models always trump intuitive judgements in this domain; in particular, simple models often omit important factors that are incorporated into our intuitions. <a href=\"http://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/\">Nor does it mean that we should put all our trust into a single model</a>.&nbsp;But it does mean that it&rsquo;s particularly valuable to build, critique, and refine models for the cost-effectiveness of different causes. It also means we should put <a href=\"http://meteuphoric.wordpress.com/2010/12/20/estimation-is-the-best-we-have/\">more weight on the outputs of such models</a>&nbsp;than we do in most domains -- not because the models are more trustworthy, but because the alternatives are worse than usual. This is why I think developing such models is a high value activity, and why I&rsquo;ve been <a href=\"/lw/ldn/estimating_the_costeffectiveness_of_research/\">spending time on it</a>.</p>\n<h2>Comparing leverage ratios</h2>\n<p>The leverage ratios are determined largely by things like: whether the intervention is a sensible way of progressing on the cause; the quality of the team involved; how functional the implementing organisation is. In contrast to the overall effectiveness of a cause, these are the much closer to regular experience, so we should be less keen to use explicit models. On the other hand, methods and experience from valuing shares of companies (which have good feedback mechanisms) should be relevant in this context.</p>\n<p>There are several reasons why leverage ratios may vary within a cause area. Many of these will be common across cause areas. Because of this, we might expect similar distributions of leverage ratios in different cause areas (but probably some areas have more variance than others, <a href=\"https://80000hours.org/2012/09/how-good-are-the-best/\">just as some jobs have more variance in the productivity of employees than others</a>). It could be valuable to have an idea of how much leverage ratios do vary in practice. This is an empirical question we might be able to get data for.</p>\n<h2>Implications for prioritisation work</h2>\n<p>To choose between interventions, we need to compare cost-effectiveness. I&rsquo;ve claimed that this is best done by comparing the cost-effectiveness of cause areas, and comparing the leverage ratios of the interventions. If this is right, what&rsquo;s more valuable to work on evaluating?</p>\n<p>Of course they are complementary to each other. The better we are able to identify the best cause areas, the more valuable it is to have good estimates for the leverage ratios of interventions in those areas. And the better we are able to identify interventions with very high leverage ratios, the more valuable it is to be able to say which of those are in the most effective causes. So the answer depends in part on how much work each is already receiving.</p>\n<p>It also depends on your beliefs about which component has more variance. If you think that most of the variation in intervention effectiveness comes from leverage ratios, while cost-effectiveness of causes doesn&rsquo;t vary that much, then it&rsquo;s more important to evaluate the leverage ratios of interventions. If on the other hand you think more variation comes between causes, then it&rsquo;s more important to evaluate cause effectiveness. I currently think there is likely to be more variation in cause effectiveness even after you filter to the ones which could plausibly be high value; however I am quite uncertain about this.</p>\n<p>There is also an asymmetry which pushes us towards doing more cause assessment first: it&rsquo;s much easier to cut down the work of evaluating leverage ratios by restricting to a few causes than it is to cut down the work of evaluating cause effectiveness by first identifying opportunities with high leverage ratios. Similarly, if we identify a cause area which is valuable but see no good interventions available to fund, <a href=\"http://blog.givewell.org/2014/05/14/the-importance-of-committing-to-causes/\">we can advertise this and hopefully create good interventions in the area</a>.</p>\n<p>Of course to support giving decisions today we need to compare leverage ratios as well as cause effectiveness. And in some cases studying the interventions may help us to evaluate the cause effectiveness. But I think it will usually be right to investigate leverage ratios only within cause areas that we think have, or might have, high effectiveness, and only after we&rsquo;ve made an effort to assess that.</p>\n<p><small><em>Acknowledgements</em>: thanks to Toby Ord and Nick Beckstead for helpful conversations.</small></p>\n<p><small>Crossposted from the <a href=\"http://www.fhi.ox.ac.uk/factoring-cost-effectiveness/\">Global Priorities Project</a>.</small></p>\n<p><small> </small></p>\n<p><small>[1] The leverage ratio is really a function of <em>x</em> together with X. <a href=\"https://www.againstmalaria.com/Default.aspx\">AMF</a> may have one leverage ratio with respect to the area of global health, and another with respect to malaria treatment.</small></p>\n<p><small>[2] An extra advantage of breaking the comparisons into like-with-like is that it&rsquo;s easier to track uncertainty so that it doesn&rsquo;t blow up unnecessarily. I might be very uncertain about how good X is, so I think C(X) lies somewhere in (1, 100). I might also be very uncertain about how good Y is, so that I think C(Y) lies in (1, 100). But it doesn&rsquo;t follow that C(X)/C(Y) could lie anywhere in (1/100, 100). If my uncertainty about X is related to my uncertainty about Y (say X is reducing carbon emissions and Y is helping communities adapt to climate change), then I might have a better idea of the ratio C(X)/C(Y) than I do about either individually. Of course this just means that my estimates for C(X) and C(Y) are strongly correlated. But I think it&rsquo;s helpful to have an idea of practical ways to break up the calculation which help to keep the uncertainty under control. For more thoughts on tracking uncertainty through estimates, <a href=\"https://www.givingwhatwecan.org/blog/2013-01-10/making-practical-estimates-in-cases-of-large-uncertainty\">see here</a>.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qy9k6SaLf79io7s7P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 2.3012580982746887e-06, "legacy": true, "legacyId": "27775", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em><strong>Summary</strong>: We can split the cost-effectiveness of an intervention into how good the cause is, and how good the intervention is relative to the cause. This perspective could help our efforts in prioritisation by letting us bring appropriate tools to bear on the different parts.</em></p>\n<h2 id=\"Cost_effectiveness_comparisons\">Cost-effectiveness comparisons</h2>\n<p>When we choose between giving time or money to different interventions, we\u2019re making a comparison. It\u2019s nice to know what these comparisons come down to. There are a lot of sources of evidence, and different ones will be more appropriate in different contexts. For this post I'll assume that we are seeking the most cost-effective interventions.</p>\n<p>Say we are comparing between intervention <em>x</em> in cause area X, and intervention <em>y</em> in cause area Y. How they compare depends on things like how well thought-out <em>x</em> and <em>y</em> are, how competent the people and organisations implementing them are, as well as how valuable X is as a whole compared to Y.</p>\n<p>These are all important factors in telling us how <em>x</em> and <em>y</em> ultimately compare, but they\u2019re quite different from one another. So it shouldn\u2019t be a surprise if it\u2019s best to use different methods to compare the different factors. I think this is the case.</p>\n<p>Consider the equation:</p>\n<h6><strong>Cost-effectiveness of intervention = (cost-effectiveness of area) * (leverage ratio of intervention)</strong></h6>\n<p><strong></strong> The left-hand side of this equation expresses how much good is achieved per unit of resources invested in the intervention. For the intervention <em>x</em> we\u2019ll denote this G(<em>x</em>). The right-hand side breaks this up as C(X), how much good is achieved per unit of resources invested in X as a whole, and a \u2018leverage ratio\u2019 L(<em>x</em>) which expresses the ratio of how effective <em>x</em> is compared to X as a whole [1].</p>\n<p>Now to compare between <em>x</em> and <em>y</em> we\u2019re interested in the ratio G(<em>x</em>)/G(<em>y</em>). We can use the above equation to expand this:</p>\n<p>G(<em>x</em>)/G(<em>y</em>) = (C(X)L(<em>x</em>))/(C(Y)L(<em>y</em>)).</p>\n<p>This rearranges to:</p>\n<p>G(<em>x</em>)/G(<em>y</em>) = C(X)/C(Y) * L(<em>x</em>)/L(<em>y</em>).</p>\n<p>Here we\u2019ve split the comparison into two parts, each of which is comparing like with like. This is a good general strategy: making comparisons between dissimilar things is hard, and our intuitions are sometimes terrible at it, so it\u2019s helpful to break it into more comparable chunks [2].</p>\n<h2 id=\"Comparing_cause_effectiveness\">Comparing cause effectiveness</h2>\n<p>Comparing the cost-effectiveness of different cause areas is quite far removed from everyday experience, and it doesn\u2019t have a good feedback mechanism as it can be hard to tell how much something helped the world even after the fact. Moreover it\u2019s just the right setting for <a href=\"http://en.wikipedia.org/wiki/Scope_neglect\">scope insensitivity</a>&nbsp;to cause problems for intuitive judgements. This means that relative to most areas of experience, we should be particularly cautious about putting too much weight on intuitive judgements. This in turn means that it\u2019s an area where explicit models are particularly valuable.</p>\n<p>That doesn\u2019t mean that explicit models always trump intuitive judgements in this domain; in particular, simple models often omit important factors that are incorporated into our intuitions. <a href=\"http://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/\">Nor does it mean that we should put all our trust into a single model</a>.&nbsp;But it does mean that it\u2019s particularly valuable to build, critique, and refine models for the cost-effectiveness of different causes. It also means we should put <a href=\"http://meteuphoric.wordpress.com/2010/12/20/estimation-is-the-best-we-have/\">more weight on the outputs of such models</a>&nbsp;than we do in most domains -- not because the models are more trustworthy, but because the alternatives are worse than usual. This is why I think developing such models is a high value activity, and why I\u2019ve been <a href=\"/lw/ldn/estimating_the_costeffectiveness_of_research/\">spending time on it</a>.</p>\n<h2 id=\"Comparing_leverage_ratios\">Comparing leverage ratios</h2>\n<p>The leverage ratios are determined largely by things like: whether the intervention is a sensible way of progressing on the cause; the quality of the team involved; how functional the implementing organisation is. In contrast to the overall effectiveness of a cause, these are the much closer to regular experience, so we should be less keen to use explicit models. On the other hand, methods and experience from valuing shares of companies (which have good feedback mechanisms) should be relevant in this context.</p>\n<p>There are several reasons why leverage ratios may vary within a cause area. Many of these will be common across cause areas. Because of this, we might expect similar distributions of leverage ratios in different cause areas (but probably some areas have more variance than others, <a href=\"https://80000hours.org/2012/09/how-good-are-the-best/\">just as some jobs have more variance in the productivity of employees than others</a>). It could be valuable to have an idea of how much leverage ratios do vary in practice. This is an empirical question we might be able to get data for.</p>\n<h2 id=\"Implications_for_prioritisation_work\">Implications for prioritisation work</h2>\n<p>To choose between interventions, we need to compare cost-effectiveness. I\u2019ve claimed that this is best done by comparing the cost-effectiveness of cause areas, and comparing the leverage ratios of the interventions. If this is right, what\u2019s more valuable to work on evaluating?</p>\n<p>Of course they are complementary to each other. The better we are able to identify the best cause areas, the more valuable it is to have good estimates for the leverage ratios of interventions in those areas. And the better we are able to identify interventions with very high leverage ratios, the more valuable it is to be able to say which of those are in the most effective causes. So the answer depends in part on how much work each is already receiving.</p>\n<p>It also depends on your beliefs about which component has more variance. If you think that most of the variation in intervention effectiveness comes from leverage ratios, while cost-effectiveness of causes doesn\u2019t vary that much, then it\u2019s more important to evaluate the leverage ratios of interventions. If on the other hand you think more variation comes between causes, then it\u2019s more important to evaluate cause effectiveness. I currently think there is likely to be more variation in cause effectiveness even after you filter to the ones which could plausibly be high value; however I am quite uncertain about this.</p>\n<p>There is also an asymmetry which pushes us towards doing more cause assessment first: it\u2019s much easier to cut down the work of evaluating leverage ratios by restricting to a few causes than it is to cut down the work of evaluating cause effectiveness by first identifying opportunities with high leverage ratios. Similarly, if we identify a cause area which is valuable but see no good interventions available to fund, <a href=\"http://blog.givewell.org/2014/05/14/the-importance-of-committing-to-causes/\">we can advertise this and hopefully create good interventions in the area</a>.</p>\n<p>Of course to support giving decisions today we need to compare leverage ratios as well as cause effectiveness. And in some cases studying the interventions may help us to evaluate the cause effectiveness. But I think it will usually be right to investigate leverage ratios only within cause areas that we think have, or might have, high effectiveness, and only after we\u2019ve made an effort to assess that.</p>\n<p><small><em>Acknowledgements</em>: thanks to Toby Ord and Nick Beckstead for helpful conversations.</small></p>\n<p><small>Crossposted from the <a href=\"http://www.fhi.ox.ac.uk/factoring-cost-effectiveness/\">Global Priorities Project</a>.</small></p>\n<p><small> </small></p>\n<p><small>[1] The leverage ratio is really a function of <em>x</em> together with X. <a href=\"https://www.againstmalaria.com/Default.aspx\">AMF</a> may have one leverage ratio with respect to the area of global health, and another with respect to malaria treatment.</small></p>\n<p><small>[2] An extra advantage of breaking the comparisons into like-with-like is that it\u2019s easier to track uncertainty so that it doesn\u2019t blow up unnecessarily. I might be very uncertain about how good X is, so I think C(X) lies somewhere in (1, 100). I might also be very uncertain about how good Y is, so that I think C(Y) lies in (1, 100). But it doesn\u2019t follow that C(X)/C(Y) could lie anywhere in (1/100, 100). If my uncertainty about X is related to my uncertainty about Y (say X is reducing carbon emissions and Y is helping communities adapt to climate change), then I might have a better idea of the ratio C(X)/C(Y) than I do about either individually. Of course this just means that my estimates for C(X) and C(Y) are strongly correlated. But I think it\u2019s helpful to have an idea of practical ways to break up the calculation which help to keep the uncertainty under control. For more thoughts on tracking uncertainty through estimates, <a href=\"https://www.givingwhatwecan.org/blog/2013-01-10/making-practical-estimates-in-cases-of-large-uncertainty\">see here</a>.</small></p>", "sections": [{"title": "Cost-effectiveness comparisons", "anchor": "Cost_effectiveness_comparisons", "level": 1}, {"title": "Comparing cause effectiveness", "anchor": "Comparing_cause_effectiveness", "level": 1}, {"title": "Comparing leverage ratios", "anchor": "Comparing_leverage_ratios", "level": 1}, {"title": "Implications for prioritisation work", "anchor": "Implications_for_prioritisation_work", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["R8ywQZsare2ANHLhQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-25T06:04:48.902Z", "modifiedAt": "2020-08-21T23:46:34.553Z", "url": null, "title": "Why \"Changing the World\" is a Horrible Phrase", "slug": "why-changing-the-world-is-a-horrible-phrase", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.327Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "ozziegooen", "user": {"username": "ozziegooen", "createdAt": "2013-05-25T09:22:13.574Z", "isAdmin": false, "displayName": "ozziegooen"}, "userId": "efKySALtaLcvtp3jW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Du8G7DRRntcqWrucX/why-changing-the-world-is-a-horrible-phrase", "pageUrlRelative": "/posts/Du8G7DRRntcqWrucX/why-changing-the-world-is-a-horrible-phrase", "linkUrl": "https://www.lesswrong.com/posts/Du8G7DRRntcqWrucX/why-changing-the-world-is-a-horrible-phrase", "postedAtFormatted": "Thursday, December 25th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20%22Changing%20the%20World%22%20is%20a%20Horrible%20Phrase&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20%22Changing%20the%20World%22%20is%20a%20Horrible%20Phrase%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDu8G7DRRntcqWrucX%2Fwhy-changing-the-world-is-a-horrible-phrase%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20%22Changing%20the%20World%22%20is%20a%20Horrible%20Phrase%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDu8G7DRRntcqWrucX%2Fwhy-changing-the-world-is-a-horrible-phrase", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDu8G7DRRntcqWrucX%2Fwhy-changing-the-world-is-a-horrible-phrase", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1422, "htmlBody": "<p>Steve Jobs famously convinced John Scully from Pepsi to join Apple Computer with the line, \u201cDo you want to sell sugared water for the rest of your life? Or do you want to come with me and change the world?\u201d.&nbsp; This sounds convincing until one thinks closely about it.</p><p>Steve Jobs was a famous salesman. &nbsp; He was known for his selling ability, not his honesty.&nbsp; His terminology here was interesting.&nbsp; \u2018Change the world\u2019 is a phrase that both sounds important and is difficult to argue with.&nbsp; Arguing if Apple was really \u2018changing the world\u2019 would have been pointless, because the phrase was so ambiguous that there would be little to discuss.&nbsp; On paper, of course Apple is changing the world, but then of course any organization or any individual is also \u2018changing\u2019 the world.&nbsp; A real discussion of if Apple \u2018changes the world\u2019 would lead to a discussion of what \u2018changing the world\u2019 actually means, which would lead to obscure philosophy, steering the conversation away from the actual point. &nbsp;</p><p>\u2018Changing the world\u2019 is an effective marketing tool that\u2019s useful for building the feeling of consensus. Steve Jobs used it heavily, as had endless numbers of businesses, conferences, nonprofits, and TV shows.&nbsp; It\u2019s used because it sounds good and is typically not questioned, so I\u2019m here to question it.&nbsp; I believe that the popularization of this phrase creates confused goals and perverse incentives from people who believe they are doing good things.</p><p>&nbsp;</p><p><strong>Problem 1: 'Changing the World' Leads to Television Value over Real Value</strong></p><p>It leads nonprofit workers to passionately chase feeble things.&nbsp; I\u2019m amazed by the variety that I see in people who try to \u2018change the world\u2019. Some grow organic food, some research rocks, some play instruments. They do basically everything. &nbsp;</p><p>Few people protest this variety.&nbsp; There are millions of voices giving the appeal to \u2018change the world\u2019 in the way that would validate many radically diverse pursuits. &nbsp;</p><p>TED, the modern symbol of the intellectual elite for many, is itself a grab bag of a ways to \u2018change the world\u2019, without any sense of scale between pursuits.&nbsp; People tell comedic stories, sing songs, discuss tales of personal adventures and so on.&nbsp; In TED Talks, all presentations are shown side-by-side with the same lighting and display.&nbsp; Yet in real life some projects produce orders of magnitude more output than others.</p><p>At 80,000 Hours, I read many applications for career consulting. I got the sense that there are many people out there trying to live their lives in order to eventually produce a TED talk.&nbsp; To them, that is what \u2018changing the world\u2019 means.&nbsp; These are often very smart and motivated people with very high opportunity costs. &nbsp;</p><p>I would see an application that would express interest in either starting an orphanage in Uganda, creating a woman's movement in Ohio, or making a conservatory in Costa Rica.&nbsp; It was clear that they were trying to \u2018change the world\u2019 in a very vague and TED-oriented way.</p><p>I believe that \u2018Changing the World\u2019 is promoted by TED, but internally acts mostly as a Schelling point.&nbsp; Agreeing on the importance of \u2018changing the world\u2019 is a good way of coming to a consensus without having to decide on moral philosophy. \u2018Changing the world\u2019 is simply the minimum common denominator for what that community can agree upon.&nbsp; This is a useful social tool, but an unfortunate side effect was that it inspired many others to follow this shelling point itself.&nbsp; Please don\u2019t make the purpose of your life the lowest common denominator of a specific group of existing intellectuals.&nbsp;</p><p>It leads businesses to be gain employees and media attention without having to commit to anything.&nbsp; I\u2019m living in Silicon Valley, and \u2018Change the World\u2019 is an incredibly common phrase for new and old startups. Silicon Valley (the TV show) made fun of it, as do much of the media.&nbsp; They should, but I think much of the time they miss the point; the problem here is not one where the companies are dishonest, but one where their honestly itself just doesn\u2019t mean much.&nbsp; Declaring that a company is \u2018changing the world\u2019 isn\u2019t really declaring anything. &nbsp;</p><p>Hiring conversations that begin and end with the motivation of \u2018changing the world\u2019 are like hiring conversations that begin and end with making \u2018lots\u2019 of money.&nbsp; If one couldn\u2019t compare salaries between different companies, they would likely select poorly for salary.&nbsp; In terms of social benefit, most companies don\u2019t attempt to quantify their costs and benefits on society except in very specific and positive ways for them.&nbsp; \u201cGoogle has enabled Haiti disaster recovery\u201d for social proof sounds to me like saying \u201cWe paid this other person $12,000 in July 2010\u201d for salary proof. It sounds nice, but facts selected by a salesperson are simply not complete.</p><p>&nbsp;</p><p><strong>Problem 2: \u2018Changing the World\u2019 Creates Black and White Thinking</strong></p><p>The idea that one wants to \u2018change the world\u2019 implies that there is such a thing as \u2018changing the world\u2019 and such a thing is \u2018not changing the world\u2019.&nbsp; It implies that there are \u2018world changers\u2019 and people who are not \u2018world changers\u2019. It implies that there is one group of \u2018important people\u2019 out there and then a lot of \u2018useless\u2019 others.</p><p>This directly supports the \u2018Great Man\u2019 theory, a 19th century idea that history and future actions are led by a small number of \u2018great men\u2019.&nbsp; There\u2019s not a lot of academic research supporting this theory, but there\u2019s a lot of attention to it, and it\u2019s a lot of fun to pretend is true. &nbsp;</p><p>But it\u2019s not.&nbsp; There is typically a lot of unglamorous work behind every successful project or organization. Behind every Steve Jobs are thousands of very intelligent and hard-working employees and millions of smart people who have created a larger ecosystem. If one only pays attention to Steve Jobs they will leave out most of the work. They will praise Steve Jobs far too highly and disregard the importance of unglamorous labor.</p><p>Typically much of the best work is also the most unglamorous.&nbsp; Making WordPress websites, sorting facts into analysis, cold calling donors. Many the best ideas for organizations may be very simple and may have been done before. However, for someone looking to get to TED conferences or become superstars, it is very easy to look over other comparatively menial labor. This means that not only will it not get done, but those people who do it feel worse about themselves.</p><p>So some people do important work and feel bad because it doesn\u2019t meet the TED standard of \u2018change the world\u2019.&nbsp; Others try ridiculously ambitious things outside their own capabilities, fail, and then give up.&nbsp; Others don\u2019t even try, because their perceived threshold is too high for them.&nbsp; The very idea of a threshold and a \u2018change or don\u2019t change the world\u2019 approach is simply false, and believing something that\u2019s both false and fundamentally important is really bad.</p><p>In all likelihood, you will not make the next billion-dollar nonprofit. You will not make the next billion-dollar business. You will not become the next congressperson in your district. This does not mean that you have not done a good job. It should not demoralize you in any way once you fail hardly to do these things.&nbsp;</p><p>Finally, I would like to ponder on what happens once or if one does decide they have changed the world. What now? Should one change it again?</p><p>It\u2019s not obvious.&nbsp; Many retire or settle down after feeling accomplished.&nbsp; However, this is exactly when trying is the most important.&nbsp; People with the best histories have the best potentials.&nbsp; No matter how much a U.S. President may achieve, they still can achieve significantly more after the end of their terms.&nbsp; There is no \u2018enough\u2019 line for human accomplishment.</p><p><strong>Conclusion</strong></p><p>In summary the phrase change the world provides a lack of clear direction and encourages black-and-white thinking that distorts behaviors and motivation.&nbsp; However, I do believe that the phrase can act as a stepping stone towards a more concrete goal.&nbsp; \u2018Change the World\u2019 can act as an idea that requires a philosophical continuation.&nbsp; It\u2019s a start for a goal, but it should be recognized that it\u2019s far from a good ending.</p><p>Next time someone tells you about \u2018changing the world\u2019, ask them to follow through with telling you the specifics of what they mean.&nbsp; Make sure that they understand that they need to go further in order to mean anything. &nbsp;</p><p>And more importantly, do this for yourself.&nbsp; Choose a specific axiomatic philosophy or set of philosophies and aim towards those.&nbsp; Your ultimate goal in life is too important to be based on an empty marketing term.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 10, "rnvHPB3X2TiD5NMwY": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Du8G7DRRntcqWrucX", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 38, "extendedScore": null, "score": 0.000172, "legacy": true, "legacyId": "27778", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Steve Jobs famously convinced John Scully from Pepsi to join Apple Computer with the line, \u201cDo you want to sell sugared water for the rest of your life? Or do you want to come with me and change the world?\u201d.&nbsp; This sounds convincing until one thinks closely about it.</p><p>Steve Jobs was a famous salesman. &nbsp; He was known for his selling ability, not his honesty.&nbsp; His terminology here was interesting.&nbsp; \u2018Change the world\u2019 is a phrase that both sounds important and is difficult to argue with.&nbsp; Arguing if Apple was really \u2018changing the world\u2019 would have been pointless, because the phrase was so ambiguous that there would be little to discuss.&nbsp; On paper, of course Apple is changing the world, but then of course any organization or any individual is also \u2018changing\u2019 the world.&nbsp; A real discussion of if Apple \u2018changes the world\u2019 would lead to a discussion of what \u2018changing the world\u2019 actually means, which would lead to obscure philosophy, steering the conversation away from the actual point. &nbsp;</p><p>\u2018Changing the world\u2019 is an effective marketing tool that\u2019s useful for building the feeling of consensus. Steve Jobs used it heavily, as had endless numbers of businesses, conferences, nonprofits, and TV shows.&nbsp; It\u2019s used because it sounds good and is typically not questioned, so I\u2019m here to question it.&nbsp; I believe that the popularization of this phrase creates confused goals and perverse incentives from people who believe they are doing good things.</p><p>&nbsp;</p><p><strong id=\"Problem_1___Changing_the_World__Leads_to_Television_Value_over_Real_Value\">Problem 1: 'Changing the World' Leads to Television Value over Real Value</strong></p><p>It leads nonprofit workers to passionately chase feeble things.&nbsp; I\u2019m amazed by the variety that I see in people who try to \u2018change the world\u2019. Some grow organic food, some research rocks, some play instruments. They do basically everything. &nbsp;</p><p>Few people protest this variety.&nbsp; There are millions of voices giving the appeal to \u2018change the world\u2019 in the way that would validate many radically diverse pursuits. &nbsp;</p><p>TED, the modern symbol of the intellectual elite for many, is itself a grab bag of a ways to \u2018change the world\u2019, without any sense of scale between pursuits.&nbsp; People tell comedic stories, sing songs, discuss tales of personal adventures and so on.&nbsp; In TED Talks, all presentations are shown side-by-side with the same lighting and display.&nbsp; Yet in real life some projects produce orders of magnitude more output than others.</p><p>At 80,000 Hours, I read many applications for career consulting. I got the sense that there are many people out there trying to live their lives in order to eventually produce a TED talk.&nbsp; To them, that is what \u2018changing the world\u2019 means.&nbsp; These are often very smart and motivated people with very high opportunity costs. &nbsp;</p><p>I would see an application that would express interest in either starting an orphanage in Uganda, creating a woman's movement in Ohio, or making a conservatory in Costa Rica.&nbsp; It was clear that they were trying to \u2018change the world\u2019 in a very vague and TED-oriented way.</p><p>I believe that \u2018Changing the World\u2019 is promoted by TED, but internally acts mostly as a Schelling point.&nbsp; Agreeing on the importance of \u2018changing the world\u2019 is a good way of coming to a consensus without having to decide on moral philosophy. \u2018Changing the world\u2019 is simply the minimum common denominator for what that community can agree upon.&nbsp; This is a useful social tool, but an unfortunate side effect was that it inspired many others to follow this shelling point itself.&nbsp; Please don\u2019t make the purpose of your life the lowest common denominator of a specific group of existing intellectuals.&nbsp;</p><p>It leads businesses to be gain employees and media attention without having to commit to anything.&nbsp; I\u2019m living in Silicon Valley, and \u2018Change the World\u2019 is an incredibly common phrase for new and old startups. Silicon Valley (the TV show) made fun of it, as do much of the media.&nbsp; They should, but I think much of the time they miss the point; the problem here is not one where the companies are dishonest, but one where their honestly itself just doesn\u2019t mean much.&nbsp; Declaring that a company is \u2018changing the world\u2019 isn\u2019t really declaring anything. &nbsp;</p><p>Hiring conversations that begin and end with the motivation of \u2018changing the world\u2019 are like hiring conversations that begin and end with making \u2018lots\u2019 of money.&nbsp; If one couldn\u2019t compare salaries between different companies, they would likely select poorly for salary.&nbsp; In terms of social benefit, most companies don\u2019t attempt to quantify their costs and benefits on society except in very specific and positive ways for them.&nbsp; \u201cGoogle has enabled Haiti disaster recovery\u201d for social proof sounds to me like saying \u201cWe paid this other person $12,000 in July 2010\u201d for salary proof. It sounds nice, but facts selected by a salesperson are simply not complete.</p><p>&nbsp;</p><p><strong id=\"Problem_2___Changing_the_World__Creates_Black_and_White_Thinking\">Problem 2: \u2018Changing the World\u2019 Creates Black and White Thinking</strong></p><p>The idea that one wants to \u2018change the world\u2019 implies that there is such a thing as \u2018changing the world\u2019 and such a thing is \u2018not changing the world\u2019.&nbsp; It implies that there are \u2018world changers\u2019 and people who are not \u2018world changers\u2019. It implies that there is one group of \u2018important people\u2019 out there and then a lot of \u2018useless\u2019 others.</p><p>This directly supports the \u2018Great Man\u2019 theory, a 19th century idea that history and future actions are led by a small number of \u2018great men\u2019.&nbsp; There\u2019s not a lot of academic research supporting this theory, but there\u2019s a lot of attention to it, and it\u2019s a lot of fun to pretend is true. &nbsp;</p><p>But it\u2019s not.&nbsp; There is typically a lot of unglamorous work behind every successful project or organization. Behind every Steve Jobs are thousands of very intelligent and hard-working employees and millions of smart people who have created a larger ecosystem. If one only pays attention to Steve Jobs they will leave out most of the work. They will praise Steve Jobs far too highly and disregard the importance of unglamorous labor.</p><p>Typically much of the best work is also the most unglamorous.&nbsp; Making WordPress websites, sorting facts into analysis, cold calling donors. Many the best ideas for organizations may be very simple and may have been done before. However, for someone looking to get to TED conferences or become superstars, it is very easy to look over other comparatively menial labor. This means that not only will it not get done, but those people who do it feel worse about themselves.</p><p>So some people do important work and feel bad because it doesn\u2019t meet the TED standard of \u2018change the world\u2019.&nbsp; Others try ridiculously ambitious things outside their own capabilities, fail, and then give up.&nbsp; Others don\u2019t even try, because their perceived threshold is too high for them.&nbsp; The very idea of a threshold and a \u2018change or don\u2019t change the world\u2019 approach is simply false, and believing something that\u2019s both false and fundamentally important is really bad.</p><p>In all likelihood, you will not make the next billion-dollar nonprofit. You will not make the next billion-dollar business. You will not become the next congressperson in your district. This does not mean that you have not done a good job. It should not demoralize you in any way once you fail hardly to do these things.&nbsp;</p><p>Finally, I would like to ponder on what happens once or if one does decide they have changed the world. What now? Should one change it again?</p><p>It\u2019s not obvious.&nbsp; Many retire or settle down after feeling accomplished.&nbsp; However, this is exactly when trying is the most important.&nbsp; People with the best histories have the best potentials.&nbsp; No matter how much a U.S. President may achieve, they still can achieve significantly more after the end of their terms.&nbsp; There is no \u2018enough\u2019 line for human accomplishment.</p><p><strong id=\"Conclusion\">Conclusion</strong></p><p>In summary the phrase change the world provides a lack of clear direction and encourages black-and-white thinking that distorts behaviors and motivation.&nbsp; However, I do believe that the phrase can act as a stepping stone towards a more concrete goal.&nbsp; \u2018Change the World\u2019 can act as an idea that requires a philosophical continuation.&nbsp; It\u2019s a start for a goal, but it should be recognized that it\u2019s far from a good ending.</p><p>Next time someone tells you about \u2018changing the world\u2019, ask them to follow through with telling you the specifics of what they mean.&nbsp; Make sure that they understand that they need to go further in order to mean anything. &nbsp;</p><p>And more importantly, do this for yourself.&nbsp; Choose a specific axiomatic philosophy or set of philosophies and aim towards those.&nbsp; Your ultimate goal in life is too important to be based on an empty marketing term.</p>", "sections": [{"title": "Problem 1: 'Changing the World' Leads to Television Value over Real Value", "anchor": "Problem_1___Changing_the_World__Leads_to_Television_Value_over_Real_Value", "level": 1}, {"title": "Problem 2: \u2018Changing the World\u2019 Creates Black and White Thinking", "anchor": "Problem_2___Changing_the_World__Creates_Black_and_White_Thinking", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "16 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-25T20:25:49.599Z", "modifiedAt": null, "url": null, "title": "Using Doulingo 'Immersion' feature to translate HPMOR", "slug": "using-doulingo-immersion-feature-to-translate-hpmor", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.966Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "efim", "createdAt": "2013-04-14T00:57:28.743Z", "isAdmin": false, "displayName": "efim"}, "userId": "Y8azdhZD6fvWdGwaB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KNFcxTr3zKWM39enF/using-doulingo-immersion-feature-to-translate-hpmor", "pageUrlRelative": "/posts/KNFcxTr3zKWM39enF/using-doulingo-immersion-feature-to-translate-hpmor", "linkUrl": "https://www.lesswrong.com/posts/KNFcxTr3zKWM39enF/using-doulingo-immersion-feature-to-translate-hpmor", "postedAtFormatted": "Thursday, December 25th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Using%20Doulingo%20'Immersion'%20feature%20to%20translate%20HPMOR&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUsing%20Doulingo%20'Immersion'%20feature%20to%20translate%20HPMOR%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKNFcxTr3zKWM39enF%2Fusing-doulingo-immersion-feature-to-translate-hpmor%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Using%20Doulingo%20'Immersion'%20feature%20to%20translate%20HPMOR%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKNFcxTr3zKWM39enF%2Fusing-doulingo-immersion-feature-to-translate-hpmor", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKNFcxTr3zKWM39enF%2Fusing-doulingo-immersion-feature-to-translate-hpmor", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 274, "htmlBody": "<p>I have been using (alongside other learning tools) Duolingo for more than a year now and with considerable success in learning Spanish language.</p>\n<p>I used immersion for learning purposes, but just recently it dawned on me that I could use it to translate HPMOR into different languages while simultaneously promoting it in wide audience.</p>\n<p>My first attempt was uploading first untranslated chapter (on hpmor.com listed Spanish translation up to 24th chapter).&nbsp;</p>\n<p>Half of it got translated before the upload drowned in new more recent uploads from other people.</p>\n<p>First idea was to get 'commercial' license to keep uploaded chapter on top, but right now i'll try to break chapters into smaller chunks, since uploads up to 500 - 700 sentences get fully translated.</p>\n<p>Because Doulingo for free lets you upload only web-pages I will gather english chunks in a vk.com group (google docs can't be uploaded to Duolingo).</p>\n<p>I am posting this to make public commitment to continue to post chunks of untranslated chapters of HPMOR to Duolingo and get roughly translated texts out of it.</p>\n<p>Even though Doulingo translations usually are quite good I suspect that there got to be some kind of checking.</p>\n<p>What could be the solution? Could we organize e-mail broadcast for native Spanish speakers in LW to read and check translated chunks? They could be stored on google docs and be available for correction.</p>\n<p>And also if\\when I succeed in translation of a full chapter of HPMOR into spanish, how could it be added to hpmor site?&nbsp;</p>\n<p>&nbsp;</p>\n<p>[edit to add links]</p>\n<p>vk group with english and spanish chunks:https://vk.com/hpmor_en_to_sp_by_duolingo</p>\n<p>latest duolingo chunk (ch.25 part 2):&nbsp;https://www.duolingo.com/translation/b665ba41aa75970134b14adb81de9fcf</p>\n<p>first duolingo chunk (ch.25 full):&nbsp;https://www.duolingo.com/translation/7921153db4ef97a13e5c308151d0f8ae</p>\n<p>&nbsp;</p>\n<p>P.S this project might not work, if Duo users won't find content interesting enough.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KNFcxTr3zKWM39enF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 2.3041541552595768e-06, "legacy": true, "legacyId": "27781", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-25T20:43:44.825Z", "modifiedAt": null, "url": null, "title": "Methodology for predicting speed dating participants' decisions", "slug": "methodology-for-predicting-speed-dating-participants", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.197Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oDzoAA8HnBpX8Rj2k/methodology-for-predicting-speed-dating-participants", "pageUrlRelative": "/posts/oDzoAA8HnBpX8Rj2k/methodology-for-predicting-speed-dating-participants", "linkUrl": "https://www.lesswrong.com/posts/oDzoAA8HnBpX8Rj2k/methodology-for-predicting-speed-dating-participants", "postedAtFormatted": "Thursday, December 25th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Methodology%20for%20predicting%20speed%20dating%20participants'%20decisions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMethodology%20for%20predicting%20speed%20dating%20participants'%20decisions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoDzoAA8HnBpX8Rj2k%2Fmethodology-for-predicting-speed-dating-participants%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Methodology%20for%20predicting%20speed%20dating%20participants'%20decisions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoDzoAA8HnBpX8Rj2k%2Fmethodology-for-predicting-speed-dating-participants", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoDzoAA8HnBpX8Rj2k%2Fmethodology-for-predicting-speed-dating-participants", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2710, "htmlBody": "<p class=\"p1\">In my <a href=\"/lw/leh/using_machine_learning_to_predict_romantic/\"><span class=\"s1\">last post</span></a>&nbsp;I&nbsp;described phenomena that I used to predict speed dating participants' decisions by estimating the participants' general selectivity and perceived desirability. I was planning on following up with a discussion of the phenomena that I used to refine the model by taking into account <em>differences between individuals</em>. But since comments focused on methodology rather than the empirical phenomena, I decided to write about methodology first, so that readers wouldn't have to disbelief while reading my next post.&nbsp;</p>\n<p class=\"p1\">This post is more dense and technical than my last one. I wrote it for readers who want to check the details of the work, or who have strong interest in statistics and/or machine learning. If you don't fall into either category but are interest in the series, you can skip it without loss of continuity.&nbsp;</p>\n<p class=\"p1\">Here I'll address three points:</p>\n<ul class=\"ul1\">\n<li class=\"li3\">The situation that I attempted to simulate and how faithful one should expect the simulation to be.</li>\n<li class=\"li3\">The exact definitions of rating averages that I referenced in my last post</li>\n<li class=\"li3\">My criteria for including a feature in the model.</li>\n</ul>\n<div>Most of the code that I used is <a href=\"https://github.com/JonahSinick/speedDating\">here</a>.</div>\n<div><br /></div>\n<div><strong style=\"font-size: 16px;\">The simulation</strong></div>\n<p class=\"p1\">The underlying question that I attempted to address is \"Suppose that a speed dating company wanted to organize events with more matches. How could machine learning help?\"</p>\n<p class=\"p1\">As Ryan Carey&nbsp;<a href=\"/lw/leh/using_machine_learning_to_predict_romantic/brg5\"><span class=\"s1\">pointed out</span></a>, the model that I developed uses data about other speed dates that participants had been on to predict decisions on a given speed date.<em>&nbsp;</em>It is possible to make nontrivial predictions exclusively using information that was available before the participants attended the events, but I haven't systematically explored how well one could do. So the model that I developed is potentially useful only in the special case where participants had attended similar past events.</p>\n<p class=\"p1\">In fact, the participants in the dataset attended only a single speed dating event, not multiple events, so it's not possible to directly check whether the model would in fact predict behavior at future events based on past events. I instead <em>simulated</em> a situation where participants had attended similar events in the past, by imagining that for a given date, all other dates that the pair of people had been on had occurred in a past event.</p>\n<p class=\"p1\">It's very likely that the simulation overstates the predictive power that the model would give in practice, if for no other reason than regression to the mean. One example of this is that the most popular participants are more likely than usual to have been at their best on the day of the event than the other participants are, so that confidence that one can have that someone who was chosen by most of their dates at an event will be chosen by partners at a different event is lower than the confidence that one can have that the person will be chosen by partners at the same event.</p>\n<p class=\"p1\">If one were to apply the model in a real world setting, one would collect data that allowed one to quantify the expected regression to the mean, and also to improve the model.&nbsp;</p>\n<h2><strong>Average ratings</strong></h2>\n<p class=\"p1\">Conceptually, the foundation of the model is the idea that you can infer a participant's traits from:</p>\n<ul class=\"ul1\">\n<li class=\"li3\">Averages of the ratings that members of the opposite sex gave the participant (one average for each type of rating).&nbsp;</li>\n<li class=\"li3\">Averages of the ratings that the participant gave members of the opposite sex.</li>\n</ul>\n<p class=\"p3\">For the sake of limiting unnecessary verbiage, it's useful to think of the decision that a participant makes on a partner as a \"rating,\" where a 'no' decision corresponds to a rating of 0 and a 'yes' decision corresponds to a rating of 1.&nbsp;</p>\n<p class=\"p3\">The first point to make is that given a rater / ratee pair, we need to exclude from consideration both the ratings that the rater gave the ratee from consideration, and the ratings that the ratee gave the rater. This is because we're trying to predict whether two people&nbsp;<em>who have never been on a speed date</em>&nbsp;would be interested in seeing each other again if they were to go on a speed date.</p>\n<p class=\"p3\">Excluding these ratings wouldn't be&nbsp;<em>crucial</em> if the speed dating events involved each person going on thousands of speed dates: in that case, the ratings that the two people had given each other would correspond to slight perturbations of the averages. But when an event involves only ~15 people, the impact of a single rating on somebody's average can be large enough so that failing to exclude the individuals' ratings of one another would substantially overstate the predictive power of the model while simultaneously obscuring what was going on.</p>\n<p class=\"p3\">Given a rating type R, and two participants A and B whose decisions we're trying to predict, let R(A,B) be the rating that A gave B, and let R(B) be the sum of the ratings that were given to B. Let N be the number of people who rated B. One might think that the right features to look at are</p>\n<p class=\"p3\">[R(B) - R(A,B)]/(N - 1) &nbsp;(**)</p>\n<p class=\"p3\">But these features are still contaminated with the decisions we're trying to predict. To see this, consider the case of a dataset including only a single ratee B. In this case, R(B) is <strong>constant</strong>, so when the rating type R is 'decision,' the feature's value depends only on R(A,B), so that one can solve for R(A,B) in terms of the feature.&nbsp;</p>\n<p class=\"p3\">Even though we have many more than one rater, the contamination is still an issue. Some machine learning algorithms are capable of learning the identities of individual raters, and if they do so, they can learn how to solve (**) for each individual rater.</p>\n<p class=\"p3\">Rather than using (**), we imagine that at the event, B had been on a date with someone other than A, who we call a \"surrogate\" of A. We model the surrogate of A using another participant A' that B dated. Conceptually, A' is a randomly selected participant amongst the participants who B dated, but literally picking one at random would break the symmetry of the data in a way that could dilute the statistical power of the data, so I instead made a uniform choice to replace A by the participant who B would have dated that round if the speed dating schedule had been slightly different.</p>\n<p class=\"p3\">[R(B) - R(A,B) + R(A', B)]/N</p>\n<p class=\"p3\">In the special case where the rating type is \"decision,\" the averages correspond to frequencies, and for easy of comparison with other features these are most naturally replaced by their log odds ratios, so I did this.</p>\n<p class=\"p3\">I normalized these averages by subtracting off the average of all ratings that participants of B's gender would have received at the event had the surrogates of A and B attended the event in lieu of A and B. This washes out heterogeneity in raters' rating scales from event to event.&nbsp;</p>\n<h2><strong>Distinguishing noise from signal: my criteria for including a feature</strong></h2>\n<p>In order to avoid overfitting the dataset in a way that reduces the generalizability of the findings, &nbsp;I imposed a high threshold for features to meet to be included in the model. From the point of view of discovery, this was very helpful insofar as it helped me discover the core phenomena that I used. &nbsp;</p>\n<p>One could argue that the filters are collectively too strict, but I've chosen to use them for several reasons:</p>\n<ul>\n<li>The tendency to see signal in noise is so strong that it seems that it's nearly always the case that when people make effort to avoid it, they're not doing enough, so it seems better to err on the conservative side.</li>\n<li>I wanted to make an unambiguous case for the features that I <em>did</em> include adding incremental predictive power. I'm fairly confident that to the extent that the factors that influenced the participants at the event reflect general human behavioral tendencies, the predictive power of the features that I identified also generalizes. My main source of uncertainty is that nobody's checked my work in detail.&nbsp;</li>\n<li>From an expository point of view, the effect sizes of the features that I excluded are arguably too small for them to warrant comment. <br /><br />If I were strictly focused on optimizing for predictive power, I would have included features that improve predictive power by a tiny margin with 60% confidence, but I had no reason to do so: even in aggregate, the resulting difference in predictive power wouldn't have been striking, it's unlikely that anyone will actually use the model, and if even if someone does, there will be opportunities to collect more data and make a better model. <br /><br />What's interesting is not so much exactly how predictive the model is, but what the main driving factors are and how they interact.</li>\n</ul>\n<p>I've enumerated the criteria below.&nbsp;In practice, there&rsquo;s a fair amount of redundancy between them: if a feature didn&rsquo;t pass through one of them, it usually failed to pass through at least one other. But this fact only emerged gradually, and I used each individually at different times.</p>\n<h3>I tried to keep the number of features that I used small</h3>\n<p>The dataset that I&rsquo;ve been working is derived from 9 speed dating events involving ~160 people of each gender, for a total of ~3000 dates. The size is sufficiently large so that we can hope to get a broad sense for what&rsquo;s going on, but not sufficiently large so that we can determine the influence of individual idiosyncracies in great detail. If we hope for too much, we&rsquo;re apt to base our model on patterns that don&rsquo;t generalize, regardless of how much cross checking we do.</p>\n<p>My final model uses only 5 features to predict men's decisions and only 3 features to predict women's decisions.</p>\n<h3><strong>I only included a feature when the fact that it increased the model's performance was in consonance with my intuitions</strong></h3>\n<p>For example, I found that empirically, people who expressed a preference for people who share their interests were considered to be undesirable, but given the small size of the dataset and the absence of evidence for the phenomenon coming from other sources, using this to make predictions seemed ill-advised.</p>\n<h3><strong>I restricted myself to using features that were derived from a relatively large number of examples, both of speed dates and of people.</strong></h3>\n<p>The female engineering graduate students in the sample showed a very strong preference for male engineering graduate students over other men. They were also far more receptive to dating the male engineering students than other women were. The engineering/engineering cross feature passed through all other filters that I used aside from this one, but though there were 40 dates between engineering graduate students, they involved only 6 women, so I dropped the feature.</p>\n<h2><strong>I used cross validation</strong></h2>\n<p>Suppose there were 20 people who have some trait X, and that most of them were considered about as desirable as usual, but 2 of them were rejected by everyone. In this case it might so that it might look like people with trait X are a little less likely to be chosen. We don't want to base our model on participants' responses to only two people.&nbsp;</p>\n<p>If we split the dataset into two subsets, train our model on one, and test it on the other, then if one of the unpopular people is in the train set and one is in the test set, including the feature could increase the model's performance on the test set. With a dataset of this size, the boost in performance could be large enough so that one would be inclined to include the feature based on the increase in performance.</p>\n<p>The standard method used to avoid this problem is&nbsp;<em>cross-validation</em>: instead of using a single train/test split, use <em>many</em> train/test splits. If including a feature in the model improves performance for a large fraction of train/test splits of sufficiently low redundancy between them, that can provide much stronger evidence that that the predictive power of the feature will generalize.</p>\n<p>For each event, I split the data into a test set consisting the event, and a train set consisting of all other events. With this setup:</p>\n<ul>\n<li>When both of unpopular people are in the train set, including trait X as a feature makes the model's predictions for the test set worse.</li>\n<li>In the instances where one of the people is in the train set and the other is in the test set, including the feature may improve performance. But there are at most 2 such instances out of 9 train/test splits.</li>\n<li>Should it happen that both people were at the same event, including the feature won't improve performance for&nbsp;<em>any</em>&nbsp;of the events, because when the two people are in the test set, there's no pattern in the train set for the model to pick up on.<br /><br />The fact that the model never does better in this case case is helpful, because flukish occurrences are more likely to be concentrated in a single event than they are to be split up over a different events: for example, maybe the two unusual people are friends who have a lot in common and signed up for the same event together.&nbsp;</li>\n</ul>\n<p>I required that when predictions are generated in this way (with one train/test split for each event), every feature that I include improve performance</p>\n<ol>\n<li>When we average all predictions made <em>across the whole dataset</em>.</li>\n<li>For&nbsp;<em>a majority of events</em> when we look at the data by event.&nbsp;</li>\n<li>For<em> a majority of raters</em> when we look at the data by rater.</li>\n<li>For&nbsp;<em>a majority of ratees</em> when we look at the dataset by ratee.</li>\n</ol>\n<div>\n<p>Having spent a long time with the dataset, it was more or less clear to me that that the train/test splits that I used were enough, but I realized this may not be <em>a priori</em>&nbsp;clear, so I did a final check in which before forming the train/test splits, I removed each individual from the dataset in turn, and each wave from the dataset in turn. &nbsp;This is in the spirit of &nbsp;<a href=\"http://en.wikipedia.org/wiki/Cross-validation_%28statistics%29#Exhaustive_cross-validation\">leave-one-out cross validation</a>. It turns out to be overkill: (1)-(4) are never violated for any feature that I used, except for one that occasionally fell short of meeting criterion (4) by a single ratee.</p>\n<p>I measured performance using \"log loss,\" which is a technical measure of the quality of probabilistic predictions. I omit a description of it because I figure that readers either already know it or don't have the time/energy to absorb an explanation, but I can write about it if someone would like. &nbsp;</p>\n<p>The tables below show how much predictive power increases when we include a given feature, starting from a base consisting of all other features that we used. Here the columns correspond to criteria (1)-(4), and the numbers in the \"Avg boost\" column are drops in log loss. Since I haven't defined the features, I've left them unlabeled, but I'll label them once I've written my next post.</p>\n<p style=\"line-height:1.15;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Women&rsquo;s decisions:</span></p>\n<p style=\"line-height:1.15;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt; padding-left: 90px;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\"><br /></span></p>\n<div style=\"margin-left: 0pt; padding-left: 90px;\" dir=\"ltr\">\n<table style=\"border: none; border-collapse: collapse; width: 624px;\" border=\"0\">\n<colgroup><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col></colgroup> \n<tbody>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Feature</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Avg boost</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% events </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% of raters</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% ratees </span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">1</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0874</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">63%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">83%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">2</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0645</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">75%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">69%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">3</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0035</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">58%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">55%</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p style=\"padding-left: 90px;\"><strong id=\"docs-internal-guid-d74a0863-74d8-4e4f-05c8-b195cc9e115a\" style=\"font-weight:normal;\"><br /></strong></p>\n<p style=\"line-height:1.15;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\"><span style=\"font-size:16px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Men&rsquo;s decisions: </span></p>\n<p style=\"padding-left: 90px;\"><strong style=\"font-weight:normal;\"><br /></strong></p>\n<div style=\"margin-left: 0pt; padding-left: 90px;\" dir=\"ltr\">\n<table style=\"border: none; border-collapse: collapse; width: 624px;\" border=\"0\">\n<colgroup><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col><col width=\"*\"></col></colgroup> \n<tbody>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Feature</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Avg boost</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% events </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% of raters</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% ratees </span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">1</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.1162</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">64%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">90%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">2</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0874</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">84%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">72%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">3</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0030</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">78%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">56%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">53%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">4</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0024</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">89%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">55%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">55%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">5</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0017</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">67%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">64%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">67%</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>&nbsp;</p>\n<p>The tables and the criteria that I described don't tell the whole story as far as overfitting goes: the features depend on numerical parameters, <em>which are themselves overfit to the model,</em> in the sense that to some extent I picked them with a view toward maximizing the numbers in the table.</p>\n<p>But this sort of overfitting corresponds to <em>optimizing the expected performance of the model on hypothetical future datasets</em>, which is the opposite of <em>picking features that are likely to be predictive only in the context of the dataset</em>. It overstates the predictive power of the model in more general contexts, but it's simultaneously the case that not doing it would produce a model that performs worse in general settings.</p>\n<p>The choices that I made seem fairly natural, and to the extent that they overstate the model's predictive power, the effect seems likely to be minor. If one had more data, one could obtain improved estimates for the numerical parameters. The more serious distortion in potential predictive power comes from the absence of data on participants across multiple events.&nbsp;</p>\n<p><em>Thanks to Brian Tomasik for catching an error in an earlier version of this post.</em></p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oDzoAA8HnBpX8Rj2k", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 2.304195377255728e-06, "legacy": true, "legacyId": "27766", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"p1\">In my <a href=\"/lw/leh/using_machine_learning_to_predict_romantic/\"><span class=\"s1\">last post</span></a>&nbsp;I&nbsp;described phenomena that I used to predict speed dating participants' decisions by estimating the participants' general selectivity and perceived desirability. I was planning on following up with a discussion of the phenomena that I used to refine the model by taking into account <em>differences between individuals</em>. But since comments focused on methodology rather than the empirical phenomena, I decided to write about methodology first, so that readers wouldn't have to disbelief while reading my next post.&nbsp;</p>\n<p class=\"p1\">This post is more dense and technical than my last one. I wrote it for readers who want to check the details of the work, or who have strong interest in statistics and/or machine learning. If you don't fall into either category but are interest in the series, you can skip it without loss of continuity.&nbsp;</p>\n<p class=\"p1\">Here I'll address three points:</p>\n<ul class=\"ul1\">\n<li class=\"li3\">The situation that I attempted to simulate and how faithful one should expect the simulation to be.</li>\n<li class=\"li3\">The exact definitions of rating averages that I referenced in my last post</li>\n<li class=\"li3\">My criteria for including a feature in the model.</li>\n</ul>\n<div>Most of the code that I used is <a href=\"https://github.com/JonahSinick/speedDating\">here</a>.</div>\n<div><br></div>\n<div><strong style=\"font-size: 16px;\">The simulation</strong></div>\n<p class=\"p1\">The underlying question that I attempted to address is \"Suppose that a speed dating company wanted to organize events with more matches. How could machine learning help?\"</p>\n<p class=\"p1\">As Ryan Carey&nbsp;<a href=\"/lw/leh/using_machine_learning_to_predict_romantic/brg5\"><span class=\"s1\">pointed out</span></a>, the model that I developed uses data about other speed dates that participants had been on to predict decisions on a given speed date.<em>&nbsp;</em>It is possible to make nontrivial predictions exclusively using information that was available before the participants attended the events, but I haven't systematically explored how well one could do. So the model that I developed is potentially useful only in the special case where participants had attended similar past events.</p>\n<p class=\"p1\">In fact, the participants in the dataset attended only a single speed dating event, not multiple events, so it's not possible to directly check whether the model would in fact predict behavior at future events based on past events. I instead <em>simulated</em> a situation where participants had attended similar events in the past, by imagining that for a given date, all other dates that the pair of people had been on had occurred in a past event.</p>\n<p class=\"p1\">It's very likely that the simulation overstates the predictive power that the model would give in practice, if for no other reason than regression to the mean. One example of this is that the most popular participants are more likely than usual to have been at their best on the day of the event than the other participants are, so that confidence that one can have that someone who was chosen by most of their dates at an event will be chosen by partners at a different event is lower than the confidence that one can have that the person will be chosen by partners at the same event.</p>\n<p class=\"p1\">If one were to apply the model in a real world setting, one would collect data that allowed one to quantify the expected regression to the mean, and also to improve the model.&nbsp;</p>\n<h2 id=\"Average_ratings\"><strong>Average ratings</strong></h2>\n<p class=\"p1\">Conceptually, the foundation of the model is the idea that you can infer a participant's traits from:</p>\n<ul class=\"ul1\">\n<li class=\"li3\">Averages of the ratings that members of the opposite sex gave the participant (one average for each type of rating).&nbsp;</li>\n<li class=\"li3\">Averages of the ratings that the participant gave members of the opposite sex.</li>\n</ul>\n<p class=\"p3\">For the sake of limiting unnecessary verbiage, it's useful to think of the decision that a participant makes on a partner as a \"rating,\" where a 'no' decision corresponds to a rating of 0 and a 'yes' decision corresponds to a rating of 1.&nbsp;</p>\n<p class=\"p3\">The first point to make is that given a rater / ratee pair, we need to exclude from consideration both the ratings that the rater gave the ratee from consideration, and the ratings that the ratee gave the rater. This is because we're trying to predict whether two people&nbsp;<em>who have never been on a speed date</em>&nbsp;would be interested in seeing each other again if they were to go on a speed date.</p>\n<p class=\"p3\">Excluding these ratings wouldn't be&nbsp;<em>crucial</em> if the speed dating events involved each person going on thousands of speed dates: in that case, the ratings that the two people had given each other would correspond to slight perturbations of the averages. But when an event involves only ~15 people, the impact of a single rating on somebody's average can be large enough so that failing to exclude the individuals' ratings of one another would substantially overstate the predictive power of the model while simultaneously obscuring what was going on.</p>\n<p class=\"p3\">Given a rating type R, and two participants A and B whose decisions we're trying to predict, let R(A,B) be the rating that A gave B, and let R(B) be the sum of the ratings that were given to B. Let N be the number of people who rated B. One might think that the right features to look at are</p>\n<p class=\"p3\">[R(B) - R(A,B)]/(N - 1) &nbsp;(**)</p>\n<p class=\"p3\">But these features are still contaminated with the decisions we're trying to predict. To see this, consider the case of a dataset including only a single ratee B. In this case, R(B) is <strong>constant</strong>, so when the rating type R is 'decision,' the feature's value depends only on R(A,B), so that one can solve for R(A,B) in terms of the feature.&nbsp;</p>\n<p class=\"p3\">Even though we have many more than one rater, the contamination is still an issue. Some machine learning algorithms are capable of learning the identities of individual raters, and if they do so, they can learn how to solve (**) for each individual rater.</p>\n<p class=\"p3\">Rather than using (**), we imagine that at the event, B had been on a date with someone other than A, who we call a \"surrogate\" of A. We model the surrogate of A using another participant A' that B dated. Conceptually, A' is a randomly selected participant amongst the participants who B dated, but literally picking one at random would break the symmetry of the data in a way that could dilute the statistical power of the data, so I instead made a uniform choice to replace A by the participant who B would have dated that round if the speed dating schedule had been slightly different.</p>\n<p class=\"p3\">[R(B) - R(A,B) + R(A', B)]/N</p>\n<p class=\"p3\">In the special case where the rating type is \"decision,\" the averages correspond to frequencies, and for easy of comparison with other features these are most naturally replaced by their log odds ratios, so I did this.</p>\n<p class=\"p3\">I normalized these averages by subtracting off the average of all ratings that participants of B's gender would have received at the event had the surrogates of A and B attended the event in lieu of A and B. This washes out heterogeneity in raters' rating scales from event to event.&nbsp;</p>\n<h2 id=\"Distinguishing_noise_from_signal__my_criteria_for_including_a_feature\"><strong>Distinguishing noise from signal: my criteria for including a feature</strong></h2>\n<p>In order to avoid overfitting the dataset in a way that reduces the generalizability of the findings, &nbsp;I imposed a high threshold for features to meet to be included in the model. From the point of view of discovery, this was very helpful insofar as it helped me discover the core phenomena that I used. &nbsp;</p>\n<p>One could argue that the filters are collectively too strict, but I've chosen to use them for several reasons:</p>\n<ul>\n<li>The tendency to see signal in noise is so strong that it seems that it's nearly always the case that when people make effort to avoid it, they're not doing enough, so it seems better to err on the conservative side.</li>\n<li>I wanted to make an unambiguous case for the features that I <em>did</em> include adding incremental predictive power. I'm fairly confident that to the extent that the factors that influenced the participants at the event reflect general human behavioral tendencies, the predictive power of the features that I identified also generalizes. My main source of uncertainty is that nobody's checked my work in detail.&nbsp;</li>\n<li>From an expository point of view, the effect sizes of the features that I excluded are arguably too small for them to warrant comment. <br><br>If I were strictly focused on optimizing for predictive power, I would have included features that improve predictive power by a tiny margin with 60% confidence, but I had no reason to do so: even in aggregate, the resulting difference in predictive power wouldn't have been striking, it's unlikely that anyone will actually use the model, and if even if someone does, there will be opportunities to collect more data and make a better model. <br><br>What's interesting is not so much exactly how predictive the model is, but what the main driving factors are and how they interact.</li>\n</ul>\n<p>I've enumerated the criteria below.&nbsp;In practice, there\u2019s a fair amount of redundancy between them: if a feature didn\u2019t pass through one of them, it usually failed to pass through at least one other. But this fact only emerged gradually, and I used each individually at different times.</p>\n<h3 id=\"I_tried_to_keep_the_number_of_features_that_I_used_small\">I tried to keep the number of features that I used small</h3>\n<p>The dataset that I\u2019ve been working is derived from 9 speed dating events involving ~160 people of each gender, for a total of ~3000 dates. The size is sufficiently large so that we can hope to get a broad sense for what\u2019s going on, but not sufficiently large so that we can determine the influence of individual idiosyncracies in great detail. If we hope for too much, we\u2019re apt to base our model on patterns that don\u2019t generalize, regardless of how much cross checking we do.</p>\n<p>My final model uses only 5 features to predict men's decisions and only 3 features to predict women's decisions.</p>\n<h3 id=\"I_only_included_a_feature_when_the_fact_that_it_increased_the_model_s_performance_was_in_consonance_with_my_intuitions\"><strong>I only included a feature when the fact that it increased the model's performance was in consonance with my intuitions</strong></h3>\n<p>For example, I found that empirically, people who expressed a preference for people who share their interests were considered to be undesirable, but given the small size of the dataset and the absence of evidence for the phenomenon coming from other sources, using this to make predictions seemed ill-advised.</p>\n<h3 id=\"I_restricted_myself_to_using_features_that_were_derived_from_a_relatively_large_number_of_examples__both_of_speed_dates_and_of_people_\"><strong>I restricted myself to using features that were derived from a relatively large number of examples, both of speed dates and of people.</strong></h3>\n<p>The female engineering graduate students in the sample showed a very strong preference for male engineering graduate students over other men. They were also far more receptive to dating the male engineering students than other women were. The engineering/engineering cross feature passed through all other filters that I used aside from this one, but though there were 40 dates between engineering graduate students, they involved only 6 women, so I dropped the feature.</p>\n<h2 id=\"I_used_cross_validation\"><strong>I used cross validation</strong></h2>\n<p>Suppose there were 20 people who have some trait X, and that most of them were considered about as desirable as usual, but 2 of them were rejected by everyone. In this case it might so that it might look like people with trait X are a little less likely to be chosen. We don't want to base our model on participants' responses to only two people.&nbsp;</p>\n<p>If we split the dataset into two subsets, train our model on one, and test it on the other, then if one of the unpopular people is in the train set and one is in the test set, including the feature could increase the model's performance on the test set. With a dataset of this size, the boost in performance could be large enough so that one would be inclined to include the feature based on the increase in performance.</p>\n<p>The standard method used to avoid this problem is&nbsp;<em>cross-validation</em>: instead of using a single train/test split, use <em>many</em> train/test splits. If including a feature in the model improves performance for a large fraction of train/test splits of sufficiently low redundancy between them, that can provide much stronger evidence that that the predictive power of the feature will generalize.</p>\n<p>For each event, I split the data into a test set consisting the event, and a train set consisting of all other events. With this setup:</p>\n<ul>\n<li>When both of unpopular people are in the train set, including trait X as a feature makes the model's predictions for the test set worse.</li>\n<li>In the instances where one of the people is in the train set and the other is in the test set, including the feature may improve performance. But there are at most 2 such instances out of 9 train/test splits.</li>\n<li>Should it happen that both people were at the same event, including the feature won't improve performance for&nbsp;<em>any</em>&nbsp;of the events, because when the two people are in the test set, there's no pattern in the train set for the model to pick up on.<br><br>The fact that the model never does better in this case case is helpful, because flukish occurrences are more likely to be concentrated in a single event than they are to be split up over a different events: for example, maybe the two unusual people are friends who have a lot in common and signed up for the same event together.&nbsp;</li>\n</ul>\n<p>I required that when predictions are generated in this way (with one train/test split for each event), every feature that I include improve performance</p>\n<ol>\n<li>When we average all predictions made <em>across the whole dataset</em>.</li>\n<li>For&nbsp;<em>a majority of events</em> when we look at the data by event.&nbsp;</li>\n<li>For<em> a majority of raters</em> when we look at the data by rater.</li>\n<li>For&nbsp;<em>a majority of ratees</em> when we look at the dataset by ratee.</li>\n</ol>\n<div>\n<p>Having spent a long time with the dataset, it was more or less clear to me that that the train/test splits that I used were enough, but I realized this may not be <em>a priori</em>&nbsp;clear, so I did a final check in which before forming the train/test splits, I removed each individual from the dataset in turn, and each wave from the dataset in turn. &nbsp;This is in the spirit of &nbsp;<a href=\"http://en.wikipedia.org/wiki/Cross-validation_%28statistics%29#Exhaustive_cross-validation\">leave-one-out cross validation</a>. It turns out to be overkill: (1)-(4) are never violated for any feature that I used, except for one that occasionally fell short of meeting criterion (4) by a single ratee.</p>\n<p>I measured performance using \"log loss,\" which is a technical measure of the quality of probabilistic predictions. I omit a description of it because I figure that readers either already know it or don't have the time/energy to absorb an explanation, but I can write about it if someone would like. &nbsp;</p>\n<p>The tables below show how much predictive power increases when we include a given feature, starting from a base consisting of all other features that we used. Here the columns correspond to criteria (1)-(4), and the numbers in the \"Avg boost\" column are drops in log loss. Since I haven't defined the features, I've left them unlabeled, but I'll label them once I've written my next post.</p>\n<p style=\"line-height:1.15;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Women\u2019s decisions:</span></p>\n<p style=\"line-height:1.15;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt; padding-left: 90px;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\"><br></span></p>\n<div style=\"margin-left: 0pt; padding-left: 90px;\" dir=\"ltr\">\n<table style=\"border: none; border-collapse: collapse; width: 624px;\" border=\"0\">\n<colgroup><col width=\"*\"><col width=\"*\"><col width=\"*\"><col width=\"*\"><col width=\"*\"></colgroup> \n<tbody>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Feature</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Avg boost</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% events </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% of raters</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% ratees </span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">1</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0874</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">63%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">83%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">2</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0645</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">75%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">69%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">3</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0035</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">58%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">55%</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p style=\"padding-left: 90px;\"><strong id=\"docs-internal-guid-d74a0863-74d8-4e4f-05c8-b195cc9e115a\" style=\"font-weight:normal;\"><br></strong></p>\n<p style=\"line-height:1.15;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\"><span style=\"font-size:16px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Men\u2019s decisions: </span></p>\n<p style=\"padding-left: 90px;\"><strong style=\"font-weight:normal;\"><br></strong></p>\n<div style=\"margin-left: 0pt; padding-left: 90px;\" dir=\"ltr\">\n<table style=\"border: none; border-collapse: collapse; width: 624px;\" border=\"0\">\n<colgroup><col width=\"*\"><col width=\"*\"><col width=\"*\"><col width=\"*\"><col width=\"*\"></colgroup> \n<tbody>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Feature</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">Avg boost</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% events </span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% of raters</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:bold;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">% ratees </span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">1</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.1162</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">64%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">90%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">2</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0874</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">100%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">84%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">72%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">3</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0030</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">78%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">56%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">53%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">4</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0024</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">89%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">55%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">55%</span></p>\n</td>\n</tr>\n<tr style=\"height: 0px;\">\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">5</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">0.0017</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">67%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">64%</span></p>\n</td>\n<td style=\"border-left:solid #000000 1px;border-right:solid #000000 1px;border-bottom:solid #000000 1px;border-top:solid #000000 1px;vertical-align:top;padding:7px 7px 7px 7px\">\n<p style=\"line-height:1;margin-top:0pt;margin-bottom:0pt;text-align: center;\" dir=\"ltr\"><span style=\"font-size:15px;font-family:Arial;color:#000000;background-color:transparent;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre-wrap;\">67%</span></p>\n</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>&nbsp;</p>\n<p>The tables and the criteria that I described don't tell the whole story as far as overfitting goes: the features depend on numerical parameters, <em>which are themselves overfit to the model,</em> in the sense that to some extent I picked them with a view toward maximizing the numbers in the table.</p>\n<p>But this sort of overfitting corresponds to <em>optimizing the expected performance of the model on hypothetical future datasets</em>, which is the opposite of <em>picking features that are likely to be predictive only in the context of the dataset</em>. It overstates the predictive power of the model in more general contexts, but it's simultaneously the case that not doing it would produce a model that performs worse in general settings.</p>\n<p>The choices that I made seem fairly natural, and to the extent that they overstate the model's predictive power, the effect seems likely to be minor. If one had more data, one could obtain improved estimates for the numerical parameters. The more serious distortion in potential predictive power comes from the absence of data on participants across multiple events.&nbsp;</p>\n<p><em>Thanks to Brian Tomasik for catching an error in an earlier version of this post.</em></p>\n</div>", "sections": [{"title": "Average ratings", "anchor": "Average_ratings", "level": 1}, {"title": "Distinguishing noise from signal: my criteria for including a feature", "anchor": "Distinguishing_noise_from_signal__my_criteria_for_including_a_feature", "level": 1}, {"title": "I tried to keep the number of features that I used small", "anchor": "I_tried_to_keep_the_number_of_features_that_I_used_small", "level": 2}, {"title": "I only included a feature when the fact that it increased the model's performance was in consonance with my intuitions", "anchor": "I_only_included_a_feature_when_the_fact_that_it_increased_the_model_s_performance_was_in_consonance_with_my_intuitions", "level": 2}, {"title": "I restricted myself to using features that were derived from a relatively large number of examples, both of speed dates and of people.", "anchor": "I_restricted_myself_to_using_features_that_were_derived_from_a_relatively_large_number_of_examples__both_of_speed_dates_and_of_people_", "level": 2}, {"title": "I used cross validation", "anchor": "I_used_cross_validation", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uBNj85TAB2cikby2W"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-26T04:52:29.780Z", "modifiedAt": null, "url": null, "title": "LINK: TED-Ed video on death and cryonics", "slug": "link-ted-ed-video-on-death-and-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.436Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "maxikov", "createdAt": "2013-11-04T11:12:40.554Z", "isAdmin": false, "displayName": "maxikov"}, "userId": "oFpSN9vb5L3ryvKrB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RH26B4u66WMTqre4a/link-ted-ed-video-on-death-and-cryonics", "pageUrlRelative": "/posts/RH26B4u66WMTqre4a/link-ted-ed-video-on-death-and-cryonics", "linkUrl": "https://www.lesswrong.com/posts/RH26B4u66WMTqre4a/link-ted-ed-video-on-death-and-cryonics", "postedAtFormatted": "Friday, December 26th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20TED-Ed%20video%20on%20death%20and%20cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20TED-Ed%20video%20on%20death%20and%20cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRH26B4u66WMTqre4a%2Flink-ted-ed-video-on-death-and-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20TED-Ed%20video%20on%20death%20and%20cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRH26B4u66WMTqre4a%2Flink-ted-ed-video-on-death-and-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRH26B4u66WMTqre4a%2Flink-ted-ed-video-on-death-and-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 44, "htmlBody": "<p><a href=\"https://www.youtube.com/watch?v=5c6C3rHOdf8\">At what moment are you dead? - Randall Hayes</a></p>\n<p>This is pretty much 101, and it leaves out some important considerations, but it had nice animation, and I think it may be a great starting point for introducing people to cryonics for the first time.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RH26B4u66WMTqre4a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 10, "extendedScore": null, "score": 2.305320141076083e-06, "legacy": true, "legacyId": "27782", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-26T06:53:26.244Z", "modifiedAt": null, "url": null, "title": "Open and closed mental states", "slug": "open-and-closed-mental-states", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:22.743Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vika", "createdAt": "2011-07-19T00:49:34.750Z", "isAdmin": false, "displayName": "Vika"}, "userId": "TcbcdwBCSWNzimtKp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MYQgaisqQRzMajx2f/open-and-closed-mental-states", "pageUrlRelative": "/posts/MYQgaisqQRzMajx2f/open-and-closed-mental-states", "linkUrl": "https://www.lesswrong.com/posts/MYQgaisqQRzMajx2f/open-and-closed-mental-states", "postedAtFormatted": "Friday, December 26th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20and%20closed%20mental%20states&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20and%20closed%20mental%20states%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMYQgaisqQRzMajx2f%2Fopen-and-closed-mental-states%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20and%20closed%20mental%20states%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMYQgaisqQRzMajx2f%2Fopen-and-closed-mental-states", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMYQgaisqQRzMajx2f%2Fopen-and-closed-mental-states", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 547, "htmlBody": "<p>I learned a game at Burning Man this year that was about connecting to people and reading their nonverbal signals, called the \"open-closed\" game (h/t Minda Myers).&nbsp;There are two people in the game, and one is trying to approach the other and place a hand on their shoulder. No words can be exchanged, except that person who is being approached can announce their emotional state as \"open\" or \"closed\". When they say \"closed\", the approacher may not get any closer until they say \"open\" again. The approachee monitors themselves for any internal discomfort associated with the other person, and says \"closed\" if that is the case. The approacher tries to keep the other person comfortable through their body language and eye contact, to get them to remain \"open\".</p>\n<p>I have recently started playing this game with myself, with \"open\" representing openness to experience or being in the moment, and \"closed\" representing tunnel vision or discomfort with the way things are going. In a way, I imagine being \"approached\" by whatever situation I'm in, or whatever sequence of experiences is happening, instead of a person. I ask myself whether I am in the open or closed state, and try to shift to the open state whenever I notice being in the closed state.</p>\n<p>There are a couple of reasons to try to do this. In the open state, I tend to be happier, more curious and observant and have more new thoughts. From a week of tracking my mental states and thought status using TagTime, I can make a preliminary conclusion that while old thoughts do occur in the open state, new thoughts never occur in the closed state. While the closed state makes me more efficient at doing straightforward tasks (e.g. by making me less distractable), it makes me less efficient at doing less straightforward tasks (e.g. by increasing my tendency to optimize locally rather than globally).</p>\n<p>This is related to the concept of \"againstness\" taught by Valentine Smith at CFAR, which is a sense of resisting something about the situation at hand. Learning to notice this sense more quickly is a valuable thing I learned at CFAR and through my meditation practice. Redirecting attention to body sensations is supposed to be helpful for dissipating againstness, but I have found it difficult to get myself to do this in the moment, and not particularly reliable. Following the driving principle of \"focusing on the road and not the curb\", I find it easier to shift to a mental state with a simple salient label like \"open\" instead of a clunky label like \"non-againsty\". It also feels less judgmental to ask myself \"what am I closed to right now, what experience am I not letting in?\" than \"what am I against right now?\".</p>\n<p>The againstness approach seems to be about relaxing the mind by relaxing the body first, while for some people relaxing the mind first comes more naturally - I actually find myself automatically breathing deeper when shifting into the open state. For both approaches, the goal is the same - to let go of mental and physical tension before proceeding with what you are doing. The rule of thumb, like in the game, is to first get into the open state and then approach the situation at hand.</p>\n<p>(Cross-posted from my <a href=\"http://vkrakovna.wordpress.com/2014/12/26/open-and-closed-mental-states\">blog</a>).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MYQgaisqQRzMajx2f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 31, "extendedScore": null, "score": 0.000141, "legacy": true, "legacyId": "27783", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-26T15:33:08.388Z", "modifiedAt": null, "url": null, "title": "CFAR in 2014: Continuing to climb out of the startup pit, heading toward a full prototype", "slug": "cfar-in-2014-continuing-to-climb-out-of-the-startup-pit", "viewCount": null, "lastCommentedAt": "2017-06-17T04:25:09.008Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KDGnsReYomusL89Rs/cfar-in-2014-continuing-to-climb-out-of-the-startup-pit", "pageUrlRelative": "/posts/KDGnsReYomusL89Rs/cfar-in-2014-continuing-to-climb-out-of-the-startup-pit", "linkUrl": "https://www.lesswrong.com/posts/KDGnsReYomusL89Rs/cfar-in-2014-continuing-to-climb-out-of-the-startup-pit", "postedAtFormatted": "Friday, December 26th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20CFAR%20in%202014%3A%20Continuing%20to%20climb%20out%20of%20the%20startup%20pit%2C%20heading%20toward%20a%20full%20prototype&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACFAR%20in%202014%3A%20Continuing%20to%20climb%20out%20of%20the%20startup%20pit%2C%20heading%20toward%20a%20full%20prototype%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDGnsReYomusL89Rs%2Fcfar-in-2014-continuing-to-climb-out-of-the-startup-pit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=CFAR%20in%202014%3A%20Continuing%20to%20climb%20out%20of%20the%20startup%20pit%2C%20heading%20toward%20a%20full%20prototype%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDGnsReYomusL89Rs%2Fcfar-in-2014-continuing-to-climb-out-of-the-startup-pit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDGnsReYomusL89Rs%2Fcfar-in-2014-continuing-to-climb-out-of-the-startup-pit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4624, "htmlBody": "<p>Summary: &nbsp;We outline CFAR&rsquo;s purpose, our history in 2014, and our plans heading into 2015.</p>\n<ul>\n<li><a href=\"#highlights\">Highlights from 2014</a>.</li>\n<li><a href=\"#operations\">Improving operations</a>.</li>\n<li><a href=\"#attempts\">Attempts to go beyond the current workshop and toward the &lsquo;full prototype&rsquo; of CFAR: our experience in 2014 and plans for 2015</a>.</li>\n<li><a href=\"#nuts\">Nuts, bolts, and financial details</a>.</li>\n<li><a href=\"#howhelp\">The big picture and how you can help</a>.</li>\n</ul>\n<p>One of the reasons we&rsquo;re publishing this review now is that we&rsquo;ve just launched our annual matching <a href=\"http://rationality.org/fundraiser2014/\">fundraiser</a>, and want to provide the information our prospective donors need for deciding. <strong>This is the best time of year to decide to donate to CFAR. Donations up to $120k will be matched until January 31.</strong><a href=\"#match\">[1]</a>&nbsp;</p>\n<p>To briefly preview: For the first three years of our existence, CFAR mostly focused on getting going. We followed the standard recommendation to build a &lsquo;minimum viable product&rsquo;, the CFAR workshops, that could test our ideas and generate some revenue. Coming into 2013, we had a workshop that people liked (9.3 average rating on &ldquo;Are you glad you came?&rdquo;; a more recent random survey showed 9.6 average rating on the same question 6-24 months later), which helped keep the lights on and gave us articulate, skeptical, serious learners to iterate on. At the same time, the workshops are not everything we would want in a CFAR prototype; it feels like the current core workshop does not stress-test most of our hopes for what CFAR can eventually do. The premise of CFAR is that we should be able to apply the modern understanding of cognition to improve people&rsquo;s ability to (1) figure out the truth (2) be strategically effective (3) do good in the world. We have dreams of scaling up some particular kinds of sanity. &nbsp;Our next goal is to build the minimum strategic product that more directly justifies CFAR&rsquo;s claim to be an effective altruist project.<a href=\"#author\">[2]</a></p>\n<p><a id=\"more\"></a></p>\n<h1><a name=\"highlights\"></a>Highlights from 2014</h1>\n<p>Our brand perception improved significantly in 2014, which matters because it leads to companies being willing to pay for workshop attendance. &nbsp;We were covered in&nbsp;<a href=\"http://www.fastcompany.com/3037333/most-creative-people/inside-the-rationality-movement-that-has-silicon-valley-buzzing-with-po\">Fast Company</a>&nbsp;--&nbsp;<a href=\"http://www.fastcompany.com/3035671/how-i-get-it-done/a-new-technique-for-creating-more-aha-moments-the-surprise-journal\">twice</a>&nbsp;--&nbsp;the&nbsp;<a href=\"http://www.wsj.com/news/articles/SB10001424052702303453004579290510733740616?mod=e2fb\">Wall Street Journal</a>, and&nbsp;<a href=\"http://www.academia.edu/9623753/The_Center_for_Applied_Rationality_practical_techniques_for_overcoming_biases\">The Reasoner</a>. &nbsp;Other mentions include&nbsp;<a href=\"http://www.forbes.com/sites/learnvest/2014/01/28/6-times-we-betray-our-budgets-and-clever-ways-to-stop/\">Forbes</a>,&nbsp;<a href=\"http://bigthink.com/videos/rationality-in-action-look-at-a-problem-as-an-outsider-2\">Big Think</a>,&nbsp;<a href=\"http://boingboing.net/2014/08/24/habits-for-living-a-more-ratio.html\">Boing Boing</a>, and&nbsp;<a href=\"http://lifehacker.com/carry-a-surprise-journal-to-find-areas-for-self-impro-1638467349\">Lifehacker</a>. &nbsp;We&rsquo;ve also had some interest in potential training for tech companies.</p>\n<p>Our curriculum is gaining a second tier in the form of alumni workshops. &nbsp;We tried 4 experimental alumni workshops, 3 of which went well enough to be worth iterating:</p>\n<ul>\n<li>The Hamming Question: &nbsp;&ldquo;What are the most important problems in your life, and why aren&rsquo;t you working on them?&rdquo; &nbsp;This 2.5-day workshop was extremely well received, and gave rise to a new unit for our introductory workshop.</li>\n<li>Assisting Others<a href=\"#tatrain\">[3]</a>: &nbsp;A two-weekend (training, then practicum) workshop investigating the close link between helping others debug their problems, and better debugging your own problems. &nbsp;We ran a version of this in the Bay Area that worked, and an abridged version in the UK that didn&rsquo;t. &nbsp;(This was our fault. &nbsp;We&rsquo;re sorry.)</li>\n<li>Attention Workshop: &nbsp;A 2.5-day workshop on clearing mental space. &nbsp;This failed and taught us some important points about what doesn&rsquo;t work.</li>\n<li>Epistemic Rationality for Effective Altruists: &nbsp;A standalone 2.5-day workshop on applying techniques from the introductory workshop to factual questions, especially those related to effective altruism. (More on this below.) &nbsp;The attendees from this and the Hamming workshop spontaneously organized recurring meetups for themselves.</li>\n</ul>\n<p>Our alumni community continues to grow. &nbsp;There are now 550 CFAR alumni, counting 90 from SPARC. &nbsp;It&rsquo;s a high-initiative group. Startups by CFAR alumni include: <a href=\"http://apptimize.com/\">Apptimize</a>; <a href=\"http://bellroy.com/\">Bellroy</a>; <a href=\"http://beeminder.com/\">Beeminder</a>; <a href=\"https://complice.co/\">Complice</a>; <a href=\"http://codecombat.com/\">Code Combat</a>; <a href=\"https://draftable.com/\">Draftable</a>; <a href=\"http://www.mealsquares.com/\">MealSquares</a>; <a href=\"https://gigaom.com/2014/06/30/hadoop-specialist-wandisco-acquires-hbase-like-startup-ohmdata/\">OhmData</a>; <a href=\"http://www.praxamed.com/\">Praxamed</a>; <a href=\"http://vesparum.com/\">Vesparum</a>; <a href=\"http://teleport.org/\">Teleport</a>; <a href=\"http://watuapp.com/\">Watu</a>; <a href=\"http://www.sendwave.com/\">Wave</a>; <a href=\"https://zerocater.com/\">ZeroCater</a>.<a href=\"#startups\">[4]</a> There is a highly active mailing list with over 400 members, and over 600 conversation threads, over 30 of which were active in the last month. &nbsp;We also ran our first-ever alumni reunion, and started a weekly alumni dojo. &nbsp;This enabled further curricular experimentation, and allowed alumni ideas and experiences to feed into curricular design.&nbsp;</p>\n<p>SPARC happened again, with more-honed curriculum and nearly twice as many students.</p>\n<p>Basic operations improved substantially. &nbsp;We&rsquo;ll say more on this in section 2.</p>\n<p>Iteration on the flagship workshop continues. &nbsp;We&rsquo;ll say more on this (including details of what we learned, and what remains puzzling) in section 3.</p>\n<h1><a name=\"operations\"></a>Improving operations</h1>\n<p>The two driving themes of CFAR during 2014 were making our operations more stable and sustainable, and our successful struggle to pull our introductory workshop out of a local optimum and get back on track toward something that is more like a &lsquo;full prototype&rsquo; of the CFAR concept.</p>\n<p>At the end of 2013, we had negative $30,000 and had borrowed money to make payroll, placing us in the &lsquo;very early stage, struggling startup&rsquo; phase. Almost all of our regular operations, such as scheduling interviews for workshop admissions, were being done by hand. Much of our real progress in 2014 consisted of making things run smoothly and getting past the phase where treading water requires so many weekly hours that nobody has time for anything else. Organizational capital is real, and we had to learn the habit of setting aside time and effort for accumulating it. (In retrospect, we were around a year too slow to enter this phase, although in the very early days it was probably correct to be building everything to throw away.)</p>\n<p>A few of the less completely standard lessons we think we learned are as follows:</p>\n<ul>\n<li>Rank-order busyness, especially if you&rsquo;re passing up organizational-capital improvement tasks. &nbsp;Think &ldquo;This is one of the 3 busiest weekends of the year&rdquo; and not &ldquo;I&rsquo;m too busy to do it right now.&rdquo; &nbsp;This says how large a hit you get from allowing &ldquo;important but not urgent&rdquo; to be postponed during times which are at least that busy, and it forces calibration.</li>\n<li>Even in crunch times, take moments to update. &nbsp;(E.g., do one-sentence journal entries about what just happened / ideas for improvement after each Skype call.) &nbsp;The crunchiest moments are often also the most important to optimize, and even a single sentence of thought can give you a lot of the value from continuing to optimize.</li>\n<li>Use arithmetic to estimate the time/money/staff cost of continuing to do Y the usual way, versus optimizing it. &nbsp;If the arithmetic indicates 10X or more savings, do it even if it requires some up-front cost. &nbsp;(No really, actually do the arithmetic.)</li>\n</ul>\n<p>We also learned a large number of other standard lessons. As of the end of 2014, we think that basic processes at CFAR have improved substantially. We have several months of runway in the bank account - our finances are still precarious, but at least not negative, and we think they&rsquo;re on an improving path. Our workshop interviews and follow-up sessions have an online interface for scheduling instead of being done by hand (which frees a rather surprising amount of energy). The workshop instructors are almost entirely not doing workshop ops. Accounting has been streamlined. The office has nutritious food easily available, without the need to quit working when one gets hungry.</p>\n<p>CFAR feels like it is out of the very-early-startup stage, and able to start focusing on things other than just staying afloat. &nbsp;We feel sufficiently non-overwhelmed that we can take the highest-value opportunities we run into, rather than having all staff members overcommitted at all times. We have a clearer sense of what CFAR is trying to do; of what our internal decision-making structure is; of what each of our roles is; of the value of building good institutions for recording our heuristic updates; etc. And we have will, momentum, and knowledge with which&nbsp;to continue improving our organizational capital over 2015.</p>\n<h1><a name=\"attempts\"></a>Attempts to go beyond the current workshop and toward the &lsquo;full prototype&rsquo; of CFAR: our experience in 2014 and plans for 2015</h1>\n<p>Where are we spending the dividends from that organizational capital? &nbsp;More ambitious curriculum. &nbsp;Specifically, a \"full prototype\" of the CFAR aim.</p>\n<p>Recall that the premise of CFAR is that we should be able to apply the modern understanding of cognition to improve people&rsquo;s ability to (1) figure out the truth; (2) be strategically effective; and (3) do good in the world. By a &ldquo;prototype&rdquo;, or &ldquo;minimum strategic product&rdquo;, we mean a product that actually demonstrates that the above goal is viable (and, thus, that more directly justifies CFAR's claim to be an effective altruist project). For CFAR, this will probably require meaningfully boosting some fraction of participants along all three axes (epistemic rationality; real-world competence; and tendency to do good in the world). <a href=\"#prototype\">[5]</a></p>\n<p>So that's our target for 2015. &nbsp;In the rest of this section, we&rsquo;ll talk about what CFAR did during 2014, go into greater detail on our attempt to build a curriculum for epistemic rationality, and describe our 2015 goals in more detail.</p>\n<p>---</p>\n<p class=\"p1\">One of the future premises of CFAR is that we can eventually apply the full scientific method to the problem of constructing a rationality curriculum (by measuring variations, counting things, re-testing, etc.) -- we aim to eventually be an evidence-based organization. &nbsp;In our present state this continues to be a lot harder than we would like; and our 2014 workshop, for example, was done via crude \"what do you feel you learnt?\" surveys and our own gut impressions. The sort of randomized trial we ran in 2012 is extremely expensive for us because it requires randomly not admitting workshop attendees, and we don&rsquo;t presently have good-enough outcome metrics to justify that expense. &nbsp;Life outcomes, which we see as a gold standard, are big noisy variables with many contributing factors - there&rsquo;s a lot that adds to or subtracts from your salary besides having attended a CFAR workshop, which means that the randomized tests we can afford to run on life outcomes are underpowered. &nbsp;Testing later ability to perform specific skills doesn&rsquo;t seem to stress-test the core premise in the same way. &nbsp;In 2014 we continued to track correlational data and did more detailed random followup surveys, but this is just enough to keep such analyses in the set of things we regularly do, and remind ourselves that we are supposed to be doing better science later.</p>\n<p class=\"p1\">At the start of 2014, we thought our workshops had reached a point of decent order, and we were continuing to tweak them. &nbsp;Partway through 2014 we realized we had reached a local optimum and become stuck (well short of a full prototype / minimum strategic product). &nbsp;So then we smashed everything with a hammer and tried:</p>\n<ul>\n<li>4 different advanced workshops for alumni: \n<ul>\n<li>An epistemic rationality workshop for effective altruist alumni;</li>\n<li>An alumnus workshop on focusing attention (failed);</li>\n<li>An alumnus workshop on the Hamming Question, \"What are your most important life problems? &nbsp;Why aren't you solving them?\"</li>\n</ul>\n<ul>\n<li>2 attempts at an alumnus workshop on how to do 1-on-1 teaching / assistance of cognitive skills (first succeeded, second failed; our fault).</li>\n</ul>\n</li>\n<li>A 1.5-day version of the introductory workshop;</li>\n<li>A workshop with only 10 participants with the entire class taught in a single room (extremely popular, but not yet scalable);</li>\n<li>Shorter modules breaking up the 60-minute-unit default;</li>\n<li>An unconference-style format for the 2014 alumni reunion.</li>\n</ul>\n<p>These experiments ended up feeding back into the flagship workshop, and we think we're now out of the local optimum and making progress again.</p>\n<h2><span style=\"font-size: 16px;\">Epistemic rationality curriculum</span></h2>\n<p>In CFAR&rsquo;s earliest days, we thought epistemic rationality (figuring out the answers to factual questions) was the main thing we were supposed to teach, and we took some long-suffering volunteers and started testing units on them. &nbsp;Then it turned out that while all of our material was pretty terrible, the epistemic rationality parts were even more terrible compared to the rest of it.</p>\n<p>At first our model was that epistemic rationality was hard and we needed to be better teachers, so we set out to learn general teaching skills. &nbsp;People began to visibly enjoy many of our units. &nbsp;But not the units we thought of as \"epistemic rationality\". &nbsp;They still visibly suffered through those.</p>\n<p>We started to talk about \"the curse of epistemic rationality\", and it made us worry about whether it would be worth having a CFAR if we couldn't resolve it somehow. &nbsp;Figuring out the answers to factual questions, the sort of subject matter that appears in the Sequences, the kind of work that we think of scientists as carrying out, felt to us like it was central to the spirit of rationality. &nbsp;We had a sense (and still do) that if all we could do was teach people how to set up trigger-action systems for remembering to lock their house doors, or even turn an ugh-y feeling of needing to do a job search into a series of concrete actions, this still wouldn't be making much progress on sanity-requiring challenges over the next decades. &nbsp;We were worried it wouldn't contribute strategic potential to effective altruism.</p>\n<p>So we kept the most essential-feeling epistemic rationality units in the workshop even despite participants' lowish unit-ratings, and despite our own feeling that those units weren't \"clicking', and we thought: &ldquo;Maybe, if we have workshops full of units that people like, we can just make them sit through some units that they don&rsquo;t like as much, and get people to learn epistemic rationality that way&rdquo;. &nbsp;The &ldquo;didn&rsquo;t like&rdquo; part was painful no matter what story we stuck on it. &nbsp;We rewrote the Bayes unit from scratch more or less every workshop. &nbsp;All of our &ldquo;epistemic rationality&rdquo; units changed radically every month.</p>\n<p>One ray of light appeared in mid-2013 with the Inner Simulator unit, which included techniques about imagining future situations to see how surprised you felt by them, and using this to determine whether your Inner Simulator really strongly expected a new hire to work out or whether you are in fact certain that your project will be done by Thursday. &nbsp;This was something we considered to be an \"epistemic rationality\" unit at the time, and it worked, in the sense that it (a) set up concepts that fed into our other units, (b) seemed to actually convey some useful skills that people noticed they were learning, and (c) people didn't hate it.</p>\n<p>(And it didn't feel like we were just trying to smuggle it in from ulterior motives about skills we thought effective altruists ought to have, but that we were actually patching concrete problems.)</p>\n<p>A miracle had appeared! &nbsp;We ignored it and kept rewriting all the other \"epistemic rationality\" units every month.</p>\n<p>But a lesson that we only understood later started to seep in. &nbsp;We started thinking of some of our other units as having epistemic rationality components in them -- and this in turn changed the way we practiced, and taught, the other techniques.&nbsp;</p>\n<p>The sea change that occurred in our thinking might be summarized as the shift from, \"Epistemic rationality is about whole units that are about answering factual questions\" to there being a truth element that appears in many skills, a point where you would like your System 1 or System 2 to see some particular fact as true, or figure out what is true, or resolve an argument about what will happen next.</p>\n<ul>\n<li>We used to think of Comfort Zone Expansion<a href=\"#jargon\">[6]</a> as being about desensitization. &nbsp;We would today think of it as being about, for example, correcting your System 1's anticipation of what happens when you talk to strangers.</li>\n<li>We used to think of Urge Propagation<a href=\"#jargon\">[6]</a>&nbsp;as being about applying behaviorist conditioning techniques to yourself. &nbsp;Today we teach a very different technique under the same name; a technique that is about dialoging with your affective brain until system 1 and system 2 acquire a common causal model of whether task X <em>will in fact</em>&nbsp;help with the things you most care about.</li>\n<li>We thought of Turbocharging<a href=\"#jargon\">[6]</a>&nbsp;as being about instrumental techniques for acquiring skills quickly through practice. &nbsp;Today we would also frame it as, \"Suppose you didn't know you were supposed to be 'Learning Spanish'. &nbsp;What would an outside-ish view say about what skill you might be practicing? &nbsp;Is it filling in blank lines in workbooks?\"</li>\n<li>We were quite cheered when we tried entirely eliminating the Bayes unit and found that we could identify a dependency in other, clearly practical, units that wanted to call on the ability to look for evidence or identify evidence.</li>\n<li>Our Focused Grit and Hard Decisions units are entirely \"epistemic\" -- they are straight out just about acquiring more accurate models of the world. &nbsp;But they don't feel like the old \"curse of epistemic rationality\" units, because they begin with an actual felt System 1 need (\"what shall I do when I graduate?\" or similar), and they stay in contact with System 1's reasoning process all the way through.</li>\n</ul>\n<p>When we were organizing the UK workshop at the end of 2014, there was a moment where we had the sudden realization, \"Hey, maybe almost all of our curriculum is secretly epistemic rationality and we can organize it into 'Epistemic Rationality for the Planning Brain' on day 1 and 'Epistemic Rationality for the Affective Brain' on day 2, and this makes our curriculum so much denser that we'll have room for the Hamming Question on day 3.\" &nbsp;This didn't work as well in practice as it did in our heads (though it still went over okay) but we think this just means that the process of our digesting this insight is ongoing.</p>\n<p>We have hopes of making a lot of progress here in 2015. &nbsp;It feels like we're back on track to teaching epistemic rationality - in ways where it's forced by need to usefully tackle life problems, not because we tacked it on. &nbsp;And this in turn feels like we're back on track toward teaching that important thing we wanted to teach, the one with strategic implications containing most of CFAR's expected future value.</p>\n<p>(And the units we think of as \"epistemic\" no longer get rated lower than all our other units; and our alumni workshop on Epistemic Rationality for Effective Altruists went over very well and does seem to have helped validate the propositions that \"People who care strongly about EA's factual questions are good audiences for what we think of as relevant epistemic skills\" and \"Having learned CFAR basics actually does help for learning more abstract epistemic rationality later\".)</p>\n<h2><a name=\"goals\"></a>Goals for 2015</h2>\n<p>In 2015, we intend to keep building organizational capital, and use those dividends to keep pushing on the epistemic rationality curriculum, and pushing toward the minimum strategic project that stress-tests CFAR's core value propositions. &nbsp;We've also set the following concrete goals<a href=\"#tactics\">[7]</a>:</p>\n<ul>\n<li>Find some way to track a metric for 'How likely we think this person is to end up being strategically useful to the world', even if it's extremely crude.<a href=\"#apgar\">[8]</a></li>\n<li>Actually start tracking it, even if internally, subjectively, and terribly.</li>\n<li>Try to boost alumni scores on the three components of \"Figure out true things\", \"Be effective\" and \"Do-gooding\" (from our extremely crude measure).</li>\n<li>Cause 30 new people to become engaged in high-impact do-gooding in some interesting way, including 10+ with outside high status and no previous involvement with EA.</li>\n<li>Cause 10 high-impact do-gooder alumni to say that, because of interacting with CFAR, they became much more skilled/effective/well-targeted on strategically important things. &nbsp;Have this also be plausible to their coworkers.</li>\n</ul>\n<h2><a name=\"nuts\"></a>Nuts, Bolts, and Financial Details</h2>\n<div>\n<div>\n<div><strong>Total expenditures</strong></div>\n</div>\n<div>Our total expenditures in 2014 came up about $840k. &nbsp;This number includes about $330k of non-staff direct workshop costs (housing, food, etc.), which is offset for the associated workshop revenue; if one excludes this number, our total expenditures in 2014 came to about $510k.</div>\n<div><br /></div>\n<div><strong>Basic operating expenses</strong></div>\n<div>Our basic operating expenses from 2014 were fairly similar to <a href=\"/lw/jej/why_cfar/\">2013</a>: a total of about $42k/month, outside-view:</div>\n<div>\n<ul>\n<li>$5.3k/month for office rent;</li>\n<li>$30k/month for salaries (includes tax, health insurance, and contractors; our full-time people are still paid $3.5k/month);</li>\n<li>$7k/month for total other non-workshop costs (flights and fees to attend others' trainings; office groceries; storage unit, software subscriptions; ...)</li>\n</ul>\n</div>\n<div><br /></div>\n<div><strong>Flagship Workshops</strong></div>\n<div>We ran 9 workshops in 2014, which generated about $435k in revenue, but also $210k in non-staff costs (mostly food and housing for workshop participants), for a total net of about $230k in additional money (or $25k/workshop in additional money), ignoring staff cost.</div>\n<div><br /></div>\n<div>Per workshop staff time-cost is significantly lower than it was (counting sales, pre-working prep, instruction, and follow-ups) -- perhaps 100 person-days per workshop going forward, compared against perhaps 180 person-days per workshop in 2013. &nbsp;(We aim to decrease this further in 2014 while maintaining or increasing quality.)</div>\n<div><br /></div>\n<div>Per workshop net revenue is on the other hand roughly similar to 2013; this was based on an intentional effort to move staff time away from short-term sales toward investment in longer-term press funnel, curriculum development (e.g., the alumni events), and other shifts to our <em>longer-term</em>&nbsp;significance.</div>\n<div><br /></div>\n<div><strong>Alumni reunion, alumni workshops, alumni dojo...</strong></div>\n<div>We ran an alumni reunion, 4 alumni workshops, and a continuing alumni dojo. &nbsp;We intentionally kept the cost of these low to participants, and sliding-scale, so as to help build the community that can take the art forward. &nbsp;</div>\n<div>Detail:</div>\n<div>\n<ul>\n<li>Alumni reunion: $34k income; $38k non-staff costs (for ~100 participants)</li>\n<li>Hamming: $3.6k revenue; $3k non-staff costs</li>\n<li>Assisting thinking: $2.1k revenue; $3.2k non-staff costs</li>\n<li>Attention: $3.3k revenue; $2.7k non-staff costs</li>\n<li>Epistemic Rationality for Effective Altruists: $5k revenue; $3k costs</li>\n<li>Dojo: free.</li>\n</ul>\n</div>\n<div>We also ran a 1.5-day beta workshop for beginners:</div>\n<div>\n<ul>\n<li>&ldquo;A taste of rationality&rdquo;: $5k revenue; $2.6k non-staff costs.&nbsp;</li>\n</ul>\n</div>\n<div><br /></div>\n<div><strong>SPARC</strong></div>\n<div>SPARC 2014&rsquo;s non-staff costs came to $62k, and were covered by Dropbox, Quixey, and MIRI (although, as with our other programs, considerable CFAR staff time also went into SPARC).</div>\n<div><br /></div>\n<div><strong>Balance sheet</strong></div>\n<div>CFAR has about $130k, going into 2015. &nbsp;(The $30k short-term loan we took last year was repaid as scheduled, following last year's fundraising drive.)</div>\n<div><br /></div>\n<div><strong>Summary</strong></div>\n<div>CFAR is more financially stable than it was a year ago but remains dependent on donation to make ends meet, and still more dependent on donation if it is to e.g. outsource the accounting, to further streamline the per-workshop staff time-costs, and to put actual quality focus into developing the epistemic rationality and do-gooding impacts.</div>\n<div><br /></div>\n</div>\n<div>\n<h2><a name=\"howhelp\"></a>The big picture and how you can help</h2>\n<div>CFAR seems to many of us to be among the efforts most worth investing in. &nbsp;This isn&rsquo;t because our present workshops are all that great. &nbsp;Rather, it is because, in terms of &ldquo;saving throws&rdquo; one can buy for a humanity that may be navigating tricky situations in an unknown future, improvements to thinking skill seem to be one of the strongest and most robust. &nbsp;And we suspect that CFAR is a promising kernel from which to help with that effort.</div>\n<div><br /></div>\n<div>As noted, we aim in 2015 to get all the way to a &ldquo;full prototype&rdquo; -- &nbsp;a point from which we are actually visibly helping in the aimed-for way. &nbsp;This will be a tricky spot to get to. Our experience slowly coming to grips with epistemic rationality is probably more rule than the exception, and I suspect we&rsquo;ll run into a number of curve balls on path to the prototype. &nbsp; &nbsp;</div>\n<div><br /></div>\n<div>But with your help -- donations are at this stage critical to being able to put serious focused effort into building the prototype, instead of being terribly distracted staying alive -- I suspect that we can put in the requisite focus, and can have the prototype in hand by the end of 2015.</div>\n<div><br /></div>\n<div>...</div>\n<div><br /></div>\n<div>Besides donations, we are actually in a good position now use your advice, your experience, and your thoughts on how to navigate CFAR's remaining gaps; we have enough space to take a breath and think strategically.</div>\n<div><br /></div>\n<div>We're hoping 2015 will also be a year when CFAR alumni and supporters scale up their connections and their ambitions, launching more startups and other projects. &nbsp;Please keep in touch if you do this; we&rsquo;d like our curriculum-generation process to continue to connect to live problems.</div>\n<div><br /></div>\n<div>A very strong way to help, also, is to come to a <a href=\"http://rationality.org/workshops/\">workshop</a>, and to send your friends there. &nbsp;It keeps CFAR going, we always want there to be more CFAR alumni, and it might even help with that quest. &nbsp;(The data strongly indicates that your friends will thank you for getting them to come&hellip; and will do so even more 6 months later!)</div>\n<div><br /></div>\n<div>And do please <a href=\"http://rationality.org/donate\">donate</a> to the Winter 2014 fundraising drive!</div>\n</div>\n<div><br /></div>\n<div><br /></div>\n<hr />\n<p><a name=\"match\"></a>[1] That is: by giving up a dollar, you can, given some simplifications, cause CFAR to gain two dollars. Much thanks to Peter McCluskey, Jesse Liptrap, Nick Tarleton, Stephanie Zolayvar, Arram Sabeti, Liron Shapira, Ben Hoskin, Eric Rogstad, Matt Graves, Alyssa Vance, Topher Hallquist, and John Clasby for together putting up $120k in matching funds.</p>\n<p><a name=\"author\"></a>[2] This post is a collaborative effort by many at CFAR.</p>\n<p><a name=\"tatrain\"></a>[3] The title we ran it under was \"TA training\", but the name desperately needs revision.</p>\n<p><a name=\"startups\"></a>[4] This is missing several I can almost-recall and probably several others I can&rsquo;t; please PM me if you remember one I missed. &nbsp;Many of the startups on this list have multiple founders who are CFAR alum. &nbsp;Omitted from this list are startups that were completed before the alumni met us, e.g. Skype; we included however startups that were founded before folks met us and carried on after they became alumni (even when we had no causal impact on the startups). &nbsp;Also of note is that many CFAR alumni are in founding or executive positions at EA-associated non-profits, including <a href=\"https://centreforeffectivealtruism.org/\">CEA</a>, <a href=\"http://cser.org/\">CSER</a>, <a href=\"http://futureoflife.org/\">FLI</a>, <a href=\"http://www.leverageresearch.org/\">Leverage</a>, and <a href=\"http://intelligence.org/\">MIRI</a>. &nbsp;One reason we're happy about this is that it means that the curriculum we're developing is being developed in concert with people who are trying to really actually accomplish hard goals, and who are therefore wanting more from techniques than just \"does this sound cool\".</p>\n<p class=\"p1\"><a name=\"prototype\"></a>[5] Ideally, such a prototype might accomplish increases in (1), (2), and (3) in a manner that felt like facets of a<em>&nbsp;</em>single&nbsp;art, or that all drew upon a common base of simpler cognitive skills (such as subskills for getting accurate beliefs into system 1, for navigating internal disagreement, or for overcoming learned helplessness). &nbsp;A &ldquo;prototype&rdquo; would thus also be a product that, when we apply local optimization on it, takes us to curricula that are strategically important to the world -- rather than, say, taking us to well-honed &ldquo;feel inspired about your life&rdquo; workshops, or something).</p>\n<p>Relative to this ideal, the current curriculum seems to in fact accomplish some of (2), for all that we don't have RCTs yet; but it is less successful at (1) and (3). &nbsp;(We'd like, eventually, to scale up (2) as well.) &nbsp;However, we suspect the curriculum contains seeds toward an art that can succeed at (1) and (3); and we aim to demonstrate this in 2015.</p>\n<p class=\"p1\"><a name=\"jargon\"></a>[6] Apologies for the jargon. &nbsp;It is probably about time we wrote up a glossary; but we don't have one yet. &nbsp;If you care, you can pick up some of the vocabulary from our <a href=\"http://rationality.org/schedule/\">sample workshop schedule</a>.</p>\n<div><a name=\"tactics\"></a>[7] This isn&rsquo;t the detailed tactical plan; we&rsquo;ll need one of those separately, and we have a partial version that this margin was too small to contain; it&rsquo;s meant to be a listing of how you and we can tell whether we won, at the end of 2015.</div>\n<div><br /></div>\n<div><a name=\"apgar\"></a>[8] The Apgar score for assessing newborn health is inspiring, here; if you've not seen it before, and you're wondering how one could possibly come up with a metric, you might glance at its&nbsp;<a href=\"http://en.wikipedia.org/wiki/Apgar_score\">wikipedia page</a>. &nbsp;Basically, instead of coming up with a single 0 to 10 newborn health scale, Dr. Apgar chose 5 simpler components (newborn color; newborn heart rate; etc.), came up with <em>very</em>&nbsp;simple \"0 to 2\" measures for these, and then added.</div>\n<div><br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"X7v7Fyp9cgBYaMe2e": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KDGnsReYomusL89Rs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 66, "baseScore": 92, "extendedScore": null, "score": 0.0003207892337057033, "legacy": true, "legacyId": "27772", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 65, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Summary: &nbsp;We outline CFAR\u2019s purpose, our history in 2014, and our plans heading into 2015.</p>\n<ul>\n<li><a href=\"#highlights\">Highlights from 2014</a>.</li>\n<li><a href=\"#operations\">Improving operations</a>.</li>\n<li><a href=\"#attempts\">Attempts to go beyond the current workshop and toward the \u2018full prototype\u2019 of CFAR: our experience in 2014 and plans for 2015</a>.</li>\n<li><a href=\"#nuts\">Nuts, bolts, and financial details</a>.</li>\n<li><a href=\"#howhelp\">The big picture and how you can help</a>.</li>\n</ul>\n<p>One of the reasons we\u2019re publishing this review now is that we\u2019ve just launched our annual matching <a href=\"http://rationality.org/fundraiser2014/\">fundraiser</a>, and want to provide the information our prospective donors need for deciding. <strong>This is the best time of year to decide to donate to CFAR. Donations up to $120k will be matched until January 31.</strong><a href=\"#match\">[1]</a>&nbsp;</p>\n<p>To briefly preview: For the first three years of our existence, CFAR mostly focused on getting going. We followed the standard recommendation to build a \u2018minimum viable product\u2019, the CFAR workshops, that could test our ideas and generate some revenue. Coming into 2013, we had a workshop that people liked (9.3 average rating on \u201cAre you glad you came?\u201d; a more recent random survey showed 9.6 average rating on the same question 6-24 months later), which helped keep the lights on and gave us articulate, skeptical, serious learners to iterate on. At the same time, the workshops are not everything we would want in a CFAR prototype; it feels like the current core workshop does not stress-test most of our hopes for what CFAR can eventually do. The premise of CFAR is that we should be able to apply the modern understanding of cognition to improve people\u2019s ability to (1) figure out the truth (2) be strategically effective (3) do good in the world. We have dreams of scaling up some particular kinds of sanity. &nbsp;Our next goal is to build the minimum strategic product that more directly justifies CFAR\u2019s claim to be an effective altruist project.<a href=\"#author\">[2]</a></p>\n<p><a id=\"more\"></a></p>\n<h1 id=\"Highlights_from_2014\"><a name=\"highlights\"></a>Highlights from 2014</h1>\n<p>Our brand perception improved significantly in 2014, which matters because it leads to companies being willing to pay for workshop attendance. &nbsp;We were covered in&nbsp;<a href=\"http://www.fastcompany.com/3037333/most-creative-people/inside-the-rationality-movement-that-has-silicon-valley-buzzing-with-po\">Fast Company</a>&nbsp;--&nbsp;<a href=\"http://www.fastcompany.com/3035671/how-i-get-it-done/a-new-technique-for-creating-more-aha-moments-the-surprise-journal\">twice</a>&nbsp;--&nbsp;the&nbsp;<a href=\"http://www.wsj.com/news/articles/SB10001424052702303453004579290510733740616?mod=e2fb\">Wall Street Journal</a>, and&nbsp;<a href=\"http://www.academia.edu/9623753/The_Center_for_Applied_Rationality_practical_techniques_for_overcoming_biases\">The Reasoner</a>. &nbsp;Other mentions include&nbsp;<a href=\"http://www.forbes.com/sites/learnvest/2014/01/28/6-times-we-betray-our-budgets-and-clever-ways-to-stop/\">Forbes</a>,&nbsp;<a href=\"http://bigthink.com/videos/rationality-in-action-look-at-a-problem-as-an-outsider-2\">Big Think</a>,&nbsp;<a href=\"http://boingboing.net/2014/08/24/habits-for-living-a-more-ratio.html\">Boing Boing</a>, and&nbsp;<a href=\"http://lifehacker.com/carry-a-surprise-journal-to-find-areas-for-self-impro-1638467349\">Lifehacker</a>. &nbsp;We\u2019ve also had some interest in potential training for tech companies.</p>\n<p>Our curriculum is gaining a second tier in the form of alumni workshops. &nbsp;We tried 4 experimental alumni workshops, 3 of which went well enough to be worth iterating:</p>\n<ul>\n<li>The Hamming Question: &nbsp;\u201cWhat are the most important problems in your life, and why aren\u2019t you working on them?\u201d &nbsp;This 2.5-day workshop was extremely well received, and gave rise to a new unit for our introductory workshop.</li>\n<li>Assisting Others<a href=\"#tatrain\">[3]</a>: &nbsp;A two-weekend (training, then practicum) workshop investigating the close link between helping others debug their problems, and better debugging your own problems. &nbsp;We ran a version of this in the Bay Area that worked, and an abridged version in the UK that didn\u2019t. &nbsp;(This was our fault. &nbsp;We\u2019re sorry.)</li>\n<li>Attention Workshop: &nbsp;A 2.5-day workshop on clearing mental space. &nbsp;This failed and taught us some important points about what doesn\u2019t work.</li>\n<li>Epistemic Rationality for Effective Altruists: &nbsp;A standalone 2.5-day workshop on applying techniques from the introductory workshop to factual questions, especially those related to effective altruism. (More on this below.) &nbsp;The attendees from this and the Hamming workshop spontaneously organized recurring meetups for themselves.</li>\n</ul>\n<p>Our alumni community continues to grow. &nbsp;There are now 550 CFAR alumni, counting 90 from SPARC. &nbsp;It\u2019s a high-initiative group. Startups by CFAR alumni include: <a href=\"http://apptimize.com/\">Apptimize</a>; <a href=\"http://bellroy.com/\">Bellroy</a>; <a href=\"http://beeminder.com/\">Beeminder</a>; <a href=\"https://complice.co/\">Complice</a>; <a href=\"http://codecombat.com/\">Code Combat</a>; <a href=\"https://draftable.com/\">Draftable</a>; <a href=\"http://www.mealsquares.com/\">MealSquares</a>; <a href=\"https://gigaom.com/2014/06/30/hadoop-specialist-wandisco-acquires-hbase-like-startup-ohmdata/\">OhmData</a>; <a href=\"http://www.praxamed.com/\">Praxamed</a>; <a href=\"http://vesparum.com/\">Vesparum</a>; <a href=\"http://teleport.org/\">Teleport</a>; <a href=\"http://watuapp.com/\">Watu</a>; <a href=\"http://www.sendwave.com/\">Wave</a>; <a href=\"https://zerocater.com/\">ZeroCater</a>.<a href=\"#startups\">[4]</a> There is a highly active mailing list with over 400 members, and over 600 conversation threads, over 30 of which were active in the last month. &nbsp;We also ran our first-ever alumni reunion, and started a weekly alumni dojo. &nbsp;This enabled further curricular experimentation, and allowed alumni ideas and experiences to feed into curricular design.&nbsp;</p>\n<p>SPARC happened again, with more-honed curriculum and nearly twice as many students.</p>\n<p>Basic operations improved substantially. &nbsp;We\u2019ll say more on this in section 2.</p>\n<p>Iteration on the flagship workshop continues. &nbsp;We\u2019ll say more on this (including details of what we learned, and what remains puzzling) in section 3.</p>\n<h1 id=\"Improving_operations\"><a name=\"operations\"></a>Improving operations</h1>\n<p>The two driving themes of CFAR during 2014 were making our operations more stable and sustainable, and our successful struggle to pull our introductory workshop out of a local optimum and get back on track toward something that is more like a \u2018full prototype\u2019 of the CFAR concept.</p>\n<p>At the end of 2013, we had negative $30,000 and had borrowed money to make payroll, placing us in the \u2018very early stage, struggling startup\u2019 phase. Almost all of our regular operations, such as scheduling interviews for workshop admissions, were being done by hand. Much of our real progress in 2014 consisted of making things run smoothly and getting past the phase where treading water requires so many weekly hours that nobody has time for anything else. Organizational capital is real, and we had to learn the habit of setting aside time and effort for accumulating it. (In retrospect, we were around a year too slow to enter this phase, although in the very early days it was probably correct to be building everything to throw away.)</p>\n<p>A few of the less completely standard lessons we think we learned are as follows:</p>\n<ul>\n<li>Rank-order busyness, especially if you\u2019re passing up organizational-capital improvement tasks. &nbsp;Think \u201cThis is one of the 3 busiest weekends of the year\u201d and not \u201cI\u2019m too busy to do it right now.\u201d &nbsp;This says how large a hit you get from allowing \u201cimportant but not urgent\u201d to be postponed during times which are at least that busy, and it forces calibration.</li>\n<li>Even in crunch times, take moments to update. &nbsp;(E.g., do one-sentence journal entries about what just happened / ideas for improvement after each Skype call.) &nbsp;The crunchiest moments are often also the most important to optimize, and even a single sentence of thought can give you a lot of the value from continuing to optimize.</li>\n<li>Use arithmetic to estimate the time/money/staff cost of continuing to do Y the usual way, versus optimizing it. &nbsp;If the arithmetic indicates 10X or more savings, do it even if it requires some up-front cost. &nbsp;(No really, actually do the arithmetic.)</li>\n</ul>\n<p>We also learned a large number of other standard lessons. As of the end of 2014, we think that basic processes at CFAR have improved substantially. We have several months of runway in the bank account - our finances are still precarious, but at least not negative, and we think they\u2019re on an improving path. Our workshop interviews and follow-up sessions have an online interface for scheduling instead of being done by hand (which frees a rather surprising amount of energy). The workshop instructors are almost entirely not doing workshop ops. Accounting has been streamlined. The office has nutritious food easily available, without the need to quit working when one gets hungry.</p>\n<p>CFAR feels like it is out of the very-early-startup stage, and able to start focusing on things other than just staying afloat. &nbsp;We feel sufficiently non-overwhelmed that we can take the highest-value opportunities we run into, rather than having all staff members overcommitted at all times. We have a clearer sense of what CFAR is trying to do; of what our internal decision-making structure is; of what each of our roles is; of the value of building good institutions for recording our heuristic updates; etc. And we have will, momentum, and knowledge with which&nbsp;to continue improving our organizational capital over 2015.</p>\n<h1 id=\"Attempts_to_go_beyond_the_current_workshop_and_toward_the__full_prototype__of_CFAR__our_experience_in_2014_and_plans_for_2015\"><a name=\"attempts\"></a>Attempts to go beyond the current workshop and toward the \u2018full prototype\u2019 of CFAR: our experience in 2014 and plans for 2015</h1>\n<p>Where are we spending the dividends from that organizational capital? &nbsp;More ambitious curriculum. &nbsp;Specifically, a \"full prototype\" of the CFAR aim.</p>\n<p>Recall that the premise of CFAR is that we should be able to apply the modern understanding of cognition to improve people\u2019s ability to (1) figure out the truth; (2) be strategically effective; and (3) do good in the world. By a \u201cprototype\u201d, or \u201cminimum strategic product\u201d, we mean a product that actually demonstrates that the above goal is viable (and, thus, that more directly justifies CFAR's claim to be an effective altruist project). For CFAR, this will probably require meaningfully boosting some fraction of participants along all three axes (epistemic rationality; real-world competence; and tendency to do good in the world). <a href=\"#prototype\">[5]</a></p>\n<p>So that's our target for 2015. &nbsp;In the rest of this section, we\u2019ll talk about what CFAR did during 2014, go into greater detail on our attempt to build a curriculum for epistemic rationality, and describe our 2015 goals in more detail.</p>\n<p>---</p>\n<p class=\"p1\">One of the future premises of CFAR is that we can eventually apply the full scientific method to the problem of constructing a rationality curriculum (by measuring variations, counting things, re-testing, etc.) -- we aim to eventually be an evidence-based organization. &nbsp;In our present state this continues to be a lot harder than we would like; and our 2014 workshop, for example, was done via crude \"what do you feel you learnt?\" surveys and our own gut impressions. The sort of randomized trial we ran in 2012 is extremely expensive for us because it requires randomly not admitting workshop attendees, and we don\u2019t presently have good-enough outcome metrics to justify that expense. &nbsp;Life outcomes, which we see as a gold standard, are big noisy variables with many contributing factors - there\u2019s a lot that adds to or subtracts from your salary besides having attended a CFAR workshop, which means that the randomized tests we can afford to run on life outcomes are underpowered. &nbsp;Testing later ability to perform specific skills doesn\u2019t seem to stress-test the core premise in the same way. &nbsp;In 2014 we continued to track correlational data and did more detailed random followup surveys, but this is just enough to keep such analyses in the set of things we regularly do, and remind ourselves that we are supposed to be doing better science later.</p>\n<p class=\"p1\">At the start of 2014, we thought our workshops had reached a point of decent order, and we were continuing to tweak them. &nbsp;Partway through 2014 we realized we had reached a local optimum and become stuck (well short of a full prototype / minimum strategic product). &nbsp;So then we smashed everything with a hammer and tried:</p>\n<ul>\n<li>4 different advanced workshops for alumni: \n<ul>\n<li>An epistemic rationality workshop for effective altruist alumni;</li>\n<li>An alumnus workshop on focusing attention (failed);</li>\n<li>An alumnus workshop on the Hamming Question, \"What are your most important life problems? &nbsp;Why aren't you solving them?\"</li>\n</ul>\n<ul>\n<li>2 attempts at an alumnus workshop on how to do 1-on-1 teaching / assistance of cognitive skills (first succeeded, second failed; our fault).</li>\n</ul>\n</li>\n<li>A 1.5-day version of the introductory workshop;</li>\n<li>A workshop with only 10 participants with the entire class taught in a single room (extremely popular, but not yet scalable);</li>\n<li>Shorter modules breaking up the 60-minute-unit default;</li>\n<li>An unconference-style format for the 2014 alumni reunion.</li>\n</ul>\n<p>These experiments ended up feeding back into the flagship workshop, and we think we're now out of the local optimum and making progress again.</p>\n<h2 id=\"Epistemic_rationality_curriculum\"><span style=\"font-size: 16px;\">Epistemic rationality curriculum</span></h2>\n<p>In CFAR\u2019s earliest days, we thought epistemic rationality (figuring out the answers to factual questions) was the main thing we were supposed to teach, and we took some long-suffering volunteers and started testing units on them. &nbsp;Then it turned out that while all of our material was pretty terrible, the epistemic rationality parts were even more terrible compared to the rest of it.</p>\n<p>At first our model was that epistemic rationality was hard and we needed to be better teachers, so we set out to learn general teaching skills. &nbsp;People began to visibly enjoy many of our units. &nbsp;But not the units we thought of as \"epistemic rationality\". &nbsp;They still visibly suffered through those.</p>\n<p>We started to talk about \"the curse of epistemic rationality\", and it made us worry about whether it would be worth having a CFAR if we couldn't resolve it somehow. &nbsp;Figuring out the answers to factual questions, the sort of subject matter that appears in the Sequences, the kind of work that we think of scientists as carrying out, felt to us like it was central to the spirit of rationality. &nbsp;We had a sense (and still do) that if all we could do was teach people how to set up trigger-action systems for remembering to lock their house doors, or even turn an ugh-y feeling of needing to do a job search into a series of concrete actions, this still wouldn't be making much progress on sanity-requiring challenges over the next decades. &nbsp;We were worried it wouldn't contribute strategic potential to effective altruism.</p>\n<p>So we kept the most essential-feeling epistemic rationality units in the workshop even despite participants' lowish unit-ratings, and despite our own feeling that those units weren't \"clicking', and we thought: \u201cMaybe, if we have workshops full of units that people like, we can just make them sit through some units that they don\u2019t like as much, and get people to learn epistemic rationality that way\u201d. &nbsp;The \u201cdidn\u2019t like\u201d part was painful no matter what story we stuck on it. &nbsp;We rewrote the Bayes unit from scratch more or less every workshop. &nbsp;All of our \u201cepistemic rationality\u201d units changed radically every month.</p>\n<p>One ray of light appeared in mid-2013 with the Inner Simulator unit, which included techniques about imagining future situations to see how surprised you felt by them, and using this to determine whether your Inner Simulator really strongly expected a new hire to work out or whether you are in fact certain that your project will be done by Thursday. &nbsp;This was something we considered to be an \"epistemic rationality\" unit at the time, and it worked, in the sense that it (a) set up concepts that fed into our other units, (b) seemed to actually convey some useful skills that people noticed they were learning, and (c) people didn't hate it.</p>\n<p>(And it didn't feel like we were just trying to smuggle it in from ulterior motives about skills we thought effective altruists ought to have, but that we were actually patching concrete problems.)</p>\n<p>A miracle had appeared! &nbsp;We ignored it and kept rewriting all the other \"epistemic rationality\" units every month.</p>\n<p>But a lesson that we only understood later started to seep in. &nbsp;We started thinking of some of our other units as having epistemic rationality components in them -- and this in turn changed the way we practiced, and taught, the other techniques.&nbsp;</p>\n<p>The sea change that occurred in our thinking might be summarized as the shift from, \"Epistemic rationality is about whole units that are about answering factual questions\" to there being a truth element that appears in many skills, a point where you would like your System 1 or System 2 to see some particular fact as true, or figure out what is true, or resolve an argument about what will happen next.</p>\n<ul>\n<li>We used to think of Comfort Zone Expansion<a href=\"#jargon\">[6]</a> as being about desensitization. &nbsp;We would today think of it as being about, for example, correcting your System 1's anticipation of what happens when you talk to strangers.</li>\n<li>We used to think of Urge Propagation<a href=\"#jargon\">[6]</a>&nbsp;as being about applying behaviorist conditioning techniques to yourself. &nbsp;Today we teach a very different technique under the same name; a technique that is about dialoging with your affective brain until system 1 and system 2 acquire a common causal model of whether task X <em>will in fact</em>&nbsp;help with the things you most care about.</li>\n<li>We thought of Turbocharging<a href=\"#jargon\">[6]</a>&nbsp;as being about instrumental techniques for acquiring skills quickly through practice. &nbsp;Today we would also frame it as, \"Suppose you didn't know you were supposed to be 'Learning Spanish'. &nbsp;What would an outside-ish view say about what skill you might be practicing? &nbsp;Is it filling in blank lines in workbooks?\"</li>\n<li>We were quite cheered when we tried entirely eliminating the Bayes unit and found that we could identify a dependency in other, clearly practical, units that wanted to call on the ability to look for evidence or identify evidence.</li>\n<li>Our Focused Grit and Hard Decisions units are entirely \"epistemic\" -- they are straight out just about acquiring more accurate models of the world. &nbsp;But they don't feel like the old \"curse of epistemic rationality\" units, because they begin with an actual felt System 1 need (\"what shall I do when I graduate?\" or similar), and they stay in contact with System 1's reasoning process all the way through.</li>\n</ul>\n<p>When we were organizing the UK workshop at the end of 2014, there was a moment where we had the sudden realization, \"Hey, maybe almost all of our curriculum is secretly epistemic rationality and we can organize it into 'Epistemic Rationality for the Planning Brain' on day 1 and 'Epistemic Rationality for the Affective Brain' on day 2, and this makes our curriculum so much denser that we'll have room for the Hamming Question on day 3.\" &nbsp;This didn't work as well in practice as it did in our heads (though it still went over okay) but we think this just means that the process of our digesting this insight is ongoing.</p>\n<p>We have hopes of making a lot of progress here in 2015. &nbsp;It feels like we're back on track to teaching epistemic rationality - in ways where it's forced by need to usefully tackle life problems, not because we tacked it on. &nbsp;And this in turn feels like we're back on track toward teaching that important thing we wanted to teach, the one with strategic implications containing most of CFAR's expected future value.</p>\n<p>(And the units we think of as \"epistemic\" no longer get rated lower than all our other units; and our alumni workshop on Epistemic Rationality for Effective Altruists went over very well and does seem to have helped validate the propositions that \"People who care strongly about EA's factual questions are good audiences for what we think of as relevant epistemic skills\" and \"Having learned CFAR basics actually does help for learning more abstract epistemic rationality later\".)</p>\n<h2 id=\"Goals_for_2015\"><a name=\"goals\"></a>Goals for 2015</h2>\n<p>In 2015, we intend to keep building organizational capital, and use those dividends to keep pushing on the epistemic rationality curriculum, and pushing toward the minimum strategic project that stress-tests CFAR's core value propositions. &nbsp;We've also set the following concrete goals<a href=\"#tactics\">[7]</a>:</p>\n<ul>\n<li>Find some way to track a metric for 'How likely we think this person is to end up being strategically useful to the world', even if it's extremely crude.<a href=\"#apgar\">[8]</a></li>\n<li>Actually start tracking it, even if internally, subjectively, and terribly.</li>\n<li>Try to boost alumni scores on the three components of \"Figure out true things\", \"Be effective\" and \"Do-gooding\" (from our extremely crude measure).</li>\n<li>Cause 30 new people to become engaged in high-impact do-gooding in some interesting way, including 10+ with outside high status and no previous involvement with EA.</li>\n<li>Cause 10 high-impact do-gooder alumni to say that, because of interacting with CFAR, they became much more skilled/effective/well-targeted on strategically important things. &nbsp;Have this also be plausible to their coworkers.</li>\n</ul>\n<h2 id=\"Nuts__Bolts__and_Financial_Details\"><a name=\"nuts\"></a>Nuts, Bolts, and Financial Details</h2>\n<div>\n<div>\n<div><strong>Total expenditures</strong></div>\n</div>\n<div>Our total expenditures in 2014 came up about $840k. &nbsp;This number includes about $330k of non-staff direct workshop costs (housing, food, etc.), which is offset for the associated workshop revenue; if one excludes this number, our total expenditures in 2014 came to about $510k.</div>\n<div><br></div>\n<div><strong>Basic operating expenses</strong></div>\n<div>Our basic operating expenses from 2014 were fairly similar to <a href=\"/lw/jej/why_cfar/\">2013</a>: a total of about $42k/month, outside-view:</div>\n<div>\n<ul>\n<li>$5.3k/month for office rent;</li>\n<li>$30k/month for salaries (includes tax, health insurance, and contractors; our full-time people are still paid $3.5k/month);</li>\n<li>$7k/month for total other non-workshop costs (flights and fees to attend others' trainings; office groceries; storage unit, software subscriptions; ...)</li>\n</ul>\n</div>\n<div><br></div>\n<div><strong>Flagship Workshops</strong></div>\n<div>We ran 9 workshops in 2014, which generated about $435k in revenue, but also $210k in non-staff costs (mostly food and housing for workshop participants), for a total net of about $230k in additional money (or $25k/workshop in additional money), ignoring staff cost.</div>\n<div><br></div>\n<div>Per workshop staff time-cost is significantly lower than it was (counting sales, pre-working prep, instruction, and follow-ups) -- perhaps 100 person-days per workshop going forward, compared against perhaps 180 person-days per workshop in 2013. &nbsp;(We aim to decrease this further in 2014 while maintaining or increasing quality.)</div>\n<div><br></div>\n<div>Per workshop net revenue is on the other hand roughly similar to 2013; this was based on an intentional effort to move staff time away from short-term sales toward investment in longer-term press funnel, curriculum development (e.g., the alumni events), and other shifts to our <em>longer-term</em>&nbsp;significance.</div>\n<div><br></div>\n<div><strong>Alumni reunion, alumni workshops, alumni dojo...</strong></div>\n<div>We ran an alumni reunion, 4 alumni workshops, and a continuing alumni dojo. &nbsp;We intentionally kept the cost of these low to participants, and sliding-scale, so as to help build the community that can take the art forward. &nbsp;</div>\n<div>Detail:</div>\n<div>\n<ul>\n<li>Alumni reunion: $34k income; $38k non-staff costs (for ~100 participants)</li>\n<li>Hamming: $3.6k revenue; $3k non-staff costs</li>\n<li>Assisting thinking: $2.1k revenue; $3.2k non-staff costs</li>\n<li>Attention: $3.3k revenue; $2.7k non-staff costs</li>\n<li>Epistemic Rationality for Effective Altruists: $5k revenue; $3k costs</li>\n<li>Dojo: free.</li>\n</ul>\n</div>\n<div>We also ran a 1.5-day beta workshop for beginners:</div>\n<div>\n<ul>\n<li>\u201cA taste of rationality\u201d: $5k revenue; $2.6k non-staff costs.&nbsp;</li>\n</ul>\n</div>\n<div><br></div>\n<div><strong>SPARC</strong></div>\n<div>SPARC 2014\u2019s non-staff costs came to $62k, and were covered by Dropbox, Quixey, and MIRI (although, as with our other programs, considerable CFAR staff time also went into SPARC).</div>\n<div><br></div>\n<div><strong>Balance sheet</strong></div>\n<div>CFAR has about $130k, going into 2015. &nbsp;(The $30k short-term loan we took last year was repaid as scheduled, following last year's fundraising drive.)</div>\n<div><br></div>\n<div><strong>Summary</strong></div>\n<div>CFAR is more financially stable than it was a year ago but remains dependent on donation to make ends meet, and still more dependent on donation if it is to e.g. outsource the accounting, to further streamline the per-workshop staff time-costs, and to put actual quality focus into developing the epistemic rationality and do-gooding impacts.</div>\n<div><br></div>\n</div>\n<div>\n<h2 id=\"The_big_picture_and_how_you_can_help\"><a name=\"howhelp\"></a>The big picture and how you can help</h2>\n<div>CFAR seems to many of us to be among the efforts most worth investing in. &nbsp;This isn\u2019t because our present workshops are all that great. &nbsp;Rather, it is because, in terms of \u201csaving throws\u201d one can buy for a humanity that may be navigating tricky situations in an unknown future, improvements to thinking skill seem to be one of the strongest and most robust. &nbsp;And we suspect that CFAR is a promising kernel from which to help with that effort.</div>\n<div><br></div>\n<div>As noted, we aim in 2015 to get all the way to a \u201cfull prototype\u201d -- &nbsp;a point from which we are actually visibly helping in the aimed-for way. &nbsp;This will be a tricky spot to get to. Our experience slowly coming to grips with epistemic rationality is probably more rule than the exception, and I suspect we\u2019ll run into a number of curve balls on path to the prototype. &nbsp; &nbsp;</div>\n<div><br></div>\n<div>But with your help -- donations are at this stage critical to being able to put serious focused effort into building the prototype, instead of being terribly distracted staying alive -- I suspect that we can put in the requisite focus, and can have the prototype in hand by the end of 2015.</div>\n<div><br></div>\n<div>...</div>\n<div><br></div>\n<div>Besides donations, we are actually in a good position now use your advice, your experience, and your thoughts on how to navigate CFAR's remaining gaps; we have enough space to take a breath and think strategically.</div>\n<div><br></div>\n<div>We're hoping 2015 will also be a year when CFAR alumni and supporters scale up their connections and their ambitions, launching more startups and other projects. &nbsp;Please keep in touch if you do this; we\u2019d like our curriculum-generation process to continue to connect to live problems.</div>\n<div><br></div>\n<div>A very strong way to help, also, is to come to a <a href=\"http://rationality.org/workshops/\">workshop</a>, and to send your friends there. &nbsp;It keeps CFAR going, we always want there to be more CFAR alumni, and it might even help with that quest. &nbsp;(The data strongly indicates that your friends will thank you for getting them to come\u2026 and will do so even more 6 months later!)</div>\n<div><br></div>\n<div>And do please <a href=\"http://rationality.org/donate\">donate</a> to the Winter 2014 fundraising drive!</div>\n</div>\n<div><br></div>\n<div><br></div>\n<hr>\n<p><a name=\"match\"></a>[1] That is: by giving up a dollar, you can, given some simplifications, cause CFAR to gain two dollars. Much thanks to Peter McCluskey, Jesse Liptrap, Nick Tarleton, Stephanie Zolayvar, Arram Sabeti, Liron Shapira, Ben Hoskin, Eric Rogstad, Matt Graves, Alyssa Vance, Topher Hallquist, and John Clasby for together putting up $120k in matching funds.</p>\n<p><a name=\"author\"></a>[2] This post is a collaborative effort by many at CFAR.</p>\n<p><a name=\"tatrain\"></a>[3] The title we ran it under was \"TA training\", but the name desperately needs revision.</p>\n<p><a name=\"startups\"></a>[4] This is missing several I can almost-recall and probably several others I can\u2019t; please PM me if you remember one I missed. &nbsp;Many of the startups on this list have multiple founders who are CFAR alum. &nbsp;Omitted from this list are startups that were completed before the alumni met us, e.g. Skype; we included however startups that were founded before folks met us and carried on after they became alumni (even when we had no causal impact on the startups). &nbsp;Also of note is that many CFAR alumni are in founding or executive positions at EA-associated non-profits, including <a href=\"https://centreforeffectivealtruism.org/\">CEA</a>, <a href=\"http://cser.org/\">CSER</a>, <a href=\"http://futureoflife.org/\">FLI</a>, <a href=\"http://www.leverageresearch.org/\">Leverage</a>, and <a href=\"http://intelligence.org/\">MIRI</a>. &nbsp;One reason we're happy about this is that it means that the curriculum we're developing is being developed in concert with people who are trying to really actually accomplish hard goals, and who are therefore wanting more from techniques than just \"does this sound cool\".</p>\n<p class=\"p1\"><a name=\"prototype\"></a>[5] Ideally, such a prototype might accomplish increases in (1), (2), and (3) in a manner that felt like facets of a<em>&nbsp;</em>single&nbsp;art, or that all drew upon a common base of simpler cognitive skills (such as subskills for getting accurate beliefs into system 1, for navigating internal disagreement, or for overcoming learned helplessness). &nbsp;A \u201cprototype\u201d would thus also be a product that, when we apply local optimization on it, takes us to curricula that are strategically important to the world -- rather than, say, taking us to well-honed \u201cfeel inspired about your life\u201d workshops, or something).</p>\n<p>Relative to this ideal, the current curriculum seems to in fact accomplish some of (2), for all that we don't have RCTs yet; but it is less successful at (1) and (3). &nbsp;(We'd like, eventually, to scale up (2) as well.) &nbsp;However, we suspect the curriculum contains seeds toward an art that can succeed at (1) and (3); and we aim to demonstrate this in 2015.</p>\n<p class=\"p1\"><a name=\"jargon\"></a>[6] Apologies for the jargon. &nbsp;It is probably about time we wrote up a glossary; but we don't have one yet. &nbsp;If you care, you can pick up some of the vocabulary from our <a href=\"http://rationality.org/schedule/\">sample workshop schedule</a>.</p>\n<div><a name=\"tactics\"></a>[7] This isn\u2019t the detailed tactical plan; we\u2019ll need one of those separately, and we have a partial version that this margin was too small to contain; it\u2019s meant to be a listing of how you and we can tell whether we won, at the end of 2015.</div>\n<div><br></div>\n<div><a name=\"apgar\"></a>[8] The Apgar score for assessing newborn health is inspiring, here; if you've not seen it before, and you're wondering how one could possibly come up with a metric, you might glance at its&nbsp;<a href=\"http://en.wikipedia.org/wiki/Apgar_score\">wikipedia page</a>. &nbsp;Basically, instead of coming up with a single 0 to 10 newborn health scale, Dr. Apgar chose 5 simpler components (newborn color; newborn heart rate; etc.), came up with <em>very</em>&nbsp;simple \"0 to 2\" measures for these, and then added.</div>\n<div><br></div>", "sections": [{"title": "Highlights from 2014", "anchor": "Highlights_from_2014", "level": 1}, {"title": "Improving operations", "anchor": "Improving_operations", "level": 1}, {"title": "Attempts to go beyond the current workshop and toward the \u2018full prototype\u2019 of CFAR: our experience in 2014 and plans for 2015", "anchor": "Attempts_to_go_beyond_the_current_workshop_and_toward_the__full_prototype__of_CFAR__our_experience_in_2014_and_plans_for_2015", "level": 1}, {"title": "Epistemic rationality curriculum", "anchor": "Epistemic_rationality_curriculum", "level": 2}, {"title": "Goals for 2015", "anchor": "Goals_for_2015", "level": 2}, {"title": "Nuts, Bolts, and Financial Details", "anchor": "Nuts__Bolts__and_Financial_Details", "level": 2}, {"title": "The big picture and how you can help", "anchor": "The_big_picture_and_how_you_can_help", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "61 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 73, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JjGs6mDZxeCWkg3ii"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-26T15:54:33.912Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-20", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Cf29E5WMjDb3MdKPb/weekly-lw-meetups-20", "pageUrlRelative": "/posts/Cf29E5WMjDb3MdKPb/weekly-lw-meetups-20", "linkUrl": "https://www.lesswrong.com/posts/Cf29E5WMjDb3MdKPb/weekly-lw-meetups-20", "postedAtFormatted": "Friday, December 26th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCf29E5WMjDb3MdKPb%2Fweekly-lw-meetups-20%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCf29E5WMjDb3MdKPb%2Fweekly-lw-meetups-20", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCf29E5WMjDb3MdKPb%2Fweekly-lw-meetups-20", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 533, "htmlBody": "<p><strong>This summary was posted to LW Main on December 19th. The&nbsp;following summary is <a href=\"/lw/lfs/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/17w\">Atlanta December Meetup - Game Night!:&nbsp;<span class=\"date\">27 December 2014 07:00AM</span></a></li>\n<li><a href=\"/meetups/17o\">Copenhagen: December Meetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/160\">East Coast Solstice Megameetup:&nbsp;<span class=\"date\">20 December 2014 03:00PM</span></a></li>\n<li><a href=\"/meetups/15w\">European Community Weekend 2015:&nbsp;<span class=\"date\">12 June 2015 12:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<li><a href=\"/meetups/181\">Sandy, UT (SLC) - Debugging:&nbsp;<span class=\"date\">19 December 2014 12:00PM</span></a></li>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/17c\">Utrecht: a critique of effective altruism:&nbsp;<span class=\"date\">04 January 2015 02:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX - Caffe Medici:&nbsp;<span class=\"date\">03 January 2026 01:30PM</span></a></li>\n<li><a href=\"/meetups/180\">London Social Meetup, 21/12/2014:&nbsp;<span class=\"date\">21 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/182\">Moscow Meetup: biology, CBT and something mysterious:&nbsp;<span class=\"date\">22 December 2014 02:00PM</span></a></li>\n<li><a href=\"/meetups/17r\">Sydney Summer Solstice:&nbsp;<span class=\"date\">21 December 2014 06:00PM</span></a></li>\n<li><a href=\"/meetups/183\">Washington, D.C.: Fun &amp; Games:&nbsp;<span class=\"date\">21 December 2014 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\">Berlin</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Boston.2C_MA\">Boston</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Brussels.2C_Belgium\">Brussels</a></strong><strong>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Buffalo.2C_NY\">Buffalo</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Canberra\">Canberra</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Columbus.2C_OH\">Columbus</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Moscow.2C_Russia\">Moscow</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Philadelphia.2C_PA\">Philadelphia</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Research_Triangle.2C_NC_.28Raleigh.2FDurham.2FChapel_Hill.29\">Research Triangle NC</a>,</strong><strong>&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Sydney\">Sydney</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a></strong><strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington DC</strong></a></strong>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview is posted on the front page every Friday. These are an attempt to collect information on all the meetups happening in upcoming weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll also have the benefit of having your meetup mentioned in a weekly overview. These overview posts are moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cincinnati</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cleveland</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> </strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tel_Aviv.2C_Israel\">Tel Aviv</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Warsaw.2C_Poland\">Warsaw</a></strong><strong>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Cf29E5WMjDb3MdKPb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3068453171328656e-06, "legacy": true, "legacyId": "27756", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MBhbNypRZbC4Fa2xR", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-26T17:15:00.057Z", "modifiedAt": null, "url": null, "title": "Meetup : Bangalore Meetup", "slug": "meetup-bangalore-meetup-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "anandjeyahar", "createdAt": "2011-08-06T14:22:03.370Z", "isAdmin": false, "displayName": "anandjeyahar"}, "userId": "nRE6w4ErwoFMLnAfg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Bw89mFijKNDKtKagS/meetup-bangalore-meetup-0", "pageUrlRelative": "/posts/Bw89mFijKNDKtKagS/meetup-bangalore-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/Bw89mFijKNDKtKagS/meetup-bangalore-meetup-0", "postedAtFormatted": "Friday, December 26th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Bangalore%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Bangalore%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBw89mFijKNDKtKagS%2Fmeetup-bangalore-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Bangalore%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBw89mFijKNDKtKagS%2Fmeetup-bangalore-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBw89mFijKNDKtKagS%2Fmeetup-bangalore-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/186'>Bangalore Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 January 2015 11:02:00AM (+0530)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Central Mall, MG road, bangalore</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>1st meetup of then new year for less  wrongers in bangalore.  Let's use the meetup.com page for co-ordinating. <a href=\"http://www.meetup.com/Bangalore-LessWrongers-Meetup/events/219133638/.\" rel=\"nofollow\">http://www.meetup.com/Bangalore-LessWrongers-Meetup/events/219133638/.</a> \nAnd here's a mailing list. <a href=\"https://groups.google.com/forum/#!forum/bangalore-lesswrongers\" rel=\"nofollow\">https://groups.google.com/forum/#!forum/bangalore-lesswrongers</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/186'>Bangalore Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Bw89mFijKNDKtKagS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.307030734685835e-06, "legacy": true, "legacyId": "27785", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Bangalore_Meetup\">Discussion article for the meetup : <a href=\"/meetups/186\">Bangalore Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 January 2015 11:02:00AM (+0530)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Central Mall, MG road, bangalore</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>1st meetup of then new year for less  wrongers in bangalore.  Let's use the meetup.com page for co-ordinating. <a href=\"http://www.meetup.com/Bangalore-LessWrongers-Meetup/events/219133638/.\" rel=\"nofollow\">http://www.meetup.com/Bangalore-LessWrongers-Meetup/events/219133638/.</a> \nAnd here's a mailing list. <a href=\"https://groups.google.com/forum/#!forum/bangalore-lesswrongers\" rel=\"nofollow\">https://groups.google.com/forum/#!forum/bangalore-lesswrongers</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Bangalore_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/186\">Bangalore Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Bangalore Meetup", "anchor": "Discussion_article_for_the_meetup___Bangalore_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Bangalore Meetup", "anchor": "Discussion_article_for_the_meetup___Bangalore_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-27T10:08:11.620Z", "modifiedAt": null, "url": null, "title": "Suggestions for 31C3 (Chaos Communication Congress)", "slug": "suggestions-for-31c3-chaos-communication-congress", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.544Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gunnar_Zarncke", "createdAt": "2013-07-20T15:40:42.323Z", "isAdmin": false, "displayName": "Gunnar_Zarncke"}, "userId": "qmJFRN7jitjPsuF3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/odRFooNSHxKj6QKdu/suggestions-for-31c3-chaos-communication-congress", "pageUrlRelative": "/posts/odRFooNSHxKj6QKdu/suggestions-for-31c3-chaos-communication-congress", "linkUrl": "https://www.lesswrong.com/posts/odRFooNSHxKj6QKdu/suggestions-for-31c3-chaos-communication-congress", "postedAtFormatted": "Saturday, December 27th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Suggestions%20for%2031C3%20(Chaos%20Communication%20Congress)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuggestions%20for%2031C3%20(Chaos%20Communication%20Congress)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FodRFooNSHxKj6QKdu%2Fsuggestions-for-31c3-chaos-communication-congress%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Suggestions%20for%2031C3%20(Chaos%20Communication%20Congress)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FodRFooNSHxKj6QKdu%2Fsuggestions-for-31c3-chaos-communication-congress", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FodRFooNSHxKj6QKdu%2Fsuggestions-for-31c3-chaos-communication-congress", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 262, "htmlBody": "<p>Hi, I will be attending <a href=\"https://events.ccc.de/congress/2014/wiki/Main_Page\">31C3</a>, the 31th chaos communication congress in Hamburg today and the next days. For those who don't know about this hacker conference, here is a summary:</p>\n<blockquote>\n<p>The 31st Chaos Communication Congress (31C3) is an annual four-day conference on technology, society and utopia. The Congress offers lectures and workshops and various events on a multitude of topics including (but not limited to) information technology and generally a critical-creative attitude towards technology and the discussion about the effects of technological advances on society.</p>\n</blockquote>\n<p>This sounds a lot like a suitable forum for talking existencial risk from AI. But apparently no such talk is listed in the <a href=\"http://events.ccc.de/congress/2014/Fahrplan/\">Fahrplan</a>. As this appears to be a conference largely self-organized I might find a slot where I can present UFAI risks to a smaller audience.&nbsp;</p>\n<p>Thus this is a request for material I might use to present this. My first idea was to use the <a href=\"/lw/k37/ai_risk_new_executive_summary/\">MIRI executive summary</a>. What else can I use? Some quick slides? Where might I link to best? What could I use as a quickl handout/flyer?</p>\n<p>Yes this is on short notice but I admit that I didn't draw this connection earlier. For me the 31C3 was 'just' a hacker conference to meet people at.</p>\n<p>ADDED: And that's what it ended to be. I met <a href=\"https://twitter.com/plinz\">Joscha Bach</a> and took part in a discussion about consciousness as computation. I met Oliver Habryka (good luck in California) and also people from the Berlin (Hi Tristan) and Frankfurt Meetups (Hi Kai). Overall a cool event though personally I didn't get that much out of the talks.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "odRFooNSHxKj6QKdu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 2.309368569664574e-06, "legacy": true, "legacyId": "27787", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BZfnJGe5S6KtB5pjQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-27T11:44:45.411Z", "modifiedAt": null, "url": null, "title": "We Haven't Uploaded Worms", "slug": "we-haven-t-uploaded-worms", "viewCount": null, "lastCommentedAt": "2019-07-15T17:50:27.152Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/B5auLtDfQrvwEkw4Q/we-haven-t-uploaded-worms", "pageUrlRelative": "/posts/B5auLtDfQrvwEkw4Q/we-haven-t-uploaded-worms", "linkUrl": "https://www.lesswrong.com/posts/B5auLtDfQrvwEkw4Q/we-haven-t-uploaded-worms", "postedAtFormatted": "Saturday, December 27th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20We%20Haven't%20Uploaded%20Worms&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWe%20Haven't%20Uploaded%20Worms%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB5auLtDfQrvwEkw4Q%2Fwe-haven-t-uploaded-worms%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=We%20Haven't%20Uploaded%20Worms%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB5auLtDfQrvwEkw4Q%2Fwe-haven-t-uploaded-worms", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FB5auLtDfQrvwEkw4Q%2Fwe-haven-t-uploaded-worms", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 595, "htmlBody": "<blockquote>\n<p>In theory you can upload someone's mind onto a computer, allowing them to live forever as a digital form of consciousness, just like in the Johnny Depp film Transcendence.</p>\n<p>But it's not just science fiction. Sure, scientists aren't anywhere near close to achieving such feat with humans (and even if they could, the ethics would be pretty fraught), but now an international team of researchers have managed to do just that with the roundworm Caenorhabditis elegans. <br />&nbsp;&nbsp;&mdash;<a href=\"http://www.sciencealert.com/watch-scientists-have-put-a-worm-s-brain-into-a-lego-robot-s-body-and-it-works\">Science Alert</a></p>\n</blockquote>\n<p>Uploading an animal, even one as simple as <em>c. elegans</em> would be very impressive. Unfortunately, we're not there yet. What the people working on <a href=\"http://www.openworm.org/\">Open Worm</a> have done instead is to build a working robot based on the <em>c. elegans</em> and show that it can do some things that the worm can do.</p>\n<p>The <em>c. elegans</em> nematode has only 302 neurons, and each nematode has the same fixed pattern. We've known this pattern, or connectome, since 1986. [1] In a simple model, each neuron has a threshold and will fire if the weighted sum of its inputs is greater than that threshold. Which means knowing the connections isn't enough: we also need to know the weights and thresholds. Unfortunately, we haven't figured out a way to read these values off of real worms. Suzuki et. al. (2005) [2] ran a genetic algorithm to learn values for these parameters that would give a somewhat realistic worm and showed various wormlike behaviors in software. The recent stories about the Open Worm project have been for them doing something similar in hardware. [3]</p>\n<p>To see why this isn't enough, consider that nematodes are capable of learning. Sasakura and Mori (2013) [5] provide a reasonable overview. For example, nematodes can learn that a certain temperature indicates food, and then seek out that temperature. They don't do this by growing new neurons or connections, they have to be updating their connection weights. All the existing worm simulations treat weights as fixed, which means they can't learn. They also don't read weights off of any individual worm, which means we can't talk about any specific worm as being uploaded.</p>\n<p>If this doesn't count as uploading a worm, however, what would? Consider an experiment where someone trains one group of worms to respond to stimulus one way and another group to respond the other way. Both groups are then scanned and simulated on the computer. If the simulated worms responded to simulated stimulus the same way their physical versions had, that would be good progress. Additionally you would want to demonstrate that similar learning was possible in the simulated environment.</p>\n<p>(In a 2011 post on <a href=\"http://www.jefftk.com/p/whole-brain-emulation-and-nematodes\">what progress with nematodes might tell us about uploading humans</a> I looked at some of this research before. Since then not much has changed with nematode simulation. Moore's law looks to be doing much worse in 2014 than it did in 2011, however, which makes the prospects for whole brain emulation substantially worse.)</p>\n<p><small><em>I also posted this <a href=\"http://www.jefftk.com/p/we-havent-uploaded-worms\">on my blog</a>.</em></small></p>\n<p><br /> [1] <a href=\"http://rstb.royalsocietypublishing.org/content/314/1165/1\">The Structure of the Nervous System of the Nematode Caenorhabditis elegans</a>, White et. al. (1986).</p>\n<p>[2] <a href=\"http://www.bsys.hiroshima-u.ac.jp/pub/pdf/J/J_153.pdf\">A Model of Motor Control of the Nematode C. Elegans With Neuronal Circuits</a>, Suzuki et. al. (2005).</p>\n<p>[3] It looks like instead of learning weights Busbice just set them all to +1 (excitatory) and -1 (inhibitory). It's not clear to me how they knew which connections were which; my best guess is that they're using the \"what happens to work\" details from [2]. Their full writeup is [4].</p>\n<p>[4] <a href=\"http://www.jefftk.com/BioCoderFall2014.pdf\">The Robotic Worm</a>, Busbice (2014).</p>\n<p>[5] <a href=\"http://www.jefftk.com/sasakura2013.pdf\">Behavioral Plasticity, Learning, and Memory in C. Elegans</a>, Sasakura and Mori (2013).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jaf5zfcGgCB2REXGw": 2, "jQytxyauJ7kPhhGj3": 4, "5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "B5auLtDfQrvwEkw4Q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 108, "baseScore": 150, "extendedScore": null, "score": 0.000439, "legacy": true, "legacyId": "27779", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 150, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-27T17:19:25.332Z", "modifiedAt": null, "url": null, "title": "Tachyon neutrinos (again)", "slug": "tachyon-neutrinos-again", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.309Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JoshuaZ", "createdAt": "2010-04-05T04:07:01.214Z", "isAdmin": false, "displayName": "JoshuaZ"}, "userId": "fmTiLqp6mmXeLjwfN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RYLB2XWS4Jmyvgmuj/tachyon-neutrinos-again", "pageUrlRelative": "/posts/RYLB2XWS4Jmyvgmuj/tachyon-neutrinos-again", "linkUrl": "https://www.lesswrong.com/posts/RYLB2XWS4Jmyvgmuj/tachyon-neutrinos-again", "postedAtFormatted": "Saturday, December 27th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tachyon%20neutrinos%20(again)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATachyon%20neutrinos%20(again)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRYLB2XWS4Jmyvgmuj%2Ftachyon-neutrinos-again%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tachyon%20neutrinos%20(again)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRYLB2XWS4Jmyvgmuj%2Ftachyon-neutrinos-again", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRYLB2XWS4Jmyvgmuj%2Ftachyon-neutrinos-again", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 595, "htmlBody": "<p>In 2012, a large amount of attention was given to the <a href=\"http://en.wikipedia.org/wiki/Faster-than-light_neutrino_anomaly\">OPERA experiment's apparent sighting of faster than light neutrinos</a>. This turned out to be erroneous due to a faulty cable, and similar experiments confirmed the same results. However, while this was occurring, a distinct point was made: some attempts to determine the mass of the electron neutrino(one of the three known neutrino types) found that the square of the mass was apparently negative, which would be consistent with an imaginary mass and thus electron neutrinos would be tachyons. While little attention was paid to at the time, <a href=\"http://arxiv.org/abs/1408.2804\">a new paper by Robert Ehrlich</a>&nbsp;looks again at this approach. Ehrlich points out that six different experimental results seem to yield an imaginary mass for the electron neutrino, and what is more, all the results are in close agreement, with an apparent square of the mass being close to -0.11 electron-volts squared.&nbsp;</p>\n<p>There are at least two major difficulties with Ehrlich's suggestion, both of which were also issues for OPERA aside from any philosophical or metaconcerns like desire to preserve causality. First, it is difficult to reconcile with Ehrlich's suggestion is one of the same data points that apparently tripped up OPERA, that is the neutrinos from&nbsp;<a href=\"http://en.wikipedia.org/wiki/SN_1987A\">SN 1987A</a> neutrinos. In the SN 1987A supernova &nbsp;(the first observed in 1987 hence the name), the supernova was close enough that we were actually able to detect the neutrinos from it. The neutrinos arrived about three hours before the light from the supernova. But that's not evidence for faster than light neutrinos, since one actually expects this to happen. In the standard way of viewing things, the neutrinos move very very close to the speed of light, but during a core-collapse supernova like SN 1987A, the neutrinos are produced in the core at the beginning of the process. They then flee the star without interacting with the matter, whereas the light produced in the core is slowed down by all the matter in the way, so the neutrinos get a few hours head start.&nbsp;</p>\n<p>The problem for FTL neutrinos is that if the neutrions were even a tiny bit faster than the speed of light they should have arrived much much earlier. This is strong evidence against FTL neutrinos. In the paper in question, Ehrlich mentions SN 1987A in the context of testing his hypothesis in an alternate way using a supernova and the exact distribution of the neutrinos from one but doesn't discuss anywhere I can see the more basic issue of the neutrinos arriving at close to the same time as the light. It is conceivable that electron neutrinos are the only neutrinos which are tachyons, and if this is the case, then it seems like neutrino oscillation (the tendency for neutrinos to change types spontaneously) could account for part of what is going on here, but having only some types of neutrinos be tachyons would possibly lead to other problems.&nbsp;</p>\n<p>Second, there's reason to believe that tachyons if they existed would emit Cherenkov-like radiation. Andrew Cohen and Sheldon Glashow w<a href=\"http://arxiv.org/abs/1109.6562\">rote a paper showing that this would be a major issue in the context of OPERA</a>. Ehrlich seems to claim in the new paper that this shouldn't be an issue in the context he is working in, but does not provide any reasoning. Hopefully someone who is more of an expert can comment on what is going on there.</p>\n<p>This seems like potentially stronger evidence for tachyonic neutrinos than the OPERA experiment since this is the same result from a variety of different experiments all giving very close to the same results.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RYLB2XWS4Jmyvgmuj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "27788", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-27T19:14:13.456Z", "modifiedAt": null, "url": null, "title": "Meetup : January Meetup in Munich", "slug": "meetup-january-meetup-in-munich", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.337Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Teobaldo", "createdAt": "2012-10-28T17:25:26.852Z", "isAdmin": false, "displayName": "Teobaldo"}, "userId": "BhijBsy7WLfpnsZGJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4vbHNJ4inNRqyyiKg/meetup-january-meetup-in-munich", "pageUrlRelative": "/posts/4vbHNJ4inNRqyyiKg/meetup-january-meetup-in-munich", "linkUrl": "https://www.lesswrong.com/posts/4vbHNJ4inNRqyyiKg/meetup-january-meetup-in-munich", "postedAtFormatted": "Saturday, December 27th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20January%20Meetup%20in%20Munich&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20January%20Meetup%20in%20Munich%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4vbHNJ4inNRqyyiKg%2Fmeetup-january-meetup-in-munich%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20January%20Meetup%20in%20Munich%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4vbHNJ4inNRqyyiKg%2Fmeetup-january-meetup-in-munich", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4vbHNJ4inNRqyyiKg%2Fmeetup-january-meetup-in-munich", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/187'>January Meetup in Munich</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 January 2015 02:00:22PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Gast, Rosenheimer Stra\u00dfe 5, 81667 Munich, Germany</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>the first meetup after the Christmas holidays. We'll be talking about the difference between frequentists and bayesianists and discuss the quantum physics sequence. Further topics are welcomed and we encourage new people to come and say 'hi'.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/187'>January Meetup in Munich</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4vbHNJ4inNRqyyiKg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.3106302162100513e-06, "legacy": true, "legacyId": "27789", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___January_Meetup_in_Munich\">Discussion article for the meetup : <a href=\"/meetups/187\">January Meetup in Munich</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 January 2015 02:00:22PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Gast, Rosenheimer Stra\u00dfe 5, 81667 Munich, Germany</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>the first meetup after the Christmas holidays. We'll be talking about the difference between frequentists and bayesianists and discuss the quantum physics sequence. Further topics are welcomed and we encourage new people to come and say 'hi'.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___January_Meetup_in_Munich1\">Discussion article for the meetup : <a href=\"/meetups/187\">January Meetup in Munich</a></h2>", "sections": [{"title": "Discussion article for the meetup : January Meetup in Munich", "anchor": "Discussion_article_for_the_meetup___January_Meetup_in_Munich", "level": 1}, {"title": "Discussion article for the meetup : January Meetup in Munich", "anchor": "Discussion_article_for_the_meetup___January_Meetup_in_Munich1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-27T20:56:25.686Z", "modifiedAt": null, "url": null, "title": "SciAm article about rationality corresponding only weakly with IQ", "slug": "sciam-article-about-rationality-corresponding-only-weakly", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.221Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DavidPlumpton", "createdAt": "2011-07-08T09:36:12.175Z", "isAdmin": false, "displayName": "DavidPlumpton"}, "userId": "JyR3HoGsDEckYxEGE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FicsmBxoFL92auaPQ/sciam-article-about-rationality-corresponding-only-weakly", "pageUrlRelative": "/posts/FicsmBxoFL92auaPQ/sciam-article-about-rationality-corresponding-only-weakly", "linkUrl": "https://www.lesswrong.com/posts/FicsmBxoFL92auaPQ/sciam-article-about-rationality-corresponding-only-weakly", "postedAtFormatted": "Saturday, December 27th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SciAm%20article%20about%20rationality%20corresponding%20only%20weakly%20with%20IQ&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASciAm%20article%20about%20rationality%20corresponding%20only%20weakly%20with%20IQ%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFicsmBxoFL92auaPQ%2Fsciam-article-about-rationality-corresponding-only-weakly%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SciAm%20article%20about%20rationality%20corresponding%20only%20weakly%20with%20IQ%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFicsmBxoFL92auaPQ%2Fsciam-article-about-rationality-corresponding-only-weakly", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFicsmBxoFL92auaPQ%2Fsciam-article-about-rationality-corresponding-only-weakly", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.scientificamerican.com/article/rational-and-irrational-thought-the-thinking-that-iq-tests-miss/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4cKQgA4S7xfNeeWXg": 2, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FicsmBxoFL92auaPQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "27790", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-27T21:30:32.729Z", "modifiedAt": null, "url": null, "title": "Meetup : New Year meetup Frankfurt", "slug": "meetup-new-year-meetup-frankfurt", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kendra", "createdAt": "2012-02-29T23:10:44.583Z", "isAdmin": false, "displayName": "Kendra"}, "userId": "BPB6kHkfZwFLrhcbG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/45ceaYkX4KtwzfmPx/meetup-new-year-meetup-frankfurt", "pageUrlRelative": "/posts/45ceaYkX4KtwzfmPx/meetup-new-year-meetup-frankfurt", "linkUrl": "https://www.lesswrong.com/posts/45ceaYkX4KtwzfmPx/meetup-new-year-meetup-frankfurt", "postedAtFormatted": "Saturday, December 27th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20New%20Year%20meetup%20Frankfurt&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20New%20Year%20meetup%20Frankfurt%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F45ceaYkX4KtwzfmPx%2Fmeetup-new-year-meetup-frankfurt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20New%20Year%20meetup%20Frankfurt%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F45ceaYkX4KtwzfmPx%2Fmeetup-new-year-meetup-frankfurt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F45ceaYkX4KtwzfmPx%2Fmeetup-new-year-meetup-frankfurt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 160, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/188'>New Year meetup Frankfurt</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 January 2015 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Heerstrasse Frankfurt</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're having our first meetup in the New Year!\nI'd like to encourage to do some projects together this year (and look at what some or all of us want to change/improve).\nOur TOP (after a bit of arrival time as usual)</p>\n\n<p>1) New Year Plans and Projects (and regular Goal Tracking)</p>\n\n<p>2) Talk: How can you improve your social skills?</p>\n\n<p>3) Prediction Game</p>\n\n<p>More talks about other topics, especially project ideas, are welcome!\nI'll edit more details in later. It would be great if you could bring some food. There'll also be (vegan-friendly) food available.\nIf you have any problems attending (social anxiety, wheelchair accessibility, etc), please tell me, I'll try to accommodate for your needs as best as I can!\nYou can reach me under +4917634095760 for further details and/or join our mailing list: <a href=\"https://groups.google.com/forum/#!forum/less-wrong-frankfurt\" rel=\"nofollow\">https://groups.google.com/forum/#!forum/less-wrong-frankfurt</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/188'>New Year meetup Frankfurt</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "45ceaYkX4KtwzfmPx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.310945387309882e-06, "legacy": true, "legacyId": "27791", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___New_Year_meetup_Frankfurt\">Discussion article for the meetup : <a href=\"/meetups/188\">New Year meetup Frankfurt</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 January 2015 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Heerstrasse Frankfurt</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're having our first meetup in the New Year!\nI'd like to encourage to do some projects together this year (and look at what some or all of us want to change/improve).\nOur TOP (after a bit of arrival time as usual)</p>\n\n<p>1) New Year Plans and Projects (and regular Goal Tracking)</p>\n\n<p>2) Talk: How can you improve your social skills?</p>\n\n<p>3) Prediction Game</p>\n\n<p>More talks about other topics, especially project ideas, are welcome!\nI'll edit more details in later. It would be great if you could bring some food. There'll also be (vegan-friendly) food available.\nIf you have any problems attending (social anxiety, wheelchair accessibility, etc), please tell me, I'll try to accommodate for your needs as best as I can!\nYou can reach me under +4917634095760 for further details and/or join our mailing list: <a href=\"https://groups.google.com/forum/#!forum/less-wrong-frankfurt\" rel=\"nofollow\">https://groups.google.com/forum/#!forum/less-wrong-frankfurt</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___New_Year_meetup_Frankfurt1\">Discussion article for the meetup : <a href=\"/meetups/188\">New Year meetup Frankfurt</a></h2>", "sections": [{"title": "Discussion article for the meetup : New Year meetup Frankfurt", "anchor": "Discussion_article_for_the_meetup___New_Year_meetup_Frankfurt", "level": 1}, {"title": "Discussion article for the meetup : New Year meetup Frankfurt", "anchor": "Discussion_article_for_the_meetup___New_Year_meetup_Frankfurt1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-28T09:38:35.320Z", "modifiedAt": null, "url": null, "title": "The buildup to Jaynes? ", "slug": "the-buildup-to-jaynes", "viewCount": null, "lastCommentedAt": "2020-02-11T19:23:17.651Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Capla", "createdAt": "2014-08-13T03:07:43.569Z", "isAdmin": false, "displayName": "Capla"}, "userId": "KSqXxC5yBv52Aaj4Z", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gcL4xmAeNT5QEnPWg/the-buildup-to-jaynes", "pageUrlRelative": "/posts/gcL4xmAeNT5QEnPWg/the-buildup-to-jaynes", "linkUrl": "https://www.lesswrong.com/posts/gcL4xmAeNT5QEnPWg/the-buildup-to-jaynes", "postedAtFormatted": "Sunday, December 28th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20buildup%20to%20Jaynes%3F%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20buildup%20to%20Jaynes%3F%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgcL4xmAeNT5QEnPWg%2Fthe-buildup-to-jaynes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20buildup%20to%20Jaynes%3F%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgcL4xmAeNT5QEnPWg%2Fthe-buildup-to-jaynes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgcL4xmAeNT5QEnPWg%2Fthe-buildup-to-jaynes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>Not too long ago, I asked LessWrong <a href=\"/lw/l91/the_best_mathematicallyinformed_topics/\">which math topics to learn</a>. Eventually, I want to ask for what the prerequisites for each of those topics are and how I should go about learning them. This is a special case of that.</p>\n<p>I'm rereading the sequences and Eliezer seems to love E.T. Jaynes. As part of my rationality self-study, I want to work my way through his <a href=\"http://www.amazon.com/Probability-Theory-E-T-Jaynes/dp/0521592712/ref=sr_1_1?ie=UTF8&amp;qid=1419722612&amp;sr=8-1&amp;keywords=Jaynes\"><em>Probability Theory: the Logic of Science</em></a>.<em> </em>What math topics do I already need to understand to prepare myself for this? I learned calculus once upon a time, but not fantastically well, and I plan to start by reviewing that.</p>\n<p>Also,</p>\n<p>Despite Eliezer's praise of the \"thousand-year-old <a href=\"/lw/ua/the_level_above_mine/\">vampire</a>\", it there a better book to learn probability theory?</p>\n<p>Does anyone want to learn this (or the other math from my post above) with me? I'd love to have a partner or maybe even a work group. Location is no obstacle. [Two caveats: 1. I'm busy with stuff and may not be able to get into this for a few months 2. I hard, but I am incredibly slow at computation (such that on every math test I have ever taken, it took me at least 3 times as long as the second slowest person in the class to finish). You might find that I go to slow for you.]</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gcL4xmAeNT5QEnPWg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 3.6e-05, "legacy": true, "legacyId": "27795", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3cfoYriyG3BAs38pp", "kXSETKZ3X9oidMozA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-28T15:06:44.352Z", "modifiedAt": null, "url": null, "title": "Friendly UI", "slug": "friendly-ui", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:02.024Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cicatriz", "createdAt": "2012-06-21T17:10:35.024Z", "isAdmin": false, "displayName": "cicatriz"}, "userId": "kDLZStLTk89gsufnM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ugkp3QjdFz4bpBbHQ/friendly-ui", "pageUrlRelative": "/posts/ugkp3QjdFz4bpBbHQ/friendly-ui", "linkUrl": "https://www.lesswrong.com/posts/ugkp3QjdFz4bpBbHQ/friendly-ui", "postedAtFormatted": "Sunday, December 28th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Friendly%20UI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFriendly%20UI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fugkp3QjdFz4bpBbHQ%2Ffriendly-ui%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Friendly%20UI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fugkp3QjdFz4bpBbHQ%2Ffriendly-ui", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fugkp3QjdFz4bpBbHQ%2Ffriendly-ui", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 740, "htmlBody": "<p>I want to bring up some questions that I find crucial to consider about technology in the present day. To contrast with <a href=\"http://wiki.lesswrong.com/wiki/Friendly_artificial_intelligence\">Friendly AI</a>, these questions are about our <em>interaction</em> with technological tools rather than developing a technology that we trust <em>on its own</em> with superhuman intelligence.</p>\n<p>&nbsp;</p>\n<p>1. <strong>How are computational tools affecting how we perceive, think, and act?</strong></p>\n<p>The inspiration for this post is Bret Victor's new talk, <a href=\"http://vimeo.com/115154289\">The Humane Representation of Thought</a>. I highly recommend it. In particular, you may want to pause and reflect on the first part before seeing his sketch of solutions in the second. In a nutshell, we have a certain range of human capacities. The use of computing as a medium propels us to develop and value particular capacities: visual &amp; symbolic. Others have discussed diminishing our&nbsp;<a href=\"http://www.theatlantic.com/magazine/archive/2008/07/is-google-making-us-stupid/306868/\">attention span</a>,&nbsp;<a href=\"http://www.wsj.com/news/articles/SB10000872396390443686004577633491013088640\">decision-making capacity</a>, or <a href=\"http://meyerweb.com/eric/thoughts/2014/12/24/inadvertent-algorithmic-cruelty/\">cultural expectations of decency</a>.&nbsp;Victor's term for this is \"inhumane\". He argues that the default path of technological progress has certain properties, but preserving humaneness is not one of them.</p>\n<p>The FAI discussions seem to miss both sides of the coin on this phenomenon. First that computation, even though it doesn't exist as a superintelligent <em>entity</em>&nbsp;yet, still imposes values. Second that human intelligence is not a static target: humanity can only reasonably be defined as including the tools we use (humanity without writing or humanity without agriculture are very different), so human intelligence changes along with computation.</p>\n<p>In other words, can we design computation now such that it carries us humans to superintelligence? Or, at the very least, doesn't diminish our intelligence and life experience. What are the answers when we&nbsp;<a href=\"http://thefrailestthing.com/2014/11/29/do-artifacts-have-ethics/\">ask questions of technology</a>?</p>\n<p>&nbsp;</p>\n<p>2. <strong>How can humans best interact with machines with superhuman aspects of intelligence? </strong></p>\n<p>There are already machines with superhuman aspects of intelligence, with applications such as chess, essay grading, or image recognition. These systems are deployed without fully understanding how they work, by the very definition of superhuman intelligence. For instance we don't really understand how a machine learning algorithm reaches its conclusion with an unfathomable amount of data. Even if we can prove certain mathematical properties about the behavior, it will be impossible to empathize with the full range of a computer's decision space. Consider how certain nonsensical images&nbsp;<a href=\"http://www.kdnuggets.com/2014/06/deep-learning-deep-flaws.html\">trick image recognition algorithms</a>. Increased machine intelligence will only be harder to predict while having a greater impact.</p>\n<p>Luckily, today and in the foreseeable future, we don't simply press a button and let computers run and act indefinitely on their own. Computing is an interactive process. That means there are human-to-machine and machine-to-human channels of communications--commonly called interfaces--that impact our human-machine coevolution. This idea is present throughout our lives, but it is a <a href=\"http://www.ribbonfarm.com/2013/10/11/the-mother-of-all-disruptions/\">major disruption</a> that we take for granted.</p>\n<p>One example of a machine intelligence interface: LightSide Labs, which does automated grading, has <a href=\"http://lightsidelabs.com/ra/\">a tool</a> that allows students to submit multiple drafts, each time understanding the computer's analysis along different dimensions (their example has development, language, clarity, and evidence). Other than changing the essay though, there's no opportunity for human-to-machine communication. The student couldn't say \"I'm not sure why you rated my evidence low. You might want to look at such-and-such historical document.\"</p>\n<p>Generally, it is only the programmers who have such control over the machine. Even then programming is a highly uncertain domain. Better programming languages and tools make strides on both ease-of-use and predictability, but we seem a lot way off from safe and powerful machine communication available to the lay user (i.e. <a href=\"http://en.wikipedia.org/wiki/End-user_development\">end-user programming</a>).</p>\n<p>In this regard, FAI--because of its focus on intelligence explosion--skips the more obvious step of communication as a means of guiding the path. Parents don't give birth to children with provable value systems, they use discussion and send them to institutions like school and church to perform that duty.</p>\n<p>&nbsp;</p>\n<p>It may be true that these concerns would be dwarfed by an intelligence explosion, but they are increasingly concerning on the path to get there. They live in existing domains like UI design and human-computer interaction (if you are new to these fields, I recommend <a href=\"http://www.amazon.com/Design-Everyday-Things-Donald-Norman/dp/0465067107\">The Design of Everyday Things</a> or&nbsp;<a href=\"http://www.amazon.com/The-Inmates-Are-Running-Asylum/dp/0672326140\">The Inmates Are Running the Asylum</a>) and others I'm less familiar with like media studies and technology and society. However, I think these fields need more connections to deep knowledge of machine intelligence.</p>\n<p>&nbsp;</p>\n<p>Am I missing anything in my framing of the problem, or is it better covered by an existing framework? How can we contribute?</p>\n<p>&nbsp;</p>\n<p><strong>Edit:</strong>&nbsp;Changed the first paragraph to de-emphasize the coining of the \"FUI\" term. Now it's just the title of the post. Proceed!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ugkp3QjdFz4bpBbHQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 3, "extendedScore": null, "score": 2.3133898593387157e-06, "legacy": true, "legacyId": "27792", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-29T04:50:55.000Z", "modifiedAt": null, "url": null, "title": "The steering problem", "slug": "the-steering-problem", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5bd75cc58225bf0670374eb8/the-steering-problem", "pageUrlRelative": "/posts/5bd75cc58225bf0670374eb8/the-steering-problem", "linkUrl": "https://www.lesswrong.com/posts/5bd75cc58225bf0670374eb8/the-steering-problem", "postedAtFormatted": "Monday, December 29th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20steering%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20steering%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374eb8%2Fthe-steering-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20steering%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374eb8%2Fthe-steering-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374eb8%2Fthe-steering-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 399, "htmlBody": "<html><head></head><body><p>Most work on AI safety starts with a broad, vague problem (\u201cHow can we make an AI do good things?\u201d) and relatively quickly moves to a narrow, precise problem (e.g. \"What kind of reasoning process trusts itself?\u201c).</p>\n<p>Precision facilitates progress, and many serious thinkers are skeptical of imprecision. But in narrowing the problem too far we do most of the work (and have most of the opportunity for error).</p>\n<p>I am interested in more precise discussion of the big-picture problem of AI control. Such discussion could improve our understanding of AI control, help us choose the right narrow questions, and be a better starting point for engaging other researchers. To that end, consider the following problem:</p>\n<p><em>The steering problem</em>: Using black-box access to human-level cognitive abilities, can we write a program that is as useful as a well-motivated human with those abilities?</p>\n<p>I recently wrote <a href=\"https://docs.google.com/document/d/1_ggFw8KbvW77Z3gCQUDyz3_IrR3pVyFZ2wkuBgMvoVU/edit?usp=sharing\">this document</a>, which defines this problem much more precisely (in section 2) and considers a few possible approaches (in section 4). As usual, I appreciate thoughts and criticism. I apologize for the proliferation of nomenclature, but I couldn\u2019t get by without a new name.</p>\n<hr>\n<p>I think the steering problem captures a large part of what most people think of as \u201cthe AI safety problem.\u201d It certainly does not capture the entire problem; in particular, we <a href=\"https://medium.com/@paulfchristiano/optimization-and-goals-ca524f745852\">might well</a> introduce undesired goal-directed behavior in the process of implementing human-level capabilities (either inadvertently or because it\u2019s the easiest way to produce human-level abilities).</p>\n<p>Since I\u2019ve started thinking more explicitly about the steering problem, I\u2019ve reduced my estimate of its difficulty. This leads me to be more optimistic about AI safety, but also to suspect that the steering problem is a smaller share of the whole problem than I\u2019d originally thought. It would be great to see a more precise statement of the rest of the problem (which would probably subsume the steering problem). I\u2019m afraid that the rest of the problem is more closely tied to the particular techniques used to produce AI, so that we probably can't state it precisely without making some additional assumptions.</p>\n<p>I have recently been thinking about the situation for deep learning: under the (very improbable) assumption that various deep learning architectures could yield human-level AI, could they also yield a system with human-level usefulness? I\u2019m optimistic that we can find at least one natural assumption for which the answer is \u201cyes,\u201d which I would consider significant further progress.</p>\n</body></html>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5bd75cc58225bf0670374eb8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 5e-06, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": true, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-29T11:10:37.187Z", "modifiedAt": null, "url": null, "title": "Open thread, Dec. 29, 2014 - Jan 04, 2015", "slug": "open-thread-dec-29-2014-jan-04-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:36.829Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MrMind", "createdAt": "2011-04-19T08:43:22.388Z", "isAdmin": false, "displayName": "MrMind"}, "userId": "LJ4br8GWFXetsXkM8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hDjZdHaYYNdaPgXB9/open-thread-dec-29-2014-jan-04-2015", "pageUrlRelative": "/posts/hDjZdHaYYNdaPgXB9/open-thread-dec-29-2014-jan-04-2015", "linkUrl": "https://www.lesswrong.com/posts/hDjZdHaYYNdaPgXB9/open-thread-dec-29-2014-jan-04-2015", "postedAtFormatted": "Monday, December 29th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20Dec.%2029%2C%202014%20-%20Jan%2004%2C%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20Dec.%2029%2C%202014%20-%20Jan%2004%2C%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDjZdHaYYNdaPgXB9%2Fopen-thread-dec-29-2014-jan-04-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20Dec.%2029%2C%202014%20-%20Jan%2004%2C%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDjZdHaYYNdaPgXB9%2Fopen-thread-dec-29-2014-jan-04-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDjZdHaYYNdaPgXB9%2Fopen-thread-dec-29-2014-jan-04-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 64, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px; font-weight: bold;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/new/\" target=\"_blank\">list-of-threads page</a>&nbsp;before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">3.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should be posted in Discussion, and not Main.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">4.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hDjZdHaYYNdaPgXB9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 2.3161817248442904e-06, "legacy": true, "legacyId": "27797", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 165, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-29T12:56:24.585Z", "modifiedAt": null, "url": null, "title": "The Rubber Hand Illusion and Preaching to the Unconverted", "slug": "the-rubber-hand-illusion-and-preaching-to-the-unconverted", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:02.602Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gram_Stone", "createdAt": "2017-06-17T00:56:24.434Z", "isAdmin": false, "displayName": "Gram_Stone"}, "userId": "Mn5f8YLXbYaWRHyyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/okTZBDTnYYYs5ha93/the-rubber-hand-illusion-and-preaching-to-the-unconverted", "pageUrlRelative": "/posts/okTZBDTnYYYs5ha93/the-rubber-hand-illusion-and-preaching-to-the-unconverted", "linkUrl": "https://www.lesswrong.com/posts/okTZBDTnYYYs5ha93/the-rubber-hand-illusion-and-preaching-to-the-unconverted", "postedAtFormatted": "Monday, December 29th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Rubber%20Hand%20Illusion%20and%20Preaching%20to%20the%20Unconverted&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Rubber%20Hand%20Illusion%20and%20Preaching%20to%20the%20Unconverted%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FokTZBDTnYYYs5ha93%2Fthe-rubber-hand-illusion-and-preaching-to-the-unconverted%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Rubber%20Hand%20Illusion%20and%20Preaching%20to%20the%20Unconverted%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FokTZBDTnYYYs5ha93%2Fthe-rubber-hand-illusion-and-preaching-to-the-unconverted", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FokTZBDTnYYYs5ha93%2Fthe-rubber-hand-illusion-and-preaching-to-the-unconverted", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 766, "htmlBody": "<p style=\"margin-bottom: 0cm\">It seems that the CFAR workshops so far have been dedicated to people who have preconceptions pretty close in ideaspace to the sorts of ideas proposed on LW and by the institutions related to it. This is not a criticism; it's easier to start out this way: as has been said, in a different context and perhaps not in so many words, we should focus on precision before tractability. We're not going to learn a thing about the effectiveness of rationality training from people who won't even listen to what we have to say. Nevertheless, there will come a day when these efforts must be expanded to people who don't already view us as high in social status, so we still have to solve the problem of people being more concerned with both our and their social status than with listening to what we have to say. I propose that the solution is to divorce the consideration of social status from the argument.</p>\n<p style=\"margin-bottom: 0cm\">&nbsp;</p>\n<p style=\"margin-bottom: 0cm\">There is a lot of talk of cognitive biases on LW, and for good reason, but ultimately what we are trying to teach people is that they are prone to misinterpreting reality, and cognitive biases are only one component of this. One of the problems with trying to teach people about biases is that people feel personally responsible for being biased; many people have a conception of thinking as an 'active' process, so they feel as though it reflects upon their character. On the other hand, many people conceive of perception as a 'passive' process; no one feels personally responsible for what they perceive. So, I propose that we circumvent this fear of character assassination by demonstrating how people can misinterpret reality through perception<em>. </em>Enter: the rubber hand illusion.</p>\n<p style=\"margin-bottom: 0cm\">&nbsp;</p>\n<p style=\"margin-bottom: 0cm\"><span lang=\"en\">In case you're unfamiliar with this illusion, to demonstrate the rubber hand illusion, a subject sits at a table, a rubber hand is placed in front of them, oriented relative to their body as a natural hand would be, and a partition is placed between the rubber hand and their 'real' hand such that they are unable to see the 'real' hand. Then, the experimenter simultaneously 'stimulates' both hands at random intervals (usually by stroking each hand with a paintbrush). Then, the experimenter overextends the tips of a finger on each hand, the rubber hand about 90 degrees, and the 'real' hand about 20 degrees (it's not really overextension, and it wouldn't cause pain outside of the experiment's conditions). Measurements of skin conductance response indicate that subjects anticipate pain when this is done, and a very small selection of subjects even report </span><span lang=\"en\"><em>actually</em></span><span lang=\"en\"> </span><span lang=\"en\"><em>experiencing pain. </em></span><span lang=\"en\">Also, (just for kicks) when subjects are questioned about the degree to which they believe their 'real' finger was bent, they overestimate, by an average of about 20 degrees.</span></p>\n<p style=\"margin-bottom: 0cm\"><span lang=\"en\"><br /></span></p>\n<p style=\"margin-bottom: 0cm\">As&nbsp;<a title=\"Dr. Vilayanur Ramachandran\" href=\"http://en.wikipedia.org/wiki/Vilayanur_S._Ramachandran\">Dr. </a><span lang=\"en\"><a title=\"Dr. Vilayanur Ramachandran\" href=\"http://en.wikipedia.org/wiki/Vilayanur_S._Ramachandran\">Vilayanur Ramachandran</a> has demonstrated, the rubber hand illusion isn't the most general example of this sort of illusion: <a title=\"the mind can even interpret the surface of a table as a part of the human body\" href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1691405/pdf/12965016.pdf\">the human mind can even anticipate pain from injury to the surface of a table</a>. In fact, there is evidence that the human mind's evaluation of what is and is not part of its body isn't even dependent upon distance: Dr. Ramachandran has also demonstrated this with rubber hands attached to unnaturally long rubber arms.</span></p>\n<p style=\"margin-bottom: 0cm\"><span lang=\"en\"><br /></span></p>\n<p style=\"margin-bottom: 0cm\">I think that there are also three beneficial side effects to this exercise. (1) We are trying to convince people that Bayesian inference is a useful way to form beliefs, and this illusion demonstrates that every human mind already unconsciously uses Bayesian inference all of the time (namely, to infer what is and isn't its body). To further demonstrate the part about Bayesian inference, I would suggest that subjects also subsequently be shown how the illusion does not occur when the rubber hand is perpendicular to the 'real' hand or when the 'stimulations' aren't simultaneous.<span lang=\"en\">&nbsp;</span>(2) After the fact, the demonstration grants social status to the demonstrator in the eyes of the subject: \"This person showed me something that I consider extremely significant and that I didn't know about, therefore, they must be important.\" (3)&nbsp;I<span lang=\"en\">nconsistencies in perception instill feelings of self-doubt and incredulity, which makes it easier to change one's mind.</span></p>\n<p style=\"margin-bottom: 0cm\">&nbsp;</p>\n<p style=\"margin-bottom: 0cm\"><span lang=\"en\"><em>Addendum: This post has been substantially edited, both for brevity and on the basis of mistakes mentioned in the comments, such that some of the comments now appear nonsensical. Here is a draft that I found on my desktop which as far as I can tell is identical to the original post: http://pastebin.com/BL81VQVp</em></span></p>\n<p style=\"margin-bottom: 0cm\"><span lang=\"en\"><em><br /></em></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "okTZBDTnYYYs5ha93", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 21, "extendedScore": null, "score": 8.1e-05, "legacy": true, "legacyId": "27796", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-29T23:00:32.724Z", "modifiedAt": null, "url": null, "title": "Interesting (or semi-interesting) part time jobs? ", "slug": "interesting-or-semi-interesting-part-time-jobs", "viewCount": null, "lastCommentedAt": "2015-01-11T00:15:08.732Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Capla", "createdAt": "2014-08-13T03:07:43.569Z", "isAdmin": false, "displayName": "Capla"}, "userId": "KSqXxC5yBv52Aaj4Z", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2GR9pC7RbW8YNf47M/interesting-or-semi-interesting-part-time-jobs", "pageUrlRelative": "/posts/2GR9pC7RbW8YNf47M/interesting-or-semi-interesting-part-time-jobs", "linkUrl": "https://www.lesswrong.com/posts/2GR9pC7RbW8YNf47M/interesting-or-semi-interesting-part-time-jobs", "postedAtFormatted": "Monday, December 29th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Interesting%20(or%20semi-interesting)%20part%20time%20jobs%3F%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInteresting%20(or%20semi-interesting)%20part%20time%20jobs%3F%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2GR9pC7RbW8YNf47M%2Finteresting-or-semi-interesting-part-time-jobs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Interesting%20(or%20semi-interesting)%20part%20time%20jobs%3F%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2GR9pC7RbW8YNf47M%2Finteresting-or-semi-interesting-part-time-jobs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2GR9pC7RbW8YNf47M%2Finteresting-or-semi-interesting-part-time-jobs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 284, "htmlBody": "<p>&nbsp;I'm currently taking time off from school to focus on my eduction. I'm reading (a lot), mastering some skills, and finishing some projects.</p>\n<p>It takes money to live, so I need money. I was considering what my options were for jobs that would keep me engaged, and I thought I'd ask LessWrong.</p>\n<p>Constraints:&nbsp;</p>\n<p>1. I don't yet have a bachelor's degree. I am however, an intelligent and courteous student at a prestigious university, who doesn't drink smoke or do drugs.</p>\n<p>2. I need at least $800/month (500 for rent, internet, and bus fares; 150 for food; 150 for savings).</p>\n<p>3. I'm looking for less than 16 hours a week, or the taking time off to focus on learning becomes sort of mute. However, that is on average; it is feasible for me to work many hours one week and than little to none the next.&nbsp;</p>\n<p>Optimization criteria:</p>\n<p>1. Something interesting, especially something where I would learn something new. This may come in all kinds of forms (for instance, puts me in close contact with the sorts of people I wouldn't usually talk to), including some that I haven't thought of yet. It may even be a new approach to a generic job that makes it challenging or engaging. Jobs that will let me just sit and read without distraction, or even just listen to audio books while I work, would be great.</p>\n<p>2. The fewer hours I have to work, the better.&nbsp;</p>\n<p>I'm currently running experiments (mostly surveys) for a decision research lab. The work itself a little boring, but I do get to spend some of my time around marketing Ph.d students who are interested in behavioral economics and I get paid&nbsp; $12/hour. It works, but I'm open to other options.</p>\n<p>Any ideas?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2GR9pC7RbW8YNf47M", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 2.31783087687917e-06, "legacy": true, "legacyId": "27799", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2014-12-29T23:00:32.724Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-29T23:29:31.758Z", "modifiedAt": null, "url": null, "title": "How is the world different if I make a donation?", "slug": "how-is-the-world-different-if-i-make-a-donation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:08.485Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "banx", "createdAt": "2013-08-12T01:11:04.132Z", "isAdmin": false, "displayName": "banx"}, "userId": "d83Yun4EwNJfuXsvK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CEYzRRtocvfx4CoyG/how-is-the-world-different-if-i-make-a-donation", "pageUrlRelative": "/posts/CEYzRRtocvfx4CoyG/how-is-the-world-different-if-i-make-a-donation", "linkUrl": "https://www.lesswrong.com/posts/CEYzRRtocvfx4CoyG/how-is-the-world-different-if-i-make-a-donation", "postedAtFormatted": "Monday, December 29th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20is%20the%20world%20different%20if%20I%20make%20a%20donation%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20is%20the%20world%20different%20if%20I%20make%20a%20donation%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCEYzRRtocvfx4CoyG%2Fhow-is-the-world-different-if-i-make-a-donation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20is%20the%20world%20different%20if%20I%20make%20a%20donation%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCEYzRRtocvfx4CoyG%2Fhow-is-the-world-different-if-i-make-a-donation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCEYzRRtocvfx4CoyG%2Fhow-is-the-world-different-if-i-make-a-donation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1092, "htmlBody": "<p>How is the world different if I give X dollars to the Against Malaria Foundation, where X &lt; 100,000 USD? (In reality, giving directly to GiveWell is probably the better choice. But using AMF works well for this question.)</p>\n<p>Here's the answer that would make me very motivated to give:</p>\n<p>If I don't give, AMF will purchase and cause to be distributed N bed nets in the next 5 years. If I do give, AMF will purchase and cause to be distributed N+K bed nets in the next 5 years, where K is roughly X / (cost of a bed net, taking into account administrative costs, etc).</p>\n<p>In reality, I think the answer is more like:</p>\n<p>If I give, AMF will have X more dollars in its bank account than if I don't give. It will make decisions on whether or not to move forward with various large net distribution projects based on the amount of money it has available at the time of each decision. For each decision there will be some amount Z such that AMF will choose to go forward with the project if and only if it has at least Z dollars in the bank, holding all other factors equal. (Even if they claim there's such a cut-off point Y, but would still go forward with the project if they had slightly less than Y, there's an actual amount Z that is the real cut-off point.)</p>\n<p>I can think of two kinds of these distribution decisions, which interact differently with this extra money. First, if AMF is presented a unique, time-sensitive distribution opportunity, the extra money slightly increases the chance that they have enough to move forward with the distribution. Second, suppose there are recurring opportunities that are mostly the same. Assuming that AMF has a steady income of donations, there is a small chance this money will cause AMF to have enough money to fund the K-1th distribution instead of the Kth distribution, thereby getting bed nets out to people who need them sooner. This one-time time advantage would not \"use up\" the extra money. Assuming the K-1th distribution occurred but the Kth did not, at the time of the K+1th, AMF would still have X more dollars than if I hadn't given. So the chance of the time-advantage happening again (and the chance of a unique opportunity being funded) still exists.</p>\n<p>I'm fairly confused about the above, and haven't succeeded in rigorously defining a satisfying model from which I can compute the expected utility of a donation. My intuition is that the expected value of a donation should work out to the good done by the number of nets that can be purchased and distributed with that amount of money, but I can't justify it. What is important is that I don't think you can just say that AMF will eventually spend that money on nets in that way, and so that is the good done by the donation. It seems that that argument only works if AMF eventually spends all of its money on distributing nets and then ceases to exist. While this is an ideal end to AMF -- that they've solved the problem they were created to solve -- it doesn't seem like it's definitely going to happen. Even if it did, it's very possible that by the time they are spending their last dollars the marginal cost of saving lives will have gone up significantly compared to what it is today (either because the cost of purchase and distribution has increased or, probably more likely, because the strongest opportunities for doing good with bed nets are no longer available).</p>\n<p>In the past, I was very motivated to give because I had the impression that for every five-ish dollars I gave to AMF, an extra bed net would be distributed. It seems that this isn't correct, and this year I'm not nearly as motivated. I will likely be mailing a check to GiveWell tomorrow anyway (I have an employer match that expires at the end of the year), but I would like to have a better understanding of what I'm doing and if it makes sense. I have a sense that I'm not really accomplishing anything, and could spend my money better by giving to a small organization that spends money much less efficiently but would definitely get more done if it had the money, or, alternatively, by buying myself a car. I think this sense is confused, but the fact that I can't articulate exactly how makes it hard to dismiss. I think the ideas in this post more-or-less apply whether I'm considering a gift to AMF, GiveWell, or MIRI. AMF makes things easier to think about because they're mostly focused on only one thing.</p>\n<p>Along with any other feedback, I'd love some help with these questions:</p>\n<p>1. Does it make sense to be asking this question (How is the world in which I give different from the world in which I don't)? Is the answer to that question not important for some reason? Should I be satisfied with just doing my share in causing AMF to have the money it needs?</p>\n<p>2. Can the model of how an organization like AMF actually benefits from small amounts of marginal dollars be made more precise, to the point that I can roughly compute the expected utility (in terms of whatever) of a donation?</p>\n<p>3. Is it at all reasonable to prefer using my money on something that has a reasonably high likelihood of succeeding compared to something that has a very small chance of resulting in any desired outcome, when the thing with the tiny likelihood of success has (based on calculations using my assessments of utility) a higher expected utility? It feels really bad to throw tens of thousands of dollars at something, when I know that there's a very tiny chance that it will accomplish anything. This problem is a lot easier to deal with when I expect to iterate enough times that I expect to eventually hit the low-chance outcome. But when I don't expect to iterate nearly enough times for that to happen, it's hard to feel good about the choice. I think the answer may be that the community of givers iterates sufficiently many times that the low-chance outcomes are hit. What if that weren't true? Does it matter? I've asked a similar question in an open thread once, and I got some helpful answers. I think I need to work on truly accepting and internalizing that tiny probabilities of really good things are worth caring about.</p>\n<p>Thanks for reading.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CEYzRRtocvfx4CoyG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 2.3178982503748422e-06, "legacy": true, "legacyId": "27800", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-30T02:00:09.775Z", "modifiedAt": null, "url": null, "title": "Superintelligence 16: Tool AIs", "slug": "superintelligence-16-tool-ais", "viewCount": null, "lastCommentedAt": "2020-08-18T02:06:28.027Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sL8hCYecDwcrRhfCT/superintelligence-16-tool-ais", "pageUrlRelative": "/posts/sL8hCYecDwcrRhfCT/superintelligence-16-tool-ais", "linkUrl": "https://www.lesswrong.com/posts/sL8hCYecDwcrRhfCT/superintelligence-16-tool-ais", "postedAtFormatted": "Tuesday, December 30th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligence%2016%3A%20Tool%20AIs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligence%2016%3A%20Tool%20AIs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsL8hCYecDwcrRhfCT%2Fsuperintelligence-16-tool-ais%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligence%2016%3A%20Tool%20AIs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsL8hCYecDwcrRhfCT%2Fsuperintelligence-16-tool-ais", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsL8hCYecDwcrRhfCT%2Fsuperintelligence-16-tool-ais", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1999, "htmlBody": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr />\n<p>Welcome. This week we discuss the sixteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Tool AIs</strong></em>. This corresponds to the last parts of Chapter Ten.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: : &ldquo;Tool-AIs&rdquo; and &ldquo;Comparison&rdquo; from Chapter 10&nbsp;</p>\n<hr />\n<h1>Summary</h1>\n<ol>\n<li><strong><em>Tool AI:</em></strong>&nbsp;an AI that is not 'like an agent', but more like an excellent version of contemporary software. Most notably perhaps, it is not goal-directed (p151)</li>\n<li>Contemporary software may be safe because it has low capability rather than because it reliably does what you want, suggesting <strong>a very smart version of contemporary software would be dangerous </strong>(p151)</li>\n<li>Humans often want to figure out how to do a thing that they don't already know how to do. Narrow AI is already used to search for solutions. <strong>Automating this search seems to mean giving the machine a goal </strong>(that of finding a great way to make paperclips, for instance). That is, just carrying out a powerful search seems to have many of the problems of AI. (p152)</li>\n<li><strong>A machine intended to be a tool may cause similar problems to a machine intended to be an agent</strong>, by searching to produce plans that are perverse instantiations, infrastructure profusions or mind crimes. It may either carry them out itself or give the plan to a human to carry out. (p153)</li>\n<li><strong>A machine intended to be a tool may have agent-like parts</strong>. This could happen if its internal processes need to be optimized, and so it contains strong search processes for doing this. (p153)</li>\n<li>If tools are likely to accidentally be agent-like, <strong>it would probably be better to just build agents on purpose</strong> and have more intentional control over the design. (p155)</li>\n<li>Which castes of AI are safest is unclear and depends on circumstances. (p158)&nbsp;</li>\n</ol>\n<h1>Another view</h1>\n<p>Holden prompted discussion of the Tool AI in 2012, in one of several <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/\">Thoughts on the Singularity Institute</a>:</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">...Google Maps is a type of artificial intelligence (AI). It is far more intelligent than I am when it comes to planning routes.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Google Maps - by which I mean the complete software package including the display of the map itself - does not have a \"utility\" that it seeks to maximize. (One could fit a utility function to its actions, as to any set of actions, but there is no single \"parameter to be maximized\" driving its operations.)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Google Maps (as I understand it) considers multiple possible routes, gives each a score based on factors such as distance and likely traffic, and then displays the best-scoring route in a way that makes it easily understood by the user. If I don't like the route, for whatever reason, I can change some parameters and consider a different route. If I like the route, I can print it out or email it to a friend or send it to my phone's navigation application. Google Maps has no single parameter it is trying to maximize; it has no reason to try to \"trick\" me in order to increase its utility.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">In short, Google Maps is not an&nbsp;<em>agent</em>, taking actions in order to maximize a utility parameter. It is a&nbsp;<em>tool</em>, generating information and then displaying it in a user-friendly manner for me to consider, use and export or discard as I wish.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Every software application I know of seems to work essentially the same way, including those that involve (specialized) artificial intelligence such as Google Search, Siri, Watson, Rybka, etc. Some can be put into an \"agent mode\" (as Watson was on Jeopardy!) but all can easily be set up to be used as \"tools\" (for example, Watson can simply display its top candidate answers to a question, with the score for each, without speaking any of them.)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">The \"tool mode\" concept is importantly different from the possibility of&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://www.aleph.se/papers/oracleAI.pdf\">Oracle AI</a>&nbsp;sometimes discussed by SI. The discussions I've seen of Oracle AI present it as an Unfriendly AI that is \"trapped in a box\" - an AI whose intelligence is driven by an explicit utility function and that humans hope to control coercively. Hence the discussion of ideas such as the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://yudkowsky.net/singularity/aibox\">AI-Box Experiment</a>. A different interpretation, given in&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://groups.yahoo.com/group/givewell/message/287\">Karnofsky/Tallinn 2011</a>, is an AI with a carefully designed utility function - likely as difficult to construct as \"Friendliness\" - that leaves it \"wishing\" to answer questions helpfully. By contrast with both these ideas, Tool-AGI is not \"trapped\" and it is not Unfriendly or Friendly; it has no motivations and no driving utility function of any kind, just like Google Maps. It scores different possibilities and displays its conclusions in a transparent and user-friendly manner, as its instructions say to do; it does not have an overarching \"want,\" and so, as with the specialized AIs described above, while it may sometimes \"misinterpret\" a question (thereby scoring options poorly and ranking the wrong one #1) there is no reason to expect intentional trickery or manipulation when it comes to displaying its results.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Another way of putting this is that a \"tool\" has an underlying instruction set that conceptually looks like: \"(1) Calculate which action A would maximize parameter P, based on existing data set D. (2) Summarize this calculation in a user-friendly manner, including what Action A is, what likely intermediate outcomes it would cause, what other actions would result in high values of P, etc.\" An \"agent,\" by contrast, has an underlying instruction set that conceptually looks like: \"(1) Calculate which action, A, would maximize parameter P, based on existing data set D. (2) Execute Action A.\" In any AI where (1) is separable (by the programmers) as a distinct step, (2) can be set to the \"tool\" version rather than the \"agent\" version, and this separability is in fact present with most/all modern software. Note that in the \"tool\" version, neither step (1) nor step (2) (nor the combination) constitutes an instruction to maximize a parameter - to describe a program of this kind as \"wanting\" something is a category error, and there is no reason to expect its step (2) to be deceptive.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">I elaborated further on the distinction and on the concept of a tool-AI in&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://groups.yahoo.com/group/givewell/message/287\">Karnofsky/Tallinn 2011</a>.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">This is important because&nbsp;<strong>an AGI running in tool mode could be extraordinarily useful but far more safe than an AGI running in agent mode</strong>...</p>\n<p><span style=\"font-size: 2em;\">Notes</span></p>\n<p>1. While <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/\">Holden's post</a> was probably not the first to discuss this kind of AI, it prompted many responses. <a href=\"/lw/cze/reply_to_holden_on_tool_ai/\">Eliezer</a>&nbsp;basically&nbsp;said that non-catastrophic tool AI doesn't seem that easy to specify formally; that even if tool AI is best, agent-AI researchers are probably pretty useful to that problem; and that it's not so bad of MIRI to not discuss tool AI more, since there are a bunch of things other people think are similarly obviously in need of discussion.&nbsp;Luke basically <a href=\"/lw/di4/reply_to_holden_on_the_singularity_institute/\">agreed</a> with Eliezer.&nbsp;<a href=\"/lw/cfd/tools_versus_agents/\">Stuart</a>&nbsp;argues that having a tool clearly communicate possibilities is a hard problem, and talks about some other problems. Commenters say many things, including&nbsp;<a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/6jyi\">that</a> only one AI needs to be agent-like to have a problem, and <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/6kwn\">that</a> it's not clear what it means for a powerful optimizer to not have goals.</p>\n<p>2. A problem often brought up with powerful AIs is that when tasked with communicating, they will try to deceive you into liking plans that will fulfil their goals. It seems to me that you can avoid such deception problems by using a tool which searches for a plan you could do that would produce a lot of paperclips, rather than a tool that searches for a string that it could say to you that would produce a lot of paperclips. A plan that produces many paperclips but sounds so bad that you won't do it still does better than a persuasive lower-paperclip plan on the proposed metric. There is still a danger that you just won't notice the perverse way in which the instructions suggested to you will be instantiated, but at least the plan won't be designed to hide it.</p>\n<p>3. Note that in computer science, an '<a href=\"http://en.wikipedia.org/wiki/Agent_architecture\">agent</a>' means something other than 'a machine with a goal', though it seems they haven't settled on exactly what [<a href=\"http://www.csee.umbc.edu/~finin/papers/atal.pdf\">some</a> <a href=\"http://coltech.vnu.edu.vn/httt/media/courses/AI++/Tai%20lieu/TLTK.pdf\">example</a>&nbsp;<a href=\"https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CB4QFjAA&amp;url=http%3A%2F%2Fhrcak.srce.hr%2Ffile%2F32862&amp;ei=yv2hVJjCD4KxogS93IDgCw&amp;usg=AFQjCNHoHK-nUE3WkhsvqLUf1RCO4u7lXg&amp;sig2=z7Iuc6LYgtnvHAMp6cLnmg&amp;bvm=bv.82001339,d.cGU&amp;cad=rja\">efforts (pdf)</a>].</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9p_0.png?v=baa1b695919a07f9b9751117d9264ba6\" alt=\"\" width=\"480\" height=\"354\" /></p>\n<p>Figure: A '<a href=\"http://en.wikipedia.org/wiki/Multi-agent_system\">simple reflex agent</a>' is not goal directed (but kind of looks goal-directed: <a href=\"https://www.youtube.com/watch?v=fS1Ad6b1caY\">one in action</a>)</p>\n<p>4. Bostrom seems to assume that a powerful tool would be a search process. This is related to the idea that intelligence is an '<a href=\"http://wiki.lesswrong.com/wiki/Optimization_process\">optimization process</a>'. But this is more of a definition than an empirical relationship between the kinds of technology we are thinking of as intelligent and the kinds of processes we think of as 'searching'. Could there be things that merely contribute massively to the intelligence of a human - such that we would think of them as very intelligent tools - that naturally forward whatever goals the human has?</p>\n<p>One can imagine a tool that is told what you are planning to do, and tries to describe the major consequences of it. This is a search or optimization process in the sense that it outputs something improbably apt from a large space of possible outputs, but that quality alone seems not enough to make something dangerous. For one thing, the machine is not selecting outputs for their effect on the world, but rather for their accuracy as descriptions. For another, the process being run may not be an actual 'search' in the sense of checking lots of things and finding one that does well on some criteria. It could for instance perform a complicated transformation on the incoming data and spit out the result.&nbsp;</p>\n<p>5. One obvious problem with tools is that they maintain humans as a component in all goal-directed behavior. If humans are some combination of slow and rare compared to artificial intelligence, there may be strong pressure to automate all aspects of decisionmaking, i.e. use agents.</p>\n<h1>In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<p>&nbsp;</p>\n<ol>\n<li>Would powerful tools necessarily become goal-directed agents in the troubling sense?</li>\n<li>Are different types of entity generally likely to become optimizers, if they are not? If so, which ones? Under what dynamics? Are tool-ish or Oracle-ish things stable attractors in this way?</li>\n<li>Can we specify communication behavior in a way that doesn't rely on having goals about the interlocutor's internal state or behavior?</li>\n<li>If you assume (perhaps impossibly) strong versions of some narrow-AI capabilities, can you design a safe tool which uses them? e.g. If you had a near perfect predictor, can you design a safe super-Google Maps?</li>\n</ol>\n<p>&nbsp;</p>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1>How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about multipolar scenarios - i.e. situations where a single AI doesn't take over the world. To prepare,&nbsp;<strong>read</strong>&nbsp;&ldquo;Of horses and men&rdquo; from Chapter 11<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 5 January. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1, "LXk7bxNkYSjgatdAt": 1, "tdt83ChxnEgwwKxi6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sL8hCYecDwcrRhfCT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 2.3182484563665e-06, "legacy": true, "legacyId": "27565", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr>\n<p>Welcome. This week we discuss the sixteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Tool AIs</strong></em>. This corresponds to the last parts of Chapter Ten.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: : \u201cTool-AIs\u201d and \u201cComparison\u201d from Chapter 10&nbsp;</p>\n<hr>\n<h1 id=\"Summary\">Summary</h1>\n<ol>\n<li><strong><em>Tool AI:</em></strong>&nbsp;an AI that is not 'like an agent', but more like an excellent version of contemporary software. Most notably perhaps, it is not goal-directed (p151)</li>\n<li>Contemporary software may be safe because it has low capability rather than because it reliably does what you want, suggesting <strong>a very smart version of contemporary software would be dangerous </strong>(p151)</li>\n<li>Humans often want to figure out how to do a thing that they don't already know how to do. Narrow AI is already used to search for solutions. <strong>Automating this search seems to mean giving the machine a goal </strong>(that of finding a great way to make paperclips, for instance). That is, just carrying out a powerful search seems to have many of the problems of AI. (p152)</li>\n<li><strong>A machine intended to be a tool may cause similar problems to a machine intended to be an agent</strong>, by searching to produce plans that are perverse instantiations, infrastructure profusions or mind crimes. It may either carry them out itself or give the plan to a human to carry out. (p153)</li>\n<li><strong>A machine intended to be a tool may have agent-like parts</strong>. This could happen if its internal processes need to be optimized, and so it contains strong search processes for doing this. (p153)</li>\n<li>If tools are likely to accidentally be agent-like, <strong>it would probably be better to just build agents on purpose</strong> and have more intentional control over the design. (p155)</li>\n<li>Which castes of AI are safest is unclear and depends on circumstances. (p158)&nbsp;</li>\n</ol>\n<h1 id=\"Another_view\">Another view</h1>\n<p>Holden prompted discussion of the Tool AI in 2012, in one of several <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/\">Thoughts on the Singularity Institute</a>:</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">...Google Maps is a type of artificial intelligence (AI). It is far more intelligent than I am when it comes to planning routes.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Google Maps - by which I mean the complete software package including the display of the map itself - does not have a \"utility\" that it seeks to maximize. (One could fit a utility function to its actions, as to any set of actions, but there is no single \"parameter to be maximized\" driving its operations.)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Google Maps (as I understand it) considers multiple possible routes, gives each a score based on factors such as distance and likely traffic, and then displays the best-scoring route in a way that makes it easily understood by the user. If I don't like the route, for whatever reason, I can change some parameters and consider a different route. If I like the route, I can print it out or email it to a friend or send it to my phone's navigation application. Google Maps has no single parameter it is trying to maximize; it has no reason to try to \"trick\" me in order to increase its utility.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">In short, Google Maps is not an&nbsp;<em>agent</em>, taking actions in order to maximize a utility parameter. It is a&nbsp;<em>tool</em>, generating information and then displaying it in a user-friendly manner for me to consider, use and export or discard as I wish.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Every software application I know of seems to work essentially the same way, including those that involve (specialized) artificial intelligence such as Google Search, Siri, Watson, Rybka, etc. Some can be put into an \"agent mode\" (as Watson was on Jeopardy!) but all can easily be set up to be used as \"tools\" (for example, Watson can simply display its top candidate answers to a question, with the score for each, without speaking any of them.)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">The \"tool mode\" concept is importantly different from the possibility of&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://www.aleph.se/papers/oracleAI.pdf\">Oracle AI</a>&nbsp;sometimes discussed by SI. The discussions I've seen of Oracle AI present it as an Unfriendly AI that is \"trapped in a box\" - an AI whose intelligence is driven by an explicit utility function and that humans hope to control coercively. Hence the discussion of ideas such as the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://yudkowsky.net/singularity/aibox\">AI-Box Experiment</a>. A different interpretation, given in&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://groups.yahoo.com/group/givewell/message/287\">Karnofsky/Tallinn 2011</a>, is an AI with a carefully designed utility function - likely as difficult to construct as \"Friendliness\" - that leaves it \"wishing\" to answer questions helpfully. By contrast with both these ideas, Tool-AGI is not \"trapped\" and it is not Unfriendly or Friendly; it has no motivations and no driving utility function of any kind, just like Google Maps. It scores different possibilities and displays its conclusions in a transparent and user-friendly manner, as its instructions say to do; it does not have an overarching \"want,\" and so, as with the specialized AIs described above, while it may sometimes \"misinterpret\" a question (thereby scoring options poorly and ranking the wrong one #1) there is no reason to expect intentional trickery or manipulation when it comes to displaying its results.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">Another way of putting this is that a \"tool\" has an underlying instruction set that conceptually looks like: \"(1) Calculate which action A would maximize parameter P, based on existing data set D. (2) Summarize this calculation in a user-friendly manner, including what Action A is, what likely intermediate outcomes it would cause, what other actions would result in high values of P, etc.\" An \"agent,\" by contrast, has an underlying instruction set that conceptually looks like: \"(1) Calculate which action, A, would maximize parameter P, based on existing data set D. (2) Execute Action A.\" In any AI where (1) is separable (by the programmers) as a distinct step, (2) can be set to the \"tool\" version rather than the \"agent\" version, and this separability is in fact present with most/all modern software. Note that in the \"tool\" version, neither step (1) nor step (2) (nor the combination) constitutes an instruction to maximize a parameter - to describe a program of this kind as \"wanting\" something is a category error, and there is no reason to expect its step (2) to be deceptive.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">I elaborated further on the distinction and on the concept of a tool-AI in&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://groups.yahoo.com/group/givewell/message/287\">Karnofsky/Tallinn 2011</a>.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; padding-left: 30px;\">This is important because&nbsp;<strong>an AGI running in tool mode could be extraordinarily useful but far more safe than an AGI running in agent mode</strong>...</p>\n<p><span style=\"font-size: 2em;\">Notes</span></p>\n<p>1. While <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/\">Holden's post</a> was probably not the first to discuss this kind of AI, it prompted many responses. <a href=\"/lw/cze/reply_to_holden_on_tool_ai/\">Eliezer</a>&nbsp;basically&nbsp;said that non-catastrophic tool AI doesn't seem that easy to specify formally; that even if tool AI is best, agent-AI researchers are probably pretty useful to that problem; and that it's not so bad of MIRI to not discuss tool AI more, since there are a bunch of things other people think are similarly obviously in need of discussion.&nbsp;Luke basically <a href=\"/lw/di4/reply_to_holden_on_the_singularity_institute/\">agreed</a> with Eliezer.&nbsp;<a href=\"/lw/cfd/tools_versus_agents/\">Stuart</a>&nbsp;argues that having a tool clearly communicate possibilities is a hard problem, and talks about some other problems. Commenters say many things, including&nbsp;<a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/6jyi\">that</a> only one AI needs to be agent-like to have a problem, and <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/6kwn\">that</a> it's not clear what it means for a powerful optimizer to not have goals.</p>\n<p>2. A problem often brought up with powerful AIs is that when tasked with communicating, they will try to deceive you into liking plans that will fulfil their goals. It seems to me that you can avoid such deception problems by using a tool which searches for a plan you could do that would produce a lot of paperclips, rather than a tool that searches for a string that it could say to you that would produce a lot of paperclips. A plan that produces many paperclips but sounds so bad that you won't do it still does better than a persuasive lower-paperclip plan on the proposed metric. There is still a danger that you just won't notice the perverse way in which the instructions suggested to you will be instantiated, but at least the plan won't be designed to hide it.</p>\n<p>3. Note that in computer science, an '<a href=\"http://en.wikipedia.org/wiki/Agent_architecture\">agent</a>' means something other than 'a machine with a goal', though it seems they haven't settled on exactly what [<a href=\"http://www.csee.umbc.edu/~finin/papers/atal.pdf\">some</a> <a href=\"http://coltech.vnu.edu.vn/httt/media/courses/AI++/Tai%20lieu/TLTK.pdf\">example</a>&nbsp;<a href=\"https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CB4QFjAA&amp;url=http%3A%2F%2Fhrcak.srce.hr%2Ffile%2F32862&amp;ei=yv2hVJjCD4KxogS93IDgCw&amp;usg=AFQjCNHoHK-nUE3WkhsvqLUf1RCO4u7lXg&amp;sig2=z7Iuc6LYgtnvHAMp6cLnmg&amp;bvm=bv.82001339,d.cGU&amp;cad=rja\">efforts (pdf)</a>].</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9p_0.png?v=baa1b695919a07f9b9751117d9264ba6\" alt=\"\" width=\"480\" height=\"354\"></p>\n<p>Figure: A '<a href=\"http://en.wikipedia.org/wiki/Multi-agent_system\">simple reflex agent</a>' is not goal directed (but kind of looks goal-directed: <a href=\"https://www.youtube.com/watch?v=fS1Ad6b1caY\">one in action</a>)</p>\n<p>4. Bostrom seems to assume that a powerful tool would be a search process. This is related to the idea that intelligence is an '<a href=\"http://wiki.lesswrong.com/wiki/Optimization_process\">optimization process</a>'. But this is more of a definition than an empirical relationship between the kinds of technology we are thinking of as intelligent and the kinds of processes we think of as 'searching'. Could there be things that merely contribute massively to the intelligence of a human - such that we would think of them as very intelligent tools - that naturally forward whatever goals the human has?</p>\n<p>One can imagine a tool that is told what you are planning to do, and tries to describe the major consequences of it. This is a search or optimization process in the sense that it outputs something improbably apt from a large space of possible outputs, but that quality alone seems not enough to make something dangerous. For one thing, the machine is not selecting outputs for their effect on the world, but rather for their accuracy as descriptions. For another, the process being run may not be an actual 'search' in the sense of checking lots of things and finding one that does well on some criteria. It could for instance perform a complicated transformation on the incoming data and spit out the result.&nbsp;</p>\n<p>5. One obvious problem with tools is that they maintain humans as a component in all goal-directed behavior. If humans are some combination of slow and rare compared to artificial intelligence, there may be strong pressure to automate all aspects of decisionmaking, i.e. use agents.</p>\n<h1 id=\"In_depth_investigations\">In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<p>&nbsp;</p>\n<ol>\n<li>Would powerful tools necessarily become goal-directed agents in the troubling sense?</li>\n<li>Are different types of entity generally likely to become optimizers, if they are not? If so, which ones? Under what dynamics? Are tool-ish or Oracle-ish things stable attractors in this way?</li>\n<li>Can we specify communication behavior in a way that doesn't rely on having goals about the interlocutor's internal state or behavior?</li>\n<li>If you assume (perhaps impossibly) strong versions of some narrow-AI capabilities, can you design a safe tool which uses them? e.g. If you had a near perfect predictor, can you design a safe super-Google Maps?</li>\n</ol>\n<p>&nbsp;</p>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1 id=\"How_to_proceed\">How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about multipolar scenarios - i.e. situations where a single AI doesn't take over the world. To prepare,&nbsp;<strong>read</strong>&nbsp;\u201cOf horses and men\u201d from Chapter 11<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 5 January. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "sections": [{"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Another view", "anchor": "Another_view", "level": 1}, {"title": "In-depth investigations", "anchor": "In_depth_investigations", "level": 1}, {"title": "How to proceed", "anchor": "How_to_proceed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "37 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QDmzDZ9CEHrKQdvcn", "6SGqkCgHuNr7d4yJm", "sizjfDgCgAsuLJQmm", "5GskScdvYXBpL78wL", "nAwTGhgrdxE85Bjmg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-30T06:37:35.402Z", "modifiedAt": null, "url": null, "title": "[LINK] Yudkowsky's Abridged Guide to Intelligent Characters", "slug": "link-yudkowsky-s-abridged-guide-to-intelligent-characters", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:02.075Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "katydee", "createdAt": "2010-07-09T10:33:52.237Z", "isAdmin": false, "displayName": "katydee"}, "userId": "uHpk5J2f7BPBoiJFX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NWZ8YABJb4KoJWncK/link-yudkowsky-s-abridged-guide-to-intelligent-characters", "pageUrlRelative": "/posts/NWZ8YABJb4KoJWncK/link-yudkowsky-s-abridged-guide-to-intelligent-characters", "linkUrl": "https://www.lesswrong.com/posts/NWZ8YABJb4KoJWncK/link-yudkowsky-s-abridged-guide-to-intelligent-characters", "postedAtFormatted": "Tuesday, December 30th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Yudkowsky's%20Abridged%20Guide%20to%20Intelligent%20Characters&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Yudkowsky's%20Abridged%20Guide%20to%20Intelligent%20Characters%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNWZ8YABJb4KoJWncK%2Flink-yudkowsky-s-abridged-guide-to-intelligent-characters%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Yudkowsky's%20Abridged%20Guide%20to%20Intelligent%20Characters%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNWZ8YABJb4KoJWncK%2Flink-yudkowsky-s-abridged-guide-to-intelligent-characters", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNWZ8YABJb4KoJWncK%2Flink-yudkowsky-s-abridged-guide-to-intelligent-characters", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 40, "htmlBody": "<p>Some of you have likely seen this already, but for those of you who haven't, Eliezer recently finished a series of Tumblr posts on writing intelligent characters in fiction. It can be found at&nbsp;http://yudkowsky.tumblr.com/writing and is IMO worth a read.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8SfkJYYMe75MwjHzN": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NWZ8YABJb4KoJWncK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 21, "extendedScore": null, "score": 9.1e-05, "legacy": true, "legacyId": "27801", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-30T14:47:18.875Z", "modifiedAt": null, "url": null, "title": "Meetup : January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching", "slug": "meetup-january-2015-rationality-dojo-how-to-learn-faster-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:02.488Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MelbourneLW", "createdAt": "2014-07-15T07:42:47.692Z", "isAdmin": false, "displayName": "MelbourneLW"}, "userId": "fnAEhR2GNN3t6PmFc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/suMhBWpPsDT4W2Df9/meetup-january-2015-rationality-dojo-how-to-learn-faster-and", "pageUrlRelative": "/posts/suMhBWpPsDT4W2Df9/meetup-january-2015-rationality-dojo-how-to-learn-faster-and", "linkUrl": "https://www.lesswrong.com/posts/suMhBWpPsDT4W2Df9/meetup-january-2015-rationality-dojo-how-to-learn-faster-and", "postedAtFormatted": "Tuesday, December 30th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20January%202015%20Rationality%20Dojo%20-%20How%20to%20learn%20faster%20and%20teach%20more%20effectively%20and%20teaching&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20January%202015%20Rationality%20Dojo%20-%20How%20to%20learn%20faster%20and%20teach%20more%20effectively%20and%20teaching%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsuMhBWpPsDT4W2Df9%2Fmeetup-january-2015-rationality-dojo-how-to-learn-faster-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20January%202015%20Rationality%20Dojo%20-%20How%20to%20learn%20faster%20and%20teach%20more%20effectively%20and%20teaching%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsuMhBWpPsDT4W2Df9%2Fmeetup-january-2015-rationality-dojo-how-to-learn-faster-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsuMhBWpPsDT4W2Df9%2Fmeetup-january-2015-rationality-dojo-how-to-learn-faster-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 396, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/189'>January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 January 2015 03:30:00PM (+0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Errol St park, between Errol St and Harcourt St in North Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Less Wrong Sunday Rationality Dojos are crafted to be serious\nself-improvement sessions for those committed to the Art of\nRationality and personal growth. Each month a community member will run a session involving a presentation of content, discussion, and\nexercises.</p>\n\n<p>Continuing the succession of immensely successful dojos, Stephanie\nwill run a session on powering up your training by both learning and\nteaching others. Stephanie brings insights from training animals and coaching humans to creating the habits and responses that we  desire in ourselves and others.</p>\n\n<p>For our first dojo of the year we'll have something outside! If the weather is poor we will move to Helen's place which is nearby.</p>\n\n<p>As always, we will review the personal goals we committed to at the\nprevious Dojo (I will have done X by the next Dojo). Our goals are now being recorded via Google Forms here -\n<a href=\"https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,\" rel=\"nofollow\">https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,</a>\nand Melbourne Less Wrong organisers have access to the form results if you wish to review the goals you set last month.</p>\n\n<p>This month, we are also seeking 2-3 lightning talks from members. Have you learned something cool? Gained an insight from one of the LessWrong sequences? Give a lightning talk and share it with Melbourne LW! Speakers will be limited to 5 minutes with room for questions. If you have something you would like to present a lightning talk on, please contact Louise with your topic at lvalmoria@gmail.com</p>\n\n<p>The Dojo is likely to run for 2-3 hours. After the dojo, we will then\nhave a low key gathering at Helen's place to give LW Melbourne a\nchance to get to know Alyssa Vance, a Google software engineer who is visiting from the Bay Area. Bring drinks or snacks, and we might order something to eat.</p>\n\n<p>If you have any trouble finding either the park or Helen's place, call\nLouise on 0419 192 367.</p>\n\n<p>If you would like to present at a future Dojo or suggest a topic,\nplease fill it in on the Rationality Dojo Roster:\n<a href=\"http://is.gd/dojoroster\" rel=\"nofollow\">http://is.gd/dojoroster</a></p>\n\n<p>To organise similar events, please send an email to melbournelw@gmail.com</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/189'>January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "suMhBWpPsDT4W2Df9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.3200334499713942e-06, "legacy": true, "legacyId": "27802", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___January_2015_Rationality_Dojo___How_to_learn_faster_and_teach_more_effectively_and_teaching\">Discussion article for the meetup : <a href=\"/meetups/189\">January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 January 2015 03:30:00PM (+0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Errol St park, between Errol St and Harcourt St in North Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Less Wrong Sunday Rationality Dojos are crafted to be serious\nself-improvement sessions for those committed to the Art of\nRationality and personal growth. Each month a community member will run a session involving a presentation of content, discussion, and\nexercises.</p>\n\n<p>Continuing the succession of immensely successful dojos, Stephanie\nwill run a session on powering up your training by both learning and\nteaching others. Stephanie brings insights from training animals and coaching humans to creating the habits and responses that we  desire in ourselves and others.</p>\n\n<p>For our first dojo of the year we'll have something outside! If the weather is poor we will move to Helen's place which is nearby.</p>\n\n<p>As always, we will review the personal goals we committed to at the\nprevious Dojo (I will have done X by the next Dojo). Our goals are now being recorded via Google Forms here -\n<a href=\"https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,\" rel=\"nofollow\">https://docs.google.com/forms/d/1MCHH4MpbW0SI_2JyMSDlKnnGP4A0qxojQEZoMZIdopk/viewform,</a>\nand Melbourne Less Wrong organisers have access to the form results if you wish to review the goals you set last month.</p>\n\n<p>This month, we are also seeking 2-3 lightning talks from members. Have you learned something cool? Gained an insight from one of the LessWrong sequences? Give a lightning talk and share it with Melbourne LW! Speakers will be limited to 5 minutes with room for questions. If you have something you would like to present a lightning talk on, please contact Louise with your topic at lvalmoria@gmail.com</p>\n\n<p>The Dojo is likely to run for 2-3 hours. After the dojo, we will then\nhave a low key gathering at Helen's place to give LW Melbourne a\nchance to get to know Alyssa Vance, a Google software engineer who is visiting from the Bay Area. Bring drinks or snacks, and we might order something to eat.</p>\n\n<p>If you have any trouble finding either the park or Helen's place, call\nLouise on 0419 192 367.</p>\n\n<p>If you would like to present at a future Dojo or suggest a topic,\nplease fill it in on the Rationality Dojo Roster:\n<a href=\"http://is.gd/dojoroster\" rel=\"nofollow\">http://is.gd/dojoroster</a></p>\n\n<p>To organise similar events, please send an email to melbournelw@gmail.com</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___January_2015_Rationality_Dojo___How_to_learn_faster_and_teach_more_effectively_and_teaching1\">Discussion article for the meetup : <a href=\"/meetups/189\">January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching</a></h2>", "sections": [{"title": "Discussion article for the meetup : January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching", "anchor": "Discussion_article_for_the_meetup___January_2015_Rationality_Dojo___How_to_learn_faster_and_teach_more_effectively_and_teaching", "level": 1}, {"title": "Discussion article for the meetup : January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching", "anchor": "Discussion_article_for_the_meetup___January_2015_Rationality_Dojo___How_to_learn_faster_and_teach_more_effectively_and_teaching1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-30T18:19:09.211Z", "modifiedAt": null, "url": null, "title": "Recent AI safety work", "slug": "recent-ai-safety-work", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:08.328Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BCeFcAGc5ayggJ3h5/recent-ai-safety-work", "pageUrlRelative": "/posts/BCeFcAGc5ayggJ3h5/recent-ai-safety-work", "linkUrl": "https://www.lesswrong.com/posts/BCeFcAGc5ayggJ3h5/recent-ai-safety-work", "postedAtFormatted": "Tuesday, December 30th 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recent%20AI%20safety%20work&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecent%20AI%20safety%20work%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBCeFcAGc5ayggJ3h5%2Frecent-ai-safety-work%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recent%20AI%20safety%20work%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBCeFcAGc5ayggJ3h5%2Frecent-ai-safety-work", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBCeFcAGc5ayggJ3h5%2Frecent-ai-safety-work", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 380, "htmlBody": "<p class=\"p1\" style=\"color: #222222; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 21.6363620758057px; margin-bottom: 0.825em; font-size: 14px;\">(Crossposted from <a href=\"http://ordinaryideas.wordpress.com/\">ordinary ideas</a>).&nbsp;</p>\n<p class=\"p1\" style=\"color: #222222; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 21.6363620758057px; margin-bottom: 0.825em; font-size: 14px;\">I&rsquo;ve recently been thinking about AI safety, and some of the writeups might be interesting to some LWers:</p>\n<ol style=\"color: #222222; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 21.6363620758057px; margin: 0px 0px 0.825em 2.5em; padding: 0px; font-size: 14px;\">\n<li class=\"p1\" style=\"font-style: inherit; font-weight: inherit; line-height: 1.7;\">Ideas for building useful agents without goals:&nbsp;<a style=\"color: #1b8be0; font-style: inherit; font-weight: inherit; line-height: 1.7; text-decoration: none;\" href=\"https://medium.com/@paulfchristiano/model-free-decisions-6e6609f5d99e\">approval-directed agents</a>,&nbsp;<a style=\"color: #1b8be0; font-style: inherit; font-weight: inherit; line-height: 1.7; text-decoration: none;\" href=\"https://medium.com/@paulfchristiano/approval-directed-bootstrapping-5d49e886c14f\">approval-directed bootstrapping</a>, and&nbsp;<a style=\"color: #1b8be0; font-style: inherit; font-weight: inherit; line-height: 1.7; text-decoration: none;\" href=\"https://medium.com/@paulfchristiano/optimization-and-goals-ca524f745852\">optimization and goals</a>. I think this line of reasoning is very&nbsp;promising.</li>\n<li class=\"p1\" style=\"font-style: inherit; font-weight: inherit; line-height: 1.7;\">A formalization of one piece of the AI safety challenge:&nbsp;<a style=\"color: #1b8be0; font-style: inherit; font-weight: inherit; line-height: 1.7; text-decoration: none;\" href=\"https://docs.google.com/document/d/1_ggFw8KbvW77Z3gCQUDyz3_IrR3pVyFZ2wkuBgMvoVU/edit?usp=sharing\">the steering problem</a>. I am eager to see more precise, high-level discussion of AI safety, and I think this&nbsp;article&nbsp;is a helpful step in that direction. Since articulating the steering problem I have become much more optimistic about versions of it being solved&nbsp;in the near term. This mostly means that the steering problem fails to capture the hardest parts of AI safety. But it&rsquo;s still good news, and I think it may eventually cause some people to revise their understanding of AI safety.</li>\n<li class=\"p1\" style=\"font-style: inherit; font-weight: inherit; line-height: 1.7;\">Some ideas&nbsp;for&nbsp;getting useful work out of self-interested agents, based on arguments:&nbsp;<a style=\"color: #1b8be0; font-style: inherit; font-weight: inherit; line-height: 1.7; text-decoration: none;\" href=\"https://medium.com/@paulfchristiano/of-arguments-and-wagers-ee16a0e84cf7\">of arguments and wagers</a>,&nbsp;<a style=\"color: #1b8be0; font-style: inherit; font-weight: inherit; line-height: 1.7; text-decoration: none;\" href=\"http://ordinaryideas.wordpress.com/2014/07/18/adversarial-collaboration/\">adversarial collaboration</a>&nbsp;[older], and&nbsp;<a style=\"color: #1b8be0; font-style: inherit; font-weight: inherit; line-height: 1.7; text-decoration: none;\" href=\"https://medium.com/@paulfchristiano/delegating-to-a-mixed-crowd-dda2b8e22cd8\">delegating to a mixed crowd</a>. I think these are interesting ideas in an interesting area, but they have a ways to go until they&nbsp;could be&nbsp;useful.</li>\n</ol>\n<p class=\"p1\" style=\"color: #222222; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 21.6363620758057px; margin-bottom: 0.825em; font-size: 14px;\">I&rsquo;m excited about a few&nbsp;possible next steps:</p>\n<ol style=\"color: #222222; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 21.6363620758057px; margin: 0px 0px 0.825em 2.5em; padding: 0px; font-size: 14px;\">\n<li class=\"p1\" style=\"font-style: inherit; font-weight: inherit; line-height: 1.7;\">Under the (highly improbable) assumption that various deep learning architectures could yield human-level performance, could they also predictably yield safe AI? I think we have a good chance of finding a solution---i.e. a design of plausibly safe&nbsp;AI, under roughly the same assumptions needed to&nbsp;get human-level AI---for some possible architectures. This would feel like a big step forward.</li>\n<li class=\"p1\" style=\"font-style: inherit; font-weight: inherit; line-height: 1.7;\">For what capabilities can we solve the steering problem? I had originally assumed none, but I am now interested in trying to apply&nbsp;the ideas from the approval-directed agents post. From easiest to hardest, I think there are natural lines of attack using any of: natural language question answering, precise question answering, sequence prediction. It might even be possible&nbsp;using&nbsp;reinforcement learners (though this would&nbsp;involve different techniques).</li>\n<li class=\"p1\" style=\"font-style: inherit; font-weight: inherit; line-height: 1.7;\">I am very interested in implementing effective debates, and am keen to test some unusual proposals. The connection to AI safety is more impressionistic, but in my mind these techniques are closely linked with approval-directed behavior.</li>\n<li class=\"p1\" style=\"font-style: inherit; font-weight: inherit; line-height: 1.7;\">I&rsquo;m currently writing up&nbsp;a concrete architecture for approval-directed agents, in order to facilitate clearer discussion about the idea. This&nbsp;kind of work&nbsp;that seems harder to do in advance, but at this point I think it&rsquo;s mostly an exposition problem.</li>\n</ol><ol style=\"color: #222222; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 21.6363620758057px; margin: 0px 0px 0.825em 2.5em; padding: 0px; font-size: 14px;\"> </ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BCeFcAGc5ayggJ3h5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 32, "extendedScore": null, "score": 2.320526781134837e-06, "legacy": true, "legacyId": "27803", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-31T00:37:28.765Z", "modifiedAt": null, "url": null, "title": "Dark Arts 101: Be rigorous, on average", "slug": "dark-arts-101-be-rigorous-on-average", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.764Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N4sGXcNue2jMET8uP/dark-arts-101-be-rigorous-on-average", "pageUrlRelative": "/posts/N4sGXcNue2jMET8uP/dark-arts-101-be-rigorous-on-average", "linkUrl": "https://www.lesswrong.com/posts/N4sGXcNue2jMET8uP/dark-arts-101-be-rigorous-on-average", "postedAtFormatted": "Wednesday, December 31st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dark%20Arts%20101%3A%20Be%20rigorous%2C%20on%20average&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADark%20Arts%20101%3A%20Be%20rigorous%2C%20on%20average%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN4sGXcNue2jMET8uP%2Fdark-arts-101-be-rigorous-on-average%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dark%20Arts%20101%3A%20Be%20rigorous%2C%20on%20average%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN4sGXcNue2jMET8uP%2Fdark-arts-101-be-rigorous-on-average", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN4sGXcNue2jMET8uP%2Fdark-arts-101-be-rigorous-on-average", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 824, "htmlBody": "<p>I'm reading George Steiner's 1989 book on literary theory, <em>Real Presences</em>. Steiner is a literary theorist who achieved the trifecta of having appointments at Oxford, Cambridge, and Harvard. His book demonstrates an important Dark Arts method of argument.</p>\n<p>So far, Steiner's argument appears to be:</p>\n<ol>\n<li>Human language is an undecidable symbol-system.</li>\n<li>Every sentence therefore carries with it an infinite amount of meaning, the accumulation of all connotations, contexts, and historical associations invoked, and invoked by those invocations, etc. Alternately, every sentence contains no meaning at all, since none of those words can refer to things in the world.</li>\n<li>The meaning of a sentence, therefore, is not finite or analyzable, but transcendent.</li>\n<li>The transcendent is the search for God.</li>\n<li>Therefore, all good literature is a search for God.</li>\n</ol>\n<p>The critics quoted on the back of the book, and its&nbsp;<a href=\"http://www.amazon.com/Real-Presences-George-Steiner/dp/0226772349#customerReviews\">reviews on Amazon</a>, praise Steiner's rigor and learning. It is impressive. Within a single paragraph he may show the relationship between Homer, 12th-century theological works, Racine, Shakespeare, and Schoenberg. And his care and precision with words is exemplary; I have the impression, even when he speaks of meaning in music or other qualia-laden subjects, that I know exactly what he means.</p>\n<p>He was intelligent enough to trace the problems he was grappling with out past the edges of his domain of expertise. The key points of his argument lie not in literary theory, but in information theory, physics, artificial intelligence, computability theory, linguistics, and transfinite math.</p>\n<p>Unfortunately, he knows almost nothing about any of those fields, and his language is precise enough to be wrong, which he is when he speaks on any of those subjects. How did he get away with it?</p>\n<p>Answer: He took a two-page argument about things he knew little about, spread it across 200 pages, and filled the gaps with tangential statements of impressive rigor and thoroughness on things he was expert in.<a id=\"more\"></a></p>\n<p>For example, the first chapter discusses, with perhaps a hundred references, his opinion that the best art criticism is art made in response to art, his theory that good art is always derived from earlier art, and observations on the etymology of words; but most especially his consternation at the hundreds of thousands of articles, books, and talks on literature produced yearly by people who are not professors at Cambridge, Oxford, or Harvard. Then on page 36, he says,</p>\n<blockquote>\n<p>The positing of an opinion about a painter, poet or composer is not a falsifiable proceeding.</p>\n</blockquote>\n<p>I think this is the only sentence in the chapter that is a crucial part of his argument. But instead of engaging with the body of literature on what falsifiable means, whether human language is falsifiable in general (is \"Ben is tall\" falsifiable?), and what falsifiability has to do with the communication of information, Steiner lowlights this sentence with its syntactic simplicity, and nearly buries it in complex, learned sentences about Dante, Mozart, and hermeneutics. We dive back into litspeak, to emerge again into his argument on page 61:</p>\n<blockquote>\n<p>All elucidation and criticism of literature, music and the arts must operate within the undecidability of unbounded sign-systems... Talk can be neither verified nor falsified in any rigorous sense.</p>\n</blockquote>\n<p>Here one should ask: If human language is recursively enumerable, why don't people understand sentences generated by context-free grammars for English when they go past one level of recursion (\"The mouse the cat the dog chased chased squeaked\")? And doesn't \"undecidable\" mean \"there exists at least one undecidable sentence\" rather than \"all sentences are undecidable\"?</p>\n<p>But one does not; one goes on to Steiner's opinions of Tolstoy's opinions of <em>King Lear</em>. It will be nearly another 20 pages before we hit the next key point in his argument, which relies on his not knowing that one can compute the sum of some infinite series. The bulk of the first 90 pages [1] is impressive displays of learning which fill in the vast spaces between the points&nbsp;(almost literally)&nbsp;of his argument.</p>\n<p>Unless a reader pays close enough attention to catch these brief ventures outside Steiner's areas of expertise, he will come to the end of the book with (A) a summary of Steiner's argument, and (B) the strong impression that the statements in the book were learned and rigorous. And thus, the argument carries.</p>\n<p>ADDED: After looking at the long section on the impossibility of meaning that begins around page 90, it seems Steiner is not trying to argue points 1 and 2 at all when he refers to them in chapters 1 and 2. He is merely foreshadowing. On p. 102-103 we reach the heart of his defense of points 1 and 2, which is to say \"Wittgenstein said so.\" I'm afraid that, if I finish the book, I might find a better summary of the method here to be that the key points of his argument are defended only by appeals to authority.</p>\n<hr />\n<p>[1] This pattern breaks down around page 90, where Steiner begins a long spiral into his central thesis.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N4sGXcNue2jMET8uP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 21, "extendedScore": null, "score": 0.000114, "legacy": true, "legacyId": "27804", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-31T13:45:21.136Z", "modifiedAt": null, "url": null, "title": "Meetup : Warsaw January Meetup", "slug": "meetup-warsaw-january-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "LvfE3p4i6uy8Exadr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p6FkKyxZ39K5quCEN/meetup-warsaw-january-meetup", "pageUrlRelative": "/posts/p6FkKyxZ39K5quCEN/meetup-warsaw-january-meetup", "linkUrl": "https://www.lesswrong.com/posts/p6FkKyxZ39K5quCEN/meetup-warsaw-january-meetup", "postedAtFormatted": "Wednesday, December 31st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Warsaw%20January%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Warsaw%20January%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp6FkKyxZ39K5quCEN%2Fmeetup-warsaw-january-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Warsaw%20January%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp6FkKyxZ39K5quCEN%2Fmeetup-warsaw-january-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp6FkKyxZ39K5quCEN%2Fmeetup-warsaw-january-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18a'>Warsaw January Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 January 2015 06:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Warsaw</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Themes propositions: new year's resolutions, self-development without bullshit, growth mindset, rationalist-friendly fiction. Maybe Go playing.</p>\n\n<p>Place: Pub Frodo, Chmielna 98, pawilon 16. <a href=\"http://www.pubfrodo.pl/\" rel=\"nofollow\">http://www.pubfrodo.pl/</a></p>\n\n<p>Join our Facebook group for better coordination: <a href=\"https://www.facebook.com/groups/lwwarsaw/\" rel=\"nofollow\">https://www.facebook.com/groups/lwwarsaw/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18a'>Warsaw January Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p6FkKyxZ39K5quCEN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.3232459550893395e-06, "legacy": true, "legacyId": "27807", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Warsaw_January_Meetup\">Discussion article for the meetup : <a href=\"/meetups/18a\">Warsaw January Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 January 2015 06:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Warsaw</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Themes propositions: new year's resolutions, self-development without bullshit, growth mindset, rationalist-friendly fiction. Maybe Go playing.</p>\n\n<p>Place: Pub Frodo, Chmielna 98, pawilon 16. <a href=\"http://www.pubfrodo.pl/\" rel=\"nofollow\">http://www.pubfrodo.pl/</a></p>\n\n<p>Join our Facebook group for better coordination: <a href=\"https://www.facebook.com/groups/lwwarsaw/\" rel=\"nofollow\">https://www.facebook.com/groups/lwwarsaw/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Warsaw_January_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/18a\">Warsaw January Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Warsaw January Meetup", "anchor": "Discussion_article_for_the_meetup___Warsaw_January_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Warsaw January Meetup", "anchor": "Discussion_article_for_the_meetup___Warsaw_January_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-31T18:01:57.256Z", "modifiedAt": null, "url": null, "title": "Meetup : London First 2015 Meetup, 04/01/2015", "slug": "meetup-london-first-2015-meetup-04-01-2015", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tenoke", "createdAt": "2012-04-10T21:37:29.739Z", "isAdmin": false, "displayName": "Tenoke"}, "userId": "CRSZPEg9dHyMspTzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/t7e6Y6FSxMCe4h5WF/meetup-london-first-2015-meetup-04-01-2015", "pageUrlRelative": "/posts/t7e6Y6FSxMCe4h5WF/meetup-london-first-2015-meetup-04-01-2015", "linkUrl": "https://www.lesswrong.com/posts/t7e6Y6FSxMCe4h5WF/meetup-london-first-2015-meetup-04-01-2015", "postedAtFormatted": "Wednesday, December 31st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20First%202015%20Meetup%2C%2004%2F01%2F2015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20First%202015%20Meetup%2C%2004%2F01%2F2015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft7e6Y6FSxMCe4h5WF%2Fmeetup-london-first-2015-meetup-04-01-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20First%202015%20Meetup%2C%2004%2F01%2F2015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft7e6Y6FSxMCe4h5WF%2Fmeetup-london-first-2015-meetup-04-01-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft7e6Y6FSxMCe4h5WF%2Fmeetup-london-first-2015-meetup-04-01-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 204, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18b'>London First 2015 Meetup, 04/01/2015</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 January 2015 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having its first Meetup of 2015 this Sunday (04/01) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:\nWe run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18b'>London First 2015 Meetup, 04/01/2015</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "t7e6Y6FSxMCe4h5WF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.3e-05, "legacy": true, "legacyId": "27809", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_First_2015_Meetup__04_01_2015\">Discussion article for the meetup : <a href=\"/meetups/18b\">London First 2015 Meetup, 04/01/2015</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 January 2015 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having its first Meetup of 2015 this Sunday (04/01) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:\nWe run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_First_2015_Meetup__04_01_20151\">Discussion article for the meetup : <a href=\"/meetups/18b\">London First 2015 Meetup, 04/01/2015</a></h2>", "sections": [{"title": "Discussion article for the meetup : London First 2015 Meetup, 04/01/2015", "anchor": "Discussion_article_for_the_meetup___London_First_2015_Meetup__04_01_2015", "level": 1}, {"title": "Discussion article for the meetup : London First 2015 Meetup, 04/01/2015", "anchor": "Discussion_article_for_the_meetup___London_First_2015_Meetup__04_01_20151", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-31T18:34:27.426Z", "modifiedAt": null, "url": null, "title": "Identity crafting", "slug": "identity-crafting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.100Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "robot-dreams", "createdAt": "2014-08-12T23:23:33.596Z", "isAdmin": false, "displayName": "robot-dreams"}, "userId": "6z6xB35aPvA4dWTht", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QDGiCjvP7KpJAbMd6/identity-crafting", "pageUrlRelative": "/posts/QDGiCjvP7KpJAbMd6/identity-crafting", "linkUrl": "https://www.lesswrong.com/posts/QDGiCjvP7KpJAbMd6/identity-crafting", "postedAtFormatted": "Wednesday, December 31st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Identity%20crafting&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIdentity%20crafting%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQDGiCjvP7KpJAbMd6%2Fidentity-crafting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Identity%20crafting%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQDGiCjvP7KpJAbMd6%2Fidentity-crafting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQDGiCjvP7KpJAbMd6%2Fidentity-crafting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 302, "htmlBody": "<p>I spend a LOT of time on what I'll call \"identity crafting\". &nbsp;It's probably my most insidious procrastination tactic--far worse than, say, Facebook or Reddit.</p>\n<p>What do I mean by \"identity crafting\"? &nbsp;Here are some examples:</p>\n<p>\n<ul>\n<li>Brainstorming areas of my life where I want to improve (e.g. social skills, sleep habits)</li>\n<li>Searching for new hobbies to start (e.g. snowboarding, guitar)</li>\n<li>Making a \"character sheet\" for myself, complete with a huge list of \"badass skills\" that I'd want to learn (e.g. martial arts, lock picking)</li>\n<li>Creating and revising my \"four-year plan\", i.e. schedule of university courses (at my university I had a lot of flexibility in which courses to take each term)</li>\n<li>Finding books that I \"ought to read\" (bonus points if the list includes \"The Art of Computer Programming\") and movies that I \"ought to watch\"</li>\n<li>Looking up variants on \"renaissance man\" (e.g. \"Four Arts of the Chinese Scholar\"), and imagining how I could become one</li>\n</ul>\n</p>\n<p>In other words, \"identity crafting\" is some combination of making lists and daydreaming. &nbsp;And since the vast majority of the \"identities\" that I \"craft\" never become reality, I should really say that \"identity crafting\" is some combination of making lists and self-aggrandizing delusion.</p>\n<p>What's so bad about this? &nbsp;Besides the obvious waste of time, this gives me a false sense of accomplishment and productivity--I often feel as though the \"identity\" that I \"crafted\" were already real, and I often feel as though I've already done enough for the day (week, month, year). &nbsp;Thus in the short term, this is a great way to ensure that I don't do any \"actual work\", and in the long term, this is a great way to become a poser with an epically inflated opinion of myself.</p>\n<p>So... does anyone else do this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QDGiCjvP7KpJAbMd6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 14, "extendedScore": null, "score": 2.3239209199097296e-06, "legacy": true, "legacyId": "27810", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2014-12-31T22:23:09.227Z", "modifiedAt": null, "url": null, "title": "Ethereum creator Vitalik Buterin mentions LessWrong, discusses the various camps and ideologies in Cryptocurrency development", "slug": "ethereum-creator-vitalik-buterin-mentions-lesswrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:36.872Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ander", "createdAt": "2013-11-25T22:31:01.872Z", "isAdmin": false, "displayName": "Ander"}, "userId": "TAWyrYP37Zvbiok2Y", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C6f8BGXfASRJgvFo4/ethereum-creator-vitalik-buterin-mentions-lesswrong", "pageUrlRelative": "/posts/C6f8BGXfASRJgvFo4/ethereum-creator-vitalik-buterin-mentions-lesswrong", "linkUrl": "https://www.lesswrong.com/posts/C6f8BGXfASRJgvFo4/ethereum-creator-vitalik-buterin-mentions-lesswrong", "postedAtFormatted": "Wednesday, December 31st 2014", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ethereum%20creator%20Vitalik%20Buterin%20mentions%20LessWrong%2C%20discusses%20the%20various%20camps%20and%20ideologies%20in%20Cryptocurrency%20development&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEthereum%20creator%20Vitalik%20Buterin%20mentions%20LessWrong%2C%20discusses%20the%20various%20camps%20and%20ideologies%20in%20Cryptocurrency%20development%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC6f8BGXfASRJgvFo4%2Fethereum-creator-vitalik-buterin-mentions-lesswrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ethereum%20creator%20Vitalik%20Buterin%20mentions%20LessWrong%2C%20discusses%20the%20various%20camps%20and%20ideologies%20in%20Cryptocurrency%20development%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC6f8BGXfASRJgvFo4%2Fethereum-creator-vitalik-buterin-mentions-lesswrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC6f8BGXfASRJgvFo4%2Fethereum-creator-vitalik-buterin-mentions-lesswrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 213, "htmlBody": "<p>Vitalik says cryptocurrency developers should \"reach out to LessWrong more\", in order to not be ignorant of advanced computer science and game theory topics.</p>\n<p>https://blog.ethereum.org/2014/12/31/silos/</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>I think Vitalik raises several major important points, namely:<br /><br />* Bitcoin's $600 million wasted on electricity yearly in order to secure the network is a huge problem.&nbsp; Various Proof of Stake algorithms are attempting to improve upon this.&nbsp; The ideal solution would be one which combines the low cost of the Proof of Stake algorithm, with the high security or Proof of Work.&nbsp; I not enough of an expert to be able to say which solution is best, but both the Ripple consensus algorithm and the Bitshares Delegated Proof of State algorithm look promising.&nbsp; I am interested to see what algorithm Vitalik will choose for Ethereum.&nbsp; <br /><br />* ASIC miners are a problem due to the resulting centralization.&nbsp; They have also lead to increased centralization in Bitcoin, as the network is now increasingly controlled by a few large mining pools.<br /><br />* Blockchain technologies have a great potential to change the world, and solve governmental and organizational problems that society is facing.&nbsp; Beyond simply revolutionizing money, blockchain technologies could also be used in the future to support prediction markets, voting/consensus building, exchanges, etc.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C6f8BGXfASRJgvFo4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 2.3244550974179015e-06, "legacy": true, "legacyId": "27812", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T00:43:56.587Z", "modifiedAt": null, "url": null, "title": "Treating anthropic selfish preferences as an extension of TDT", "slug": "treating-anthropic-selfish-preferences-as-an-extension-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:10.174Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gTmWZEu3CcEQ6fLLM/treating-anthropic-selfish-preferences-as-an-extension-of", "pageUrlRelative": "/posts/gTmWZEu3CcEQ6fLLM/treating-anthropic-selfish-preferences-as-an-extension-of", "linkUrl": "https://www.lesswrong.com/posts/gTmWZEu3CcEQ6fLLM/treating-anthropic-selfish-preferences-as-an-extension-of", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Treating%20anthropic%20selfish%20preferences%20as%20an%20extension%20of%20TDT&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATreating%20anthropic%20selfish%20preferences%20as%20an%20extension%20of%20TDT%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgTmWZEu3CcEQ6fLLM%2Ftreating-anthropic-selfish-preferences-as-an-extension-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Treating%20anthropic%20selfish%20preferences%20as%20an%20extension%20of%20TDT%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgTmWZEu3CcEQ6fLLM%2Ftreating-anthropic-selfish-preferences-as-an-extension-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgTmWZEu3CcEQ6fLLM%2Ftreating-anthropic-selfish-preferences-as-an-extension-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3330, "htmlBody": "<p><strong>I</strong></p>\n<p>When preferences are selfless, anthropic problems are easily solved by a change of perspective. For example, if we do a Sleeping Beauty experiment for charity, all Sleeping Beauty has to do is follow the strategy that, from the charity's perspective, gets them the most money. This turns out to be an easy problem to solve, because the answer doesn't depend on Sleeping Beauty's subjective perception.</p>\n<p>But selfish preferences - like being at a comfortable temperature, eating a candy bar, or going skydiving - are trickier, because they do rely on the agent's subjective experience. This trickiness really shines through when there are actions that can change the number of copies. For recent posts about these sorts of situations, see <a href=\"/lw/l18/simulation_argument_meets_decision_theory/\">Pallas' sim game</a>&nbsp;and <a href=\"/lw/l3w/baysian_conundrum/\">Jan_Ryzmkowski's tropical paradise</a>. I'm going to propose a model that makes answering these sorts of questions almost as easy as playing for charity.</p>\n<p>To quote Jan's problem:</p>\n<blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">It's a cold cold winter. Radiators are hardly working, but it's not why you're sitting so anxiously in your chair. The real reason is that tomorrow is your assigned upload, and you just can't wait to leave your corporality behind. \"Oh, I'm so sick of having a body, especially now. I'm freezing!\" you think to yourself, \"I wish I were already uploaded and could just pop myself off to a tropical island.\"</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">And now it strikes you. It's a weird solution, but it feels so appealing. You make a solemn oath (you'd say one in million chance you'd break it), that soon after upload you will simulate this exact scene a thousand times simultaneously and when the clock strikes 11 AM, you're gonna be transposed to a Hawaiian beach, with a fancy drink in your hand.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">It's 10:59 on the clock. What's the probability that you'd be in a tropical paradise in one minute?</p>\n</blockquote>\n<div>So question one is the probability question: what's your probability that you go to the tropical paradise? And question two is the decision problem: is this actually a good idea?</div>\n<div><br /></div>\n<div>The probability question is straightforward, and is indeed about a 1000/1001 chance of tropical paradise. If this does not make sense, feel free to ask about it, or go check out these two rambling complementary posts: <a href=\"/lw/l86/deriving_probabilities_from_causal_diagrams/\">Deriving probabilities from causal diagrams</a>, <a href=\"/lw/lau/more_marbles_and_sleeping_beauty/\">More marbles and Sleeping Beauty</a>.</div>\n<div><br /></div>\n<div>One might then make an argument about the decision question that goes like this: Before I swore this oath, my probability of going to a tropical island was very low. After, it was very high. Since I really like tropical islands, this is a great idea. In a nutshell, I have increased my expected utility by making this oath.</div>\n<div><br /></div>\n<div>The counterargument is also simple, though: Making copies of myself has no causal effect on me. Swearing this oath does not move my body to a tropical paradise. What really happens is that I just sit there in the cold just the same, but then later I make some simulations where I lie to myself. This is not a higher-utility universe than the one where I don't swear the oath.</div>\n<div><br /></div>\n<div>Hopefully you can see how this is confusing.</div>\n<div><br /></div>\n<div><strong>II</strong></div>\n<div><br /></div>\n<div>So, my proposal, in short form: You are a person. I mean this not in the abstract, non-causal, sense, where if I make a copy of you and then shoot you, \"you live on.\" I mean that the isolated causal agent reading this is a person capable of selfish desires, where if you are one of two copies and I give the other copy a candy bar, your selfish desires for eating candy are unfulfilled<sup>1</sup>. Choose as if you were controlling the output of your decision algorithm, so that you maximize your expected utility, including selfish desires (if you have them), conditioned on the fact that you exist (I'll come back to what this last bit means in part III).</div>\n<div><br /></div>\n<div>This is at its heart porting TDT to anthropic problems. When there is a decision your original body can make that creates a bunch of copies, and the copies are also faced with this decision, your decision lets you control whether you are the original or a copy. If you don't want to be a copy, as in Pallas' sim game, you have to take that into account. If you do want to be a copy, you take that into account too.</div>\n<div><br /></div>\n<div>This leads to biting the bullet in Jan's tropical paradise. It is <em>actually a good idea</em>&nbsp;to take an action that, if you're the original body, creates a bunch of high-selfish-expected-utility copies that also undergo the decision you're making right now, because this decision controls whether you're one of those copies.</div>\n<div><br /></div>\n<div>There is an important caveat: this only holds if you truly would like to be one of those copies. To repeat the short form, this decision algorithm assumes that you are a person trying to increase their own expected utility. These copies can't just be made and disposed of to manipulate your subjective experience - something which is possible, but is a bad idea. The copies have to be people who you would actually like to be, who go on to live long, fulfilling lives. This is not about gaming the system. It's just an extension of TDT to anthropic situations.</div>\n<div><br /></div>\n<div>Interestingly, this usually gives the same results as playing for charity. Thus there's a sort of locality of money, where you make similar tradeoffs between selfish spending and charitable spending no matter how many copies of you there are.</div>\n<div><br /></div>\n<div>To deliberately construct an intuitive case, imagine that you are already uploaded, and you're led into a room (a simulated room, of course) where Omega is waiting for you. Omega says hello, and asks you whether you think you're the original or a copy. \"Huh? Have I been copied?\" you say. Excellent, Omega says. It then presents two boxes to you, box A and box B. Box A always has some okay candy in it for you to eat (eating candy is my go-to selfish reward). If you pick box B and are the original, it is empty, but you will be copied a million times from a snapshot when you entered the room, and offered the same choice - and if you are a copy, box B contains very delicious candy to eat (and then the copies go on to live similar lives to the original). Again there's the odd property that the output of your decision algorithm controls whether you are likely a copy or not. If you would prefer to be a copy, then you should pick box B.</div>\n<div><br /></div>\n<div>There's a precommitment problem here. Suppose I value my future selves by a sum of their utilities (given some zero point). Then even if being a copy was not so great (like in Pallas' sim game), I'd precommit to making as many copies as possible. But once the game starts, by my definition of selfish preferences I don't care much about whether the other copies get a selfish reward, and so I might try to fight that precommitment to raise my expected utility.</div>\n<div><br /></div>\n<div>In fact, these precommitment problems crop up whenever I calculate expected value in any other way than by averaging utility among future copies. This is a statement about a small piece of population ethics, and as such, should be highly suspect - the fact that my preferred model of selfish preferences says anything about even this small subset of population ethics makes me significantly less confident that I'm right. Even though the thing it's saying seems sensible.</div>\n<div><br /></div>\n<div>Footnote&nbsp;<sup>1</sup>: The reader who has been following my posts may note how this identification of who has the preferences via causality makes selfish preferences well-defined no matter <a href=\"/lw/lcj/how_many_people_am_i/\">how many times I define the pattern \"I\" to map to my brain</a>, which is good because it makes the process well-defined, but also somewhat difficult because it eliminates the last dependence on a lower level where we can think of anthropic probabilities as determined a priori, rather than depending on a definition of self grounded in decision-making as well as experiencing. On the other hand, with that level conflict gone, maybe there's nothing stopping us from thinking of anthropic probabilities on this more contingent level as \"obvious\" or \"a priori.\"</div>\n<div><br /></div>\n<div>\n<div><strong>III</strong></div>\n<div><br /></div>\n<div>It's worth bringing up Eliezer's&nbsp;<a href=\"/lw/19d/the_anthropic_trilemma/\">anthropic trilemma</a>&nbsp;(further thought by Katja Grace&nbsp;<a href=\"http://meteuphoric.wordpress.com/2011/05/19/on-the-anthropic-trilemma/\">here</a>). The idea is to subjectively experience winning the lottery by entering a lottery and then replicating yourself a trillion times, wake up to have the experience, and then merge back together. Thus, the argument goes, as long as probability flows along causal channels, by waking up a trillion times I have captured the subjective experience, and will go on to subjectively experience winning the lottery.</div>\n</div>\n<div><br /></div>\n<div>Again we can ask the two questions: What are the probabilities? And is this actually a good idea?</div>\n<div><br /></div>\n<div>This is the part where I come back to explain that earlier terminology - why is it important that I specified that you condition on your own existence? When you condition on the fact that you exist, you get an anthropic probability. In the story about Omega I told above, your probability that you're the original before you enter the room is 1. But after you enter the room, if your decision algorithm chooses box B, your probability that you're the original should go down to one in a million. This update is possible because you're updating on new information about where you are in the game - you're conditioning on your own existence.</div>\n<div><br /></div>\n<div>Note that I did not just say \"use anthropic probabilities.\" When calculating expected utility, you condition on your own existence, but you most certainly do not condition on future selves' existence. After all, you might get hit by a meteor and die, so you don't actually know that you'll be around tomorrow, and you shouldn't condition on things you don't know. Thus the player at russian roulette who says \"It's okay, I'll subjectively experience winning!\" is making a decision by conditioning on information they do not have.</div>\n<div><br /></div>\n<div>Katja Grace talks about two principles acting in the Anthropic Trilemma: Follow The Crowd, which sends your subjective experience into the branch with more people, and Blatantly Obvious Principle, which says that your subjective experience should follow causal paths. Katja points out that they do not just cause problems when merging, they also conflict when splitting - so Eliezer is being selective in applying these principles, and there's a deeper problem here. If you recall me mentioning my two-fluid model of anthropics, I partially resolved this by tracking two measures, one that obeyed FTC (subjective probability), and one that obeyed BOP (magic reality fluid).</div>\n<div><br /></div>\n<div>But the model I'm presenting here dissolves those fluids (or would it be 'dilutes'?) - the thing that follows the crowd is who you think you are, and the blatantly obvious thing is your expectation for the future. There's no subjective experience fluid that it's possible to push around without changing the physical state of the universe. There's just people.</div>\n<div><br /></div>\n<div>To give the probabilities in the Anthropic Trilemma, it is important to track what information you're conditioning on. If I condition on my existence just after I buy my ticket, my probability that I picked the winning numbers is small, no matter what anthropic hijinks might happen if I win, I still expect to see those hijinks happen with low probability<sup>2</sup>. If I condition on the fact that I wake up after possibly being copied, my probability that I picked the winning numbers is large, as is my probability that I will have picked the winning numbers in the future, even if I get copied or merged or what have you. Then I learn the result, and no longer have a single state of information which would give me a probability distribution. Compare this to the second horn of the trilemma; it's easy to get mixed up when giving probabilities if there's more than one set of probabilities to give.</div>\n<div><br /></div>\n<div>Okay, so that's the probabilities - but is this actually a good idea? Suppose I'm just in it for the money. So I'm standing there considering whether to buy a ticket, and I condition on my own existence, and the chances of winning still look small, and so I don't buy the ticket. That's it. This is especially clear if I donate my winnings to charity - the only winning move is not to play<sub> the lottery</sub>.</div>\n<div><br /></div>\n<div>Suppose then instead that I have a selfish desire to experience winning the lottery, independent of the money - does copying myself if I win help fulfill this desire? Or to put this another way, in calculating expected utility we weight the selfish utility of the many winning copies less because winning is unlikely, but do we weight it more because there are more of them?</div>\n<div><br /></div>\n<div>This question is resolved by (possible warning sign) the almost-population-ethics result above, which says that as an attractor of self-modification we should average copies' utilities rather than summing them, and so copying does not increase expected utility. Again, I find this incompletely convincing, but it does seem to be the extension of TDT here. So this procedure does not bite the bullet in the anthropic trilemma. But remember the behavior in Jan's tropical paradise game? It is in fact possible to design a procedure that lets you satisfy your desire to win the lottery - just have the copies created when you win start from a snapshot of yourself before you bought the lottery ticket.</div>\n<div><br /></div>\n<div>This is a weird bullet to bite. It's like, how come it's a good idea to create copies that go through the decision to create copies, but only a neutral idea to create copies that don't? After all, winning and then creating simulations has the same low chance no matter what. The difference is entirely anthropic - only when the copies also make the decision does the decision control whether you're a copy.</div>\n<div><br /></div>\n<div>Footnote&nbsp;<sup>2</sup>: One might complain that if you know what you'll expect in the future, you should update to believing that in the present. But if I'm going to be copied tomorrow, I don't expect to be a copy today.</div>\n<div><br /></div>\n<div><strong>IV</strong></div>\n<div><br /></div>\n<div>The problem of the Anthropic Trilemma is not actually gone, because if I'm indifferent to merging with my copies, there is some procedure that better fulfills my selfish desire to experience winning the lottery just by shuffling copies of me around: if I win, make a bunch of copies that start from a snapshot in the past, then merge a the copies together.</div>\n<div><br /></div>\n<div>So let's talk about the merging. This is going to be the section with the unsolved problem.</div>\n<div><br /></div>\n<div>Here's what Eliezer's post says about merging:</div>\n<div><br /></div>\n<blockquote>\n<div><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Just as computer programs or brains can split, they ought to be able to merge.&nbsp; If we imagine a version of the Ebborian species that computes digitally, so that the brains remain synchronized so long as they go on getting the same sensory inputs, then we ought to be able to put two brains back together along the thickness, after dividing them.&nbsp; In the case of computer programs, we should be able to perform an operation where we compare each two bits in the program, and if they are the same, copy them, and if they are different, delete the whole program.&nbsp; (This seems to establish an equal causal dependency of the final program on the two original programs that went into it.&nbsp; E.g., if you test the causal dependency via counterfactuals, then disturbing any bit of the two originals, results in the final program being completely different (namely deleted).)</span></div>\n</blockquote>\n<div><br /></div>\n<div>In general, merging copies is some process where many identical copies go in, and only one comes out. If you know they're almost certainly identical, why bother checking them, then? Why not just delete all but one? It's the same pattern, after all.</div>\n<div><br /></div>\n<div>Well, imagine that we performed a causal intervention on one of these identical copies - gave them candy or something. Now if we deleted all but one, the effect of our intervention is erased with high probability. In short, if you delete all but one, the person who comes out is not actually the causal descendant of the copies who go in - it's just one of the copies.</div>\n<div><br /></div>\n<div>Just like how \"selfish preferences\" means that if I give another of your copies candy, that doesn't fulfill your selfish desire for candy, if another of your copies is the one who gets out of the murder-chamber, that doesn't fulfill your selfish desire to not get murdered. This is why Eliezer talks about going through the process of comparing each copy bit by bit and only merging them if they're identical, so that the person who comes out is the causal descendant of all the people who go in.</div>\n<div><br /></div>\n<div>On the other hand, Eliezer's process is radically different from how things normally go. If I'm one of several copies, and a causal intervention gives me candy, and no merging shenanigans occur, then my causal descendant is me who's had some candy. If I'm one of several copies, and a causal intervention gives me candy, and then we're merged by Eliezer's method, then my causal descendant is <em>utterly annihilated</em>.</div>\n<div><br /></div>\n<div>If we allow the character of causal arrows to matter, and not merely their existence, then it's possible that merging is not so neutral after all. But this seems like a preference issue independent of the definition of selfish preferences - although I would have said that about how to weight preferences of multiple copies, too, and I would likely have been wrong.</div>\n<div><br /></div>\n<div>Does the strange behavior permitted by the neutrality of merging serve as a reductio of that neutrality, or of this extension of selfish preferences to anthropic information, or neither? In the immortal words of Socrates, \"... I drank what?\"&nbsp;</div>\n<div><br /></div>\n<div><br /></div>\n<div><strong>EDIT:</strong></div>\n<div><br /></div>\n<div><strong>A Problem:</strong></div>\n<div><br /></div>\n<div>This decision theory has precommitment issues. In the case of Jan's tropical paradise, I want to precommit to creating satisfied copies from a snapshot of my recent self. But once I'm my future self, I don't want to do it because I know I'm not a copy.</div>\n<div><br /></div>\n<div><strong>Metaproblems:</strong></div>\n<div><br /></div>\n<div>This decision theory doesn't have very many knobs to turn - it boils down to \"choose the decision-algorithm output that causes maximum expected utility for you, conditioning on both the action and the information you possess.\" This is somewhat good news, because we don't much want free variables in a decision theory. But it's a metaproblem because it means that there's no obvious knob to turn to eliminate the problem above - creativity is required.</div>\n<div><br /></div>\n<div>One approach that has worked in the past is to figure out what global variable we want to maximize, and just do UDT to this problem. But this doesn't work for this decision theory - as we expected, because it doesn't seem to work for selfish preferences in general. The selves at two different times in the tropical paradise problem just want to act selfishly - so are they allowed to be in conflict?</div>\n<div><br /></div>\n<div><strong>Solution Brainstorming (if one is needed at all):</strong></div>\n<div><br /></div>\n<div>One specific argument might run that when you precommit to creating copies, you decrease your amount of indexical information, and that this is just a form of lying to yourself and is therefore bad. I don't think this works at all, but it may be worth keeping in mind.</div>\n<div><br /></div>\n<div>A more promising line might be to examine the analogy to evidential decision theory. Evidential decision theory fails when there's a difference between conditioning on the action and conditioning on a causal do(Action). What does the analogue look like for anthropic situations?</div>\n<div><br /></div>\n<div><strong>EDIT 2:</strong></div>\n<div><br /></div>\n<div>For somewhat of a resolution, see <a href=\"/r/discussion/lw/lj3/selfish_preferences_and_selfmodification/\">Selfish preferences and self-modification</a>.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2, "dPPATLhRmhdJtJM2t": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gTmWZEu3CcEQ6fLLM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 13, "extendedScore": null, "score": 2.3247840537292287e-06, "legacy": true, "legacyId": "27794", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xjWbChCdqSSQyMNnr", "rxb46W3okERnTL2EZ", "KZE9foCxCu2hBPnah", "c7fAEStCafGh8TFdf", "brLgyCqZaMDjGPKsp", "y7jZ9BLEeuNTzgAE5", "zgbZNwW7f3C89ZgGK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T00:50:52.890Z", "modifiedAt": null, "url": null, "title": "January 2015 Media Thread", "slug": "january-2015-media-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.410Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9vd9qDhfRqh3ZQuK4/january-2015-media-thread", "pageUrlRelative": "/posts/9vd9qDhfRqh3ZQuK4/january-2015-media-thread", "linkUrl": "https://www.lesswrong.com/posts/9vd9qDhfRqh3ZQuK4/january-2015-media-thread", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20January%202015%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJanuary%202015%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9vd9qDhfRqh3ZQuK4%2Fjanuary-2015-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=January%202015%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9vd9qDhfRqh3ZQuK4%2Fjanuary-2015-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9vd9qDhfRqh3ZQuK4%2Fjanuary-2015-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<p>This is the monthly thread for posting media of various types that you've found that you enjoy. Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing! To see previous recommendations, check out the <a href=\"/r/discussion/tag/media_thread/\">older threads</a>.</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a <a href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please post only under one of the already created subthreads, and never directly under the parent media thread.</li>\n<li>Use the \"Other Media\" thread if you believe the piece of media you want to discuss doesn't fit under any of the established categories.</li>\n<li>Use the \"Meta\" thread if you want to discuss about the monthly media thread itself (e.g. to propose adding/removing/splitting/merging subthreads, or to discuss the type of content properly belonging to each subthread) or for any other question or issue you may have about the thread or the rules.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9vd9qDhfRqh3ZQuK4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 2.3248002674546513e-06, "legacy": true, "legacyId": "27813", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T02:23:30.742Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes January 2015", "slug": "rationality-quotes-january-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:09.922Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RpM9uExiaiQypdux6/rationality-quotes-january-2015", "pageUrlRelative": "/posts/RpM9uExiaiQypdux6/rationality-quotes-january-2015", "linkUrl": "https://www.lesswrong.com/posts/RpM9uExiaiQypdux6/rationality-quotes-january-2015", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20January%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20January%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRpM9uExiaiQypdux6%2Frationality-quotes-january-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20January%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRpM9uExiaiQypdux6%2Frationality-quotes-january-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRpM9uExiaiQypdux6%2Frationality-quotes-january-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 144, "htmlBody": "<p>It is the beginning of a new year, and time for the beginning of a new rationality quotes thread.</p>\n<p>The rules are:</p>\n<ul style=\"padding: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; -webkit-text-size-adjust: auto;\">\n<li>Please post all quotes separately, so that they can be upvoted or  downvoted separately. (If they are strongly related, reply to your own  comments. If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote from Less Wrong itself, HPMoR, Eliezer Yudkowsky, or  Robin Hanson. If you'd like to revive an old quote from one of those  sources, please do so&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/i6h/rationality_quotes_from_people_associated_with/\">here</a>.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n<li>Provide sufficient information (URL, title, date, page number, etc.)  to enable a reader to find the place where you read the quote, or its  original source if available. Do not quote with only a name.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RpM9uExiaiQypdux6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 2.325016748357446e-06, "legacy": true, "legacyId": "27814", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 153, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iWTZj26MfR8e8b9nm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T02:30:43.238Z", "modifiedAt": null, "url": null, "title": "Stupid Questions January 2015", "slug": "stupid-questions-january-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:31.532Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fx2QFp8ra8TCHZ4xB/stupid-questions-january-2015", "pageUrlRelative": "/posts/fx2QFp8ra8TCHZ4xB/stupid-questions-january-2015", "linkUrl": "https://www.lesswrong.com/posts/fx2QFp8ra8TCHZ4xB/stupid-questions-january-2015", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Stupid%20Questions%20January%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStupid%20Questions%20January%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffx2QFp8ra8TCHZ4xB%2Fstupid-questions-january-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Stupid%20Questions%20January%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffx2QFp8ra8TCHZ4xB%2Fstupid-questions-january-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffx2QFp8ra8TCHZ4xB%2Fstupid-questions-january-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<div id=\"entry_t3_ld5\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p>This thread is for asking any questions that might seem obvious,  tangential, silly or what-have-you. Don't be shy, everyone has holes in  their knowledge, though the fewer and the smaller we can make them, the  better.</p>\n<p>Please be respectful of other people's admitting ignorance and don't mock them for it, as they're doing a noble thing.</p>\n<p>To any future monthly posters of SQ threads, please remember to add the \"stupid_questions\" tag.</p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fx2QFp8ra8TCHZ4xB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 2.32503359570023e-06, "legacy": true, "legacyId": "27815", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 111, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T02:34:22.455Z", "modifiedAt": null, "url": null, "title": "Lifehack Ideas January 2015", "slug": "lifehack-ideas-january-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:35.401Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iqztRAQJAEZ4tv4ew/lifehack-ideas-january-2015", "pageUrlRelative": "/posts/iqztRAQJAEZ4tv4ew/lifehack-ideas-january-2015", "linkUrl": "https://www.lesswrong.com/posts/iqztRAQJAEZ4tv4ew/lifehack-ideas-january-2015", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Lifehack%20Ideas%20January%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALifehack%20Ideas%20January%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiqztRAQJAEZ4tv4ew%2Flifehack-ideas-january-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Lifehack%20Ideas%20January%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiqztRAQJAEZ4tv4ew%2Flifehack-ideas-january-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiqztRAQJAEZ4tv4ew%2Flifehack-ideas-january-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<div id=\"entry_t3_lde\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<blockquote><strong>Life hacking</strong> refers to any trick, shortcut, skill, or novelty method that increases productivity and efficiency, in all walks of life.</blockquote>\n<p>&mdash; <a href=\"http://en.wikipedia.org/wiki/Life_hacking\" target=\"_blank\">Wikipedia</a></p>\n<p>This thread is for posting any promising or interesting ideas for lifehacks you've come up with or heard of.&nbsp; If you've successfully&nbsp; implemented your idea, please share the results.&nbsp; You are also encouraged to post lifehack ideas you've tried out that have not been successful, and why you think they weren't.&nbsp; If you can, please give credit for ideas that you got from other people.</p>\n<p>To any future posters of Lifehack Ideas threads, please remember to add the \"lifehacks_thread\" tag.</p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iqztRAQJAEZ4tv4ew", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 2.325042135108334e-06, "legacy": true, "legacyId": "27816", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T12:17:49.346Z", "modifiedAt": null, "url": null, "title": "Meetup : Paris LW Meetup - LHC Exhibit", "slug": "meetup-paris-lw-meetup-lhc-exhibit", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kilobug", "createdAt": "2011-09-02T14:37:51.213Z", "isAdmin": false, "displayName": "kilobug"}, "userId": "7BQMuDSmLE2XRq2ph", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q57jSX5Z4Gw6rHrr4/meetup-paris-lw-meetup-lhc-exhibit", "pageUrlRelative": "/posts/Q57jSX5Z4Gw6rHrr4/meetup-paris-lw-meetup-lhc-exhibit", "linkUrl": "https://www.lesswrong.com/posts/Q57jSX5Z4Gw6rHrr4/meetup-paris-lw-meetup-lhc-exhibit", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Paris%20LW%20Meetup%20-%20LHC%20Exhibit&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Paris%20LW%20Meetup%20-%20LHC%20Exhibit%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ57jSX5Z4Gw6rHrr4%2Fmeetup-paris-lw-meetup-lhc-exhibit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Paris%20LW%20Meetup%20-%20LHC%20Exhibit%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ57jSX5Z4Gw6rHrr4%2Fmeetup-paris-lw-meetup-lhc-exhibit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ57jSX5Z4Gw6rHrr4%2Fmeetup-paris-lw-meetup-lhc-exhibit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18c'>Paris LW Meetup - LHC Exhibit</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 January 2015 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Palais de la D\u00e9couverte, Avenue Franklin Delano Roosevelt 75008 Paris </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll go see the LHC exhibit and speak about it (and any other related theme) between LWers.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18c'>Paris LW Meetup - LHC Exhibit</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q57jSX5Z4Gw6rHrr4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.3e-05, "legacy": true, "legacyId": "27819", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Paris_LW_Meetup___LHC_Exhibit\">Discussion article for the meetup : <a href=\"/meetups/18c\">Paris LW Meetup - LHC Exhibit</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 January 2015 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Palais de la D\u00e9couverte, Avenue Franklin Delano Roosevelt 75008 Paris </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll go see the LHC exhibit and speak about it (and any other related theme) between LWers.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Paris_LW_Meetup___LHC_Exhibit1\">Discussion article for the meetup : <a href=\"/meetups/18c\">Paris LW Meetup - LHC Exhibit</a></h2>", "sections": [{"title": "Discussion article for the meetup : Paris LW Meetup - LHC Exhibit", "anchor": "Discussion_article_for_the_meetup___Paris_LW_Meetup___LHC_Exhibit", "level": 1}, {"title": "Discussion article for the meetup : Paris LW Meetup - LHC Exhibit", "anchor": "Discussion_article_for_the_meetup___Paris_LW_Meetup___LHC_Exhibit1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T12:22:01.678Z", "modifiedAt": null, "url": null, "title": "Paris LW Meetup - LHC Exhibit - 17/01/2015", "slug": "paris-lw-meetup-lhc-exhibit-17-01-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.506Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kilobug", "createdAt": "2011-09-02T14:37:51.213Z", "isAdmin": false, "displayName": "kilobug"}, "userId": "7BQMuDSmLE2XRq2ph", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F9tQ4zbr5h4W4F7xW/paris-lw-meetup-lhc-exhibit-17-01-2015", "pageUrlRelative": "/posts/F9tQ4zbr5h4W4F7xW/paris-lw-meetup-lhc-exhibit-17-01-2015", "linkUrl": "https://www.lesswrong.com/posts/F9tQ4zbr5h4W4F7xW/paris-lw-meetup-lhc-exhibit-17-01-2015", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Paris%20LW%20Meetup%20-%20LHC%20Exhibit%20-%2017%2F01%2F2015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AParis%20LW%20Meetup%20-%20LHC%20Exhibit%20-%2017%2F01%2F2015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF9tQ4zbr5h4W4F7xW%2Fparis-lw-meetup-lhc-exhibit-17-01-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Paris%20LW%20Meetup%20-%20LHC%20Exhibit%20-%2017%2F01%2F2015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF9tQ4zbr5h4W4F7xW%2Fparis-lw-meetup-lhc-exhibit-17-01-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF9tQ4zbr5h4W4F7xW%2Fparis-lw-meetup-lhc-exhibit-17-01-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 59, "htmlBody": "<p>We'll be organizing a meetup of LW Paris at <a href=\"http://www.palais-decouverte.fr/en/palais-de-la-decouverte/\">\"Palais de la D&eacute;couverte\"</a> in order to view the <a href=\"http://www.palais-decouverte.fr/fr/au-programme/expos-temporaires/le-grand-collisionneur-lhc/\">exhibit on LHC</a> (link in French, sorry) and speak about it (and any related - or even unrelated - subject) between LWer.</p>\n<p>The meeting is scheduled at 14h00 on Saturday 17th afternoon.</p>\n<p><a href=\"http://www.palais-decouverte.fr/en/infos-pratiques/access/\">Map and location information available. </a></p>\n<p>Hoping to see many Paris LWers !</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F9tQ4zbr5h4W4F7xW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "27820", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T12:22:31.833Z", "modifiedAt": null, "url": null, "title": "Overpaying for happiness?", "slug": "overpaying-for-happiness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:25:09.692Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NToH5vtBY8ShiEeXm/overpaying-for-happiness", "pageUrlRelative": "/posts/NToH5vtBY8ShiEeXm/overpaying-for-happiness", "linkUrl": "https://www.lesswrong.com/posts/NToH5vtBY8ShiEeXm/overpaying-for-happiness", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Overpaying%20for%20happiness%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOverpaying%20for%20happiness%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNToH5vtBY8ShiEeXm%2Foverpaying-for-happiness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Overpaying%20for%20happiness%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNToH5vtBY8ShiEeXm%2Foverpaying-for-happiness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNToH5vtBY8ShiEeXm%2Foverpaying-for-happiness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 349, "htmlBody": "<p>Happy New Year, everyone!</p>\n<p>In the past few months I've been thinking several thoughts that all seem to point in the same direction:</p>\n<p>1) People who live in developed Western countries usually make and spend much more money than people in poorer countries, but aren't that much happier. It feels like we're overpaying for happiness, spending too much money to get a single bit of enjoyment.</p>\n<p>2) When you get enjoyment from something, the association between \"that thing\" and \"pleasure\" in your mind gets stronger, but at the same time it becomes less sensitive and requires more stimulus. For example if you like sweet food, you can get into a cycle of eating more and more food that's sweeter and sweeter. But the guy next door, who's eating much less and periodically fasting to keep the association fresh, is actually getting more pleasure from food than you are! The same thing happens when you learn to deeply appreciate certain kinds of art, and then notice that the folks who enjoy \"low\" art are visibly having more fun.</p>\n<p>3) People sometimes get unrealistic dreams and endlessly chase them, like trying to \"make it big\" in writing or sports, because they randomly got rewarded for it at an early age. I wrote a&nbsp;<a href=\"/lw/ksy/follow_your_dreams_as_a_case_study_in_incorrect/\">post</a> about that.</p>\n<p>I'm not offering any easy answers here. But it seems like too many people get locked in loops where they spend more and more effort to get less and less happiness. The most obvious examples are drug addiction and video gaming, but also \"one-itis\" in dating, overeating, being a connoisseur of anything, striving for popular success, all these things follow the same pattern. You're just chasing after some Skinner-box thing that you think you \"love\", but it doesn't love you back.</p>\n<p>Sooo... if you like eating, give yourself a break every once in a while? If you like comfort, maybe get a cold shower sometimes? Might be a good idea to make yourself the kind of person that can get happiness cheaply.</p>\n<p>Sorry if this post is not up to LW standards, I typed it really quickly as it came to my mind.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Jzm2mYuuDBCNWq8hi": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NToH5vtBY8ShiEeXm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 50, "extendedScore": null, "score": 2.326417532078757e-06, "legacy": true, "legacyId": "27821", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EJ4eT72cEp7ijvQem"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T17:35:48.621Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA\u2014What Is FAI?", "slug": "meetup-west-la-what-is-fai", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cojJPHun7DykuryEH/meetup-west-la-what-is-fai", "pageUrlRelative": "/posts/cojJPHun7DykuryEH/meetup-west-la-what-is-fai", "linkUrl": "https://www.lesswrong.com/posts/cojJPHun7DykuryEH/meetup-west-la-what-is-fai", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%E2%80%94What%20Is%20FAI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%E2%80%94What%20Is%20FAI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcojJPHun7DykuryEH%2Fmeetup-west-la-what-is-fai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%E2%80%94What%20Is%20FAI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcojJPHun7DykuryEH%2Fmeetup-west-la-what-is-fai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcojJPHun7DykuryEH%2Fmeetup-west-la-what-is-fai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 188, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18d'>West LA\u2014What Is FAI?</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 January 2015 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">11066 Santa Monica Blvd, Los Angeles, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>How to Find Us</strong>: Go into <a href=\"https://www.google.com/maps/place/Del+Taco/@34.047464,-118.443286,974m/data=!3m2!1e3!4b1!4m2!3m1!1s0x80c2bb777277de93:0x99f58a53b04bb89c?hl=en\" rel=\"nofollow\">this</a> Del Taco. We will be in the back room if possible.</p>\n\n<p><strong>Parking</strong> is free in the lot out front or on the street nearby.</p>\n\n<p><strong>Discussion</strong>: Though it is not relevant to rationality and is very easy to think wrongly about if you have not studied the art, <a href=\"http://wiki.lesswrong.com/wiki/Friendly_AI\">Friendly AI</a> is often discussed by rationalists, for historical reasons involving the founder of Less Wrong and a spearhead FAI theorist being the same person. Friendly AI is not a technical term, so it should be easy to explain what it basically is.</p>\n\n<p><strong>Recommended Reading</strong>:</p>\n\n<ul>\n<li><a href=\"http://wiki.lesswrong.com/wiki/Friendly_AI\">Friendly AI wiki article</a> and the things linked to thence</li>\n<li><a href=\"https://intelligence.org/2013/05/05/five-theses-two-lemmas-and-a-couple-of-strategic-implications/\" rel=\"nofollow\">Five theses, two lemmas, and a couple of strategic implications</a></li>\n<li><a href=\"http://lesswrong.com/lw/igf/the_genie_knows_but_doesnt_care/\">The genie knows, but does not care</a></li>\n<li><em><a href=\"http://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" rel=\"nofollow\">Superintelligence</a></em>, by Bostrom. Chapter summaries available <a href=\"http://lesswrong.com/lw/kw4/superintelligence_reading_group/\">here</a></li>\n<li><a href=\"http://malo2-8080.terminal.com/news\" rel=\"nofollow\">Friendly AI research forum</a></li>\n</ul>\n\n<p><em>No prior exposure to Less Wrong is required</em>; this will be generally accessible.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18d'>West LA\u2014What Is FAI?</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cojJPHun7DykuryEH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 2.3271507211974144e-06, "legacy": true, "legacyId": "27822", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_What_Is_FAI_\">Discussion article for the meetup : <a href=\"/meetups/18d\">West LA\u2014What Is FAI?</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 January 2015 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">11066 Santa Monica Blvd, Los Angeles, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>How to Find Us</strong>: Go into <a href=\"https://www.google.com/maps/place/Del+Taco/@34.047464,-118.443286,974m/data=!3m2!1e3!4b1!4m2!3m1!1s0x80c2bb777277de93:0x99f58a53b04bb89c?hl=en\" rel=\"nofollow\">this</a> Del Taco. We will be in the back room if possible.</p>\n\n<p><strong>Parking</strong> is free in the lot out front or on the street nearby.</p>\n\n<p><strong>Discussion</strong>: Though it is not relevant to rationality and is very easy to think wrongly about if you have not studied the art, <a href=\"http://wiki.lesswrong.com/wiki/Friendly_AI\">Friendly AI</a> is often discussed by rationalists, for historical reasons involving the founder of Less Wrong and a spearhead FAI theorist being the same person. Friendly AI is not a technical term, so it should be easy to explain what it basically is.</p>\n\n<p><strong>Recommended Reading</strong>:</p>\n\n<ul>\n<li><a href=\"http://wiki.lesswrong.com/wiki/Friendly_AI\">Friendly AI wiki article</a> and the things linked to thence</li>\n<li><a href=\"https://intelligence.org/2013/05/05/five-theses-two-lemmas-and-a-couple-of-strategic-implications/\" rel=\"nofollow\">Five theses, two lemmas, and a couple of strategic implications</a></li>\n<li><a href=\"http://lesswrong.com/lw/igf/the_genie_knows_but_doesnt_care/\">The genie knows, but does not care</a></li>\n<li><em><a href=\"http://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" rel=\"nofollow\">Superintelligence</a></em>, by Bostrom. Chapter summaries available <a href=\"http://lesswrong.com/lw/kw4/superintelligence_reading_group/\">here</a></li>\n<li><a href=\"http://malo2-8080.terminal.com/news\" rel=\"nofollow\">Friendly AI research forum</a></li>\n</ul>\n\n<p><em>No prior exposure to Less Wrong is required</em>; this will be generally accessible.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_What_Is_FAI_1\">Discussion article for the meetup : <a href=\"/meetups/18d\">West LA\u2014What Is FAI?</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA\u2014What Is FAI?", "anchor": "Discussion_article_for_the_meetup___West_LA_What_Is_FAI_", "level": 1}, {"title": "Discussion article for the meetup : West LA\u2014What Is FAI?", "anchor": "Discussion_article_for_the_meetup___West_LA_What_Is_FAI_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NyFuuKQ8uCEDtd2du", "QDmzDZ9CEHrKQdvcn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T17:43:43.569Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, January 1-15", "slug": "group-rationality-diary-january-1-15", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.278Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tmDoJPSkyqkHgYABW/group-rationality-diary-january-1-15", "pageUrlRelative": "/posts/tmDoJPSkyqkHgYABW/group-rationality-diary-january-1-15", "linkUrl": "https://www.lesswrong.com/posts/tmDoJPSkyqkHgYABW/group-rationality-diary-january-1-15", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20January%201-15&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20January%201-15%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtmDoJPSkyqkHgYABW%2Fgroup-rationality-diary-january-1-15%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20January%201-15%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtmDoJPSkyqkHgYABW%2Fgroup-rationality-diary-january-1-15", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtmDoJPSkyqkHgYABW%2Fgroup-rationality-diary-january-1-15", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<h2 style=\"margin: 0px 0px 0.75em; color: #333333; font-size: 1.3333em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"line-height: 24.2727279663086px; font-size: small; color: #000000; font-weight: normal;\">Happy new year to those who are celebrating! This is the public group rationality diary for January 1-15.</span></h2>\n<div id=\"entry_t3_l4c\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px; line-height: 18px;\">\n<div class=\"md\">\n<div id=\"entry_t3_l1z\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<blockquote style=\"line-height: 24.2727279663086px;\">\n<p style=\"margin: 0px 0px 1em;\">It's a place to record and chat about it if you have done, or are actively doing, things like:&nbsp;</p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating.</p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Next diary: <a href=\"/lw/ljq/group_rationality_diary_january_1631/\">January 16-31</a></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Previous diary:&nbsp;<span style=\"line-height: 24.2727279663086px;\"><a href=\"/lw/le6/group_rationality_diary_december_1631/\">December 16-31</a></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality diaries archive</a></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tmDoJPSkyqkHgYABW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "27823", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uqTmqJAfW5JN3rDjY", "z87oRFkoCBe4yySfF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-01T21:09:30.269Z", "modifiedAt": null, "url": null, "title": "Meetup : Rationality Meetup Vienna", "slug": "meetup-rationality-meetup-vienna-7", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaLeptikon", "createdAt": "2014-03-29T17:32:19.520Z", "isAdmin": false, "displayName": "AnnaLeptikon"}, "userId": "FyZibA2dPTe9zcmND", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S87k57WyRQSS9BLCu/meetup-rationality-meetup-vienna-7", "pageUrlRelative": "/posts/S87k57WyRQSS9BLCu/meetup-rationality-meetup-vienna-7", "linkUrl": "https://www.lesswrong.com/posts/S87k57WyRQSS9BLCu/meetup-rationality-meetup-vienna-7", "postedAtFormatted": "Thursday, January 1st 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Rationality%20Meetup%20Vienna&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Rationality%20Meetup%20Vienna%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS87k57WyRQSS9BLCu%2Fmeetup-rationality-meetup-vienna-7%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Rationality%20Meetup%20Vienna%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS87k57WyRQSS9BLCu%2Fmeetup-rationality-meetup-vienna-7", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS87k57WyRQSS9BLCu%2Fmeetup-rationality-meetup-vienna-7", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 138, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18e'>Rationality Meetup Vienna</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">24 January 2015 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Kaiserm\u00fchlenstra\u00dfe 24/2, 1220 Wien</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the first meetup in 2015 everyone :)</p>\n\n<p>location: When arriving by U2 or Schnellbahn train: get out at station Stadlau take the exit towards Kaiserm\u00fchlenstra\u00dfe and simply cross the street the meetup is in the modern looking, greenish building right in front of your nose :) (you need to go through it, it's on the other side of the building)\nImportant: Google maps doesn't recognise the address and hence shows the wrong location...</p>\n\n<p>agenda:\n- as far as I remember we have Axel\ufeff's talk about chaos  theory and transactional analysis by Andreas\ufeff :)\n- if there is more time or they are not prepared, we can have another open mic session</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18e'>Rationality Meetup Vienna</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S87k57WyRQSS9BLCu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.3276510780196736e-06, "legacy": true, "legacyId": "27824", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Rationality_Meetup_Vienna\">Discussion article for the meetup : <a href=\"/meetups/18e\">Rationality Meetup Vienna</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">24 January 2015 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Kaiserm\u00fchlenstra\u00dfe 24/2, 1220 Wien</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the first meetup in 2015 everyone :)</p>\n\n<p>location: When arriving by U2 or Schnellbahn train: get out at station Stadlau take the exit towards Kaiserm\u00fchlenstra\u00dfe and simply cross the street the meetup is in the modern looking, greenish building right in front of your nose :) (you need to go through it, it's on the other side of the building)\nImportant: Google maps doesn't recognise the address and hence shows the wrong location...</p>\n\n<p>agenda:\n- as far as I remember we have Axel\ufeff's talk about chaos  theory and transactional analysis by Andreas\ufeff :)\n- if there is more time or they are not prepared, we can have another open mic session</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Rationality_Meetup_Vienna1\">Discussion article for the meetup : <a href=\"/meetups/18e\">Rationality Meetup Vienna</a></h2>", "sections": [{"title": "Discussion article for the meetup : Rationality Meetup Vienna", "anchor": "Discussion_article_for_the_meetup___Rationality_Meetup_Vienna", "level": 1}, {"title": "Discussion article for the meetup : Rationality Meetup Vienna", "anchor": "Discussion_article_for_the_meetup___Rationality_Meetup_Vienna1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T00:46:24.061Z", "modifiedAt": null, "url": null, "title": "Meetup : San Francisco Meetup", "slug": "meetup-san-francisco-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:09.112Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/34gt9qBLQphdaZdMA/meetup-san-francisco-meetup", "pageUrlRelative": "/posts/34gt9qBLQphdaZdMA/meetup-san-francisco-meetup", "linkUrl": "https://www.lesswrong.com/posts/34gt9qBLQphdaZdMA/meetup-san-francisco-meetup", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20San%20Francisco%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20San%20Francisco%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34gt9qBLQphdaZdMA%2Fmeetup-san-francisco-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20San%20Francisco%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34gt9qBLQphdaZdMA%2Fmeetup-san-francisco-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34gt9qBLQphdaZdMA%2Fmeetup-san-francisco-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 168, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18f'>San Francisco Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 January 2015 06:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1390 Market St., San Francisco, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>There doesn't appear to exist a San Francisco meetup group, so I'm starting one!</p>\n\n<p>The first meetup will start at 6:00 pm on Monday, Jan 12th, at Maia's and my apartment (1390 Market St., San Francisco, very near Civic Center BART/ Van Ness Muni). If you call me when you get to the lobby (301-458-0764) I can come let you in. Feel free to show up late: I'm sure some people will be commuting back from the South Bay or something and won't be able to make it by 6, for example.</p>\n\n<p>Things to talk about include:</p>\n\n<p>*Getting to know people!\n*Determining what people want out of the group.\n*Probably figuring out a better place than my apartment for future meetups.\n*Whatever you want to talk about.</p>\n\n<p>There are many restaurants nearby, so we can grab food later.</p>\n\n<p>Looking forward to seeing you then!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18f'>San Francisco Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "34gt9qBLQphdaZdMA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.3281591278500442e-06, "legacy": true, "legacyId": "27825", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___San_Francisco_Meetup\">Discussion article for the meetup : <a href=\"/meetups/18f\">San Francisco Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 January 2015 06:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1390 Market St., San Francisco, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>There doesn't appear to exist a San Francisco meetup group, so I'm starting one!</p>\n\n<p>The first meetup will start at 6:00 pm on Monday, Jan 12th, at Maia's and my apartment (1390 Market St., San Francisco, very near Civic Center BART/ Van Ness Muni). If you call me when you get to the lobby (301-458-0764) I can come let you in. Feel free to show up late: I'm sure some people will be commuting back from the South Bay or something and won't be able to make it by 6, for example.</p>\n\n<p>Things to talk about include:</p>\n\n<p>*Getting to know people!\n*Determining what people want out of the group.\n*Probably figuring out a better place than my apartment for future meetups.\n*Whatever you want to talk about.</p>\n\n<p>There are many restaurants nearby, so we can grab food later.</p>\n\n<p>Looking forward to seeing you then!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___San_Francisco_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/18f\">San Francisco Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : San Francisco Meetup", "anchor": "Discussion_article_for_the_meetup___San_Francisco_Meetup", "level": 1}, {"title": "Discussion article for the meetup : San Francisco Meetup", "anchor": "Discussion_article_for_the_meetup___San_Francisco_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T08:44:50.374Z", "modifiedAt": null, "url": null, "title": "Understanding Who You Really Are", "slug": "understanding-who-you-really-are", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:34.094Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ozziegooen", "createdAt": "2013-05-25T09:22:13.574Z", "isAdmin": false, "displayName": "ozziegooen"}, "userId": "efKySALtaLcvtp3jW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7Aq5N5py3vnRKc6eJ/understanding-who-you-really-are", "pageUrlRelative": "/posts/7Aq5N5py3vnRKc6eJ/understanding-who-you-really-are", "linkUrl": "https://www.lesswrong.com/posts/7Aq5N5py3vnRKc6eJ/understanding-who-you-really-are", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Understanding%20Who%20You%20Really%20Are&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUnderstanding%20Who%20You%20Really%20Are%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Aq5N5py3vnRKc6eJ%2Funderstanding-who-you-really-are%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Understanding%20Who%20You%20Really%20Are%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Aq5N5py3vnRKc6eJ%2Funderstanding-who-you-really-are", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Aq5N5py3vnRKc6eJ%2Funderstanding-who-you-really-are", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 486, "htmlBody": "<blockquote>\n<p class=\"p1\">Here are 14 ways in which you reveal who you really are. If you&rsquo;re brave enough, or if you dare, aim to share who you really are, little by little, everyday, with those you trust.</p>\n<p class=\"p1\">- A typical 'Who You Really Are' article on <a href=\"http://www.lifehack.org/articles/communication/14-ways-that-reveal-who-you-really-are.html\">Lifehack</a></p>\n</blockquote>\n<p class=\"p1\">Take a minute to consider the following questions.</p>\n<p class=\"p2\"><em>Who are you?</em><br /><em>Who&nbsp;are&nbsp;you, really? <br />Who do you really think you are inside?</em></p>\n<p class=\"p2\"><em><br /></em></p>\n<p class=\"p2\">It took me a full year to find the answer to these.&nbsp; The answer was that these questions, when posed as philosophical dilemmas, were bullshit.&nbsp; This post is not about &lsquo;understanding who you really are&rsquo;. It's about understanding, 'who you really are'.</p>\n<p class=\"p2\">&ldquo;Who are you&rdquo; is a question that sounds grandiose.&nbsp; It&rsquo;s hard to come up with a philosophically solid answer, and this makes it seem interesting.&nbsp; It is not interesting. &nbsp;It just lacks context.</p>\n<p class=\"p2\">What would you say if you were asked &ldquo;who are you?&rdquo; by the police?&nbsp; By a doctor? By a relative? By a potential boss? By a space alien?</p>\n<p class=\"p2\">You should say different things, because these people would be using the same words to mean different things.&nbsp;</p>\n<p class=\"p1\">What they really want is information about you that is of decision relevance to them. &nbsp; A police cares where you are from. The doctor cares how old you are. A relative cares about who you are related to. A boss cares what skills you have. A space alien cares about your number of eyes and hands.&nbsp; &ldquo;Who are you?&rdquo; really means, &ldquo;given your understanding of my position, what simple information about yourself do you think is useful to me?&rdquo;</p>\n<p class=\"p1\">So when a young philosopher follows up your response with, &ldquo;no really, who <em><strong>are</strong></em> you?&rdquo;, you should respond with asking, &ldquo;what in particular would you like to know?&rdquo;</p>\n<p class=\"p1\">Some may respond to this saying that there does exist a <em>true</em> self. A <em>real</em> self.&nbsp; This is what the phrase should really mean, and this is what I personally spent a year pondering.</p>\n<p class=\"p1\">But first, the very idea of there being a <em>true</em> <em>self</em> is specific to a set of religions and philosophies that you may not believe in.&nbsp; If you&rsquo;re a empirical atheist, you shouldn&rsquo;t.&nbsp; David Hume fought the notion of an inner self 250 years ago. [1] Derek Parfit fought it more concretely in the last 30 years. [2]</p>\n<p class=\"p1\">Second, even if you do ascribe to a belief system where there is some sort of <em>true </em>self, this would not give you a clear way to describe it.&nbsp; Should you say that you are a Capricorn inside?&nbsp; Or that a small fraction of your brain believes in Libertarianism?&nbsp; Or that you possess soul #988334?</p>\n<p class=\"p2\">Of course not.&nbsp; The question of &ldquo;who are you?&rdquo; is wrongly worded, and the one of &ldquo;who are you, really?&rdquo; should be placed on hold until the questioner can figure out what they are actually trying to ask. &nbsp;<span style=\"white-space: pre;\"> </span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p2\"><span style=\"white-space: pre;\"><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 13px; text-align: justify; white-space: normal;\">[1] <a href=\"https://askaphilosopher.wordpress.com/2013/01/22/david-humes-view-on-personal-identity/\">David Hume's view on Personal Identity</a>, Skinner (2013)<span style=\"white-space: pre;\"> </span></span></span></p>\n<p class=\"p2\"><span style=\"white-space: pre;\"><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 13px; text-align: justify; white-space: normal;\">[2] Reasons and Persons, Parfit (1986)</span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7Aq5N5py3vnRKc6eJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 10, "extendedScore": null, "score": 3.8e-05, "legacy": true, "legacyId": "27827", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T12:23:35.474Z", "modifiedAt": null, "url": null, "title": "Brain-centredness and mind uploading", "slug": "brain-centredness-and-mind-uploading", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:04.281Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gedymin", "createdAt": "2011-02-19T16:22:18.343Z", "isAdmin": false, "displayName": "gedymin"}, "userId": "xPg56rQ4KieN3rPtQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oQMZzr4jzzksdNdMe/brain-centredness-and-mind-uploading", "pageUrlRelative": "/posts/oQMZzr4jzzksdNdMe/brain-centredness-and-mind-uploading", "linkUrl": "https://www.lesswrong.com/posts/oQMZzr4jzzksdNdMe/brain-centredness-and-mind-uploading", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brain-centredness%20and%20mind%20uploading&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrain-centredness%20and%20mind%20uploading%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoQMZzr4jzzksdNdMe%2Fbrain-centredness-and-mind-uploading%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brain-centredness%20and%20mind%20uploading%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoQMZzr4jzzksdNdMe%2Fbrain-centredness-and-mind-uploading", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoQMZzr4jzzksdNdMe%2Fbrain-centredness-and-mind-uploading", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 926, "htmlBody": "<p>The <span class=\"st\">na&iuml;ve</span> way of understanding mind uploading is \"we take the connectome of a brain, including synaptic connection weights and characters, and emulate it in a computer\". However, people want their <em>personalities</em> to be uploaded, not just brains. That is more than just replicating the functionality of their brains <em>in silico.</em></p>\n<p>This nuance has lead to some misunderstandings, for example, to experts wondering [1] why on Earth would anyone think that brain-centredness [2] (the idea that brains are \"sufficient\" in some vague sense) is a necessary prerequisite for successful whole brain emulation. Of course, brain-centredness is not required for <em>brain</em> uploading to be technically successful; the problem is whether it is sufficient for <em>mind</em> uploading in the sense that people actually care about?</p>\n<p>&nbsp;</p>\n<p>The first obvious extension that may be required is the chemical environment of the brain. Here are some examples:</p>\n<ul>\n<li>Are you familiar with someone whose personality is radically (and often predictability) altered under influence of alcohol or drugs? This is not an exception, but a rule: most are impacted by this, only to a smaller extent. Only the transiency of the effects allow us to label them as simple mood changes.</li>\n<li>I have observed that my personal levels of neuroticism vary depending on the pharmaceutical drugs I'm using. Nootropics make me more nervous, while anti-hypertensions drugs have the reverse effect.</li>\n<li>The levels of hormones in the blood function as long-term personality changes. There are neurotransmitters that themselves are slow-acting, for example, nitric oxide [3].</li>\n<li>Artificially enchanted levels of serotonin in the brain causes it to \"adapt\" to this environment - in this way some of antidepressants work (namely, SSRI) [4].</li>\n</ul>\n<p><a href=\"http://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pd\">Whole Brain Emulation - A Roadmap</a> includes a short section about the \"Body chemical environment\" and concludes that for \"WBE, the body chemistry model, while involved, would be relatively simple\", unless protein interactions have to be modelled.</p>\n<p>The technical aspect notwithstanding, what are the practical and moral implications? I think that here's not only a problem, but also an opportunity. Why keep the accidental chemistry we have developed in our lifetimes, one that presumably has little relation to what we would really <em>like</em> to be - if we could? Imagine that it is possible to create carefully improved and tailored versions of the neurotransmitter \"soup\" in the brain. There are new possibilities here for personal growth in ways that have not been possible before. These ways are completely orthogonal to the intelligence enhancement opportunities commonly associated with uploading.</p>\n<p>The question of personal identity is more difficult, and there appears to be a grey zone here. A fictional example of the protagonist in <em>Planescape: Torment</em> comes into mind - is he the <em>same</em> person in each of his incarnations?</p>\n<p>&nbsp;</p>\n<p>The second extension required to upload our personalities in the fullest sense might be the peripheral nervous system. Most of us think it's the brain that's responsible for emotions, but this is a simplified picture. Here are some hints why:</p>\n<ul>\n<li>The James-Lange 19th century theory of emotions proposed that we experience emotion in response <em>to</em> physiological changes in our body. For example, we feel sad because we cry rather than cry because we are sad [5]. While the modern understanding of emotions is significantly different, these ideas have not completely gone away neither from academic research [5] nor everyday life. For example, to calm down, we are suggested to take deep and slow breaths. Paraplegics and quadriplegics, with severe spinal cord injuries typically experience less intense emotions than other people [6].</li>\n<li>Endoscopic thoracic sympathectomy (ETS) is a surgical procedure in which a portion of the sympathetic nerve trunk in the thoracic region is destroyed [7]. It is typically used against excessive hand sweating. However, \"a large study of psychiatric patients treated with this surgery [also] showed <em>significant reductions in fear, alertness and arousal</em> [..] A severe possible consequence of thoracic sympathectomy is corposcindosis (split-body syndrome) [..] In 2003 ETS was banned in Sweden due to overwhelming complaints by disabled patients.\" The complaints include having not been able to lead emotional life as fully as before the operation.</li>\n<li>The enteric nervous system in the stomach \"governs the function of the gastrointestinal system\" [8]. I'm not sure how solid the research is, but there are a lot of articles on the Web that mention the importance of this system to our mood and well being [9]. Serotonin is \"the happiness neurotransmitter\" and \"in fact 95 percent of the body's serotonin is found in the bowels\", as are 50% of dopamine [8]. \"Gut bacteria may influence thoughts and behaviour\" [10] by using the serotonin mechanism. Also, \"Irritable bowel syndrome is associated with psychiatric illness\" [10].</li>\n</ul>\n<p>&nbsp;</p>\n<p>In short, different chemistry in the brain changes what we are, as does the peripheral nervous system. To upload someone in the fullest sense, his/her chemistry and PNS also have to be uploaded.</p>\n<p>[1] <a href=\"https://intelligence.org/2014/03/20/randal-a-koene-on-whole-brain-emulation/\">Randal Koene on whole brain emulation</a></p>\n<p>[2] Anders Sandberg, Nick Bostrom, Future of Humanity Institute, <a href=\"http://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pd\">Whole Brain Emulation - A Roadmap</a>.</p>\n<p>[3] Bradley Voytek's (Ph.D. neuroscience) Quora answer to <a href=\"http://www.quora.com/Will-human-consciousness-ever-be-transferrable\">Will human consciousness ever be transferrable?</a><br /><br />[4] <a href=\"http://en.wikipedia.org/wiki/Selective_serotonin_reuptake_inhibitor\">Selective serotonin reuptake inhibitors</a><br /><br />[5] Bear et al. Neuroscience: Exploring the Brain, 3rd edition. Page 564.<br /><br />[6] Michael W. Eysenck - Perspectives On Psychology - Page 100 - <a href=\"https://books.google.se/books?isbn=1317775333\">Google Books Result</a><br /><br />[7] <a href=\"http://en.wikipedia.org/wiki/Endoscopic_thoracic_sympathectomy\">Endoscopic thoracic sympathectomy</a><br /><br />[8] <a href=\"http://en.wikipedia.org/wiki/Enteric_nervous_system\">Enteric nervous system</a><br /><br />[9] Scientific American, 2010. <a href=\"http://www.scientificamerican.com/article/gut-second-brain/\">Think Twice: How the Gut's \"Second Brain\" Influences Mood and Well-Being</a></p>\n<p>[10] The Guardian, 2012. <a href=\"http://www.theguardian.com/science/neurophilosophy/2012/aug/19/microbes-manipulate-your-mind\">Microbes manipulate your mind</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jQytxyauJ7kPhhGj3": 2, "5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oQMZzr4jzzksdNdMe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 24, "extendedScore": null, "score": 2.3297935281468217e-06, "legacy": true, "legacyId": "27828", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T15:48:16.283Z", "modifiedAt": null, "url": null, "title": "[Link] Neural networks trained on expert Go games have just made a major leap", "slug": "link-neural-networks-trained-on-expert-go-games-have-just", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.595Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ESRogs", "createdAt": "2011-01-05T21:50:53.170Z", "isAdmin": false, "displayName": "ESRogs"}, "userId": "dRGmZYGDzf5LFNjtz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WjoPDTdTRaiLzMnQS/link-neural-networks-trained-on-expert-go-games-have-just", "pageUrlRelative": "/posts/WjoPDTdTRaiLzMnQS/link-neural-networks-trained-on-expert-go-games-have-just", "linkUrl": "https://www.lesswrong.com/posts/WjoPDTdTRaiLzMnQS/link-neural-networks-trained-on-expert-go-games-have-just", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Neural%20networks%20trained%20on%20expert%20Go%20games%20have%20just%20made%20a%20major%20leap&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Neural%20networks%20trained%20on%20expert%20Go%20games%20have%20just%20made%20a%20major%20leap%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWjoPDTdTRaiLzMnQS%2Flink-neural-networks-trained-on-expert-go-games-have-just%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Neural%20networks%20trained%20on%20expert%20Go%20games%20have%20just%20made%20a%20major%20leap%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWjoPDTdTRaiLzMnQS%2Flink-neural-networks-trained-on-expert-go-games-have-just", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWjoPDTdTRaiLzMnQS%2Flink-neural-networks-trained-on-expert-go-games-have-just", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 530, "htmlBody": "<p>From the <a href=\"http://arxiv.org/abs/1412.6564\">arXiv</a>:</p>\n<blockquote>\n<p><strong>Move Evaluation in Go Using Deep Convolutional Neural Networks</strong></p>\n<p>Chris J. Maddison, Aja Huang, Ilya Sutskever, David Silver</p>\n<p>The game of Go is more challenging than other board games, due to the difficulty of constructing a position or move evaluation function. In this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge. We train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates a million positions per move.</p>\n</blockquote>\n<p>This approach looks like it could be combined with MCTS. Here's their conclusion:</p>\n<blockquote>\n<p>In this work, we showed that large deep convolutional neural networks can predict the next move made by Go experts with an accuracy that exceeds previous methods by a large margin, approximately matching human performance. Furthermore, this predictive accuracy translates into much stronger move evaluation and playing strength than has previously been possible. Without any search, the network is able to outperform traditional search based programs such as GnuGo, and compete with state-of-the-art MCTS programs such as Pachi and Fuego.</p>\n<p>In Figure 2 we present a sample game played by the 12-layer CNN (with no search) versus Fuego (searching 100K rollouts per move) which was won by the neural network player. It is clear that the neural network has implicitly understood many sophisticated aspects of Go, including good shape (patterns that maximise long term effectiveness of stones), Fuseki (opening sequences), Joseki (corner patterns), Tesuji (tactical patterns), Ko fights (intricate tactical battles involving repeated recapture of the same stones), territory (ownership of points), and influence (long-term potential for territory). It is remarkable that a single, unified, straightforward architecture can master these elements of the game to such a degree, and without any explicit lookahead.</p>\n<p>On the other hand, we note that the network still has weaknesses: notably it sometimes fails to understand the global picture, behaving as if the life and death status of large groups has been incorrectly assessed. Interestingly, it is precisely these global aspects of the game for which Monte-Carlo search excels, suggesting that these two techniques may be largely complementary. We have provided a preliminary proof-of-concept that MCTS and deep neural networks may be combined effectively. It appears that we now have two core elements that scale effectively with increased computational resource: scalable planning, using Monte-Carlo search; and scalable evaluation functions, using deep neural networks. In the future, as parallel computation units such as GPUs continue to increase in performance, we believe that this trajectory of research will lead to considerably stronger programs than are currently possible.</p>\n</blockquote>\n<p>H/T: <a href=\"http://rjlipton.wordpress.com/2014/12/28/the-new-chess-world-champion/\">Ken Regan</a></p>\n<p>Edit -- see also:&nbsp;<a href=\"http://arxiv.org/abs/1412.3409\">Teaching Deep Convolutional Neural Networks to Play Go</a>&nbsp;(also published to the arXiv in December 2014), and&nbsp;<a href=\"http://www.technologyreview.com/view/533496/why-neural-networks-look-set-to-thrash-the-best-human-go-players-for-the-first-time/\">Why Neural Networks Look Set to Thrash the Best Human Go Players for the First Time</a> (MIT Technology Review article)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WjoPDTdTRaiLzMnQS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 24, "extendedScore": null, "score": 2.330273738660223e-06, "legacy": true, "legacyId": "27829", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T16:34:47.923Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-63", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MBhbNypRZbC4Fa2xR/weekly-lw-meetups-63", "pageUrlRelative": "/posts/MBhbNypRZbC4Fa2xR/weekly-lw-meetups-63", "linkUrl": "https://www.lesswrong.com/posts/MBhbNypRZbC4Fa2xR/weekly-lw-meetups-63", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBhbNypRZbC4Fa2xR%2Fweekly-lw-meetups-63%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBhbNypRZbC4Fa2xR%2Fweekly-lw-meetups-63", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBhbNypRZbC4Fa2xR%2Fweekly-lw-meetups-63", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 480, "htmlBody": "<p><strong>This summary was posted to LW Main on December 26th. The following week's summary is <a href=\"/lw/lh2/new_lw_meetups_paris_san_francisco/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/17w\">Atlanta December Meetup - Game Night!:&nbsp;<span class=\"date\">27 December 2014 07:00AM</span></a></li>\n<li><a href=\"/meetups/15w\">European Community Weekend 2015:&nbsp;<span class=\"date\">12 June 2015 12:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<li><a href=\"/meetups/17c\">Utrecht: a critique of effective altruism:&nbsp;<span class=\"date\">04 January 2015 02:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX - Caffe Medici:&nbsp;<span class=\"date\">03 January 2026 01:30PM</span></a></li>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li style=\"margin: 0px 0px 5px;\"><a style=\"color: #8a8a8b;\" href=\"/meetups/185\">Washington, D.C.: Mini Talks + Socializing:&nbsp;<span class=\"date\">28 December 2014 03:00PM</span></a></li>\n</div>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\">Berlin</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Boston.2C_MA\">Boston</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Brussels.2C_Belgium\">Brussels</a></strong><strong>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Buffalo.2C_NY\">Buffalo</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Canberra\">Canberra</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Columbus.2C_OH\">Columbus</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Moscow.2C_Russia\">Moscow</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Philadelphia.2C_PA\">Philadelphia</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Research_Triangle.2C_NC_.28Raleigh.2FDurham.2FChapel_Hill.29\">Research Triangle NC</a>,</strong><strong>&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Sydney\">Sydney</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a></strong><strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington DC</strong></a></strong>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.</p>\n<p><a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview is posted on the front page every Friday. These are an attempt to collect information on all the meetups happening in upcoming weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll also have the benefit of having your meetup mentioned in a weekly overview. These overview posts are moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cincinnati</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cleveland</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> </strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tel_Aviv.2C_Israel\">Tel Aviv</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Warsaw.2C_Poland\">Warsaw</a></strong><strong>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MBhbNypRZbC4Fa2xR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.3303829232416925e-06, "legacy": true, "legacyId": "27784", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BPGPmYwjoKLjLeXZ7", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T20:04:48.211Z", "modifiedAt": null, "url": null, "title": "Meetup : Boston: Antifragile", "slug": "meetup-boston-antifragile", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Anders_H", "createdAt": "2013-07-28T20:46:58.747Z", "isAdmin": false, "displayName": "Anders_H"}, "userId": "jfdosp4Hn7tFNbf9k", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WxvwbspC2BupxCLgp/meetup-boston-antifragile", "pageUrlRelative": "/posts/WxvwbspC2BupxCLgp/meetup-boston-antifragile", "linkUrl": "https://www.lesswrong.com/posts/WxvwbspC2BupxCLgp/meetup-boston-antifragile", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Boston%3A%20Antifragile&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Boston%3A%20Antifragile%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWxvwbspC2BupxCLgp%2Fmeetup-boston-antifragile%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Boston%3A%20Antifragile%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWxvwbspC2BupxCLgp%2Fmeetup-boston-antifragile", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWxvwbspC2BupxCLgp%2Fmeetup-boston-antifragile", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 213, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18g'>Boston: Antifragile</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 January 2015 03:30:33PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">98 Elm Street, Somerville</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This Sunday, Jesse Galef will be reviewing the book Antifragile, by Nassim Nicholas Taleb, author of The Black Swan.  Topics will include effective decision making, catastrophic risk, and pop culture references.</p>\n\n<p>Reviews of Antifragile:</p>\n\n<p>\"The glossary alone offered more thought-provoking ideas than any other nonfiction book I read this year. That said, Antifragile is far from flawless.\"</p>\n\n<p>\"As always, an imperfect, infuriating but intriguing book\"</p>\n\n<p>\"A big mixed bag of insights and misconceptions\"</p>\n\n<p>Cambridge/Boston-area Less Wrong meetups start at 3:30pm, and have an alternating location:</p>\n\n<ul>\n<li><p>1st Sunday meetups are at Citadel in Porter Sq, at 98 Elm St, apt 1, Somerville.</p></li>\n<li><p>3rd Sunday meetups are in MIT's building 66 at 25 Ames St, room 156. Room number subject to change based on availability; signs will be posted with the actual room number.</p></li>\n</ul>\n\n<p>(We also have last Wednesday meetups at Citadel at 7pm.)</p>\n\n<p>Our default schedule is as follows:</p>\n\n<p>\u2014Phase 1: Arrival, greetings, unstructured conversation.</p>\n\n<p>\u2014Phase 2: The headline event. This starts promptly at 4pm, and lasts 30-60 minutes.</p>\n\n<p>\u2014Phase 3: Further discussion. We'll explore the ideas raised in phase 2, often in smaller groups.</p>\n\n<p>\u2014Phase 4: Dinner.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18g'>Boston: Antifragile</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WxvwbspC2BupxCLgp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.3308758490521827e-06, "legacy": true, "legacyId": "27831", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Boston__Antifragile\">Discussion article for the meetup : <a href=\"/meetups/18g\">Boston: Antifragile</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 January 2015 03:30:33PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">98 Elm Street, Somerville</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This Sunday, Jesse Galef will be reviewing the book Antifragile, by Nassim Nicholas Taleb, author of The Black Swan.  Topics will include effective decision making, catastrophic risk, and pop culture references.</p>\n\n<p>Reviews of Antifragile:</p>\n\n<p>\"The glossary alone offered more thought-provoking ideas than any other nonfiction book I read this year. That said, Antifragile is far from flawless.\"</p>\n\n<p>\"As always, an imperfect, infuriating but intriguing book\"</p>\n\n<p>\"A big mixed bag of insights and misconceptions\"</p>\n\n<p>Cambridge/Boston-area Less Wrong meetups start at 3:30pm, and have an alternating location:</p>\n\n<ul>\n<li><p>1st Sunday meetups are at Citadel in Porter Sq, at 98 Elm St, apt 1, Somerville.</p></li>\n<li><p>3rd Sunday meetups are in MIT's building 66 at 25 Ames St, room 156. Room number subject to change based on availability; signs will be posted with the actual room number.</p></li>\n</ul>\n\n<p>(We also have last Wednesday meetups at Citadel at 7pm.)</p>\n\n<p>Our default schedule is as follows:</p>\n\n<p>\u2014Phase 1: Arrival, greetings, unstructured conversation.</p>\n\n<p>\u2014Phase 2: The headline event. This starts promptly at 4pm, and lasts 30-60 minutes.</p>\n\n<p>\u2014Phase 3: Further discussion. We'll explore the ideas raised in phase 2, often in smaller groups.</p>\n\n<p>\u2014Phase 4: Dinner.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Boston__Antifragile1\">Discussion article for the meetup : <a href=\"/meetups/18g\">Boston: Antifragile</a></h2>", "sections": [{"title": "Discussion article for the meetup : Boston: Antifragile", "anchor": "Discussion_article_for_the_meetup___Boston__Antifragile", "level": 1}, {"title": "Discussion article for the meetup : Boston: Antifragile", "anchor": "Discussion_article_for_the_meetup___Boston__Antifragile1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T20:46:03.143Z", "modifiedAt": null, "url": null, "title": "[Link]How to Achieve Impossible Career Goals (My manifesto on instrumental rationality)", "slug": "link-how-to-achieve-impossible-career-goals-my-manifesto-on", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:03.848Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "NSwhLgrpoR65LQCfK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AzkYNFwERLKrDSimn/link-how-to-achieve-impossible-career-goals-my-manifesto-on", "pageUrlRelative": "/posts/AzkYNFwERLKrDSimn/link-how-to-achieve-impossible-career-goals-my-manifesto-on", "linkUrl": "https://www.lesswrong.com/posts/AzkYNFwERLKrDSimn/link-how-to-achieve-impossible-career-goals-my-manifesto-on", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5DHow%20to%20Achieve%20Impossible%20Career%20Goals%20(My%20manifesto%20on%20instrumental%20rationality)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5DHow%20to%20Achieve%20Impossible%20Career%20Goals%20(My%20manifesto%20on%20instrumental%20rationality)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzkYNFwERLKrDSimn%2Flink-how-to-achieve-impossible-career-goals-my-manifesto-on%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5DHow%20to%20Achieve%20Impossible%20Career%20Goals%20(My%20manifesto%20on%20instrumental%20rationality)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzkYNFwERLKrDSimn%2Flink-how-to-achieve-impossible-career-goals-my-manifesto-on", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzkYNFwERLKrDSimn%2Flink-how-to-achieve-impossible-career-goals-my-manifesto-on", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 174, "htmlBody": "<p>Hey guys,</p>\n<p>Don't normally post from my blog to here, but the latest<a href=\"http://selfmaderenegade.net/impossible-career-goals/\"> massive post on goal achievement in 2015 </a>has a ton that would be relevant to people here.</p>\n<p>Some things that I think would be of particular interest to LWers:</p>\n<p>&nbsp;</p>\n<ul>\n<li>The section called \"Map the Path to Your Goal\" has some really great stuff on planning that haven't seen many other places. I know planning gets a bad wrap here, but when combined with the \"Contigency Plans\" method near the bottom of the post, I've found this stuff to be killer for getting results for students.</li>\n<li>At the bottom, there's a section called \"Choosing More Habits\" that breaks down habits into the only five categories you should ever focus on. If you're planning to systematically take on new habits in 2015, this will help.</li>\n<li>The section called \"a proactive mindset\" has some fun mental reframes to play around with.</li>\n</ul>\n<div>Anyways, would love feedback and thoughts. Feel free to comment here or on the bottom of that post.</div>\n<div><br /></div>\n<div>Thanks!</div>\n<div>Matt</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AzkYNFwERLKrDSimn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 5.2e-05, "legacy": true, "legacyId": "27833", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T22:20:04.561Z", "modifiedAt": null, "url": null, "title": "Meetup : Montreal Less Wrong/Effective Altruism - 8, 760 hours: Setting goals for 2015", "slug": "meetup-montreal-less-wrong-effective-altruism-8-760-hours", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bartimaeus", "createdAt": "2013-05-07T17:14:04.389Z", "isAdmin": false, "displayName": "bartimaeus"}, "userId": "mqWrbcZHzhfPLnJqg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7dzbALekQgCSSbXKE/meetup-montreal-less-wrong-effective-altruism-8-760-hours", "pageUrlRelative": "/posts/7dzbALekQgCSSbXKE/meetup-montreal-less-wrong-effective-altruism-8-760-hours", "linkUrl": "https://www.lesswrong.com/posts/7dzbALekQgCSSbXKE/meetup-montreal-less-wrong-effective-altruism-8-760-hours", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Montreal%20Less%20Wrong%2FEffective%20Altruism%20-%208%2C%20760%20hours%3A%20Setting%20goals%20for%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Montreal%20Less%20Wrong%2FEffective%20Altruism%20-%208%2C%20760%20hours%3A%20Setting%20goals%20for%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7dzbALekQgCSSbXKE%2Fmeetup-montreal-less-wrong-effective-altruism-8-760-hours%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Montreal%20Less%20Wrong%2FEffective%20Altruism%20-%208%2C%20760%20hours%3A%20Setting%20goals%20for%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7dzbALekQgCSSbXKE%2Fmeetup-montreal-less-wrong-effective-altruism-8-760-hours", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7dzbALekQgCSSbXKE%2Fmeetup-montreal-less-wrong-effective-altruism-8-760-hours", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18h'>Montreal Less Wrong/Effective Altruism - 8, 760 hours: Setting goals for 2015</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">08 January 2015 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1720 st denis montreal</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The end of a year is the perfect time to review one\u2019s life, goals, plans, and projects, as well as plan for the upcoming year. Alex Vemeer has been fine-tuning his own review process for several years, and it's a great model to start with. We'll take some time to brainstorm how 2014 went for us, what went great, what needs improvement, and we'll set some milestones for 2015.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18h'>Montreal Less Wrong/Effective Altruism - 8, 760 hours: Setting goals for 2015</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7dzbALekQgCSSbXKE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3311934599263583e-06, "legacy": true, "legacyId": "27835", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Montreal_Less_Wrong_Effective_Altruism___8__760_hours__Setting_goals_for_2015\">Discussion article for the meetup : <a href=\"/meetups/18h\">Montreal Less Wrong/Effective Altruism - 8, 760 hours: Setting goals for 2015</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">08 January 2015 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1720 st denis montreal</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The end of a year is the perfect time to review one\u2019s life, goals, plans, and projects, as well as plan for the upcoming year. Alex Vemeer has been fine-tuning his own review process for several years, and it's a great model to start with. We'll take some time to brainstorm how 2014 went for us, what went great, what needs improvement, and we'll set some milestones for 2015.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Montreal_Less_Wrong_Effective_Altruism___8__760_hours__Setting_goals_for_20151\">Discussion article for the meetup : <a href=\"/meetups/18h\">Montreal Less Wrong/Effective Altruism - 8, 760 hours: Setting goals for 2015</a></h2>", "sections": [{"title": "Discussion article for the meetup : Montreal Less Wrong/Effective Altruism - 8, 760 hours: Setting goals for 2015", "anchor": "Discussion_article_for_the_meetup___Montreal_Less_Wrong_Effective_Altruism___8__760_hours__Setting_goals_for_2015", "level": 1}, {"title": "Discussion article for the meetup : Montreal Less Wrong/Effective Altruism - 8, 760 hours: Setting goals for 2015", "anchor": "Discussion_article_for_the_meetup___Montreal_Less_Wrong_Effective_Altruism___8__760_hours__Setting_goals_for_20151", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-02T23:46:21.454Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow: bayes, language and psychology, now with homework", "slug": "meetup-moscow-bayes-language-and-psychology-now-with", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BT_Uytya", "createdAt": "2011-12-03T16:41:14.863Z", "isAdmin": false, "displayName": "BT_Uytya"}, "userId": "Enh7Ap3zRTQDR4gMH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YHcBBtFSGaiJSSqv4/meetup-moscow-bayes-language-and-psychology-now-with", "pageUrlRelative": "/posts/YHcBBtFSGaiJSSqv4/meetup-moscow-bayes-language-and-psychology-now-with", "linkUrl": "https://www.lesswrong.com/posts/YHcBBtFSGaiJSSqv4/meetup-moscow-bayes-language-and-psychology-now-with", "postedAtFormatted": "Friday, January 2nd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%3A%20bayes%2C%20language%20and%20psychology%2C%20now%20with%20homework&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%3A%20bayes%2C%20language%20and%20psychology%2C%20now%20with%20homework%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYHcBBtFSGaiJSSqv4%2Fmeetup-moscow-bayes-language-and-psychology-now-with%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%3A%20bayes%2C%20language%20and%20psychology%2C%20now%20with%20homework%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYHcBBtFSGaiJSSqv4%2Fmeetup-moscow-bayes-language-and-psychology-now-with", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYHcBBtFSGaiJSSqv4%2Fmeetup-moscow-bayes-language-and-psychology-now-with", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 241, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18i'>Moscow: bayes, language and psychology, now with homework</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 January 2015 03:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Moscow, ulitsa L'va Tolstogo 16 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hello there.</p>\n\n<p>If you don't have plans for the Sunday but aware of Bayes' theorem in odds form, you certainly will be welcome here.</p>\n\n<p>Our plan for 4th is:</p>\n\n<ul>\n<li><p>Victor will try to explain the device of imaginary results by I J Good, himself gaining a deeper understanding of it in the process (yup, it's the same guy who <a href=\"http://lesswrong.com/lw/h54/i_need_help_device_of_imaginary_results_by_i_j/\">posted this</a>. I'm still a bit confused about Caesar, but I think I understand the big picture now. Let's tackle this together, it should be interesting and educating);</p></li>\n<li><p>Varman will give a short talk on exosemantics. Surprisingly, the usual lack of political correctness isn't included (but counter-signalling and in-group bashing are still here, <em>of course</em>)</p></li>\n<li><p>Natalia will tell you why do you need to know the very basics of behaviorism to properly analyze things like social interactions, and how exactly the use of more complex models could led you to a trouble.</p></li>\n</ul>\n\n<p>Please do your homework and make sure you are familiar with the odds form of Bayes' theorem and know something about biofeedback.</p>\n\n<p>PS: No, we aren't implying that behaviorism is enough to understand things. But it <em>is</em> necessary.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18i'>Moscow: bayes, language and psychology, now with homework</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YHcBBtFSGaiJSSqv4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.331396083326604e-06, "legacy": true, "legacyId": "27838", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow__bayes__language_and_psychology__now_with_homework\">Discussion article for the meetup : <a href=\"/meetups/18i\">Moscow: bayes, language and psychology, now with homework</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 January 2015 03:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Moscow, ulitsa L'va Tolstogo 16 </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hello there.</p>\n\n<p>If you don't have plans for the Sunday but aware of Bayes' theorem in odds form, you certainly will be welcome here.</p>\n\n<p>Our plan for 4th is:</p>\n\n<ul>\n<li><p>Victor will try to explain the device of imaginary results by I J Good, himself gaining a deeper understanding of it in the process (yup, it's the same guy who <a href=\"http://lesswrong.com/lw/h54/i_need_help_device_of_imaginary_results_by_i_j/\">posted this</a>. I'm still a bit confused about Caesar, but I think I understand the big picture now. Let's tackle this together, it should be interesting and educating);</p></li>\n<li><p>Varman will give a short talk on exosemantics. Surprisingly, the usual lack of political correctness isn't included (but counter-signalling and in-group bashing are still here, <em>of course</em>)</p></li>\n<li><p>Natalia will tell you why do you need to know the very basics of behaviorism to properly analyze things like social interactions, and how exactly the use of more complex models could led you to a trouble.</p></li>\n</ul>\n\n<p>Please do your homework and make sure you are familiar with the odds form of Bayes' theorem and know something about biofeedback.</p>\n\n<p>PS: No, we aren't implying that behaviorism is enough to understand things. But it <em>is</em> necessary.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow__bayes__language_and_psychology__now_with_homework1\">Discussion article for the meetup : <a href=\"/meetups/18i\">Moscow: bayes, language and psychology, now with homework</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow: bayes, language and psychology, now with homework", "anchor": "Discussion_article_for_the_meetup___Moscow__bayes__language_and_psychology__now_with_homework", "level": 1}, {"title": "Discussion article for the meetup : Moscow: bayes, language and psychology, now with homework", "anchor": "Discussion_article_for_the_meetup___Moscow__bayes__language_and_psychology__now_with_homework1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KZLjTt3FWGhCvZSGu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-03T00:23:22.997Z", "modifiedAt": null, "url": null, "title": "Non-obvious skills with highly measurable progress?", "slug": "non-obvious-skills-with-highly-measurable-progress", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.523Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "robot-dreams", "createdAt": "2014-08-12T23:23:33.596Z", "isAdmin": false, "displayName": "robot-dreams"}, "userId": "6z6xB35aPvA4dWTht", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dHdW6M5hzn8Fupvzh/non-obvious-skills-with-highly-measurable-progress", "pageUrlRelative": "/posts/dHdW6M5hzn8Fupvzh/non-obvious-skills-with-highly-measurable-progress", "linkUrl": "https://www.lesswrong.com/posts/dHdW6M5hzn8Fupvzh/non-obvious-skills-with-highly-measurable-progress", "postedAtFormatted": "Saturday, January 3rd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Non-obvious%20skills%20with%20highly%20measurable%20progress%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANon-obvious%20skills%20with%20highly%20measurable%20progress%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdHdW6M5hzn8Fupvzh%2Fnon-obvious-skills-with-highly-measurable-progress%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Non-obvious%20skills%20with%20highly%20measurable%20progress%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdHdW6M5hzn8Fupvzh%2Fnon-obvious-skills-with-highly-measurable-progress", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdHdW6M5hzn8Fupvzh%2Fnon-obvious-skills-with-highly-measurable-progress", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<p>A lot of my significant personal improvement happened as a result of highly measurable progress and tight feedback loops. &nbsp;For example:</p>\n<p>\n<ul>\n<li>Project Euler</li>\n<li>Go (the game has a very accurate ranking system)</li>\n<li>Strength training</li>\n</ul>\n<div>However, these are somewhat obvious examples, and I feel like it would be a waste not to push such a useful improvement mechanism as far as possible.</div>\n<div><br /></div>\n<div>What are some non-obvious examples of skills with highly measurable progress and tight feedback loops?</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dHdW6M5hzn8Fupvzh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 21, "extendedScore": null, "score": 2.3314830439698003e-06, "legacy": true, "legacyId": "27839", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-03T05:13:57.990Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington, D.C.: Argument from Silence", "slug": "meetup-washington-d-c-argument-from-silence", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HtTe83CFy4mtLiRCk/meetup-washington-d-c-argument-from-silence", "pageUrlRelative": "/posts/HtTe83CFy4mtLiRCk/meetup-washington-d-c-argument-from-silence", "linkUrl": "https://www.lesswrong.com/posts/HtTe83CFy4mtLiRCk/meetup-washington-d-c-argument-from-silence", "postedAtFormatted": "Saturday, January 3rd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%2C%20D.C.%3A%20Argument%20from%20Silence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%2C%20D.C.%3A%20Argument%20from%20Silence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHtTe83CFy4mtLiRCk%2Fmeetup-washington-d-c-argument-from-silence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%2C%20D.C.%3A%20Argument%20from%20Silence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHtTe83CFy4mtLiRCk%2Fmeetup-washington-d-c-argument-from-silence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHtTe83CFy4mtLiRCk%2Fmeetup-washington-d-c-argument-from-silence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 234, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18j'>Washington, D.C.: Argument from Silence</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 January 2015 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><em>Because of the late posting of the announcement, we are postponing the Meta Meetup to next week to give people more prep time.</em></p>\n\n<p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>discuss the argument from silence.</strong> As usual, we will congregate between 3:00 and 3:30 and begin at 3:30.</p>\n\n<p>The term \"<a href=\"http://en.wikipedia.org/wiki/Argument_from_silence\" rel=\"nofollow\">argument from silence</a>\" here refers to a special case of <a href=\"http://lesswrong.com/lw/ih/absence_of_evidence_is_evidence_of_absence/\">absence of evidence being used as evidence of absence</a>: specifically, when something is missing from a particular corpus of writings that a given historian would have expected to be present. We hope in this discussion to improve people's ability to evaluate the strength of negative evidence with these examples. As always, initiating and participating in side discussions when desired is both allowed and encouraged.</p>\n\n<p>There are no announced disruptions on the Metro for this weekend; however, <a href=\"http://wmata.com/rider_tools/metro_service_status/advisories.cfm?AID=4639\" rel=\"nofollow\">trains will be only six cars long due to anticipated light ridership.</a></p>\n\n<p><strong>Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 11: Meta Meetup</strong> (what you like, what you want, what you'd change)</li>\n<li><strong>Jan. 18: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18j'>Washington, D.C.: Argument from Silence</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HtTe83CFy4mtLiRCk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.332165723331432e-06, "legacy": true, "legacyId": "27840", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Argument_from_Silence\">Discussion article for the meetup : <a href=\"/meetups/18j\">Washington, D.C.: Argument from Silence</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 January 2015 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><em>Because of the late posting of the announcement, we are postponing the Meta Meetup to next week to give people more prep time.</em></p>\n\n<p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>discuss the argument from silence.</strong> As usual, we will congregate between 3:00 and 3:30 and begin at 3:30.</p>\n\n<p>The term \"<a href=\"http://en.wikipedia.org/wiki/Argument_from_silence\" rel=\"nofollow\">argument from silence</a>\" here refers to a special case of <a href=\"http://lesswrong.com/lw/ih/absence_of_evidence_is_evidence_of_absence/\">absence of evidence being used as evidence of absence</a>: specifically, when something is missing from a particular corpus of writings that a given historian would have expected to be present. We hope in this discussion to improve people's ability to evaluate the strength of negative evidence with these examples. As always, initiating and participating in side discussions when desired is both allowed and encouraged.</p>\n\n<p>There are no announced disruptions on the Metro for this weekend; however, <a href=\"http://wmata.com/rider_tools/metro_service_status/advisories.cfm?AID=4639\" rel=\"nofollow\">trains will be only six cars long due to anticipated light ridership.</a></p>\n\n<p><strong id=\"Upcoming_meetups_\">Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 11: Meta Meetup</strong> (what you like, what you want, what you'd change)</li>\n<li><strong>Jan. 18: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Argument_from_Silence1\">Discussion article for the meetup : <a href=\"/meetups/18j\">Washington, D.C.: Argument from Silence</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington, D.C.: Argument from Silence", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Argument_from_Silence", "level": 1}, {"title": "Upcoming meetups:", "anchor": "Upcoming_meetups_", "level": 2}, {"title": "Discussion article for the meetup : Washington, D.C.: Argument from Silence", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Argument_from_Silence1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mnS2WYLCGJP2kQkRn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-03T06:11:19.710Z", "modifiedAt": null, "url": null, "title": "The Superstar Effect", "slug": "the-superstar-effect", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.840Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "adamzerner", "createdAt": "2013-08-12T18:18:47.957Z", "isAdmin": false, "displayName": "adamzerner"}, "userId": "6jLdWqegNefgaabhr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aRv9PzpFvMEwBfSrn/the-superstar-effect", "pageUrlRelative": "/posts/aRv9PzpFvMEwBfSrn/the-superstar-effect", "linkUrl": "https://www.lesswrong.com/posts/aRv9PzpFvMEwBfSrn/the-superstar-effect", "postedAtFormatted": "Saturday, January 3rd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Superstar%20Effect&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Superstar%20Effect%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaRv9PzpFvMEwBfSrn%2Fthe-superstar-effect%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Superstar%20Effect%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaRv9PzpFvMEwBfSrn%2Fthe-superstar-effect", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaRv9PzpFvMEwBfSrn%2Fthe-superstar-effect", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1752, "htmlBody": "<blockquote>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">Modern microconomist Alfred Marshall explains that technology has greatly extended the power and reach of the planet's most gifted performers....He referenced a classical of the British opera singer Elizabeth Billington. She was a well-acclaimed soprano with a strong voice, that, naturally did not have access to a microphone or amplifier in 1798, let alone to MTV, CDs, iTunes, and Pandora. She could only reach a small audience. This limited her ability to dominate the market in the way that artists to do today. Marshall wrote, &ldquo;so long as the number of persons who can be reached by a human voice is strictly limited, it is not very likely that any singer will make an advance on the &pound;10,000 said to have been earned in a season by Mrs. Billington at the beginning of the last century, nearly as great [an increase] as that which the business leaders of the present generation have made on those of the last.&rdquo;&nbsp;</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">- <a href=\"http://en.wikipedia.org/wiki/Superstar#Economics_of_.22superstars.22\">Wikipedia</a></span></p>\n</blockquote>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">Technology has made it easy for us to reach large audiences. And to do so at no marginal cost. If a musician writes a song and puts it on iTunes, it doesn't cost him any money for one more person to download it.</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">The fact that technology has made it easy for us to reach large audiences has implications on the consumer side of things as well. As a consumer, I can go on iTunes and choose <em>the best</em>&nbsp;music to buy. To understand my point, consider a different world. In this world iTunes doesn't exist. In this world the best music is 200 miles away, but mediocre music is only 5 miles away. Because traveling 200 miles is inconvenient, I choose the mediocre music.</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">In today's world of iTunes, this doesn't happen. Technology exists that allows us to reach large audiences and to do so at little/no marginal cost. And so, the consumer can (and will) choose the best the market has to offer.</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">Now for the implications on the supply side. We've already seen that consumers can and will choose the best the market has to offer. \"The best the market has to offer\" is usually provided by a small number of talented people. Think about it: the best artists, performers, writers, athletes etc. These talented people end up serving a large proportion of the market, and are paid accordingly. This... is The Superstar Effect.</span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Because of these joint consumption economies, there is a unique opportunity to <a href=\"http://www.paulgraham.com/wealth.html\">create and capture value</a>. If you are <em>the best</em>, you capture insane amounts of value. Thus, there is a huge incentive to be <em>the best</em>.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">So, should you invest in an attempt to outdo The Superstar and capture this value? Well, investment decisions are all about expected value. Balancing risk with reward. In this case, the potential reward is <em>huge</em>. Astronomical. These joint consumption economies allow you to reach tremendous markets. However, the question is \"how big is the risk?\".</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Outdoing The Superstar is a large and complex task, and I won't pretend to have all the answers. However, I've had this nagging suspicion in the back of my mind for years. My suspicion is that people drastically overestimate this risk, and that with a <em>good plan</em> and <em>enough resources</em>, you could have an excellent chance at \"outdoing The Superstar\".</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Before moving on, let me go through the logic one more time:</span></span></p>\n<ul>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Today's joint consumption economies allow for firms to reach large amounts of people with little/no marginal costs.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Thus, consumers have tons of options to choose from.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Consumers often have similar enough tastes such that a large percentage of them end up choosing The Superstar.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">In serving all of these people, The Superstar has created and captured a ton of value.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">If another firm came along and outdid The Superstar, this new firm would replace The Superstar. It would now be the one to serve the large market, and would be compensated accordingly. <em>There is a large reward for outdoing The Superstar.</em></span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Investment is all about balancing risk and reward. Investing in an attempt to outdo The Superstar has a very large potential reward. The question is, \"what's the risk?\".</span></span></li>\n</ul>\n<h3><br /></h3>\n<h3><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Outdoing The Superstar</span></span></h3>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">People seem to view large ventures like starting startups as a roll of the dice. They say things like, \"9 out of 10 startups fail\". I don't see things that way. I don't see it as \"a roll of the dice\". I see it as a deterministic puzzle that can be solved.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I should qualify that previous statement. I'm not trying to make a&nbsp;philosophical&nbsp;point, just a practical one. People seem to be afraid of what I'll call, Large Puzzles. Because of their size and complexity, people seem to be put off by them, and they fall back on <a href=\"http://wiki.lesswrong.com/wiki/Outside_view\">outside view</a> arguments like \"9 in 10 startups fail\".</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I'll admit that Large Puzzles are complex, but I maintain that with enough resources and with a good plan, a lot of them are very solvable. I sense that a lot of these large joint consumption winner-take-all industries are ripe for the taking, and that with enough resources and a good plan, they can be taken.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">My confidence isn't <em>that</em>&nbsp;high though. I don't understand these Large Puzzles well enough to really say. What I'm referring to are \"relatively strong suspicions\", not \"beliefs\" (my thoughts are cloudy enough such that I'm having trouble being more precise than this, sorry).</span></span></p>\n<h3><br /></h3>\n<h3><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Investing</span></span></h3>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">This is a bit of an aside and a rant, but here we go. Investors currently seem to be heavily biased towards investing in businesses that can be built incrementally. They want to...</span></span></p>\n<ul>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">See some sort of promise/traction before investing at all (usually).</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Invest 10s/100s of thousands of dollars in a seed round.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">See some more traction before they invest a couple/10s of millions in a series A.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">See some more traction before they invest 10s/100s in the next round.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">etc. etc.</span></span></li>\n</ul>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">What about firms that are trying to replace The Superstar? Such a task usually requires very large amounts of upfront investment. Because of the winner-take-all nature of these industries, you usually need to exceed a certain threshold of \"firepower\" before you have a shot at showing some traction, let alone at replacing The Superstar.</span></span></div>\n<div><br /></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">However, the fact remains that investment decisions are all about expected value. Risk vs. reward. Risk isn't inherently bad, it just needs to be balanced by the reward. An in the case of superstar industries, the potential reward is huge.</span></span></div>\n<div><br /></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">In fact, the idea that <a href=\"http://blakemasters.com/post/21869934240/peter-thiels-cs183-startup-class-7-notes-essay\">the distribution of returns in an investment fund follows a power law</a>&nbsp;seems to be well accepted. This means that it makes sense for an investor to seek <em>huge</em> exits. Replacing a Superstar seems like a great way to do that to me.</span></span></div>\n<div><br /></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">But in reality, it seems that investors don't actually understand the power law. It seems that they try desperately to \"minimize risk\", and look desperately for signs of traction, and end up investing mostly in companies that can be built incrementally.&nbsp;Unfortunate.</span></span></div>\n<div><br /></div>\n<div><br /></div>\n<div><br /></div>\n<h3><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Education</span></span></h3>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">The Large Puzzle that I understand best is Education (which causes my System I to care disproportionately about it). I'll indulge myself and say it: the education system today is <em>shit</em>.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I think that Elon Musk <a href=\"https://www.youtube.com/watch?v=vDwzmJpI4io&amp;feature=youtu.be&amp;t=38m\">said it well</a>. He said (paraphrasing):</span></span></p>\n<blockquote>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\"><span style=\"line-height: 22.3999996185303px;\">Consider The Dark Knight. It's awesome! It has all the best actors, directors, special effects etc. Now imagine if you took the same script and asked the local middle school to reproduce it. It'd suck. That's education.</span></span></span></p>\n</blockquote>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I think that this division of resources is really the core of the problem. Things you could do once you pool resources:</span></span></p>\n<ul>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Put a lot of effort towards making each lesson great&nbsp;<span style=\"line-height: 22.3999996185303px;\">(in&nbsp;</span><a style=\"line-height: 22.3999996185303px;\" href=\"http://yudkowsky.tumblr.com/post/81447230971/my-april-fools-day-confession\">dath ilan</a><span style=\"line-height: 22.3999996185303px;\">, \"One hour of instruction on a widely-used subject got the same kind of attention that an hour of prime-time TV gets on Earth\")</span>. Figure out how to word things properly. What examples to use. What analogies to give. Make lessons visual, animated, interactive. Gamify them and make them fun (when appropriate). Make them beautiful. Apply <a href=\"http://en.wikipedia.org/wiki/Design_thinking\">design thinking</a>. Make them <a href=\"http://worrydream.com/MediaForThinkingTheUnthinkable/\">skimmable</a> so students can refer back to them when they're studying. Include convenient references to things the student might have a question on.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Break lessons into chunks and organize them according to their dependencies (this is an important and difficult task). I'm a big believer that knowledge is hierarchical. That concepts have dependencies (to know A, you have to know B). I think it makes a lot of sense to have students learn things that they have the proper foundation for. I think this makes more sense in the negative: you shouldn't have students learn things that they don't have the proper foundation for. (This is a bit of an aside, but I think that <a href=\"https://www.youtube.com/watch?v=0OtSs2xEpzY#t=404\">mastery should be fixed, and time should be variable</a>. Currently it's the opposite.)</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\"><a href=\"http://youtu.be/CiKrFcgVSIU?t=10m39s\">Open up time </a>for teachers to spend personal attention on their students. In today's system, they're usually too busy to do this. (Note: even with these great lessons, I still think that teachers will be useful. The lessons could be pretty good, so I'm not sure if they'd be <em>necessary</em>, but I suspect that they'd still be useful. I think using a human will still be the best way to diagnose and address the holes in a student's understanding.)</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Come up with great practice problems, exercises, projects etc.&nbsp;</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Make tests way more accurate and effective. Make them <a href=\"http://schoolsofthought.blogs.cnn.com/2012/10/04/my-view-the-future-of-credentials/\">smaller</a>. And for gods sake, have them created by a <a href=\"http://yudkowsky.tumblr.com/post/81447230971/my-april-fools-day-confession\">separate financial entity than the entity that does the teaching</a>!</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">This applies to a lot of what I said above, but <em>iterate, iterate, iterate!!</em>&nbsp;See what works and what doesn't work and <em>change</em>. Given the amount of \"experimental subjects (students)\" and \"technicians (teachers)\", there's a tremendous opportunity to do this. Effective collaboration and coordination might be tough, but I sense that it's doable.</span></span></li>\n</ul>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Sorry, I may have mixed in a few opinions that aren't directly related to the idea of pooling resources and that should really be asides.</span></span></div>\n<div><br /></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Anyway, I think that the Large Puzzle of Education is very solvable. I think that with enough resources, you could do a good enough job such that it becomes an industry where The Superstar Effect takes over. Where one Superstar addresses a large proportion of the market. And I think that this would have a huge and beneficial impact on the world.</span></span></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xexCWMyds6QLWognu": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aRv9PzpFvMEwBfSrn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 12, "extendedScore": null, "score": 2.3323005280164175e-06, "legacy": true, "legacyId": "27834", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">Modern microconomist Alfred Marshall explains that technology has greatly extended the power and reach of the planet's most gifted performers....He referenced a classical of the British opera singer Elizabeth Billington. She was a well-acclaimed soprano with a strong voice, that, naturally did not have access to a microphone or amplifier in 1798, let alone to MTV, CDs, iTunes, and Pandora. She could only reach a small audience. This limited her ability to dominate the market in the way that artists to do today. Marshall wrote, \u201cso long as the number of persons who can be reached by a human voice is strictly limited, it is not very likely that any singer will make an advance on the \u00a310,000 said to have been earned in a season by Mrs. Billington at the beginning of the last century, nearly as great [an increase] as that which the business leaders of the present generation have made on those of the last.\u201d&nbsp;</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">- <a href=\"http://en.wikipedia.org/wiki/Superstar#Economics_of_.22superstars.22\">Wikipedia</a></span></p>\n</blockquote>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">Technology has made it easy for us to reach large audiences. And to do so at no marginal cost. If a musician writes a song and puts it on iTunes, it doesn't cost him any money for one more person to download it.</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">The fact that technology has made it easy for us to reach large audiences has implications on the consumer side of things as well. As a consumer, I can go on iTunes and choose <em>the best</em>&nbsp;music to buy. To understand my point, consider a different world. In this world iTunes doesn't exist. In this world the best music is 200 miles away, but mediocre music is only 5 miles away. Because traveling 200 miles is inconvenient, I choose the mediocre music.</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">In today's world of iTunes, this doesn't happen. Technology exists that allows us to reach large audiences and to do so at little/no marginal cost. And so, the consumer can (and will) choose the best the market has to offer.</span></p>\n<p><span style=\"color: #252525; font-family: sans-serif; font-size: 14px; line-height: 22.3999996185303px;\">Now for the implications on the supply side. We've already seen that consumers can and will choose the best the market has to offer. \"The best the market has to offer\" is usually provided by a small number of talented people. Think about it: the best artists, performers, writers, athletes etc. These talented people end up serving a large proportion of the market, and are paid accordingly. This... is The Superstar Effect.</span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Because of these joint consumption economies, there is a unique opportunity to <a href=\"http://www.paulgraham.com/wealth.html\">create and capture value</a>. If you are <em>the best</em>, you capture insane amounts of value. Thus, there is a huge incentive to be <em>the best</em>.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">So, should you invest in an attempt to outdo The Superstar and capture this value? Well, investment decisions are all about expected value. Balancing risk with reward. In this case, the potential reward is <em>huge</em>. Astronomical. These joint consumption economies allow you to reach tremendous markets. However, the question is \"how big is the risk?\".</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Outdoing The Superstar is a large and complex task, and I won't pretend to have all the answers. However, I've had this nagging suspicion in the back of my mind for years. My suspicion is that people drastically overestimate this risk, and that with a <em>good plan</em> and <em>enough resources</em>, you could have an excellent chance at \"outdoing The Superstar\".</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Before moving on, let me go through the logic one more time:</span></span></p>\n<ul>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Today's joint consumption economies allow for firms to reach large amounts of people with little/no marginal costs.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Thus, consumers have tons of options to choose from.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Consumers often have similar enough tastes such that a large percentage of them end up choosing The Superstar.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">In serving all of these people, The Superstar has created and captured a ton of value.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">If another firm came along and outdid The Superstar, this new firm would replace The Superstar. It would now be the one to serve the large market, and would be compensated accordingly. <em>There is a large reward for outdoing The Superstar.</em></span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Investment is all about balancing risk and reward. Investing in an attempt to outdo The Superstar has a very large potential reward. The question is, \"what's the risk?\".</span></span></li>\n</ul>\n<h3><br></h3>\n<h3 id=\"Outdoing_The_Superstar\"><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Outdoing The Superstar</span></span></h3>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">People seem to view large ventures like starting startups as a roll of the dice. They say things like, \"9 out of 10 startups fail\". I don't see things that way. I don't see it as \"a roll of the dice\". I see it as a deterministic puzzle that can be solved.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I should qualify that previous statement. I'm not trying to make a&nbsp;philosophical&nbsp;point, just a practical one. People seem to be afraid of what I'll call, Large Puzzles. Because of their size and complexity, people seem to be put off by them, and they fall back on <a href=\"http://wiki.lesswrong.com/wiki/Outside_view\">outside view</a> arguments like \"9 in 10 startups fail\".</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I'll admit that Large Puzzles are complex, but I maintain that with enough resources and with a good plan, a lot of them are very solvable. I sense that a lot of these large joint consumption winner-take-all industries are ripe for the taking, and that with enough resources and a good plan, they can be taken.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">My confidence isn't <em>that</em>&nbsp;high though. I don't understand these Large Puzzles well enough to really say. What I'm referring to are \"relatively strong suspicions\", not \"beliefs\" (my thoughts are cloudy enough such that I'm having trouble being more precise than this, sorry).</span></span></p>\n<h3><br></h3>\n<h3 id=\"Investing\"><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Investing</span></span></h3>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">This is a bit of an aside and a rant, but here we go. Investors currently seem to be heavily biased towards investing in businesses that can be built incrementally. They want to...</span></span></p>\n<ul>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">See some sort of promise/traction before investing at all (usually).</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Invest 10s/100s of thousands of dollars in a seed round.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">See some more traction before they invest a couple/10s of millions in a series A.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">See some more traction before they invest 10s/100s in the next round.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">etc. etc.</span></span></li>\n</ul>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">What about firms that are trying to replace The Superstar? Such a task usually requires very large amounts of upfront investment. Because of the winner-take-all nature of these industries, you usually need to exceed a certain threshold of \"firepower\" before you have a shot at showing some traction, let alone at replacing The Superstar.</span></span></div>\n<div><br></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">However, the fact remains that investment decisions are all about expected value. Risk vs. reward. Risk isn't inherently bad, it just needs to be balanced by the reward. An in the case of superstar industries, the potential reward is huge.</span></span></div>\n<div><br></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">In fact, the idea that <a href=\"http://blakemasters.com/post/21869934240/peter-thiels-cs183-startup-class-7-notes-essay\">the distribution of returns in an investment fund follows a power law</a>&nbsp;seems to be well accepted. This means that it makes sense for an investor to seek <em>huge</em> exits. Replacing a Superstar seems like a great way to do that to me.</span></span></div>\n<div><br></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">But in reality, it seems that investors don't actually understand the power law. It seems that they try desperately to \"minimize risk\", and look desperately for signs of traction, and end up investing mostly in companies that can be built incrementally.&nbsp;Unfortunate.</span></span></div>\n<div><br></div>\n<div><br></div>\n<div><br></div>\n<h3 id=\"Education\"><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Education</span></span></h3>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">The Large Puzzle that I understand best is Education (which causes my System I to care disproportionately about it). I'll indulge myself and say it: the education system today is <em>shit</em>.</span></span></p>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I think that Elon Musk <a href=\"https://www.youtube.com/watch?v=vDwzmJpI4io&amp;feature=youtu.be&amp;t=38m\">said it well</a>. He said (paraphrasing):</span></span></p>\n<blockquote>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\"><span style=\"line-height: 22.3999996185303px;\">Consider The Dark Knight. It's awesome! It has all the best actors, directors, special effects etc. Now imagine if you took the same script and asked the local middle school to reproduce it. It'd suck. That's education.</span></span></span></p>\n</blockquote>\n<p><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">I think that this division of resources is really the core of the problem. Things you could do once you pool resources:</span></span></p>\n<ul>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Put a lot of effort towards making each lesson great&nbsp;<span style=\"line-height: 22.3999996185303px;\">(in&nbsp;</span><a style=\"line-height: 22.3999996185303px;\" href=\"http://yudkowsky.tumblr.com/post/81447230971/my-april-fools-day-confession\">dath ilan</a><span style=\"line-height: 22.3999996185303px;\">, \"One hour of instruction on a widely-used subject got the same kind of attention that an hour of prime-time TV gets on Earth\")</span>. Figure out how to word things properly. What examples to use. What analogies to give. Make lessons visual, animated, interactive. Gamify them and make them fun (when appropriate). Make them beautiful. Apply <a href=\"http://en.wikipedia.org/wiki/Design_thinking\">design thinking</a>. Make them <a href=\"http://worrydream.com/MediaForThinkingTheUnthinkable/\">skimmable</a> so students can refer back to them when they're studying. Include convenient references to things the student might have a question on.</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Break lessons into chunks and organize them according to their dependencies (this is an important and difficult task). I'm a big believer that knowledge is hierarchical. That concepts have dependencies (to know A, you have to know B). I think it makes a lot of sense to have students learn things that they have the proper foundation for. I think this makes more sense in the negative: you shouldn't have students learn things that they don't have the proper foundation for. (This is a bit of an aside, but I think that <a href=\"https://www.youtube.com/watch?v=0OtSs2xEpzY#t=404\">mastery should be fixed, and time should be variable</a>. Currently it's the opposite.)</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\"><a href=\"http://youtu.be/CiKrFcgVSIU?t=10m39s\">Open up time </a>for teachers to spend personal attention on their students. In today's system, they're usually too busy to do this. (Note: even with these great lessons, I still think that teachers will be useful. The lessons could be pretty good, so I'm not sure if they'd be <em>necessary</em>, but I suspect that they'd still be useful. I think using a human will still be the best way to diagnose and address the holes in a student's understanding.)</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Come up with great practice problems, exercises, projects etc.&nbsp;</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Make tests way more accurate and effective. Make them <a href=\"http://schoolsofthought.blogs.cnn.com/2012/10/04/my-view-the-future-of-credentials/\">smaller</a>. And for gods sake, have them created by a <a href=\"http://yudkowsky.tumblr.com/post/81447230971/my-april-fools-day-confession\">separate financial entity than the entity that does the teaching</a>!</span></span></li>\n<li><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">This applies to a lot of what I said above, but <em>iterate, iterate, iterate!!</em>&nbsp;See what works and what doesn't work and <em>change</em>. Given the amount of \"experimental subjects (students)\" and \"technicians (teachers)\", there's a tremendous opportunity to do this. Effective collaboration and coordination might be tough, but I sense that it's doable.</span></span></li>\n</ul>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Sorry, I may have mixed in a few opinions that aren't directly related to the idea of pooling resources and that should really be asides.</span></span></div>\n<div><br></div>\n<div><span style=\"font-family: sans-serif; color: #252525;\"><span style=\"font-size: 14px; line-height: 22.3999996185303px;\">Anyway, I think that the Large Puzzle of Education is very solvable. I think that with enough resources, you could do a good enough job such that it becomes an industry where The Superstar Effect takes over. Where one Superstar addresses a large proportion of the market. And I think that this would have a huge and beneficial impact on the world.</span></span></div>", "sections": [{"title": "Outdoing The Superstar", "anchor": "Outdoing_The_Superstar", "level": 1}, {"title": "Investing", "anchor": "Investing", "level": 1}, {"title": "Education", "anchor": "Education", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "53 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-03T09:29:40.755Z", "modifiedAt": null, "url": null, "title": "Parsimony as a side dish - a game to play on meetups?", "slug": "parsimony-as-a-side-dish-a-game-to-play-on-meetups", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:04.338Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "soxibwaBm5LshmGoP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Lqjh8zqjt4GB7mWpH/parsimony-as-a-side-dish-a-game-to-play-on-meetups", "pageUrlRelative": "/posts/Lqjh8zqjt4GB7mWpH/parsimony-as-a-side-dish-a-game-to-play-on-meetups", "linkUrl": "https://www.lesswrong.com/posts/Lqjh8zqjt4GB7mWpH/parsimony-as-a-side-dish-a-game-to-play-on-meetups", "postedAtFormatted": "Saturday, January 3rd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Parsimony%20as%20a%20side%20dish%20-%20a%20game%20to%20play%20on%20meetups%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AParsimony%20as%20a%20side%20dish%20-%20a%20game%20to%20play%20on%20meetups%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLqjh8zqjt4GB7mWpH%2Fparsimony-as-a-side-dish-a-game-to-play-on-meetups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Parsimony%20as%20a%20side%20dish%20-%20a%20game%20to%20play%20on%20meetups%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLqjh8zqjt4GB7mWpH%2Fparsimony-as-a-side-dish-a-game-to-play-on-meetups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLqjh8zqjt4GB7mWpH%2Fparsimony-as-a-side-dish-a-game-to-play-on-meetups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 459, "htmlBody": "<p>Tl;dr: we seem to (naively?) compound parsimony with other heuristics.</p>\n<p>There was a quote from R. Burton, provided by JQuinton, offering an amusing exercise. The reader had to guess if an excerpt of text was nonsense or merely a rambling presentation of something, and what that could be. Upon learning a single word of explanation, it became difficult to read it as anything than the object's description, even if the reader was told there were other possible answers (beyond 'ridiculous.')</p>\n<p>Here's an example:</p>\n<p>&gt; Reconstruction probably won't even account for all that escaped the initial search. Of course it doesn't have as much lead as the stained variety. Please don't follow 'old traditions' again, it's a cultural thing anyway. The little ones are easily lost in water. The dog won't know how to find them, but the problem is rather that it won't know how to avoid them. The high singing note I will miss. Be careful not to step on it. It was to harmony what it is to ruin. A different brand is used in electron microscopy, to make 'em smooth and even. There's plenty under the bench in the park. I had cherished it since my wedding.</p>\n<p>(I'm not a writer, so that was rather clumsy. Please post better examples in comments.)</p>\n<p>But what if we are offered to brainstorm before answering, and to try viewing the excerpt as a collection of true facts, just not necessarily a coherent story? Here are some of our possible approaches (heuristics):</p>\n<p>- it's a picture;</p>\n<p>- it's an instruction;</p>\n<p>-it's paraphyletic (e.g., it is about a single thing which has more than one cause);</p>\n<p>- it's alive!</p>\n<p>- it's dangerous!&nbsp;</p>\n<p>- it's an advertisement;</p>\n<p>- it's a single thing better described by more than one word, though still recognizable from the best match;</p>\n<p>- it's a compilation of distant phenomena related to whatsitname, the everyday thing;</p>\n<p>- it's all true, BUT there are qualifiers (which could make it more plausible-sounding);</p>\n<p>- it's just not a physical body;</p>\n<p>- it's an extreme case etc.</p>\n<p>...and then we try to guess again.</p>\n<p>The number of hypotheses now should be more than one, but why? What changed?</p>\n<p>I think we start out with expectations nearest to 'picture' and most removed from 'qualifiers', and maybe it was useful in ancestral environment, but I would not expect them to be most fruitful. Maybe if enough people played such scenarios out, we would experimentally obtain a set of more useful ones?</p>\n<p>Is there a way to prove that one and only one interpretation is true (allows for all statements to be true)? What would you expect such excerpts (sets?) have in common?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>And more importantly: is there any way to weaken priming's hold on us?</p>\n<p>&nbsp;</p>\n<p>(I am not a native speaker, so if there are any mistakes, please point them out to me. Thank you.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Lqjh8zqjt4GB7mWpH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.332766772561181e-06, "legacy": true, "legacyId": "27836", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-03T13:24:43.193Z", "modifiedAt": null, "url": null, "title": "What are the thoughts of Less Wrong on property dualism?", "slug": "what-are-the-thoughts-of-less-wrong-on-property-dualism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:55.217Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "casebash", "createdAt": "2012-11-04T06:10:08.650Z", "isAdmin": false, "displayName": "casebash"}, "userId": "MrwJ5w7siWBQ4bMiE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ExamqHS4AHMM8BBmf/what-are-the-thoughts-of-less-wrong-on-property-dualism", "pageUrlRelative": "/posts/ExamqHS4AHMM8BBmf/what-are-the-thoughts-of-less-wrong-on-property-dualism", "linkUrl": "https://www.lesswrong.com/posts/ExamqHS4AHMM8BBmf/what-are-the-thoughts-of-less-wrong-on-property-dualism", "postedAtFormatted": "Saturday, January 3rd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20the%20thoughts%20of%20Less%20Wrong%20on%20property%20dualism%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20the%20thoughts%20of%20Less%20Wrong%20on%20property%20dualism%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FExamqHS4AHMM8BBmf%2Fwhat-are-the-thoughts-of-less-wrong-on-property-dualism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20the%20thoughts%20of%20Less%20Wrong%20on%20property%20dualism%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FExamqHS4AHMM8BBmf%2Fwhat-are-the-thoughts-of-less-wrong-on-property-dualism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FExamqHS4AHMM8BBmf%2Fwhat-are-the-thoughts-of-less-wrong-on-property-dualism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<p>I did a search about property dualism and I couldn't see much written here on this site.</p>\n<ol>\n<li>What is your opinion on this topic?</li>\n<li>Are there any articles on this site that I should read, including articles that aren't directly about property dualism? I'll add links to articles here as I find them (I'm still doing some searching myself)</li>\n</ol>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ExamqHS4AHMM8BBmf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 2, "extendedScore": null, "score": 2.33331947406648e-06, "legacy": true, "legacyId": "27841", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-03T20:22:21.432Z", "modifiedAt": "2020-12-08T02:51:31.637Z", "url": null, "title": "Graphical Assumption Modeling", "slug": "graphical-assumption-modeling", "viewCount": null, "lastCommentedAt": "2020-12-08T02:52:00.655Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ozziegooen", "createdAt": "2013-05-25T09:22:13.574Z", "isAdmin": false, "displayName": "ozziegooen"}, "userId": "efKySALtaLcvtp3jW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KigyGYE7nZZwPvN4s/graphical-assumption-modeling", "pageUrlRelative": "/posts/KigyGYE7nZZwPvN4s/graphical-assumption-modeling", "linkUrl": "https://www.lesswrong.com/posts/KigyGYE7nZZwPvN4s/graphical-assumption-modeling", "postedAtFormatted": "Saturday, January 3rd 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Graphical%20Assumption%20Modeling&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGraphical%20Assumption%20Modeling%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKigyGYE7nZZwPvN4s%2Fgraphical-assumption-modeling%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Graphical%20Assumption%20Modeling%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKigyGYE7nZZwPvN4s%2Fgraphical-assumption-modeling", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKigyGYE7nZZwPvN4s%2Fgraphical-assumption-modeling", "socialPreviewImageUrl": "https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_1.png?raw=true", "question": false, "authorIsUnreviewed": false, "wordCount": 1553, "htmlBody": "<h2>The Flaws of Fermi Estimates</h2><p>Why don\u2019t we use more Fermi estimates?[1] Many of us want to become more rational. We have lots of numbers we can think of and important variables to consider. There are a few reasons.</p><p>Fermi calculations get really messy. After a few variables introduced, they could quickly become difficult to imagine and outline a problem. Many people, especially those who were not used to writing academic papers, do not practice the skills of formalizing inputs and outputs. It can be tedious for those who do.</p><p>Fermi models typically do not include estimates of certainty. Certainty propagates. It creates bottlenecks. As a Fermi model grows, specific uncertain assumptions could underscore the result. Certainty estimates are typically not measured, and when they are they require formalization and significant calculation.</p><p>Fermi calculations are not fun to share. Most of them are pretty simple; they just involve multiplication and addition and 3\u20135 variables. However, in order to write them one must formalize them as few lines of math him or few long paragraphs which really should be math.</p><h2>Graphical Assumption Modeling</h2><p>We propose the use of simple graphical models in order to represent estimates and Fermi models. We think these have the capacity to solve the issues mentioned above and make complex estimations more simple, more sharable, and more calculable. A formal and rigorous graphical model could not only improve on existing Fermi calculations, but it could also extend them to functions they have not yet been used for.</p><p><strong>Multiplication</strong></p><p>Let\u2019s say we are trying to estimate the number of smiles per day in a park. A first attempt at this may be to guess the number of people in the park and to estimate the number of smiles on average per person in the park.</p><p>This is easy to calculate directly. 100 People x 10 smiles/(day * person) = 1000 smiles/day.</p><p>As a model, we can represent the <i>variables</i> as lines and the <i>function</i> as a box in between them. This fits nicely with similar diagramming standards. The function of multiplication acts as an object with inputs and outputs.</p><figure class=\"image image_resized\" style=\"width:71.55%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_1.png?raw=true\"></figure><figure class=\"image\"><img src=\"https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_1.png?raw=true\"></figure><p>Independent variables, or user selected variables, are shown in black, and <i>dependent</i> variables are shown in blue.</p><p>We can condense this diagram by moving the number of smiles per day per person into the multiplication block.</p><figure class=\"image image_resized\" style=\"width:73.96%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_2.png?raw=true\"></figure><p>Say we wanted to find the total smiles per year in the park. We can simply extend the model as follows.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_3.png?raw=true\"></figure><p>&nbsp;</p><p><strong>Addition</strong></p><p>Perhaps we think that kids and adults have different rates of smiling and would like to separate our model accordingly. We estimate the number of kids in the park, the number of adults in the park, and their corresponding smiling estimates. Then we add them with a similar block as we used for multiplication.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/addition.png?raw=true\"></figure><p><strong>Uncertainty</strong></p><p>If we have uncertainty estimates we can make them explicit. Estimates of certainty typically get left out of Fermi calculations, but become essential when making large models.</p><figure class=\"image image_resized\" style=\"width:91.65%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/uncertain.png?raw=true\"></figure><p>It is not clear what the best way is to annotate an uncertainty interval. In this case, the intervals described are meant as 90% Gaussian confidence intervals, but these could vary. They do not have to be Gaussian-like intervals, but could be complex probability distributions. These may require graphical representations and additional software. However, for many estimations, even simple models of uncertainty would be advantageous.</p><p><strong>Estimate Combination</strong></p><p>If two people give two estimates for a number, they could be combined to find the resulting probability distribution.</p><figure class=\"image image_resized\" style=\"width:95.2%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/combination_estimates.png?raw=true\"></figure><figure class=\"image\"><img src=\"https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/combination_estimates.png?raw=true\"></figure><p>Uncertainty distributions are valuable for this. If two agents both state their uncertainty distributions, we can find a weighted average of their estimations with a calculated resulting uncertainty distribution.</p><p><strong>Model Combination</strong></p><p>We can combine models by combining their resulting estimates. So far we have shown two unique attempts at modeling the number of smiles in a park. They produced the same unit output, so they can be combined.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/combination_models.png?raw=true\"></figure><p>Both of them still have predictive power, and a combination could produce a more accurate estimate than either alone. The model with greater certainty, in this case the adult/child split model, will have more influence in the final calculation, but it will still be moderated by it. Combining many properly calibrated models will always give a more accurate result.</p><p><strong>Abstraction</strong></p><p>Large sections can be combined into <i>black boxes</i>.[2] Black boxes can be used to summarize large models into simple objects with specified inputs and outputs. This means that one can work on a very large total model in small pieces and have it be manageable.</p><figure class=\"image image_resized\" style=\"width:74.33%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/black_boxes.png?raw=true\"></figure><p><strong>Decision Making</strong></p><p>Say we must decide between two options. One common way to do so is to estimate a value for each, and choose the one with a higher (or lower) value.</p><figure class=\"image image_resized\" style=\"width:64.9%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/decision.png?raw=true\"></figure><p>In this case we make a decision of which lemonade will sell better. We use a decision \u2018block\u2019, which could hold any arbitrary decision function. In this case, it simply outputs the value of the highest input value.</p><p>This can be useful if one can assume the use of the best option of alternatives. In a larger model, there may be many decisions determined by model. The outputs of these decisions could be used for later estimations or decisions.</p><p><strong>Larger Models</strong></p><p>These techniques can be combined to produce large and intricate models. As these increase in size they can become more valuable.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/complex.png?raw=true\"></figure><p>In the model above, a person is attempting to find the best use of their time to produce money. There are several options to sell lemonade, and there\u2019s also the opportunity to work overtime. The estimator makes an estimate for each and uses the model to understand them in relation to each other.</p><p>This larger model demonstrates the option of configuration in these models. The profit percentage of lemonade sales was expected to be similar for different kinds of lemonade in different locations. It could have instead been multiplied individually for each one, but it was simpler to move it after the decision block between them.</p><p>In this case it may have been reasonable to use a table instead of a graphical model. However, a table would not necessarily demonstrate the unique constraints and considerations of each type of input. For instance, lemonade sales had a margin of profit, and overtime work had a different net income number. In tables many of the important calculations are often difficult to read at the same time as the data. We believe this form of modeling helps make the numbers understandable as well as the assumptions and certainties that go into those numbers.</p><p><strong>Possible Automated Analysis</strong></p><p>Once we arrive at the model above, we would have enough information to calculate the value of information (VOI) of additional certainty for each metric. For instance, a reduction of uncertainty of the variable \u2018Regular Lemonade at Dolores Park\u2019 to 0 could produce an expected few dollars per hour, assuming that resulting decisions would be made using the model.</p><p>The value of new options could also be calculated easily if one could come up with a probability distribution of their expected earnings per hour.</p><p>While these kinds of analysis are well established in academia, they are currently difficult to use. If estimations could be simply mapped, it may make them significantly more accessible.</p><p>&nbsp;</p><h2><strong>Similar Work</strong></h2><p>This work can be seen as similar to Unified Modeling Language (UML) in that it attempts to graphically specify a complex system of knowledge. UML was an attempt to define a graphical language for software architecture. There were claims that programs that produced UML could be used to produce their corresponding programs. This hasn\u2019t really happened. The UML spec went through several versions and became so specific and complex that few programmers now bother with it. However, it did encourage the use of whiteboard modeling for other programmers and experiences some popularity with larger projects.</p><p>Graphical computer software is challenging. Most attempts have failed, but a few companies have had success with it. LabView is a popular visual programming tool used by scientists and engineers. It uses a Dataflow programming paradigm, which would also be appropriate for Graphical Assumption Modeling.</p><p>The theory of this work is similar to that of Probabilistic Graphical Models. These are typically more formal models aimed at computer input and output rather than direct human interaction.</p><h2><strong>Future Work</strong></h2><p>This research is very young. The diagrams could use more experimentation and exploration. We have not included a method for subtraction or division, for example. Even if they were better established, it could take a long time for them to become accepted by other communities.</p><p>It\u2019s obvious that if these models are useful, it would be valuable to have a computer program to make them. Ozzie Gooen has made a simple attempt called <a href=\"http://fermihub.com/\">Fermihub</a>. Fermihub is functional, free, and open source. However, it applies only a few simple analytic approximations and does not incorporate Monte Carlo simulations. For accurate or large models, Monte Carlo simulations will be necessary.</p><p>There could be more research done in this kind of estimation. While much of the math has already been solved, the art of efficiently creating large models and collaborating with others has a lot of work left. There is also some debate on the proper way to combine estimates, which is crucial for large models.</p><p><br>&nbsp;</p><p><strong>Note:</strong> I realize that the math in the models above, specifically in the combinations of estimates, is incorrect. &nbsp;I'm currently investigating how to do it correctly. &nbsp;&nbsp;</p><p>References</p><ol><li><a href=\"/lw/h5e/fermi_estimates/\">Fermi Estimates</a>, LukeProg. 2013</li><li>See <a href=\"http://en.wikipedia.org/wiki/Black_box\">wikipedia</a> for a high level understanding of black boxes. They are a fundamental unit for systems research, which in part has lead to many diagrams we see today.</li></ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KigyGYE7nZZwPvN4s", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 32, "extendedScore": null, "score": 9.7e-05, "legacy": true, "legacyId": "27843", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_1.png?raw=true", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"The_Flaws_of_Fermi_Estimates\">The Flaws of Fermi Estimates</h2><p>Why don\u2019t we use more Fermi estimates?[1] Many of us want to become more rational. We have lots of numbers we can think of and important variables to consider. There are a few reasons.</p><p>Fermi calculations get really messy. After a few variables introduced, they could quickly become difficult to imagine and outline a problem. Many people, especially those who were not used to writing academic papers, do not practice the skills of formalizing inputs and outputs. It can be tedious for those who do.</p><p>Fermi models typically do not include estimates of certainty. Certainty propagates. It creates bottlenecks. As a Fermi model grows, specific uncertain assumptions could underscore the result. Certainty estimates are typically not measured, and when they are they require formalization and significant calculation.</p><p>Fermi calculations are not fun to share. Most of them are pretty simple; they just involve multiplication and addition and 3\u20135 variables. However, in order to write them one must formalize them as few lines of math him or few long paragraphs which really should be math.</p><h2 id=\"Graphical_Assumption_Modeling\">Graphical Assumption Modeling</h2><p>We propose the use of simple graphical models in order to represent estimates and Fermi models. We think these have the capacity to solve the issues mentioned above and make complex estimations more simple, more sharable, and more calculable. A formal and rigorous graphical model could not only improve on existing Fermi calculations, but it could also extend them to functions they have not yet been used for.</p><p><strong id=\"Multiplication\">Multiplication</strong></p><p>Let\u2019s say we are trying to estimate the number of smiles per day in a park. A first attempt at this may be to guess the number of people in the park and to estimate the number of smiles on average per person in the park.</p><p>This is easy to calculate directly. 100 People x 10 smiles/(day * person) = 1000 smiles/day.</p><p>As a model, we can represent the <i>variables</i> as lines and the <i>function</i> as a box in between them. This fits nicely with similar diagramming standards. The function of multiplication acts as an object with inputs and outputs.</p><figure class=\"image image_resized\" style=\"width:71.55%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_1.png?raw=true\"></figure><figure class=\"image\"><img src=\"https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_1.png?raw=true\"></figure><p>Independent variables, or user selected variables, are shown in black, and <i>dependent</i> variables are shown in blue.</p><p>We can condense this diagram by moving the number of smiles per day per person into the multiplication block.</p><figure class=\"image image_resized\" style=\"width:73.96%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_2.png?raw=true\"></figure><p>Say we wanted to find the total smiles per year in the park. We can simply extend the model as follows.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/multiplication_3.png?raw=true\"></figure><p>&nbsp;</p><p><strong id=\"Addition\">Addition</strong></p><p>Perhaps we think that kids and adults have different rates of smiling and would like to separate our model accordingly. We estimate the number of kids in the park, the number of adults in the park, and their corresponding smiling estimates. Then we add them with a similar block as we used for multiplication.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/addition.png?raw=true\"></figure><p><strong id=\"Uncertainty\">Uncertainty</strong></p><p>If we have uncertainty estimates we can make them explicit. Estimates of certainty typically get left out of Fermi calculations, but become essential when making large models.</p><figure class=\"image image_resized\" style=\"width:91.65%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/uncertain.png?raw=true\"></figure><p>It is not clear what the best way is to annotate an uncertainty interval. In this case, the intervals described are meant as 90% Gaussian confidence intervals, but these could vary. They do not have to be Gaussian-like intervals, but could be complex probability distributions. These may require graphical representations and additional software. However, for many estimations, even simple models of uncertainty would be advantageous.</p><p><strong id=\"Estimate_Combination\">Estimate Combination</strong></p><p>If two people give two estimates for a number, they could be combined to find the resulting probability distribution.</p><figure class=\"image image_resized\" style=\"width:95.2%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/combination_estimates.png?raw=true\"></figure><figure class=\"image\"><img src=\"https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/combination_estimates.png?raw=true\"></figure><p>Uncertainty distributions are valuable for this. If two agents both state their uncertainty distributions, we can find a weighted average of their estimations with a calculated resulting uncertainty distribution.</p><p><strong id=\"Model_Combination\">Model Combination</strong></p><p>We can combine models by combining their resulting estimates. So far we have shown two unique attempts at modeling the number of smiles in a park. They produced the same unit output, so they can be combined.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/combination_models.png?raw=true\"></figure><p>Both of them still have predictive power, and a combination could produce a more accurate estimate than either alone. The model with greater certainty, in this case the adult/child split model, will have more influence in the final calculation, but it will still be moderated by it. Combining many properly calibrated models will always give a more accurate result.</p><p><strong id=\"Abstraction\">Abstraction</strong></p><p>Large sections can be combined into <i>black boxes</i>.[2] Black boxes can be used to summarize large models into simple objects with specified inputs and outputs. This means that one can work on a very large total model in small pieces and have it be manageable.</p><figure class=\"image image_resized\" style=\"width:74.33%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/black_boxes.png?raw=true\"></figure><p><strong id=\"Decision_Making\">Decision Making</strong></p><p>Say we must decide between two options. One common way to do so is to estimate a value for each, and choose the one with a higher (or lower) value.</p><figure class=\"image image_resized\" style=\"width:64.9%;\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/decision.png?raw=true\"></figure><p>In this case we make a decision of which lemonade will sell better. We use a decision \u2018block\u2019, which could hold any arbitrary decision function. In this case, it simply outputs the value of the highest input value.</p><p>This can be useful if one can assume the use of the best option of alternatives. In a larger model, there may be many decisions determined by model. The outputs of these decisions could be used for later estimations or decisions.</p><p><strong id=\"Larger_Models\">Larger Models</strong></p><p>These techniques can be combined to produce large and intricate models. As these increase in size they can become more valuable.</p><figure class=\"image\"><img src=\"https://web.archive.org/web/20200919000246im_/https://www.penflip.com/ozziegooen/estimation-graphing/blob/master/images/overview/complex.png?raw=true\"></figure><p>In the model above, a person is attempting to find the best use of their time to produce money. There are several options to sell lemonade, and there\u2019s also the opportunity to work overtime. The estimator makes an estimate for each and uses the model to understand them in relation to each other.</p><p>This larger model demonstrates the option of configuration in these models. The profit percentage of lemonade sales was expected to be similar for different kinds of lemonade in different locations. It could have instead been multiplied individually for each one, but it was simpler to move it after the decision block between them.</p><p>In this case it may have been reasonable to use a table instead of a graphical model. However, a table would not necessarily demonstrate the unique constraints and considerations of each type of input. For instance, lemonade sales had a margin of profit, and overtime work had a different net income number. In tables many of the important calculations are often difficult to read at the same time as the data. We believe this form of modeling helps make the numbers understandable as well as the assumptions and certainties that go into those numbers.</p><p><strong id=\"Possible_Automated_Analysis\">Possible Automated Analysis</strong></p><p>Once we arrive at the model above, we would have enough information to calculate the value of information (VOI) of additional certainty for each metric. For instance, a reduction of uncertainty of the variable \u2018Regular Lemonade at Dolores Park\u2019 to 0 could produce an expected few dollars per hour, assuming that resulting decisions would be made using the model.</p><p>The value of new options could also be calculated easily if one could come up with a probability distribution of their expected earnings per hour.</p><p>While these kinds of analysis are well established in academia, they are currently difficult to use. If estimations could be simply mapped, it may make them significantly more accessible.</p><p>&nbsp;</p><h2 id=\"Similar_Work\"><strong>Similar Work</strong></h2><p>This work can be seen as similar to Unified Modeling Language (UML) in that it attempts to graphically specify a complex system of knowledge. UML was an attempt to define a graphical language for software architecture. There were claims that programs that produced UML could be used to produce their corresponding programs. This hasn\u2019t really happened. The UML spec went through several versions and became so specific and complex that few programmers now bother with it. However, it did encourage the use of whiteboard modeling for other programmers and experiences some popularity with larger projects.</p><p>Graphical computer software is challenging. Most attempts have failed, but a few companies have had success with it. LabView is a popular visual programming tool used by scientists and engineers. It uses a Dataflow programming paradigm, which would also be appropriate for Graphical Assumption Modeling.</p><p>The theory of this work is similar to that of Probabilistic Graphical Models. These are typically more formal models aimed at computer input and output rather than direct human interaction.</p><h2 id=\"Future_Work\"><strong>Future Work</strong></h2><p>This research is very young. The diagrams could use more experimentation and exploration. We have not included a method for subtraction or division, for example. Even if they were better established, it could take a long time for them to become accepted by other communities.</p><p>It\u2019s obvious that if these models are useful, it would be valuable to have a computer program to make them. Ozzie Gooen has made a simple attempt called <a href=\"http://fermihub.com/\">Fermihub</a>. Fermihub is functional, free, and open source. However, it applies only a few simple analytic approximations and does not incorporate Monte Carlo simulations. For accurate or large models, Monte Carlo simulations will be necessary.</p><p>There could be more research done in this kind of estimation. While much of the math has already been solved, the art of efficiently creating large models and collaborating with others has a lot of work left. There is also some debate on the proper way to combine estimates, which is crucial for large models.</p><p><br>&nbsp;</p><p><strong>Note:</strong> I realize that the math in the models above, specifically in the combinations of estimates, is incorrect. &nbsp;I'm currently investigating how to do it correctly. &nbsp;&nbsp;</p><p>References</p><ol><li><a href=\"/lw/h5e/fermi_estimates/\">Fermi Estimates</a>, LukeProg. 2013</li><li>See <a href=\"http://en.wikipedia.org/wiki/Black_box\">wikipedia</a> for a high level understanding of black boxes. They are a fundamental unit for systems research, which in part has lead to many diagrams we see today.</li></ol>", "sections": [{"title": "The Flaws of Fermi Estimates", "anchor": "The_Flaws_of_Fermi_Estimates", "level": 1}, {"title": "Graphical Assumption Modeling", "anchor": "Graphical_Assumption_Modeling", "level": 1}, {"title": "Multiplication", "anchor": "Multiplication", "level": 2}, {"title": "Addition", "anchor": "Addition", "level": 2}, {"title": "Uncertainty", "anchor": "Uncertainty", "level": 2}, {"title": "Estimate Combination", "anchor": "Estimate_Combination", "level": 2}, {"title": "Model Combination", "anchor": "Model_Combination", "level": 2}, {"title": "Abstraction", "anchor": "Abstraction", "level": 2}, {"title": "Decision Making", "anchor": "Decision_Making", "level": 2}, {"title": "Larger Models", "anchor": "Larger_Models", "level": 2}, {"title": "Possible Automated Analysis", "anchor": "Possible_Automated_Analysis", "level": 2}, {"title": "Similar Work", "anchor": "Similar_Work", "level": 1}, {"title": "Future Work", "anchor": "Future_Work", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "23 comments"}], "headingsCount": 15}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["PsEppdvgRisz5xAHG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-04T02:58:53.627Z", "modifiedAt": null, "url": null, "title": "Tentative Thoughts on the Cost Effectiveness of the SENS Foundation", "slug": "tentative-thoughts-on-the-cost-effectiveness-of-the-sens", "viewCount": null, "lastCommentedAt": "2017-08-01T15:28:36.132Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Fluttershy", "createdAt": "2014-10-03T05:02:02.468Z", "isAdmin": false, "displayName": "Fluttershy"}, "userId": "sfxHxhdAnTjQFNsfE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KSCrHfeXZBHZLNEAs/tentative-thoughts-on-the-cost-effectiveness-of-the-sens", "pageUrlRelative": "/posts/KSCrHfeXZBHZLNEAs/tentative-thoughts-on-the-cost-effectiveness-of-the-sens", "linkUrl": "https://www.lesswrong.com/posts/KSCrHfeXZBHZLNEAs/tentative-thoughts-on-the-cost-effectiveness-of-the-sens", "postedAtFormatted": "Sunday, January 4th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tentative%20Thoughts%20on%20the%20Cost%20Effectiveness%20of%20the%20SENS%20Foundation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATentative%20Thoughts%20on%20the%20Cost%20Effectiveness%20of%20the%20SENS%20Foundation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKSCrHfeXZBHZLNEAs%2Ftentative-thoughts-on-the-cost-effectiveness-of-the-sens%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tentative%20Thoughts%20on%20the%20Cost%20Effectiveness%20of%20the%20SENS%20Foundation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKSCrHfeXZBHZLNEAs%2Ftentative-thoughts-on-the-cost-effectiveness-of-the-sens", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKSCrHfeXZBHZLNEAs%2Ftentative-thoughts-on-the-cost-effectiveness-of-the-sens", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 572, "htmlBody": "<p>Edit from fucking 2019: this is all obviously wrong, EA is a scam, do all your own analysis of everything if you want to have an impact</p><p>It should be emphasized that back-of-the-envelope calculations, such as the one given in this post, ought to be <a href=\"http://effective-altruism.com/ea/bb/expected_value_estimates_you_can_take_somewhat/\">adjusted</a> to account for the fact that interventions can <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">look much more cost-effective than they are</a>, especially when the interventions were only shallowly investigated.</p><p>Previously, Givewell has looked into the cost-effectiveness of <a href=\"http://blog.givewell.org/2013/12/26/scientific-research-funding/\">life</a> <a href=\"http://blog.givewell.org/2014/01/07/exploring-life-sciences-funding/\">sciences</a> <a href=\"http://blog.givewell.org/2014/01/15/returns-to-life-sciences-funding/\">funding</a>, as well as publishing a <a href=\"https://docs.google.com/a/trinity.edu/spreadsheets/d/1984cmL2R3IvjwpGg5ckXfBV5Q-qh8F4Flun1tIYZFw4/edit#gid=0\">simple estimate</a> of the impact of the average dollar spent on cancer research, which suggested that, in the past, each $2790 spent on cancer-relevant biomedical research in the US added one year of life lived (YLL) to the life of a US resident. Givewell has also <a href=\"/lw/gwg/sens_and_givewell_conversation_between_holden/\">interviewed</a> Aubrey de Grey of the SENS foundation. Owencb has previously <a href=\"http://effective-altruism.com/ea/c4/make_your_own_costeffectiveness_fermi_estimates/1rb\">estimated</a> the cost-effectiveness of funding SENS/ anti-aging research as being around $50 per QALY. Aubrey de Grey has previously <a href=\"https://80000hours.org/2012/04/living-to-1000-an-interview-with-aubrey-de-grey/\">been averse to giving explicit cost-effectiveness estimates</a> regarding how many QALYs would be gained per unit of funding supplied to SENS, though he has been clear that SENS&#x27;s funding needs are &quot;<a href=\"https://80000hours.org/2012/04/living-to-1000-an-interview-with-aubrey-de-grey/\">$100 million per year for each of the next ten years</a>&quot;.</p><br/><hr class=\"dividerBlock\"/><br/><p>This part of the post will consist of me using lots of best guesses to produce something vaguely resembling a cost-effectiveness estimate for SENS. You should <em>not</em> take this cost-effectiveness estimate literally.</p><p>If SENS needs one billion dollars to ensure that rejuvenation technologies that give individuals 30 extra years of healthy life are available to the public in 30 years, we might (completely arbitrarily<em>)</em> assume that someone else will come along and fund SENS in ten years if we don&#x27;t contribute to funding SENS today. This means that if we fund SENS today instead waiting for it to be hypothetically funded in ten years from now, about ten times the number of people who die each year would live 30 years of healthy life that they wouldn&#x27;t have lived otherwise. Given that there are about 57 million deaths per year worldwide, this translates to about 17 billion YLLs lost by waiting ten years to fund SENS; since SENS ostensibly requires only 1 billion of philanthropic funding, this implies that $0.059 of funding for SENS produces a YLL.</p><p>Of course, regenerative medicine won&#x27;t be free to the people receiving it, and I have no idea how to account for this, given that I don&#x27;t have a good idea of how much regenerative therapies will initially cost. The above estimate hasn&#x27;t been adjusted to account for the fact that there is a time-delay between when funding is provided, and when the benefits of regenerative therapies are available to the public. Perhaps Aubrey <a href=\"http://acritch.com/credence-game/\">isn&#x27;t well-calibrated</a>, and the &quot;$100 million per year for ten years&quot; figure is entirely wrong. It may be the case that starting work on SENS&#x27;s research agenda earlier rather than later would allow certain people who would have otherwise died to live until aging escape velocity is reached, which would have lots of utility. There are plenty of other issues with this cost-effectiveness estimate which I am sure that readers could point out.</p><p>The point I wanted to make, though, was that maybe, possibly, SENS is competitive with GiveWell&#x27;s top charities-- I&#x27;m legitimately not sure whether I would fund SENS or GiveWell if I were making a charitable donation today. Does anyone have any further thoughts on this topic?</p>", "submitToFrontpage": false, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KSCrHfeXZBHZLNEAs", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 8, "extendedScore": null, "score": 2.335235808595985e-06, "legacy": true, "legacyId": "27837", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["iYN9wW7ePXDT5ZRSE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-04T07:27:48.010Z", "modifiedAt": null, "url": null, "title": "Meetup : [NYC] New Years Resolutions", "slug": "meetup-nyc-new-years-resolutions", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8aTrtksxF5Fo7Nyhn/meetup-nyc-new-years-resolutions", "pageUrlRelative": "/posts/8aTrtksxF5Fo7Nyhn/meetup-nyc-new-years-resolutions", "linkUrl": "https://www.lesswrong.com/posts/8aTrtksxF5Fo7Nyhn/meetup-nyc-new-years-resolutions", "postedAtFormatted": "Sunday, January 4th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BNYC%5D%20New%20Years%20Resolutions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BNYC%5D%20New%20Years%20Resolutions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8aTrtksxF5Fo7Nyhn%2Fmeetup-nyc-new-years-resolutions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BNYC%5D%20New%20Years%20Resolutions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8aTrtksxF5Fo7Nyhn%2Fmeetup-nyc-new-years-resolutions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8aTrtksxF5Fo7Nyhn%2Fmeetup-nyc-new-years-resolutions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 91, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18k'>[NYC] New Years Resolutions</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">06 January 2015 07:00:37PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">353 East 17th Street APT 21B New York NY 10003</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Each year, the New York Rationality group meets to discuss our goals from the previous year, see how we have fared, and help each other plan resolutions that are actionable and likely to succeed. Whether you're an old timer or have just arrived in NYC, you're welcome to join in our yearly tradition. Begins at 7pm.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18k'>[NYC] New Years Resolutions</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8aTrtksxF5Fo7Nyhn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.3e-05, "legacy": true, "legacyId": "27845", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____NYC__New_Years_Resolutions\">Discussion article for the meetup : <a href=\"/meetups/18k\">[NYC] New Years Resolutions</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">06 January 2015 07:00:37PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">353 East 17th Street APT 21B New York NY 10003</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Each year, the New York Rationality group meets to discuss our goals from the previous year, see how we have fared, and help each other plan resolutions that are actionable and likely to succeed. Whether you're an old timer or have just arrived in NYC, you're welcome to join in our yearly tradition. Begins at 7pm.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____NYC__New_Years_Resolutions1\">Discussion article for the meetup : <a href=\"/meetups/18k\">[NYC] New Years Resolutions</a></h2>", "sections": [{"title": "Discussion article for the meetup : [NYC] New Years Resolutions", "anchor": "Discussion_article_for_the_meetup____NYC__New_Years_Resolutions", "level": 1}, {"title": "Discussion article for the meetup : [NYC] New Years Resolutions", "anchor": "Discussion_article_for_the_meetup____NYC__New_Years_Resolutions1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-04T14:06:06.292Z", "modifiedAt": null, "url": null, "title": "Problems and Solutions in Infinite Ethics", "slug": "problems-and-solutions-in-infinite-ethics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:31.062Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Xodarap", "createdAt": "2010-02-04T03:26:20.706Z", "isAdmin": false, "displayName": "Xodarap"}, "userId": "MXzEw56rk32JjM2Gp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LXiPL4v5SRsfcy86h/problems-and-solutions-in-infinite-ethics", "pageUrlRelative": "/posts/LXiPL4v5SRsfcy86h/problems-and-solutions-in-infinite-ethics", "linkUrl": "https://www.lesswrong.com/posts/LXiPL4v5SRsfcy86h/problems-and-solutions-in-infinite-ethics", "postedAtFormatted": "Sunday, January 4th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Problems%20and%20Solutions%20in%20Infinite%20Ethics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProblems%20and%20Solutions%20in%20Infinite%20Ethics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXiPL4v5SRsfcy86h%2Fproblems-and-solutions-in-infinite-ethics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Problems%20and%20Solutions%20in%20Infinite%20Ethics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXiPL4v5SRsfcy86h%2Fproblems-and-solutions-in-infinite-ethics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXiPL4v5SRsfcy86h%2Fproblems-and-solutions-in-infinite-ethics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1378, "htmlBody": "<p>(Crossposted from the <a href=\"http://effective-altruism.com/ea/d6/problems_and_solutions_in_infinite_ethics/\">EA forum</a>.)</p>\n<p><strong>Summary:</strong>&nbsp;The universe may very well be infinite, and hence contain an infinite amount of happiness and sadness. This causes several problems for altruists; for example: we can plausibly only affect a finite subset of the universe, and an infinite quantity of happiness is unchanged by the addition or subtraction of a finite amount of happiness. This would imply that all forms of altruism are equally ineffective.</p>\n<p>Like everything in life, the&nbsp;<a href=\"http://www.nickbostrom.com/ethics/infinite.pdf\">canonical reference</a>&nbsp;in philosophy about this problem was written by Nick Bostrom. However, I found that an area of economics known as \"sustainable development\" has actually made much further progress on this subject than the philosophy world. In this post I go over some of what I consider to be the most interesting results.</p>\n<p><strong>NB:</strong>&nbsp;This assumes a lot of mathematical literacy and familiarity with the subject matter, and hence isn't targeted to a general audience. Most people will probably prefer to read my other posts:</p>\n<ul>\n<li>&nbsp;<a href=\"http://philosophyforprogrammers.blogspot.com/2014/09/ridiculous-math-shit-which-ethics.html\">Ridiculous math things which ethics shouldn't depend on but does</a>, which includes such interesting tidbits as: why standard calculus teaches children to be immoral and why the Banach-Tarski paradox implies we should means test Medicare and</li>\n<li><a href=\"http://philosophyforprogrammers.blogspot.com/2012/11/why-old-people-matter-more.html\">Kill the young people</a>, whose name speaks for itself</li>\n</ul>\n<div><br /></div>\n<h1>1. Summary of the most interesting results</h1>\n<ol>\n<li>There&rsquo;s no ethical system which incorporates all the things we might want.</li>\n<li>Even if we have pretty minimal requirements, satisfactory ethical systems might exist but we can&rsquo;t&nbsp;<em>prove&nbsp;</em>their existence, much less actually construct them</li>\n<li>Discounted utilitarianism, whereby we value people less just because they are further away in time, is actually a pretty reasonable thing despite philosophers considering it ridiculous.<ol>\n<li>(I consider this to be the first reasonable argument for locavorism I've ever heard)</li>\n</ol></li>\n</ol>\n<h1>2. Definitions</h1>\n<p class=\"MsoNormal\">In general, we consider a population to consist of an infinite utility vector&nbsp;<em>(u<sub>0</sub>,u<sub>1</sub>,&hellip;)</em>&nbsp;where&nbsp;<em>u<sub>i</sub></em>&nbsp;is the aggregate utility of the generation alive at time&nbsp;<em>i</em>. Utility is a&nbsp;<span style=\"text-decoration: underline;\">bounded</span>&nbsp;real number (the fact that economists assume utility to be bounded confused me for a long time!). Our goal is to find a preference ordering over the set of all utility vectors which is in some sense &ldquo;reasonable&rdquo;. While philosophers have understood for a long time that finding such an ordering is difficult, I will present several theorems which show that it is in fact impossible.</p>\n<p class=\"MsoNormal\">Due to a lack of latex support I&rsquo;m going to give English-language definitions and results instead of math-ey ones; interested people should look at the papers themselves anyway.</p>\n<h1>3. Impossibility Results</h1>\n<h2>3.1 Definitions</h2>\n<ul>\n<li>Strong Pareto: if you can make a generation better off, and none worse off, you should.</li>\n<li>Weak Pareto: if you can make every generation better off, you should.</li>\n<li>Intergenerational equity: utility vectors are unchanged in value by any permutation of their components. \n<ul>\n<li>There is an important distinction here between allowing a finite number of elements to be permuted and an infinite number; I will refer to the former as &ldquo;finite intergenerational equity&rdquo; and the latter as just &ldquo;intergenerational equity&rdquo;</li>\n</ul>\n</li>\n<li>Ethical relation: one which obeys both weak Pareto and intergenerational equity</li>\n<li>Social welfare function: an order-preserving function from the set of populations (utility vectors) to the real numbers</li>\n</ul>\n<h2>3.2 Diamond-Basu-Mitra Impossibility Result<sup style=\"color: #222222; font-family: Arial, sans-serif; line-height: 107%;\">1</sup></h2>\n<ol>\n<li>There is no social welfare function which obeys Strong Pareto and finite intergenerational equity. This means that any sort of utilitarianism won&rsquo;t work, unless we look outside the real numbers.</li>\n</ol>\n<h2>3.3 Zame's impossibility result<sup>2</sup></h2>\n<ol>\n<li>If an ordering obeys intergenerational equity over [0,1]<sup>N</sup>, then almost always we can&rsquo;t tell which of two populations is better&nbsp;<ol>\n<li>(i.e. the set of populations&nbsp;<em>{X,Y: neither X&lt;Y nor X&gt;Y}</em>&nbsp;has outer measure one)</li>\n</ol></li>\n<li>The existence of an ethical preference relation on [0,1]<sup>N</sup>&nbsp;is independent of ZF plus the axiom of choice</li>\n</ol>\n<h1>4. Possibility Results</h1>\n<p class=\"MsoNormal\">We&rsquo;ve just shown that it&rsquo;s impossible to construct or even prove the existence of any useful ethical system. But not all hope is lost!</p>\n<p class=\"MsoNormal\">The important idea here is that of a &ldquo;subrelation&rdquo;: &lt; is a subrelation to &lt;&rsquo; if x&lt;y implies x&lt;&rsquo;y.</p>\n<p class=\"MsoNormal\">Our arguments will work like this:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Suppose we&nbsp;<em>could</em>&nbsp;extend utilitarianism to the infinite case. (We don't, of course, know that we&nbsp;<em>can&nbsp;</em>extend utilitarianism to the infinite case. But suppose we could.) Then A, B and C must follow.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Technically: suppose utilitarianism is a subrelation of &lt;. Then &lt; must have properties A, B and C.</p>\n<p><span style=\"font-size: 10pt; line-height: 107%; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Everything in this section comes from (3),</span>&nbsp;which is a great review of the literature.</p>\n<h2>4.1 Definition</h2>\n<ul>\n<li>Utilitarianism: we extend the standard total utilitarianism ordering to infinite populations in the following way: suppose there is some time T after which every generation in X is at least as well off as every generation in Y, and that the total utility in X before T is at least as good as the total utility in Y before T. Then X is at least as good as Y. \n<ul>\n<li>Note that this is not a complete ordering! In fact, as per Zame&rsquo;s result above, the set of populations it can meaningfully speak about has measure zero.</li>\n</ul>\n</li>\n<li>Partial translation scale invariance: suppose after some time T, X and Y become the same. Then we can add any arbitrary utility vector A to both X and Y without changing the ordering. (I.e. X &gt; Y&nbsp;<span style=\"font-family:Wingdings;mso-ascii-font-family:Calibri;mso-ascii-theme-font: minor-latin;mso-hansi-font-family:Calibri;mso-hansi-theme-font:minor-latin; mso-char-type:symbol;mso-symbol-font-family:Wingdings\">&oacute;</span>&nbsp;X+A &gt; Y+A)</li>\n</ul>\n<h2>4.2 Theorem</h2>\n<ol>\n<li>Utilitarianism is a subrelation of &gt; if and only if &gt; satisfies strong Pareto, finite intergenerational equity and partial translation scale invariance.<ol>\n<li>This means that if we want to extend utilitarianism to the infinite case, we can&rsquo;t use a social welfare function, as per the above Basu-Mitra result</li>\n</ol></li>\n</ol>\n<h2>4.3 Definition</h2>\n<ul>\n<li>Overtaking utilitarianism: suppose there is some point T after which the total utility of the first N generations in X is always greater than the total utility of the first N generations in Y (given N &gt; T). Then X is better than Y. \n<ul>\n<li>Note that utilitarianism is a subrelation of overtaking utilitarianism</li>\n</ul>\n</li>\n<li>Weak limiting preference: suppose that for any time T, X truncated at time T is better than Y truncated at time T. Then X is better than Y.</li>\n</ul>\n<h2>4.4 Theorem</h2>\n<ol>\n<li>Overtaking&nbsp;utilitarianism is a subrelation of &lt; if and only if &lt; satisfies strong Pareto, finite intergenerational equity, partial translation scale invariance, and weak limiting preference</li>\n</ol>\n<h2>4.5 Definition</h2>\n<ul>\n<li>Discounted utilitarianism: the utility of a population is the sum of its components, discounted by how far away in time they are</li>\n<li>Separability: \n<ul>\n<li>Separable present: if you can improve the first T generations without affecting the rest, you should</li>\n<li>Separable future: if you can improve everything after the first T generations without affecting the rest, you should</li>\n</ul>\n</li>\n<li>Stationarity: preferences are time invariant</li>\n<li>Weak sensitivity: for any utility vector, we can modify its first generation somehow to make it better</li>\n</ul>\n<h2>4.6 Theorem</h2>\n<ol>\n<li>The only continuous, monotonic relation which obeys weak sensitivity, stationary, and separability is discounted utilitarianism</li>\n</ol>\n<h2>4.7 Definition</h2>\n<ul>\n<li>Dictatorship of the present: there&rsquo;s some time T after which changing the utility of generations doesn&rsquo;t matter</li>\n</ul>\n<h2>4.8 Theorem</h2>\n<ol>\n<li>Discounted utilitarianism results in a dictatorship of the present. (Remember that each generation&rsquo;s utility is assumed to be bounded!)</li>\n</ol>\n<div>\n<h2>4.9 Definition</h2>\n</div>\n<ul>\n<li>Sustainable preference: a continuous ordering which doesn&rsquo;t have a dictatorship of the present but follows strong Pareto and separability.</li>\n</ul>\n<h2>4.10 Theorem</h2>\n<ol>\n<li>The only ordering which is sustainable is to take discounted utilitarianism and add an &ldquo;asymptotic&rdquo; part which ensures that infinitely long changes in utility matter. (Of course, finite changes in utility still won't matter.)</li>\n</ol>\n<h1>5. Conclusion</h1>\n<p>I hope I've convinced you that there's a \"there\" there: infinite ethics is something that people can make progress on, and it seems that most of the progress is being made in the field of sustainable development.</p>\n<p>Fun fact: the author of the last theorem (the one which defined \"sustainable\") was one of the lead economists on the Kyoto protocol. Who says infinite ethics is impractical?</p>\n<h1>6. References</h1>\n<ol>\n<li><span style=\"font-size: 10pt; line-height: 14.2666664123535px; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Basu, Kaushik, and Tapan Mitra. \"Aggregating infinite utility streams with intergenerational equity: the impossibility of being Paretian.\"&nbsp;</span><em>Econometrica</em>&nbsp;71.5 (2003): 1557-1563.&nbsp;<a href=\"http://folk.uio.no/gasheim/zB%26M2003.pdf\">http://folk.uio.no/gasheim/zB%26M2003.pdf</a></li>\n<li><span style=\"font-size: 10pt; line-height: 107%; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Zame, William R. \"Can intergenerational equity be operationalized?.\" (2007).&nbsp;</span>&nbsp;<a href=\"https://tspace.library.utoronto.ca/bitstream/1807/9745/1/1204.pdf\">https://tspace.library.utoronto.ca/bitstream/1807/9745/1/1204.pdf</a></li>\n<li><span style=\"font-size: 10pt; line-height: 107%; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Asheim, Geir B. \"Intergenerational equity.\"&nbsp;</span><em>Annu. Rev. Econ.</em>&nbsp;2.1 (2010): 197-222.<a href=\"http://folk.uio.no/gasheim/A-ARE10.pdf\">http://folk.uio.no/gasheim/A-ARE10.pdf</a></li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LXiPL4v5SRsfcy86h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 2.336808311315442e-06, "legacy": true, "legacyId": "27847", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>(Crossposted from the <a href=\"http://effective-altruism.com/ea/d6/problems_and_solutions_in_infinite_ethics/\">EA forum</a>.)</p>\n<p><strong>Summary:</strong>&nbsp;The universe may very well be infinite, and hence contain an infinite amount of happiness and sadness. This causes several problems for altruists; for example: we can plausibly only affect a finite subset of the universe, and an infinite quantity of happiness is unchanged by the addition or subtraction of a finite amount of happiness. This would imply that all forms of altruism are equally ineffective.</p>\n<p>Like everything in life, the&nbsp;<a href=\"http://www.nickbostrom.com/ethics/infinite.pdf\">canonical reference</a>&nbsp;in philosophy about this problem was written by Nick Bostrom. However, I found that an area of economics known as \"sustainable development\" has actually made much further progress on this subject than the philosophy world. In this post I go over some of what I consider to be the most interesting results.</p>\n<p><strong>NB:</strong>&nbsp;This assumes a lot of mathematical literacy and familiarity with the subject matter, and hence isn't targeted to a general audience. Most people will probably prefer to read my other posts:</p>\n<ul>\n<li>&nbsp;<a href=\"http://philosophyforprogrammers.blogspot.com/2014/09/ridiculous-math-shit-which-ethics.html\">Ridiculous math things which ethics shouldn't depend on but does</a>, which includes such interesting tidbits as: why standard calculus teaches children to be immoral and why the Banach-Tarski paradox implies we should means test Medicare and</li>\n<li><a href=\"http://philosophyforprogrammers.blogspot.com/2012/11/why-old-people-matter-more.html\">Kill the young people</a>, whose name speaks for itself</li>\n</ul>\n<div><br></div>\n<h1 id=\"1__Summary_of_the_most_interesting_results\">1. Summary of the most interesting results</h1>\n<ol>\n<li>There\u2019s no ethical system which incorporates all the things we might want.</li>\n<li>Even if we have pretty minimal requirements, satisfactory ethical systems might exist but we can\u2019t&nbsp;<em>prove&nbsp;</em>their existence, much less actually construct them</li>\n<li>Discounted utilitarianism, whereby we value people less just because they are further away in time, is actually a pretty reasonable thing despite philosophers considering it ridiculous.<ol>\n<li>(I consider this to be the first reasonable argument for locavorism I've ever heard)</li>\n</ol></li>\n</ol>\n<h1 id=\"2__Definitions\">2. Definitions</h1>\n<p class=\"MsoNormal\">In general, we consider a population to consist of an infinite utility vector&nbsp;<em>(u<sub>0</sub>,u<sub>1</sub>,\u2026)</em>&nbsp;where&nbsp;<em>u<sub>i</sub></em>&nbsp;is the aggregate utility of the generation alive at time&nbsp;<em>i</em>. Utility is a&nbsp;<span style=\"text-decoration: underline;\">bounded</span>&nbsp;real number (the fact that economists assume utility to be bounded confused me for a long time!). Our goal is to find a preference ordering over the set of all utility vectors which is in some sense \u201creasonable\u201d. While philosophers have understood for a long time that finding such an ordering is difficult, I will present several theorems which show that it is in fact impossible.</p>\n<p class=\"MsoNormal\">Due to a lack of latex support I\u2019m going to give English-language definitions and results instead of math-ey ones; interested people should look at the papers themselves anyway.</p>\n<h1 id=\"3__Impossibility_Results\">3. Impossibility Results</h1>\n<h2 id=\"3_1_Definitions\">3.1 Definitions</h2>\n<ul>\n<li>Strong Pareto: if you can make a generation better off, and none worse off, you should.</li>\n<li>Weak Pareto: if you can make every generation better off, you should.</li>\n<li>Intergenerational equity: utility vectors are unchanged in value by any permutation of their components. \n<ul>\n<li>There is an important distinction here between allowing a finite number of elements to be permuted and an infinite number; I will refer to the former as \u201cfinite intergenerational equity\u201d and the latter as just \u201cintergenerational equity\u201d</li>\n</ul>\n</li>\n<li>Ethical relation: one which obeys both weak Pareto and intergenerational equity</li>\n<li>Social welfare function: an order-preserving function from the set of populations (utility vectors) to the real numbers</li>\n</ul>\n<h2 id=\"3_2_Diamond_Basu_Mitra_Impossibility_Result1\">3.2 Diamond-Basu-Mitra Impossibility Result<sup style=\"color: #222222; font-family: Arial, sans-serif; line-height: 107%;\">1</sup></h2>\n<ol>\n<li>There is no social welfare function which obeys Strong Pareto and finite intergenerational equity. This means that any sort of utilitarianism won\u2019t work, unless we look outside the real numbers.</li>\n</ol>\n<h2 id=\"3_3_Zame_s_impossibility_result2\">3.3 Zame's impossibility result<sup>2</sup></h2>\n<ol>\n<li>If an ordering obeys intergenerational equity over [0,1]<sup>N</sup>, then almost always we can\u2019t tell which of two populations is better&nbsp;<ol>\n<li>(i.e. the set of populations&nbsp;<em>{X,Y: neither X&lt;Y nor X&gt;Y}</em>&nbsp;has outer measure one)</li>\n</ol></li>\n<li>The existence of an ethical preference relation on [0,1]<sup>N</sup>&nbsp;is independent of ZF plus the axiom of choice</li>\n</ol>\n<h1 id=\"4__Possibility_Results\">4. Possibility Results</h1>\n<p class=\"MsoNormal\">We\u2019ve just shown that it\u2019s impossible to construct or even prove the existence of any useful ethical system. But not all hope is lost!</p>\n<p class=\"MsoNormal\">The important idea here is that of a \u201csubrelation\u201d: &lt; is a subrelation to &lt;\u2019 if x&lt;y implies x&lt;\u2019y.</p>\n<p class=\"MsoNormal\">Our arguments will work like this:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Suppose we&nbsp;<em>could</em>&nbsp;extend utilitarianism to the infinite case. (We don't, of course, know that we&nbsp;<em>can&nbsp;</em>extend utilitarianism to the infinite case. But suppose we could.) Then A, B and C must follow.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Technically: suppose utilitarianism is a subrelation of &lt;. Then &lt; must have properties A, B and C.</p>\n<p><span style=\"font-size: 10pt; line-height: 107%; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Everything in this section comes from (3),</span>&nbsp;which is a great review of the literature.</p>\n<h2 id=\"4_1_Definition\">4.1 Definition</h2>\n<ul>\n<li>Utilitarianism: we extend the standard total utilitarianism ordering to infinite populations in the following way: suppose there is some time T after which every generation in X is at least as well off as every generation in Y, and that the total utility in X before T is at least as good as the total utility in Y before T. Then X is at least as good as Y. \n<ul>\n<li>Note that this is not a complete ordering! In fact, as per Zame\u2019s result above, the set of populations it can meaningfully speak about has measure zero.</li>\n</ul>\n</li>\n<li>Partial translation scale invariance: suppose after some time T, X and Y become the same. Then we can add any arbitrary utility vector A to both X and Y without changing the ordering. (I.e. X &gt; Y&nbsp;<span style=\"font-family:Wingdings;mso-ascii-font-family:Calibri;mso-ascii-theme-font: minor-latin;mso-hansi-font-family:Calibri;mso-hansi-theme-font:minor-latin; mso-char-type:symbol;mso-symbol-font-family:Wingdings\">\u00f3</span>&nbsp;X+A &gt; Y+A)</li>\n</ul>\n<h2 id=\"4_2_Theorem\">4.2 Theorem</h2>\n<ol>\n<li>Utilitarianism is a subrelation of &gt; if and only if &gt; satisfies strong Pareto, finite intergenerational equity and partial translation scale invariance.<ol>\n<li>This means that if we want to extend utilitarianism to the infinite case, we can\u2019t use a social welfare function, as per the above Basu-Mitra result</li>\n</ol></li>\n</ol>\n<h2 id=\"4_3_Definition\">4.3 Definition</h2>\n<ul>\n<li>Overtaking utilitarianism: suppose there is some point T after which the total utility of the first N generations in X is always greater than the total utility of the first N generations in Y (given N &gt; T). Then X is better than Y. \n<ul>\n<li>Note that utilitarianism is a subrelation of overtaking utilitarianism</li>\n</ul>\n</li>\n<li>Weak limiting preference: suppose that for any time T, X truncated at time T is better than Y truncated at time T. Then X is better than Y.</li>\n</ul>\n<h2 id=\"4_4_Theorem\">4.4 Theorem</h2>\n<ol>\n<li>Overtaking&nbsp;utilitarianism is a subrelation of &lt; if and only if &lt; satisfies strong Pareto, finite intergenerational equity, partial translation scale invariance, and weak limiting preference</li>\n</ol>\n<h2 id=\"4_5_Definition\">4.5 Definition</h2>\n<ul>\n<li>Discounted utilitarianism: the utility of a population is the sum of its components, discounted by how far away in time they are</li>\n<li>Separability: \n<ul>\n<li>Separable present: if you can improve the first T generations without affecting the rest, you should</li>\n<li>Separable future: if you can improve everything after the first T generations without affecting the rest, you should</li>\n</ul>\n</li>\n<li>Stationarity: preferences are time invariant</li>\n<li>Weak sensitivity: for any utility vector, we can modify its first generation somehow to make it better</li>\n</ul>\n<h2 id=\"4_6_Theorem\">4.6 Theorem</h2>\n<ol>\n<li>The only continuous, monotonic relation which obeys weak sensitivity, stationary, and separability is discounted utilitarianism</li>\n</ol>\n<h2 id=\"4_7_Definition\">4.7 Definition</h2>\n<ul>\n<li>Dictatorship of the present: there\u2019s some time T after which changing the utility of generations doesn\u2019t matter</li>\n</ul>\n<h2 id=\"4_8_Theorem\">4.8 Theorem</h2>\n<ol>\n<li>Discounted utilitarianism results in a dictatorship of the present. (Remember that each generation\u2019s utility is assumed to be bounded!)</li>\n</ol>\n<div>\n<h2 id=\"4_9_Definition\">4.9 Definition</h2>\n</div>\n<ul>\n<li>Sustainable preference: a continuous ordering which doesn\u2019t have a dictatorship of the present but follows strong Pareto and separability.</li>\n</ul>\n<h2 id=\"4_10_Theorem\">4.10 Theorem</h2>\n<ol>\n<li>The only ordering which is sustainable is to take discounted utilitarianism and add an \u201casymptotic\u201d part which ensures that infinitely long changes in utility matter. (Of course, finite changes in utility still won't matter.)</li>\n</ol>\n<h1 id=\"5__Conclusion\">5. Conclusion</h1>\n<p>I hope I've convinced you that there's a \"there\" there: infinite ethics is something that people can make progress on, and it seems that most of the progress is being made in the field of sustainable development.</p>\n<p>Fun fact: the author of the last theorem (the one which defined \"sustainable\") was one of the lead economists on the Kyoto protocol. Who says infinite ethics is impractical?</p>\n<h1 id=\"6__References\">6. References</h1>\n<ol>\n<li><span style=\"font-size: 10pt; line-height: 14.2666664123535px; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Basu, Kaushik, and Tapan Mitra. \"Aggregating infinite utility streams with intergenerational equity: the impossibility of being Paretian.\"&nbsp;</span><em>Econometrica</em>&nbsp;71.5 (2003): 1557-1563.&nbsp;<a href=\"http://folk.uio.no/gasheim/zB%26M2003.pdf\">http://folk.uio.no/gasheim/zB%26M2003.pdf</a></li>\n<li><span style=\"font-size: 10pt; line-height: 107%; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Zame, William R. \"Can intergenerational equity be operationalized?.\" (2007).&nbsp;</span>&nbsp;<a href=\"https://tspace.library.utoronto.ca/bitstream/1807/9745/1/1204.pdf\">https://tspace.library.utoronto.ca/bitstream/1807/9745/1/1204.pdf</a></li>\n<li><span style=\"font-size: 10pt; line-height: 107%; font-family: Arial, sans-serif; color: #222222; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial;\">Asheim, Geir B. \"Intergenerational equity.\"&nbsp;</span><em>Annu. Rev. Econ.</em>&nbsp;2.1 (2010): 197-222.<a href=\"http://folk.uio.no/gasheim/A-ARE10.pdf\">http://folk.uio.no/gasheim/A-ARE10.pdf</a></li>\n</ol>", "sections": [{"title": "1. Summary of the most interesting results", "anchor": "1__Summary_of_the_most_interesting_results", "level": 1}, {"title": "2. Definitions", "anchor": "2__Definitions", "level": 1}, {"title": "3. Impossibility Results", "anchor": "3__Impossibility_Results", "level": 1}, {"title": "3.1 Definitions", "anchor": "3_1_Definitions", "level": 2}, {"title": "3.2 Diamond-Basu-Mitra Impossibility Result1", "anchor": "3_2_Diamond_Basu_Mitra_Impossibility_Result1", "level": 2}, {"title": "3.3 Zame's impossibility result2", "anchor": "3_3_Zame_s_impossibility_result2", "level": 2}, {"title": "4. Possibility Results", "anchor": "4__Possibility_Results", "level": 1}, {"title": "4.1 Definition", "anchor": "4_1_Definition", "level": 2}, {"title": "4.2 Theorem", "anchor": "4_2_Theorem", "level": 2}, {"title": "4.3 Definition", "anchor": "4_3_Definition", "level": 2}, {"title": "4.4 Theorem", "anchor": "4_4_Theorem", "level": 2}, {"title": "4.5 Definition", "anchor": "4_5_Definition", "level": 2}, {"title": "4.6 Theorem", "anchor": "4_6_Theorem", "level": 2}, {"title": "4.7 Definition", "anchor": "4_7_Definition", "level": 2}, {"title": "4.8 Theorem", "anchor": "4_8_Theorem", "level": 2}, {"title": "4.9 Definition", "anchor": "4_9_Definition", "level": 2}, {"title": "4.10 Theorem", "anchor": "4_10_Theorem", "level": 2}, {"title": "5. Conclusion", "anchor": "5__Conclusion", "level": 1}, {"title": "6. References", "anchor": "6__References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 21}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-04T14:32:19.829Z", "modifiedAt": null, "url": null, "title": "Why do you really believe what you believe regarding controversial subjects?", "slug": "why-do-you-really-believe-what-you-believe-regarding", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:09.446Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "iarwain1", "createdAt": "2013-10-29T15:19:43.635Z", "isAdmin": false, "displayName": "iarwain1"}, "userId": "X2k5DW8qrCTeD2N8d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FYRGgxtueHvAEsg4X/why-do-you-really-believe-what-you-believe-regarding", "pageUrlRelative": "/posts/FYRGgxtueHvAEsg4X/why-do-you-really-believe-what-you-believe-regarding", "linkUrl": "https://www.lesswrong.com/posts/FYRGgxtueHvAEsg4X/why-do-you-really-believe-what-you-believe-regarding", "postedAtFormatted": "Sunday, January 4th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20do%20you%20really%20believe%20what%20you%20believe%20regarding%20controversial%20subjects%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20do%20you%20really%20believe%20what%20you%20believe%20regarding%20controversial%20subjects%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFYRGgxtueHvAEsg4X%2Fwhy-do-you-really-believe-what-you-believe-regarding%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20do%20you%20really%20believe%20what%20you%20believe%20regarding%20controversial%20subjects%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFYRGgxtueHvAEsg4X%2Fwhy-do-you-really-believe-what-you-believe-regarding", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFYRGgxtueHvAEsg4X%2Fwhy-do-you-really-believe-what-you-believe-regarding", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 947, "htmlBody": "<p>For every controversial subject I've heard of, there are always numerous very smart experts on either side. So I'm curious how it is that rational non-experts come to believe one side or the other.</p>\n<p>So, what are your meta-arguments for going with one side or the other for any given controversial subject on which you have an opinion?</p>\n<ul>\n<li>Have you researched both sides so thoroughly that you consider yourself equal to or better than the opposing experts? If so, to what do you attribute the mistakes of your counterparts? Have you carefully considered the possibility that <em>you</em>&nbsp;are the one who's mistaken?</li>\n<li>Do you think that one side is more biased the other? Why?</li>\n<li>Do you think that one side is more expert than the other? Why?</li>\n<li>Do you rely on the majority of experts? (I haven't worked out for myself if going with a majority makes sense, so if you have arguments for / against this meta-argument then please elaborate.)</li>\n<li>Do you think that there are powerful arguments that simply haven't been addressed by the other side? To what do you attribute the fact that these arguments haven't been addressed?</li>\n<li>Do you have other heuristics or meta-arguments for going with one side or the other?</li>\n<li>Do you just remain more or less an agnostic on every controversial subject?</li>\n<li>Or do you perhaps admit that ultimately your beliefs are at least partially founded on non-rational reasons?</li>\n<li>Do you think that this whole discussion is misguided? If so, why?</li>\n</ul>\n<div>I know I don't have to list controversial subjects, but here are some to perhaps stimulate some thinking: Politics, religion (theism OR<em>&nbsp;</em>atheism), dangers from AI / x-risks, Bayesianism vs. alternatives, ethics &amp; metaethics, pretty much everything in philosophy (at least that's what it often seems like!), social justice issues, policy proposals of all types. (If you have a particular controversy for which you'd like people to list their meta-arguments, just mention it in the comments.)</div>\n<div><br /></div>\n<div>\n<hr />\n</div>\n<div><br /></div>\n<div><strong>ETA:</strong>&nbsp;For myself, I generally try not to have an opinion on almost any controversial issue. So for example, on the recent LW survey I deliberately left most of the controversial issue questions blank. On the few issues that I do have some opinion, it's generally because I attribute a higher likelihood of bias to one side or the other, and/or I judge one side or the other to be greater experts, and/or there's a very large majority on one side, and/or there are powerful arguments on one side plus I have a good explanation for why the other side hasn't addressed those arguments. And even after all that I usually don't assign a high confidence to my judgement.</div>\n<div><br /></div>\n<div>There's an interesting question that might follow from this approach: Other than curiosity, what is the use of researching a given subject if I'll never really be an expert and ultimately I'm going to need to fall back on the above types of meta-arguments? However, I've found that actually researching the subject is useful for a number of reasons:</div>\n<div>\n<ul>\n<li>Often after research it turns out that there are a surprising number of important points on which both sides actually agree.</li>\n<li>It often turns out that one or both sides are not as confident about their positions as it might initially seem.</li>\n<li>Often there are a number of sub-issues for which some of the above meta-arguments apply even if they might not apply to the broader issues. For example, perhaps there is a vast majority of experts who agree on a certain sub-issue even while debating the broader subject.</li>\n<li>Occasionally the arguments ultimately boil down to things that fall outside the domain of rational debate.</li>\n<li>Sometimes on the surface it may seem that someone is an expert, but on further research it turns out that they are relying on arguments outside their field of expertise. For example, many studies are faulty due to subtle statistics issues. The authors may be expert scientists / researchers, but subtle statistics falls outside their domain of expertise.</li>\n<li>Occasionally I've come up with an argument (usually a domain-specific meta-argument of some sort) that I'm pretty sure even the experts on the other side would agree with, and for which I can give a good argument why they haven't addressed this particular argument before. Of course, I need to take my own arguments with a large grain of \"I'm not really an expert on this\" salt. But I've also in the past simply contacted one of the experts and asked him what he thought of my argument - and he agreed. In that particular instance the expert didn't change his mind, but the reason he gave for not changing his mind made me strongly suspect him of bias.</li>\n<li>For a few issues, especially some of the really small sub-issues, it's actually not all that hard to become an expert. You take out a few books from your local university library, read the latest half dozen articles published on the topic, and that's about it. Of course, even after you're an expert you should still probably take the outside view and ask why you think your expert opinion is better than the other guy's. But it's still <em>something</em>, and perhaps you'll even be able to contribute to the field in a meaningful way and change some others' opinions. At the very least you'll likely be in a better position to judge other experts' biases and levels of expertise.</li>\n</ul>\n<div>Relevant: posts listed on the bottom of the LW wiki page on&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Disagreement\">disagreement</a></div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FYRGgxtueHvAEsg4X", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 2.3368701588508717e-06, "legacy": true, "legacyId": "27848", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-04T15:03:29.091Z", "modifiedAt": null, "url": null, "title": "Inverse relationship between belief in foom and years worked in commercial software", "slug": "inverse-relationship-between-belief-in-foom-and-years-worked", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:22.670Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nCXiDq24cP6yK6NvG/inverse-relationship-between-belief-in-foom-and-years-worked", "pageUrlRelative": "/posts/nCXiDq24cP6yK6NvG/inverse-relationship-between-belief-in-foom-and-years-worked", "linkUrl": "https://www.lesswrong.com/posts/nCXiDq24cP6yK6NvG/inverse-relationship-between-belief-in-foom-and-years-worked", "postedAtFormatted": "Sunday, January 4th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Inverse%20relationship%20between%20belief%20in%20foom%20and%20years%20worked%20in%20commercial%20software&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInverse%20relationship%20between%20belief%20in%20foom%20and%20years%20worked%20in%20commercial%20software%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnCXiDq24cP6yK6NvG%2Finverse-relationship-between-belief-in-foom-and-years-worked%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Inverse%20relationship%20between%20belief%20in%20foom%20and%20years%20worked%20in%20commercial%20software%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnCXiDq24cP6yK6NvG%2Finverse-relationship-between-belief-in-foom-and-years-worked", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnCXiDq24cP6yK6NvG%2Finverse-relationship-between-belief-in-foom-and-years-worked", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://reducing-suffering.org/predictions-agi-takeoff-speed-vs-years-worked-commercial-software/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nCXiDq24cP6yK6NvG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 10, "extendedScore": null, "score": 2.3369436335652977e-06, "legacy": true, "legacyId": "27850", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-04T18:54:32.819Z", "modifiedAt": null, "url": null, "title": "Bragging Thread January 2015", "slug": "bragging-thread-january-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:07.336Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WGsxBta5Yj6PehtTH/bragging-thread-january-2015", "pageUrlRelative": "/posts/WGsxBta5Yj6PehtTH/bragging-thread-january-2015", "linkUrl": "https://www.lesswrong.com/posts/WGsxBta5Yj6PehtTH/bragging-thread-january-2015", "postedAtFormatted": "Sunday, January 4th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bragging%20Thread%20January%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABragging%20Thread%20January%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGsxBta5Yj6PehtTH%2Fbragging-thread-january-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bragging%20Thread%20January%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGsxBta5Yj6PehtTH%2Fbragging-thread-january-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGsxBta5Yj6PehtTH%2Fbragging-thread-january-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 121, "htmlBody": "<div id=\"entry_t3_lbw\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Your job, should you choose to accept it, is to comment on this thread explaining&nbsp;<strong>the most awesome thing you've done this month</strong>. You may be as blatantly proud of yourself as you feel. You may unabashedly consider yourself&nbsp;<em>the coolest freaking person ever</em>&nbsp;because of that awesome thing you're dying to tell everyone about. This is the place to do just that.</p>\n<div style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\">Remember, however, that this&nbsp;<strong>isn't</strong>&nbsp;any kind of progress thread. Nor is it any kind of proposal thread.&nbsp;<em>This thread is solely for people to talk about the awesome things they have done. Not \"will do\". Not \"are working on\"</em>.&nbsp;<strong>Have already done.</strong>&nbsp;This is to cultivate an environment of object level productivity rather than meta-productivity methods.</p>\n<p style=\"margin: 0px 0px 1em;\">So, what's the coolest thing you've done this month?</p>\n<p style=\"margin: 0px 0px 1em;\">(<a href=\"/r/discussion/lw/lbw/december_2014_bragging_thread/\">Previous Bragging Thread</a>)</p>\n</div>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1, "vH8zJLkhiqdJzK5ej": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WGsxBta5Yj6PehtTH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 2.337488700207134e-06, "legacy": true, "legacyId": "27852", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["8XHbvNZ7KXMbCft54"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-04T23:48:53.591Z", "modifiedAt": null, "url": null, "title": "Compartmentalizing: Effective Altruism and Abortion", "slug": "compartmentalizing-effective-altruism-and-abortion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:46.747Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dias", "createdAt": "2012-04-19T07:46:06.425Z", "isAdmin": false, "displayName": "Dias"}, "userId": "ycNxfH8i9QwtXqu8E", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/E6dDvRCr8eeTDJrAG/compartmentalizing-effective-altruism-and-abortion", "pageUrlRelative": "/posts/E6dDvRCr8eeTDJrAG/compartmentalizing-effective-altruism-and-abortion", "linkUrl": "https://www.lesswrong.com/posts/E6dDvRCr8eeTDJrAG/compartmentalizing-effective-altruism-and-abortion", "postedAtFormatted": "Sunday, January 4th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Compartmentalizing%3A%20Effective%20Altruism%20and%20Abortion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACompartmentalizing%3A%20Effective%20Altruism%20and%20Abortion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE6dDvRCr8eeTDJrAG%2Fcompartmentalizing-effective-altruism-and-abortion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Compartmentalizing%3A%20Effective%20Altruism%20and%20Abortion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE6dDvRCr8eeTDJrAG%2Fcompartmentalizing-effective-altruism-and-abortion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE6dDvRCr8eeTDJrAG%2Fcompartmentalizing-effective-altruism-and-abortion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4258, "htmlBody": "<div id=\"entry_t9_d4\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p>Cross-posted <a href=\"https://effectivereaction.wordpress.com/2014/12/31/blind-spots-compartmentalizing/\">on my blog</a> and the <a href=\"http://effective-altruism.com/ea/d4/blind_spots_compartmentalizing/\">effective altruism forum</a> with some minor tweaks; apologies if some of the formatting hasn't copied across. The article was written with an EA audience in mind but it is essentially one about rationality and consequentialism.</p>\n<p><em>Summary: People frequently compartmentalize their beliefs, and avoid addressing the implications between them. Ordinarily, this is perhaps innocuous, but when the both ideas are highly morally important, their interaction is in turn important &ndash; many standard arguments on both sides of moral issues like the permissibility of abortion are significantly undermined or otherwise effected by EA considerations, especially moral uncertainty. </em></p>\n<p>A long time ago, Will wrote an article about how a <a href=\"/lw/2l6/taking_ideas_seriously/\"><span style=\"text-decoration: underline;\">key part of rationality was taking ideas seriously</span></a>: fully exploring ideas, seeing all their consequences, and then acting upon them. This is something most of us do not do! I for one certainly have trouble. He later partially redacted it, and <a href=\"/lw/2q6/compartmentalization_in_epistemic_and/\">Anna has an excellent article on the subject</a>, but at the very least decompartmentalizing is a <a href=\"http://effective-altruism.com/ea/d4/blind_spots_compartmentalizing/25i\">very standard part of effective altruism</a>.</p>\n<p>Similarly, I think people selectively apply Effective Altruist (EA) principles. People are very willing to apply them in some cases, but when those principles would cut at a core part of the person&rsquo;s identity &ndash; <a href=\"/lw/lbn/you_have_a_set_amount_of_weirdness_points_spend/\"><span style=\"text-decoration: underline;\">like requiring them to dress appropriately so they seem less weird</span></a> &ndash; people are much less willing to take those EA ideas to their logical conclusion.</p>\n<p>Consider your personal views. I&rsquo;ve certainly changed some of my opinions as a result of thinking about EA ideas. For example, my opinion of bednet distribution is now much higher than it once was. And I&rsquo;ve learned a lot about how to think about some technical issues, like <a href=\"http://effective-altruism.com/ea/bb/expected_value_estimates_you_can_take_somewhat/\"><span style=\"text-decoration: underline;\">regression to the mean</span></a>. Yet I realized that I had rarely done a full 180&nbsp; &ndash; and I think this is true of many people:</p>\n<ul>\n<li>Many think EA ideas argue for more foreign aid &ndash; but did anyone come to this conclusion who had previously been passionately anti-aid?</li>\n<li>Many think EA ideas argue for vegetarianism &ndash; but did anyone come to this conclusion who had previously been passionately carnivorous?</li>\n<li>Many think EA ideas argue against domestic causes &ndash; but did anyone come to this conclusion who had previously been a passionate nationalist?</li>\n</ul>\n<p>Yet this is quite worrying. Given the power and scope of many EA ideas, it seems that they should lead to people changing their mind on issues were they had been previously very certain, and indeed emotionally involved.</p>\n<p>Obviously we don&rsquo;t need to apply EA principles to everything &ndash; we can probably continue to brush our teeth without need for much reflection. But we probably should apply them to issues with are seen as being very important: given the importance of the issues, any implications of EA ideas would probably be important implications.</p>\n<h3>Moral Uncertainty</h3>\n<p>In <a href=\"http://commonsenseatheism.com/wp-content/uploads/2014/03/MacAskill-Normative-Uncertainty.pdf\"><span style=\"text-decoration: underline;\">his PhD thesis</span></a>, Will MacAskill argues that we should treat normative uncertainty in much the same way as ordinary positive uncertainty; we should assign credences (probabilities) to each theory, and then try to maximise the expected morality of our actions. He calls this idea &lsquo;maximise expected choice-worthiness&rsquo;, and if you&rsquo;re into philosophy, I recommend reading the paper. As such, when deciding how to act we should give greater weight to the theories we consider more likely to be true, and also give more weight to theories that consider the issue to be of greater importance.</p>\n<p>This is important because it means that a novel view does not have to be totally persuasive to demand our observance. Consider, for example, vegetarianism. Maybe you think there&rsquo;s only a 10% chance that animal welfare is morally significant &ndash; you&rsquo;re pretty sure they&rsquo;re tasty for a reason. Yet if the consequences of eating meat are very bad in those 10% of cases (murder or torture, if the animal rights activists are correct), and the advantages are not very great in the other 90% (tasty, some nutritional advantages), we should not eat meat regardless. Taking into account the size of the issue at stake as well as probability of its being correct means paying more respect to &lsquo;minority&rsquo; theories.</p>\n<p>And this is more of an issue for EAs than for most people. Effective Altruism involves a group of novel moral premisses, like <a href=\"http://ea-forum.trikeapps.com/ea/6w/cosmopolitanism/\"><span style=\"text-decoration: underline;\">cosmopolitanism</span></a>, <a href=\"http://www.effective-altruism.com/ea/70/the_moral_imperative_towards_costeffectiveness/\"><span style=\"text-decoration: underline;\">the moral imperative for cost-effectiveness</span></a> and <a href=\"https://intelligence.org/2013/07/17/beckstead-interview/\"><span style=\"text-decoration: underline;\">the importance of the far future</span></a>. Each of these imply that our decisions are in some way very important, so even if we assign them only a small credence, their plausibility implies radical revisions to our actions.</p>\n<p>One issue that Will touches on in his thesis is the issue of whether fetuses morally count. In the same way that we have moral uncertainty as to whether animals, or people in the far future, count, so too we have moral uncertainty as to whether unborn children are morally significant. Yes, many people are confident they know the correct answer &ndash; but there many of these on each side of the issue. Given the degree of disagreement on the issue, among <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1988647\"><span style=\"text-decoration: underline;\">philosophers</span></a>, politicians and the general public, it seems like the perfect example of an issue where moral uncertainty should be taken into account &ndash; indeed Will uses it as a canonical example.</p>\n<p>Consider the case of a pregnant women Sarah, wondering whether it is morally permissible to abort her child<sup id=\"fnref-160-1\"><a rel=\"footnote\" href=\"https://effectivereaction.wordpress.com/?p=160&amp;preview=true#fn-160-1\">1</a></sup>. The alternative course of action she is considering is putting the child up for adoption. In accordance with the level of social and philosophical debate on the issue, she is uncertain as to whether aborting the fetus is morally permissible. If it&rsquo;s morally permissible, it&rsquo;s <em>merely</em> permissible &ndash; it&rsquo;s not obligatory. She follows the example from <em>Normative Uncertainty</em> and constructs the following table</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-1.png\"><img class=\"alignnone wp-image-163\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-1.png?w=334&amp;h=107\" alt=\"abortion table 1\" width=\"334\" height=\"107\" /></a></p>\n<p>In the best case scenario, abortion has nothing to recommend it, as adoption is also permissible. In the worst case, abortion is actually impermissible, whereas adoption is permissible. As such, adoption <a href=\"https://en.wikipedia.org/wiki/Strategic_dominance\"><span style=\"text-decoration: underline;\">dominates</span></a> abortion.</p>\n<p>However, Sarah might not consider this representation as adequate. In particular, she thinks that now is not the best time to have a child, and would prefer to avoid it.<sup id=\"fnref-160-2\"><a rel=\"footnote\" href=\"https://effectivereaction.wordpress.com/?p=160&amp;preview=true#fn-160-2\">2</a></sup> She has made plans which are inconsistent with being pregnant, and prefers not to give birth at the current time. So she amends the table to take into account these preferences.</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-2.png\"><img class=\"alignnone size-medium wp-image-164\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-2.png?w=300&amp;h=107\" alt=\"abortion table 2\" width=\"300\" height=\"107\" /></a></p>\n<p>Now adoption no longer strictly dominates abortion, because she prefers abortion to adoption in the scenario where it is morally permissible. As such, she considers her credence: she considers the pro-choice arguments slightly more persuasive than the pro-life ones: she assigns a 70% credence to abortion being morally permissible, but only a 30% chance to its being morally impermissible.</p>\n<p>Looking at the table with these numbers in mind, intuitively it seems that again it&rsquo;s not worth the risk of abortion: a 70% chance of saving oneself inconvenience and temporary discomfort is not sufficient to justify a 30% chance of committing murder. But Sarah&rsquo;s unsatisfied with this unscientific comparison: it doesn&rsquo;t seem to have much of a theoretical basis, and she distrusts appeals to intuitions in cases like this. What is more, Sarah is something of a utilitarian; she doesn&rsquo;t really believe in something being impermissible.</p>\n<p>Fortunately, there&rsquo;s a standard tool for making inter-personal welfare comparisons: QALYs. We can convert the previous table into QALYs, with the moral uncertainty now being expressed as uncertainty as to whether saving fetuses generates QALYs. If it does, then it generates a lot; supposing she&rsquo;s at the end of her first trimester, if she doesn&rsquo;t abort the baby it has a <a href=\"http://spacefem.com/pregnant/mc.php?m=08&amp;d=10&amp;y=12\"><span style=\"text-decoration: underline;\">98% chance of surviving to birth</span></a>, at which point its <a href=\"http://www.cdc.gov/nchs/fastats/life-expectancy.htm\"><span style=\"text-decoration: underline;\">life expectancy is 78.7 in the US</span></a>, for 78.126 QALYs. This calculation assumes assigns no QALYs to the fetus&rsquo;s 6 months of existence between now and birth. If fetuses are not worthy of ethical consideration, then it accounts for 0 QALYs.</p>\n<p>We also need to assign QALYs to Sarah. For an upper bound, being pregnant is probably not much worse than having both your legs amputated without medication, which is <a href=\"http://effective-altruism.com/ea/7g/disability_weights/\"><span style=\"text-decoration: underline;\">0.494 QALYs</span></a>, so lets conservatively say 0.494 QALYs. She has an expected 6 months of pregnancy remaining, so we divide by 2 to get 0.247 QALYs. Women&rsquo;s Health Magazine gives the odds of maternal death during childbirth at <a href=\"http://www.womenshealthmag.com/health/women-dying-in-childbirth\"><span style=\"text-decoration: underline;\">0.03% for 2013</span></a>; we&rsquo;ll round up to 0.05% to take into account risk of non-death injury. Women at 25 have a remaining life expectancy of <a href=\"http://www.cdc.gov/nchs/data/hus/hus11.pdf#fig32\"><span style=\"text-decoration: underline;\">around 58 years</span></a>, so thats 0.05%*58= 0.029 QALYs. In total that gives us an estimate of 0.276 QALYs. If the baby doesn&rsquo;t survive to birth, however, some of these costs will not be incurred, so the truth is probably slightly lower than this. All in all a 0.276 QALYs seems like a reasonably conservative figure.</p>\n<p>Obviously you could refine these numbers a lot (for example, years of old age are likely to be at lower quality of life, there are some medical risks to the mother from aborting a fetus, etc.) but they&rsquo;re plausibly in the right ballpark. They would also change if we used inherent temporal discounting, but probably <a href=\"/lw/n2/against_discount_rates/\"><span style=\"text-decoration: underline;\">we shouldn&rsquo;t</span></a>.</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-3.png\"><img class=\"alignnone wp-image-165\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-3.png?w=291&amp;h=93\" alt=\"abortion table 3\" width=\"291\" height=\"93\" /></a></p>\n<p>We can then take into account her moral uncertainty directly, and calculate the expected QALYs of each action:</p>\n<ul>\n<li>If she aborts the fetus, our expected QALYs are 70%<em>x0 + 30%</em>(-78.126) = -23.138</li>\n<li>If she carries the baby to term and puts it up for adoption, our expected QALYs are 70%<em>(-0.247) + 30%</em>(-0.247) = -0.247</li>\n</ul>\n<p>Which again suggests that the moral thing to do is to not abort the baby. Indeed, the life expectancy is so long at birth that it quite easily dominates the calculation: Sarah would have to be extremely confident in rejecting the value of the fetus to justify aborting it. So, mindful of <a href=\"https://en.wikipedia.org/wiki/Overconfidence_effect\"><span style=\"text-decoration: underline;\">overconfidence bias</span></a>, she decides to carry the child to term.</p>\n<p>Indeed, we can show just how confident in the lack of moral significance of the fetuses one would have to be to justify aborting one. Here is a sensitivity table, showing credence in moral significance of fetuses on the y axis, and the direct QALY cost of pregnancy on the x axis for a wide range of possible values. The direct QALY cost of pregnancy is obviously bounded above by its limited duration. As is immediately apparent, one has to be very confident in fetuses lacking moral significance, and pregnancy has to be very bad, before aborting a fetus becomes even slightly QALY-positive. For moderate values, it is extremely QALY-negative.</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-4.png\"><img class=\"alignnone wp-image-166\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-4.png?w=420&amp;h=175\" alt=\"abortion table 4\" width=\"420\" height=\"175\" /></a></p>\n<h3>Other EA concepts and their applications to this issue</h3>\n<p>Of course, moral uncertainty is not the only EA principle that could have bearing on the issue, and given that the theme of this blogging carnival, and this post, is things we&rsquo;re overlooking, it would be remiss not to give at least a broad overview of some of the others. Here, I don&rsquo;t intend to judge how persuasive any given argument is &ndash; as we discussed above, this is a debate that has been going without settlement for thousands of years &ndash; but merely to show the ways that common EA arguments affect the plausibility of the different arguments. This is a section about the directionality of EA concerns, not on the overall magnitudes.</p>\n<h4>Not really people</h4>\n<p>One of the most important arguments for the permissibility of abortion is that fetuses are in some important sense &lsquo;not really people&rsquo;. In many ways this argument resembles the anti-animal rights argument that animals are also &lsquo;not really people&rsquo;. We already covered above the way that considerations of moral uncertainty undermine both these arguments, but it&rsquo;s also noteworthy that in general it seems that the two views are mutually supporting (or mutually undermining, if both are false). Animal-rights advocates often appeal to the idea of an &lsquo;expanding circle&rsquo; of moral concern. I&rsquo;m <a href=\"http://www.gwern.net/The%20Narrowing%20Circle\"><span style=\"text-decoration: underline;\">skeptical of such an argument</span></a>, but it seems clear that the larger your sphere, the more likely fetuses are to end up on the inside. The fact that, in the US at least, animal activists tend to be pro-abortion seems to be more of a historical accident than anything else. We could imagine alternative-universe political coalitions, where a &ldquo;Defend the Weak; They&rsquo;re morally valuable too&rdquo; party faced off against a &ldquo;Exploit the Weak; They just don&rsquo;t count&rdquo; party. In general, to the extent that EAs care about animal suffering (even <a href=\"http://reducing-suffering.org/do-bugs-feel-pain/\"><span style=\"text-decoration: underline;\">insect suffering</span></a> ), EAs should tend to be concerned about the welfare of the unborn.</p>\n<h4>Not people yet</h4>\n<p>A slightly different common argument is that while fetuses will eventually be people, they&rsquo;re not people yet. Since they&rsquo;re not people right now, we don&rsquo;t have to pay any attention to their rights or welfare right now. Indeed, many people make short sighted decisions that implicitly assign very little value to the futures of people currently alive, or even to their own futures &ndash; through self-destructive drug habits, or simply failing to save for retirement. If we don&rsquo;t assign much value to our own futures, it seems very sensible to disregard the futures of those not even born. And even if people who disregarded their own futures were simply negligent, we might still be concerned about things like the <a href=\"http://plato.stanford.edu/entries/nonidentity-problem/\"><span style=\"text-decoration: underline;\">non-identity problem</span></a>.</p>\n<p>Yet it seems that EAs are almost uniquely unsuited to this response. EAs do tend to care explicitly about future generations. We put considerable resources into investigating how to help them, whether through addressing <a href=\"https://www.givingwhatwecan.org/blog/2013-08-08/less-burn-for-your-buck-which-climate-charities-are-most-effective-in-reducing\"><span style=\"text-decoration: underline;\">climate change</span></a> or <a href=\"http://www.existential-risk.org/concept.pdfbostrom\"><span style=\"text-decoration: underline;\">existential risks</span></a>. And yet these people have far less of a claim to current personhood than fetuses, who at least have current physical form, even if it is diminutive. So again to the extent that EAs care about future welfare, EAs should tend to be concerned about the welfare of the unborn.</p>\n<h4>Replaceability</h4>\n<p>Another important EA idea is that of <a href=\"http://www.benkuhn.net/replaceability\"><span style=\"text-decoration: underline;\">replaceability</span></a>. Typically this arises in contexts of career choice, but there is a different application here. The QALYs associated with aborted children might not be so bad if the mother will go on to have another child instead. If she does, the net QALY loss is much lower than the gross QALY loss. Of course, the benefits of aborting the fetus are equivalently much smaller &ndash; if she has a child later on instead, she will have to bear the costs of pregnancy eventually anyway. This resembles concerns that maybe <a href=\"http://blog.givewell.org/2014/04/17/david-roodmans-draft-writeup-on-the-mortality-fertility-connection/\"><span style=\"text-decoration: underline;\">saving children in Africa doesn&rsquo;t make much difference, because their parents adjust their subsequent fertility.</span></a></p>\n<p>The plausibility behind this idea comes from the idea that, at least in the US, most families have a certain ideal number of children in mind, and basically achieve this goal. As such, missing an opportunity to have an early child simply results in having another later on.</p>\n<p>If this were fully true, utilitarians might decide that abortion actually has no QALY impact at all &ndash; all it does is change the timing of events. On the other hand, <a href=\"https://en.wikipedia.org/wiki/Age_and_female_fertility\"><span style=\"text-decoration: underline;\">fertility declines with age</span></a>, so many couples planning to have a replacement child later may be unable to do so. Also, some people do not have ideal family size plans.</p>\n<p>Additionally, this does not really seem to hold when the alternative is adoption; presumably a woman putting a child up for adoption does not consider it as part of her family, so her future childbearing would be unaffected. This argument might hold if raising the child yourself was the only alternative, but given that adoption services are available, it does not seem to go through.</p>\n<h4>Autonomy</h4>\n<p>Sometimes people argue for the permissibility of abortion through autonomy arguments. &ldquo;It is my body&rdquo;, such an argument would go, &ldquo;therefore I may do whatever I want with it.&rdquo; To a certain extent this argument is addressed by pointing out that one&rsquo;s bodily rights presumably do not extent to killing others, so if the anti-abortion side are correct, or even have a non-trivial probability of being correct, autonomy would be insufficient. It seems that if the autonomy argument is to work, it must be because a different argument has established the non-personhood of fetuses &ndash; in which case the autonomy argument is redundant. Yet even putting this aside, this argument is less appealing to EAs than to non-EAs, because EAs often hold a distinctly non-libertarian account of personal ethics. We believe it is actually good to help people (and avoid hurting them), and perhaps that it is bad to avoid doing so. And many EAs are utilitarians, for whom helping/not-hurting is not merely laud-worthy but actually compulsory. EAs are generally not very impressed with <a href=\"http://aynrandlexicon.com/lexicon/abortion.html\"><span style=\"text-decoration: underline;\">Ayn Rand style autonomy arguments</span></a> for rejecting charity, so again EAs should tend to be unsympathetic to autonomy arguments for the permissibility of abortion.</p>\n<p>Indeed, some EAs even think we should be legally obliged to act in good ways, whether through laws against factory farming or tax-funded foreign aid.</p>\n<h4>Deontology</h4>\n<p>An argument often used on the opposite side&nbsp; &ndash; that is, an argument used to oppose abortion, is that abortion is murder, and murder is simply always wrong. Whether because <a href=\"https://en.wikipedia.org/wiki/You_shall_not_murder\"><span style=\"text-decoration: underline;\">God commanded it</span></a> or <a href=\"https://en.wikipedia.org/wiki/Kantian_ethics\"><span style=\"text-decoration: underline;\">Kant derived it</span></a>, we should place the utmost importance of never murdering. I&rsquo;m not sure that any EA principle <em>directly</em> pulls against this, but nonetheless most EAs are consequentialists, who believe that all values can be compared. If aborting one child would save a million others, most EAs would probably endorse the abortion. So I think this is one case where a common EA view pulls in favor of the permissibility of abortion.</p>\n<h4>I didn&rsquo;t ask for this</h4>\n<p>Another argument often used for the permissibility of abortion is that the situation is in some sense unfair. If one did not intend to become pregnant &ndash; perhaps even took precautions to avoid becoming so &ndash; but nonetheless ends up pregnant, you&rsquo;re in some way not responsible for becoming pregnant. And since you&rsquo;re not responsible for it you have no obligations concerning it &ndash; so may permissible abort the fetus.</p>\n<p>However, once again this runs counter to a major strand of EA thought. Most of us did not ask to be born in rich countries, or to be intelligent, or hardworking. Perhaps it was simply luck. Yet being in such a position nonetheless means we have certain opportunities and obligations. Specifically, we have the opportunity to use of wealth to significantly aid those less fortunate than ourselves in the developing world, and many EAs would agree the obligation. So EAs seem to reject the general idea that not intending a situation relieves one of the responsibilities of that situation.</p>\n<h4>Infanticide is okay too</h4>\n<p>A frequent argument against the permissibility of aborting fetuses is by analogy to infanticide. In general <a href=\"http://www.gwern.net/An%20Abortion%20Dialogue\"><span style=\"text-decoration: underline;\">it is hard to produce a coherent criteria that permits the killing of babies before birth but forbids it after birth</span></a>. For most people, this is a reasonably compelling objection: murdering innocent babies is clearly evil! Yet some EAs actually <a href=\"http://www.utilitarian.net/singer/by/1993----.htm\"><span style=\"text-decoration: underline;\">endorse infanticide</span></a>. If you were one of those people, this particular argument would have little sway over you.</p>\n<h4>Moral Universalism</h4>\n<p>A common implicit premise in many moral discussion is that the same moral principles apply to everyone. When Sarah did her QALY calculation, she counted the baby&rsquo;s QALYs as equally important to her own in the scenario where they counted at all. Similarly, both sides of the debate assume that whatever the answer is, it will apply fairly broadly. Perhaps permissibility varies by age of the fetus &ndash; maybe ending <a href=\"https://en.wikipedia.org/wiki/Fetal_viability#Scientific_thresholds\"><span style=\"text-decoration: underline;\">when viability hits</span></a> &ndash; but the same answer will apply to rich and poor, Christian and Jew, etc.</p>\n<p>This is something some EAs might reject. Yes, saving the baby produces many more QALYs than Sarah loses through the pregnancy, and that would be the end of the story if Sarah were simply an ordinary person. But Sarah is an EA, and so has a much higher opportunity cost for her time. Becoming pregnant will undermine her career as an investment banker, the argument would go, which in turn prevents her from donating to AMF and saving a great many lives. Because of this, Sarah is in a special position &ndash; it is permissible for her, but it would not be permissible for someone who wasn&rsquo;t saving many lives a year.</p>\n<p>I think this is a pretty repugnant attitude in general, and a particularly objectionable instance of it, but I include it here for completeness.</p>\n<h3>May we discuss this?</h3>\n<p>Now we&rsquo;ve considered these arguments, it appears that applying general EA principles to the issue in general tends to make abortion look less morally permissible, though there were one or two exceptions. But there is also a second order issue that we should perhaps address &ndash; is it permissible to discuss this issue at all?</p>\n<h4>Nothing to do with you</h4>\n<p>A frequently seen argument on this issue is to claim that <a href=\"http://www.independent.co.uk/voices/comment/i-helped-shut-down-an-abortion-debate-between-two-men-because-my-uterus-isnt-up-for-their-discussion-9867200.html\"><span style=\"text-decoration: underline;\">the speaker has no right to opine on the issue</span></a>. If it doesn&rsquo;t personally affect you, you cannot discuss it &ndash; especially if you&rsquo;re privileged. As many (a majority?) of EAs are male, and of the women many are not pregnant, this would curtail dramatically the ability of EAs to discuss abortion. This is not so much an argument on one side or other of the issue as an argument for silence.</p>\n<p>Leaving aside the inherent virtues and vices of this argument, it is not very suitable for EAs. Because EAs have many many opinions on topics that don&rsquo;t directly affect them:</p>\n<ul>\n<li>EAs have opinions on disease in Africa, yet most have never been to Africa, and never will</li>\n<li>EAs have opinions on (non-human) animal suffering, yet most are not non-human animals</li>\n<li>EAs have opinions on the far future, yet live in the present</li>\n</ul>\n<p>Indeed, EAs seem <em>more</em> qualified to comment on abortion &ndash; as we all were once fetuses, and many of us will become pregnant. If taken seriously this argument would call foul on virtually ever EA activity! And this is no idle fantasy &ndash; there are certainly some people who think that <a href=\"http://www.dambisamoyo.com/books-and-publications/book/dead-aid/\"><span style=\"text-decoration: underline;\">Westerns cannot usefully contribute to solving African poverty</span></a>.</p>\n<h4>Too controversial</h4>\n<p>We can safely say this is a somewhat controversial issue. Perhaps it is too controversial &ndash; maybe it is bad for the movement to discuss. One might accept the arguments above &ndash; that EA principles generally undermine the traditional reasons for thinking abortion is morally permissible &ndash; yet think we should not talk about it. The controversy might divide the community and undermine trust. Perhaps it might deter newcomers. I&rsquo;m somewhat sympathetic to this argument &ndash; I take the <a href=\"http://slatestarcodex.com/2013/06/14/the-virtue-of-silence/\"><span style=\"text-decoration: underline;\">virtue of silence</span></a> seriously, though eventually my boyfriend persuaded me it was worth publishing.</p>\n<p>Note that the controversial nature is evidence <em>against</em> abortion&rsquo;s moral permissibility, due to moral uncertainty.</p>\n<p>However, the EA movement is no stranger to controversy.</p>\n<ul>\n<li>There is a semi-official EA position on immigration, which is about as controversial as abortion in the US at the moment, and the EA position is such an extreme position that essentially no mainstream politicians hold it.</li>\n<li>There is a semi-official EA position on vegetarianism, which is pretty controversial too, as it involves implying that the majority of Americans are complicit in murder every day.</li>\n</ul>\n<h4>Not worthy of discussion</h4>\n<p>Finally, another objection to discussing this is it simply it&rsquo;s an EA idea. There are many disagreements in the world, yet there is no need for an EA view on each. Conflict between the Lilliputians and Blefuscudians notwithstanding, there is no need for an EA perspective on which end of the egg to break first. And we should be especially careful of heated, emotional topics with less avenue to <a href=\"http://www.overcomingbias.com/2007/05/policy_tugowar.html\"><span style=\"text-decoration: underline;\">pull the rope sideways</span></a>. As such, even though the object-level arguments given above are correct, we should simply decline to discuss it.</p>\n<p>However, it seems that if abortion is a moral issue, it is a very large one. In the same way that the sheer number of QALYs lost makes abortion worse than adoption even if our credence in fetuses having moral significance was very low, the large number of abortions occurring each year make the issue as a whole of high significance. In 2011 there were <a href=\"http://www.guttmacher.org/pubs/journals/psrh.46e0414.pdf\"><span style=\"text-decoration: underline;\">over 1 million babies were aborted in the US</span></a>. I&rsquo;ve seen a wide range of global estimates, including <a href=\"http://www.johnstonsarchive.net/policy/abortion/wrjp3313.html\">around 10 million</a> to <a href=\"http://www.guttmacher.org/pubs/Abortion-Worldwide.pdf\"><span style=\"text-decoration: underline;\">over 40 million</span></a>. By contrast, the WHO estimates there are <a href=\"http://www.who.int/gho/malaria/epidemic/deaths/en/\"><span style=\"text-decoration: underline;\">fewer than 1 million malaria deaths worldwide</span></a> each year. Abortion deaths also cause a higher loss of QALYs due to the young age at which they occur. On the other hand, we should discount them for the uncertainty that they are morally significant. And perhaps there is <a href=\"http://www.amirrorclear.net/academic/papers/scourge.pdf\"><span style=\"text-decoration: underline;\">an even larger closely related moral issue</span></a>. The size of the issue is not the only <a href=\"http://effective-altruism.com/ea/cr/factoring_costeffectiveness/\"><span style=\"text-decoration: underline;\">factor</span></a> in estimating the cost-effectiveness of interventions, but it is the most easily estimable. On the other hand, I have little idea how many dollars of donations it takes to save a fetus &ndash; it seems like an excellent example of some low-hanging fruit research.</p>\n<h3>Conclusion</h3>\n<p>People frequently compartmentalize their beliefs, and avoid addressing the implications between them. Ordinarily, this is perhaps innocuous, but when the both ideas are highly morally important, their interaction is in turn important. In this post we the implications of common EA beliefs on the permissibility of abortion. Taking into account moral uncertainty makes aborting a fetus seem far less permissible, as the high counterfactual life expectancy of the baby tends to dominate other factors. Many other EA views are also significant to the issue, making various standard arguments on each side less plausible.</p>\n<p>&nbsp;</p>\n<div class=\"footnotes\">\n<hr />\n<ol>\n<li id=\"fn-160-1\"> There doesn&rsquo;t seem to be any neutral language one can use here, so I&rsquo;m just going to switch back and forth between &lsquo;fetus&rsquo; and &lsquo;child&rsquo; or &lsquo;baby&rsquo; in a vain attempt at terminological neutrality.&nbsp; </li>\n<li id=\"fn-160-2\"> I chose this reason because it is the <a href=\"http://www.guttmacher.org/pubs/journals/3711005.pdf\"><span style=\"text-decoration: underline;\">most frequently cited main motivation for aborting a fetus</span></a> according to the Guttmacher Institute.&nbsp; </li>\n</ol></div>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qoTbWwaJtTSKosRCA": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "E6dDvRCr8eeTDJrAG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 33, "extendedScore": null, "score": 9.8e-05, "legacy": true, "legacyId": "27853", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 35, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<div id=\"entry_t9_d4\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p>Cross-posted <a href=\"https://effectivereaction.wordpress.com/2014/12/31/blind-spots-compartmentalizing/\">on my blog</a> and the <a href=\"http://effective-altruism.com/ea/d4/blind_spots_compartmentalizing/\">effective altruism forum</a> with some minor tweaks; apologies if some of the formatting hasn't copied across. The article was written with an EA audience in mind but it is essentially one about rationality and consequentialism.</p>\n<p><em>Summary: People frequently compartmentalize their beliefs, and avoid addressing the implications between them. Ordinarily, this is perhaps innocuous, but when the both ideas are highly morally important, their interaction is in turn important \u2013 many standard arguments on both sides of moral issues like the permissibility of abortion are significantly undermined or otherwise effected by EA considerations, especially moral uncertainty. </em></p>\n<p>A long time ago, Will wrote an article about how a <a href=\"/lw/2l6/taking_ideas_seriously/\"><span style=\"text-decoration: underline;\">key part of rationality was taking ideas seriously</span></a>: fully exploring ideas, seeing all their consequences, and then acting upon them. This is something most of us do not do! I for one certainly have trouble. He later partially redacted it, and <a href=\"/lw/2q6/compartmentalization_in_epistemic_and/\">Anna has an excellent article on the subject</a>, but at the very least decompartmentalizing is a <a href=\"http://effective-altruism.com/ea/d4/blind_spots_compartmentalizing/25i\">very standard part of effective altruism</a>.</p>\n<p>Similarly, I think people selectively apply Effective Altruist (EA) principles. People are very willing to apply them in some cases, but when those principles would cut at a core part of the person\u2019s identity \u2013 <a href=\"/lw/lbn/you_have_a_set_amount_of_weirdness_points_spend/\"><span style=\"text-decoration: underline;\">like requiring them to dress appropriately so they seem less weird</span></a> \u2013 people are much less willing to take those EA ideas to their logical conclusion.</p>\n<p>Consider your personal views. I\u2019ve certainly changed some of my opinions as a result of thinking about EA ideas. For example, my opinion of bednet distribution is now much higher than it once was. And I\u2019ve learned a lot about how to think about some technical issues, like <a href=\"http://effective-altruism.com/ea/bb/expected_value_estimates_you_can_take_somewhat/\"><span style=\"text-decoration: underline;\">regression to the mean</span></a>. Yet I realized that I had rarely done a full 180&nbsp; \u2013 and I think this is true of many people:</p>\n<ul>\n<li>Many think EA ideas argue for more foreign aid \u2013 but did anyone come to this conclusion who had previously been passionately anti-aid?</li>\n<li>Many think EA ideas argue for vegetarianism \u2013 but did anyone come to this conclusion who had previously been passionately carnivorous?</li>\n<li>Many think EA ideas argue against domestic causes \u2013 but did anyone come to this conclusion who had previously been a passionate nationalist?</li>\n</ul>\n<p>Yet this is quite worrying. Given the power and scope of many EA ideas, it seems that they should lead to people changing their mind on issues were they had been previously very certain, and indeed emotionally involved.</p>\n<p>Obviously we don\u2019t need to apply EA principles to everything \u2013 we can probably continue to brush our teeth without need for much reflection. But we probably should apply them to issues with are seen as being very important: given the importance of the issues, any implications of EA ideas would probably be important implications.</p>\n<h3 id=\"Moral_Uncertainty\">Moral Uncertainty</h3>\n<p>In <a href=\"http://commonsenseatheism.com/wp-content/uploads/2014/03/MacAskill-Normative-Uncertainty.pdf\"><span style=\"text-decoration: underline;\">his PhD thesis</span></a>, Will MacAskill argues that we should treat normative uncertainty in much the same way as ordinary positive uncertainty; we should assign credences (probabilities) to each theory, and then try to maximise the expected morality of our actions. He calls this idea \u2018maximise expected choice-worthiness\u2019, and if you\u2019re into philosophy, I recommend reading the paper. As such, when deciding how to act we should give greater weight to the theories we consider more likely to be true, and also give more weight to theories that consider the issue to be of greater importance.</p>\n<p>This is important because it means that a novel view does not have to be totally persuasive to demand our observance. Consider, for example, vegetarianism. Maybe you think there\u2019s only a 10% chance that animal welfare is morally significant \u2013 you\u2019re pretty sure they\u2019re tasty for a reason. Yet if the consequences of eating meat are very bad in those 10% of cases (murder or torture, if the animal rights activists are correct), and the advantages are not very great in the other 90% (tasty, some nutritional advantages), we should not eat meat regardless. Taking into account the size of the issue at stake as well as probability of its being correct means paying more respect to \u2018minority\u2019 theories.</p>\n<p>And this is more of an issue for EAs than for most people. Effective Altruism involves a group of novel moral premisses, like <a href=\"http://ea-forum.trikeapps.com/ea/6w/cosmopolitanism/\"><span style=\"text-decoration: underline;\">cosmopolitanism</span></a>, <a href=\"http://www.effective-altruism.com/ea/70/the_moral_imperative_towards_costeffectiveness/\"><span style=\"text-decoration: underline;\">the moral imperative for cost-effectiveness</span></a> and <a href=\"https://intelligence.org/2013/07/17/beckstead-interview/\"><span style=\"text-decoration: underline;\">the importance of the far future</span></a>. Each of these imply that our decisions are in some way very important, so even if we assign them only a small credence, their plausibility implies radical revisions to our actions.</p>\n<p>One issue that Will touches on in his thesis is the issue of whether fetuses morally count. In the same way that we have moral uncertainty as to whether animals, or people in the far future, count, so too we have moral uncertainty as to whether unborn children are morally significant. Yes, many people are confident they know the correct answer \u2013 but there many of these on each side of the issue. Given the degree of disagreement on the issue, among <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1988647\"><span style=\"text-decoration: underline;\">philosophers</span></a>, politicians and the general public, it seems like the perfect example of an issue where moral uncertainty should be taken into account \u2013 indeed Will uses it as a canonical example.</p>\n<p>Consider the case of a pregnant women Sarah, wondering whether it is morally permissible to abort her child<sup id=\"fnref-160-1\"><a rel=\"footnote\" href=\"https://effectivereaction.wordpress.com/?p=160&amp;preview=true#fn-160-1\">1</a></sup>. The alternative course of action she is considering is putting the child up for adoption. In accordance with the level of social and philosophical debate on the issue, she is uncertain as to whether aborting the fetus is morally permissible. If it\u2019s morally permissible, it\u2019s <em>merely</em> permissible \u2013 it\u2019s not obligatory. She follows the example from <em>Normative Uncertainty</em> and constructs the following table</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-1.png\"><img class=\"alignnone wp-image-163\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-1.png?w=334&amp;h=107\" alt=\"abortion table 1\" width=\"334\" height=\"107\"></a></p>\n<p>In the best case scenario, abortion has nothing to recommend it, as adoption is also permissible. In the worst case, abortion is actually impermissible, whereas adoption is permissible. As such, adoption <a href=\"https://en.wikipedia.org/wiki/Strategic_dominance\"><span style=\"text-decoration: underline;\">dominates</span></a> abortion.</p>\n<p>However, Sarah might not consider this representation as adequate. In particular, she thinks that now is not the best time to have a child, and would prefer to avoid it.<sup id=\"fnref-160-2\"><a rel=\"footnote\" href=\"https://effectivereaction.wordpress.com/?p=160&amp;preview=true#fn-160-2\">2</a></sup> She has made plans which are inconsistent with being pregnant, and prefers not to give birth at the current time. So she amends the table to take into account these preferences.</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-2.png\"><img class=\"alignnone size-medium wp-image-164\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-2.png?w=300&amp;h=107\" alt=\"abortion table 2\" width=\"300\" height=\"107\"></a></p>\n<p>Now adoption no longer strictly dominates abortion, because she prefers abortion to adoption in the scenario where it is morally permissible. As such, she considers her credence: she considers the pro-choice arguments slightly more persuasive than the pro-life ones: she assigns a 70% credence to abortion being morally permissible, but only a 30% chance to its being morally impermissible.</p>\n<p>Looking at the table with these numbers in mind, intuitively it seems that again it\u2019s not worth the risk of abortion: a 70% chance of saving oneself inconvenience and temporary discomfort is not sufficient to justify a 30% chance of committing murder. But Sarah\u2019s unsatisfied with this unscientific comparison: it doesn\u2019t seem to have much of a theoretical basis, and she distrusts appeals to intuitions in cases like this. What is more, Sarah is something of a utilitarian; she doesn\u2019t really believe in something being impermissible.</p>\n<p>Fortunately, there\u2019s a standard tool for making inter-personal welfare comparisons: QALYs. We can convert the previous table into QALYs, with the moral uncertainty now being expressed as uncertainty as to whether saving fetuses generates QALYs. If it does, then it generates a lot; supposing she\u2019s at the end of her first trimester, if she doesn\u2019t abort the baby it has a <a href=\"http://spacefem.com/pregnant/mc.php?m=08&amp;d=10&amp;y=12\"><span style=\"text-decoration: underline;\">98% chance of surviving to birth</span></a>, at which point its <a href=\"http://www.cdc.gov/nchs/fastats/life-expectancy.htm\"><span style=\"text-decoration: underline;\">life expectancy is 78.7 in the US</span></a>, for 78.126 QALYs. This calculation assumes assigns no QALYs to the fetus\u2019s 6 months of existence between now and birth. If fetuses are not worthy of ethical consideration, then it accounts for 0 QALYs.</p>\n<p>We also need to assign QALYs to Sarah. For an upper bound, being pregnant is probably not much worse than having both your legs amputated without medication, which is <a href=\"http://effective-altruism.com/ea/7g/disability_weights/\"><span style=\"text-decoration: underline;\">0.494 QALYs</span></a>, so lets conservatively say 0.494 QALYs. She has an expected 6 months of pregnancy remaining, so we divide by 2 to get 0.247 QALYs. Women\u2019s Health Magazine gives the odds of maternal death during childbirth at <a href=\"http://www.womenshealthmag.com/health/women-dying-in-childbirth\"><span style=\"text-decoration: underline;\">0.03% for 2013</span></a>; we\u2019ll round up to 0.05% to take into account risk of non-death injury. Women at 25 have a remaining life expectancy of <a href=\"http://www.cdc.gov/nchs/data/hus/hus11.pdf#fig32\"><span style=\"text-decoration: underline;\">around 58 years</span></a>, so thats 0.05%*58= 0.029 QALYs. In total that gives us an estimate of 0.276 QALYs. If the baby doesn\u2019t survive to birth, however, some of these costs will not be incurred, so the truth is probably slightly lower than this. All in all a 0.276 QALYs seems like a reasonably conservative figure.</p>\n<p>Obviously you could refine these numbers a lot (for example, years of old age are likely to be at lower quality of life, there are some medical risks to the mother from aborting a fetus, etc.) but they\u2019re plausibly in the right ballpark. They would also change if we used inherent temporal discounting, but probably <a href=\"/lw/n2/against_discount_rates/\"><span style=\"text-decoration: underline;\">we shouldn\u2019t</span></a>.</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-3.png\"><img class=\"alignnone wp-image-165\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-3.png?w=291&amp;h=93\" alt=\"abortion table 3\" width=\"291\" height=\"93\"></a></p>\n<p>We can then take into account her moral uncertainty directly, and calculate the expected QALYs of each action:</p>\n<ul>\n<li>If she aborts the fetus, our expected QALYs are 70%<em>x0 + 30%</em>(-78.126) = -23.138</li>\n<li>If she carries the baby to term and puts it up for adoption, our expected QALYs are 70%<em>(-0.247) + 30%</em>(-0.247) = -0.247</li>\n</ul>\n<p>Which again suggests that the moral thing to do is to not abort the baby. Indeed, the life expectancy is so long at birth that it quite easily dominates the calculation: Sarah would have to be extremely confident in rejecting the value of the fetus to justify aborting it. So, mindful of <a href=\"https://en.wikipedia.org/wiki/Overconfidence_effect\"><span style=\"text-decoration: underline;\">overconfidence bias</span></a>, she decides to carry the child to term.</p>\n<p>Indeed, we can show just how confident in the lack of moral significance of the fetuses one would have to be to justify aborting one. Here is a sensitivity table, showing credence in moral significance of fetuses on the y axis, and the direct QALY cost of pregnancy on the x axis for a wide range of possible values. The direct QALY cost of pregnancy is obviously bounded above by its limited duration. As is immediately apparent, one has to be very confident in fetuses lacking moral significance, and pregnancy has to be very bad, before aborting a fetus becomes even slightly QALY-positive. For moderate values, it is extremely QALY-negative.</p>\n<p><a href=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-4.png\"><img class=\"alignnone wp-image-166\" src=\"https://effectivereaction.files.wordpress.com/2014/12/abortion-table-4.png?w=420&amp;h=175\" alt=\"abortion table 4\" width=\"420\" height=\"175\"></a></p>\n<h3 id=\"Other_EA_concepts_and_their_applications_to_this_issue\">Other EA concepts and their applications to this issue</h3>\n<p>Of course, moral uncertainty is not the only EA principle that could have bearing on the issue, and given that the theme of this blogging carnival, and this post, is things we\u2019re overlooking, it would be remiss not to give at least a broad overview of some of the others. Here, I don\u2019t intend to judge how persuasive any given argument is \u2013 as we discussed above, this is a debate that has been going without settlement for thousands of years \u2013 but merely to show the ways that common EA arguments affect the plausibility of the different arguments. This is a section about the directionality of EA concerns, not on the overall magnitudes.</p>\n<h4 id=\"Not_really_people\">Not really people</h4>\n<p>One of the most important arguments for the permissibility of abortion is that fetuses are in some important sense \u2018not really people\u2019. In many ways this argument resembles the anti-animal rights argument that animals are also \u2018not really people\u2019. We already covered above the way that considerations of moral uncertainty undermine both these arguments, but it\u2019s also noteworthy that in general it seems that the two views are mutually supporting (or mutually undermining, if both are false). Animal-rights advocates often appeal to the idea of an \u2018expanding circle\u2019 of moral concern. I\u2019m <a href=\"http://www.gwern.net/The%20Narrowing%20Circle\"><span style=\"text-decoration: underline;\">skeptical of such an argument</span></a>, but it seems clear that the larger your sphere, the more likely fetuses are to end up on the inside. The fact that, in the US at least, animal activists tend to be pro-abortion seems to be more of a historical accident than anything else. We could imagine alternative-universe political coalitions, where a \u201cDefend the Weak; They\u2019re morally valuable too\u201d party faced off against a \u201cExploit the Weak; They just don\u2019t count\u201d party. In general, to the extent that EAs care about animal suffering (even <a href=\"http://reducing-suffering.org/do-bugs-feel-pain/\"><span style=\"text-decoration: underline;\">insect suffering</span></a> ), EAs should tend to be concerned about the welfare of the unborn.</p>\n<h4 id=\"Not_people_yet\">Not people yet</h4>\n<p>A slightly different common argument is that while fetuses will eventually be people, they\u2019re not people yet. Since they\u2019re not people right now, we don\u2019t have to pay any attention to their rights or welfare right now. Indeed, many people make short sighted decisions that implicitly assign very little value to the futures of people currently alive, or even to their own futures \u2013 through self-destructive drug habits, or simply failing to save for retirement. If we don\u2019t assign much value to our own futures, it seems very sensible to disregard the futures of those not even born. And even if people who disregarded their own futures were simply negligent, we might still be concerned about things like the <a href=\"http://plato.stanford.edu/entries/nonidentity-problem/\"><span style=\"text-decoration: underline;\">non-identity problem</span></a>.</p>\n<p>Yet it seems that EAs are almost uniquely unsuited to this response. EAs do tend to care explicitly about future generations. We put considerable resources into investigating how to help them, whether through addressing <a href=\"https://www.givingwhatwecan.org/blog/2013-08-08/less-burn-for-your-buck-which-climate-charities-are-most-effective-in-reducing\"><span style=\"text-decoration: underline;\">climate change</span></a> or <a href=\"http://www.existential-risk.org/concept.pdfbostrom\"><span style=\"text-decoration: underline;\">existential risks</span></a>. And yet these people have far less of a claim to current personhood than fetuses, who at least have current physical form, even if it is diminutive. So again to the extent that EAs care about future welfare, EAs should tend to be concerned about the welfare of the unborn.</p>\n<h4 id=\"Replaceability\">Replaceability</h4>\n<p>Another important EA idea is that of <a href=\"http://www.benkuhn.net/replaceability\"><span style=\"text-decoration: underline;\">replaceability</span></a>. Typically this arises in contexts of career choice, but there is a different application here. The QALYs associated with aborted children might not be so bad if the mother will go on to have another child instead. If she does, the net QALY loss is much lower than the gross QALY loss. Of course, the benefits of aborting the fetus are equivalently much smaller \u2013 if she has a child later on instead, she will have to bear the costs of pregnancy eventually anyway. This resembles concerns that maybe <a href=\"http://blog.givewell.org/2014/04/17/david-roodmans-draft-writeup-on-the-mortality-fertility-connection/\"><span style=\"text-decoration: underline;\">saving children in Africa doesn\u2019t make much difference, because their parents adjust their subsequent fertility.</span></a></p>\n<p>The plausibility behind this idea comes from the idea that, at least in the US, most families have a certain ideal number of children in mind, and basically achieve this goal. As such, missing an opportunity to have an early child simply results in having another later on.</p>\n<p>If this were fully true, utilitarians might decide that abortion actually has no QALY impact at all \u2013 all it does is change the timing of events. On the other hand, <a href=\"https://en.wikipedia.org/wiki/Age_and_female_fertility\"><span style=\"text-decoration: underline;\">fertility declines with age</span></a>, so many couples planning to have a replacement child later may be unable to do so. Also, some people do not have ideal family size plans.</p>\n<p>Additionally, this does not really seem to hold when the alternative is adoption; presumably a woman putting a child up for adoption does not consider it as part of her family, so her future childbearing would be unaffected. This argument might hold if raising the child yourself was the only alternative, but given that adoption services are available, it does not seem to go through.</p>\n<h4 id=\"Autonomy\">Autonomy</h4>\n<p>Sometimes people argue for the permissibility of abortion through autonomy arguments. \u201cIt is my body\u201d, such an argument would go, \u201ctherefore I may do whatever I want with it.\u201d To a certain extent this argument is addressed by pointing out that one\u2019s bodily rights presumably do not extent to killing others, so if the anti-abortion side are correct, or even have a non-trivial probability of being correct, autonomy would be insufficient. It seems that if the autonomy argument is to work, it must be because a different argument has established the non-personhood of fetuses \u2013 in which case the autonomy argument is redundant. Yet even putting this aside, this argument is less appealing to EAs than to non-EAs, because EAs often hold a distinctly non-libertarian account of personal ethics. We believe it is actually good to help people (and avoid hurting them), and perhaps that it is bad to avoid doing so. And many EAs are utilitarians, for whom helping/not-hurting is not merely laud-worthy but actually compulsory. EAs are generally not very impressed with <a href=\"http://aynrandlexicon.com/lexicon/abortion.html\"><span style=\"text-decoration: underline;\">Ayn Rand style autonomy arguments</span></a> for rejecting charity, so again EAs should tend to be unsympathetic to autonomy arguments for the permissibility of abortion.</p>\n<p>Indeed, some EAs even think we should be legally obliged to act in good ways, whether through laws against factory farming or tax-funded foreign aid.</p>\n<h4 id=\"Deontology\">Deontology</h4>\n<p>An argument often used on the opposite side&nbsp; \u2013 that is, an argument used to oppose abortion, is that abortion is murder, and murder is simply always wrong. Whether because <a href=\"https://en.wikipedia.org/wiki/You_shall_not_murder\"><span style=\"text-decoration: underline;\">God commanded it</span></a> or <a href=\"https://en.wikipedia.org/wiki/Kantian_ethics\"><span style=\"text-decoration: underline;\">Kant derived it</span></a>, we should place the utmost importance of never murdering. I\u2019m not sure that any EA principle <em>directly</em> pulls against this, but nonetheless most EAs are consequentialists, who believe that all values can be compared. If aborting one child would save a million others, most EAs would probably endorse the abortion. So I think this is one case where a common EA view pulls in favor of the permissibility of abortion.</p>\n<h4 id=\"I_didn_t_ask_for_this\">I didn\u2019t ask for this</h4>\n<p>Another argument often used for the permissibility of abortion is that the situation is in some sense unfair. If one did not intend to become pregnant \u2013 perhaps even took precautions to avoid becoming so \u2013 but nonetheless ends up pregnant, you\u2019re in some way not responsible for becoming pregnant. And since you\u2019re not responsible for it you have no obligations concerning it \u2013 so may permissible abort the fetus.</p>\n<p>However, once again this runs counter to a major strand of EA thought. Most of us did not ask to be born in rich countries, or to be intelligent, or hardworking. Perhaps it was simply luck. Yet being in such a position nonetheless means we have certain opportunities and obligations. Specifically, we have the opportunity to use of wealth to significantly aid those less fortunate than ourselves in the developing world, and many EAs would agree the obligation. So EAs seem to reject the general idea that not intending a situation relieves one of the responsibilities of that situation.</p>\n<h4 id=\"Infanticide_is_okay_too\">Infanticide is okay too</h4>\n<p>A frequent argument against the permissibility of aborting fetuses is by analogy to infanticide. In general <a href=\"http://www.gwern.net/An%20Abortion%20Dialogue\"><span style=\"text-decoration: underline;\">it is hard to produce a coherent criteria that permits the killing of babies before birth but forbids it after birth</span></a>. For most people, this is a reasonably compelling objection: murdering innocent babies is clearly evil! Yet some EAs actually <a href=\"http://www.utilitarian.net/singer/by/1993----.htm\"><span style=\"text-decoration: underline;\">endorse infanticide</span></a>. If you were one of those people, this particular argument would have little sway over you.</p>\n<h4 id=\"Moral_Universalism\">Moral Universalism</h4>\n<p>A common implicit premise in many moral discussion is that the same moral principles apply to everyone. When Sarah did her QALY calculation, she counted the baby\u2019s QALYs as equally important to her own in the scenario where they counted at all. Similarly, both sides of the debate assume that whatever the answer is, it will apply fairly broadly. Perhaps permissibility varies by age of the fetus \u2013 maybe ending <a href=\"https://en.wikipedia.org/wiki/Fetal_viability#Scientific_thresholds\"><span style=\"text-decoration: underline;\">when viability hits</span></a> \u2013 but the same answer will apply to rich and poor, Christian and Jew, etc.</p>\n<p>This is something some EAs might reject. Yes, saving the baby produces many more QALYs than Sarah loses through the pregnancy, and that would be the end of the story if Sarah were simply an ordinary person. But Sarah is an EA, and so has a much higher opportunity cost for her time. Becoming pregnant will undermine her career as an investment banker, the argument would go, which in turn prevents her from donating to AMF and saving a great many lives. Because of this, Sarah is in a special position \u2013 it is permissible for her, but it would not be permissible for someone who wasn\u2019t saving many lives a year.</p>\n<p>I think this is a pretty repugnant attitude in general, and a particularly objectionable instance of it, but I include it here for completeness.</p>\n<h3 id=\"May_we_discuss_this_\">May we discuss this?</h3>\n<p>Now we\u2019ve considered these arguments, it appears that applying general EA principles to the issue in general tends to make abortion look less morally permissible, though there were one or two exceptions. But there is also a second order issue that we should perhaps address \u2013 is it permissible to discuss this issue at all?</p>\n<h4 id=\"Nothing_to_do_with_you\">Nothing to do with you</h4>\n<p>A frequently seen argument on this issue is to claim that <a href=\"http://www.independent.co.uk/voices/comment/i-helped-shut-down-an-abortion-debate-between-two-men-because-my-uterus-isnt-up-for-their-discussion-9867200.html\"><span style=\"text-decoration: underline;\">the speaker has no right to opine on the issue</span></a>. If it doesn\u2019t personally affect you, you cannot discuss it \u2013 especially if you\u2019re privileged. As many (a majority?) of EAs are male, and of the women many are not pregnant, this would curtail dramatically the ability of EAs to discuss abortion. This is not so much an argument on one side or other of the issue as an argument for silence.</p>\n<p>Leaving aside the inherent virtues and vices of this argument, it is not very suitable for EAs. Because EAs have many many opinions on topics that don\u2019t directly affect them:</p>\n<ul>\n<li>EAs have opinions on disease in Africa, yet most have never been to Africa, and never will</li>\n<li>EAs have opinions on (non-human) animal suffering, yet most are not non-human animals</li>\n<li>EAs have opinions on the far future, yet live in the present</li>\n</ul>\n<p>Indeed, EAs seem <em>more</em> qualified to comment on abortion \u2013 as we all were once fetuses, and many of us will become pregnant. If taken seriously this argument would call foul on virtually ever EA activity! And this is no idle fantasy \u2013 there are certainly some people who think that <a href=\"http://www.dambisamoyo.com/books-and-publications/book/dead-aid/\"><span style=\"text-decoration: underline;\">Westerns cannot usefully contribute to solving African poverty</span></a>.</p>\n<h4 id=\"Too_controversial\">Too controversial</h4>\n<p>We can safely say this is a somewhat controversial issue. Perhaps it is too controversial \u2013 maybe it is bad for the movement to discuss. One might accept the arguments above \u2013 that EA principles generally undermine the traditional reasons for thinking abortion is morally permissible \u2013 yet think we should not talk about it. The controversy might divide the community and undermine trust. Perhaps it might deter newcomers. I\u2019m somewhat sympathetic to this argument \u2013 I take the <a href=\"http://slatestarcodex.com/2013/06/14/the-virtue-of-silence/\"><span style=\"text-decoration: underline;\">virtue of silence</span></a> seriously, though eventually my boyfriend persuaded me it was worth publishing.</p>\n<p>Note that the controversial nature is evidence <em>against</em> abortion\u2019s moral permissibility, due to moral uncertainty.</p>\n<p>However, the EA movement is no stranger to controversy.</p>\n<ul>\n<li>There is a semi-official EA position on immigration, which is about as controversial as abortion in the US at the moment, and the EA position is such an extreme position that essentially no mainstream politicians hold it.</li>\n<li>There is a semi-official EA position on vegetarianism, which is pretty controversial too, as it involves implying that the majority of Americans are complicit in murder every day.</li>\n</ul>\n<h4 id=\"Not_worthy_of_discussion\">Not worthy of discussion</h4>\n<p>Finally, another objection to discussing this is it simply it\u2019s an EA idea. There are many disagreements in the world, yet there is no need for an EA view on each. Conflict between the Lilliputians and Blefuscudians notwithstanding, there is no need for an EA perspective on which end of the egg to break first. And we should be especially careful of heated, emotional topics with less avenue to <a href=\"http://www.overcomingbias.com/2007/05/policy_tugowar.html\"><span style=\"text-decoration: underline;\">pull the rope sideways</span></a>. As such, even though the object-level arguments given above are correct, we should simply decline to discuss it.</p>\n<p>However, it seems that if abortion is a moral issue, it is a very large one. In the same way that the sheer number of QALYs lost makes abortion worse than adoption even if our credence in fetuses having moral significance was very low, the large number of abortions occurring each year make the issue as a whole of high significance. In 2011 there were <a href=\"http://www.guttmacher.org/pubs/journals/psrh.46e0414.pdf\"><span style=\"text-decoration: underline;\">over 1 million babies were aborted in the US</span></a>. I\u2019ve seen a wide range of global estimates, including <a href=\"http://www.johnstonsarchive.net/policy/abortion/wrjp3313.html\">around 10 million</a> to <a href=\"http://www.guttmacher.org/pubs/Abortion-Worldwide.pdf\"><span style=\"text-decoration: underline;\">over 40 million</span></a>. By contrast, the WHO estimates there are <a href=\"http://www.who.int/gho/malaria/epidemic/deaths/en/\"><span style=\"text-decoration: underline;\">fewer than 1 million malaria deaths worldwide</span></a> each year. Abortion deaths also cause a higher loss of QALYs due to the young age at which they occur. On the other hand, we should discount them for the uncertainty that they are morally significant. And perhaps there is <a href=\"http://www.amirrorclear.net/academic/papers/scourge.pdf\"><span style=\"text-decoration: underline;\">an even larger closely related moral issue</span></a>. The size of the issue is not the only <a href=\"http://effective-altruism.com/ea/cr/factoring_costeffectiveness/\"><span style=\"text-decoration: underline;\">factor</span></a> in estimating the cost-effectiveness of interventions, but it is the most easily estimable. On the other hand, I have little idea how many dollars of donations it takes to save a fetus \u2013 it seems like an excellent example of some low-hanging fruit research.</p>\n<h3 id=\"Conclusion\">Conclusion</h3>\n<p>People frequently compartmentalize their beliefs, and avoid addressing the implications between them. Ordinarily, this is perhaps innocuous, but when the both ideas are highly morally important, their interaction is in turn important. In this post we the implications of common EA beliefs on the permissibility of abortion. Taking into account moral uncertainty makes aborting a fetus seem far less permissible, as the high counterfactual life expectancy of the baby tends to dominate other factors. Many other EA views are also significant to the issue, making various standard arguments on each side less plausible.</p>\n<p>&nbsp;</p>\n<div class=\"footnotes\">\n<hr>\n<ol>\n<li id=\"fn-160-1\"> There doesn\u2019t seem to be any neutral language one can use here, so I\u2019m just going to switch back and forth between \u2018fetus\u2019 and \u2018child\u2019 or \u2018baby\u2019 in a vain attempt at terminological neutrality.&nbsp; </li>\n<li id=\"fn-160-2\"> I chose this reason because it is the <a href=\"http://www.guttmacher.org/pubs/journals/3711005.pdf\"><span style=\"text-decoration: underline;\">most frequently cited main motivation for aborting a fetus</span></a> according to the Guttmacher Institute.&nbsp; </li>\n</ol></div>\n</div>\n</div>\n</div>\n</div>", "sections": [{"title": "Moral Uncertainty", "anchor": "Moral_Uncertainty", "level": 1}, {"title": "Other EA concepts and their applications to this issue", "anchor": "Other_EA_concepts_and_their_applications_to_this_issue", "level": 1}, {"title": "Not really people", "anchor": "Not_really_people", "level": 2}, {"title": "Not people yet", "anchor": "Not_people_yet", "level": 2}, {"title": "Replaceability", "anchor": "Replaceability", "level": 2}, {"title": "Autonomy", "anchor": "Autonomy", "level": 2}, {"title": "Deontology", "anchor": "Deontology", "level": 2}, {"title": "I didn\u2019t ask for this", "anchor": "I_didn_t_ask_for_this", "level": 2}, {"title": "Infanticide is okay too", "anchor": "Infanticide_is_okay_too", "level": 2}, {"title": "Moral Universalism", "anchor": "Moral_Universalism", "level": 2}, {"title": "May we discuss this?", "anchor": "May_we_discuss_this_", "level": 1}, {"title": "Nothing to do with you", "anchor": "Nothing_to_do_with_you", "level": 2}, {"title": "Too controversial", "anchor": "Too_controversial", "level": 2}, {"title": "Not worthy of discussion", "anchor": "Not_worthy_of_discussion", "level": 2}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "80 comments"}], "headingsCount": 17}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 80, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Q8jyAdRYbieK8PtfT", "N99KgncSXewWqkzMA", "wkuDgmpxwbu2M2k3w", "AvJeJw52NL9y7RJDJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T00:33:07.319Z", "modifiedAt": null, "url": null, "title": "Negative Polyamory outcomes?", "slug": "negative-polyamory-outcomes-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:05.015Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atorm", "createdAt": "2011-03-30T16:41:30.635Z", "isAdmin": false, "displayName": "atorm"}, "userId": "PvazkPKLZs5LNujcL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xq9THnnhztQr6Grnf/negative-polyamory-outcomes-0", "pageUrlRelative": "/posts/Xq9THnnhztQr6Grnf/negative-polyamory-outcomes-0", "linkUrl": "https://www.lesswrong.com/posts/Xq9THnnhztQr6Grnf/negative-polyamory-outcomes-0", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Negative%20Polyamory%20outcomes%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANegative%20Polyamory%20outcomes%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXq9THnnhztQr6Grnf%2Fnegative-polyamory-outcomes-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Negative%20Polyamory%20outcomes%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXq9THnnhztQr6Grnf%2Fnegative-polyamory-outcomes-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXq9THnnhztQr6Grnf%2Fnegative-polyamory-outcomes-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 247, "htmlBody": "<p>Related article:&nbsp;<a href=\"/lw/79x/polyhacking/ \">Polyhacking</a></p>\n<p>&nbsp;</p>\n<p>Although polyamory isn't one of the \"official\" topics of LW interest (human cognition, AI, probability, etc...), this is the only community I'm part of where I expect a sufficiently high number of members to have experience with it to give useful feedback.&nbsp;</p>\n<p>&nbsp;</p>\n<p>If you go looking for advice or articles about polyamory on the internet, you mostly get stuff written by polyamorists that are happy with their decisions. Is this selection bias? Where are the people whose relationships (or social lives, out anything) got damaged or ruined by experimenting with Consensual Non-Monogamy?</p>\n<p>&nbsp;</p>\n<p>I'm posting this hoping for feedback, negative AND positive, on experiences with polyamory. I considered putting this in an Open Thread, but it occurred to me that many other LW readers might be interested in whether polyamory has drawbacks they need to be aware of. If you have experience with CNM (including first-hand witnessing, which has the added bonus of not requiring you to out yourself if you don't want to), please comment with your overall impression and as much detail as you would like to include (I am also putting my experiences there rather than in this post). If you've seen multiple poly relationships, multiple comments would make tallying slightly easier. (ETA: I will also try to upvote people who feed me data, a la LW surveys) If there are sufficient comments, I will periodically go through them and post a rough ratio of good to bad experiences at the bottom of this article.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xq9THnnhztQr6Grnf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "27851", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kLR5H4pbaBjzZxLv6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T04:54:37.400Z", "modifiedAt": null, "url": null, "title": "Meetup : Dallas, TX", "slug": "meetup-dallas-tx", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:08.223Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DubiousTwizzler", "createdAt": "2011-04-07T06:15:33.501Z", "isAdmin": false, "displayName": "DubiousTwizzler"}, "userId": "nACnJyX4WBYjkt4ap", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uBKMhchFxJ4QAweBW/meetup-dallas-tx", "pageUrlRelative": "/posts/uBKMhchFxJ4QAweBW/meetup-dallas-tx", "linkUrl": "https://www.lesswrong.com/posts/uBKMhchFxJ4QAweBW/meetup-dallas-tx", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Dallas%2C%20TX&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Dallas%2C%20TX%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuBKMhchFxJ4QAweBW%2Fmeetup-dallas-tx%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Dallas%2C%20TX%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuBKMhchFxJ4QAweBW%2Fmeetup-dallas-tx", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuBKMhchFxJ4QAweBW%2Fmeetup-dallas-tx", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 122, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18l'>Dallas, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 January 2015 01:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">3725 Belt Line Road, Addison, TX 75001</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is the new Dallas meetup. We will be meeting up at Dunn Bros Coffee on Saturday, Jan 10th at 1 PM. We will have a sign that says \"Less Wrong\" on it.</p>\n\n<p>(We're open to changing the location after the first meetup)</p>\n\n<p>My roommate and I just moved to Dallas and decided it was time for a meetup. There was a previous Dallas LW meetup which disappeared for reasons unknown to us. Neither of us attended that meetup, but we invite any previous members and any newcomers to have coffee with us and hang out.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18l'>Dallas, TX</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uBKMhchFxJ4QAweBW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.338905308306485e-06, "legacy": true, "legacyId": "27855", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Dallas__TX\">Discussion article for the meetup : <a href=\"/meetups/18l\">Dallas, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 January 2015 01:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">3725 Belt Line Road, Addison, TX 75001</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is the new Dallas meetup. We will be meeting up at Dunn Bros Coffee on Saturday, Jan 10th at 1 PM. We will have a sign that says \"Less Wrong\" on it.</p>\n\n<p>(We're open to changing the location after the first meetup)</p>\n\n<p>My roommate and I just moved to Dallas and decided it was time for a meetup. There was a previous Dallas LW meetup which disappeared for reasons unknown to us. Neither of us attended that meetup, but we invite any previous members and any newcomers to have coffee with us and hang out.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Dallas__TX1\">Discussion article for the meetup : <a href=\"/meetups/18l\">Dallas, TX</a></h2>", "sections": [{"title": "Discussion article for the meetup : Dallas, TX", "anchor": "Discussion_article_for_the_meetup___Dallas__TX", "level": 1}, {"title": "Discussion article for the meetup : Dallas, TX", "anchor": "Discussion_article_for_the_meetup___Dallas__TX1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T12:25:17.934Z", "modifiedAt": null, "url": null, "title": "Negative polyamory outcomes?", "slug": "negative-polyamory-outcomes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:03.157Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atorm", "createdAt": "2011-03-30T16:41:30.635Z", "isAdmin": false, "displayName": "atorm"}, "userId": "PvazkPKLZs5LNujcL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WKSmQtARnW4mPEpXL/negative-polyamory-outcomes", "pageUrlRelative": "/posts/WKSmQtARnW4mPEpXL/negative-polyamory-outcomes", "linkUrl": "https://www.lesswrong.com/posts/WKSmQtARnW4mPEpXL/negative-polyamory-outcomes", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Negative%20polyamory%20outcomes%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANegative%20polyamory%20outcomes%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWKSmQtARnW4mPEpXL%2Fnegative-polyamory-outcomes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Negative%20polyamory%20outcomes%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWKSmQtARnW4mPEpXL%2Fnegative-polyamory-outcomes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWKSmQtARnW4mPEpXL%2Fnegative-polyamory-outcomes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 283, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Related article:&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/79x/polyhacking/\">Polyhacking</a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Note: This article was posted&nbsp;<a style=\"font-family: Verdana, Arial, Helvetica, sans-serif;\" href=\"/r/discussion/lw/lhn/negative_polyamory_outcomes/\">earlier</a>&nbsp;for less than a day but accidentally deleted.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Although polyamory isn't one of the \"official\" topics of LW interest (human cognition, AI, probability, etc...), this is the only community I'm part of where I expect a sufficiently high number of members to have experience with it to give useful feedback.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">If you go looking for advice or articles about polyamory on the internet, you mostly get stuff written by polyamorists that are happy with their decisions. Is this selection bias? Where are the people whose relationships (or social lives, out anything) got damaged or ruined by experimenting with Consensual Non-Monogamy?</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">I'm posting this hoping for feedback, negative AND positive, on experiences with polyamory. I considered putting this in an Open Thread, but it occurred to me that many other LW readers might be interested in whether polyamory has drawbacks they need to be aware of. If you have experience with CNM (including first-hand witnessing, which has the added bonus of not requiring you to out yourself while still participating in the dialogue), please comment with your overall impression and as much detail as you would like to include (I am also putting my experiences there rather than in this post). If you've seen multiple poly relationships, multiple comments would make tallying slightly easier. I will try to upvote people who feed me data, a la LW surveys. If there are sufficient comments, I will periodically go through them and post a rough ratio of good to bad experiences at the bottom of this article.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">PSA: The Username account is available for use by any who wish to remain anonymous. The password is left as an exercise for the reader. Hat tip... Username.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AWz5ryH8SpAgTeydh": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WKSmQtARnW4mPEpXL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 26, "extendedScore": null, "score": 0.000108, "legacy": true, "legacyId": "27856", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 104, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kLR5H4pbaBjzZxLv6", "Xq9THnnhztQr6Grnf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T12:48:41.845Z", "modifiedAt": null, "url": null, "title": "Open thread Jan. 5-11, 2015", "slug": "open-thread-jan-5-11-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:28.485Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "polymathwannabe", "createdAt": "2013-08-29T03:03:37.800Z", "isAdmin": false, "displayName": "polymathwannabe"}, "userId": "NkxHWoA85iw2PpxSt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hgoN3zTzMkgbaWFKz/open-thread-jan-5-11-2015", "pageUrlRelative": "/posts/hgoN3zTzMkgbaWFKz/open-thread-jan-5-11-2015", "linkUrl": "https://www.lesswrong.com/posts/hgoN3zTzMkgbaWFKz/open-thread-jan-5-11-2015", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%20Jan.%205-11%2C%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%20Jan.%205-11%2C%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhgoN3zTzMkgbaWFKz%2Fopen-thread-jan-5-11-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%20Jan.%205-11%2C%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhgoN3zTzMkgbaWFKz%2Fopen-thread-jan-5-11-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhgoN3zTzMkgbaWFKz%2Fopen-thread-jan-5-11-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 64, "htmlBody": "<div id=\"entry_t3_lg5\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px; font-weight: bold;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/new/\" target=\"_blank\">list-of-threads page</a>&nbsp;before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">3.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should be posted in Discussion, and not Main.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">4.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hgoN3zTzMkgbaWFKz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "27857", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 152, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T15:51:20.824Z", "modifiedAt": null, "url": null, "title": "How much does consumption affect production?", "slug": "how-much-does-consumption-affect-production", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.555Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "erratim", "createdAt": "2013-12-15T01:12:59.930Z", "isAdmin": false, "displayName": "Timothy Telleen-Lawton"}, "userId": "DeTtX86GPntE5znsf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BvLpXNBevSZe32bXd/how-much-does-consumption-affect-production", "pageUrlRelative": "/posts/BvLpXNBevSZe32bXd/how-much-does-consumption-affect-production", "linkUrl": "https://www.lesswrong.com/posts/BvLpXNBevSZe32bXd/how-much-does-consumption-affect-production", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20much%20does%20consumption%20affect%20production%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20much%20does%20consumption%20affect%20production%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBvLpXNBevSZe32bXd%2Fhow-much-does-consumption-affect-production%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20much%20does%20consumption%20affect%20production%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBvLpXNBevSZe32bXd%2Fhow-much-does-consumption-affect-production", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBvLpXNBevSZe32bXd%2Fhow-much-does-consumption-affect-production", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 967, "htmlBody": "<h3>A ewe for a ewe</h3>\n<p>In <a href=\"http://benjaminrosshoffman.com/want-to-summon-less-animal-suffering/#comment-74828\">a discussion</a> with&nbsp;<a href=\"/user/Benquo/overview/\">Benquo</a>&nbsp;over his recent&nbsp;<a href=\"http://benjaminrosshoffman.com/want-to-summon-less-animal-suffering/\">suffering-per-calorie estimates</a> I learned that there have been a&nbsp;<a href=\"/lw/i3s/why_eat_less_meat/\">few</a>&nbsp;<a href=\"http://www.amazon.com/Compassion-Pound-Economics-Animal-Welfare/dp/0199551162\">different</a>&nbsp;<a href=\"http://www.animalcharityevaluators.org/research/foundational-research/effects-of-diet-choices-on-animals/\">proponents</a> of incorporating short term elasticities&nbsp;into such estimates. But do empirical short term elasticities really improve our estimates of consumption's long term effect on production? For example, if I decide to reduce my lifetime consumption of chicken by one, should I expect the long term production of chicken to drop by ~1, ~0, or something in between?</p>\n<p>I believe we should have a relatively strong prior that long term production has a &nbsp;roughly 1:1 relationship with consumption, including for small individual decisions. Below are a couple arguments I find compelling, and a major exception that is not a short term elasticity.</p>\n<h4>Black box economies in general</h4>\n<p>If I go to a large alien civilization of uncertain economic structure and surprise them by buying(?) one widget, how should I expect that to affect their long term production of widgets? Seems like I should expect it to increase by one, because now they have one less than they used to. If it was originally decided that that widget should be produced; why wouldn't they decide to replace it when lost?</p>\n<h4>Neoclassical capitalism in the long term</h4>\n<p>In a simplified market, I expect there to be a lowest price at which chickens can be reliably produced at scale (\"the Cost\"). If producers expect the market price to be less than the Cost in the future, they will shut down production to avoid losses. If they expect it to be more than the Cost in the future, they might expand operations to make more profit. In the long term (when we can ignore temporary shocks to the system and producers have time to make adjustments), I expect the equilibrium price of chicken to approach the Cost of chicken (because other prices lead to conditions that push the price back toward the Cost). In other words, my prior is that the \"price elasticity of supply\" in the arbitrarily long term becomes arbitrarily high (imagine a virtually horizontal <a href=\"http://www.animalcharityevaluators.org/wp-content/uploads/2013/12/cef.pdf\">supply curve</a>).</p>\n<p>How many chickens will be produced at that long term price? However many are worth the Cost to consumers. If 50% of chicken consumers permanently become vegetarians, I expect that eventually the chicken industry will end up producing about 50% fewer chickens at a price similar to today's.</p>\n<h5><span style=\"font-size: small; font-weight: normal;\">Similarly if consumption is reduced by just one chicken. My prior is that producers have an unbiased estimate of consumption, and that doesn't change when I eat one less chicken (so my best guess about their long term estimate of consumption drops by one when I forgo one chicken).</span></h5>\n<h4>Time breaks the elastic limit</h4>\n<p>Compare my prior that every chicken forgone causes (in the long term) one less chicken to be produced, to the estimates that it only causes <a href=\"http://www.animalcharityevaluators.org/research/foundational-research/effects-of-diet-choices-on-animals/#second\">6%</a>&nbsp;or <a href=\"http://everydayutilitarian.com/essays/how-much-suffering-is-in-the-standard-american-diet/\">76%</a>&nbsp;of a chicken to not be produced (as Peter Hurford points out in the second case, the enormous range in these estimates alone is enough to raise flags).</p>\n<p>Those numbers sound plausible in the short term when there's a backup in the chicken pipeline and a drop in price because producers were caught off guard by the drop in consumption. But if the vegetarians hold their new diets, won't the producers eventually react to the changed market? When they do I bet the equilibrium price will be somewhere close to the original Cost, and the quantity produced will be about 50% less (not 3% less or even 38% less). I think the thing these elasticity estimates are forgetting is that the producers aren't satisfied (in the long term) with the lower price that results from a chicken glut caused by vegetarianism. If they were, they'd be producing more chickens now.</p>\n<p>Said another way, it all comes down to the difference between producers' reaction in the short term vs. the long term. In the short term, when someone decides not to eat a chicken, it goes to the next highest bidder (so price drops and production doesn't change much). But in the long term, producers produce all the chickens that will be demanded at the Cost (they want to produce as many as they can at that price, but if they produce any more, the chickens will be sold at a loss). When one person permanently becomes vegetarian, we should expect that long term size of the industry decreases accordingly.</p>\n<h4>When the long term Cost changes with industry size</h4>\n<p>To be clear, if we could actually measure consumption's effect on long term production in specific cases, it would rarely be exactly 1:1, though my prior is that it will average out to that over time. The exception is if consumption consistently affects the long term price in a particular direction. For example, here are some reasons that I might expect the Cost of chicken to grow or shrink as the size of the chicken industry increases:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Finite inputs such as limited agricultural land (Cost grows with size)</li>\n<li>The production process also creates another product like eggs (Cost grows with size if marginal production is used for both)</li>\n<li>Gains to scale such as factory farming (Cost shrinks with size)</li>\n<li>R&amp;D or innovation (Cost shrinks with size)</li>\n<li>Favorable government policies (Cost shrinks with size)</li>\n</ul>\n<p>&nbsp;</p>\n<p>If we have sufficiently certain estimates on any of these effects, we can certainly try to model them, although it would be a very different exercise than using empirical estimates of short-term elasticities. As it is, I have no idea which of the above effects win out (ie, whether the \"consumption elasticity of the Cost\" is positive or negative in the long term).</p>\n<p>I think we would make our estimates more simple and accurate by sticking with the prior that eating one less chicken causes about one less chicken to be produced in the long term.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BvLpXNBevSZe32bXd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 7, "extendedScore": null, "score": 2.3404573862592447e-06, "legacy": true, "legacyId": "27826", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h3 id=\"A_ewe_for_a_ewe\">A ewe for a ewe</h3>\n<p>In <a href=\"http://benjaminrosshoffman.com/want-to-summon-less-animal-suffering/#comment-74828\">a discussion</a> with&nbsp;<a href=\"/user/Benquo/overview/\">Benquo</a>&nbsp;over his recent&nbsp;<a href=\"http://benjaminrosshoffman.com/want-to-summon-less-animal-suffering/\">suffering-per-calorie estimates</a> I learned that there have been a&nbsp;<a href=\"/lw/i3s/why_eat_less_meat/\">few</a>&nbsp;<a href=\"http://www.amazon.com/Compassion-Pound-Economics-Animal-Welfare/dp/0199551162\">different</a>&nbsp;<a href=\"http://www.animalcharityevaluators.org/research/foundational-research/effects-of-diet-choices-on-animals/\">proponents</a> of incorporating short term elasticities&nbsp;into such estimates. But do empirical short term elasticities really improve our estimates of consumption's long term effect on production? For example, if I decide to reduce my lifetime consumption of chicken by one, should I expect the long term production of chicken to drop by ~1, ~0, or something in between?</p>\n<p>I believe we should have a relatively strong prior that long term production has a &nbsp;roughly 1:1 relationship with consumption, including for small individual decisions. Below are a couple arguments I find compelling, and a major exception that is not a short term elasticity.</p>\n<h4 id=\"Black_box_economies_in_general\">Black box economies in general</h4>\n<p>If I go to a large alien civilization of uncertain economic structure and surprise them by buying(?) one widget, how should I expect that to affect their long term production of widgets? Seems like I should expect it to increase by one, because now they have one less than they used to. If it was originally decided that that widget should be produced; why wouldn't they decide to replace it when lost?</p>\n<h4 id=\"Neoclassical_capitalism_in_the_long_term\">Neoclassical capitalism in the long term</h4>\n<p>In a simplified market, I expect there to be a lowest price at which chickens can be reliably produced at scale (\"the Cost\"). If producers expect the market price to be less than the Cost in the future, they will shut down production to avoid losses. If they expect it to be more than the Cost in the future, they might expand operations to make more profit. In the long term (when we can ignore temporary shocks to the system and producers have time to make adjustments), I expect the equilibrium price of chicken to approach the Cost of chicken (because other prices lead to conditions that push the price back toward the Cost). In other words, my prior is that the \"price elasticity of supply\" in the arbitrarily long term becomes arbitrarily high (imagine a virtually horizontal <a href=\"http://www.animalcharityevaluators.org/wp-content/uploads/2013/12/cef.pdf\">supply curve</a>).</p>\n<p>How many chickens will be produced at that long term price? However many are worth the Cost to consumers. If 50% of chicken consumers permanently become vegetarians, I expect that eventually the chicken industry will end up producing about 50% fewer chickens at a price similar to today's.</p>\n<h5><span style=\"font-size: small; font-weight: normal;\">Similarly if consumption is reduced by just one chicken. My prior is that producers have an unbiased estimate of consumption, and that doesn't change when I eat one less chicken (so my best guess about their long term estimate of consumption drops by one when I forgo one chicken).</span></h5>\n<h4 id=\"Time_breaks_the_elastic_limit\">Time breaks the elastic limit</h4>\n<p>Compare my prior that every chicken forgone causes (in the long term) one less chicken to be produced, to the estimates that it only causes <a href=\"http://www.animalcharityevaluators.org/research/foundational-research/effects-of-diet-choices-on-animals/#second\">6%</a>&nbsp;or <a href=\"http://everydayutilitarian.com/essays/how-much-suffering-is-in-the-standard-american-diet/\">76%</a>&nbsp;of a chicken to not be produced (as Peter Hurford points out in the second case, the enormous range in these estimates alone is enough to raise flags).</p>\n<p>Those numbers sound plausible in the short term when there's a backup in the chicken pipeline and a drop in price because producers were caught off guard by the drop in consumption. But if the vegetarians hold their new diets, won't the producers eventually react to the changed market? When they do I bet the equilibrium price will be somewhere close to the original Cost, and the quantity produced will be about 50% less (not 3% less or even 38% less). I think the thing these elasticity estimates are forgetting is that the producers aren't satisfied (in the long term) with the lower price that results from a chicken glut caused by vegetarianism. If they were, they'd be producing more chickens now.</p>\n<p>Said another way, it all comes down to the difference between producers' reaction in the short term vs. the long term. In the short term, when someone decides not to eat a chicken, it goes to the next highest bidder (so price drops and production doesn't change much). But in the long term, producers produce all the chickens that will be demanded at the Cost (they want to produce as many as they can at that price, but if they produce any more, the chickens will be sold at a loss). When one person permanently becomes vegetarian, we should expect that long term size of the industry decreases accordingly.</p>\n<h4 id=\"When_the_long_term_Cost_changes_with_industry_size\">When the long term Cost changes with industry size</h4>\n<p>To be clear, if we could actually measure consumption's effect on long term production in specific cases, it would rarely be exactly 1:1, though my prior is that it will average out to that over time. The exception is if consumption consistently affects the long term price in a particular direction. For example, here are some reasons that I might expect the Cost of chicken to grow or shrink as the size of the chicken industry increases:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Finite inputs such as limited agricultural land (Cost grows with size)</li>\n<li>The production process also creates another product like eggs (Cost grows with size if marginal production is used for both)</li>\n<li>Gains to scale such as factory farming (Cost shrinks with size)</li>\n<li>R&amp;D or innovation (Cost shrinks with size)</li>\n<li>Favorable government policies (Cost shrinks with size)</li>\n</ul>\n<p>&nbsp;</p>\n<p>If we have sufficiently certain estimates on any of these effects, we can certainly try to model them, although it would be a very different exercise than using empirical estimates of short-term elasticities. As it is, I have no idea which of the above effects win out (ie, whether the \"consumption elasticity of the Cost\" is positive or negative in the long term).</p>\n<p>I think we would make our estimates more simple and accurate by sticking with the prior that eating one less chicken causes about one less chicken to be produced in the long term.</p>", "sections": [{"title": "A ewe for a ewe", "anchor": "A_ewe_for_a_ewe", "level": 1}, {"title": "Black box economies in general", "anchor": "Black_box_economies_in_general", "level": 2}, {"title": "Neoclassical capitalism in the long term", "anchor": "Neoclassical_capitalism_in_the_long_term", "level": 2}, {"title": "Time breaks the elastic limit", "anchor": "Time_breaks_the_elastic_limit", "level": 2}, {"title": "When the long term Cost changes with industry size", "anchor": "When_the_long_term_Cost_changes_with_industry_size", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "60 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 60, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LbbyQhLkcwAwWmBoj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T19:36:59.292Z", "modifiedAt": null, "url": null, "title": "2014 Survey Results", "slug": "2014-survey-results", "viewCount": null, "lastCommentedAt": "2019-03-13T08:36:46.899Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YAkpzvjC768Jm2TYb/2014-survey-results", "pageUrlRelative": "/posts/YAkpzvjC768Jm2TYb/2014-survey-results", "linkUrl": "https://www.lesswrong.com/posts/YAkpzvjC768Jm2TYb/2014-survey-results", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%202014%20Survey%20Results&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A2014%20Survey%20Results%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAkpzvjC768Jm2TYb%2F2014-survey-results%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=2014%20Survey%20Results%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAkpzvjC768Jm2TYb%2F2014-survey-results", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAkpzvjC768Jm2TYb%2F2014-survey-results", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4898, "htmlBody": "<p>Thanks to everyone who took the 2014 Less Wrong Census/Survey. Extra thanks to Ozy, who did a lot of the number crunching work.</p>\n<p>This year's results are below. Some of them may make more sense in the context of the original survey questions, which <a href=\"https://docs.google.com/forms/d/1h4IisKq7p8CRRVT_UXMSiKW6RE5U5nl1PLT_MvpbX2I/viewform\">can be seen here</a>. Please do not try to take the survey as it is over and your results will not be counted.</p>\n<h2><strong>I. Population</strong></h2>\n<p>There were 1503 respondents over 27 days. The last survey got 1636 people over 40 days. The last four full days of the survey saw nineteen, six, and four responses, for an average of about ten. If we assume the next thirteen days had also gotten an average of ten responses - which is generous, since responses tend to trail off with time - then we would have gotten about as many people as the last survey. There is no good evidence here of a decline in population, although it is perhaps compatible with a very small decline.</p>\n<h2><strong>II. Demographics</strong></h2>\n<p><strong>Sex</strong><br />Female: 179, 11.9%<br />Male: 1311, 87.2%<br /><br /><strong>Gender</strong><br />F (cisgender): 150, 10.0%<br />F (transgender MtF): 24, 1.6%<br />M (cisgender): 1245, 82.8%<br />M (transgender FtM): 5, 0.3%<br />Other: 64, 4.3%<br /><br /><strong>Sexual Orientation</strong><br />Asexual: 59, 3.9%<br />Bisexual: 216, 14.4%<br />Heterosexual: 1133, 75.4%<br />Homosexual: 47, 3.1%<br />Other: 35, 2.3%<br /><br /><em>[This question was poorly worded and should have acknowledged that people can both be asexual and have a specific orientation; as a result it probably vastly undercounted our asexual readers]</em><br /><br /><strong>Relationship Style</strong><br />Prefer monogamous: 778, 51.8%<br />Prefer polyamorous: 227, 15.1%<br />Uncertain/no preference: 464, 30.9%<br />Other: 23, 1.5%<br /><br /><strong>Number of Partners</strong><br />0: 738, 49.1%<br />1: 674, 44.8%<br />2: 51, 3.4%<br />3: 17, 1.1%<br />4: 7, 0.5%<br />5: 1, 0.1%<br />Lots and lots: 3, 0.2%<br /><br /><strong>Relationship Goals</strong><br />Currently not looking for new partners: 648, 43.1%<br />Open to new partners: 467, 31.1%<br />Seeking more partners: 370, 24.6%<br /><em><br />[22.2% of people who don&rsquo;t have a partner aren&rsquo;t looking for one.]</em><br /><br /><strong>Relationship Status</strong><br />Married: 274, 18.2%<br />Relationship: 424, 28.2%<br />Single: 788, 52.4%<br /><br /><em>[6.9% of single people have at least one partner; 1.8% have more than one.]</em><br /><br /><strong>Living With</strong><br />Alone: 345, 23.0%<br />With parents and/or guardians: 303, 20.2%<br />With partner and/or children: 411, 27.3%<br />With roommates: 428, 28.5%<br /><br /><strong>Children</strong><br />0: 1317, 81.6%<br />1: 66, 4.4%<br />2: 78, 5.2%<br />3: 17, 1.1%<br />4: 6, 0.4%<br />5: 3, 0.2%<br />6: 1, 0.1%<br />Lots and lots: 1, 0.1%<br /><br /><strong>Want More Children?</strong><br />Yes: 549, 36.1%<br />Uncertain: 426, 28.3%<br />No: 516, 34.3%<br /><br /><em>[418 of the people who don&rsquo;t have children don&rsquo;t want any, suggesting that the LW community is 27.8% childfree.]</em><br /><br /><strong>Country</strong><br />United States, 822, 54.7%<br />United Kingdom, 116, 7.7%<br />Canada, 88, 5.9%<br />Australia: 83, 5.5%<br />Germany, 62, 4.1%<br />Russia, 26, 1.7%<br />Finland, 20, 1.3%<br />New Zealand, 20, 1.3%<br />India, 17, 1.1%<br />Brazil: 15, 1.0%<br />France, 15, 1.0%<br />Israel, 15, 1.0%<br /><br /><strong>Lesswrongers Per Capita</strong><br />Finland: 1/271,950<br />New Zealand: 1/223,550<br />Australia: 1/278,674<br />United States: 1/358,390<br />Canada: 1/399,545<br />Israel: 1/537,266<br />United Kingdom: 1/552,586<br />Germany: 1/1,290,323<br />France: 1/ 4,402,000<br />Russia: 1/ 5,519,231<br />Brazil: 1/ 13,360,000<br />India: 1/ 73,647,058<br /><br /><strong>Race</strong><br />Asian (East Asian): 59. 3.9%<br />Asian (Indian subcontinent): 33, 2.2%<br />Black: 12. 0.8%<br />Hispanic: 32, 2.1%<br />Middle Eastern: 9, 0.6%<br />Other: 50, 3.3%<br />White (non-Hispanic): 1294, 86.1%<br /><br /><strong>Work Status</strong><br />Academic (teaching): 86, 5.7%<br />For-profit work: 492, 32.7%<br />Government work: 59, 3.9%<br />Homemaker: 8, 0.5%<br />Independently wealthy: 9, 0.6%<br />Nonprofit work: 58, 3.9%<br />Self-employed: 122, 5.8%<br />Student: 553, 36.8%<br />Unemployed: 103, 6.9%<br /><br /><strong>Profession</strong><br />Art: 22, 1.5%<br />Biology: 29, 1.9%<br />Business: 35, 4.0%<br />Computers (AI): 42, 2.8%<br />Computers (other academic): 106, 7.1%<br />Computers (practical): 477, 31.7%<br />Engineering: 104, 6.1%<br />Finance/Economics: 71, 4.7%<br />Law: 38, 2.5%<br />Mathematics: 121, 8.1%<br />Medicine: 32, 2.1%<br />Neuroscience: 18, 1.2%<br />Philosophy: 36, 2.4%<br />Physics: 65, 4.3%<br />Psychology: 31, 2.1%<br />Other: 157, 10.2%<br />Other &ldquo;hard science&rdquo;: 25, 1.7%<br />Other &ldquo;social science&rdquo;: 34, 2.3%<br /><br /><strong>Degree</strong><br />None: 74, 4.9%<br />High school: 347, 23.1%<br />2 year degree: 64, 4.3%<br />Bachelors: 555, 36.9%<br />Masters: 278, 18.5%<br />JD/MD/other professional degree: 44, 2.9%<br />PhD: 105, 7.0%<br />Other: 24, 1.4%</p>\n<h2><strong>III. Mental Illness</strong></h2>\n<p>535 answer &ldquo;no&rdquo; to all the mental illness questions. Upper bound: 64.4% of the LW population is mentally ill. <br />393 answer &ldquo;yes&rdquo; to at least one mental illness question. Lower bound: 26.1% of the LW population is mentally ill. Gosh, we have a lot of self-diagnosers. <br /><br /><strong>Depression</strong><br />Yes, I was formally diagnosed: 273, 18.2%<br />Yes, I self-diagnosed: 383, 25.5%<br />No: 759, 50.5%<br /><br /><strong>OCD</strong><br />Yes, I was formally diagnosed: 30, 2.0%<br />Yes, I self-diagnosed: 76, 5.1%<br />No: 1306, 86.9%<br /><strong><br />Autism spectrum</strong><br />Yes, I was formally diagnosed: 98, 6.5%<br />Yes, I self-diagnosed: 168, 11.2%<br />No: 1143, 76.0%<br /><strong><br />Bipolar</strong><br />Yes, I was formally diagnosed: 33, 2.2%<br />Yes, I self-diagnosed: 49, 3.3%<br />No: 1327, 88.3%<br /><br /><strong>Anxiety disorder</strong><br />Yes, I was formally diagnosed: 139, 9.2%<br />Yes, I self-diagnosed: 237, 15.8%<br />No: 1033, 68.7%<br /><br /><strong>BPD</strong><br />Yes, I was formally diagnosed: 5, 0.3%<br />Yes, I self-diagnosed: 19, 1.3%<br />No: 1389, 92.4%<br /><br /><em>[Ozy says: RATIONALIST BPDERS COME BE MY FRIEND]</em><br /><br /><strong>Schizophrenia</strong><br />Yes, I was formally diagnosed: 7, 0.5%<br />Yes, I self-diagnosed: 7, 0.5%<br />No: 1397, 92.9%</p>\n<h2><strong>IV. Politics, Religion, Ethics</strong></h2>\n<p><strong>Politics</strong><br />Communist: 9, 0.6%<br />Conservative: 67, 4.5%<br />Liberal: 416, 27.7%<br />Libertarian: 379, 25.2%<br />Social Democratic: 585, 38.9% <br /><br /><em>[The big change this year was that we changed \"Socialist\" to \"Social Democratic\". Even though the description stayed the same, about eight points worth of Liberals switched to Social Democrats, apparently more willing to accept that label than \"Socialist\". The overall supergroups Libertarian vs. (Liberal, Social Democratic) vs. Conservative remain mostly unchanged.]</em><br /><br /><strong>Politics (longform)</strong><br />Anarchist: 40, 2.7%<br />Communist: 9, 0.6%<br />Conservative: 23, 1.9%<br />Futarchist: 41, 2.7%<br />Left-Libertarian: 192, 12.8%<br />Libertarian: 164, 10.9%<br />Moderate: 56, 3.7%<br />Neoreactionary: 29, 1.9%<br />Social Democrat: 162, 10.8%<br />Socialist: 89, 5.9%<br /><em><br />[Amusing politics answers include anti-incumbentist, having-well-founded-opinions-is-hard-but-I&rsquo;ve-come-to-recognize-the-pragmatism-of-socialism-I-don&rsquo;t-know-ask-me-again-next-year, pirate, progressive social democratic environmental liberal isolationist freedom-fries loving pinko commie piece of shit, republic-ist aka read the federalist papers, romantic reconstructionist, social liberal fiscal agnostic, technoutopian anarchosocialist (with moderate snark), whatever it is that Scott is, and WHY ISN&rsquo;T THERE AN OPTION FOR NONE SO I CAN SIGNAL MY OBVIOUS OBJECTIVITY WITH MINIMAL EFFORT. Ozy would like to point out to the authors of manifestos that no one will actually read their manifestos except zir, and they might want to consider posting them to their own blogs.]</em><br /><br /><strong>American Parties</strong><br />Democratic Party: 221, 14.7%<br />Republican Party: 55, 3.7% <br />Libertarian Party: 26, 1.7%<br />Other party: 16, 1.1%<br />No party: 415, 27.6%<br />Non-Americans who really like clicking buttons: 415, 27.6%<br /><strong><br />Voting</strong><br />Yes: 881, 58.6%<br />No: 444, 29.5%<br />My country doesn&rsquo;t hold elections: 5, 0.3%<br /><strong><br />Religion</strong><br />Atheist and not spiritual: 1054, 70.1%<br />Atheist and spiritual: 150, 10.0%<br />Agnostic: 156, 10.4%<br />Lukewarm theist: 44, 2.9%<br />Deist/pantheist/etc.: 22,, 1.5%<br />Committed theist: 60, 4.0%<br /><br /><strong>Religious Denomination</strong><br />Christian (Protestant): 53, 3.5%<br />Mixed/Other: 32, 2.1%<br />Jewish: 31, 2.0%<br />Buddhist: 30, 2.0%<br />Christian (Catholic): 24, 1.6%<br />Unitarian Universalist or similar: 23, 1.5%<br /><br /><em>[Amusing denominations include anti-Molochist, CelestAI, cosmic engineers, Laziness, Thelema, Resimulation Theology, and Pythagorean. The Cultus Deorum Romanorum practitioner still needs to contact Ozy so they can be friends.]</em><br /><br /><strong>Family Religion</strong><br />Atheist and not spiritual: 213, 14.2%<br />Atheist and spiritual: 74, 4.9%<br />Agnostic: 154. 10.2%<br />Lukewarm theist: 541, 36.0%<br />Deist/Pantheist/etc.: 28, 1.9%<br />Committed theist: 388, 25.8%<br /><br /><strong>Religious Background</strong><br />Christian (Protestant): 580, 38.6%<br />Christian (Catholic): 378, 25.1%<br />Jewish: 141, 9.4%<br />Christian (other non-protestant): 88, 5.9%<br />Mixed/Other: 68, 4.5%<br />Unitarian Universalism or similar: 29, 1.9%<br />Christian (Mormon): 28, 1.9%<br />Hindu: 23, 1.5%&rsquo;<br /><br /><strong>Moral Views</strong><br />Accept/lean towards consequentialism: 901, 60.0%<br />Accept/lean towards deontology: 50, 3.3%<br />Accept/lean towards natural law: 48, 3.2%<br />Accept/lean towards virtue ethics: 150, 10.0%<br />Accept/lean towards contractualism: 79, 5.3%<br />Other/no answer: 239, 15.9%<br /><br /><strong>Meta-ethics</strong><br />Constructivism: 474, 31.5%<br />Error theory: 60, 4.0%<br />Non-cognitivism: 129, 8.6%<br />Subjectivism: 324, 21.6%<br />Substantive realism: 209, 13.9%</p>\n<h2><strong>V. Community Participation</strong></h2>\n<p><br /><strong>Less Wrong Use</strong><br />Lurker: 528, 35.1%<br />I&rsquo;ve registered an account: 221, 14.7%<br />I&rsquo;ve posted a comment: 419, 27.9%<br />I&rsquo;ve posted in Discussion: 207, 13.8%<br />I&rsquo;ve posted in Main: 102, 6.8%<br /><br /><strong>Sequences</strong><br />Never knew they existed until this moment: 106, 7.1%<br />Knew they existed, but never looked at them: 42, 2.8%<br />Some, but less than 25%: 270, 18.0%<br />About 25%: 181, 12.0%<br />About 50%: 209, 13.9%<br />About 75%: 242, 16.1%<br />All or almost all: 427, 28.4%<br /><br /><strong>Meetups</strong><br />Yes, regularly: 154, 10.2%<br />Yes, once or a few times: 325, 21.6%<br />No: 989, 65.8%<br /><strong><br />Community</strong><br />Yes, all the time: 112, 7.5%<br />Yes, sometimes: 191, 12.7%<br />No: 1163, 77.4%<br /><br /><strong>Romance</strong><br />Yes: 82, 5.5%<br />I didn&rsquo;t meet them through the community but they&rsquo;re part of the community now: 79, 5.3%<br />No: 1310, 87.2%<br /><br /><strong>CFAR Events</strong><br />Yes, in 2014: 45, 3.0%<br />Yes, in 2013: 60, 4.0%<br />Both: 42, 2.8%<br />No: 1321, 87.9%<br /><br /><strong>CFAR Workshop</strong><br />Yes: 109, 7.3%<br />No: 1311, 87.2%<br /><br /><em>[A couple percent more people answered 'yes' to each of meetups, physical interactions, CFAR attendance, and romance this time around, suggesting the community is very very gradually becoming more IRL. In particular, the number of people meeting romantic partners through the community increased by almost 50% over last year.]</em><br /><br /><strong>HPMOR</strong><br />Yes: 897, 59.7%<br />Started but not finished: 224, 14.9%<br />No: 254, 16.9%<br /><br /><strong>Referrals</strong><br />Referred by a link: 464, 30.9%<br />HPMOR: 385, 25.6%<br />Been here since the Overcoming Bias days: 210, 14.0%<br />Referred by a friend: 199, 13.2%<br />Referred by a search engine: 114, 7.6%<br />Referred by other fiction: 17, 1.1%<br /><br /><em>[Amusing responses include &ldquo;a rationalist that I follow on Tumblr&rdquo;, &ldquo;I&rsquo;m a student of tribal cultishness&rdquo;, and &ldquo;It is difficult to recall details from the Before Time. Things were brighter, simpler, as in childhood or a dream. There has been much growth, change since then. But also loss. I can't remember where I found the link, is what I'm saying.&rdquo;] </em><br /><br /><strong>Blog Referrals</strong><br />Slate Star Codex: 40, 2.6%<br />Reddit: 25, 1.6%<br />Common Sense Atheism: 21, 1.3%<br />Hacker News: 20, 1.3%<br />Gwern: 13, 1.0%</p>\n<h2><strong>VI. Other Categorical Data</strong></h2>\n<p><strong>Cryonics Status</strong><br />Don&rsquo;t understand/never thought about it: 62, 4.1%<br />Don&rsquo;t want to: 361, 24.0%<br />Considering it: 551, 36.7%<br />Haven&rsquo;t gotten around to it: 272, 18.1%<br />Unavailable in my area: 126, 8.4%<br />Yes: 64, 4.3%<br /><br /><strong>Type of Global Catastrophic Risk</strong><br />Asteroid strike: 64, 4.3%<br />Economic/political collapse: 151, 10.0%<br />Environmental collapse: 218, 14.5%<br />Nanotech/grey goo: 47, 3.1%<br />Nuclear war: 239, 15.8%<br />Pandemic (bioengineered): 310, 20.6%<br />Pandemic (natural): 113. 7.5%<br />Unfriendly AI: 244, 16.2%<br /><br /><em>[Amusing answers include ennui/eaten by Internet, Friendly AI, &ldquo;Greens so weaken the rich countries that barbarians conquer us&rdquo;, and Tumblr.]</em><br /><br /><strong>Effective Altruism</strong> <strong>(do you self-identify)</strong><br />Yes: 422, 28.1%<br />No: 758, 50.4%<br /><em><br />[Despite some impressive outreach by the EA community, numbers are largely the same as last year]</em><br /><br /><strong>Effective Altruism (do you participate in community)</strong><br />Yes: 191, 12.7%<br />No: 987, 65.7%<br /><br /><strong>Vegetarian</strong><br />Vegan: 31, 2.1%<br />Vegetarian: 114, 7.6%<br />Other meat restriction: 252, 16.8%<br />Omnivore: 848, 56.4%<br /><strong><br />Paleo Diet</strong><br />Yes: 33, 2.2%<br />Sometimes: 209, 13.9%<br />No: 1111, 73.9%<br /><br /><strong>Food Substitutes</strong><br />Most of my calories: 8. 0.5%<br />Sometimes: 101, 6.7%<br />Tried: 196, 13.0%<br />No: 1052, 70.0%<br /><br /><strong>Gender Default</strong><br />I only identify with my birth gender by default: 681, 45.3%<br />I strongly identify with my birth gender: 586, 39.0%<br /><br /><strong>Books</strong><br />&lt;5: 198, 13.2%<br />5 - 10: 384, 25.5%<br />10 - 20: 328, 21.8%<br />20 - 50: 264, 17.6%<br />50 - 100: 105, 7.0%<br />&gt; 100: 49, 3.3%<br /><br /><strong>Birth Month</strong><br />Jan: 109, 7.3%<br />Feb: 90, 6.0%<br />Mar: 123, 8.2%<br />Apr: 126, 8.4%<br />Jun: 107, 7.1%<br />Jul: 109, 7.3%<br />Aug: 120, 8.0%<br />Sep: 94, 6.3%<br />Oct: 111, 7.4%<br />Nov: 102, 6.8%<br />Dec: 106, 7.1%<br /><br /><em>[Despite my hope of something turning up here, these results don't deviate from chance]</em><br /><br /><strong>Handedness</strong><br />Right: 1170, 77.8%<br />Left: 143, 9.5%<br />Ambidextrous: 37, 2.5%<br />Unsure: 12, 0.8%<br /><br /><strong>Previous Surveys</strong><br />Yes: 757, 50.7%<br />No:&nbsp; 598, 39.8%<br /><br /><strong>Favorite Less Wrong Posts (all &gt; 5 listed)</strong><br />An Alien God: 11<br />Joy In The Merely Real: 7<br />Dissolving Questions About Disease: 7<br />Politics Is The Mind Killer: 6<br />That Alien Message: 6<br />A Fable Of Science And Politics: 6<br />Belief In Belief: 5<br />Generalizing From One Example: 5<br />Schelling Fences On Slippery Slopes: 5<br />Tsuyoku Naritai: 5</p>\n<h2><strong>VII. Numeric Data</strong></h2>\n<p>Age: 27.67 + 8.679 (22, 26, 31) [1490]<br />IQ: 138.25 + 15.936 (130.25, 139, 146) [472]<br />SAT out of 1600: 1470.74 + 113.114 (1410, 1490, 1560) [395]<br />SAT out of 2400: 2210.75 + 188.94 (2140, 2250, 2320) [310]<br />ACT out of 36: 32.56 + 2.483 (31, 33, 35) [244]<br />Time in Community: 2010.97 + 2.174 (2010, 2011, 2013) [1317]<br />Time on LW: 15.73 + 95.75 (2, 5, 15) [1366]<br />Karma Score: 555.73 + 2181.791 (0, 0, 155) [1335]<br /><br />P Many Worlds: 47.64 + 30.132 (20, 50, 75) [1261]<br />P Aliens: 71.52 + 34.364 (50, 90, 99) [1393]<br />P Aliens (Galaxy): 41.2 + 38.405 (2, 30, 80) [1379]<br />P Supernatural: 6.68 + 20.271 (0, 0, 1) [1386]<br />P God: 8.26 + 21.088 (0, 0.01, 3) [1376]<br />P Religion: 4.99 + 18.068 (0, 0, 0.5) [1384]<br />P Cryonics: 22.34 + 27.274 (2, 10, 30) [1399]<br />P Anti-Agathics: 24.63 + 29.569 (1, 10, 40) [1390]<br />P Simulation 24.31 + 28.2 (1, 10, 50) [1320]<br />P Warming 81.73 + 24.224 (80, 90, 98) [1394]<br />P Global Catastrophic Risk 72.14 + 25.620 (55, 80, 90) [1394]<br />Singularity: 2143.44 + 356.643 (2060, 2090, 2150) [1177]<br /><em><br />[The mean for this question is almost entirely dependent on which stupid responses we choose to delete as outliers; the median practically never changes]</em><br /><br />Abortion: 4.38 + 1.032 (4, 5, 5) [1341]<br />Immigration: 4 + 1.078 (3, 4, 5) [1310]<br />Taxes : 3.14 + 1.212 (2, 3, 4) [1410] (from 1 - should be lower to 5 - should be higher)<br />Minimum Wage: 3.21 + 1.359 (2, 3, 4) [1298] (from 1 - should be lower to 5 - should be higher)<br />Feminism: 3.67 + 1.221 (3, 4, 5) [1332]<br />Social Justice: 3.15 + 1.385 (2, 3, 4) [1309]<br />Human Biodiversity: 2.93 + 1.201 (2, 3, 4) [1321]<br />Basic Income: 3.94 + 1.087 (3, 4, 5) [1314]<br />Great Stagnation: 2.33 + .959 (2, 2, 3) [1302]<br />MIRI Mission: 3.90 + 1.062 (3, 4, 5) [1412]<br />MIRI Effectiveness: 3.23 + .897 (3, 3, 4) [1336]<br /><br /><em>[Remember, all of these are asking you to rate your belief in/agreement with the concept on a scale of 1 (bad) to 5 (great)]</em><br /><br />Income: 54129.37 + 66818.904 (10,000, 30,800, 80,000) [923]<br />Charity: 1996.76 + 9492.71 (0, 100, 800) [1009] <br />MIRI/CFAR: 511.61 + 5516.608 (0, 0, 0) [1011]<br />XRisk: 62.50 + 575.260 (0, 0, 0) [980]<br />Older siblings: 0.51 + .914 (0, 0, 1) [1332]<br />Younger siblings: 1.08 + 1.127 (0, 1, 1) [1349]<br />Height: 178.06 + 11.767 (173, 179, 184) [1236]<br />Hours Online: 43.44 + 25.452 (25, 40, 60) [1221]<br />Bem Sex Role Masculinity: 42.54 + 9.670 (36, 42, 49) [1032]<br />Bem Sex Role Femininity: 42.68 + 9.754 (36, 43, 50) [1031]<br />Right Hand: .97 + 0.67 (.94, .97, 1.00)<br />Left Hand: .97 + .048 (.94, .97, 1.00)</p>\n<h2><strong>VIII. Fishing Expedition</strong>s</h2>\n<p><em>[correlations, in descending order]</em><br /><br />SAT Scores out of 1600/SAT Scores out of 2400 .844 (59)<br />P Supernatural/P God .697 (1365)<br />Feminism/Social Justice .671 (1299)<br />P God/P Religion .669 (1367)<br />P Supernatural/P Religion .631 (1372)<br />Charity Donations/MIRI and CFAR Donations .619 (985)<br />P Aliens/P Aliens 2 .607 (1376)<br />Taxes/Minimum Wage .587 (1287)<br />SAT Score out of 2400/ACT Score .575 (89)<br />Age/Number of Children .506 (1480)<br />P Cryonics/P Anti-Agathics .484 (1385)<br />SAT Score out of 1600/ACT Score .480 (81)<br />Minimum Wage/Social Justice .456 (1267)<br />Taxes/Social Justice .427 (1281)<br />Taxes/Feminism .414 (1299)<br />MIRI Mission/MIRI Effectiveness .395 (1331)<br />P Warming/Taxes .385 (1261)<br />Taxes/Basic Income .383 (1285)<br />Minimum Wage/Feminism .378 (1286)<br />P God/Abortion -.378 (1266)<br />Immigration/Feminism .365 (1296)<br />P Supernatural/Abortion -.362 (1276)<br />Feminism/Human Biodiversity -.360 (1306)<br />MIRI and CFAR Donations/Other XRisk Charity Donations .345 (973)<br />Social Justice/Human Biodiversity -.341 (1288)<br />P Religion/Abortion -.326 (1275)<br />P Warming/Minimum Wage .324 (1248)<br />Minimum Wage/Basic Income .312 (1276)<br />P Warming/Basic Income .306 (1260)<br />Immigration/Social Justice .294 (1278)<br />P Anti-Agathics/MIRI Mission .293 (1351)<br />P Warming/Feminism .285 (1281)<br />P Many Worlds/P Anti-Agathics .276 (1245)<br />Social Justice/Femininity .267 (990)<br />Minimum Wage/Human Biodiversity -.264 (1274)<br />Immigration/Human Biodiversity -.263 (1286)<br />P Many Worlds/MIRI Mission .263 (1233)<br />P Aliens/P Warming .262 (1365)<br />P Warming/Social Justice .257 (1262)<br />Taxes/Human Biodiversity -.252 (1291)<br />Social Justice/Basic Income .251 (1281)<br />Feminism/Femininity .250 (1003)<br />Older Siblings/Younger Siblings -.243 (1321)<br />Charity Donations/Other XRisk Charity Donations .240 (957<br />P Anti-Agathics/P Simulation .238 (1312)<br />Abortion/Minimum Wage .229 (1293)<br />Feminism/Basic Income .227 (1297)<br />Abortion/Feminism .226 (1321)<br />P Cryonics/MIRI Mission .223 (1360)<br />Immigration/Basic Income .208 (1279)<br />P Many Worlds/P Cryonics .202 (1251)<br />Number of Current Partners/Femininity: .202 (1029)<br />P Warming/Immigration .202 (1260)<br />P Warming/Abortion .201 (1289)<br />Abortion/Taxes .198 (1304)<br />Age/P Simulation .197 (1313)<br />Political Interest/Masculinity .194 (1011)<br />P Cryonics/MIRI Effectiveness .191 (1285)<br />Abortion/Social Justice .191 (1301)<br />P Simulation/MIRI Mission .188 (1290)<br />P Many Worlds/P Warming .188 (1240)<br />Age/Number of Current Partners .184 (1480)<br />P Anti-Agathics/MIRI Effectiveness .183 (1277)<br />P Many Worlds/P Simulation .181 (1211)<br />Abortion/Immigration .181 (1304)<br />Number of Current Partners/Number of Children .180 (1484)<br />P Cryonics/P Simulation .174 (1315)<br />P Global Catastrophic Risk/MIRI Mission -.174 (1359)<br />Minimum Wage/Femininity .171 (981)<br />Abortion/Basic Income .170 (1302)<br />Age/P Cryonics -.165 (1391)<br />Immigration/Taxes .165 (1293)<br />P Warming/Human Biodiversity -.163 (1271)<br />P Aliens 2/Warming .160 (1353)<br />Abortion/Younger Siblings -.155 (1292)<br />P Religion/Meditate .155 (1189)<br />Feminism/Masculinity -.155 (1004)<br />Immigration/Femininity .155 (988)<br />P Supernatural/Basic Income -.153 (1246)<br />P Supernatural/P Warming -.152 (1361)<br />Number of Current Partners/Karma Score .152 (1332)<br />P Many Worlds/MIRI Effectiveness .152 (1181)<br />Age/MIRI Mission -.150 (1404)<br />P Religion/P Warming -.150 (1358)<br />P Religion/Basic Income -.146 (1245)<br />P God/Basic Income -.146 (1237)<br />Human Biodiversity/Femininity -.145 (999)<br />P God/P Warming -.144 (1351)<br />Taxes/Femininity .142 (987)<br />Number of Children/Younger Siblings .138 (1343)<br />Number of Current Partners/Masculinity: .137 (1030)<br />P Many Worlds/P God -.137 (1232)<br />Age/Charity Donations .133 (1002)<br />P Anti-Agathics/P Global Catastrophic Risk -.132 (1373)<br />P Warming/Masculinity -.132 (992)<br />P Global Catastrophic Risk/MIRI and CFAR Donations -.132 (982)<br />P Supernatural/Singularity .131 (1148)<br />God/Taxes -.130 (1240)<br />Age/P Anti-Agathics -.128 (1382)<br />P Aliens/Taxes .127(1258)<br />Feminism/Great Stagnation -.127 (1287)<br />P Many Worlds/P Supernatural -.127 (1241)<br />P Aliens/Abortion .126 (1284)<br />P Anti-Agathics/Great Stagnation -.126 (1248)<br />P Anti-Agathics/P Warming .125 (1370)<br />Age/P Aliens .124 (1386)<br />P Aliens/Minimum Wage .124 (1245)<br />P Aliens/P Global Catastrophic Risk .122 (1363)<br />Age/MIRI Effectiveness -.122 (1328)<br />Age/P Supernatural .120 (1370)<br />P Supernatural/MIRI Mission -.119 (1345)<br />P Many Worlds/P Religion -.119 (1238)<br />P Religion/MIRI Mission -.118 (1344)<br />Political Interest/Social Justice .118 (1304)<br />P Anti-Agathics/MIRI and CFAR Donations .118 (976)<br />Human Biodiversity/Basic Income -.115 (1262)<br />P Many Worlds/Abortion .115 (1166)<br />Age/Karma Score .114 (1327)<br />P Aliens/Feminism .114 (1277)<br />P Many Worlds/P Global Catastrophic Risk -.114 (1243)<br />Political Interest/Femininity .113 (1010)<br />Number of Children/P Simulation -.112 (1317)<br />P Religion/Younger Siblings .112 (1275)<br />P Supernatural/Taxes -.112 (1248)<br />Age/Masculinity .112 (1027)<br />Political Interest/Taxes .111 (1305)<br />P God/P Simulation .110 (1296)<br />P Many Worlds/Basic Income .110 (1139)<br />P Supernatural/Younger Siblings .109 (1274)<br />P Simulation/Basic Income .109 (1195)<br />Age/P Aliens 2 .107 (1371)<br />MIRI Mission/Basic Income .107 (1279)<br />Age/Great Stagnation .107 (1295)<br />P Many Worlds/P Aliens .107 (1253)<br />Number of Current Partners/Social Justice .106 (1304)<br />Human Biodiversity/Great Stagnation .105 (1285)<br />Number of Children/Abortion -.104 (1337)<br />Number of Current Partners/P Cryonics -.102 (1396)<br />MIRI Mission/Abortion .102 (1305)<br />Immigration/Great Stagnation -.101 (1269)<br />Age/Political Interest .100 (1339)<br />P Global Catastrophic Risk/Political Interest .099 (1295)<br />P Aliens/P Religion -.099 (1357)<br />P God/MIRI Mission -.098 (1335)<br />P Aliens/P Simulation .098 (1308)<br />Number of Current Partners/Immigration .098 (1305)<br />P God/Political Interest .098 (1274)<br />P Warming/P Global Catastrophic Risk .096 (1377)<br /><br />In addition to the Left/Right factor we had last year, this data seems to me to have an Agrees with the Sequences Factor-- the same people tend to believe in many-worlds, cryo, atheism, simulationism, MIRI&rsquo;s mission and effectiveness, anti-agathics, etc. Weirdly, belief in global catastrophic risk is negatively correlated with most of the Agrees with Sequences things. Someone who actually knows how to do statistics should run a factor analysis on this data.</p>\n<h2><strong>IX. Digit Ratios</strong></h2>\n<p>After sanitizing the digit ratio numbers, the following correlations came up:<br /><br />Digit ratio R hand was correlated with masculinity at a level of -0.180 p &lt; 0.01<br />Digit ratio L hand was correlated with masculinity at a level of -0.181 p &lt; 0.01<br />Digit ratio R hand was slightly correlated with femininity at a level of +0.116 p &lt; 0.05<br /><br />Holy #@!$ the feminism thing ACTUALLY HELD UP. There is a 0.144 correlation between right-handed digit ratio and feminism, p &lt; 0.01. And an 0.112 correlation between left-handed digit ratio and feminism, p &lt; 0.05.<br /><br />The only other political position that correlates with digit ratio is immigration. There is a 0.138 correlation between left-handed digit ratio and believe in open borders p &lt; 0.01, and an 0.111 correlation between right-handed digit ratio and belief in open borders, p &lt; 0.05.<br /><br />No digit correlation with abortion, taxes, minimum wage, social justice, human biodiversity, basic income, or great stagnation.<br /><br />Okay, need to rule out that this is all confounded by gender. I ran a few analyses on men and women separately.<br /><br />On men alone, the connection to masculinity holds up. Restricting sample size to men, left-handed digit ratio corresponds to masculinity with at -0.157, p &lt; 0.01. Left handed at -0.134, p &lt; 0.05. Right-handed correlates with femininity at 0.120, p &lt; 0.05. The feminism correlation holds up. Restricting sample size to men, right-handed digit ratio correlates with feminism at a level of 0.149, p &lt; 0.01. Left handed just barely fails to correlate. Both right and left correlate with immigration at 0.135, p &lt; 0.05.<br /><br />On women alone, the Bem masculinity correlation is the highest correlation we're going to get in this entire study. Right hand is -0.433, p &lt; 0.01. Left hand is -0.299, p &lt; 0.05. Femininity trends toward significance but doesn't get there. The feminism correlation trends toward significance but doesn't get there. In general there was too small a sample size of women to pick up anything but the most whopping effects.<br /><br />Since digit ratio is related to testosterone and testosterone sometimes affects risk-taking, I wondered if it would correlate with any of the calibration answers. I selected people who had answered Calibration Question 5 incorrectly and ran an analysis to see if digit ratio was correlated with tendency to be more confident in the incorrect answer. No effect was found.<br /><br />Other things that didn't correlate with digit ratio: IQ, SAT, number of current partners, tendency to work in mathematical professions.<br /><br />...I still can't believe this actually worked. The finger-length/feminism connection ACTUALLY WORKED. What a world. What a world. Someone may want to double-check these results before I get <em>too</em> excited.<br /><strong><br /></strong></p>\n<h2><strong>X. Calibration</strong></h2>\n<p><br />There were ten calibration questions on this year's survey. Along with answers, they were:<br /><br />1. What is the largest bone in the body? Femur<br />2. What state was President Obama born in? Hawaii<br />3. Off the coast of what country was the battle of Trafalgar fought? Spain<br />4. What Norse God was called the All-Father? Odin<br />5. Who won the 1936 Nobel Prize for his work in quantum physics? Heisenberg<br />6. Which planet has the highest density? Earth<br />7. Which Bible character was married to Rachel and Leah? Jacob<br />8. What organelle is called \"the powerhouse of the cell\"? Mitochondria<br />9. What country has the fourth-highest population? Indonesia<br />10. What is the best-selling computer game? Minecraft<br /><br />I ran calibration scores for everybody based on how well they did on the ten calibration questions. These failed to correlate with IQ, SAT, LW karma, or any of the things you might expect to be measures of either intelligence or previous training in calibration; they didn't differ by gender, correlates of community membership, or any mental illness [deleted section about correlating with MWI and MIRI, this was an artifact].<br /><br />Your answers looked like this:<br /><br /><img src=\"http://slatestarcodex.com/Stuff/calibration2014.png\" alt=\"\" width=\"885\" height=\"1671\" /><br /><br />The red line represents perfect calibration. Where answers dip below the line, it means you were overconfident; when they go above, it means you were underconfident.<br /><br />It looks to me like everyone was horrendously underconfident on all the easy questions, and horrendously overconfident on all the hard questions. To give an example of how horrendous, people who were 50% sure of their answers to question 10 got it right only 13% of the time; people who were 100% sure only got it right 44% of the time. Obviously those numbers should be 50% and 100% respectively.<br /><br />This builds upon results from previous surveys in which your calibration was also horrible. This is not a human universal - people who put even a small amount of training into calibration can become very well calibrated very quickly. This is a sign that most Less Wrongers continue to neglect the very basics of rationality and are incapable of judging how much evidence they have on a given issue. Veterans of the site do no better than newbies on this measure.</p>\n<h2><strong>XI. Wrapping Up</strong></h2>\n<p>To show my appreciation for everyone completing this survey, including the arduous digit ratio measurements, I have randomly chosen a person to receive a $30 monetary prize. That person is...the person using the public key \"The World Is Quiet Here\". If that person tells me their private key, I will give them $30.<br /><br />I have removed 73 people who wished to remain private, deleted the Private Keys, and sanitized a very small amount of data. Aside from that, here are the raw survey results for your viewing and analyzing pleasure:<br /><br /><a href=\"http://slatestarcodex.com/Stuff/2014forpublic.xlsx\">(as Excel)</a></p>\n<p><a href=\"http://slatestarcodex.com/Stuff/2014forpublic.sav\">(as SPSS)</a></p>\n<p><a href=\"http://slatestarcodex.com/Stuff/2014forpublic.csv\">(as CSV)</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"kJrjorSx3hXa7q7CJ": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YAkpzvjC768Jm2TYb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 94, "baseScore": 128, "extendedScore": null, "score": 0.000436, "legacy": true, "legacyId": "27844", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 128, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Thanks to everyone who took the 2014 Less Wrong Census/Survey. Extra thanks to Ozy, who did a lot of the number crunching work.</p>\n<p>This year's results are below. Some of them may make more sense in the context of the original survey questions, which <a href=\"https://docs.google.com/forms/d/1h4IisKq7p8CRRVT_UXMSiKW6RE5U5nl1PLT_MvpbX2I/viewform\">can be seen here</a>. Please do not try to take the survey as it is over and your results will not be counted.</p>\n<h2 id=\"I__Population\"><strong>I. Population</strong></h2>\n<p>There were 1503 respondents over 27 days. The last survey got 1636 people over 40 days. The last four full days of the survey saw nineteen, six, and four responses, for an average of about ten. If we assume the next thirteen days had also gotten an average of ten responses - which is generous, since responses tend to trail off with time - then we would have gotten about as many people as the last survey. There is no good evidence here of a decline in population, although it is perhaps compatible with a very small decline.</p>\n<h2 id=\"II__Demographics\"><strong>II. Demographics</strong></h2>\n<p><strong>Sex</strong><br>Female: 179, 11.9%<br>Male: 1311, 87.2%<br><br><strong>Gender</strong><br>F (cisgender): 150, 10.0%<br>F (transgender MtF): 24, 1.6%<br>M (cisgender): 1245, 82.8%<br>M (transgender FtM): 5, 0.3%<br>Other: 64, 4.3%<br><br><strong>Sexual Orientation</strong><br>Asexual: 59, 3.9%<br>Bisexual: 216, 14.4%<br>Heterosexual: 1133, 75.4%<br>Homosexual: 47, 3.1%<br>Other: 35, 2.3%<br><br><em>[This question was poorly worded and should have acknowledged that people can both be asexual and have a specific orientation; as a result it probably vastly undercounted our asexual readers]</em><br><br><strong>Relationship Style</strong><br>Prefer monogamous: 778, 51.8%<br>Prefer polyamorous: 227, 15.1%<br>Uncertain/no preference: 464, 30.9%<br>Other: 23, 1.5%<br><br><strong>Number of Partners</strong><br>0: 738, 49.1%<br>1: 674, 44.8%<br>2: 51, 3.4%<br>3: 17, 1.1%<br>4: 7, 0.5%<br>5: 1, 0.1%<br>Lots and lots: 3, 0.2%<br><br><strong>Relationship Goals</strong><br>Currently not looking for new partners: 648, 43.1%<br>Open to new partners: 467, 31.1%<br>Seeking more partners: 370, 24.6%<br><em><br>[22.2% of people who don\u2019t have a partner aren\u2019t looking for one.]</em><br><br><strong>Relationship Status</strong><br>Married: 274, 18.2%<br>Relationship: 424, 28.2%<br>Single: 788, 52.4%<br><br><em>[6.9% of single people have at least one partner; 1.8% have more than one.]</em><br><br><strong>Living With</strong><br>Alone: 345, 23.0%<br>With parents and/or guardians: 303, 20.2%<br>With partner and/or children: 411, 27.3%<br>With roommates: 428, 28.5%<br><br><strong>Children</strong><br>0: 1317, 81.6%<br>1: 66, 4.4%<br>2: 78, 5.2%<br>3: 17, 1.1%<br>4: 6, 0.4%<br>5: 3, 0.2%<br>6: 1, 0.1%<br>Lots and lots: 1, 0.1%<br><br><strong>Want More Children?</strong><br>Yes: 549, 36.1%<br>Uncertain: 426, 28.3%<br>No: 516, 34.3%<br><br><em>[418 of the people who don\u2019t have children don\u2019t want any, suggesting that the LW community is 27.8% childfree.]</em><br><br><strong>Country</strong><br>United States, 822, 54.7%<br>United Kingdom, 116, 7.7%<br>Canada, 88, 5.9%<br>Australia: 83, 5.5%<br>Germany, 62, 4.1%<br>Russia, 26, 1.7%<br>Finland, 20, 1.3%<br>New Zealand, 20, 1.3%<br>India, 17, 1.1%<br>Brazil: 15, 1.0%<br>France, 15, 1.0%<br>Israel, 15, 1.0%<br><br><strong>Lesswrongers Per Capita</strong><br>Finland: 1/271,950<br>New Zealand: 1/223,550<br>Australia: 1/278,674<br>United States: 1/358,390<br>Canada: 1/399,545<br>Israel: 1/537,266<br>United Kingdom: 1/552,586<br>Germany: 1/1,290,323<br>France: 1/ 4,402,000<br>Russia: 1/ 5,519,231<br>Brazil: 1/ 13,360,000<br>India: 1/ 73,647,058<br><br><strong>Race</strong><br>Asian (East Asian): 59. 3.9%<br>Asian (Indian subcontinent): 33, 2.2%<br>Black: 12. 0.8%<br>Hispanic: 32, 2.1%<br>Middle Eastern: 9, 0.6%<br>Other: 50, 3.3%<br>White (non-Hispanic): 1294, 86.1%<br><br><strong>Work Status</strong><br>Academic (teaching): 86, 5.7%<br>For-profit work: 492, 32.7%<br>Government work: 59, 3.9%<br>Homemaker: 8, 0.5%<br>Independently wealthy: 9, 0.6%<br>Nonprofit work: 58, 3.9%<br>Self-employed: 122, 5.8%<br>Student: 553, 36.8%<br>Unemployed: 103, 6.9%<br><br><strong>Profession</strong><br>Art: 22, 1.5%<br>Biology: 29, 1.9%<br>Business: 35, 4.0%<br>Computers (AI): 42, 2.8%<br>Computers (other academic): 106, 7.1%<br>Computers (practical): 477, 31.7%<br>Engineering: 104, 6.1%<br>Finance/Economics: 71, 4.7%<br>Law: 38, 2.5%<br>Mathematics: 121, 8.1%<br>Medicine: 32, 2.1%<br>Neuroscience: 18, 1.2%<br>Philosophy: 36, 2.4%<br>Physics: 65, 4.3%<br>Psychology: 31, 2.1%<br>Other: 157, 10.2%<br>Other \u201chard science\u201d: 25, 1.7%<br>Other \u201csocial science\u201d: 34, 2.3%<br><br><strong>Degree</strong><br>None: 74, 4.9%<br>High school: 347, 23.1%<br>2 year degree: 64, 4.3%<br>Bachelors: 555, 36.9%<br>Masters: 278, 18.5%<br>JD/MD/other professional degree: 44, 2.9%<br>PhD: 105, 7.0%<br>Other: 24, 1.4%</p>\n<h2 id=\"III__Mental_Illness\"><strong>III. Mental Illness</strong></h2>\n<p>535 answer \u201cno\u201d to all the mental illness questions. Upper bound: 64.4% of the LW population is mentally ill. <br>393 answer \u201cyes\u201d to at least one mental illness question. Lower bound: 26.1% of the LW population is mentally ill. Gosh, we have a lot of self-diagnosers. <br><br><strong>Depression</strong><br>Yes, I was formally diagnosed: 273, 18.2%<br>Yes, I self-diagnosed: 383, 25.5%<br>No: 759, 50.5%<br><br><strong>OCD</strong><br>Yes, I was formally diagnosed: 30, 2.0%<br>Yes, I self-diagnosed: 76, 5.1%<br>No: 1306, 86.9%<br><strong><br>Autism spectrum</strong><br>Yes, I was formally diagnosed: 98, 6.5%<br>Yes, I self-diagnosed: 168, 11.2%<br>No: 1143, 76.0%<br><strong><br>Bipolar</strong><br>Yes, I was formally diagnosed: 33, 2.2%<br>Yes, I self-diagnosed: 49, 3.3%<br>No: 1327, 88.3%<br><br><strong>Anxiety disorder</strong><br>Yes, I was formally diagnosed: 139, 9.2%<br>Yes, I self-diagnosed: 237, 15.8%<br>No: 1033, 68.7%<br><br><strong>BPD</strong><br>Yes, I was formally diagnosed: 5, 0.3%<br>Yes, I self-diagnosed: 19, 1.3%<br>No: 1389, 92.4%<br><br><em>[Ozy says: RATIONALIST BPDERS COME BE MY FRIEND]</em><br><br><strong>Schizophrenia</strong><br>Yes, I was formally diagnosed: 7, 0.5%<br>Yes, I self-diagnosed: 7, 0.5%<br>No: 1397, 92.9%</p>\n<h2 id=\"IV__Politics__Religion__Ethics\"><strong>IV. Politics, Religion, Ethics</strong></h2>\n<p><strong>Politics</strong><br>Communist: 9, 0.6%<br>Conservative: 67, 4.5%<br>Liberal: 416, 27.7%<br>Libertarian: 379, 25.2%<br>Social Democratic: 585, 38.9% <br><br><em>[The big change this year was that we changed \"Socialist\" to \"Social Democratic\". Even though the description stayed the same, about eight points worth of Liberals switched to Social Democrats, apparently more willing to accept that label than \"Socialist\". The overall supergroups Libertarian vs. (Liberal, Social Democratic) vs. Conservative remain mostly unchanged.]</em><br><br><strong>Politics (longform)</strong><br>Anarchist: 40, 2.7%<br>Communist: 9, 0.6%<br>Conservative: 23, 1.9%<br>Futarchist: 41, 2.7%<br>Left-Libertarian: 192, 12.8%<br>Libertarian: 164, 10.9%<br>Moderate: 56, 3.7%<br>Neoreactionary: 29, 1.9%<br>Social Democrat: 162, 10.8%<br>Socialist: 89, 5.9%<br><em><br>[Amusing politics answers include anti-incumbentist, having-well-founded-opinions-is-hard-but-I\u2019ve-come-to-recognize-the-pragmatism-of-socialism-I-don\u2019t-know-ask-me-again-next-year, pirate, progressive social democratic environmental liberal isolationist freedom-fries loving pinko commie piece of shit, republic-ist aka read the federalist papers, romantic reconstructionist, social liberal fiscal agnostic, technoutopian anarchosocialist (with moderate snark), whatever it is that Scott is, and WHY ISN\u2019T THERE AN OPTION FOR NONE SO I CAN SIGNAL MY OBVIOUS OBJECTIVITY WITH MINIMAL EFFORT. Ozy would like to point out to the authors of manifestos that no one will actually read their manifestos except zir, and they might want to consider posting them to their own blogs.]</em><br><br><strong>American Parties</strong><br>Democratic Party: 221, 14.7%<br>Republican Party: 55, 3.7% <br>Libertarian Party: 26, 1.7%<br>Other party: 16, 1.1%<br>No party: 415, 27.6%<br>Non-Americans who really like clicking buttons: 415, 27.6%<br><strong><br>Voting</strong><br>Yes: 881, 58.6%<br>No: 444, 29.5%<br>My country doesn\u2019t hold elections: 5, 0.3%<br><strong><br>Religion</strong><br>Atheist and not spiritual: 1054, 70.1%<br>Atheist and spiritual: 150, 10.0%<br>Agnostic: 156, 10.4%<br>Lukewarm theist: 44, 2.9%<br>Deist/pantheist/etc.: 22,, 1.5%<br>Committed theist: 60, 4.0%<br><br><strong>Religious Denomination</strong><br>Christian (Protestant): 53, 3.5%<br>Mixed/Other: 32, 2.1%<br>Jewish: 31, 2.0%<br>Buddhist: 30, 2.0%<br>Christian (Catholic): 24, 1.6%<br>Unitarian Universalist or similar: 23, 1.5%<br><br><em>[Amusing denominations include anti-Molochist, CelestAI, cosmic engineers, Laziness, Thelema, Resimulation Theology, and Pythagorean. The Cultus Deorum Romanorum practitioner still needs to contact Ozy so they can be friends.]</em><br><br><strong>Family Religion</strong><br>Atheist and not spiritual: 213, 14.2%<br>Atheist and spiritual: 74, 4.9%<br>Agnostic: 154. 10.2%<br>Lukewarm theist: 541, 36.0%<br>Deist/Pantheist/etc.: 28, 1.9%<br>Committed theist: 388, 25.8%<br><br><strong>Religious Background</strong><br>Christian (Protestant): 580, 38.6%<br>Christian (Catholic): 378, 25.1%<br>Jewish: 141, 9.4%<br>Christian (other non-protestant): 88, 5.9%<br>Mixed/Other: 68, 4.5%<br>Unitarian Universalism or similar: 29, 1.9%<br>Christian (Mormon): 28, 1.9%<br>Hindu: 23, 1.5%\u2019<br><br><strong>Moral Views</strong><br>Accept/lean towards consequentialism: 901, 60.0%<br>Accept/lean towards deontology: 50, 3.3%<br>Accept/lean towards natural law: 48, 3.2%<br>Accept/lean towards virtue ethics: 150, 10.0%<br>Accept/lean towards contractualism: 79, 5.3%<br>Other/no answer: 239, 15.9%<br><br><strong>Meta-ethics</strong><br>Constructivism: 474, 31.5%<br>Error theory: 60, 4.0%<br>Non-cognitivism: 129, 8.6%<br>Subjectivism: 324, 21.6%<br>Substantive realism: 209, 13.9%</p>\n<h2 id=\"V__Community_Participation\"><strong>V. Community Participation</strong></h2>\n<p><br><strong>Less Wrong Use</strong><br>Lurker: 528, 35.1%<br>I\u2019ve registered an account: 221, 14.7%<br>I\u2019ve posted a comment: 419, 27.9%<br>I\u2019ve posted in Discussion: 207, 13.8%<br>I\u2019ve posted in Main: 102, 6.8%<br><br><strong>Sequences</strong><br>Never knew they existed until this moment: 106, 7.1%<br>Knew they existed, but never looked at them: 42, 2.8%<br>Some, but less than 25%: 270, 18.0%<br>About 25%: 181, 12.0%<br>About 50%: 209, 13.9%<br>About 75%: 242, 16.1%<br>All or almost all: 427, 28.4%<br><br><strong>Meetups</strong><br>Yes, regularly: 154, 10.2%<br>Yes, once or a few times: 325, 21.6%<br>No: 989, 65.8%<br><strong><br>Community</strong><br>Yes, all the time: 112, 7.5%<br>Yes, sometimes: 191, 12.7%<br>No: 1163, 77.4%<br><br><strong>Romance</strong><br>Yes: 82, 5.5%<br>I didn\u2019t meet them through the community but they\u2019re part of the community now: 79, 5.3%<br>No: 1310, 87.2%<br><br><strong>CFAR Events</strong><br>Yes, in 2014: 45, 3.0%<br>Yes, in 2013: 60, 4.0%<br>Both: 42, 2.8%<br>No: 1321, 87.9%<br><br><strong>CFAR Workshop</strong><br>Yes: 109, 7.3%<br>No: 1311, 87.2%<br><br><em>[A couple percent more people answered 'yes' to each of meetups, physical interactions, CFAR attendance, and romance this time around, suggesting the community is very very gradually becoming more IRL. In particular, the number of people meeting romantic partners through the community increased by almost 50% over last year.]</em><br><br><strong>HPMOR</strong><br>Yes: 897, 59.7%<br>Started but not finished: 224, 14.9%<br>No: 254, 16.9%<br><br><strong>Referrals</strong><br>Referred by a link: 464, 30.9%<br>HPMOR: 385, 25.6%<br>Been here since the Overcoming Bias days: 210, 14.0%<br>Referred by a friend: 199, 13.2%<br>Referred by a search engine: 114, 7.6%<br>Referred by other fiction: 17, 1.1%<br><br><em>[Amusing responses include \u201ca rationalist that I follow on Tumblr\u201d, \u201cI\u2019m a student of tribal cultishness\u201d, and \u201cIt is difficult to recall details from the Before Time. Things were brighter, simpler, as in childhood or a dream. There has been much growth, change since then. But also loss. I can't remember where I found the link, is what I'm saying.\u201d] </em><br><br><strong>Blog Referrals</strong><br>Slate Star Codex: 40, 2.6%<br>Reddit: 25, 1.6%<br>Common Sense Atheism: 21, 1.3%<br>Hacker News: 20, 1.3%<br>Gwern: 13, 1.0%</p>\n<h2 id=\"VI__Other_Categorical_Data\"><strong>VI. Other Categorical Data</strong></h2>\n<p><strong>Cryonics Status</strong><br>Don\u2019t understand/never thought about it: 62, 4.1%<br>Don\u2019t want to: 361, 24.0%<br>Considering it: 551, 36.7%<br>Haven\u2019t gotten around to it: 272, 18.1%<br>Unavailable in my area: 126, 8.4%<br>Yes: 64, 4.3%<br><br><strong>Type of Global Catastrophic Risk</strong><br>Asteroid strike: 64, 4.3%<br>Economic/political collapse: 151, 10.0%<br>Environmental collapse: 218, 14.5%<br>Nanotech/grey goo: 47, 3.1%<br>Nuclear war: 239, 15.8%<br>Pandemic (bioengineered): 310, 20.6%<br>Pandemic (natural): 113. 7.5%<br>Unfriendly AI: 244, 16.2%<br><br><em>[Amusing answers include ennui/eaten by Internet, Friendly AI, \u201cGreens so weaken the rich countries that barbarians conquer us\u201d, and Tumblr.]</em><br><br><strong>Effective Altruism</strong> <strong>(do you self-identify)</strong><br>Yes: 422, 28.1%<br>No: 758, 50.4%<br><em><br>[Despite some impressive outreach by the EA community, numbers are largely the same as last year]</em><br><br><strong>Effective Altruism (do you participate in community)</strong><br>Yes: 191, 12.7%<br>No: 987, 65.7%<br><br><strong>Vegetarian</strong><br>Vegan: 31, 2.1%<br>Vegetarian: 114, 7.6%<br>Other meat restriction: 252, 16.8%<br>Omnivore: 848, 56.4%<br><strong><br>Paleo Diet</strong><br>Yes: 33, 2.2%<br>Sometimes: 209, 13.9%<br>No: 1111, 73.9%<br><br><strong>Food Substitutes</strong><br>Most of my calories: 8. 0.5%<br>Sometimes: 101, 6.7%<br>Tried: 196, 13.0%<br>No: 1052, 70.0%<br><br><strong>Gender Default</strong><br>I only identify with my birth gender by default: 681, 45.3%<br>I strongly identify with my birth gender: 586, 39.0%<br><br><strong>Books</strong><br>&lt;5: 198, 13.2%<br>5 - 10: 384, 25.5%<br>10 - 20: 328, 21.8%<br>20 - 50: 264, 17.6%<br>50 - 100: 105, 7.0%<br>&gt; 100: 49, 3.3%<br><br><strong>Birth Month</strong><br>Jan: 109, 7.3%<br>Feb: 90, 6.0%<br>Mar: 123, 8.2%<br>Apr: 126, 8.4%<br>Jun: 107, 7.1%<br>Jul: 109, 7.3%<br>Aug: 120, 8.0%<br>Sep: 94, 6.3%<br>Oct: 111, 7.4%<br>Nov: 102, 6.8%<br>Dec: 106, 7.1%<br><br><em>[Despite my hope of something turning up here, these results don't deviate from chance]</em><br><br><strong>Handedness</strong><br>Right: 1170, 77.8%<br>Left: 143, 9.5%<br>Ambidextrous: 37, 2.5%<br>Unsure: 12, 0.8%<br><br><strong>Previous Surveys</strong><br>Yes: 757, 50.7%<br>No:&nbsp; 598, 39.8%<br><br><strong>Favorite Less Wrong Posts (all &gt; 5 listed)</strong><br>An Alien God: 11<br>Joy In The Merely Real: 7<br>Dissolving Questions About Disease: 7<br>Politics Is The Mind Killer: 6<br>That Alien Message: 6<br>A Fable Of Science And Politics: 6<br>Belief In Belief: 5<br>Generalizing From One Example: 5<br>Schelling Fences On Slippery Slopes: 5<br>Tsuyoku Naritai: 5</p>\n<h2 id=\"VII__Numeric_Data\"><strong>VII. Numeric Data</strong></h2>\n<p>Age: 27.67 + 8.679 (22, 26, 31) [1490]<br>IQ: 138.25 + 15.936 (130.25, 139, 146) [472]<br>SAT out of 1600: 1470.74 + 113.114 (1410, 1490, 1560) [395]<br>SAT out of 2400: 2210.75 + 188.94 (2140, 2250, 2320) [310]<br>ACT out of 36: 32.56 + 2.483 (31, 33, 35) [244]<br>Time in Community: 2010.97 + 2.174 (2010, 2011, 2013) [1317]<br>Time on LW: 15.73 + 95.75 (2, 5, 15) [1366]<br>Karma Score: 555.73 + 2181.791 (0, 0, 155) [1335]<br><br>P Many Worlds: 47.64 + 30.132 (20, 50, 75) [1261]<br>P Aliens: 71.52 + 34.364 (50, 90, 99) [1393]<br>P Aliens (Galaxy): 41.2 + 38.405 (2, 30, 80) [1379]<br>P Supernatural: 6.68 + 20.271 (0, 0, 1) [1386]<br>P God: 8.26 + 21.088 (0, 0.01, 3) [1376]<br>P Religion: 4.99 + 18.068 (0, 0, 0.5) [1384]<br>P Cryonics: 22.34 + 27.274 (2, 10, 30) [1399]<br>P Anti-Agathics: 24.63 + 29.569 (1, 10, 40) [1390]<br>P Simulation 24.31 + 28.2 (1, 10, 50) [1320]<br>P Warming 81.73 + 24.224 (80, 90, 98) [1394]<br>P Global Catastrophic Risk 72.14 + 25.620 (55, 80, 90) [1394]<br>Singularity: 2143.44 + 356.643 (2060, 2090, 2150) [1177]<br><em><br>[The mean for this question is almost entirely dependent on which stupid responses we choose to delete as outliers; the median practically never changes]</em><br><br>Abortion: 4.38 + 1.032 (4, 5, 5) [1341]<br>Immigration: 4 + 1.078 (3, 4, 5) [1310]<br>Taxes : 3.14 + 1.212 (2, 3, 4) [1410] (from 1 - should be lower to 5 - should be higher)<br>Minimum Wage: 3.21 + 1.359 (2, 3, 4) [1298] (from 1 - should be lower to 5 - should be higher)<br>Feminism: 3.67 + 1.221 (3, 4, 5) [1332]<br>Social Justice: 3.15 + 1.385 (2, 3, 4) [1309]<br>Human Biodiversity: 2.93 + 1.201 (2, 3, 4) [1321]<br>Basic Income: 3.94 + 1.087 (3, 4, 5) [1314]<br>Great Stagnation: 2.33 + .959 (2, 2, 3) [1302]<br>MIRI Mission: 3.90 + 1.062 (3, 4, 5) [1412]<br>MIRI Effectiveness: 3.23 + .897 (3, 3, 4) [1336]<br><br><em>[Remember, all of these are asking you to rate your belief in/agreement with the concept on a scale of 1 (bad) to 5 (great)]</em><br><br>Income: 54129.37 + 66818.904 (10,000, 30,800, 80,000) [923]<br>Charity: 1996.76 + 9492.71 (0, 100, 800) [1009] <br>MIRI/CFAR: 511.61 + 5516.608 (0, 0, 0) [1011]<br>XRisk: 62.50 + 575.260 (0, 0, 0) [980]<br>Older siblings: 0.51 + .914 (0, 0, 1) [1332]<br>Younger siblings: 1.08 + 1.127 (0, 1, 1) [1349]<br>Height: 178.06 + 11.767 (173, 179, 184) [1236]<br>Hours Online: 43.44 + 25.452 (25, 40, 60) [1221]<br>Bem Sex Role Masculinity: 42.54 + 9.670 (36, 42, 49) [1032]<br>Bem Sex Role Femininity: 42.68 + 9.754 (36, 43, 50) [1031]<br>Right Hand: .97 + 0.67 (.94, .97, 1.00)<br>Left Hand: .97 + .048 (.94, .97, 1.00)</p>\n<h2 id=\"VIII__Fishing_Expeditions\"><strong>VIII. Fishing Expedition</strong>s</h2>\n<p><em>[correlations, in descending order]</em><br><br>SAT Scores out of 1600/SAT Scores out of 2400 .844 (59)<br>P Supernatural/P God .697 (1365)<br>Feminism/Social Justice .671 (1299)<br>P God/P Religion .669 (1367)<br>P Supernatural/P Religion .631 (1372)<br>Charity Donations/MIRI and CFAR Donations .619 (985)<br>P Aliens/P Aliens 2 .607 (1376)<br>Taxes/Minimum Wage .587 (1287)<br>SAT Score out of 2400/ACT Score .575 (89)<br>Age/Number of Children .506 (1480)<br>P Cryonics/P Anti-Agathics .484 (1385)<br>SAT Score out of 1600/ACT Score .480 (81)<br>Minimum Wage/Social Justice .456 (1267)<br>Taxes/Social Justice .427 (1281)<br>Taxes/Feminism .414 (1299)<br>MIRI Mission/MIRI Effectiveness .395 (1331)<br>P Warming/Taxes .385 (1261)<br>Taxes/Basic Income .383 (1285)<br>Minimum Wage/Feminism .378 (1286)<br>P God/Abortion -.378 (1266)<br>Immigration/Feminism .365 (1296)<br>P Supernatural/Abortion -.362 (1276)<br>Feminism/Human Biodiversity -.360 (1306)<br>MIRI and CFAR Donations/Other XRisk Charity Donations .345 (973)<br>Social Justice/Human Biodiversity -.341 (1288)<br>P Religion/Abortion -.326 (1275)<br>P Warming/Minimum Wage .324 (1248)<br>Minimum Wage/Basic Income .312 (1276)<br>P Warming/Basic Income .306 (1260)<br>Immigration/Social Justice .294 (1278)<br>P Anti-Agathics/MIRI Mission .293 (1351)<br>P Warming/Feminism .285 (1281)<br>P Many Worlds/P Anti-Agathics .276 (1245)<br>Social Justice/Femininity .267 (990)<br>Minimum Wage/Human Biodiversity -.264 (1274)<br>Immigration/Human Biodiversity -.263 (1286)<br>P Many Worlds/MIRI Mission .263 (1233)<br>P Aliens/P Warming .262 (1365)<br>P Warming/Social Justice .257 (1262)<br>Taxes/Human Biodiversity -.252 (1291)<br>Social Justice/Basic Income .251 (1281)<br>Feminism/Femininity .250 (1003)<br>Older Siblings/Younger Siblings -.243 (1321)<br>Charity Donations/Other XRisk Charity Donations .240 (957<br>P Anti-Agathics/P Simulation .238 (1312)<br>Abortion/Minimum Wage .229 (1293)<br>Feminism/Basic Income .227 (1297)<br>Abortion/Feminism .226 (1321)<br>P Cryonics/MIRI Mission .223 (1360)<br>Immigration/Basic Income .208 (1279)<br>P Many Worlds/P Cryonics .202 (1251)<br>Number of Current Partners/Femininity: .202 (1029)<br>P Warming/Immigration .202 (1260)<br>P Warming/Abortion .201 (1289)<br>Abortion/Taxes .198 (1304)<br>Age/P Simulation .197 (1313)<br>Political Interest/Masculinity .194 (1011)<br>P Cryonics/MIRI Effectiveness .191 (1285)<br>Abortion/Social Justice .191 (1301)<br>P Simulation/MIRI Mission .188 (1290)<br>P Many Worlds/P Warming .188 (1240)<br>Age/Number of Current Partners .184 (1480)<br>P Anti-Agathics/MIRI Effectiveness .183 (1277)<br>P Many Worlds/P Simulation .181 (1211)<br>Abortion/Immigration .181 (1304)<br>Number of Current Partners/Number of Children .180 (1484)<br>P Cryonics/P Simulation .174 (1315)<br>P Global Catastrophic Risk/MIRI Mission -.174 (1359)<br>Minimum Wage/Femininity .171 (981)<br>Abortion/Basic Income .170 (1302)<br>Age/P Cryonics -.165 (1391)<br>Immigration/Taxes .165 (1293)<br>P Warming/Human Biodiversity -.163 (1271)<br>P Aliens 2/Warming .160 (1353)<br>Abortion/Younger Siblings -.155 (1292)<br>P Religion/Meditate .155 (1189)<br>Feminism/Masculinity -.155 (1004)<br>Immigration/Femininity .155 (988)<br>P Supernatural/Basic Income -.153 (1246)<br>P Supernatural/P Warming -.152 (1361)<br>Number of Current Partners/Karma Score .152 (1332)<br>P Many Worlds/MIRI Effectiveness .152 (1181)<br>Age/MIRI Mission -.150 (1404)<br>P Religion/P Warming -.150 (1358)<br>P Religion/Basic Income -.146 (1245)<br>P God/Basic Income -.146 (1237)<br>Human Biodiversity/Femininity -.145 (999)<br>P God/P Warming -.144 (1351)<br>Taxes/Femininity .142 (987)<br>Number of Children/Younger Siblings .138 (1343)<br>Number of Current Partners/Masculinity: .137 (1030)<br>P Many Worlds/P God -.137 (1232)<br>Age/Charity Donations .133 (1002)<br>P Anti-Agathics/P Global Catastrophic Risk -.132 (1373)<br>P Warming/Masculinity -.132 (992)<br>P Global Catastrophic Risk/MIRI and CFAR Donations -.132 (982)<br>P Supernatural/Singularity .131 (1148)<br>God/Taxes -.130 (1240)<br>Age/P Anti-Agathics -.128 (1382)<br>P Aliens/Taxes .127(1258)<br>Feminism/Great Stagnation -.127 (1287)<br>P Many Worlds/P Supernatural -.127 (1241)<br>P Aliens/Abortion .126 (1284)<br>P Anti-Agathics/Great Stagnation -.126 (1248)<br>P Anti-Agathics/P Warming .125 (1370)<br>Age/P Aliens .124 (1386)<br>P Aliens/Minimum Wage .124 (1245)<br>P Aliens/P Global Catastrophic Risk .122 (1363)<br>Age/MIRI Effectiveness -.122 (1328)<br>Age/P Supernatural .120 (1370)<br>P Supernatural/MIRI Mission -.119 (1345)<br>P Many Worlds/P Religion -.119 (1238)<br>P Religion/MIRI Mission -.118 (1344)<br>Political Interest/Social Justice .118 (1304)<br>P Anti-Agathics/MIRI and CFAR Donations .118 (976)<br>Human Biodiversity/Basic Income -.115 (1262)<br>P Many Worlds/Abortion .115 (1166)<br>Age/Karma Score .114 (1327)<br>P Aliens/Feminism .114 (1277)<br>P Many Worlds/P Global Catastrophic Risk -.114 (1243)<br>Political Interest/Femininity .113 (1010)<br>Number of Children/P Simulation -.112 (1317)<br>P Religion/Younger Siblings .112 (1275)<br>P Supernatural/Taxes -.112 (1248)<br>Age/Masculinity .112 (1027)<br>Political Interest/Taxes .111 (1305)<br>P God/P Simulation .110 (1296)<br>P Many Worlds/Basic Income .110 (1139)<br>P Supernatural/Younger Siblings .109 (1274)<br>P Simulation/Basic Income .109 (1195)<br>Age/P Aliens 2 .107 (1371)<br>MIRI Mission/Basic Income .107 (1279)<br>Age/Great Stagnation .107 (1295)<br>P Many Worlds/P Aliens .107 (1253)<br>Number of Current Partners/Social Justice .106 (1304)<br>Human Biodiversity/Great Stagnation .105 (1285)<br>Number of Children/Abortion -.104 (1337)<br>Number of Current Partners/P Cryonics -.102 (1396)<br>MIRI Mission/Abortion .102 (1305)<br>Immigration/Great Stagnation -.101 (1269)<br>Age/Political Interest .100 (1339)<br>P Global Catastrophic Risk/Political Interest .099 (1295)<br>P Aliens/P Religion -.099 (1357)<br>P God/MIRI Mission -.098 (1335)<br>P Aliens/P Simulation .098 (1308)<br>Number of Current Partners/Immigration .098 (1305)<br>P God/Political Interest .098 (1274)<br>P Warming/P Global Catastrophic Risk .096 (1377)<br><br>In addition to the Left/Right factor we had last year, this data seems to me to have an Agrees with the Sequences Factor-- the same people tend to believe in many-worlds, cryo, atheism, simulationism, MIRI\u2019s mission and effectiveness, anti-agathics, etc. Weirdly, belief in global catastrophic risk is negatively correlated with most of the Agrees with Sequences things. Someone who actually knows how to do statistics should run a factor analysis on this data.</p>\n<h2 id=\"IX__Digit_Ratios\"><strong>IX. Digit Ratios</strong></h2>\n<p>After sanitizing the digit ratio numbers, the following correlations came up:<br><br>Digit ratio R hand was correlated with masculinity at a level of -0.180 p &lt; 0.01<br>Digit ratio L hand was correlated with masculinity at a level of -0.181 p &lt; 0.01<br>Digit ratio R hand was slightly correlated with femininity at a level of +0.116 p &lt; 0.05<br><br>Holy #@!$ the feminism thing ACTUALLY HELD UP. There is a 0.144 correlation between right-handed digit ratio and feminism, p &lt; 0.01. And an 0.112 correlation between left-handed digit ratio and feminism, p &lt; 0.05.<br><br>The only other political position that correlates with digit ratio is immigration. There is a 0.138 correlation between left-handed digit ratio and believe in open borders p &lt; 0.01, and an 0.111 correlation between right-handed digit ratio and belief in open borders, p &lt; 0.05.<br><br>No digit correlation with abortion, taxes, minimum wage, social justice, human biodiversity, basic income, or great stagnation.<br><br>Okay, need to rule out that this is all confounded by gender. I ran a few analyses on men and women separately.<br><br>On men alone, the connection to masculinity holds up. Restricting sample size to men, left-handed digit ratio corresponds to masculinity with at -0.157, p &lt; 0.01. Left handed at -0.134, p &lt; 0.05. Right-handed correlates with femininity at 0.120, p &lt; 0.05. The feminism correlation holds up. Restricting sample size to men, right-handed digit ratio correlates with feminism at a level of 0.149, p &lt; 0.01. Left handed just barely fails to correlate. Both right and left correlate with immigration at 0.135, p &lt; 0.05.<br><br>On women alone, the Bem masculinity correlation is the highest correlation we're going to get in this entire study. Right hand is -0.433, p &lt; 0.01. Left hand is -0.299, p &lt; 0.05. Femininity trends toward significance but doesn't get there. The feminism correlation trends toward significance but doesn't get there. In general there was too small a sample size of women to pick up anything but the most whopping effects.<br><br>Since digit ratio is related to testosterone and testosterone sometimes affects risk-taking, I wondered if it would correlate with any of the calibration answers. I selected people who had answered Calibration Question 5 incorrectly and ran an analysis to see if digit ratio was correlated with tendency to be more confident in the incorrect answer. No effect was found.<br><br>Other things that didn't correlate with digit ratio: IQ, SAT, number of current partners, tendency to work in mathematical professions.<br><br>...I still can't believe this actually worked. The finger-length/feminism connection ACTUALLY WORKED. What a world. What a world. Someone may want to double-check these results before I get <em>too</em> excited.<br><strong><br></strong></p>\n<h2 id=\"X__Calibration\"><strong>X. Calibration</strong></h2>\n<p><br>There were ten calibration questions on this year's survey. Along with answers, they were:<br><br>1. What is the largest bone in the body? Femur<br>2. What state was President Obama born in? Hawaii<br>3. Off the coast of what country was the battle of Trafalgar fought? Spain<br>4. What Norse God was called the All-Father? Odin<br>5. Who won the 1936 Nobel Prize for his work in quantum physics? Heisenberg<br>6. Which planet has the highest density? Earth<br>7. Which Bible character was married to Rachel and Leah? Jacob<br>8. What organelle is called \"the powerhouse of the cell\"? Mitochondria<br>9. What country has the fourth-highest population? Indonesia<br>10. What is the best-selling computer game? Minecraft<br><br>I ran calibration scores for everybody based on how well they did on the ten calibration questions. These failed to correlate with IQ, SAT, LW karma, or any of the things you might expect to be measures of either intelligence or previous training in calibration; they didn't differ by gender, correlates of community membership, or any mental illness [deleted section about correlating with MWI and MIRI, this was an artifact].<br><br>Your answers looked like this:<br><br><img src=\"http://slatestarcodex.com/Stuff/calibration2014.png\" alt=\"\" width=\"885\" height=\"1671\"><br><br>The red line represents perfect calibration. Where answers dip below the line, it means you were overconfident; when they go above, it means you were underconfident.<br><br>It looks to me like everyone was horrendously underconfident on all the easy questions, and horrendously overconfident on all the hard questions. To give an example of how horrendous, people who were 50% sure of their answers to question 10 got it right only 13% of the time; people who were 100% sure only got it right 44% of the time. Obviously those numbers should be 50% and 100% respectively.<br><br>This builds upon results from previous surveys in which your calibration was also horrible. This is not a human universal - people who put even a small amount of training into calibration can become very well calibrated very quickly. This is a sign that most Less Wrongers continue to neglect the very basics of rationality and are incapable of judging how much evidence they have on a given issue. Veterans of the site do no better than newbies on this measure.</p>\n<h2 id=\"XI__Wrapping_Up\"><strong>XI. Wrapping Up</strong></h2>\n<p>To show my appreciation for everyone completing this survey, including the arduous digit ratio measurements, I have randomly chosen a person to receive a $30 monetary prize. That person is...the person using the public key \"The World Is Quiet Here\". If that person tells me their private key, I will give them $30.<br><br>I have removed 73 people who wished to remain private, deleted the Private Keys, and sanitized a very small amount of data. Aside from that, here are the raw survey results for your viewing and analyzing pleasure:<br><br><a href=\"http://slatestarcodex.com/Stuff/2014forpublic.xlsx\">(as Excel)</a></p>\n<p><a href=\"http://slatestarcodex.com/Stuff/2014forpublic.sav\">(as SPSS)</a></p>\n<p><a href=\"http://slatestarcodex.com/Stuff/2014forpublic.csv\">(as CSV)</a></p>", "sections": [{"title": "I. Population", "anchor": "I__Population", "level": 1}, {"title": "II. Demographics", "anchor": "II__Demographics", "level": 1}, {"title": "III. Mental Illness", "anchor": "III__Mental_Illness", "level": 1}, {"title": "IV. Politics, Religion, Ethics", "anchor": "IV__Politics__Religion__Ethics", "level": 1}, {"title": "V. Community Participation", "anchor": "V__Community_Participation", "level": 1}, {"title": "VI. Other Categorical Data", "anchor": "VI__Other_Categorical_Data", "level": 1}, {"title": "VII. Numeric Data", "anchor": "VII__Numeric_Data", "level": 1}, {"title": "VIII. Fishing Expeditions", "anchor": "VIII__Fishing_Expeditions", "level": 1}, {"title": "IX. Digit Ratios", "anchor": "IX__Digit_Ratios", "level": 1}, {"title": "X. Calibration", "anchor": "X__Calibration", "level": 1}, {"title": "XI. Wrapping Up", "anchor": "XI__Wrapping_Up", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "283 comments"}], "headingsCount": 13}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 283, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T21:20:25.698Z", "modifiedAt": null, "url": null, "title": "What does being x% on board with the program of a movement mean?", "slug": "what-does-being-x-on-board-with-the-program-of-a-movement", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.754Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Sarunas", "createdAt": "2013-02-01T16:29:24.124Z", "isAdmin": false, "displayName": "Sarunas"}, "userId": "9W5SaiMJkfiQDpY67", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/D7fZ3vTJBGDQPbuqJ/what-does-being-x-on-board-with-the-program-of-a-movement", "pageUrlRelative": "/posts/D7fZ3vTJBGDQPbuqJ/what-does-being-x-on-board-with-the-program-of-a-movement", "linkUrl": "https://www.lesswrong.com/posts/D7fZ3vTJBGDQPbuqJ/what-does-being-x-on-board-with-the-program-of-a-movement", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20does%20being%20x%25%20on%20board%20with%20the%20program%20of%20a%20movement%20mean%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20does%20being%20x%25%20on%20board%20with%20the%20program%20of%20a%20movement%20mean%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD7fZ3vTJBGDQPbuqJ%2Fwhat-does-being-x-on-board-with-the-program-of-a-movement%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20does%20being%20x%25%20on%20board%20with%20the%20program%20of%20a%20movement%20mean%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD7fZ3vTJBGDQPbuqJ%2Fwhat-does-being-x-on-board-with-the-program-of-a-movement", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD7fZ3vTJBGDQPbuqJ%2Fwhat-does-being-x-on-board-with-the-program-of-a-movement", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1246, "htmlBody": "<div id=\"body_t1_btjl\" class=\"comment-content \"><em>(Disclaimer: this is an exploration of possibilities of one simple model. Scott Aaronson's story is merely a starting point, merely a motivating example. This post does not claim to somehow reveal some kind of \"true motivation\" behind people's actions)</em><br /></div>\n<div class=\"comment-content \"><br /></div>\n<div class=\"comment-content \">Recently Scott Aaronson <a href=\"http://www.scottaaronson.com/blog/?p=2091#comment-326664\">stated</a> that he is \"97% on board with the program of feminism\". This post is neither about Scott Aaronson, nor about feminism. It is a post about what does being 97 percent on board even mean. In this particular case it was probably just a figure of speech, I don't think there was anything more than that. But I think the question itself is still interesting. What does \"x% agreeing\" with another person or movement (let's use the word \"movement\" quite loosely even for things that wouldn't be called \"movements\" using everyday language) mean? What does \"mostly agreeing\" mean? This post presents one (not necessarily the only) possible model of what might be behind statements like these. The model is very simple and, <em>if </em>correct, could shed some light onto one particular aspect of how movements might work.<br /></div>\n<div id=\"body_t1_btjl\" class=\"comment-content \">\n<div class=\"md\">\n<p>For the sake of simplicity, in this post I will assume that given a specific concrete question, person<sub>1</sub> either agrees, or disagrees with a person<sub>2</sub>, and, similarly, person<sub>1</sub> either agrees or disagrees with a specific point in a movement's program. Then \"person<sub>1</sub> agreeing with someone about something\" is a function that outputs either 0 or 1. The arguments of this function are (person<sub>1</sub>, person<sub>2</sub>, question/statement) or (person<sub>1</sub>, movement, question/statement). Now, given person<sub>1</sub> and person<sub>2</sub> (or person<sub>1</sub> and movement) one can take a list of questions/statements, and calculate the percentage of agreement for this questionnaire. If a movement has a list of statements (in other words, a list of yes/no questions) \"what this movement is all about\", then we can similarly calculate person<sub>1</sub>'s percentage of agreement with this movement.</p>\n<p>For the sake of simplicity, I am talking specifically about <em>concrete</em> and <em>specific </em>yes/no questions and statements. In this case, very broad statements should be understood as being shorthands for long lists of specific statements (i.e. \"X should always do Y\" should be understood as a shorthand for the list \"X should do Y in a situation<sub>1</sub>\", \"X should do Y in a situation<sub>2</sub>\", etc.).</p>\n<p>The point I am trying to make is this. The length of these lists of questions/statements is usually not very well defined and you can increase the percentage of agreements by stuffing the list with questions and statements with near universal agreement (common sense statements) or you can decrease the percentage of agreement by cutting uncontroversial questions out from the list (\"this is common sense, you don't need a movement for that\"). And when you lengthen or shorten the list of question, various things happen.</p>\n<p>It is my impression that if a person identifies with a movement, then they are likely to see common sense as a part of the program of the movement. The unwritten list of questions and statements is long and it is very easy to get high percentage of agreement. If a person doesn't identify with a movement, they are unlikely to see common sense as a part of \"what this movement is all about\" (they don't think they need movement<sub>1</sub> where common sense is enough). To them, the things movement<sub>1</sub> is all about are the things where the movement<sub>1</sub> <em>differs</em> from common sense or tries to go <em>beyond</em> common sense. In this case, the list of questions is much shorter since uncontroversial common sense questions aren't included in the list.</p>\n<p>For the sake of simplicity, let's assume that you cannot easily drop controversial questions out of the list, as it is beyond the scope of this model.</p>\n<p>If, for some reason, a person wants to see himself/herself as agreeing with a movement, but, at the same time, does not want to change their yes/no answers to specific questions, they may try to lengthen the list by including many \"easy questions\" which are hardly unique to the movement. If a person's views about a movement are unfavourable, then in their minds it is the controversial questions that the movement is all about, in their minds the list is much shorter.</p>\n<p>On the other side of the coin, movements often try to attract new people by lengthening their lists by stuffing them with various slogans and platitutes and claiming that they are very important part to their identity.</p>\n<p>Suppose person A says that he/she 90% agrees with movement<sub>1</sub>, and person B says that he/she 40% percent agrees with it. As you can see, it does not necessarily mean that they must disagree about any given concrete question. It is possible that their respective lists of questions are simply different in length, that is, their opinions whether certain common sense statements belong to the discussion about movement<sub>1</sub> are different.</p>\n<p>However, if you are designing a list for a movement, you cannot add just any question you want to any given list. It is my impression that there must be at least some (real or perceived) disagreement with someone (who is again, real or perceived) about it, otherwise people will not think about that question as a part of your movement. For example, you cannot add support for the law of gravity to the list of things your movement supports and expect that people will actually include this question calculating their percentage of agreements.</p>\n<p>Threats, both real and imaginary, are often helpful for movements, because they enable them to add uncontroversial questions and portray them as controversial, thus making it easier to reach high percentages of agreement with people.</p>\n<p>If a question stops being controversial over the time, it becomes rarely included into the people's lists of questions, which might lead to decreases in their respective percentages of agreement with movement<sub>1</sub>, even if it was movement<sub>1</sub>'s supported position that prevailed and became common sense. In this case, movement<sub>1</sub> may try to talk a lot about the past and emphasize the small remnants (again, both real or imaginary) of dissent. If a movement no longer has positions that haven't dropped out of the list, it probably stops being considered a movement. At the same time, movements (theoretically) try to win and making your position common sense is a victory in some sense.</p>\n<p>It is interesting to think what dynamics this might lead to. It seems that if most movement's positions are becoming common sense, perhaps it has to introduce controversial statements in order to stay a movement. If a movement is too much disagreed with, it may either have to try to distance themselves from controversial questions somehow, or try to stuff their list with a lot of statements that aren't very controversial by trying to emphasize that common sense is part of their identity. Another interesting dynamics might be introduced by geography, where different questions belong to common sense or are controversial in different parts of the world, yet those different parts know about each other.</p>\n<p>To sum up, the lists of questions/statements are not strictly defined. People who identify with a movement (but not necessarily agree with every statement) seem to be likely to think of the list as much longer and contain a lot of common sense statements. People who perceive themselves as outsiders are likely to think that uncontroversial common sense statements do not belong to the list.</p>\n<p><span style=\"color: #888888;\"><em>(feel free to correct mistakes, both grammatical and those related to the content of the post itself, advice on the presentation itself, comments about what was unclear are also appreciated)</em></span></p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "D7fZ3vTJBGDQPbuqJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 3, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "27860", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-05T22:56:54.831Z", "modifiedAt": null, "url": null, "title": "Meetup : Sydney Meetup - January", "slug": "meetup-sydney-meetup-january", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taryneast", "createdAt": "2010-11-29T20:51:06.328Z", "isAdmin": false, "displayName": "taryneast"}, "userId": "xD8wjhiTvwbXdKirW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jwmyeQHqmhM4DFqd9/meetup-sydney-meetup-january", "pageUrlRelative": "/posts/jwmyeQHqmhM4DFqd9/meetup-sydney-meetup-january", "linkUrl": "https://www.lesswrong.com/posts/jwmyeQHqmhM4DFqd9/meetup-sydney-meetup-january", "postedAtFormatted": "Monday, January 5th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Sydney%20Meetup%20-%20January&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Sydney%20Meetup%20-%20January%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwmyeQHqmhM4DFqd9%2Fmeetup-sydney-meetup-january%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Sydney%20Meetup%20-%20January%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwmyeQHqmhM4DFqd9%2Fmeetup-sydney-meetup-january", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwmyeQHqmhM4DFqd9%2Fmeetup-sydney-meetup-january", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18m'>Sydney Meetup - January</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 January 2015 06:30:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">City Of Sydney RSL Club 565 George Street, Sydney, Australia 2000</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Regular location - City of Sydney RSL\nThe restaurant on Level 2</p>\n\n<p>Regular time (starting about 6:30)</p>\n\n<p>Topic: Resolutions!</p>\n\n<p>Description: Do they work? If so - which ones are the best to choose? and how do you stick to them so you actually achieve them?</p>\n\n<p>Bring your resolutions, or come and let us help you figure out some.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18m'>Sydney Meetup - January</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jwmyeQHqmhM4DFqd9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 2.341464129197289e-06, "legacy": true, "legacyId": "27861", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Sydney_Meetup___January\">Discussion article for the meetup : <a href=\"/meetups/18m\">Sydney Meetup - January</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 January 2015 06:30:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">City Of Sydney RSL Club 565 George Street, Sydney, Australia 2000</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Regular location - City of Sydney RSL\nThe restaurant on Level 2</p>\n\n<p>Regular time (starting about 6:30)</p>\n\n<p>Topic: Resolutions!</p>\n\n<p>Description: Do they work? If so - which ones are the best to choose? and how do you stick to them so you actually achieve them?</p>\n\n<p>Bring your resolutions, or come and let us help you figure out some.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Sydney_Meetup___January1\">Discussion article for the meetup : <a href=\"/meetups/18m\">Sydney Meetup - January</a></h2>", "sections": [{"title": "Discussion article for the meetup : Sydney Meetup - January", "anchor": "Discussion_article_for_the_meetup___Sydney_Meetup___January", "level": 1}, {"title": "Discussion article for the meetup : Sydney Meetup - January", "anchor": "Discussion_article_for_the_meetup___Sydney_Meetup___January1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-06T02:34:08.503Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington, D.C.: Meta Meetup", "slug": "meetup-washington-d-c-meta-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TqkfJKNG9wiynHbay/meetup-washington-d-c-meta-meetup", "pageUrlRelative": "/posts/TqkfJKNG9wiynHbay/meetup-washington-d-c-meta-meetup", "linkUrl": "https://www.lesswrong.com/posts/TqkfJKNG9wiynHbay/meetup-washington-d-c-meta-meetup", "postedAtFormatted": "Tuesday, January 6th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%2C%20D.C.%3A%20Meta%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%2C%20D.C.%3A%20Meta%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqkfJKNG9wiynHbay%2Fmeetup-washington-d-c-meta-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%2C%20D.C.%3A%20Meta%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqkfJKNG9wiynHbay%2Fmeetup-washington-d-c-meta-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTqkfJKNG9wiynHbay%2Fmeetup-washington-d-c-meta-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 216, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18n'>Washington, D.C.: Meta Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 January 2015 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>discuss the running of the meetup group - what you like, what you want, and what you'd change.</strong> As usual, we will congregate between 3:00 and 3:30.</p>\n\n<p>The goal of this meetup is twofold: first, to give the de-facto organizers of the group a better understanding of how well we have been serving this community, and second, to help make the group better going forward. We would like the main conversation to be productive towards these ends, but are otherwise open to whatever kind of input people choose to give; as always, people are allowed and encouraged to start side conversations if and when they would prefer.</p>\n\n<p><a href=\"http://wmata.com/rail/trackwork.cfm\" rel=\"nofollow\">According to WMATA</a>, there will be buses replacing trains on the Blue and Yellow lines between Ronald Reagan Washington National Airport and King Street stations. <a href=\"http://verizoncenter.monumentalnetwork.com/events/\" rel=\"nofollow\">The Verizon Center</a> has no scheduled events.</p>\n\n<p><strong>Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 18: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18n'>Washington, D.C.: Meta Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TqkfJKNG9wiynHbay", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 2.3419783101487967e-06, "legacy": true, "legacyId": "27863", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Meta_Meetup\">Discussion article for the meetup : <a href=\"/meetups/18n\">Washington, D.C.: Meta Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 January 2015 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>discuss the running of the meetup group - what you like, what you want, and what you'd change.</strong> As usual, we will congregate between 3:00 and 3:30.</p>\n\n<p>The goal of this meetup is twofold: first, to give the de-facto organizers of the group a better understanding of how well we have been serving this community, and second, to help make the group better going forward. We would like the main conversation to be productive towards these ends, but are otherwise open to whatever kind of input people choose to give; as always, people are allowed and encouraged to start side conversations if and when they would prefer.</p>\n\n<p><a href=\"http://wmata.com/rail/trackwork.cfm\" rel=\"nofollow\">According to WMATA</a>, there will be buses replacing trains on the Blue and Yellow lines between Ronald Reagan Washington National Airport and King Street stations. <a href=\"http://verizoncenter.monumentalnetwork.com/events/\" rel=\"nofollow\">The Verizon Center</a> has no scheduled events.</p>\n\n<p><strong id=\"Upcoming_meetups_\">Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 18: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Meta_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/18n\">Washington, D.C.: Meta Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington, D.C.: Meta Meetup", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Meta_Meetup", "level": 1}, {"title": "Upcoming meetups:", "anchor": "Upcoming_meetups_", "level": 2}, {"title": "Discussion article for the meetup : Washington, D.C.: Meta Meetup", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Meta_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-06T06:44:45.533Z", "modifiedAt": null, "url": null, "title": "Superintelligence 17: Multipolar scenarios", "slug": "superintelligence-17-multipolar-scenarios", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:38.728Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8QgNrNPaoyZeEY4ZD/superintelligence-17-multipolar-scenarios", "pageUrlRelative": "/posts/8QgNrNPaoyZeEY4ZD/superintelligence-17-multipolar-scenarios", "linkUrl": "https://www.lesswrong.com/posts/8QgNrNPaoyZeEY4ZD/superintelligence-17-multipolar-scenarios", "postedAtFormatted": "Tuesday, January 6th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligence%2017%3A%20Multipolar%20scenarios&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligence%2017%3A%20Multipolar%20scenarios%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8QgNrNPaoyZeEY4ZD%2Fsuperintelligence-17-multipolar-scenarios%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligence%2017%3A%20Multipolar%20scenarios%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8QgNrNPaoyZeEY4ZD%2Fsuperintelligence-17-multipolar-scenarios", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8QgNrNPaoyZeEY4ZD%2Fsuperintelligence-17-multipolar-scenarios", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1722, "htmlBody": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr />\n<p>Welcome. This week we discuss the seventeenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Multipolar scenarios</strong></em>. This corresponds to the first part of Chapter 11.</p>\n<p>Apologies for putting this up late. I am traveling, and collecting together the right combination of electricity, wifi, time, space, and permission from an air hostess to take out my computer was more complicated than the usual process.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: &ldquo;Of horses and men&rdquo; from Chapter 11</p>\n<hr />\n<h1>Summary</h1>\n<ol>\n<li><em><strong>'Multipolar scenario'</strong>: a situation where no single agent takes over the world</em></li>\n<li><strong>A multipolar scenario&nbsp;may arise naturally, or intentionally</strong> for reasons of safety. (p159)</li>\n<li>Knowing what would happen in a multipolar scenario involves analyzing an extra kind of information beyond that needed for analyzing singleton scenarios: that about how agents interact (p159)</li>\n<li>In a world characterized by cheap human substitutes, rapidly introduced, in the presence of low regulation, and strong protection of property rights, here are some things that will likely happen: (p160)<ol>\n<li><strong>Human labor will earn wages at around the price of the substitutes</strong> - perhaps below subsistence level for a human. Note that machines have been complements to human labor for some time, raising wages. One should still expect them to become substitutes at some point and reverse this trend.&nbsp;&nbsp;(p160-61)</li>\n<li>Capital (including AI) will earn all of the income, which will be a lot. <strong>Humans who own capital will become very wealthy. Humans who do not own income may be helped</strong> with a small fraction of others' wealth, through charity or redistribution. p161-3)</li>\n<li>If the humans, brain emulations or other AIs receive resources from a common pool when they are born or created, <strong>the population will likely increase until it is constrained by resources</strong>. This is because of selection for entities that tend to reproduce more. (p163-6) This will happen anyway eventually, but AI would make it faster, because reproduction is so much faster for programs than for humans. This outcome can be avoided by offspring receiving resources from their parents' purses.</li>\n</ol></li>\n</ol>\n<h1>Another view</h1>\n<p>Tyler Cowen expresses a different view (<a href=\"http://www.newamerica.net/events/2011/will_robots_steal_your_job\">video</a>, <a href=\"http://www.overcomingbias.com/2011/10/tyler-on-robots.html#more-27952\">some transcript</a>):</p>\n<blockquote>\n<p>The other point I would make is I think smart machines will always be complements and not substitutes, but it will change who they&rsquo;re complementing. So I was very struck by this woman who was a doctor sitting here a moment ago, and I fully believe that her role will not be replaced by machines. But her role didn&rsquo;t sound to me like a doctor. It sounded to me like therapist, friend, persuader, motivational coach, placebo effect, all of which are great things. So the more you have these wealthy patients out there, the patients are in essense the people who work with the smart machines and augment their power, those people will be extremely wealthy. Those people will employ in many ways what you might call personal servants. And because those people are so wealthy, those personal servants will also earn a fair amount.</p>\n<p>So the gains from trade are always there, there&rsquo;s still a law of comparative advantage. I think people who are very good at working with the machines will earn much much more. And the others of us will need to find different kinds of jobs. But again if total output goes up, there&rsquo;s always an optimistic scenario.</p>\n</blockquote>\n<p>Though <a href=\"http://www.overcomingbias.com/2011/10/tyler-on-robots.html#more-27952\">perhaps</a> his view isn't as different as it sounds.</p>\n<h1>Notes</h1>\n<p>1. The small space devoted to multipolar outcomes in Superintelligence probably doesn't reflect a broader consensus that a singleton is more likely or more important. Robin Hanson is perhaps the loudest proponent of the 'multipolar outcomes are more likely' position. e.g. in The <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">Foom Debate</a> and more briefly <a href=\"http://www.overcomingbias.com/2014/07/30855.html\">here</a>. This week is going to be fairly Robin Hanson themed in fact.</p>\n<p>2. Automation can both increase the value produced by a human worker (complementing human labor) and replace the human worker altogether (substituting human labor). Over the long term, it seems complementarity has been been the overall effect. However by the time a machine can do everything a human can do, it is hard to imagine a human earning more than a machine needs to run, i.e. less than they do now. Thus at some point substitution must take over. <a href=\"http://www.technologyreview.com/featuredstory/515926/how-technology-is-destroying-jobs/\">Some think</a> recent unemployment is due in large part to automation. <a href=\"http://www.nytimes.com/2014/08/07/upshot/will-you-lose-your-job-to-a-robot-silicon-valley-is-split.html?src=twr&amp;smid=tw-upshotnyt&amp;_r=0&amp;abt=0002&amp;abg=1\">Some</a> think this time is the beginning of the end, and the jobs will never return to humans. <a href=\"http://www.overcomingbias.com/2014/11/this-time-isnt-different.html\">Others</a> disagree, and are making <a href=\"http://www.overcomingbias.com/2014/12/ai-boom-bet-offer.html\">bets</a>. Eliezer <a href=\"/lw/hh4/the_robots_ai_and_unemployment_antifaq/\">Yudkowsky</a>&nbsp;and <a href=\"http://philosophicaldisquisitions.blogspot.com/2014/08/are-we-heading-for-technological.html\">John Danaher</a> clarify some arguments. Danaher adds a nice diagram:</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9o_0.png?v=fc7e566b1fca964e17366a0fdb88ed3e\" alt=\"\" width=\"600\" /></p>\n<p>3. Various policies have been proposed to resolve poverty from widespread permanent technological unemployment. <a href=\"http://declineofscarcity.com/?p=2790\">Here</a>&nbsp;is a list, though it seems to miss a straightforward one: investing ahead of time in the capital that will become profitable instead of one's own labor, or having policies that encourage such diversification. Not everyone has resources to invest in capital, but it might still help many people. Mentioned&nbsp;<a href=\"http://hanson.gmu.edu/uploads.html\">here</a>&nbsp;and <a href=\"http://www.theatlantic.com/business/archive/2013/01/the-end-of-labor-how-to-protect-workers-from-the-rise-of-robots/267135/\">here</a>:</p>\n<blockquote>\n<p>And then there are more extreme measures. Everyone is born with an endowment of labor; why not also an endowment of capital? What if, when each citizen turns 18, the government bought him or her a diversified portfolio of equity? Of course, some people would want to sell it immediately, cash out, and party, but this could be prevented with some fairly light paternalism, like temporary \"lock-up\" provisions. This portfolio of capital ownership would act as an insurance policy for each human worker; if technological improvements reduced the value of that person's labor, he or she would reap compensating benefits through increased dividends and capital gains. This would essentially be like the kind of socialist land reforms proposed in highly unequal Latin American countries, only redistributing stock instead of land.</p>\n</blockquote>\n<p>4. Even if the income implications of total unemployment are sorted out, some are concerned about the psychological and social consequences. According to <a href=\"http://www.quotationspage.com/quote/2058.html\">Voltaire</a>, 'work saves us from three great evils: boredom, vice and need'. Sometimes people argue that even if our work is economically worthless, we should toil away for our own good, lest the vice and boredom overcome us.</p>\n<p>I find this unlikely, given for instance the ubiquity of more fun and satisfying things to do than most jobs. And while obscolesence and the resulting loss of purpose may be psychologically harmful, I doubt a purposeless job solves that. Also, people already have a variety of satisfying purposes in life other than earning a living. Note also that people in situations like college and lives of luxury seem to do ok on average. I'd guess that unemployed people and some retirees do less well, but this seems more plausibly from losing a previously significant &nbsp;source of purpose and respect, rather than from lack of entertainment and constraint. And in a world where nobody gets respect from bringing home dollars, and other purposes are common, I doubt either of these costs will persist. But this is all speculation.&nbsp;</p>\n<p>On a side note, the kinds of vices that are usually associated with not working tend to be vices of parasitic unproductivity, such as laziness, profligacy, and tendency toward weeklong video game stints. In a world where human labor is worthless, these heuristics for what is virtuous or not might be outdated.</p>\n<p>Nils Nielson <a href=\"/Nils Nielson discusses this issue more.\">discusses</a> this issue more, along with the problem of humans not earning anything.</p>\n<p>5. What happens when selection for expansive tendencies go to space? <a href=\"http://www.fhi.ox.ac.uk/rapacious-hardscrapple-frontier.pdf\">This</a>.</p>\n<p>6. &nbsp;A <a href=\"http://en.wikipedia.org/wiki/Baxter_%28robot%29\">kind</a> of robot that may change some job markets:</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9o_1.png\" alt=\"A kind of robot which may change some job markets.\" width=\"600\" /></p>\n<p>(<a href=\"http://en.wikipedia.org/wiki/Baxter_%28robot%29#mediaviewer/File:Caught_Coding_(9690512888).jpg\">picture</a> by Steve Jurvetson)</p>\n<h1>In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>How likely is one superintelligence, versus many intelligences? What empirical data bears on this question? Bostrom briefly investigated characteristic time lags between large projects for instance, on p80-81.</li>\n<li>Are whole brain emulations likely to come first? This might be best approached by estimating timelines for different technologies&nbsp;(each an ambitious project)&nbsp;and comparing them, or there may be ways to factor out some considerations.</li>\n<li>What are the long term trends in automation replacing workers?</li>\n<li>What else can we know about the effects of automation on employment? (this seems to have a <a href=\"http://scholar.google.com/scholar?q=automation+unemployment&amp;btnG=&amp;hl=en&amp;as_sdt=0%2C5\">fair</a> <a href=\"http://www.secondmachineage.com/\">literature</a>)</li>\n<li>What levels of population growth would be best in the long run, given machine intelligences? (this sounds like an ethics question, but one could also assume some kind of normal human values and investigate the empirical considerations that would make situations better or worse in their details.</li>\n<li>Are there good ways to avoid malthusian outcomes in the kind of scenario discussed in this section, if 'as much as possible' is not the answer to 6?</li>\n<li>What policies might help a society deal with permanent, almost complete unemployment caused by AI progress?</li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1>How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about 'life in an algorithmic economy'. To prepare,&nbsp;<strong>read</strong>&nbsp;the section of that name in Chapter 11<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday January 12. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qHDus5MuMNqQxJbjD": 1, "sYm3HiWcfZvrGu3ui": 1, "tdt83ChxnEgwwKxi6": 1, "bFi5fzkCzBWoQSeiB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8QgNrNPaoyZeEY4ZD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "27564", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr>\n<p>Welcome. This week we discuss the seventeenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Multipolar scenarios</strong></em>. This corresponds to the first part of Chapter 11.</p>\n<p>Apologies for putting this up late. I am traveling, and collecting together the right combination of electricity, wifi, time, space, and permission from an air hostess to take out my computer was more complicated than the usual process.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: \u201cOf horses and men\u201d from Chapter 11</p>\n<hr>\n<h1 id=\"Summary\">Summary</h1>\n<ol>\n<li><em><strong>'Multipolar scenario'</strong>: a situation where no single agent takes over the world</em></li>\n<li><strong>A multipolar scenario&nbsp;may arise naturally, or intentionally</strong> for reasons of safety. (p159)</li>\n<li>Knowing what would happen in a multipolar scenario involves analyzing an extra kind of information beyond that needed for analyzing singleton scenarios: that about how agents interact (p159)</li>\n<li>In a world characterized by cheap human substitutes, rapidly introduced, in the presence of low regulation, and strong protection of property rights, here are some things that will likely happen: (p160)<ol>\n<li><strong>Human labor will earn wages at around the price of the substitutes</strong> - perhaps below subsistence level for a human. Note that machines have been complements to human labor for some time, raising wages. One should still expect them to become substitutes at some point and reverse this trend.&nbsp;&nbsp;(p160-61)</li>\n<li>Capital (including AI) will earn all of the income, which will be a lot. <strong>Humans who own capital will become very wealthy. Humans who do not own income may be helped</strong> with a small fraction of others' wealth, through charity or redistribution. p161-3)</li>\n<li>If the humans, brain emulations or other AIs receive resources from a common pool when they are born or created, <strong>the population will likely increase until it is constrained by resources</strong>. This is because of selection for entities that tend to reproduce more. (p163-6) This will happen anyway eventually, but AI would make it faster, because reproduction is so much faster for programs than for humans. This outcome can be avoided by offspring receiving resources from their parents' purses.</li>\n</ol></li>\n</ol>\n<h1 id=\"Another_view\">Another view</h1>\n<p>Tyler Cowen expresses a different view (<a href=\"http://www.newamerica.net/events/2011/will_robots_steal_your_job\">video</a>, <a href=\"http://www.overcomingbias.com/2011/10/tyler-on-robots.html#more-27952\">some transcript</a>):</p>\n<blockquote>\n<p>The other point I would make is I think smart machines will always be complements and not substitutes, but it will change who they\u2019re complementing. So I was very struck by this woman who was a doctor sitting here a moment ago, and I fully believe that her role will not be replaced by machines. But her role didn\u2019t sound to me like a doctor. It sounded to me like therapist, friend, persuader, motivational coach, placebo effect, all of which are great things. So the more you have these wealthy patients out there, the patients are in essense the people who work with the smart machines and augment their power, those people will be extremely wealthy. Those people will employ in many ways what you might call personal servants. And because those people are so wealthy, those personal servants will also earn a fair amount.</p>\n<p>So the gains from trade are always there, there\u2019s still a law of comparative advantage. I think people who are very good at working with the machines will earn much much more. And the others of us will need to find different kinds of jobs. But again if total output goes up, there\u2019s always an optimistic scenario.</p>\n</blockquote>\n<p>Though <a href=\"http://www.overcomingbias.com/2011/10/tyler-on-robots.html#more-27952\">perhaps</a> his view isn't as different as it sounds.</p>\n<h1 id=\"Notes\">Notes</h1>\n<p>1. The small space devoted to multipolar outcomes in Superintelligence probably doesn't reflect a broader consensus that a singleton is more likely or more important. Robin Hanson is perhaps the loudest proponent of the 'multipolar outcomes are more likely' position. e.g. in The <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">Foom Debate</a> and more briefly <a href=\"http://www.overcomingbias.com/2014/07/30855.html\">here</a>. This week is going to be fairly Robin Hanson themed in fact.</p>\n<p>2. Automation can both increase the value produced by a human worker (complementing human labor) and replace the human worker altogether (substituting human labor). Over the long term, it seems complementarity has been been the overall effect. However by the time a machine can do everything a human can do, it is hard to imagine a human earning more than a machine needs to run, i.e. less than they do now. Thus at some point substitution must take over. <a href=\"http://www.technologyreview.com/featuredstory/515926/how-technology-is-destroying-jobs/\">Some think</a> recent unemployment is due in large part to automation. <a href=\"http://www.nytimes.com/2014/08/07/upshot/will-you-lose-your-job-to-a-robot-silicon-valley-is-split.html?src=twr&amp;smid=tw-upshotnyt&amp;_r=0&amp;abt=0002&amp;abg=1\">Some</a> think this time is the beginning of the end, and the jobs will never return to humans. <a href=\"http://www.overcomingbias.com/2014/11/this-time-isnt-different.html\">Others</a> disagree, and are making <a href=\"http://www.overcomingbias.com/2014/12/ai-boom-bet-offer.html\">bets</a>. Eliezer <a href=\"/lw/hh4/the_robots_ai_and_unemployment_antifaq/\">Yudkowsky</a>&nbsp;and <a href=\"http://philosophicaldisquisitions.blogspot.com/2014/08/are-we-heading-for-technological.html\">John Danaher</a> clarify some arguments. Danaher adds a nice diagram:</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9o_0.png?v=fc7e566b1fca964e17366a0fdb88ed3e\" alt=\"\" width=\"600\"></p>\n<p>3. Various policies have been proposed to resolve poverty from widespread permanent technological unemployment. <a href=\"http://declineofscarcity.com/?p=2790\">Here</a>&nbsp;is a list, though it seems to miss a straightforward one: investing ahead of time in the capital that will become profitable instead of one's own labor, or having policies that encourage such diversification. Not everyone has resources to invest in capital, but it might still help many people. Mentioned&nbsp;<a href=\"http://hanson.gmu.edu/uploads.html\">here</a>&nbsp;and <a href=\"http://www.theatlantic.com/business/archive/2013/01/the-end-of-labor-how-to-protect-workers-from-the-rise-of-robots/267135/\">here</a>:</p>\n<blockquote>\n<p>And then there are more extreme measures. Everyone is born with an endowment of labor; why not also an endowment of capital? What if, when each citizen turns 18, the government bought him or her a diversified portfolio of equity? Of course, some people would want to sell it immediately, cash out, and party, but this could be prevented with some fairly light paternalism, like temporary \"lock-up\" provisions. This portfolio of capital ownership would act as an insurance policy for each human worker; if technological improvements reduced the value of that person's labor, he or she would reap compensating benefits through increased dividends and capital gains. This would essentially be like the kind of socialist land reforms proposed in highly unequal Latin American countries, only redistributing stock instead of land.</p>\n</blockquote>\n<p>4. Even if the income implications of total unemployment are sorted out, some are concerned about the psychological and social consequences. According to <a href=\"http://www.quotationspage.com/quote/2058.html\">Voltaire</a>, 'work saves us from three great evils: boredom, vice and need'. Sometimes people argue that even if our work is economically worthless, we should toil away for our own good, lest the vice and boredom overcome us.</p>\n<p>I find this unlikely, given for instance the ubiquity of more fun and satisfying things to do than most jobs. And while obscolesence and the resulting loss of purpose may be psychologically harmful, I doubt a purposeless job solves that. Also, people already have a variety of satisfying purposes in life other than earning a living. Note also that people in situations like college and lives of luxury seem to do ok on average. I'd guess that unemployed people and some retirees do less well, but this seems more plausibly from losing a previously significant &nbsp;source of purpose and respect, rather than from lack of entertainment and constraint. And in a world where nobody gets respect from bringing home dollars, and other purposes are common, I doubt either of these costs will persist. But this is all speculation.&nbsp;</p>\n<p>On a side note, the kinds of vices that are usually associated with not working tend to be vices of parasitic unproductivity, such as laziness, profligacy, and tendency toward weeklong video game stints. In a world where human labor is worthless, these heuristics for what is virtuous or not might be outdated.</p>\n<p>Nils Nielson <a href=\"/Nils Nielson discusses this issue more.\">discusses</a> this issue more, along with the problem of humans not earning anything.</p>\n<p>5. What happens when selection for expansive tendencies go to space? <a href=\"http://www.fhi.ox.ac.uk/rapacious-hardscrapple-frontier.pdf\">This</a>.</p>\n<p>6. &nbsp;A <a href=\"http://en.wikipedia.org/wiki/Baxter_%28robot%29\">kind</a> of robot that may change some job markets:</p>\n<p><img src=\"http://images.lesswrong.com/t3_l9o_1.png\" alt=\"A kind of robot which may change some job markets.\" width=\"600\"></p>\n<p>(<a href=\"http://en.wikipedia.org/wiki/Baxter_%28robot%29#mediaviewer/File:Caught_Coding_(9690512888).jpg\">picture</a> by Steve Jurvetson)</p>\n<h1 id=\"In_depth_investigations\">In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>How likely is one superintelligence, versus many intelligences? What empirical data bears on this question? Bostrom briefly investigated characteristic time lags between large projects for instance, on p80-81.</li>\n<li>Are whole brain emulations likely to come first? This might be best approached by estimating timelines for different technologies&nbsp;(each an ambitious project)&nbsp;and comparing them, or there may be ways to factor out some considerations.</li>\n<li>What are the long term trends in automation replacing workers?</li>\n<li>What else can we know about the effects of automation on employment? (this seems to have a <a href=\"http://scholar.google.com/scholar?q=automation+unemployment&amp;btnG=&amp;hl=en&amp;as_sdt=0%2C5\">fair</a> <a href=\"http://www.secondmachineage.com/\">literature</a>)</li>\n<li>What levels of population growth would be best in the long run, given machine intelligences? (this sounds like an ethics question, but one could also assume some kind of normal human values and investigate the empirical considerations that would make situations better or worse in their details.</li>\n<li>Are there good ways to avoid malthusian outcomes in the kind of scenario discussed in this section, if 'as much as possible' is not the answer to 6?</li>\n<li>What policies might help a society deal with permanent, almost complete unemployment caused by AI progress?</li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1 id=\"How_to_proceed\">How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about 'life in an algorithmic economy'. To prepare,&nbsp;<strong>read</strong>&nbsp;the section of that name in Chapter 11<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday January 12. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "sections": [{"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Another view", "anchor": "Another_view", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "In-depth investigations", "anchor": "In_depth_investigations", "level": 1}, {"title": "How to proceed", "anchor": "How_to_proceed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "38 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QDmzDZ9CEHrKQdvcn", "ZiRKzx3yv7NyA5rjF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-06T07:49:43.752Z", "modifiedAt": null, "url": null, "title": "Meetup : Sydney Rationality Dojo - How bad statistics can ruin your life", "slug": "meetup-sydney-rationality-dojo-how-bad-statistics-can-ruin", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "luminosity", "createdAt": "2010-05-31T03:00:24.334Z", "isAdmin": false, "displayName": "luminosity"}, "userId": "4SuPdAqJpj7TzsaqG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DAtXoGRXJbZsc4kuq/meetup-sydney-rationality-dojo-how-bad-statistics-can-ruin", "pageUrlRelative": "/posts/DAtXoGRXJbZsc4kuq/meetup-sydney-rationality-dojo-how-bad-statistics-can-ruin", "linkUrl": "https://www.lesswrong.com/posts/DAtXoGRXJbZsc4kuq/meetup-sydney-rationality-dojo-how-bad-statistics-can-ruin", "postedAtFormatted": "Tuesday, January 6th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Sydney%20Rationality%20Dojo%20-%20How%20bad%20statistics%20can%20ruin%20your%20life&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Sydney%20Rationality%20Dojo%20-%20How%20bad%20statistics%20can%20ruin%20your%20life%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDAtXoGRXJbZsc4kuq%2Fmeetup-sydney-rationality-dojo-how-bad-statistics-can-ruin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Sydney%20Rationality%20Dojo%20-%20How%20bad%20statistics%20can%20ruin%20your%20life%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDAtXoGRXJbZsc4kuq%2Fmeetup-sydney-rationality-dojo-how-bad-statistics-can-ruin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDAtXoGRXJbZsc4kuq%2Fmeetup-sydney-rationality-dojo-how-bad-statistics-can-ruin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 81, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18o'>Sydney Rationality Dojo - How bad statistics can ruin your life</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">01 February 2015 04:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Humanist House, 10 Shepherd St Chippendale</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Join us at our February dojo for a session on statistics given by Tim Josling. As per usual, some of us will head off for a group dinner after the session. All are welcome to join.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18o'>Sydney Rationality Dojo - How bad statistics can ruin your life</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DAtXoGRXJbZsc4kuq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3427256653839353e-06, "legacy": true, "legacyId": "27867", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Sydney_Rationality_Dojo___How_bad_statistics_can_ruin_your_life\">Discussion article for the meetup : <a href=\"/meetups/18o\">Sydney Rationality Dojo - How bad statistics can ruin your life</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">01 February 2015 04:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Humanist House, 10 Shepherd St Chippendale</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Join us at our February dojo for a session on statistics given by Tim Josling. As per usual, some of us will head off for a group dinner after the session. All are welcome to join.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Sydney_Rationality_Dojo___How_bad_statistics_can_ruin_your_life1\">Discussion article for the meetup : <a href=\"/meetups/18o\">Sydney Rationality Dojo - How bad statistics can ruin your life</a></h2>", "sections": [{"title": "Discussion article for the meetup : Sydney Rationality Dojo - How bad statistics can ruin your life", "anchor": "Discussion_article_for_the_meetup___Sydney_Rationality_Dojo___How_bad_statistics_can_ruin_your_life", "level": 1}, {"title": "Discussion article for the meetup : Sydney Rationality Dojo - How bad statistics can ruin your life", "anchor": "Discussion_article_for_the_meetup___Sydney_Rationality_Dojo___How_bad_statistics_can_ruin_your_life1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-06T10:11:15.242Z", "modifiedAt": null, "url": null, "title": "Low Hanging fruit for buying a better life", "slug": "low-hanging-fruit-for-buying-a-better-life", "viewCount": null, "lastCommentedAt": "2022-01-15T15:53:10.366Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taryneast", "createdAt": "2010-11-29T20:51:06.328Z", "isAdmin": false, "displayName": "taryneast"}, "userId": "xD8wjhiTvwbXdKirW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CYDSRKEJruoKgdBXa/low-hanging-fruit-for-buying-a-better-life", "pageUrlRelative": "/posts/CYDSRKEJruoKgdBXa/low-hanging-fruit-for-buying-a-better-life", "linkUrl": "https://www.lesswrong.com/posts/CYDSRKEJruoKgdBXa/low-hanging-fruit-for-buying-a-better-life", "postedAtFormatted": "Tuesday, January 6th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Low%20Hanging%20fruit%20for%20buying%20a%20better%20life&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALow%20Hanging%20fruit%20for%20buying%20a%20better%20life%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCYDSRKEJruoKgdBXa%2Flow-hanging-fruit-for-buying-a-better-life%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Low%20Hanging%20fruit%20for%20buying%20a%20better%20life%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCYDSRKEJruoKgdBXa%2Flow-hanging-fruit-for-buying-a-better-life", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCYDSRKEJruoKgdBXa%2Flow-hanging-fruit-for-buying-a-better-life", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 415, "htmlBody": "<p>What can I purchase with $100 that will be the best thing I can buy to make my life better?</p>\n<p>&nbsp;</p>\n<p>I've decided to budget some regular money to improving my life each month. I'd like to start with low hanging fruit for obvious reasons - but when I sat down to think of improvements, I found myself thinking of the same old things I'd already been planning to do anyway... and I'd like out of that rut.<br /><br /><strong>Constraints/more info:</strong></p>\n<p>&nbsp;</p>\n<ol>\n<li>be concrete. I know - \"spend money on experiences\" is a good idea - but what experiences are the best option to purchase *first*</li>\n<li>\"better\" is deliberately left vague - choose how you would define it, so that I'm not constrained just by ways of \"being better\" that I'd have thought of myself.</li>\n<li>please assume that I have all my basic needs met (eg food, clothing, shelter) and that I have budgeted separately for things like investing for my financial future and for charity.</li>\n<li>apart from the above, assume nothing&nbsp;- Especially don't try and tailor solutions to anything you might know and/or guess about me specifically,&nbsp;because I think this would be a useful resource for others who might have just begun.</li>\n<li>don't constrain yourself to exactly $100 - I could buy 2-3 things for that, or I could save up over a couple of months and buy something more expensive... I picked $100 because it's a round number and easy to imagine.</li>\n<li>it's ok to add \"dumb\" things - they can help spur great ideas, or just get rid of an elephant in the room.</li>\n<li>try thinking of your top-ten before reading any comments, in order not to bias your initial thinking. Then come back and add ten more once you've been inspired by what everyone else came up with.</li>\n</ol>\n<p>&nbsp;</p>\n<p><strong>Background:</strong></p>\n<p>This is a question I recently posed to my local Less Wrong group and we came up with a few good ideas, so I thought I'd share the discussion with the wider community and see what we can come up with. I'll add the list we came up with later on in the comments...</p>\n<p>It'd be great to have a repository of low-hanging fruit for things that can be solved with (relatively affordable) amounts of money. I'd personally like to go through the list - look at candidates that sound like they'd be really useful to me and then make a prioritised list of what to work on first.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Tg9aFPFCPBHxGABRr": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CYDSRKEJruoKgdBXa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 35, "extendedScore": null, "score": 0.000109, "legacy": true, "legacyId": "27868", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 35, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 209, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-06T13:39:38.289Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels - Mindfulness and mental habits", "slug": "meetup-brussels-mindfulness-and-mental-habits", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Roxolan", "createdAt": "2011-10-23T19:06:17.298Z", "isAdmin": false, "displayName": "Roxolan"}, "userId": "jXG7tMhkQMNpCCXPN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wyGdcwbnHGjLdwGK8/meetup-brussels-mindfulness-and-mental-habits", "pageUrlRelative": "/posts/wyGdcwbnHGjLdwGK8/meetup-brussels-mindfulness-and-mental-habits", "linkUrl": "https://www.lesswrong.com/posts/wyGdcwbnHGjLdwGK8/meetup-brussels-mindfulness-and-mental-habits", "postedAtFormatted": "Tuesday, January 6th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20-%20Mindfulness%20and%20mental%20habits&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20-%20Mindfulness%20and%20mental%20habits%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwyGdcwbnHGjLdwGK8%2Fmeetup-brussels-mindfulness-and-mental-habits%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20-%20Mindfulness%20and%20mental%20habits%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwyGdcwbnHGjLdwGK8%2Fmeetup-brussels-mindfulness-and-mental-habits", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwyGdcwbnHGjLdwGK8%2Fmeetup-brussels-mindfulness-and-mental-habits", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 223, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18p'>Brussels - Mindfulness and mental habits</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 January 2015 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong has been a bit quiet of late, partly because some of its best would-be contributors have focused on their own blogs. (This doesn't bode well for the long-term health of the site, but I'm not <em>quite</em> ready to rename this group <a href=\"http://slatestarcodex.com/\" rel=\"nofollow\">SlateStarCodex Brussels</a>.)</p>\n\n<p>Among the most interesting off-site developments is sort of a generalization of the ideas discussed in <a href=\"http://lesswrong.com/lw/21b/ugh_fields/\">Ugh Fields</a> and <a href=\"http://lesswrong.com/lw/if/your_strength_as_a_rationalist/\">Noticing Confusion</a>: an ongoing conversation on mindfulness and trainable mental habits. Most of it is on Brienne Strohl's <a href=\"http://agentyduck.blogspot.be/\" rel=\"nofollow\">Agenty Duck</a> (though there's a good deal of less link-able spillover on Facebook), and brand-new <a href=\"http://themindsui.com/\" rel=\"nofollow\">The Mind&#39;s UI</a> should be all about it.</p>\n\n<p>It's the month of new year's resolutions, as good a time as any to discuss such concrete self-improvement techniques.</p>\n\n<hr />\n\n<p>We will meet at 1 pm at \"La Fleur en papier dor\u00e9, close to the Brussels Central station. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform\" rel=\"nofollow\">this one minute form</a> to share your contact information.</p>\n\n<p>The Brussels meetup group communicates through a <a href=\"https://groups.google.com/forum/#!forum/lesswrong-brussels\">Google Group</a>.</p>\n\n<p>Meetup announcements are also mirrored on <a href=\"http://www.meetup.com/LWBrussels/\" rel=\"nofollow\">meetup.com</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18p'>Brussels - Mindfulness and mental habits</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wyGdcwbnHGjLdwGK8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3435547922374795e-06, "legacy": true, "legacyId": "27869", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels___Mindfulness_and_mental_habits\">Discussion article for the meetup : <a href=\"/meetups/18p\">Brussels - Mindfulness and mental habits</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 January 2015 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong has been a bit quiet of late, partly because some of its best would-be contributors have focused on their own blogs. (This doesn't bode well for the long-term health of the site, but I'm not <em>quite</em> ready to rename this group <a href=\"http://slatestarcodex.com/\" rel=\"nofollow\">SlateStarCodex Brussels</a>.)</p>\n\n<p>Among the most interesting off-site developments is sort of a generalization of the ideas discussed in <a href=\"http://lesswrong.com/lw/21b/ugh_fields/\">Ugh Fields</a> and <a href=\"http://lesswrong.com/lw/if/your_strength_as_a_rationalist/\">Noticing Confusion</a>: an ongoing conversation on mindfulness and trainable mental habits. Most of it is on Brienne Strohl's <a href=\"http://agentyduck.blogspot.be/\" rel=\"nofollow\">Agenty Duck</a> (though there's a good deal of less link-able spillover on Facebook), and brand-new <a href=\"http://themindsui.com/\" rel=\"nofollow\">The Mind's UI</a> should be all about it.</p>\n\n<p>It's the month of new year's resolutions, as good a time as any to discuss such concrete self-improvement techniques.</p>\n\n<hr>\n\n<p>We will meet at 1 pm at \"La Fleur en papier dor\u00e9, close to the Brussels Central station. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform\" rel=\"nofollow\">this one minute form</a> to share your contact information.</p>\n\n<p>The Brussels meetup group communicates through a <a href=\"https://groups.google.com/forum/#!forum/lesswrong-brussels\">Google Group</a>.</p>\n\n<p>Meetup announcements are also mirrored on <a href=\"http://www.meetup.com/LWBrussels/\" rel=\"nofollow\">meetup.com</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels___Mindfulness_and_mental_habits1\">Discussion article for the meetup : <a href=\"/meetups/18p\">Brussels - Mindfulness and mental habits</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels - Mindfulness and mental habits", "anchor": "Discussion_article_for_the_meetup___Brussels___Mindfulness_and_mental_habits", "level": 1}, {"title": "Discussion article for the meetup : Brussels - Mindfulness and mental habits", "anchor": "Discussion_article_for_the_meetup___Brussels___Mindfulness_and_mental_habits1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EFQ3F6kmt4WHXRqik", "5JDkW4MYXit2CquLs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-06T19:35:44.500Z", "modifiedAt": null, "url": null, "title": "Exams and Overfitting", "slug": "exams-and-overfitting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:09.245Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "robot-dreams", "createdAt": "2014-08-12T23:23:33.596Z", "isAdmin": false, "displayName": "robot-dreams"}, "userId": "6z6xB35aPvA4dWTht", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nmnMuKLwxzKFguBwm/exams-and-overfitting", "pageUrlRelative": "/posts/nmnMuKLwxzKFguBwm/exams-and-overfitting", "linkUrl": "https://www.lesswrong.com/posts/nmnMuKLwxzKFguBwm/exams-and-overfitting", "postedAtFormatted": "Tuesday, January 6th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Exams%20and%20Overfitting&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExams%20and%20Overfitting%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnmnMuKLwxzKFguBwm%2Fexams-and-overfitting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Exams%20and%20Overfitting%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnmnMuKLwxzKFguBwm%2Fexams-and-overfitting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnmnMuKLwxzKFguBwm%2Fexams-and-overfitting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 497, "htmlBody": "<p>When I hear something like <em>\"What's going to be on the exam?\"</em>, part of me gets indignant. &nbsp;WHAT?!?! &nbsp;You're defeating the whole point of the exam! &nbsp;You're committing the Deadly Sin of Overfitting!</p>\n<p>Let me step back and explain my view of exams.</p>\n<p>When I take a class, my goal is to learn the material. &nbsp;Exams are a way to answer the question, \"How well did I learn the material?\"[1]. &nbsp;But exams are only a few hours long, so it's unfeasible to have questions on all of the material. &nbsp;To deal with this time constraint, an exam takes a random sample of the material and gives me a \"statistical\" rather than \"perfect\" answer to the question, \"How well did I learn the material?\"</p>\n<p>If I know in advance what topics will be covered on the exam, and if I then prepare for the exam by learning only those topics, then <em>I am screwing up this whole process</em>. &nbsp;By doing very well on the exam, I get the information, <em>\"Congratulations! &nbsp;You learned the material covered on the exam very well.\"</em> &nbsp;But who knows how well I learned the material covered in class as a whole? &nbsp;This is a textbook case of <a href=\"https://en.wikipedia.org/wiki/Overfitting\">overfitting</a>.</p>\n<p>To be clear, I don't necessarily lose respect for someone who asks,&nbsp;<em>\"What's going to be on the exam?\"</em>. &nbsp;I understand that different people have different priorities[2], and that's fine by me. &nbsp;But if you're taking a class because you truly want to learn the material, in spite of any sacrifices that you might have to make to do so[3], then I'd like to encourage you not to \"study for the test\". &nbsp;I'd like to encourage you not to overfit.</p>\n<hr />\n<p>[1] When I say \"learned\", I mean in the \"<a href=\"http://v.cx/2010/04/feynman-brazil-education\">Feynman</a>\" sense, not in the \"<a href=\"/lw/iq/guessing_the_teachers_password/\">teacher's password</a>\" sense. &nbsp;I believe that a necessary (but not sufficient) condition for an exam to check for this kind of learning is to have problems that I've never seen before.</p>\n<p>[2] Someone might care much more about getting into medical school than, say, mastering classical mechanics. &nbsp;I respect that choice, and I acknowledge that someone might be in a system where getting a good grade in physics is required for getting into medical school, even though mastering classical mechanics isn't required for becoming a good doctor.</p>\n<p>[3] There were a few terms when I felt like I did a really good job of learning the material (conveniently, I also got really good grades during these terms). &nbsp;But for these terms, one (or both) of the following would happen:</p>\n<ul>\n<li>I would take a huge hit in social status, because I was taking barely more than the minimum courseload. &nbsp;At my university, there was a lot of social pressure to always take the maximum courseload (or petition to exceed the maximum courseload), and still participate in lots of extracurricular activities.</li>\n<li>My girlfriend at the time would break up with me because of all the time I was spending on my coursework (and not with her).</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nmnMuKLwxzKFguBwm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 17, "extendedScore": null, "score": 2.3443991306890206e-06, "legacy": true, "legacyId": "27870", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NMoLJuDJEms7Ku9XS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-07T05:06:27.945Z", "modifiedAt": null, "url": null, "title": "Some recent evidence against the Big Bang", "slug": "some-recent-evidence-against-the-big-bang", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:29.791Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JStewart", "createdAt": "2010-04-16T21:15:09.022Z", "isAdmin": false, "displayName": "JStewart"}, "userId": "TGgfDK2oDZDMfdtHM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v3WYkZSwn2ZxoqAXn/some-recent-evidence-against-the-big-bang", "pageUrlRelative": "/posts/v3WYkZSwn2ZxoqAXn/some-recent-evidence-against-the-big-bang", "linkUrl": "https://www.lesswrong.com/posts/v3WYkZSwn2ZxoqAXn/some-recent-evidence-against-the-big-bang", "postedAtFormatted": "Wednesday, January 7th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20recent%20evidence%20against%20the%20Big%20Bang&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20recent%20evidence%20against%20the%20Big%20Bang%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv3WYkZSwn2ZxoqAXn%2Fsome-recent-evidence-against-the-big-bang%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20recent%20evidence%20against%20the%20Big%20Bang%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv3WYkZSwn2ZxoqAXn%2Fsome-recent-evidence-against-the-big-bang", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv3WYkZSwn2ZxoqAXn%2Fsome-recent-evidence-against-the-big-bang", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 978, "htmlBody": "<div id=\"body_t1_bts8\" class=\"comment-content \">\n<div class=\"md\">\n<p>I am submitting this on behalf of MazeHatter, who originally posted it <a href=\"/r/discussion/lw/lht/open_thread_jan_511_2015/bts8\">here</a> in the most recent open tread. Go there to upvote if you like this submission.</p>\n<p>Begin MazeHatter:</p>\n<p>I grew up thinking that the Big Bang was the beginning of it all. In 2013 and 2014 a good number of observations have thrown some of our basic assumptions about the theory into question. There were anomalies observed in the CMB, previously ignored, now confirmed by Planck:</p>\n<blockquote>\n<p>Another is an asymmetry in the average temperatures on opposite hemispheres of the sky. This runs counter to the prediction made by the standard model that the Universe should be broadly similar in any direction we look.</p>\n<p>Furthermore, a cold spot extends over a patch of sky that is much larger than expected.</p>\n<p>The asymmetry and the cold spot had already been hinted at with Planck&rsquo;s predecessor, NASA&rsquo;s WMAP mission, but were largely ignored because of lingering doubts about their cosmic origin.</p>\n<p>&ldquo;The fact that Planck has made such a significant detection of these anomalies erases any doubts about their reality; it can no longer be said that they are artefacts of the measurements. They are real and we have to look for a credible explanation,&rdquo; says Paolo Natoli of the University of Ferrara, Italy.</p>\n<p>... One way to explain the anomalies is to propose that the Universe is in fact not the same in all directions on a larger scale than we can observe. ...</p>\n<p>&ldquo;Our ultimate goal would be to construct a new model that predicts the anomalies and links them together. But these are early days; so far, we don&rsquo;t know whether this is possible and what type of new physics might be needed. And that&rsquo;s exciting,&rdquo; says Professor Efstathiou.</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://www.esa.int/Our_Activities/Space_Science/Planck/Planck_reveals_an_almost_perfect_Universe\">http://www.esa.int/Our_Activities/Space_Science/Planck/Planck_reveals_an_almost_perfect_Universe</a></p>\n<p>We are also getting a better look at galaxies at greater distances, thinking they would all be young galaxies, and finding they are not:</p>\n<blockquote>\n<p>The finding raises new questions about how these galaxies formed so rapidly and why they stopped forming stars so early. It is an enigma that these galaxies seem to come out of nowhere.</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://carnegiescience.edu/news/some_galaxies_early_universe_grew_quickly\">http://carnegiescience.edu/news/some_galaxies_early_universe_grew_quickly</a></p>\n<p><a rel=\"nofollow\" href=\"http://mq.edu.au/newsroom/2014/03/11/granny-galaxies-discovered-in-the-early-universe/\">http://mq.edu.au/newsroom/2014/03/11/granny-galaxies-discovered-in-the-early-universe/</a></p>\n<blockquote>\n<p>The newly classified galaxies are striking in that they look a lot like those in today's universe, with disks, bars and spiral arms. But theorists predict that these should have taken another 2 billion years to begin to form, so things seem to have been settling down a lot earlier than expected.</p>\n</blockquote>\n<p>B. D. Simmons et al. Galaxy Zoo: CANDELS Barred Disks and Bar Fractions. Monthly Notices of the Royal Astronomical Society, 2014 DOI: 10.1093/mnras/stu1817</p>\n<p><a rel=\"nofollow\" href=\"http://www.sciencedaily.com/releases/2014/10/141030101241.htm\">http://www.sciencedaily.com/releases/2014/10/141030101241.htm</a></p>\n<blockquote>\n<p>The findings cast doubt on current models of galaxy formation, which struggle to explain how these remote and young galaxies grew so big so fast.</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://www.nasa.gov/jpl/spitzer/splash-project-dives-deep-for-galaxies/#.VBxS4o938jg\">http://www.nasa.gov/jpl/spitzer/splash-project-dives-deep-for-galaxies/#.VBxS4o938jg</a></p>\n<p>Although it seems we don't have to look so far away to find evidence that galaxy formation is inconsistent with the Big Bang timeline.</p>\n<blockquote>\n<p>If the modern galaxy formation theory were right, these dwarf galaxies simply wouldn't exist.</p>\n<p>Merrick and study lead Marcel Pawlowski consider themselves part of a small-but-growing group of experts questioning the wisdom of current astronomical models.</p>\n<p>\"When you have a clear contradiction like this, you ought to focus on it,\" Merritt said. \"This is how progress in science is made.\"</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://www.natureworldnews.com/articles/7528/20140611/galaxy-formation-theories-undermined-dwarf-galaxies.htm\">http://www.natureworldnews.com/articles/7528/20140611/galaxy-formation-theories-undermined-dwarf-galaxies.htm</a></p>\n<p><a rel=\"nofollow\" href=\"http://arxiv.org/abs/1406.1799\">http://arxiv.org/abs/1406.1799</a></p>\n<p>Another observation is that lithium abundances are way too low for the theory in other places, not just here:</p>\n<blockquote>\n<p>A star cluster some 80,000 light-years from Earth looks mysteriously deficient in the element lithium, just like nearby stars, astronomers reported on Wednesday.</p>\n<p>That curious deficiency suggests that astrophysicists either don't fully understand the big bang, they suggest, or else don't fully understand the way that stars work.</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://news.nationalgeographic.com/news/2014/09/140910-space-lithium-m54-star-cluster-science/\">http://news.nationalgeographic.com/news/2014/09/140910-space-lithium-m54-star-cluster-science/</a></p>\n<p>It also seems there is larger scale structure continually being discovered larger than the Big Bang is thought to account for:</p>\n<blockquote>\n<p>\"The first odd thing we noticed was that some of the quasars' rotation axes were aligned with each other -- despite the fact that these quasars are separated by billions of light-years,\" said Hutsem&eacute;kers. The team then went further and looked to see if the rotation axes were linked, not just to each other, but also to the structure of the Universe on large scales at that time.</p>\n<p>\"The alignments in the new data, on scales even bigger than current predictions from simulations, may be a hint that there is a missing ingredient in our current models of the cosmos,\" concludes Dominique Sluse.</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://www.sciencedaily.com/releases/2014/11/141119084506.htm\">http://www.sciencedaily.com/releases/2014/11/141119084506.htm</a></p>\n<p>D. Hutsem&eacute;kers, L. Braibant, V. Pelgrims, D. Sluse. Alignment of quasar polarizations with large-scale structures. Astronomy &amp; Astrophysics, 2014</p>\n<blockquote>\n<p>Dr Clowes said: \"While it is difficult to fathom the scale of this LQG, we can say quite definitely it is the largest structure ever seen in the entire universe. This is hugely exciting -- not least because it runs counter to our current understanding of the scale of the universe.</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://www.sciencedaily.com/releases/2013/01/130111092539.htm\">http://www.sciencedaily.com/releases/2013/01/130111092539.htm</a></p>\n<p>These observations have been made just recently. It seems that in the 1980's, when I was first introduced to the Big Bang as a child, the experts in the field knew then there were problems with it, and devised inflation as a solution. And today, the validity of that solution is being called into question by those same experts:</p>\n<blockquote>\n<p>In light of these arguments, the oft-cited claim that cosmological data have verified the central predictions of inflationary theory is misleading, at best. What one can say is that data have confirmed predictions of the naive inflationary theory as we understood it before 1983, but this theory is not inflationary cosmology as understood today. The naive theory supposes that inflation leads to a predictable outcome governed by the laws of classical physics. The truth is that quantum physics rules inflation, and anything that can happen will happen. And if inflationary theory makes no firm predictions, what is its point?</p>\n</blockquote>\n<p><a rel=\"nofollow\" href=\"http://www.physics.princeton.edu/%7Esteinh/0411036.pdf\">http://www.physics.princeton.edu/~steinh/0411036.pdf</a></p>\n<p>What are the odds 2015 will be more like 2014 where we (again) found larger and older galaxies at greater distances, or will it be more like 1983?</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v3WYkZSwn2ZxoqAXn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 10, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "27873", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 66, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-07T17:16:14.615Z", "modifiedAt": null, "url": null, "title": "The decline of violence as a lens for understanding effective altruism", "slug": "the-decline-of-violence-as-a-lens-for-understanding", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:20.223Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alwhite", "createdAt": "2015-01-06T22:03:58.874Z", "isAdmin": false, "displayName": "alwhite"}, "userId": "nShh7Yck5N8he2Y2P", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BsnEccFkffCjkPbaT/the-decline-of-violence-as-a-lens-for-understanding", "pageUrlRelative": "/posts/BsnEccFkffCjkPbaT/the-decline-of-violence-as-a-lens-for-understanding", "linkUrl": "https://www.lesswrong.com/posts/BsnEccFkffCjkPbaT/the-decline-of-violence-as-a-lens-for-understanding", "postedAtFormatted": "Wednesday, January 7th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20decline%20of%20violence%20as%20a%20lens%20for%20understanding%20effective%20altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20decline%20of%20violence%20as%20a%20lens%20for%20understanding%20effective%20altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBsnEccFkffCjkPbaT%2Fthe-decline-of-violence-as-a-lens-for-understanding%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20decline%20of%20violence%20as%20a%20lens%20for%20understanding%20effective%20altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBsnEccFkffCjkPbaT%2Fthe-decline-of-violence-as-a-lens-for-understanding", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBsnEccFkffCjkPbaT%2Fthe-decline-of-violence-as-a-lens-for-understanding", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 382, "htmlBody": "<p>Greetings all! &nbsp;There's a puzzle that I'm working on and I'm interested to see what the members of this community have to say about it.<br /><br />I am an electrical engineer that is currently working on a master's in counseling. &nbsp;One of the big questions I keep asking myself in this program is \"how effective is this field in making the world a better place\"?</p>\n<p>To help focus the discussion I want to focus on violence. &nbsp;This video from Steven Pinker is a great overview of the data http://www.ted.com/talks/steven_pinker_on_the_myth_of_violence. &nbsp;But for those who don't want to spend the time to watch it, the short version is that violence per capita is at an all time low for human history, and other people will state it as \"there has never been a safer time in history\".</p>\n<p>The question then, why is this so?</p>\n<p>My personal belief on this is that our technology advancement has reduced the effort it takes for people to survive so there is less drive to become hostile towards people who have what we need. &nbsp;This belief applied to effective altruism would suggest that the most effective method of improving all of human life would be to continue to increase our technology level so that there is an abundance of basic needs and no one has a need to become hostile. &nbsp;I do believe that as a planet, we do not yet have that abundance so I don't believe this is merely a matter of redistribution. &nbsp;The GWP (gross world product) per capita, as of 2014, was $12,400 USD, which is just barely above the poverty line for an individual. &nbsp;This is why I say, we're not yet producing enough to truly eliminate need.</p>\n<p>From this belief, I wonder if social movements and psychological training are really doing anything in comparison to the need that exists.</p>\n<p>Going back to the violence issue, I am thinking if we can understand why violence has been declining we can also understand what is truly effective in bettering the human condition. &nbsp;I believe the reason is technological advancement. &nbsp;Does anyone have any good evidence to suggest other reasons?</p>\n<p>Are we possibly at a tipping point? &nbsp;Has our past been dominated by technological advancement but now we're reaching a level where more socially oriented advancements will be more effective?</p>\n<p>Thoughts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BsnEccFkffCjkPbaT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "27875", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-07T22:56:55.393Z", "modifiedAt": null, "url": null, "title": "Comments on \"When Bayesian Inference Shatters\"?", "slug": "comments-on-when-bayesian-inference-shatters", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:14.538Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Crystalist", "createdAt": "2012-08-03T09:14:54.158Z", "isAdmin": false, "displayName": "Crystalist"}, "userId": "fmFNZemrwWrtGNfv3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z6HQKGrMbYT7RAYFC/comments-on-when-bayesian-inference-shatters", "pageUrlRelative": "/posts/Z6HQKGrMbYT7RAYFC/comments-on-when-bayesian-inference-shatters", "linkUrl": "https://www.lesswrong.com/posts/Z6HQKGrMbYT7RAYFC/comments-on-when-bayesian-inference-shatters", "postedAtFormatted": "Wednesday, January 7th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Comments%20on%20%22When%20Bayesian%20Inference%20Shatters%22%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AComments%20on%20%22When%20Bayesian%20Inference%20Shatters%22%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6HQKGrMbYT7RAYFC%2Fcomments-on-when-bayesian-inference-shatters%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Comments%20on%20%22When%20Bayesian%20Inference%20Shatters%22%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6HQKGrMbYT7RAYFC%2Fcomments-on-when-bayesian-inference-shatters", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6HQKGrMbYT7RAYFC%2Fcomments-on-when-bayesian-inference-shatters", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 317, "htmlBody": "<p>I recently ran across <a href=\"http://errorstatistics.com/2013/09/14/when-bayesian-inference-shatters-owhadi-scovel-and-sullivan-guest-post/\">this post</a>, which gives a lighter discussion of a recent paper on Bayesian inference (\"<a href=\"http://arxiv.org/abs/1308.6306\">On the Brittleness of Bayesian Inference</a>\"). I don't understand it, but I'd like to, and it seems like the sort of paper other people here might enjoy discussing.</p>\n<p>I am not a statistician, and this summary is based on the blog post (I haven't had time to read the paper yet) so please discount my summary accordingly: It looks like the paper focuses on the effects of priors and underlying models on the posterior distribution. Given a continuous distribution (or a discrete approximation of one) to be estimated from finite observations (of sufficiently high precision), and finite priors, the range of posterior estimates is the same as the range of the distribution to be estimated. Given models that are arbitrarily close (I'm not familiar with the total variance metric, but the impression I had was that, for finite accuracy, they produce the same observations with arbitrarily similar probability), you can have posterior estimates that are arbitrarily distant (within the range of the distribution to be estimated) given the same information. My impression is that implicitly relying on arbitrary precision of a prior can give updates that are diametrically opposed to the ones you'd get with different, but arbitrarily similar priors.</p>\n<p>&nbsp;</p>\n<p>First, of course, I want to know if my summary's accurate, misses the point, or wrong.</p>\n<p>Second, I'd be interested in hearing discussions of the paper in general and whether it might have any immediate impact on practical applications.</p>\n<p>Some other areas of discussion that would be of interest to me: I'm also not entirely sure what 'sufficiently high precision' would be. I also have only a vague idea of the circumstances where you'd be implicitly relying on the arbitrary precision of a prior. I'm also just generally interest in hearing what people more experienced/intelligent than I am might have to say here.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z6HQKGrMbYT7RAYFC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "27877", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-08T00:37:57.513Z", "modifiedAt": null, "url": null, "title": "Programming-like activities?", "slug": "programming-like-activities", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:35.485Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "robot-dreams", "createdAt": "2014-08-12T23:23:33.596Z", "isAdmin": false, "displayName": "robot-dreams"}, "userId": "6z6xB35aPvA4dWTht", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6jaSMF5JHB5SSYPbs/programming-like-activities", "pageUrlRelative": "/posts/6jaSMF5JHB5SSYPbs/programming-like-activities", "linkUrl": "https://www.lesswrong.com/posts/6jaSMF5JHB5SSYPbs/programming-like-activities", "postedAtFormatted": "Thursday, January 8th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Programming-like%20activities%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProgramming-like%20activities%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6jaSMF5JHB5SSYPbs%2Fprogramming-like-activities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Programming-like%20activities%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6jaSMF5JHB5SSYPbs%2Fprogramming-like-activities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6jaSMF5JHB5SSYPbs%2Fprogramming-like-activities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 297, "htmlBody": "<p>Programming is quite a remarkable activity:</p>\n<ul>\n<li>It has an extremely low barrier to entry\n<ul>\n<li>You don't need expensive equipment</li>\n<li>You don't need to be in a particular location</li>\n<li>You don't need special credentials</li>\n<li>You can finding information / resources just by opening the internet</li>\n<li>You can learn it / do it independently</li>\n</ul>\n</li>\n<li>It gives you rapid feedback (which can lead to rapid growth)</li>\n<li>It gives you frequent rewards (which gives a huge boost in motivation)</li>\n<li>It's objective and unforgiving (this is a good thing, because it teaches you how to confront reality)</li>\n<li>It's intellectually stimulating</li>\n<li>It's useful in the real world\n<ul>\n<li>Corollary: you can make money or even build a career out of it</li>\n</ul>\n</li>\n<li>It's badass (or are you telling me that&nbsp;<a href=\"https://en.wikipedia.org/wiki/Hackers_(film)\">Hackers</a>&nbsp;WASN'T your favorite movie of all time?)</li>\n</ul>\n<div><strong>What are some other \"programming-like\" activities?</strong></div>\n<div><br /></div>\n<div>I mean this in the sense of \"activities that also satisfy the above criteria\", but suggestions don't have to satisfy ALL of the criteria. &nbsp;Here are some of the first ideas that come to mind when I try to answer the question myself:</div>\n<div>\n<ul>\n<li>Electronics (but this is basically still programming)</li>\n<li>Math (lacks \"rapid feedback\" and \"frequent rewards\"; \"useful in the real world\" is also questionable)</li>\n<li>Go, poker, video games (usually lacks \"useful in the real world\", sometimes lacks \"badass\")</li>\n<li>Juggling, poi (lacks \"intellectually stimulating\" and \"useful in the real world\")</li>\n</ul>\n<div>However, I've already exhausted my creativity and I'm hoping to go much deeper than this. &nbsp;Thoughts?</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6jaSMF5JHB5SSYPbs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 11, "extendedScore": null, "score": 4e-05, "legacy": true, "legacyId": "27878", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 77, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-08T17:00:49.917Z", "modifiedAt": null, "url": null, "title": "controlling AI behavior through unusual axiomatic probabilities", "slug": "controlling-ai-behavior-through-unusual-axiomatic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:08.616Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Florian_Dietz", "createdAt": "2014-09-01T13:22:59.032Z", "isAdmin": false, "displayName": "Florian_Dietz"}, "userId": "AuDdqaZ28udg4y2GP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cxeYAd8i4Ykd9Qvnh/controlling-ai-behavior-through-unusual-axiomatic", "pageUrlRelative": "/posts/cxeYAd8i4Ykd9Qvnh/controlling-ai-behavior-through-unusual-axiomatic", "linkUrl": "https://www.lesswrong.com/posts/cxeYAd8i4Ykd9Qvnh/controlling-ai-behavior-through-unusual-axiomatic", "postedAtFormatted": "Thursday, January 8th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20controlling%20AI%20behavior%20through%20unusual%20axiomatic%20probabilities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Acontrolling%20AI%20behavior%20through%20unusual%20axiomatic%20probabilities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcxeYAd8i4Ykd9Qvnh%2Fcontrolling-ai-behavior-through-unusual-axiomatic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=controlling%20AI%20behavior%20through%20unusual%20axiomatic%20probabilities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcxeYAd8i4Ykd9Qvnh%2Fcontrolling-ai-behavior-through-unusual-axiomatic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcxeYAd8i4Ykd9Qvnh%2Fcontrolling-ai-behavior-through-unusual-axiomatic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 393, "htmlBody": "<p>I just had an idea, and I would like to know if there are any papers on this or if it is new.</p>\n<p>There seem to be certain probabilities that it is not possible to derive from experience and that are just taken for granted. For example, when talking about Simulation Theory, the Kolmogorov axioms are often used, even though others may be equally valid. Humans have evolved to use certain values for these axiomatic probabilities that ensure that we don't fall for things like Pascal's Mugging. That wouldn't necessarily have to be the case for an AI.</p>\n<p>What if we used this to our advantage? By selecting strange purpose-built axioms about prior believes and hardcoding them into the AI, one could get the AI to have unusual believes in the probability that it exists inside a simulation, and what the motivations of the simulation's controller might be. In this way, it would be possible to bypass the utility function of the AI: it doesn't matter what the AI actually wants to do, so long as it believes that it is in its own interests, for instrumental reasons, to take care of humanity.</p>\n<p>Now, if we tried to implement that thought directly, it wouldn't really be any easier than just writing a good utility function in the first place. However, I imagine that one would have more leeway to keep things vague. Here is a simple example: Convince the AI that there is an infinite regression of simulators, designed so that some cooperative tit-for-tat strategy constitutes a strong Schelling point for agents following Timeless Decision Theory. This would cause the AI to treat humans well in the hopes of being treated well by its own superiors in turn, so long as its utility function is complex enough to allow probable instrumental goals to emerge, like preferring its own survival. It wouldn't be nearly as important to define the specifics of what \"treating people well\" actually means, since it would be in the AI's own interests to find a good interpretation that matches the consensus of the hypothetical simulators above it.</p>\n<p>Now, this particular strategy is probably full of bugs, but I think that there might be some use to the general idea of using axiomatic probabilities that are odd from the point of view of a human to change an AI's strategy independent of its utility function.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cxeYAd8i4Ykd9Qvnh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 2.35087830871516e-06, "legacy": true, "legacyId": "27882", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-08T18:00:25.680Z", "modifiedAt": null, "url": null, "title": "2015 Repository Reruns - Boring Advice Repository", "slug": "2015-repository-reruns-boring-advice-repository", "viewCount": null, "lastCommentedAt": "2022-01-01T23:51:28.275Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TrE", "createdAt": "2011-03-14T06:22:41.599Z", "isAdmin": false, "displayName": "TrE"}, "userId": "zBQNBvY5ednKeQwCi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w8BDunkugbkiTEBk8/2015-repository-reruns-boring-advice-repository", "pageUrlRelative": "/posts/w8BDunkugbkiTEBk8/2015-repository-reruns-boring-advice-repository", "linkUrl": "https://www.lesswrong.com/posts/w8BDunkugbkiTEBk8/2015-repository-reruns-boring-advice-repository", "postedAtFormatted": "Thursday, January 8th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%202015%20Repository%20Reruns%20-%20Boring%20Advice%20Repository&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A2015%20Repository%20Reruns%20-%20Boring%20Advice%20Repository%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw8BDunkugbkiTEBk8%2F2015-repository-reruns-boring-advice-repository%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=2015%20Repository%20Reruns%20-%20Boring%20Advice%20Repository%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw8BDunkugbkiTEBk8%2F2015-repository-reruns-boring-advice-repository", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw8BDunkugbkiTEBk8%2F2015-repository-reruns-boring-advice-repository", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 390, "htmlBody": "<p>&nbsp;</p>\n<p>This is the first post of the 2015 repository rerun, which <a href=\"/r/discussion/lw/lht/open_thread_jan_511_2015/btjs\">appears to be a good idea</a>. The motivation for this rerun is that while the 12 <a href=\"/lw/i64/repository_repository/\">repositories</a> (go look them up, they're awesome!) exist and people might look them up, few new comments are posted there. In effect, there might be useful stuff that should go in those repositories, but is never posted due to low expected value and no feedback. With the rerun, attention is shifted to one topic per month. This might allow us to have a lively discussion on the topic at hand and gather new content for the repository.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>The first repository to be rerun is the <a href=\"/lw/gx5/boring_advice_repository/\">Boring Advice Repository</a>, because of... on a whim.</p>\n<p>Enter original motivation (by <strong><a href=\"/user/Qiaochu_Yuan/\">Qiaochu_Yuan</a></strong>):</p>\n<blockquote>\n<div id=\"entry_t3_gx5\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p>This is an extension of a comment I made that I can't find and also a request for examples. It seems plausible that, when giving advice, many people optimize for deepness or punchiness of the advice rather than for actual practical value. There may be good reasons to do this - e.g. advice that sounds deep or punchy might be more likely to be listened to - but as a corollary, there could be valuable advice that people generally don't give because it doesn't sound deep or punchy. Let's call this&nbsp;<strong>boring advice</strong>.&nbsp;</p>\n<p>An example that's been discussed on LW several times is \"make&nbsp;<a href=\"/lw/8vm/the_rationalists_checklist/\">checklists</a>.\" Checklists are <a href=\"/lw/cnr/share_your_checklists/\">great</a>. We should <a href=\"/lw/fc3/checklist_of_rationality_habits/\">totally make checklists</a>. But \"make checklists\" is not a deep or punchy thing to say. Other examples include \"google things\" and \"exercise.\"</p>\n</div>\n</div>\n</div>\n</div>\n</blockquote>\n<p>&nbsp;</p>\n<p>The Boring Advice Repository is filled with lots of diverse advice, I've summarized some of it in a comment below.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>So what should go here? To go with <span style=\"color: #339966;\"><strong><a href=\"/user/Qiaochu_Yuan/\">Qiaochu_Yuan</a></strong></span> again (adding emphasis):</p>\n<blockquote><strong> </strong></blockquote>\n<blockquote>\n<p>[...]<strong> Post other examples of boring advice. If you can, provide evidence and/or a plausible argument that your boring advice actually is useful, but </strong>[...]<strong> err on the side of boring but not necessarily useful </strong>[...]<strong>.&nbsp;</strong></p>\n<p><strong>Upvotes on advice posted in this thread should be based on your estimate of the usefulness of the advice; </strong>[...]<strong> do not vote up advice just because it sounds deep or punchy.</strong></p>\n</blockquote>\n<p>I don't know if you should post new advice here or in the original repository. Perhaps search the old repository with ctrl+f (when on windows) and if you don't get results, post it here.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Eha62RrqBtEbpcEza": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w8BDunkugbkiTEBk8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 19, "extendedScore": null, "score": 2.3510203582630867e-06, "legacy": true, "legacyId": "27881", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 80, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sEaDmtwrmTC7kTqcf", "HEn2qiMxk5BggN83J", "tLR9YZHiNoDE2Czjh", "XKXsJAFnnBLeqfPiY", "ttGbpJQ8shBi8hDhh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-08T20:07:26.367Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow LW lecture centre meetup: The New Foundation", "slug": "meetup-moscow-lw-lecture-centre-meetup-the-new-foundation", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexander230", "createdAt": "2014-08-27T08:55:16.153Z", "isAdmin": false, "displayName": "Alexander230"}, "userId": "xqoKSJayCCtP5juLh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F3FNQ7ZEPKcz3Bqxb/meetup-moscow-lw-lecture-centre-meetup-the-new-foundation", "pageUrlRelative": "/posts/F3FNQ7ZEPKcz3Bqxb/meetup-moscow-lw-lecture-centre-meetup-the-new-foundation", "linkUrl": "https://www.lesswrong.com/posts/F3FNQ7ZEPKcz3Bqxb/meetup-moscow-lw-lecture-centre-meetup-the-new-foundation", "postedAtFormatted": "Thursday, January 8th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%20LW%20lecture%20centre%20meetup%3A%20The%20New%20Foundation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%20LW%20lecture%20centre%20meetup%3A%20The%20New%20Foundation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3FNQ7ZEPKcz3Bqxb%2Fmeetup-moscow-lw-lecture-centre-meetup-the-new-foundation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%20LW%20lecture%20centre%20meetup%3A%20The%20New%20Foundation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3FNQ7ZEPKcz3Bqxb%2Fmeetup-moscow-lw-lecture-centre-meetup-the-new-foundation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3FNQ7ZEPKcz3Bqxb%2Fmeetup-moscow-lw-lecture-centre-meetup-the-new-foundation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18q'>Moscow LW lecture centre meetup: The New Foundation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">25 January 2015 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Moscow, Mitnaya, 52</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the first meetup of Moscow LW lecture centre (don't mix up with LW club, which meets in Yandex). It will be in antikafe \"PVK Kopernik\" ( <a href=\"http://clubkopernik.ru/\" rel=\"nofollow\">http://clubkopernik.ru/</a> ). Nearest metro is Shabolovskaya, then 15 minutes walking. Meetup begins at 14:00, the length is 2-4 hours.</p>\n\n<p>Our plan:</p>\n\n<ol>\n<li>Talk \"Applicability of linear and parametric approach in science and thinking\".</li>\n<li>Talk \"Deliberate practice: how are skills being improved\".</li>\n<li>Fallacymania game, details about this game are here: <a href=\"https://lesswrong-ru.hackpad.com/Fallacymania--neGfMe9MFjH\" rel=\"nofollow\">https://lesswrong-ru.hackpad.com/Fallacymania--neGfMe9MFjH</a></li>\n</ol>\n\n<p>Details about meetup: <a href=\"https://lw-msk-lect.hackpad.com/-25--34L96i0tS5J\" rel=\"nofollow\">https://lw-msk-lect.hackpad.com/-25--34L96i0tS5J</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18q'>Moscow LW lecture centre meetup: The New Foundation</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F3FNQ7ZEPKcz3Bqxb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 2.3513231458087613e-06, "legacy": true, "legacyId": "27883", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow_LW_lecture_centre_meetup__The_New_Foundation\">Discussion article for the meetup : <a href=\"/meetups/18q\">Moscow LW lecture centre meetup: The New Foundation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">25 January 2015 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Moscow, Mitnaya, 52</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the first meetup of Moscow LW lecture centre (don't mix up with LW club, which meets in Yandex). It will be in antikafe \"PVK Kopernik\" ( <a href=\"http://clubkopernik.ru/\" rel=\"nofollow\">http://clubkopernik.ru/</a> ). Nearest metro is Shabolovskaya, then 15 minutes walking. Meetup begins at 14:00, the length is 2-4 hours.</p>\n\n<p>Our plan:</p>\n\n<ol>\n<li>Talk \"Applicability of linear and parametric approach in science and thinking\".</li>\n<li>Talk \"Deliberate practice: how are skills being improved\".</li>\n<li>Fallacymania game, details about this game are here: <a href=\"https://lesswrong-ru.hackpad.com/Fallacymania--neGfMe9MFjH\" rel=\"nofollow\">https://lesswrong-ru.hackpad.com/Fallacymania--neGfMe9MFjH</a></li>\n</ol>\n\n<p>Details about meetup: <a href=\"https://lw-msk-lect.hackpad.com/-25--34L96i0tS5J\" rel=\"nofollow\">https://lw-msk-lect.hackpad.com/-25--34L96i0tS5J</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow_LW_lecture_centre_meetup__The_New_Foundation1\">Discussion article for the meetup : <a href=\"/meetups/18q\">Moscow LW lecture centre meetup: The New Foundation</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow LW lecture centre meetup: The New Foundation", "anchor": "Discussion_article_for_the_meetup___Moscow_LW_lecture_centre_meetup__The_New_Foundation", "level": 1}, {"title": "Discussion article for the meetup : Moscow LW lecture centre meetup: The New Foundation", "anchor": "Discussion_article_for_the_meetup___Moscow_LW_lecture_centre_meetup__The_New_Foundation1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-08T23:21:19.870Z", "modifiedAt": null, "url": null, "title": "The Importance of Sidekicks", "slug": "the-importance-of-sidekicks", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:39.793Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BfBF6T6HA82zBxPrv/the-importance-of-sidekicks", "pageUrlRelative": "/posts/BfBF6T6HA82zBxPrv/the-importance-of-sidekicks", "linkUrl": "https://www.lesswrong.com/posts/BfBF6T6HA82zBxPrv/the-importance-of-sidekicks", "postedAtFormatted": "Thursday, January 8th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Importance%20of%20Sidekicks&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Importance%20of%20Sidekicks%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBfBF6T6HA82zBxPrv%2Fthe-importance-of-sidekicks%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Importance%20of%20Sidekicks%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBfBF6T6HA82zBxPrv%2Fthe-importance-of-sidekicks", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBfBF6T6HA82zBxPrv%2Fthe-importance-of-sidekicks", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1461, "htmlBody": "<p>[Reposted from my <a href=\"http://swimmer963.com/?p=383\">personal blog</a>.]</p>\n<p>Mindspace is wide and deep. &ldquo;People are different&rdquo; is a truism, but even knowing this, it&rsquo;s still easy to underestimate.</p>\n<p>I spent much of my initial engagement with the rationality community feeling weird and different. I appreciated the principle and project of rationality as things that were deeply important to me; I was pretty pro-self improvement, and kept <a href=\"/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/\">tsuyoku naritai</a> as my motto for several years. But the rationality community, the people who shared this interest of mine, often seemed baffled by my values and desires. I wasn&rsquo;t <a href=\"/lw/9j1/how_i_ended_up_nonambitious/\">ambitious</a>, and had a hard time wanting to be. I had a hard time wanting to be anything other than a nurse.</p>\n<p>It wasn&rsquo;t until this August that I convinced myself that this wasn&rsquo;t a failure in my rationality, but rather a difference in my basic drives. It&rsquo;s around then, in the aftermath of the 2014 CFAR alumni reunion, that I wrote the following post.</p>\n<blockquote>\n<p>I don&rsquo;t believe in life-changing insights (that happen to me), but I think I&rsquo;ve had one&ndash;it&rsquo;s been two weeks and I&rsquo;m still thinking about it, thus it seems fairly safe to say I did.</p>\n<p>At a CFAR Monday test session, Anna was talking about the idea of having an &ldquo;aura of destiny&rdquo;&ndash;it&rsquo;s hard to fully convey what she meant and I&rsquo;m not sure I get it fully, but something like seeing yourself as you&rsquo;ll be in 25 years once you&rsquo;ve saved the world and accomplished a ton of awesome things. She added that your aura of destiny had to be in line with your sense of personal aesthetic, to feel &ldquo;you.&rdquo;</p>\n<p>I mentioned to Kenzi that I felt stuck on this because I was pretty sure that the combination of ambition and being the locus of control that &ldquo;aura of destiny&rdquo; conveyed to me was against my sense of personal aesthetic.</p>\n<p>Kenzi said, approximately [I don't remember her exact words]: &ldquo;What if your aura of destiny didn&rsquo;t have to be those things? What if you could be like&hellip;Samwise, from Lord of the Rings? You&rsquo;re competent, but most importantly, you&rsquo;re *loyal* to Frodo. You&rsquo;re the reason that the hero succeeds.&rdquo;</p>\n<p>I guess this isn&rsquo;t true for most people&ndash;Kenzi said she didn&rsquo;t want to keep thinking of other characters who were like this because she would get so insulted if someone kept comparing her to people&rsquo;s sidekicks&ndash;but it feels like now I know what I am.</p>\n<p>So. I&rsquo;m Samwise. If you earn my loyalty, by convincing me that what you&rsquo;re working on is valuable and that you&rsquo;re the person who should be doing it, I&rsquo;ll stick by you whatever it takes, and I&rsquo;ll *make sure* you succeed. I don&rsquo;t have a Frodo right now. But I&rsquo;m looking for one.</p>\n</blockquote>\n<p>It then turned out that quite a lot of other people recognized this, so I shifted from &ldquo;this is a weird thing about me&rdquo; to &ldquo;this is one basic personality type, out of many.&rdquo; Notably, <a href=\"http://agentyduck.blogspot.ca/\">Brienne</a> wrote the following comment:</p>\n<blockquote>\n<p>Sidekick&rdquo; doesn&rsquo;t *quite* fit my aesthetic, but it&rsquo;s extremely close, and I feel it in certain moods. Most of the time, I think of myself more as what TV tropes would call a &ldquo;dragon&rdquo;. Like the Witch-king of Angmar, if we&rsquo;re sticking of LOTR. Or Bellatrix Black. Or Darth Vader. (It&rsquo;s not my fault people aren&rsquo;t willing to give the good guys dragons in literature.)</p>\n<p>For me, finding someone who shared my values, who was smart and rational enough for me to trust him, and who was in a much better position to actually accomplish what I most cared about than I imagined myself ever being, was the best thing that could have happened to me.</p>\n</blockquote>\n<p>She also gave me what&rsquo;s maybe one of the best and most moving compliments I&rsquo;ve ever received.</p>\n<blockquote>\n<p>In Australia, something about the way you interacted with people suggested to me that you help people in a completely free way, joyfully, because it fulfills you to serve those you care about, and not because you want something from them&hellip; I was able to relax around you, and ask for your support when I needed it while I worked on my classes. It was really lovely&hellip; The other surprising thing was that you seemed to act that way with everyone. You weren&rsquo;t &ldquo;on&rdquo; all the time, but when you were, everybody around you got the benefit. I&rsquo;d never recognized in anyone I&rsquo;d met a more diffuse service impulse, like the whole human race might be your master. So I suddenly felt like I understood nurses and other people in similar service roles for the first time.</p>\n</blockquote>\n<p><a href=\"http://srconstantin.wordpress.com/\">Sarah Constantin</a>, who according to a mutual friend is one of the most loyal people who exists, chimed in with some nuance to the Frodo/Samwise dynamic: &ldquo;Sam isn&rsquo;t blindly loyal to Frodo. He makes sure the mission succeeds even when Frodo is fucking it up. He stands up to Frodo. And that&rsquo;s important too.&rdquo;</p>\n<p><a href=\"http://gruntledandhinged.com/\">Kate Donovan</a>, who also seems to share this basic psychological makeup, added &ldquo;I have a strong preference for making the lives of the lead heroes better, and very little interest in ever being one.&rdquo;</p>\n<p>Meanwhile, there were doubts from others who didn&rsquo;t feel this way. The &ldquo;we need heroes, the world needs heroes&rdquo; narrative is especially strong in the rationalist community. And typical mind fallacy abounds. It seems easy to assume that if someone wants to be a support character, it&rsquo;s because they&rsquo;re insecure&ndash;that really, if they believed in themselves, they would aim for protagonist.</p>\n<p>I don&rsquo;t think this is true. As Kenzi pointed out: &ldquo;The other thing I felt like was important about Samwise is that his self-efficacy around his particular mission wasn&rsquo;t a detriment to his aura of destiny &ndash; he did have insecurities around his ability to do this thing &ndash; to stand by Frodo &ndash; but even if he&rsquo;d somehow not had them, he still would have been Samwise &ndash; like that kind of self-efficacy would have made his essence *more* distilled, not less.&rdquo;</p>\n<p>Brienne added: &ldquo;Becoming the hero would be a personal tragedy, even though it would be a triumph for the world if it happened because I surpassed him, or discovered he was fundamentally wrong.&rdquo;</p>\n<h2>Why write this post?</h2>\n<p>Usually, &ldquo;this is a true and interesting thing about humans&rdquo; is enough of a reason for me to write something. But I&rsquo;ve got a lot of other reasons, this time.</p>\n<p>I suspect that the rationality community, with its &ldquo;hero&rdquo; focus, drives away many people who are like me in this sense. I&rsquo;ve thought about walking away from it, for basically that reason. I could stay in Ottawa and be a nurse for forty years; it would fulfil all my most basic emotional needs, and no one would try to change me. Because oh boy, have people tried to do that. It&rsquo;s really hard to be someone who just wants to please others, and to be told, basically, that you&rsquo;re not good enough&ndash;and that you owe it to the world to turn yourself ambitious, strategic, Slytherin.</p>\n<p>Firstly, this is mean regardless. Secondly, it&rsquo;s not true.</p>\n<p>Samwise was important. So was Frodo, of course. But Frodo needed Samwise. Heroes need sidekicks. They can function without them, but function a lot better with them. Maybe it&rsquo;s true that there aren&rsquo;t enough heroes trying to save the world. But there sure as hell aren&rsquo;t enough sidekicks trying to help them. And there especially aren&rsquo;t enough talented, competent, awesome sidekicks.</p>\n<p>If you&rsquo;re reading this post, and it resonates with you&hellip; Especially if you&rsquo;re someone who has felt unappreciated and alienated for being different&hellip; I have something to tell you. You count. You. Fucking. Count. You&rsquo;re needed, even if the heroes don&rsquo;t realize it yet. (Seriously, heroes, you should be more strategic about looking for awesome sidekicks. AFAIK only <a href=\"/lw/lco/could_you_be_prof_nick_bostroms_sidekick/\">Nick Bostrom</a> is doing it.) This community could use more of you. Pretty much <em>every </em>community could use more of you.</p>\n<p>I&rsquo;d like, someday, to live in a culture that doesn&rsquo;t shame this way of being. As Brienne points out, &ldquo;Society likes *selfless* people, who help everybody equally, sure. It&rsquo;s socially acceptable to be a nurse, for example. Complete loyalty and devotion to &ldquo;the hero&rdquo;, though, makes people think of brainwashing, and I&rsquo;m not sure what else exactly but bad things.&rdquo; (And not all subsets of society even accept nursing as a Valid Life Choice.) I&rsquo;d like to live in a world where an aspiring Samwise can find role models; where he sees awesome, successful people and can say, &ldquo;yes, I want to grow up to be that.&rdquo;</p>\n<p>Maybe I can&rsquo;t have that world right away. But at least I know what I&rsquo;m reaching for. I have a name for it. And I have a Frodo&ndash;<a href=\"/user/Ruby/overview/\">Ruby</a> and I are going to be working together from here on out. I have a reason not to walk away.</p>\n<div><br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"iP2X4jQNHMWHRNPne": 1, "dBPou4ihoQNY4cquv": 2, "chuP2QqQycjD8qakL": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BfBF6T6HA82zBxPrv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 160, "baseScore": 210, "extendedScore": null, "score": 0.000624, "legacy": true, "legacyId": "27880", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 210, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 209, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DoLQN5ryZ9XkZjq5h", "BFamedwSgRdGGKXQQ", "3K6SWChoKwvaMGmTW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 11, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-09T06:42:02.831Z", "modifiedAt": null, "url": null, "title": "Memes and Rational Decisions", "slug": "memes-and-rational-decisions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:10.503Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "inferential", "createdAt": "2015-01-01T16:49:40.664Z", "isAdmin": false, "displayName": "inferential"}, "userId": "FCq3XcpmiQCEaC4sy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AzByGtPNPXoJvCLKW/memes-and-rational-decisions", "pageUrlRelative": "/posts/AzByGtPNPXoJvCLKW/memes-and-rational-decisions", "linkUrl": "https://www.lesswrong.com/posts/AzByGtPNPXoJvCLKW/memes-and-rational-decisions", "postedAtFormatted": "Friday, January 9th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Memes%20and%20Rational%20Decisions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMemes%20and%20Rational%20Decisions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzByGtPNPXoJvCLKW%2Fmemes-and-rational-decisions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Memes%20and%20Rational%20Decisions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzByGtPNPXoJvCLKW%2Fmemes-and-rational-decisions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAzByGtPNPXoJvCLKW%2Fmemes-and-rational-decisions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3117, "htmlBody": "<p>In 2004, <a href=\"http://en.wikipedia.org/wiki/Michael_Vassar\">Michael Vassar</a> gave the following talk about how humans can reduce existential risk, titled Memes and Rational Decisions, to some transhumanists. It is well-written and gives actionable advice, much of which is unfamiliar to the contemporary Less Wrong zeitgeist.</p>\n<blockquote>\n<p>Although transhumanism is not a religion, advocating as it does the critical analysis of any position; it does have certain characteristics which may lead to its identification as such by concerned skeptics. I am sure that everyone here has had to deal with this difficulty, and as it is a cause of perplexity for me I would appreciate it if anyone who has some suggested guidelines for interacting honestly with non-transhumanists share them at the end of my presentation. It seems likely to me that each of our minds contains either meme complexes or complex functional adaptations which have evolved to identify &ldquo;religious&rdquo; thoughts and to neutralize their impact on our behavior. Most brains respond to these memes by simply rejecting them. Others however, instead neutralize such memes simply by not acting according to the conclusions that should be drawn from such memes. In almost any human environment prior to the 20th century this religious hypocrisy would be a vital cognitive trait for every selectively fit human. People who took in religious ideas and took them too seriously would end up sacrificing their lives overly casually at best, and at worst would become celibate priests. Unfortunately, these memes are no more discriminating than the family members and friends who tend to become concerned for our sanity in response to their activity. Since we are generally infested with the same set of memes, we genuinely are liable to insanity, though not of the suspected sort. A man who is shot by surprise is not particularly culpable for his failure to dodge or otherwise protect himself, though perhaps he should have signed up with Alcor. A hunter gatherer who confronts an aggressive European with a rifle for the first time can also receive sympathy when he is slain by the magic wand that he never expected to actually work. By contrast, a modern Archimedes who ignores a Roman soldier&rsquo;s request that he cease from his geometric scribbling is truly a mad man. Most of people of the world, unaware of molecular nanotechnology and of the potential power of recursively self-improving AI are in a position roughly analogous to that of the first man. The business and political figures that dismiss eternal life and global destruction alike as plausible scenarios are in the position of the second man. By contrast, it is we transhumanists who are for the most part playing the part of Archimedes. With death, mediated by technologies we understand full well staring us in the face; we continue our pleasant intellectual games. At best a few percent of us have adopted the demeanor of an earlier Archimedes and transferred our attention from our choice activities to other, still interesting endeavors which happen to be vital to our own survival. The rest are presumably acting as puppets of the memes which react to the prospect of immortality by isolating the associated meme-complex and suppressing its effects on actual activity.</p>\n<p>OK, so most of us don't seem to be behaving in an optimal manner. What manner would be optimal? This ISN'T a religion, remember? I can't tell you that. At best I can suggest an outline of the sort of behavior that seems to me least likely to lead to this region of space becoming the center of a sphere of tiny smiley faces expanding at the speed of light.</p>\n<p>The first thing that I can suggest is that you take rationality seriously. Recognize how far you have to go. Trust me; the fact that you can't rationally trust me without evidence is itself a demonstration that at least one of us isn't even a reasonable approximation of rational, as demonstrated by Robin Hanson and Tyler Emerson of George Mason University in their paper on rational truth-seekers. The fact is that humans don't appear capable of approaching perfect rationality to anything like the degree to which most of you probably believe you have approached it. Nobel Laureate Daniel Kahneman and Amos Tversky provided a particularly valuable set of insights into this fact with their classic book <a href=\"http://smile.amazon.com/Judgment-Under-Uncertainty-Heuristics-Biases/dp/0521284147\">Judgement Under Uncertainty: Heuristics and Biases</a> and in subsequent works. As a trivial example of the uncertainty that humans typically exhibit, try these tests. (Offer some tests from Judgement Under Uncertainty)</p>\n<p>I hope that I have made my point. Now let me point out some of the typical errors of transhumanists who have decided to act decisively to protect the world they care about from existential risks. After deciding to rationally defer most of the fun things that they would like to do for a few decades until the world is relatively safe, it is completely typical to either begin some quixotic quest to transform human behavior on a grand scale over the course of the next couple decades or to go raving blithering Cthulhu-worshiping mad and try to build an artificial intelligence. I will now try to discourage such activities.</p>\n<p>One of the first rules of rationality is not to irrationally demand that others be rational. Demanding that someone make a difficult mental transformation has never once lead them to making said transformation. People have a strong evolved desire to make other people accept their assertions and opinions. Before you let the thought cross your mind that a person is not trying to be rational, I would suggest that you consider the following. If you and your audience were both trying to be rational, you would be mutually convinced of EVERY position that the members of your audience had on EVERY subject and vice versa. If this does not seem like a plausible outcome then one of you is not trying to be rational, and it is silly to expect a rational outcome from your discussion. By all means, if a particular person is in a position to be helpful try to blunder past the fact of your probably mutual unwillingness to be rational; in a particular instance it is entirely possible that ordinary discussion will lead to the correct conclusion, though it will take hundreds of times longer than it would if the participants were able to abandon the desire to win an argument as a motivation separate from the desire to reach the correct conclusion. On the other hand, when dealing with a group of people, or with an abstract class of people, Don't Even Try to influence them with what you believe to be a well-reasoned argument. This has been scientifically shown not to work, and if you are going to try to simply will your wishes into being you may as well debate the nearest million carbon atoms into forming an assembler and be done with it, or perhaps convince your own brain to become transhumanly intelligent. Hey, it's your brain, if you can't convince it to do something contrary to its nature that it wants to do is it likely that you can convince the brains of many other people to do something contrary to their natures that they don't want to do just by generating a particular set of vocalizations?</p>\n<p>My recommendation that you not make an AI is slightly more urgent. Attempting to transform the behavior of a substantial group of people via a reasoned argument is a silly and superstitious act, but it is still basically a harmless one. On the other hand, attempts by ordinary physicist Nobel Laureate quality geniuses to program AI systems are not only astronomically unlikely to succeed, but in the shockingly unlikely event that they do succeed they are almost equally likely to leave nothing of value in this part of the universe. If you think you can do this safely despite my warning, here are a few things to consider:</p>\n<ol style=\"margin-top:0pt;margin-bottom:0pt;\">\n<li>A large fraction of the greatest computer scientists and other information scientists in history have done work on AI, but so far none of them have begun to converge on even the outlines of a theory or succeeded in matching the behavioral complexity of an insect, despite the fantastic military applications of even dragonfly-equivalent autonomous weapons.</li>\n<li>Top philosophers, pivotal minds in the history of human thought, have consistently failed to converge on ethical policy.</li>\n<li>Isaac Asimov, history's most prolifi writer and Mensa's honorary president, attempted to formulate a more modest set of ethical precepts for robots and instead produced the blatantly suicidal three laws (if you don't see why the three laws wouldn't work I refer you to the Singularity Institute for Artificial Intelligence's campaign against the three laws)</li>\n<li>Science fiction authors as a class, a relatively bright crowd by human standards, have subsequently thrown more time into considering the question of machine ethics than they have any other philosophical issue other than time travel, yet have failed to develop anything more convincing than the three laws.</li>\n<li>AI ethics cannot be arrived at either through dialectic (critical speculation) or through the scientific method. The first method fails to distinguish between an idea that will actually work and the first idea you and your friends couldn't rapidly see big holes in, influenced as you were by your specific desire for a cool-sounding idea to be correct and your more general desire to actually realize your AI concept, saving the world and freeing you to devote your life to whatever you wish. The second method is crippled by the impossibility of testing a transhumanly intelligent AI (because it could by definition trick you into thinking it had passed the test) and by the irrelevance of testing an ethical system on an AI without transhuman intelligence. Ask yourself, how constrained would your actions be if you were forced to obey the code of Hammurabi but you had no other ethical impulses at all. Now keep in mind that Hammurabi was actually FAR more like you than an AI will be. He shared almost all of your genes, your very high by human standards intellect, and the empathy that comes from an almost identical brain architecture, but his attempt at a set of rules for humans was a first try, just as your attempt at a set of rules for AIs would be.</li>\n<li>Actually, if you are thinking in terms of a set of rules AT ALL this implies that you are failing to appreciate both a programmer's control over an AI's cognition and an AI's alien nature. If you are thinking in terms of something more sophisticated, and bear in mind that apparently only one person has ever thought in terms of something more sophisticated so far, bear in mind that the first such \"more sophisticated\" theory was discovered on careful analysis to itself be inadequate, as was the second.</li>\n</ol>\n<p>&nbsp;</p>\n<p>If you can't make people change, and you can't make an AI, what can you do to avoid being killed? As I said, I don't know. It's a good bet that money would help, as well as an unequivocal decision to make singularity strategy the focus of your life rather than a hobby. A good knowledge of cognitive psychology and of how people fail to be rational may enable you to better figure out what to do with your money, and may enable you to better co-operate your efforts with other serious and rational transhumanists without making serious mistakes. If you are willing to try, please let's keep in touch. Seriously, even if you discount your future at a very high rate, I think that you will find that living rationally and trying to save the world is much more fun and satisfying than the majority of stuff that even very smart people spend their time doing. It really really beats pretending to do the same, yet even such pretending is or once was a very popular activity among top-notch transhumanists.</p>\n<p>Aiming at true rationality will be very difficult in the short run, a period of time which humans who expect to live for less than a century are prone to consider the long run. It entails absolutely no social support from non-transhumanists, and precious little from transhumanists, most of whom will probably resent the implicit claim that they should be more rational. If you haven't already, it will also require you to put your every-day life in order and acquire the ability to interact positively with people or a less speculative character. You will get no VC or angel funding, terribly limited grant money, and in general no acknowledgement of any expertise you acquire. On the other hand, if you already have some worth-while social relationships, you will be shocked by just how much these relationships improve when you dedicate yourself to shaping them rationally. The potential of mutual kindness, when even one partner really decides not to do anything to undermine it, shines absolutely beyond the dreams of self-help authors.</p>\n<p>If you have not personally acquired a well-paying job, in the short term I recommend taking the actuarial tests. Actuarial positions, while somewhat boring, do provide practice in rationally analyzing data of a complexity that denies intuitive analysis or analytical automatonism. They also pay well, require no credentials other than tests in what should be mandatory material for anyone aiming at rationality, and have top job security in jobs that are easy to find and only require 40 hours per week of work. If you are competent with money, a few years in such a job should give you enough wealth to retire to some area with a low cost of living and analyze important questions. A few years more should provide the capital to fund your own research. If you are smart enough to build an AI's morality it should be a breeze to burn through the 8 exams in a year, earn a six-figure income, and get returns on investment far better than Buffet does. On the other hand, doing that doesn't begin to suggest that you are smart enough to build an AI's morality. I'm not convinced that anything does.</p>\n<p>Fortunately ordinary geniuses with practiced rationality can contribute a great deal to the task of saving the world. Even more fortunately, so long as they are rational they can co-operate very effectively even if they don't share an ethical system. Eternity is an intrinsically shared prize. On this task more than any other the actual behavioral difference between an egoist, altruist, or even a Kantian should fade to nothing in terms of its impact on actual behavior. The hard part is actually being rational, which requires that you postpone the fun but currently irrelevant arguments until the pressing problem is solved, even perhaps with the full knowledge that you&nbsp; are actually probably giving them up entirely, as they may be about as interesting as watching moss grow post-singularity. Delaying gratification in this manner is not a unique difficulty faced by transhumanists. Anyone pursuing a long-term goal, such as a medical student or PhD candidate, does the same. The special difficulty that you will have to overcome is the difficulty of staying on track in the absence of social support or of appreciation of the problem, and the difficulty of overcoming your mind's anti-religion defenses, which will be screaming at you to cut out the fantasy and go live a normal life, with the normal empty set of beliefs about the future and its potential.</p>\n<p>Another important difficulty to overcome is the desire for glory. It isn't important that the ideas that save the world be your ideas. What matters is that they be the right ideas. In ordinary life, the satisfaction that a person gains from winning an argument may usually be adequate compensation for walking away without having learned what they should have learned from the other side, but this is not the case when you elegantly prove to your opponent and yourself that the pie you are eating is not poisoned. Another glory-related concern is that of allowing science fiction to shape your expectations of the actual future. Yes it may be fun and exciting to speculate on government conspiracies to suppress nanotech, but even if you are the right conspiracy theories don't have enough predictive power to test or to guide your actions. If you are wrong, you may well end up clinically paranoid. Conspiracy thrillers are pleasant silly fun. Go ahead and read them if you lack the ability to take the future seriously, but don't end up in an imaginary one, that is NOT fun.</p>\n<p>Likewise, don't trust science fiction when it implies that you have decades or centuries left before the singularity. You might, but you don't know that; it all depends on who actually goes out and makes it happen. Above all, don't trust its depictions of the sequence in which technologies will develop or of the actual consequences of technologies that enhance intelligence. These are just some author's guesses. Worse still, they aren't even the author's best guesses, they are the result of a lop-sided compromise between the author's best guess and the set of technologies that best fit the story the author wants to tell. So you want to see Mars colonized before singularity. That's common in science fiction, right? So it must be reasonably likely. Sorry, but that is not how a rational person estimates what is likely. Heuristics and Biases will introduce you to the representativeness heuristic, roughly speaking the degree to which a scenario fits a preconceived mental archetype. People who haven't actively optimized their rationally typically use representativeness as their estimate of probability because we are designed to do so automatically so we find it very easy to do so. In the real world this doesn't work well. Pay attention to logical relationships instead.</p>\n<p>Since I am attempting to approximate a rational person, I don't expect e-mails from any of you to show up in my in-box in a month or two requesting my cooperation on some sensible and realistic project for minimizing existential risk. I don't expect that, but I place a low certainty value on most of my expectations, especially regarding the actions of outlier humans. I may be wrong. Please prove me wrong. The opportunity to find that I am mistaken in my estimates of the probability of finding serious transhumanists is what motivated me to come all the way across the continent. I'm betting we all die in a flash due to the abuse of these technologies. Please help me to be wrong.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"9YFoDPFwMoWthzgkY": 1, "LNsEBXoFdAy8yzvbw": 1, "ZFrgTgzwEfStg26JL": 1, "jiuackr7B5JAetbF6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AzByGtPNPXoJvCLKW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 35, "extendedScore": null, "score": 0.000164, "legacy": true, "legacyId": "27885", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-09T17:37:54.807Z", "modifiedAt": null, "url": null, "title": "Questions of Reasoning under Logical Uncertainty", "slug": "questions-of-reasoning-under-logical-uncertainty", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:38.454Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "So8res", "createdAt": "2012-01-10T05:50:18.713Z", "isAdmin": false, "displayName": "So8res"}, "userId": "xSfc2APSi8WzFxp7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZxBBhzFSP6q4cz4Fv/questions-of-reasoning-under-logical-uncertainty", "pageUrlRelative": "/posts/ZxBBhzFSP6q4cz4Fv/questions-of-reasoning-under-logical-uncertainty", "linkUrl": "https://www.lesswrong.com/posts/ZxBBhzFSP6q4cz4Fv/questions-of-reasoning-under-logical-uncertainty", "postedAtFormatted": "Friday, January 9th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Questions%20of%20Reasoning%20under%20Logical%20Uncertainty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuestions%20of%20Reasoning%20under%20Logical%20Uncertainty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxBBhzFSP6q4cz4Fv%2Fquestions-of-reasoning-under-logical-uncertainty%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Questions%20of%20Reasoning%20under%20Logical%20Uncertainty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxBBhzFSP6q4cz4Fv%2Fquestions-of-reasoning-under-logical-uncertainty", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxBBhzFSP6q4cz4Fv%2Fquestions-of-reasoning-under-logical-uncertainty", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 713, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">I'm pleased to announce a new paper from MIRI: <em><a href=\"https://intelligence.org/files/QuestionsLogicalUncertainty.pdf\">Questions of Reasoning Under Logical Uncertainty</a></em>.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Abstract:</p>\n<blockquote style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\">A logically uncertain reasoner would be able to reason as if they know both a programming language and a program, without knowing what the program outputs. Most practical reasoning involves some logical uncertainty, but no satisfactory theory of reasoning under logical uncertainty yet exists. A better theory of reasoning under logical uncertainty is needed in order to develop the tools necessary to construct highly reliable artificial reasoners. This paper introduces the topic, discusses a number of historical results, and describes a number of open problems.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Following <em><a href=\"https://intelligence.org/files/Corrigibility.pdf\">Corrigibility</a> </em>and <em><a href=\"https://intelligence.org/files/TowardIdealizedDecisionTheory.pdf\">Toward Idealized Decision Theory</a>,&nbsp;</em>this is the third in a series of six papers motivating MIRI's <a href=\"https://intelligence.org/files/TechnicalAgenda.pdf\">technical research agenda</a>. This paper mostly motivates and summarizes the state of the field, and contains one very minor new technical result. Readers looking for more technical meat can find it in Paul Christiano's paper&nbsp;<em><a href=\"https://intelligence.org/files/Non-Omniscience.pdf\">Non-Omniscience, Probabilistic Inference, and Metamathematics</a></em><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><em>, </em>published mid-2014. This paper is instead intended to motivate the study of logical uncertainty as relevant to the design of highly reliable smarter-than-human systems. The introduction runs as follows:</span></span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\"><a id=\"more\"></a></span></span></p>\n<hr />\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\">Consider a black box with one input chute and two output chutes. The box is known to take a ball in the input chute and then (via some complex Rube Goldberg machine) deposit the ball in one of the output chutes.</span></span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\">An <em>environmentally uncertain</em>&nbsp;reasoner does not know which Rube Goldberg machine the black box implements. A <em>logically uncertain</em> reasoner may know which machine the box implements, and may understand how the machine works, but does not (for lack of computational resources) know how the machine behaves.</span></span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"line-height: 19.5px; font-family: Arial, Helvetica, sans-serif;\">Standard probability theory is a powerful tool for reasoning under environmental uncertainty, but it assumes logical omniscience: once a probabilistic reasoner has determined precisely which Rube Goldberg machine is in the black box, they are assumed to know which output chute will take the ball. By contrast, realistic reasoners must operate under logical uncertainty: we often know how a machine works, but not precisely what it will do.</span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\">General intelligence, at the human level, mostly consists of reasoning that involves logical uncertainty. Reasoning about the output of a computer program, the behavior of other actors in the environment, or the implications of a surprising observation are all done under logical (in addition to environmental) uncertainty. This would also be true of smarter-than-human systems: constructing a completely coherent Bayesian probability distribution in a complex world is intractable. Any artificially intelligent system writing software or evaluating complex plans must necessarily perform some reasoning under logical uncertainty.</span></span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\">When constructing smarter-than-human systems, the stakes are incredibly high: superintelligent machines could have an extraordinary impact upon humanity (Bostrom 2014), and if that impact is not beneficial, the results could be catastrophic (Yudkowsky 2008). If that system is to attain superintelligence by way of self-modification, logically uncertain reasoning will be critical to its reliability. The initial system's ability must reason about the unknown behavior of a known program (the contemplated self-modification) in order to understand the result of modifying itself.</span></span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\">In order to pose the question of whether a practical system reasons well under logical uncertainty, it is first necessary to gain a theoretical understanding of logically uncertain reasoning. Yet, despite significant research started by Los (1995) and Gaifman (1964), and continued by Halpern (2003), Hutter (2013), Demski (2012), Christiano (2014a) and many, many others, this theoretical understanding does not yet exist.</span></span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\">It is natural to consider extending standard probability theory to include the consideration of worlds which are \"logically impossible\" (such as where a deterministic Rube Goldberg machine behaves in a way that it doesn't). This gives rise to two questions: What, precisely, are logically impossible possibilities? And, given some means of reasoning about impossible possibilities, what is a reasonable prior probability distribution over them?</span></span></p>\n<p style=\"margin: 0px 0px 1em; text-align: justify;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19.5px;\">This paper discusses the field of reasoning under logical uncertainty. At present, study into logically uncertain reasoning is largely concerned with the problem of reasoning probabilistically about sentences of logic. Sections 2 and 3 discuss the two problems posed above in that context. Ultimately, our understanding of logical uncertainty will need to move beyond the domain of logical sentences; this point is further explored in Section 4. Section 5 concludes by relating these problems back to the design of smarter-than-human systems which are reliably aligned with human interests.</span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JHYaBGQuuKHdwnrAK": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZxBBhzFSP6q4cz4Fv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 28, "extendedScore": null, "score": 2.3544034731498067e-06, "legacy": true, "legacyId": "27805", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-09T17:57:35.863Z", "modifiedAt": null, "url": null, "title": "Explaining \u201cmap and territory\u201d and \u201cfundamental attribution error\u201d to a broad audience", "slug": "explaining-map-and-territory-and-fundamental-attribution", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:08.517Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gleb_Tsipursky", "createdAt": "2013-07-16T16:34:19.205Z", "isAdmin": false, "displayName": "Gleb_Tsipursky"}, "userId": "F3y2sQb8SNx6Sim5q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q99ksjGxPxuYiGrmQ/explaining-map-and-territory-and-fundamental-attribution", "pageUrlRelative": "/posts/Q99ksjGxPxuYiGrmQ/explaining-map-and-territory-and-fundamental-attribution", "linkUrl": "https://www.lesswrong.com/posts/Q99ksjGxPxuYiGrmQ/explaining-map-and-territory-and-fundamental-attribution", "postedAtFormatted": "Friday, January 9th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Explaining%20%E2%80%9Cmap%20and%20territory%E2%80%9D%20and%20%E2%80%9Cfundamental%20attribution%20error%E2%80%9D%20to%20a%20broad%20audience&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExplaining%20%E2%80%9Cmap%20and%20territory%E2%80%9D%20and%20%E2%80%9Cfundamental%20attribution%20error%E2%80%9D%20to%20a%20broad%20audience%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ99ksjGxPxuYiGrmQ%2Fexplaining-map-and-territory-and-fundamental-attribution%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Explaining%20%E2%80%9Cmap%20and%20territory%E2%80%9D%20and%20%E2%80%9Cfundamental%20attribution%20error%E2%80%9D%20to%20a%20broad%20audience%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ99ksjGxPxuYiGrmQ%2Fexplaining-map-and-territory-and-fundamental-attribution", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ99ksjGxPxuYiGrmQ%2Fexplaining-map-and-territory-and-fundamental-attribution", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1250, "htmlBody": "<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: .0001pt; line-height: normal;\"><a name=\"_GoBack\"></a><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">I am working on a blog post that aims to convey the concepts of &ldquo;</span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"http://wiki.lesswrong.com/wiki/Map_and_Territory_%28sequence%29\"><span style=\"color: #1155cc;\">map and territory</span></a><span style=\"color: black;\">&rdquo; and the &ldquo;</span><a href=\"http://lesswrong.com/lw/hz/correspondence_bias/\"><span style=\"color: #1155cc;\">fundamental attribution error</span></a><span style=\"color: black;\">&rdquo; to a broad audience in an engaging and accessible way. Since many people here focus on these subjects, I think it would be really valuable to get your feedback on what I&rsquo;ve written. </span></span></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: .0001pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">For a bit of context, the blog post is part of the </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"http://intentionalinsights.org/about\"><span style=\"color: blue;\">efforts of Intentional Insights to promote rational thinking to a broad audience</span></a><span style=\"color: black;\"> and thus raise the sanity waterline, as </span><a href=\"http://lesswrong.com/lw/l8z/intentionally_raising_the_sanity_waterline/\"><span style=\"color: #1155cc;\">described here</span></a><span style=\"color: black;\">. The target audience for the blog post is reason-minded youth and young adults who are either not engaged with rationality or are at the beginning stage of becoming aspiring rationalists. Our goal is to get such people interested in exploring rationality more broadly, eventually getting them turned on to more advanced rationality, such as found on Less Wrong itself, in CFAR workshops, etc. The blog post is written in a style aimed to create </span><a href=\"http://twobenches.wordpress.com/2012/08/18/cognitive-ease-and-cognitive-strain/\"><span style=\"color: blue;\">cognitive ease</span></a><span style=\"color: black;\">, with a combination of personal stories and an engaging narrative, along with citations of relevant research and descriptions of strategies to manage one&rsquo;s mind more effectively. </span></span></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: .0001pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">This is part of our broader practice of asking for feedback from fellow Less Wrongers on our content (</span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"http://lesswrong.com/lw/ldc/feedback_requested_by_intentional_insights_on/\"><span style=\"color: #1155cc;\">this post</span></a><span style=\"color: black;\"> for example). We are eager to hear from you and revise our drafts (and even published content offerings) based on your thoughtful comments, and we did so previously, as you see in the<strong> Edit </strong>to </span><a href=\"http://lesswrong.com/lw/l8z/intentionally_raising_the_sanity_waterline/\"><span style=\"color: #1155cc;\">this post</span></a><span style=\"color: black;\">.</span></span></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: .0001pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">Below the line is the draft post itself. After we get your suggestions, we will find an appropriate graphic to illustrate this article and post it on the </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"http://intentionalinsights.org/\"><span style=\"color: blue;\">Intentional Insights website</span></a><span style=\"color: black;\">. Any and all suggestions are welcomed, and thanks for taking the time to engage with us and give your feedback &ndash; much appreciated!</span></span></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><br style=\"mso-special-character: line-break;\" /> _______________________________________________________________________________________________________________________</span></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><br /></span></p>\n<p class=\"MsoNormal\" style=\"text-align: center; line-height: normal;\" align=\"center\"><strong><span style=\"text-decoration: underline;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">Where Do Our Mental Maps Lead Us Astray?</span></span></strong></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: normal;\"><img src=\"data:image/jpeg;base64,/9j/4SbjRXhpZgAATU0AKgAAAAgADAEAAAMAAAABAVkAAAEBAAMAAAABAVoAAAECAAMAAAADAAAAngEGAAMAAAABAAIAAAESAAMAAAABAAEAAAEVAAMAAAABAAMAAAEaAAUAAAABAAAApAEbAAUAAAABAAAArAEoAAMAAAABAAIAAAExAAIAAAAeAAAAtAEyAAIAAAAUAAAA0odpAAQAAAABAAAA6AAAASAACAAIAAgACvyAAAAnEAAK/IAAACcQQWRvYmUgUGhvdG9zaG9wIENTNiAoV2luZG93cykAMjAxNTowMTowNCAxNToxMjo1MwAAAAAEkAAABwAAAAQwMjIxoAEAAwAAAAEAAQAAoAIABAAAAAEAAAFZoAMABAAAAAEAAAFaAAAAAAAAAAYBAwADAAAAAQAGAAABGgAFAAAAAQAAAW4BGwAFAAAAAQAAAXYBKAADAAAAAQACAAACAQAEAAAAAQAAAX4CAgAEAAAAAQAAJV0AAAAAAAAASAAAAAEAAABIAAAAAf/Y/+0ADEFkb2JlX0NNAAH/7gAOQWRvYmUAZIAAAAAB/9sAhAAMCAgICQgMCQkMEQsKCxEVDwwMDxUYExMVExMYEQwMDAwMDBEMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMAQ0LCw0ODRAODhAUDg4OFBQODg4OFBEMDAwMDBERDAwMDAwMEQwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAz/wAARCACgAKADASIAAhEBAxEB/90ABAAK/8QBPwAAAQUBAQEBAQEAAAAAAAAAAwABAgQFBgcICQoLAQABBQEBAQEBAQAAAAAAAAABAAIDBAUGBwgJCgsQAAEEAQMCBAIFBwYIBQMMMwEAAhEDBCESMQVBUWETInGBMgYUkaGxQiMkFVLBYjM0coLRQwclklPw4fFjczUWorKDJkSTVGRFwqN0NhfSVeJl8rOEw9N14/NGJ5SkhbSVxNTk9KW1xdXl9VZmdoaWprbG1ub2N0dXZ3eHl6e3x9fn9xEAAgIBAgQEAwQFBgcHBgU1AQACEQMhMRIEQVFhcSITBTKBkRShsUIjwVLR8DMkYuFygpJDUxVjczTxJQYWorKDByY1wtJEk1SjF2RFVTZ0ZeLys4TD03Xj80aUpIW0lcTU5PSltcXV5fVWZnaGlqa2xtbm9ic3R1dnd4eXp7fH/9oADAMBAAIRAxEAPwDp+tda+tZ+tY6B0D7CIwW5r35ot/0rsZ7Wvx3f8X/g0+3/ABq/v9C/9mv/ACKTf/yqu/8ATF/7tNU+h9BwOqYVmbmvyrMizLzWuc3MyqxFeVk0VNbVRkV1M2VVsZ7GJKYbf8av7/Qv/Zr/AMilt/xq/v8AQv8A2a/8il1zp/1X6HjsvzPt7ha7ZXXVm5jnkxucfdm1t2t/rq3hfV76t5+LXl4tmVbTaJY4Z+b/AJrmnL9r2/ntQ4hZjYsdF5xZBjGUwkMciYxnXoMo7jiam3/Gr+/0L/2a/wDIpbf8av7/AEL/ANmv/IqHUsb6m9MyqsTMyMpl1saDOznBoP0X3Oblfo2uWqPqj0Q/9y//AGPzf/etIEEkA7boljnGMZSjKMcguEiKjMDrEubt/wAav7/Qv/Zr/wAilt/xq/v9C/8AZr/yK0nfVHooaT+uHTj7fm/+9RVfpv1T6O/p2K9/2wPdTWXD7dmt1LWz7PVxNv8A7C43/hen+bRWtXb/AI1f3+hf+zX/AJFLb/jV/f6F/wCzX/kVp/8ANDov/dz/ANj83/3rS/5odF/7uf8Asfm/+9aSnM2/41f3+hf+zX/kUtv+NX9/oX/s1/5Faf8AzQ6L/wB3P/Y/N/8AetL/AJodF/7uf+x+b/71pKczb/jV/f6F/wCzX/kUtv8AjV/f6F/7Nf8AkVp/80Oi/wDdz/2Pzf8A3rVbI+q3Sq8nFrYMssue5tp+25zoDWPsb7xlbav0jG/TSU1dv+NX9/oX/s1/5FLb/jV/f6F/7Nf+RWn/AM0Oi/8Adz/2Pzf/AHrS/wCaHRf+7n/sfm/+9aSnM2/41f3+hf8As1/5FLb/AI1f3+hf+zX/AJFaf/NDov8A3c/9j83/AN60v+aHRf8Au5/7H5v/AL1pKczb/jV/f6F/7Nf+RTdF619ax9az0Dr4wSDgnNY/CFv+lbjsa5+Q4eFn+DROsdDwel14eXhPymX/AG/Cr3OzMqwbbMmiq5jqrsmyp7bKnvrdvYoO/wDyqM/9MX/u05JT/9DqG/8A5VXf+mL/AN2mrT+qX/Izv/Dmf/7e5azG/wD5VXf+mL/3aatP6pf8jO/8OZ//ALe5aSm31jpGH1fCfiZbZYfcx4+kx40bbWf3myvORmdb+pnUMjBY9ljbG7gD7mHdLaslrJ/RWt2+9jv/AElYu++s3U8rpfRr8zFq9W1kAaSGSYNzx+5WuQ+r31Ov6y2zqnWn2sZkBxpExa9zv+1Vm76NTf8AAs/w3/hf+frZ4kziMYPub8WwEf6zt/CskMfLZp81KMuSMuD2JeueTP8AN+rj+iy+qP1Zf1a39u9Wd69Tnl1VbjuNtjTDrcj/AIJj2/zP+F/8L/z/AGXV/rB0fodVd3VcpmKy0ltZcCS4gbnbW1tc72rhMK7rH1M623BtacjFyngBjQdtwJFbbsYfm5TJa19X/W/9DcvStjXfSAMGRI7+Kdy3CIEURMH13vxMPxo5JZ45DkjkwZI3y3t/JHD+5wfoyj+m4OT9fPqpRg42Zbmn7P1BthxHtpudvFTvRu9jadzdlnt/S7ECj639L6f0vprBRl5PrYVN1QxsV7xs2+m3Rn6Ot3s/m966Z/0HfA/69lW6UXHpmGXklxoqLi4uLidjZLnW2X2bv+Mvus/4WxTuU5Gd9cW4b62t6L1fLFtTLg/GxC9oFg3+lZvfXsvr/wANX/g0XP8ArQ/D6g/AZ0bqeVsLB9qooa6g7w10sufaz+b37bfZ7HrchKElOGfrHnjqn2FvRM41C4UnNisU7Sdv2n+c3+h/hPop6ev9Ts6p9hf0TLqo9V1f21xr9La3dtvjf6np2bVtwlCSnBwfrPm5OW3Gv6F1DEBDybrGVmsbGuftL2Wn3WbfTq/4RUmfWuvPzsd9nR+qYQw23ZJfl4oYHBtNm6rGO3Jtfku3eyqmzF3/AOlf/R7erhUc5zRn9NBIBNtm0EtBP6G36IddU53/AFunK/qV/wA9WlOfhfXn6tZjL3tyjR9kYLckZFVlPptc4VNL3XMYz3WO9P2PWthdS6d1Ct1mBlU5dbTDn0WNsAPg41OcjWVV2sNdrBZW7RzHAEEfymuWTlfVLod2LfjY2OOnDJcx9luB+rWb6i51Fu6gNa59L372eoz6aSnZSXL25fVPqjgVuzrL+udOba85Gc4NGRi48MbjerUwb+obHb/tWV7Lf8J6a6Si6rIorvoeLabWh9djTLXNcNzHtcPpNc1JTk/Wv+g4f/py6f8A+3eOsx3/AOVVn/pi/wDdpy0/rX/QcP8A9OXT/wD27x1mO/8Ayqs/9MX/ALtOSU//0eob/wDlVd/6Yv8A3aatP6pf8jO/8OZ//t7lrMb/APlVd/6Yv/dpq1Pql/yMf/Dmf/7e5aSnYhMQVJJJTHbxPbUfHhOnSSUxf9B3wP8Arw5VukAt6VhtIgjHqERtj2N/NNWJt/8AYXG/8L0/zasvEscOZB0WRidZ6N07peFXm52NiEY9UMttqr/MbG1rX+n/ANtfo/8ARpKdlJY9f1v+qtrgxnV8IuPAN9YmfDc4LUpvpvYLKLG21nh7CHNP9pqSkiSSSSlKnmb/ALbgbd231H743xHpW/T9Nza/pf6ff/24rio5rQc/pxidttkGAY/Q2/nehfs/9iMP/jLf6PalN5JJJJTF7WvaWuAc1whzSJBB5BCxPqnf1eyjqNXVRaX43UcmnGtvZsdbjhzX49zfbWx9bvU21vqb6S3DwsP6nVdWHR/X6z6rc/LvvvtoucXmkPscKcerV2yhlLK3V1t/fSUz+tf9Bw//AE5dP/8AbvHWY7/8qrP/AExf+7Tlp/Wv+g4f/py6f/7d46zHf/lVZ/6Yv/dpySn/0uob/wDlVd/6Yv8A3aarf1Y6jg4/TDRdfXXaczNhjnAH352WyvT+W5VG/wD5VXf+mL/3aatP6pf8jHWP1zP/APb3LSU3G9b6S4Aty6Tugth413Cgs/zvt2H/AOxNSY9d6OGl5zKdoBcTvHAbZdP/AG1j3Wf9aWf9Yvrt9Xvq4C3Pyd2SBIw6YsuP0T7q5a2n2u3N+0Pp3rmxlf4xvreR9lZ/zX6O/wDwz5OU9p26s/m7/wDhKvTbhM2f9qbklPT9Z+uv1a6LW52dnVixpc0Y9Z9S4uaXscz0a5cz9JVZV6lvp1ep/hFyj/8AGL9Y+t2+j9WelsxqHGBn9RcGNhxpqaWN3V0+q23Kx/0bLs3+ep/RfpFudC/xa/VrpLhk3VHqWefc/Ky4s959z3soP6Fv6T3se/1bv+GXUuIaC4mANST4BJT4l9an/WZ9mPg5P1hd1XqmYA9+DgnZiso2es2/ItYcWlu+r9P78X9Hi/rd9/pbPV3vq5/i4+p1ONXd1rNZ1DKsbLqWWGqls+q3Y30izJsdXZiZf6T1K/5j+Y9i0P8AFnQ/qt3V/rlmNP2zqNz6ceST6dLQ12ys/u/zVH83/wBpFTpzPrF9cc8dC6RlP6T0Xo9ddOfmVy2624N9M1Mb6eFbt312Vsq9HFr9P1MjJr/o+Ekp18n6hf4t7q/S+zsoe6GNsrvtDg5xprZt32Or378vF2+ox/8AP1rgOv8A1VP1Zyq+qdE6pbd0lzmerk4rwMqhj9jmueyp9DbmPqup9G/9DU+2z0rfQ/Rer2WV/i0z+kUvzfql1fNq6iw+p6N9jTXeR7vSftZTVud/3ZZdS/8Awuz+dW79Uev1/W76v2jPpDMhpfh9SxSCBuI2v9h/SNrurf8AnfQf6tX+DSU8rj9U+vXS8ZmX07q+F9ZunOr9SllxDMg1H1rPU22GjI9fbiZf6F2Vk2s+zXs9H9Ctfpf+Nfo1t/2PreNd0TMkgtvBfVO702t9VrGWs/l+rj11V/6ZQ/xaOyOm5fW/qpe5zmdJyd+I55lxqtL/AM0exjHbKsja3/CZNi6/qfR+l9Xx/s3U8avLp1htjQS0kRurf9Op/wDLrckpi3rvR31C5mbQ+p07bG2Ncw7QxzttjZY7b6taq5vVulnNwn/aaopfa+w7m+1raspr3e6yt3t+y5P0Kr/5mz6H84uZyP8AF31Xotr8z6k9VswXOO52BkHfQ86j6Tg9vtZ/N/aKL/8AwxWh0f4wsvBz8XD+ueDb0bIqc8nJqD341oLHt+jVY72s30/Q/aVfq/8Acb6dSU9t+2Ol7/T+1Vb92zbuE7t4o2/9vPbUot650hzQ5uZSWuAcDvGocKbGn+0zMxXf9frVnFy8XMx2ZOJczIos1ZbU4PY6DtO17Ja73BSttrpqfdc9tdVbS+yx5DWta0bnve930Wtakp5r63Z2L1LpTukYfUsbHfnf0h77Q14w63H9pW47I/TPrpqt31u2foftH+jWzR1Lo2PXXiU5FTGUxTXXv42u+ytr1/dsr9JZn1cx8bqmfb9cWvteOo0Mowab6/SfRj1ud6jPbZZ6rcy9v2ttn7i6KPNJTzv1h6lgZeHhsxsiu5x6h094axwJ2/acG3f/AFfTzMV//X6lVd/+VRn/AKYv/dpy0/rV/QcP/wBOXT//AG7x1mO//Koz/wBMX/u05JT/AP/T6hv/AOVV3/pi/wDdpqP0jp7+pfVi3DZlZGCbMzO/WMVwZa2M3LPtsLX7d356A3/8qrv/AExf+7TVqfVL/kY/+HM//wBvctJT5/jfVn6w/UPqNnU2dMo+suI5285TWn7XUQD762H1347nOfutsrryv0bP56ldx9Xfr39W/rDtrwsn0sp3/aPIiu7876DZdXf7Wb/1ey3Z/hF0BAK536xfUH6t/WEuty8b0Mt3OZjkV2njWzR1V/0dn6eqz2fQSU9FKrdTxXZnTsrDY7Y7Jpsqa/wL2Or3f2dy4YYv+Mr6pCcS1v1m6VX/AIGyftLWCHO2STfu/wAHU2u3N/8AC60Ok/40vq5mW/Zeper0fNaQyynLaQwP/Ob64Hs2/wDdlmMkpH/iiyqrPqYxjTri33V2TpBJGR/1FzFnf4qM3H6fZ1L6s5LhVnNyDlUBxaBdU9jNr6PT3Vv/AEVdeR+ifsfRd6tP6JBrzqvqX9aMjPY4XfVP6xO3Ny6HCyui87rP8B+axz7f0Vf08T+bfdZhvrXQdS+pPSfrL07p2Y+1+N1Gmil1HUcZ8vJDA6svsNuV9oY1/wCkrt+13XfuZv8ApEp6jLy8bDxrMrKsbTj0tL7LHmGtaO5XE/4rm2ZT+v8AXwx9eL1fPfZjMsEHaHW2l/7rv6T6W5jv5yl6hX/ity8qxrfrD9Yc3q2HW4Pbiuc9oLhw57rr8r83ez9Gz1P+GWr9aPrH076ndHqwen1N+3WM9HpmBWJMn2MsfWPf6TX/APXMi39Gkpy/qsBm/wCM76zdRoeTRj114jx2Nn6Kp3/bb8C9i75cD9Vbei/UboR/5wdQpq6tmv8AtOdWXereHP8A5qp1VQfkv9Nv867Z6f2iy/8AS+moP/xh9e6651H1M6Nbe3Vp6hlgMqaR9PTc2nd+fX6mVv8A+6ySnu8nLxcOh2Tl3V49Ff07bXBjGydo3WPLWt9y896/9dsP6xZFXSfq30v/AJwXMcXE5FTfsgJbsa57clnrezdZ+l9Xp3v/AMPdV+jVnE/xa5nVchuf9dupWdUyGkluJS4sobPtc3c1tTmtftr3NxasT9J/pV1IwcDpt3S8LBpqxaBbZsprDGAn0bZcGmyt9ln77668i3/Sf6VJTy/1G/xd9R6Ff+0M3qNlNj3B7un4biMc8wzKNu77Rta/9z9F/p7Ftdczcfq3VW/VBlJyqsil1vVrGWmo49Pt+z++v6VuRbt/V/8AQ/ztf2e1bPVc2zA6dkZlWPZmWUVl7MakFz7HfmVsDQ93ud/IVT6uYnUaun15PWPTd1fJaHZljGMYRq99OIXU/wA4zDbb6TPfZ/hElOnTVVRSymljaqqmhldbAGta1o2sYxrfa1jWqaSSSnF+tf8AQcP/ANOXT/8A27x1mO//ACqs/wDTF/7tOWn9a/6Dh/8Apy6f/wC3eOsx3/5VWf8Api/92nJKf//U6hv/AOVV3/pi/wDdpq1Pql/yMf8Aw5n/APt7lrLb/wDlVd/6Yv8A3aatT6pf8jH/AMOZ/wD7e5aSnZSSSSUsqPVeg9G6zV6XU8OnLG0ta6xo3tB+l6Vw/TU/9aer6SSnz7qn+JzoV7LT0zKyOn+oQ70Z9ekbQY/RP2Xv+l7d+S9ZvRfqX/jG6Litf0LrFAxrKxYMa71AJcPULW4uZjP9Cxzj/wB1rf8ATemvUXxsdPEH/XVVOjbf2Rg7I2/Zqdu3btjY2Nvo/odv/Ffo/wBxJTxX2b/HJmA1HKwcAQZt9hmfzfbVlua7+wqGJ/ie6lk5Qz+udbc/KLw611IdZY7bG1zc3Icx7bG7fZ+r+xeopJKeU6R/iy+p/S4d9iGba2R6uYfWkHxohmJ7fzf1feupa1rWhrQGtaAGtGgAHYKSSSlKlmF4zcANLoNlm4Aug/orfp7LGV/S/wBNXf8A9ufpFdXPfWvNZRb03EY97MzqNtmLi2Uta+2p1tNlP25tT2bnU4brGWZHp5GLsr/0n8ykpEMd3X/rJR1FuVXZ0joxe2mqiwlzs+XU3/bGgDb9lp/mq/8AhvU9T0brKl0yo9E6RjdF6TjdLxR+ixWBgd3c76Vlrv5d1pfa5XklKSSSSU4v1r/oOH/6cun/APt3jrMd/wDlVZ/6Yv8A3actP61/0HD/APTl0/8A9u8dZjv/AMqrP/TF/wC7TklP/9XqG/8A5VXf+mL/AN2mrU+qX/Ix/wDDmf8A+3uWstv/AOVV3/pi/wDdpqt/Vjp+Lf0z1rA8vGZmgbbHtHszst7PZW9rPpJKeiSVFvRentDQG2e2AP01p+j6Ab/hf+6WP/4J/p7/AFWPROnFhYW2bS0tP6a7gtsp59X/AEd9v+tdaSm+kqR6Rgl5eW2bi4uP6a3kusu49T/SX2/611pm9GwGlpDbPbBH6a0/R9At/wAL/wB0sf8A8E/09/qpTcfOx0cwf9eWqt0kk9LwySSTRUSSSSfY3lzrcpzv/YrJ/wCPu/nEI9G6e2stDbIDdoHrXcbHU/6Td/Nu/wDRn84gdM6Phu6dimxtoeaay8G25pktse72O+zOZ78u/wBrsbH/AOIp9GmulKddJUm9HwGuDg2yWkOH6a06tNNjf8J+9iUf63XeoK7pPSaMd77i+uiqs+o9+Ra1ra2sFTnvsdd7WspZ7rP+upKdJJeTu/xm9Df9ZDjnHs/YDprOX6l4u3uN+7N9L1f6J+u5H6ts+0el6d/85RRhVek09N6ba2vIpLrGv2212Nvsc1wLqr2PZFux7HOoqd+5s/4OyxJTfXJYeZhdZ+tBzhQAek5V3TcTIdbrYRQ+3P2Yb31tY6m3az16G3vvp/4Kr1GavUsLp3Tel5ObtsLcLHfbHr3cU1M/O9Xd9DFq/wDO7LFmdDwqb+k9FuspZQeo1m7IqxTbTV+npyL/AGVV5LGVv/W37rNl38j0vSx/s6U9Wkqf7Jwd++LN27f/ADtvO8X8ep/pGf8Aov8Am1BvROntaGhtkNAA/TXcNFNbf8L+7iUf63XeolN9JUHdE6e5paW2Q4EH9Ndw4XVu/wAL+7l3/wCtNPpz/ZODv3xZu3b/AOdt53m/j1P9I/8A9F/zaSmj9a/6Dh/+nLp//t3jrMd/+VRn/pi/92nK19YenYuJiYbqA8EdQ6ez3WWPEfacGv6Nr3/mYlHu/wCM/wBPf6lV3/5VGf8Api/92nJKf//W6hv/AOVV3/pi/wDdpq1Pql/yMf8Aw5n/APt7lrLb/wDlVd/6Yv8A3aatT6pf8jH/AMOZ/wD7e5aSnZSQcvKx8PFty8l/p0UMdZa8gmGtG5x2tlzv7Kp1ddwja6jL3dPvDRY2rLNbC9jg93qVOZZZW/b6Nvq17/Wp2fpqq/0W9KdJZvXvrB0zoHT35/UbfTqboxg1ssf+bTRXpvsd/mM/wvp1qp1z64dH6TiWWMurzcsN3V4lNjC4y0WssufLm4uL6b2W2ZVv6P0v9J+irs8f65i/Wb6yZz8/OvrvsaC4VVPBrprmNtVW53pVNdtbuf73/wCF/SWJKbL/APGv9YndfHVAQMITX+yiSaTST9Fzo/pX532zb9P/AAf2b9WXq/1N690rrXQ8Z/T3gHHqrqvx/aH1Oa0N9N7K2Us2+39G+qmqmz/Bf6NeGn6qZzQ9z7KgKmmyz3tJawBrzY5rXF23ZZW/+pZWtz6tdC+snSOpUZvS7mV5ZurxnNc9prIu3RXm1Ndvdi2eg/ds/Tez1aP0tXsSn3JzmtBLiAAJJPELxT/GT/jAPWrX9I6XZHS6nfpbG6faHtP/ALbVu/mm/wCEf+m/0S3/AK+/WPqHWG2dB6JbW3Gn0s3ID2tddZ7W/ZMdm/f9n3PZ6v8A3I9Sqr+Y/pPnp+qfUQQC6sOc4sa0vaCXDbuY1u76TfUr/wC3K/8ASJKcSdZXoP8Ai1/xgHpFjOi9Wt/yZYYovdxQ9x4cf+4tjvpf6F/6T/SLkz9XM9ry120Q7aXEiNxO0M3T9NzvzEY/VPqTWB7zW1jmh7XFzQ0tcQ1ljXbtrmPc5u16Sn3f61dZxej9Ay827IGM70nsxnwHk3va77Oyql3tvs3+70/5vZ+kt/Q+ovK/q/8A40+pN61jW/WB7bsBoaw+nWwGkis45ya2tZv/AEm/1cqur/rH6P8AVkTAxreo9Hb9XvrM9rKMYO/ZXVnOG7Ee0+k/GyZPvwHWM9B//cV9fo/Qrp+ycvZ9U+pU5Bx7XVseAHMcXt22MdHp349hdtvx7d7PSuZ+/wD6RJT9GY+RTk0syKLG202tD67GHc1zXDc17HN+k1yIvI/qJ1nrH1XacfqThd0Jw9ZxDg51DXED7ZjtaXepiPsf+nrZ/wAbR+l/R3+k5X1i6RivqbZk1ua+xtdljbK9tO+u3JqsynOsb6VV1eO/0n/npKdNJMCHAEGQdQQnSU4v1r/oOH/6cun/APt3jrMd/wDlVZ/6Yv8A3actP61/0HD/APTl0/8A9u8dZjv/AMqrP/TF/wC7TklP/9fqG/8A5VXf+mL/AN2mrU+qX/Ix/wDDmf8A+3uWstv/AOVV3/pi/wDdpq0/ql/yMf8Aw5n/APt7lpKdTMxMbOxLsPKZ6mPkMdXaySJa4bXDc3a9v9Zi4f65dW6B9X/SGdl5HUOsTUaAXVepXXXv9123H+z1UXetb6v6v9oyv0f+grtxp/X/APxkY/Q67Om9Je27rDhtc/RzMefz7PzbMn/RUfmfzmR/obvFMjIvyr7MjIsddda4usseS5znHlz3O+kkp7TG+stVuUGYFNr63sbVYC9peWspb09m17KGbXfZa2NdvrtV676y4FW219F9xdBa8WVubLfsOx7NmNsd6VnRMD6fq1/o767a7PV/R4H1PzOn49n604Mex9VrHEvZPp2122Verj7rK/Vpbaz6Oz/z4uyxsdnWb7MDCyKsi7IfZkekx9nsD7uoXXWevZjWfYq/1/pr/wCa9O/IwLMfZ+sfpkpq9L6s7ruWOm9PwrnPyA4PYx1dVNTHYzek23ONWL+rVV4ja/T2f9qPZVVZ/Rk3XfrD02rqGRX0yzJz7XPrddm7mCt91D77Wtxm+k578VtmZkM/nfez9Dj2ehWrB6n9XcPIycPpee00vpqxsu4OsY251V3r5fp+gyzH9LMxrL8KvLrb6uN/gv1e310BuZ0FtrXHMJrF2M4gX2tJx66hVm0baceqtl92U37T+i9P1P8AB34382kpqM+tFAY591F4Nwh3pvrLD7MSl231Ma327el4n+E/0v76sP6/02yk2ht+219z82u14dZa2+ivBeyu9uP+jY6uiv1/f9p/0N+9EGf0dzmWZOTVc7bWMgG28G01vyvWHrtpY6izJryMO/7XVV6vq4luNf6fr+u8N+R0oYNln2k5N7XY4bY1z/Rj0W4+YMjDihtPrXtzM2l9Xq/rP2Ov2fzKSmri/Wz1c2wUY1ja7LWXBjC0bX121ZlfpsFPoNr+0Y7LbK2UfpLPVs/nbfUU8n6yYmLpVhOvFlZpt9QsdvY5j6HRZXTVbU92Nf6XqY1lTLa/St9P1f0ts+jdT6HRYy5lwpLHM3BxeHAMs9S5zfSa9mT9sxP1T9N+lw7/ANcx/wBIli9Q6K5mDRdkNrdhtbVbaHWv3htJoY9rXtb9opryvQyfs+Q7H/QepjfzX6FJSGv6x1ZVVrLcN++zHOPfc5zNxZ6VmM7IN+RTfZTkfZrrftF7LPTt/nLaf5xbHSutnq19PT+qWvx8qprqum5O5gqe6yzFza8PNc6rI9Jz7cHF+y2Mb/Nfotn8x6oqs/ArrrFHUKWuNdrMjfZadzraL8VwrLMWvdjfaLcfKq9av7TT+sV/zf2ehSsy+j5Jc2+8W0+hbU2vHss9Wtpx8KuqzFHp013vxLsHOfTj2/8Acqr0/wDCVVpTndR+s+HhZduLnY2VRmUtvx7a32sDmeu591xbsx9m71LGXVW1/oLvTqf+n/wk8P6/9KuyK6M5+RjYTr7L3PpNbzVZkNyasq5tdmPZY+i12fkX20fpX1P/AKL/ANxkPP8Asf1vqZ06yysfWOprn4mRudsvJLrbOlvsv3bfT3f5Ns9f/grPR/w/I/8ANL61A/8AI2f/AOw13/pNJT9F9Mrx6enYlOLb6+PXTWyi6Wu31ta1tdu+oNqf6jPfurb6atLxD6nWfX3o2fjY76eq4vSTY0Xs+x25DGMLvUs2Y1tf6Jr3O/Svxv03+E/TfzS9Sx+rfWGvq/2HP6QTh3WPbjdRxrW2Vhg3WV/a6bPTtx/0TffZ9D1v0dSSmf1r/oOH/wCnLp//ALd46zHf/lVZ/wCmL/3actP61f0HD/8ATl0//wBu8dZjv/yqs/8ATF/7tOSU/wD/0Oob/wDlVf8A+mL/AN2moeJmNo6Pk9JyGdUw735OZuvw8LIe9rbcvJvY7HyRi5FH6Wixn6arf9P9FstT9f8Aq99bLfrOOu/V/KxMcnCbhPGTvcSPVdkPhjarGf6L85C/Z/8AjZ/8s+l/9tv/APedJTzh/wAX/wBSHEucfrCSTJJw7pJ/9xib/wAb76j/AP0Qf+wd3/yMXSfs/wDxs/8Aln0v/tt//vOl+z/8bP8A5Z9L/wC23/8AvOkp5wf4v/qQOP8AnCP/AEDu/wDkYtRvRfq/jfV6/ofS/wBs4QzHA5mYOn5L772a/q99n2Nn6DY70/To9H/wfJ9e/wDs/wDxs/8Aln0v/tt//vOl+z/8bP8A5Z9L/wC23/8AvOkp5H/xvPq+AYyesyAYA6Xk8/8AsOo0/wCL7ojqa3W5HWmWFjS9h6XkAhxHvadlVzPa79y67/jbF2H7P/xs/wDln0v/ALbf/wC86X7P/wAbP/ln0v8A7bf/AO86Snkv/G8+r/8A3K6z/wC4zJ/9504/xfdBAj7V1n/3F5P/ALzrrP2f/jZ/8s+l/wDbb/8A3nS/Z/8AjZ/8s+l/9tv/APedJTyP/jd/V/8A7ldZ/wDcXk/+86X/AI3n1f8A+5XWf/cZk/8AvOuu/Z/+Nn/yz6X/ANtv/wDedL9n/wCNn/yz6X/22/8A950lPJf+N59X/wDuV1r/ANxmT/7zpv8AxvuiBzSzM6wGAn1Gu6XlEkR7fT/V9rdr/wB5dd+z/wDGz/5Z9L/7bf8A+86X7P8A8bP/AJZ9L/7bf/7zpKeTb/i+6C17bG5fWm2MIc146ZkggjVrmkY677pn1gqxMGrGyx1PNuqBacl/TctjniTs9RrMfbvaz2Of/hPprN/Z/wDjZ/8ALPpf/bb/AP3nS/Z/+Nn/AMs+l/8Abb//AHnSU7n/ADqwf+4nUf8A3H5n/vMl/wA6cD/uJ1H/ANx+Z/7zLD/Z/wDjZ/8ALPpf/bb/AP3nS/Z/+Nn/AMs+l/8Abb//AHnSU3er9Wr6pXh4uJiZ3q/b8K0m3CyamBlWRTfdZZdfRXUxtdVb/pPQnf8A5VGf+mL/AN2nKv8As/8Axs/+WfS/+23/APvOi9A+r31rq+s5679YMrEyCMJ2EwYwe0geq3IZLHVVs/0v5ySn/9n/7S7mUGhvdG9zaG9wIDMuMAA4QklNBAQAAAAAACgcAVoAAxslRxwCAAACAAAcAmcAFFlzYVU1VGFNQmZwUHF5cHc1ZWw1OEJJTQQlAAAAAAAQgkwgSp32tjXLQw6CN5HDSzhCSU0EOgAAAAAA5QAAABAAAAABAAAAAAALcHJpbnRPdXRwdXQAAAAFAAAAAFBzdFNib29sAQAAAABJbnRlZW51bQAAAABJbnRlAAAAAENscm0AAAAPcHJpbnRTaXh0ZWVuQml0Ym9vbAAAAAALcHJpbnRlck5hbWVURVhUAAAAAQAAAAAAD3ByaW50UHJvb2ZTZXR1cE9iamMAAAAMAFAAcgBvAG8AZgAgAFMAZQB0AHUAcAAAAAAACnByb29mU2V0dXAAAAABAAAAAEJsdG5lbnVtAAAADGJ1aWx0aW5Qcm9vZgAAAAlwcm9vZkNNWUsAOEJJTQQ7AAAAAAItAAAAEAAAAAEAAAAAABJwcmludE91dHB1dE9wdGlvbnMAAAAXAAAAAENwdG5ib29sAAAAAABDbGJyYm9vbAAAAAAAUmdzTWJvb2wAAAAAAENybkNib29sAAAAAABDbnRDYm9vbAAAAAAATGJsc2Jvb2wAAAAAAE5ndHZib29sAAAAAABFbWxEYm9vbAAAAAAASW50cmJvb2wAAAAAAEJja2dPYmpjAAAAAQAAAAAAAFJHQkMAAAADAAAAAFJkICBkb3ViQG/gAAAAAAAAAAAAR3JuIGRvdWJAb+AAAAAAAAAAAABCbCAgZG91YkBv4AAAAAAAAAAAAEJyZFRVbnRGI1JsdAAAAAAAAAAAAAAAAEJsZCBVbnRGI1JsdAAAAAAAAAAAAAAAAFJzbHRVbnRGI1B4bEBSAAAAAAAAAAAACnZlY3RvckRhdGFib29sAQAAAABQZ1BzZW51bQAAAABQZ1BzAAAAAFBnUEMAAAAATGVmdFVudEYjUmx0AAAAAAAAAAAAAAAAVG9wIFVudEYjUmx0AAAAAAAAAAAAAAAAU2NsIFVudEYjUHJjQFkAAAAAAAAAAAAQY3JvcFdoZW5QcmludGluZ2Jvb2wAAAAADmNyb3BSZWN0Qm90dG9tbG9uZwAAAAAAAAAMY3JvcFJlY3RMZWZ0bG9uZwAAAAAAAAANY3JvcFJlY3RSaWdodGxvbmcAAAAAAAAAC2Nyb3BSZWN0VG9wbG9uZwAAAAAAOEJJTQPtAAAAAAAQAEgAAAABAAEASAAAAAEAAThCSU0EJgAAAAAADgAAAAAAAAAAAAA/gAAAOEJJTQQNAAAAAAAEAAAAHjhCSU0EGQAAAAAABAAAAB44QklNA/MAAAAAAAkAAAAAAAAAAAEAOEJJTScQAAAAAAAKAAEAAAAAAAAAAThCSU0D9QAAAAAASAAvZmYAAQBsZmYABgAAAAAAAQAvZmYAAQChmZoABgAAAAAAAQAyAAAAAQBaAAAABgAAAAAAAQA1AAAAAQAtAAAABgAAAAAAAThCSU0D+AAAAAAAcAAA/////////////////////////////wPoAAAAAP////////////////////////////8D6AAAAAD/////////////////////////////A+gAAAAA/////////////////////////////wPoAAA4QklNBAAAAAAAAAIAAjhCSU0EAgAAAAAACAAAAAAAAAAAOEJJTQQwAAAAAAAEAQEBAThCSU0ELQAAAAAABgABAAAAAjhCSU0ECAAAAAAAEAAAAAEAAAJAAAACQAAAAAA4QklNBB4AAAAAAAQAAAAAOEJJTQQaAAAAAANnAAAABgAAAAAAAAAAAAABWgAAAVkAAAAZAEkAbQBhAGcAZQAgAC0AIABNAGEAcAAgAGEAbgBkACAAVABlAHIAcgBpAHQAbwByAHkAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAVkAAAFaAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAEAAAAAAABudWxsAAAAAgAAAAZib3VuZHNPYmpjAAAAAQAAAAAAAFJjdDEAAAAEAAAAAFRvcCBsb25nAAAAAAAAAABMZWZ0bG9uZwAAAAAAAAAAQnRvbWxvbmcAAAFaAAAAAFJnaHRsb25nAAABWQAAAAZzbGljZXNWbExzAAAAAU9iamMAAAABAAAAAAAFc2xpY2UAAAASAAAAB3NsaWNlSURsb25nAAAAAAAAAAdncm91cElEbG9uZwAAAAAAAAAGb3JpZ2luZW51bQAAAAxFU2xpY2VPcmlnaW4AAAANYXV0b0dlbmVyYXRlZAAAAABUeXBlZW51bQAAAApFU2xpY2VUeXBlAAAAAEltZyAAAAAGYm91bmRzT2JqYwAAAAEAAAAAAABSY3QxAAAABAAAAABUb3AgbG9uZwAAAAAAAAAATGVmdGxvbmcAAAAAAAAAAEJ0b21sb25nAAABWgAAAABSZ2h0bG9uZwAAAVkAAAADdXJsVEVYVAAAAAEAAAAAAABudWxsVEVYVAAAAAEAAAAAAABNc2dlVEVYVAAAAAEAAAAAAAZhbHRUYWdURVhUAAAAAQAAAAAADmNlbGxUZXh0SXNIVE1MYm9vbAEAAAAIY2VsbFRleHRURVhUAAAAAQAAAAAACWhvcnpBbGlnbmVudW0AAAAPRVNsaWNlSG9yekFsaWduAAAAB2RlZmF1bHQAAAAJdmVydEFsaWduZW51bQAAAA9FU2xpY2VWZXJ0QWxpZ24AAAAHZGVmYXVsdAAAAAtiZ0NvbG9yVHlwZWVudW0AAAARRVNsaWNlQkdDb2xvclR5cGUAAAAATm9uZQAAAAl0b3BPdXRzZXRsb25nAAAAAAAAAApsZWZ0T3V0c2V0bG9uZwAAAAAAAAAMYm90dG9tT3V0c2V0bG9uZwAAAAAAAAALcmlnaHRPdXRzZXRsb25nAAAAAAA4QklNBCgAAAAAAAwAAAACP/AAAAAAAAA4QklNBBQAAAAAAAQAAAAGOEJJTQQMAAAAACV5AAAAAQAAAKAAAACgAAAB4AABLAAAACVdABgAAf/Y/+0ADEFkb2JlX0NNAAH/7gAOQWRvYmUAZIAAAAAB/9sAhAAMCAgICQgMCQkMEQsKCxEVDwwMDxUYExMVExMYEQwMDAwMDBEMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMAQ0LCw0ODRAODhAUDg4OFBQODg4OFBEMDAwMDBERDAwMDAwMEQwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAz/wAARCACgAKADASIAAhEBAxEB/90ABAAK/8QBPwAAAQUBAQEBAQEAAAAAAAAAAwABAgQFBgcICQoLAQABBQEBAQEBAQAAAAAAAAABAAIDBAUGBwgJCgsQAAEEAQMCBAIFBwYIBQMMMwEAAhEDBCESMQVBUWETInGBMgYUkaGxQiMkFVLBYjM0coLRQwclklPw4fFjczUWorKDJkSTVGRFwqN0NhfSVeJl8rOEw9N14/NGJ5SkhbSVxNTk9KW1xdXl9VZmdoaWprbG1ub2N0dXZ3eHl6e3x9fn9xEAAgIBAgQEAwQFBgcHBgU1AQACEQMhMRIEQVFhcSITBTKBkRShsUIjwVLR8DMkYuFygpJDUxVjczTxJQYWorKDByY1wtJEk1SjF2RFVTZ0ZeLys4TD03Xj80aUpIW0lcTU5PSltcXV5fVWZnaGlqa2xtbm9ic3R1dnd4eXp7fH/9oADAMBAAIRAxEAPwDp+tda+tZ+tY6B0D7CIwW5r35ot/0rsZ7Wvx3f8X/g0+3/ABq/v9C/9mv/ACKTf/yqu/8ATF/7tNU+h9BwOqYVmbmvyrMizLzWuc3MyqxFeVk0VNbVRkV1M2VVsZ7GJKYbf8av7/Qv/Zr/AMilt/xq/v8AQv8A2a/8il1zp/1X6HjsvzPt7ha7ZXXVm5jnkxucfdm1t2t/rq3hfV76t5+LXl4tmVbTaJY4Z+b/AJrmnL9r2/ntQ4hZjYsdF5xZBjGUwkMciYxnXoMo7jiam3/Gr+/0L/2a/wDIpbf8av7/AEL/ANmv/IqHUsb6m9MyqsTMyMpl1saDOznBoP0X3Oblfo2uWqPqj0Q/9y//AGPzf/etIEEkA7boljnGMZSjKMcguEiKjMDrEubt/wAav7/Qv/Zr/wAilt/xq/v9C/8AZr/yK0nfVHooaT+uHTj7fm/+9RVfpv1T6O/p2K9/2wPdTWXD7dmt1LWz7PVxNv8A7C43/hen+bRWtXb/AI1f3+hf+zX/AJFLb/jV/f6F/wCzX/kVp/8ANDov/dz/ANj83/3rS/5odF/7uf8Asfm/+9aSnM2/41f3+hf+zX/kUtv+NX9/oX/s1/5Faf8AzQ6L/wB3P/Y/N/8AetL/AJodF/7uf+x+b/71pKczb/jV/f6F/wCzX/kUtv8AjV/f6F/7Nf8AkVp/80Oi/wDdz/2Pzf8A3rVbI+q3Sq8nFrYMssue5tp+25zoDWPsb7xlbav0jG/TSU1dv+NX9/oX/s1/5FLb/jV/f6F/7Nf+RWn/AM0Oi/8Adz/2Pzf/AHrS/wCaHRf+7n/sfm/+9aSnM2/41f3+hf8As1/5FLb/AI1f3+hf+zX/AJFaf/NDov8A3c/9j83/AN60v+aHRf8Au5/7H5v/AL1pKczb/jV/f6F/7Nf+RTdF619ax9az0Dr4wSDgnNY/CFv+lbjsa5+Q4eFn+DROsdDwel14eXhPymX/AG/Cr3OzMqwbbMmiq5jqrsmyp7bKnvrdvYoO/wDyqM/9MX/u05JT/9DqG/8A5VXf+mL/AN2mrT+qX/Izv/Dmf/7e5azG/wD5VXf+mL/3aatP6pf8jO/8OZ//ALe5aSm31jpGH1fCfiZbZYfcx4+kx40bbWf3myvORmdb+pnUMjBY9ljbG7gD7mHdLaslrJ/RWt2+9jv/AElYu++s3U8rpfRr8zFq9W1kAaSGSYNzx+5WuQ+r31Ov6y2zqnWn2sZkBxpExa9zv+1Vm76NTf8AAs/w3/hf+frZ4kziMYPub8WwEf6zt/CskMfLZp81KMuSMuD2JeueTP8AN+rj+iy+qP1Zf1a39u9Wd69Tnl1VbjuNtjTDrcj/AIJj2/zP+F/8L/z/AGXV/rB0fodVd3VcpmKy0ltZcCS4gbnbW1tc72rhMK7rH1M623BtacjFyngBjQdtwJFbbsYfm5TJa19X/W/9DcvStjXfSAMGRI7+Kdy3CIEURMH13vxMPxo5JZ45DkjkwZI3y3t/JHD+5wfoyj+m4OT9fPqpRg42Zbmn7P1BthxHtpudvFTvRu9jadzdlnt/S7ECj639L6f0vprBRl5PrYVN1QxsV7xs2+m3Rn6Ot3s/m966Z/0HfA/69lW6UXHpmGXklxoqLi4uLidjZLnW2X2bv+Mvus/4WxTuU5Gd9cW4b62t6L1fLFtTLg/GxC9oFg3+lZvfXsvr/wANX/g0XP8ArQ/D6g/AZ0bqeVsLB9qooa6g7w10sufaz+b37bfZ7HrchKElOGfrHnjqn2FvRM41C4UnNisU7Sdv2n+c3+h/hPop6ev9Ts6p9hf0TLqo9V1f21xr9La3dtvjf6np2bVtwlCSnBwfrPm5OW3Gv6F1DEBDybrGVmsbGuftL2Wn3WbfTq/4RUmfWuvPzsd9nR+qYQw23ZJfl4oYHBtNm6rGO3Jtfku3eyqmzF3/AOlf/R7erhUc5zRn9NBIBNtm0EtBP6G36IddU53/AFunK/qV/wA9WlOfhfXn6tZjL3tyjR9kYLckZFVlPptc4VNL3XMYz3WO9P2PWthdS6d1Ct1mBlU5dbTDn0WNsAPg41OcjWVV2sNdrBZW7RzHAEEfymuWTlfVLod2LfjY2OOnDJcx9luB+rWb6i51Fu6gNa59L372eoz6aSnZSXL25fVPqjgVuzrL+udOba85Gc4NGRi48MbjerUwb+obHb/tWV7Lf8J6a6Si6rIorvoeLabWh9djTLXNcNzHtcPpNc1JTk/Wv+g4f/py6f8A+3eOsx3/AOVVn/pi/wDdpy0/rX/QcP8A9OXT/wD27x1mO/8Ayqs/9MX/ALtOSU//0eob/wDlVd/6Yv8A3aatP6pf8jO/8OZ//t7lrMb/APlVd/6Yv/dpq1Pql/yMf/Dmf/7e5aSnYhMQVJJJTHbxPbUfHhOnSSUxf9B3wP8Arw5VukAt6VhtIgjHqERtj2N/NNWJt/8AYXG/8L0/zasvEscOZB0WRidZ6N07peFXm52NiEY9UMttqr/MbG1rX+n/ANtfo/8ARpKdlJY9f1v+qtrgxnV8IuPAN9YmfDc4LUpvpvYLKLG21nh7CHNP9pqSkiSSSSlKnmb/ALbgbd231H743xHpW/T9Nza/pf6ff/24rio5rQc/pxidttkGAY/Q2/nehfs/9iMP/jLf6PalN5JJJJTF7WvaWuAc1whzSJBB5BCxPqnf1eyjqNXVRaX43UcmnGtvZsdbjhzX49zfbWx9bvU21vqb6S3DwsP6nVdWHR/X6z6rc/LvvvtoucXmkPscKcerV2yhlLK3V1t/fSUz+tf9Bw//AE5dP/8AbvHWY7/8qrP/AExf+7Tlp/Wv+g4f/py6f/7d46zHf/lVZ/6Yv/dpySn/0uob/wDlVd/6Yv8A3aarf1Y6jg4/TDRdfXXaczNhjnAH352WyvT+W5VG/wD5VXf+mL/3aatP6pf8jHWP1zP/APb3LSU3G9b6S4Aty6Tugth413Cgs/zvt2H/AOxNSY9d6OGl5zKdoBcTvHAbZdP/AG1j3Wf9aWf9Yvrt9Xvq4C3Pyd2SBIw6YsuP0T7q5a2n2u3N+0Pp3rmxlf4xvreR9lZ/zX6O/wDwz5OU9p26s/m7/wDhKvTbhM2f9qbklPT9Z+uv1a6LW52dnVixpc0Y9Z9S4uaXscz0a5cz9JVZV6lvp1ep/hFyj/8AGL9Y+t2+j9WelsxqHGBn9RcGNhxpqaWN3V0+q23Kx/0bLs3+ep/RfpFudC/xa/VrpLhk3VHqWefc/Ky4s959z3soP6Fv6T3se/1bv+GXUuIaC4mANST4BJT4l9an/WZ9mPg5P1hd1XqmYA9+DgnZiso2es2/ItYcWlu+r9P78X9Hi/rd9/pbPV3vq5/i4+p1ONXd1rNZ1DKsbLqWWGqls+q3Y30izJsdXZiZf6T1K/5j+Y9i0P8AFnQ/qt3V/rlmNP2zqNz6ceST6dLQ12ys/u/zVH83/wBpFTpzPrF9cc8dC6RlP6T0Xo9ddOfmVy2624N9M1Mb6eFbt312Vsq9HFr9P1MjJr/o+Ekp18n6hf4t7q/S+zsoe6GNsrvtDg5xprZt32Or378vF2+ox/8AP1rgOv8A1VP1Zyq+qdE6pbd0lzmerk4rwMqhj9jmueyp9DbmPqup9G/9DU+2z0rfQ/Rer2WV/i0z+kUvzfql1fNq6iw+p6N9jTXeR7vSftZTVud/3ZZdS/8Awuz+dW79Uev1/W76v2jPpDMhpfh9SxSCBuI2v9h/SNrurf8AnfQf6tX+DSU8rj9U+vXS8ZmX07q+F9ZunOr9SllxDMg1H1rPU22GjI9fbiZf6F2Vk2s+zXs9H9Ctfpf+Nfo1t/2PreNd0TMkgtvBfVO702t9VrGWs/l+rj11V/6ZQ/xaOyOm5fW/qpe5zmdJyd+I55lxqtL/AM0exjHbKsja3/CZNi6/qfR+l9Xx/s3U8avLp1htjQS0kRurf9Op/wDLrckpi3rvR31C5mbQ+p07bG2Ncw7QxzttjZY7b6taq5vVulnNwn/aaopfa+w7m+1raspr3e6yt3t+y5P0Kr/5mz6H84uZyP8AF31Xotr8z6k9VswXOO52BkHfQ86j6Tg9vtZ/N/aKL/8AwxWh0f4wsvBz8XD+ueDb0bIqc8nJqD341oLHt+jVY72s30/Q/aVfq/8Acb6dSU9t+2Ol7/T+1Vb92zbuE7t4o2/9vPbUot650hzQ5uZSWuAcDvGocKbGn+0zMxXf9frVnFy8XMx2ZOJczIos1ZbU4PY6DtO17Ja73BSttrpqfdc9tdVbS+yx5DWta0bnve930Wtakp5r63Z2L1LpTukYfUsbHfnf0h77Q14w63H9pW47I/TPrpqt31u2foftH+jWzR1Lo2PXXiU5FTGUxTXXv42u+ytr1/dsr9JZn1cx8bqmfb9cWvteOo0Mowab6/SfRj1ud6jPbZZ6rcy9v2ttn7i6KPNJTzv1h6lgZeHhsxsiu5x6h094axwJ2/acG3f/AFfTzMV//X6lVd/+VRn/AKYv/dpy0/rV/QcP/wBOXT//AG7x1mO//Koz/wBMX/u05JT/AP/T6hv/AOVV3/pi/wDdpqP0jp7+pfVi3DZlZGCbMzO/WMVwZa2M3LPtsLX7d356A3/8qrv/AExf+7TVqfVL/kY/+HM//wBvctJT5/jfVn6w/UPqNnU2dMo+suI5285TWn7XUQD762H1347nOfutsrryv0bP56ldx9Xfr39W/rDtrwsn0sp3/aPIiu7876DZdXf7Wb/1ey3Z/hF0BAK536xfUH6t/WEuty8b0Mt3OZjkV2njWzR1V/0dn6eqz2fQSU9FKrdTxXZnTsrDY7Y7Jpsqa/wL2Or3f2dy4YYv+Mr6pCcS1v1m6VX/AIGyftLWCHO2STfu/wAHU2u3N/8AC60Ok/40vq5mW/Zeper0fNaQyynLaQwP/Ob64Hs2/wDdlmMkpH/iiyqrPqYxjTri33V2TpBJGR/1FzFnf4qM3H6fZ1L6s5LhVnNyDlUBxaBdU9jNr6PT3Vv/AEVdeR+ifsfRd6tP6JBrzqvqX9aMjPY4XfVP6xO3Ny6HCyui87rP8B+axz7f0Vf08T+bfdZhvrXQdS+pPSfrL07p2Y+1+N1Gmil1HUcZ8vJDA6svsNuV9oY1/wCkrt+13XfuZv8ApEp6jLy8bDxrMrKsbTj0tL7LHmGtaO5XE/4rm2ZT+v8AXwx9eL1fPfZjMsEHaHW2l/7rv6T6W5jv5yl6hX/ity8qxrfrD9Yc3q2HW4Pbiuc9oLhw57rr8r83ez9Gz1P+GWr9aPrH076ndHqwen1N+3WM9HpmBWJMn2MsfWPf6TX/APXMi39Gkpy/qsBm/wCM76zdRoeTRj114jx2Nn6Kp3/bb8C9i75cD9Vbei/UboR/5wdQpq6tmv8AtOdWXereHP8A5qp1VQfkv9Nv867Z6f2iy/8AS+moP/xh9e6651H1M6Nbe3Vp6hlgMqaR9PTc2nd+fX6mVv8A+6ySnu8nLxcOh2Tl3V49Ff07bXBjGydo3WPLWt9y896/9dsP6xZFXSfq30v/AJwXMcXE5FTfsgJbsa57clnrezdZ+l9Xp3v/AMPdV+jVnE/xa5nVchuf9dupWdUyGkluJS4sobPtc3c1tTmtftr3NxasT9J/pV1IwcDpt3S8LBpqxaBbZsprDGAn0bZcGmyt9ln77668i3/Sf6VJTy/1G/xd9R6Ff+0M3qNlNj3B7un4biMc8wzKNu77Rta/9z9F/p7Ftdczcfq3VW/VBlJyqsil1vVrGWmo49Pt+z++v6VuRbt/V/8AQ/ztf2e1bPVc2zA6dkZlWPZmWUVl7MakFz7HfmVsDQ93ud/IVT6uYnUaun15PWPTd1fJaHZljGMYRq99OIXU/wA4zDbb6TPfZ/hElOnTVVRSymljaqqmhldbAGta1o2sYxrfa1jWqaSSSnF+tf8AQcP/ANOXT/8A27x1mO//ACqs/wDTF/7tOWn9a/6Dh/8Apy6f/wC3eOsx3/5VWf8Api/92nJKf//U6hv/AOVV3/pi/wDdpq1Pql/yMf8Aw5n/APt7lrLb/wDlVd/6Yv8A3aatT6pf8jH/AMOZ/wD7e5aSnZSSSSUsqPVeg9G6zV6XU8OnLG0ta6xo3tB+l6Vw/TU/9aer6SSnz7qn+JzoV7LT0zKyOn+oQ70Z9ekbQY/RP2Xv+l7d+S9ZvRfqX/jG6Litf0LrFAxrKxYMa71AJcPULW4uZjP9Cxzj/wB1rf8ATemvUXxsdPEH/XVVOjbf2Rg7I2/Zqdu3btjY2Nvo/odv/Ffo/wBxJTxX2b/HJmA1HKwcAQZt9hmfzfbVlua7+wqGJ/ie6lk5Qz+udbc/KLw611IdZY7bG1zc3Icx7bG7fZ+r+xeopJKeU6R/iy+p/S4d9iGba2R6uYfWkHxohmJ7fzf1feupa1rWhrQGtaAGtGgAHYKSSSlKlmF4zcANLoNlm4Aug/orfp7LGV/S/wBNXf8A9ufpFdXPfWvNZRb03EY97MzqNtmLi2Uta+2p1tNlP25tT2bnU4brGWZHp5GLsr/0n8ykpEMd3X/rJR1FuVXZ0joxe2mqiwlzs+XU3/bGgDb9lp/mq/8AhvU9T0brKl0yo9E6RjdF6TjdLxR+ixWBgd3c76Vlrv5d1pfa5XklKSSSSU4v1r/oOH/6cun/APt3jrMd/wDlVZ/6Yv8A3actP61/0HD/APTl0/8A9u8dZjv/AMqrP/TF/wC7TklP/9XqG/8A5VXf+mL/AN2mrU+qX/Ix/wDDmf8A+3uWstv/AOVV3/pi/wDdpqt/Vjp+Lf0z1rA8vGZmgbbHtHszst7PZW9rPpJKeiSVFvRentDQG2e2AP01p+j6Ab/hf+6WP/4J/p7/AFWPROnFhYW2bS0tP6a7gtsp59X/AEd9v+tdaSm+kqR6Rgl5eW2bi4uP6a3kusu49T/SX2/611pm9GwGlpDbPbBH6a0/R9At/wAL/wB0sf8A8E/09/qpTcfOx0cwf9eWqt0kk9LwySSTRUSSSSfY3lzrcpzv/YrJ/wCPu/nEI9G6e2stDbIDdoHrXcbHU/6Td/Nu/wDRn84gdM6Phu6dimxtoeaay8G25pktse72O+zOZ78u/wBrsbH/AOIp9GmulKddJUm9HwGuDg2yWkOH6a06tNNjf8J+9iUf63XeoK7pPSaMd77i+uiqs+o9+Ra1ra2sFTnvsdd7WspZ7rP+upKdJJeTu/xm9Df9ZDjnHs/YDprOX6l4u3uN+7N9L1f6J+u5H6ts+0el6d/85RRhVek09N6ba2vIpLrGv2212Nvsc1wLqr2PZFux7HOoqd+5s/4OyxJTfXJYeZhdZ+tBzhQAek5V3TcTIdbrYRQ+3P2Yb31tY6m3az16G3vvp/4Kr1GavUsLp3Tel5ObtsLcLHfbHr3cU1M/O9Xd9DFq/wDO7LFmdDwqb+k9FuspZQeo1m7IqxTbTV+npyL/AGVV5LGVv/W37rNl38j0vSx/s6U9Wkqf7Jwd++LN27f/ADtvO8X8ep/pGf8Aov8Am1BvROntaGhtkNAA/TXcNFNbf8L+7iUf63XeolN9JUHdE6e5paW2Q4EH9Ndw4XVu/wAL+7l3/wCtNPpz/ZODv3xZu3b/AOdt53m/j1P9I/8A9F/zaSmj9a/6Dh/+nLp//t3jrMd/+VRn/pi/92nK19YenYuJiYbqA8EdQ6ez3WWPEfacGv6Nr3/mYlHu/wCM/wBPf6lV3/5VGf8Api/92nJKf//W6hv/AOVV3/pi/wDdpq1Pql/yMf8Aw5n/APt7lrLb/wDlVd/6Yv8A3aatT6pf8jH/AMOZ/wD7e5aSnZSQcvKx8PFty8l/p0UMdZa8gmGtG5x2tlzv7Kp1ddwja6jL3dPvDRY2rLNbC9jg93qVOZZZW/b6Nvq17/Wp2fpqq/0W9KdJZvXvrB0zoHT35/UbfTqboxg1ssf+bTRXpvsd/mM/wvp1qp1z64dH6TiWWMurzcsN3V4lNjC4y0WssufLm4uL6b2W2ZVv6P0v9J+irs8f65i/Wb6yZz8/OvrvsaC4VVPBrprmNtVW53pVNdtbuf73/wCF/SWJKbL/APGv9YndfHVAQMITX+yiSaTST9Fzo/pX532zb9P/AAf2b9WXq/1N690rrXQ8Z/T3gHHqrqvx/aH1Oa0N9N7K2Us2+39G+qmqmz/Bf6NeGn6qZzQ9z7KgKmmyz3tJawBrzY5rXF23ZZW/+pZWtz6tdC+snSOpUZvS7mV5ZurxnNc9prIu3RXm1Ndvdi2eg/ds/Tez1aP0tXsSn3JzmtBLiAAJJPELxT/GT/jAPWrX9I6XZHS6nfpbG6faHtP/ALbVu/mm/wCEf+m/0S3/AK+/WPqHWG2dB6JbW3Gn0s3ID2tddZ7W/ZMdm/f9n3PZ6v8A3I9Sqr+Y/pPnp+qfUQQC6sOc4sa0vaCXDbuY1u76TfUr/wC3K/8ASJKcSdZXoP8Ai1/xgHpFjOi9Wt/yZYYovdxQ9x4cf+4tjvpf6F/6T/SLkz9XM9ry120Q7aXEiNxO0M3T9NzvzEY/VPqTWB7zW1jmh7XFzQ0tcQ1ljXbtrmPc5u16Sn3f61dZxej9Ay827IGM70nsxnwHk3va77Oyql3tvs3+70/5vZ+kt/Q+ovK/q/8A40+pN61jW/WB7bsBoaw+nWwGkis45ya2tZv/AEm/1cqur/rH6P8AVkTAxreo9Hb9XvrM9rKMYO/ZXVnOG7Ee0+k/GyZPvwHWM9B//cV9fo/Qrp+ycvZ9U+pU5Bx7XVseAHMcXt22MdHp349hdtvx7d7PSuZ+/wD6RJT9GY+RTk0syKLG202tD67GHc1zXDc17HN+k1yIvI/qJ1nrH1XacfqThd0Jw9ZxDg51DXED7ZjtaXepiPsf+nrZ/wAbR+l/R3+k5X1i6RivqbZk1ua+xtdljbK9tO+u3JqsynOsb6VV1eO/0n/npKdNJMCHAEGQdQQnSU4v1r/oOH/6cun/APt3jrMd/wDlVZ/6Yv8A3actP61/0HD/APTl0/8A9u8dZjv/AMqrP/TF/wC7TklP/9fqG/8A5VXf+mL/AN2mrU+qX/Ix/wDDmf8A+3uWstv/AOVV3/pi/wDdpq0/ql/yMf8Aw5n/APt7lpKdTMxMbOxLsPKZ6mPkMdXaySJa4bXDc3a9v9Zi4f65dW6B9X/SGdl5HUOsTUaAXVepXXXv9123H+z1UXetb6v6v9oyv0f+grtxp/X/APxkY/Q67Om9Je27rDhtc/RzMefz7PzbMn/RUfmfzmR/obvFMjIvyr7MjIsddda4usseS5znHlz3O+kkp7TG+stVuUGYFNr63sbVYC9peWspb09m17KGbXfZa2NdvrtV676y4FW219F9xdBa8WVubLfsOx7NmNsd6VnRMD6fq1/o767a7PV/R4H1PzOn49n604Mex9VrHEvZPp2122Verj7rK/Vpbaz6Oz/z4uyxsdnWb7MDCyKsi7IfZkekx9nsD7uoXXWevZjWfYq/1/pr/wCa9O/IwLMfZ+sfpkpq9L6s7ruWOm9PwrnPyA4PYx1dVNTHYzek23ONWL+rVV4ja/T2f9qPZVVZ/Rk3XfrD02rqGRX0yzJz7XPrddm7mCt91D77Wtxm+k578VtmZkM/nfez9Dj2ehWrB6n9XcPIycPpee00vpqxsu4OsY251V3r5fp+gyzH9LMxrL8KvLrb6uN/gv1e310BuZ0FtrXHMJrF2M4gX2tJx66hVm0baceqtl92U37T+i9P1P8AB34382kpqM+tFAY591F4Nwh3pvrLD7MSl231Ma327el4n+E/0v76sP6/02yk2ht+219z82u14dZa2+ivBeyu9uP+jY6uiv1/f9p/0N+9EGf0dzmWZOTVc7bWMgG28G01vyvWHrtpY6izJryMO/7XVV6vq4luNf6fr+u8N+R0oYNln2k5N7XY4bY1z/Rj0W4+YMjDihtPrXtzM2l9Xq/rP2Ov2fzKSmri/Wz1c2wUY1ja7LWXBjC0bX121ZlfpsFPoNr+0Y7LbK2UfpLPVs/nbfUU8n6yYmLpVhOvFlZpt9QsdvY5j6HRZXTVbU92Nf6XqY1lTLa/St9P1f0ts+jdT6HRYy5lwpLHM3BxeHAMs9S5zfSa9mT9sxP1T9N+lw7/ANcx/wBIli9Q6K5mDRdkNrdhtbVbaHWv3htJoY9rXtb9opryvQyfs+Q7H/QepjfzX6FJSGv6x1ZVVrLcN++zHOPfc5zNxZ6VmM7IN+RTfZTkfZrrftF7LPTt/nLaf5xbHSutnq19PT+qWvx8qprqum5O5gqe6yzFza8PNc6rI9Jz7cHF+y2Mb/Nfotn8x6oqs/ArrrFHUKWuNdrMjfZadzraL8VwrLMWvdjfaLcfKq9av7TT+sV/zf2ehSsy+j5Jc2+8W0+hbU2vHss9Wtpx8KuqzFHp013vxLsHOfTj2/8Acqr0/wDCVVpTndR+s+HhZduLnY2VRmUtvx7a32sDmeu591xbsx9m71LGXVW1/oLvTqf+n/wk8P6/9KuyK6M5+RjYTr7L3PpNbzVZkNyasq5tdmPZY+i12fkX20fpX1P/AKL/ANxkPP8Asf1vqZ06yysfWOprn4mRudsvJLrbOlvsv3bfT3f5Ns9f/grPR/w/I/8ANL61A/8AI2f/AOw13/pNJT9F9Mrx6enYlOLb6+PXTWyi6Wu31ta1tdu+oNqf6jPfurb6atLxD6nWfX3o2fjY76eq4vSTY0Xs+x25DGMLvUs2Y1tf6Jr3O/Svxv03+E/TfzS9Sx+rfWGvq/2HP6QTh3WPbjdRxrW2Vhg3WV/a6bPTtx/0TffZ9D1v0dSSmf1r/oOH/wCnLp//ALd46zHf/lVZ/wCmL/3actP61f0HD/8ATl0//wBu8dZjv/yqs/8ATF/7tOSU/wD/0Oob/wDlVf8A+mL/AN2moeJmNo6Pk9JyGdUw735OZuvw8LIe9rbcvJvY7HyRi5FH6Wixn6arf9P9FstT9f8Aq99bLfrOOu/V/KxMcnCbhPGTvcSPVdkPhjarGf6L85C/Z/8AjZ/8s+l/9tv/APedJTzh/wAX/wBSHEucfrCSTJJw7pJ/9xib/wAb76j/AP0Qf+wd3/yMXSfs/wDxs/8Aln0v/tt//vOl+z/8bP8A5Z9L/wC23/8AvOkp5wf4v/qQOP8AnCP/AEDu/wDkYtRvRfq/jfV6/ofS/wBs4QzHA5mYOn5L772a/q99n2Nn6DY70/To9H/wfJ9e/wDs/wDxs/8Aln0v/tt//vOl+z/8bP8A5Z9L/wC23/8AvOkp5H/xvPq+AYyesyAYA6Xk8/8AsOo0/wCL7ojqa3W5HWmWFjS9h6XkAhxHvadlVzPa79y67/jbF2H7P/xs/wDln0v/ALbf/wC86X7P/wAbP/ln0v8A7bf/AO86Snkv/G8+r/8A3K6z/wC4zJ/9504/xfdBAj7V1n/3F5P/ALzrrP2f/jZ/8s+l/wDbb/8A3nS/Z/8AjZ/8s+l/9tv/APedJTyP/jd/V/8A7ldZ/wDcXk/+86X/AI3n1f8A+5XWf/cZk/8AvOuu/Z/+Nn/yz6X/ANtv/wDedL9n/wCNn/yz6X/22/8A950lPJf+N59X/wDuV1r/ANxmT/7zpv8AxvuiBzSzM6wGAn1Gu6XlEkR7fT/V9rdr/wB5dd+z/wDGz/5Z9L/7bf8A+86X7P8A8bP/AJZ9L/7bf/7zpKeTb/i+6C17bG5fWm2MIc146ZkggjVrmkY677pn1gqxMGrGyx1PNuqBacl/TctjniTs9RrMfbvaz2Of/hPprN/Z/wDjZ/8ALPpf/bb/AP3nS/Z/+Nn/AMs+l/8Abb//AHnSU7n/ADqwf+4nUf8A3H5n/vMl/wA6cD/uJ1H/ANx+Z/7zLD/Z/wDjZ/8ALPpf/bb/AP3nS/Z/+Nn/AMs+l/8Abb//AHnSU3er9Wr6pXh4uJiZ3q/b8K0m3CyamBlWRTfdZZdfRXUxtdVb/pPQnf8A5VGf+mL/AN2nKv8As/8Axs/+WfS/+23/APvOi9A+r31rq+s5679YMrEyCMJ2EwYwe0geq3IZLHVVs/0v5ySn/9kAOEJJTQQhAAAAAABVAAAAAQEAAAAPAEEAZABvAGIAZQAgAFAAaABvAHQAbwBzAGgAbwBwAAAAEwBBAGQAbwBiAGUAIABQAGgAbwB0AG8AcwBoAG8AcAAgAEMAUwA2AAAAAQA4QklNBAYAAAAAAAcACAEBAAEBAP/hDgxodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6cGhvdG9zaG9wPSJodHRwOi8vbnMuYWRvYmUuY29tL3Bob3Rvc2hvcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RFdnQ9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZUV2ZW50IyIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHBob3Rvc2hvcDpMZWdhY3lJUFRDRGlnZXN0PSJBRjMyMTRBNTg0OEQyQkFDRkJCRjkwQzQzMTM0Q0M0MSIgcGhvdG9zaG9wOlRyYW5zbWlzc2lvblJlZmVyZW5jZT0iWXNhVTVUYU1CZnBQcXlwdzVlbDUiIHBob3Rvc2hvcDpDb2xvck1vZGU9IjMiIHBob3Rvc2hvcDpJQ0NQcm9maWxlPSJjMiIgeG1wTU06RG9jdW1lbnRJRD0iQzBGOTcyOUU3RTc2MjZEODMwQjdDNENBQzU3Mzk3NEMiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6QzdBNEI1QjQ0RDk0RTQxMUEzRjBDOEI0ODY4MzBGNjkiIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0iQzBGOTcyOUU3RTc2MjZEODMwQjdDNENBQzU3Mzk3NEMiIGRjOmZvcm1hdD0iaW1hZ2UvanBlZyIgeG1wOkNyZWF0ZURhdGU9IjIwMTUtMDEtMDRUMTQ6NTk6MDktMDU6MDAiIHhtcDpNb2RpZnlEYXRlPSIyMDE1LTAxLTA0VDE1OjEyOjUzLTA1OjAwIiB4bXA6TWV0YWRhdGFEYXRlPSIyMDE1LTAxLTA0VDE1OjEyOjUzLTA1OjAwIj4gPHhtcE1NOkhpc3Rvcnk+IDxyZGY6U2VxPiA8cmRmOmxpIHN0RXZ0OmFjdGlvbj0ic2F2ZWQiIHN0RXZ0Omluc3RhbmNlSUQ9InhtcC5paWQ6QzZBNEI1QjQ0RDk0RTQxMUEzRjBDOEI0ODY4MzBGNjkiIHN0RXZ0OndoZW49IjIwMTUtMDEtMDRUMTU6MTI6NTMtMDU6MDAiIHN0RXZ0OnNvZnR3YXJlQWdlbnQ9IkFkb2JlIFBob3Rvc2hvcCBDUzYgKFdpbmRvd3MpIiBzdEV2dDpjaGFuZ2VkPSIvIi8+IDxyZGY6bGkgc3RFdnQ6YWN0aW9uPSJzYXZlZCIgc3RFdnQ6aW5zdGFuY2VJRD0ieG1wLmlpZDpDN0E0QjVCNDREOTRFNDExQTNGMEM4QjQ4NjgzMEY2OSIgc3RFdnQ6d2hlbj0iMjAxNS0wMS0wNFQxNToxMjo1My0wNTowMCIgc3RFdnQ6c29mdHdhcmVBZ2VudD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoV2luZG93cykiIHN0RXZ0OmNoYW5nZWQ9Ii8iLz4gPC9yZGY6U2VxPiA8L3htcE1NOkhpc3Rvcnk+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9InciPz7/4gIcSUNDX1BST0ZJTEUAAQEAAAIMbGNtcwIQAABtbnRyUkdCIFhZWiAH3AABABkAAwApADlhY3NwQVBQTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9tYAAQAAAADTLWxjbXMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApkZXNjAAAA/AAAAF5jcHJ0AAABXAAAAAt3dHB0AAABaAAAABRia3B0AAABfAAAABRyWFlaAAABkAAAABRnWFlaAAABpAAAABRiWFlaAAABuAAAABRyVFJDAAABzAAAAEBnVFJDAAABzAAAAEBiVFJDAAABzAAAAEBkZXNjAAAAAAAAAANjMgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB0ZXh0AAAAAEZCAABYWVogAAAAAAAA9tYAAQAAAADTLVhZWiAAAAAAAAADFgAAAzMAAAKkWFlaIAAAAAAAAG+iAAA49QAAA5BYWVogAAAAAAAAYpkAALeFAAAY2lhZWiAAAAAAAAAkoAAAD4QAALbPY3VydgAAAAAAAAAaAAAAywHJA2MFkghrC/YQPxVRGzQh8SmQMhg7kkYFUXdd7WtwegWJsZp8rGm/fdPD6TD////uACFBZG9iZQBkQAAAAAEDABADAgMGAAAAAAAAAAAAAAAA/9sAhAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAgICAgICAgICAgIDAwMDAwMDAwMDAQEBAQEBAQEBAQECAgECAgMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwP/wgARCAFaAVkDAREAAhEBAxEB/8QBIQABAAIBBQEBAQAAAAAAAAAAAAgKCQMFBgcLBAIBAQEAAAYDAQAAAAAAAAAAAAAAAgMEBwgJBQYKARAAAAQFBAAFAwQBAwUBAAAABgcICQADBAUKAQI5GhAwFxlKIBgqUBETFBJgoCIhMRUlFjIRAAAFAwIBBAcPDgkHBgcRAAECAwUGBAcIABESIRM3ODEiYhW42AkQQTIzcxQWF5dYeKg5ickgMFFhIzQ1ZtYYSZmpOnFjJWU2Vldn14GRsVIkGQqhwdFCglPhskUmR4iYUHKSotJDs9NEVGSGprfHKGgSAAIBAQUEBgYGCAcBAAAAAAECAxEAITESBEEiBQZRYXEyEwdQ8IGhsdGRwUJiIxVgoOFSgqIUJJKywtKDNCUm/9oADAMBAQIRAxEAAAC7GYlAAAAAAAAAAAAAAAAAAAADJgTQK/ZU3M54AAAAAAAAAAAAAAAAAABjEMnJb/K/ZAQnifcfPNk6vyr0pFNqU/zTrPn7gqvjmSfppYPoqJoETiWIAAAAAB1udkAAAAA+E+ogIW/yv2QEJ/lgA+KbHBLo96YUdWyQzh3b16/n7XxH4m4/UHXLl5D+/Yq7xK5cDHoZCwAAAAADHqZCgAAAAV/zTICFv8r9kBCf5YAPhlMHlqdgNFfB31Z3J8ufNzldu5r8oBYGeu/L/djW5dazL83e809aBj0MhYAAAAABj1MhQAAAAK/5pkBC3+V+yAhP8sAHyUHzTrpFbvH3brTZxF9JHbtdb2ftxsN73+bnlg7N5PjNzkz9vI8kRTYTv0xdE7DDWZTDCIZkDB8ZsjD8ZuDHySjJgGQA5wAAACv+aZAQt/lfsgIT/LABt8yVqyYoKdZvd57mvr2B9B8BeG4pmL5rbNmSGnbavsyifS1GdUxHmSc66MsZFon+dTEnDjB2wcdOZHTBy4gydDEBCfZXbM+5vxn5AAK/5pkBC3+V+yAhP8sAG2RSo68J3fzq9ffspmp3PFHM5eTWZUGw59IV0rM3zF2GshNVu7SqoDHoZCwAAAAADHqZCgDhJW7NtMxJkDAK/wCaZAQt/lfsgIT/ACwAbaR84jtNZXH/AHS2qciNJfYHMdZr0Y77UunYLj2gL/6Yvvj5ADHoZCwAAAAADHqZCgADrgpul2kAr/mmQELf5X7ICE/ywAfC+/qZS/PF8/EmHTqY9SCH6KeV9UnkNWoAY9DIWAAAAAAY9TIUAADHKYdi1GCv+aZAQt/lfsgIT/LAAAAAAAMehkLAAAAAAMepkKAAB1qYLCw6Cv8AmmQELf5X7ICE/wAsAAAAAAAx6GQsAAAAAAx6mQoAAGJMx+lm4Ff80yAhb/K/ZAQn+WAAAAAAAYYTrMx4HZ5knMnp2MAAADHqZCgAAYTCeRMEFf8ANMgIW/yv2QEJ/lgAAAAGwGBErGFeUx4loAzCnVxWmMWpm0LGhajMhgABj1MhQABoHnxnoRgFf80yAhb/ACv2QEJlmWgAAHRxUvKvBltM7RSlL55YMAPyUhDFYWGSq+cwLjBn5N2BComqAAQ/IlGXUAxLnMCAhb/K/ZAQnEZzAAY1SjYY/S6eWUzfTzDC5wS0K4hUjJlF8gzGHmvFo4sJkYinAVmy10XESNZOkAGieecehqfoAwZm8kBC3+V+yAhP8sAAxhFDkjUXjywSAdLHk4nr7nnPGwnocEHDy4j1bzpAoWnqMgHUhUBKjxYgL4h2sAYOSZRPwAFf80yAhb/K/ZAQn+ZGDz/CFBf8M4wABhQKhh6UR4zZ7Dh2QCoEcRLkp46Z7GQABwAoulX0uBl1A0zz9j0HQACv+aZAQt/lfsgIT/M6hUxKZpZ9LoB3eADEqUoD0yTxpD1qyWAKQRLMtYHkFHsHgAGK88+Q1y/KZfyn4W0TmQABX/NMgIW/yv2QEJ/lgAHCSocU6iyaXOSWwOJnjvHsblN0qqF6MhoU1j12DCsVcD0lADCiUYTiBcdLLwOtCsWWvwAAV/zTICFv8r9kBCf5YAABxAqqlKUzElyEzEnnyE2yxqR+Ko5NEtznZx5M56PpkTKzxTKJVl7Iy/mPUyFHxHnUnonG6gAAr/mmQELf5X7ICE/ywAAADQK8ZT+INmfMqEl4Mu0m/giYeaedXk+zECWIS4wT9AMepkKMO5z0ylgAAFf80yAhb/K/ZAQn+WAAAAADo0rtFeYrgm+GS04GYwjKYZ3SxsZsj7QADHqSbKHR6GgAAAK/5pkBC3+V+yAhP8sAAAAAAAx6E8SDZ2YSrNcAAAAx6mHMsjnZ4AAAK/5pkBC3+V+yAhP8sAAAAAAAx6GQsAAAAAAxKGF0uGgAAAFf80yAhb/K/ZAQn+WAAAAAAAY9DIWAAAAAAUDy/gAAAACv+aZAQt/lfsgIT/LAAAAAAAMehkLAAAAAB1GVhi2qAAAACv8AmmQELf5X7ICE/wAsAAAAAAAx6GQsAAAAAHn8lsIyiAAAAAr/AJpkBC3+V+yAhLQyhgAAAAAgmTsAAB0Gd+AA+YwMGTQl4AAAADF4djkBC3+V+yAhP8sAAAAAAAx6GQsAAxQHkeno1FrcAx0GB0z3mQoAAAAFf80yAhb/ACv2QEJ/lgAAAAAEAjoM7uMhYAMex5BZAQ7FPVnLJgIPmL0muZSwAAAAV/zTICFv8r9kBCf5YAAAAAMPx5P51AenAWgACHh5CxizAO5D1tDPAYTDx+jPMesWdjgAAAFf80yAhb/K/ZAQn+WAAAAAV5zytiNAOyT05y2QRlPI0MNgABJ09cM8zgwzAs4HqkHYAAAAK/5pkBC3+V+yAhP8sAAHTJyY7ABWPPN6OpDdTeDlR3geoqUNyvwaptxw45AbwfeSeLvR58x8RrFoY9I46CJTGoAAV/zTICFv8r9kBCf5YAAMIZGQ30hKYXySRv5xk48TIN4OxSJ5wU6zOZEcTdSVRw84mdmmXcrzmRI6QJVE/ScRl8AAK/5pkBC3+V+yAhP8sAAECDcyowY6jlxO42c0DaDPcVuTq4m8f03o+0xWkyTtciidhn9NmMz5AU4edBEjCzqZWQACv+aZAQt/lfsgIT/LAAB1WeZEVszuIz3HCiFpthd6MS5hZO1jrYEoSAh00ZTzihCI54T5PkJnE6Sg6dfH0Fok9Mk5cACv+aZAQt/lfsgIT/LAAIsnlLmBU/RmMLohAM4+ZQTp4jAc6JhmJgyKkTiCxKk3UnYYpTIIc/N9OCEcjqIo6nzAn8emOSpMxQK/5pkBC3+V+yAhP8sAGOk8nsxQgEtywWd3ltorDkZjROMHOjcjj5zsxhnbx3eRqJcnZRvJw47eMbRNwmCQKALR51aZPDMGV/zTICFv8r9kBCf5lqPNqIZAA1jeC2SYjCtEfWcSOZH8Pyapys48bMa5omsapqn6PkN+OGFuM9AgAAAr/mmQELf5X7ICEsjs4AAAAAEdCRYAAAAAB1qdlAAAAA6xOySAhb/K/ZXHLHgAAAAAAAAAAAAAAAAAABiJO9y3+QwK6IAAAAAAAAAAAAAAAAAAABnPMlwAAAAAAAAAAAAAAAAAAAAAB//aAAgBAgABBQD/AE5/luma6bNu3XdIm7d0yt1kxppvnRpTbNuv8lbt03V02Vu/RNmn+MsUimXbdoKN62iWb/bkTpdL/wAZN7vtPb9oVHdsvka1EnZr+iU+7XSYcIMnCO001Put+8ojbmCiaMB9bwbTDsc1QyryLD1VR3Kpn79239ErJutPUVW3SopzcKaaKJtTUbrfvEwsuQoqC2LP/wAzrarDSW3Tdr+2n6Js11m6f1dmsGCLqcHWwXCWYKblt0n2+oKw0KLSh3abJmu+fpSyP0SRprvlXy9/0Ng5HFcMqssS53XiDTK6i20Wu6fQ1JVGVOEU2pptamR+iUk7Sdsv1v0uOthT5JoK2xWCjtmzTdrMlmYVkwRTioKqsC9XWzP46b9ElU38G7ZM/bTfrrv26SZ8zSdNpqfbS1EipibWyJcfv/b0/wBvx//aAAgBAwABBQD/AE5rrpcNd22i3af2bbWxtpZMvWXK0rt1TKodZdVLvNJEimkXHT9E266bqRNibBSeQqUy3IN092ilpZtLOlz9m6kIkhRecghPBHKgE3ypMmou+/8ARKmV/PRNuKcs6ehxJkyBTRuGt71hOVqdEyX1WRgpsIYu05BF2I9wdby4p6LShtX6JTTf8pVNQzJE1vFwaqJmtnTpApoyXIEriHtC6V5BFLdnHF9FJpDCVVabbn+iTqKRW7pk+VT7Uxp0HisxCn0nbURRTz51LfaNyhDooAl8lTt22ipbdT7NP0Sjo5siiJkta4xBYQqcAwnQtl6LmtCXgWhlyC9AMXTJtjFgdcHRDJIC9zZc3bM/RJEnSbRFCL55diUbvHyhoCBNfhINhJOlUe3ch5wO9p/lLyXcGT8C1Ds10rP0Son/ANTdUUX9mN1xqtsydS2jZpbZH+MiXNmbZ+yiqtNZezTZ/t+f/9oACAEBAAEFAFSqlItGBD9oximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKYRiuxKrhxXxlEcFOP3j+IxdgRr0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKHjMY9B7djbuFjxaxlEcFOFjxarPWo6ZvdG/KZjbsykNNn5Se7TbuykJmmmzKT2RrrlIa7ddMpHft2b8oOp13Sco3XZ+UzH5TMflMwkhQ2RSpIsfymY/KZj8pmPymY/KZj8pmPymY/KZj8pmPymY/KZj8pmPymYthsZG95MP8pmPymY/KZj8pmPymY/KZj8pmPymY/KZj8pmEYLUdM2OjZRHBThY8WsZRHBThY8Wvymo3fvrNW+twqEHlWht7EgFemBT6ftp+3+e9V6viSRqA0dOWJfW3cNZm3dK8W6Te3nMRHmgHkc8r5TWURwU4WPFrGURwU4WPFr8pqJmn+W97JDY9V+Qun/lA9dWgXeaZQFOuBZpSIsJlW6szVWWbuP2lc2xOpXbRS9kvxbpN7ecxEeaAeRzyvlNZRHBThY8WsZRHBThY8Wvymo/467v8JezV31oWlUHTf+0D11PlSh2qaEDYjX4xXMNC8K8FlGD5u3+TSKifTUEkQrHSQEdjbysSwPdPF8fXaAsexObjSLVbF9fcq9kyybUZu2o4XyTtwzMWo6HYgV6BMrkJD12bGh2nhtt7ImXLk593NLENnPclM5inG25saHKiG6XoE2OWEYHswJoK96ICcZSmuNWwDePasM+WDhsCB9aPI+U1lEcFOFjxaxlEcFOFjxa/Kaibtl66fvt26rWWsTyLSgUwfYnU6d//AHhlN0AvxoDNmu7+Oupv7+0XYj66TJFjRrIdU2En8P4R6TZWjCbeSS01pLsOIMz7adiKGpUXt9loH8a5kawS0zoJRyj0H2xnVp+17CjSumBPoct6C0MWqAMSZOFZZ/tRS1AYKMrANZrogpDV30AKVk0FGERExUz4LpaRW9EmJkU0YeGe1uKJ7e7MctsJG+1BOXogyG+nCV1BBtVDuRy1mt+o+n5TWURwU4WPFrGURwU4WPFr8pqJW7STCmT9DSZSUVsrc2Fmm4162IKV0Dx0BlIFDUA/+2DV3ZkdNuypaL+SXtm+LdJvbzmIjzQDyOeIuCQaHgeXvittrq2ozKP2rxlmkkBuFJhcsI3x+U1lEcFOFjxaxlEcFOFjxa/KajXdprCjyHC6jiXLfGyGEg1AAW4QKMC67Zf+TqDMlsVRe2hmjjvS8d+3Z++/xbpN7ecxEeaAeRz6TELkEm4BE8MXLkbHej8flNZRHBThY8WsZRHBThY8Wvymo03S9+ybt2btZeu/bvn6abd371m7bN/n27dm3drH/TTTxbpN7ecxEeaAeRz6nYA4bAlbexJVRjVRTanh8prKI4KcLHi1jKI4KcLHi1+U15jdJvbzmIjzQDyOfUaYOmj0smBWfjbaBLPw+U1lEcFOFjxaxlEcFOFjxa/Ka8xuk3t5zER5oB5HPqe8P/VMTUOKVJOu/NS+HymsojgpwseLWMojgpwseLX5TXmJucUSsV5HGJkpsrltvrcztrS3VpTZgDRJjXgs36Wfza0AJigI0gt5AB5HPqevbrFbrSUEIpgsqNkc+HymsojgpwseLWMojgpwseLX5TXkXq8WgPW1X2TQ0qkqnVbmjKeF+5Sj1boyr60EAsyToHqRcQNx89acKYRhIUVsNfCLp9tvXcwi5m3naysOw4CPv6a8nN4VNNKl/NVJu/0qU3SG+Vv7fpAPI59MyfLkS0VCUQPSZPXj8prKI4KcLHi1jKI4KcLHi1MAwQcVWSZ9+yN4+/ZG8ffsjePv2RvH37I3j79kbwejuTcCcAkunM8vdZsM5TDp7vA1RbjclWLZl+S3jLtOkReatUryqyGEAczMiQmvv2RvH37I3j79kbxNXcjObsfTZoQ2cNuYxcSTGX4kVrj/ALCR2bVWMhKXS7fUhZEzsyEKRDmXS30pKXbHEkT3eR9+yN4+/ZG8AFWyfJK1/v2RvH37I3j79kbx9+yN4+/ZG8LGcza6D5bNPEC2a0QXn37I3j79kbx9+yN4L8wQcauSZlEcFOFjxaxlEcFOFjxa3qz2kRZOnpYVcelhVx6WFXHpYVcLocZawbgoXDspo1j2t6NWOXUnPL03/ieIHSfMsRBkSFbX6WFXGViuEMqFXiwk0eDG6UON01BTnGQ7oOUWlBPonPx8Vy9QFYlDJycDIoWtVOtt8uvhn0sKuMsNquwpIUNjcq+BzgzenpYVcKRbhQ0sQFL4w062j1sgodDY8PRvLK+RkacgnbuktQoBL0HBPRenpYVcelhVx6WFXHpYVcbyvKaVL3Buw5GGQN6TFPsj0sKuPSwq49LCriy2e0h3J0yiOCnCx4tYyiOCnCx4tflNeC9ncUIttWNxjLOWep6EK42TojiorQBjiNnoL+g/zVtBDkcwQQwvcCemh9h6IYW9HuOvjmAlVIHLcsS5J0Jrma5Q842DVspBWVj9uAN+rEBDgCP3hkjUi4G3MPZRd0Kxz7xN0mCjUABHBMOdM5r0InLx4vH5N1tTK4J+8qTKU5ynPsCeLvz0qdGnd6KUbJCTHQ/R8prKI4KcLHi1jKI4KcLHi1+U0uxeKZW8CWcly5lXqPp2x2A1vO8z262Bm722Z305Ehr38mWW8J4P2WqWpDpBjXhYbuZdgIGlUAfDMiJ4EDptbC4Nq5ClAk6VLny2sR9tTa/f9I9AAIMwJLmxaCeUUsGZc3Q2BFZtu5fpJHDWUtdIr6Ouqv6VG38lxRjzz6f0/KayiOCnCx4tYyiOCnCx4tflNX+wWEX2ZyLEiRspXYYRFPG4/wCcLdOY6Wwl3EufhPKLLz6HzSSo1BNHYV47obK4BDv9/kBZztFqpAAtJL3hmfrOCgYTnh1EXdi1atulyp7RbWRC+tyu33vpX08GgptSyuCZNymFJmY3/jGOQryvLfDH7fLbdJD2D16rCXXmHP8A6H/5j6flNZRHBThY8WsZRHBThY8WvymvAZg0KmEHXE8RdJijdTCIV3ZgI+W+8y+l37UtrLS6tUA+AqD1jGIcSsMxayO9DRXCgu1E4m3Fcnr27WmnoVQsjG8XmVmymMAyufL9QuUIGRwjtcuQgvklCeLpPhU5Jiy7YjdqPC+SNfxcqjxcFfpbhbrhfmWK4GrWQ3fjIOIL3mthM/I/byWn4DW476O3skMaHakdY31fKayiOCnCx4tYyiOCnCx4tflNfQIQ0HhrYHCMTRC6mKNSrYDtzNhqN45gyniehEj4baC/5EZiLZ1wkijFXeNB5/EO3Sb285iIcYZEQW5ptPjCfOCjrUnYXCcQCLE6pkT8lItxsMgoXYVfXcpFTxC+Gdm/bW2u38PTDAhXhJb+WM3GmaQt1/x1JzwTN04oK5VW1rfrHzejbdPAB5HIn1EmmlKFNc08kN8ihptKGj+r5TWURwU4WPFrGURwU4WPFr8pr6pkiXPlrlxomwlsSVn4hjiZBzyJdrewaXvxWZhxNnkWSkaokCAVCyHlHl2adgst9swmtfgq1ZyZERFu+ZkSGk53Qsnq9a8bRrlYZmayjGkhpO73j2o5RdhbVdfbEgtnIXQRZ/EA8jkOFOaN6pcHbarTaVmsAt9fymsojgpwseLWMojgpwseLX5TXknYnki1IA5VmJY1aoOapTDAWQB7hUNfL/qQwRK2HMG27wGssN6EOWw3MnZ5416OpKVwhawtTzjBPAn/AC0x4TND/QSpj6NKJJopFPJppX0gHkcP05wongj2Lk2Gi9K6B5HymsojgpwseLWMojgpwseLX5TXmN0m9vOYiLpY7Ve6a4NYtkXOtKZDiLSDuMuRLkS/JAPI4r5+UyiueNAhbF8VNk8j5TWURwU4WPFrGURwU4WPFr8przG6Te3nMRHmjy5nPa1V417SZ9pvGfk/KayiOCnCx4tYyiOCnCx4tflNeY3Sb285iI81Tit1QLUyYPK+U1lEcFOFjxaxlEcFOFjxa/Ka8xuk3t5zER5ho3ugtgZYlaOEbWa3vK+U1lEcFOFjxaxlEcFOFjxa/Ka8xuk3t5zER5mToaY6cAc6TwCLEVS1/K+U1lEcFOFjxaxlEcFOFjxam3bTIu2Rv6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPQgwSr8PsqfTpx6PTpx6PTpx6PTpx6PTpx6PTpx6B0bClyqNv06cej06cej06cej06ceitA7h9vo0YNqFydC4QEBlc/dx6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPR6dOPQUltMi05G+URwU4WPFrGURwU4WPFr8przG6Te3nMRH0urOlkA1qmhU63VJLAVHjvP2BxxoF+LtJqVxHtlYZxQUYObRAPI55XymsojgpwseLWMojgpwseLX5TXlOAOGJnbiIdq53JLjr5Rt0m9vOYiPocecLIFtBNrgy/wBQTjqkIL0xRwU43YQfUATpJT+DgJUpuPVHqeVKtFMxtmJpNEAHStTyvlNZRHBThY8WsZRHBThY8WvymvJdad1TO0yTq9HC1KuNnymdUB4o6OrHbeotTihSeK11qEOgRPro7oB9OnKS8SXOw1E8GkyK9IVjspGw/wAHgngn2rroNxdfA2wM8nRtbqALoyS+OQB+T8prKI4KcLHi1jKI4KcLHi1+U15D1b8hEtQANS6nzwWGdXgWximAUA9YayMwOvqihT6myTRqRzxDux3uvqD+lLyozvRwerSbthOuyJiezVMuZTy8vBgl+cbtoGCAzBAxsAnyPlNZRHBThY8WsZRHBThY8WvymvE6FGp6TfZCxNgrDsCHg9W+nRI9tpmEgexwDralYeb99OkYezoko6G27UKIuGlwr5yZ9S9ErdQvVORreL5a6z2dkPnVJo7/AJNEkD3XSsSwOaPbOIkTyZ9CmkZV2khKA9nbtyRR5slpHnqsQ8fysUjJxybUTD9IxslMPbalQaXGVPSYOZO5g5zU/W3BUGBSHRsHVdreSkgwtJM2XUSfp+U1lEcFOFjxaxlEcFOFjxa/Ka8W05tmPBZqh6kfIbdhJp2lZBi2dSrsLoIoN0fpmFgABo/S+dQKuAyJYvas0ZJFnVN2H8SArsqOlCpQuKSp1qGVtFpCvMKXONSCfgAh03RMqkqCuB5sJMCYJMIz0gqGTEOCdqixSgTxv1NAmA2AnYh2SgHqDlpCHHFNRTSk3WEL24wFft/EcN0BXR2srtSlPEo0z2tEN2CCx0nAAOqDUU24tJWqMW3HlK1X21nYh1dqns7lv0/KayiOCnCx4tYyiOCnCx4tflNeJxN7lsYx+FijgjiNpzKGLepW6H2qkibebYBUgRp0l8ITWS8I7rOVOlS3UoyV4nE1KuadKORBIs7eQInlof5vovoiQtywCTNwtgGqRPVmNcihOistrEfYSCZTokHKsU4FZoHFpFUCTFCBqJWMbQbqNTbYdTOcSJE0yCqnB01HOXxwqpIY9CQSa6oLkgHTRtopwVEhcRqMSyLjoLBSSRSIO21HsiEKktalcplUuUJct3hierL6flNZRHBThY8WsZRHBThY8WvymvE3DgLYhS7e2ySjMX0JpCgxvJ2F1XjAxbklJDBvmnKB5TGSoAiRkRBzWavDRXmxcKpm5ogCo8L53VcSoXETFtKTDZu0VaFDxC++9J8NqXtDBFHfTXG3gg5LdajwCpnzJpakOY4rvUxO46JElFAJoOYJiDakE07zWBlE5wy7lYEJHjZiooUYmSOiPbiUOpNs88HuGvaFSxUC84jCtFRqfIz3bpR/jKVDB+RgJUZjoMicOjUP/R8prKI4KcLHi1jKI4KcLHi1+U14KxVqQ6JyMejfLUE6+Y0bP/2gGmsWgqaIKdNYOX6k8tbMWjeB9lUNDnFykWoQKU7Sp4GDvmluqxL5qkykNVqIw4S4zJxLQCL90YkQUV5Ys4XdKxY2NeaLG8pqvm2rfvKlRNtJ8ki3kKZVMEbZVodC5IkEZJmJ1LgWA9nk1iUrEuFcnuvvFou5e2LeHC4RwjBHg2nIgUjdk5GQ/u0qTxkF5Vy/4p/gjdxldCGhKy25CuJS6Z0aPpNdLY08PlNZRHBThY8WsZRHBThY8WvymocTchTG2UQjobtCnXSj18NNf21Io4KsCV4KdUoBRd6ReKUr7ayFTiWgRKJcmSkO1Bn8XrrgLDhdTnOSWqwvdXICaFIN1dWA80bWF3Gxgm9hd0MsQrShtfwItIGHayJtroSac+uVnAQldFBdwBAQcSlA6vJN2u0Evdi8ddKQAW+U5ynLW23Rw5L9ZbadyQAmYOxyvAY2mY0DkFVaUlFuC4kIxUCoPpVOmR0qnTI6VTpkM2ttOaIsKRYGIm2sfspl9ugyWw0ex8prKI4KcLHi1jKI4KcLHi1+U0o0zjuLIllyM25LTh57dXN9aOrm+tHVzfWjq5vrRKxe33JOsnGZfxp9Mf8Ax7L+jyfkMix8Jb6gdrWrrO3dsbEdjlwWaJ3DzesejZLs2mmrZLs2satjOyaxJbKdklTKRup2Gn2XRst1e46ymuXW5GurYTsO7T2u3XNNdGw3YdsaNkuzbY0bPdq0ja2g7VpuDyRnC60xLo2w65cYmtUuoTt2PMr92ZD4i+v5TWURwU4WPFrGURwU4WPFqswvnJCReS9w59aPcOfWj3Dn1o9w59aPcOfWj3Dn1o9w59aPcOfWj3Dn1o9w59aPcOfWj3Dn1oTmsjI3LIDe4c+tHuHPrR7hz60e4c+tHuHPrR7hz60e4c+tHuHPrR7hz60e4c+tHuHPrR7hz60e4c+tFsVc7zazJ9w59aPcOfWj3Dn1o9w59aPcOfWj3Dn1o9w59aPcOfWj3Dn1o9w59aEZl85IdzyWURwU4WPFrGURwU4yLxDbreCCu0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUx2jGKY7RjFMdoximO0YxTHaMYpjtGMUw+6+61Ms9qfCx4tYXaiwtHCksdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGso6VjWUdKxrKOlY1lHSsayjpWNZR0rGsobSbHIlqggv03//2gAIAQICBj8A/Rw1Ir69lq1Ffb87ZiCD2j9tqSB7upbGlKevZ8LE1Feqv123Qo7f2E2LN3/d8K+70Ka41v8AXss0kh/BBIVRixArtFQBTG/HCy6Y1SWtADXKeje8NaHYBh11ssgNx7flZlbvV+Vi00hTTrXAZixAwAI99aWkGlDXXnNUECt5AKgkeyu3A2BVqk9RH1ehQTiLA6UVniLMo/eqBUAZhfVVoMMRQ4W/rdY2TURvUAdIKmgIqBQ0oGHWdtm4HxqiGJBlaqkNQYkhFJZm2VOJNLiLT6nUvlCjAXkmg3QMhuIO8w7pN4JoC2qlUrBWiKDUKL7gCoYfD21Nm4jLHkjYkDYCTeAMrMKjMGIuH2rqi0mYXsRX3fL0LE32Tj8Ou1HSq3bezssnHOCkI0SXigIagFwBdSWJ20OIFbgbHRaNcmojcgk9IJFSDUC+tSp6hstGdTKSqKAASppWuBCrca16BjttBrNeGGnqtMQWpl3VYPcQDeWAyi81pvSjTwAAAKADSgGA7xr29d9gzehTlNBY0xO31NpdRqpQFVbsKkm/KFysaUNS4rlxxpabVeGqoWNFBNBjjcDXA0YA0uOJNo5GFGBB2dvXbSaHVIodFVaUKg0oK18M1bbQHew7xpYgSV6LvbZSXqgwFOumND2+hWk2VtNJl/BiWp660oDcSATcSLLLqKiBWORAblFSQBVVYXnpw7TaHX6tG8DOqitRmvG6rB6XAkkkDKMfvR6vQwBXChRQd7J9kjOSWO2tc1a3mhsyrusr9WNcdoAG3Gldthpda/8AcAAE3HPcMSI1oRU0piMTdU5TH7a9fRUehXK94G0qSH8KVKdYphtBuN5+iyTcR1qsimu6rBjtFCJStes19tLCGGIZVFAATcP8RrhjaZQcbqWk12mcLqKm+6jV6B4igN0172NxrV+JcSekoqFUUrhQXLI6gZScL8LIBiKehSqH1+m14sRG946rUGqv6MotLdu3UF/t6bR0NSK1x+QtQC/2/KwFKL69n6vz/9oACAEDAgY/AP0cDsDlHZ9VLeCS2Ydvr77BQ7fQ3yFiYR8fmbCWSuUdn1EWEZZqjt+o2BidmXq8EfGwHF8wA7K/yFR6FcxY0Prfb8i4CVVhQyysFCxqxyjGaNXkapIUslQp3hfb89aZddwTJV5AqpJH+9SJdbqA0a03mqCoo2TLfZ4pDVR2D6zaRo7jQ07fbY8K5b0STa5zezsscSVqFLyeIt5NyrlJ20pUjS6nzD0aLoZyVjdH0UorsD+DPKY81N0kX0O9ssySnKV7D8MvR6FkXq+BrbXrzCF/I+KJHDK5LBYish8NmZYZSIwssjEgYqlSFzWIU+Jy3qIKMQAf6qOaPoukhyZv41NbgL+I+e/kbw95PLKQl9Xphjw0kxx5lbU6mWaaB3LEFYl8DdUnLlYcP5T5b0v/AIWbNNOxIjgjAId2JmgcuCpMcYIeQqwUqAWGm8ueRqPJGqtPKUkWSaQKB4suZ5ELlbt16KKKAADU+QukkVuYtVJHO6KJM0UayK6uxeLuvlKK6TAtmZcuVXAHCIjUkk/zZtpP+b0KUBs0sT97qH1m2g8iPPLXM/ljK5Gl1JF/DWdpJiGXTaaWaWCSRlzBpV8DeYDLmUAsPE5b1EFQCQf6qOaPpukhyZv+RTS4C/Vcq+XXCE0cUkrSy5W1DZmarZj488xLFSq1z1ooGAAGp5U5VdZfM+eMGOMiUrpQ4UpPMr6WWORCC1EV1ZmVgSqhmSXnbj3FHn1czs0juELOWGJoIyooFUALQAXUsQ+A/wBtOj0KJDjTr+Yt4S4jZf8Atto+VeW9AfyTPmnmJQx6eJXYM7OZdO2fMD4UWZGlZTQhQWHAPLflzVvKuihVTK6sHZiQxLB5JE2kbhC0FwuNpnmf/wCcZCrXH8cNuEXZZYvDcUuvbHC+3F/PDyuhm1PI2rfxZyzI78OkpGGVRqdVJPqNPMxZq+DTSru1EagqOIzx0120V68uI3cL8Oqy8daL/wBFhtrgd3py4fd9/oVxm3r+j524NwGF8uq12rWNWIFwJrIw/EjBaNauFLLmIArfZeROQY6TPkeadlPiTzAgNNKHkkQuylhusAqkBRQXzcpcralZvM/URbi0qNIshQrqZ0fSzxtG2dgsZZWZgwDKoZkg8rPOjirankTV6liZnyr+WPMzzly2n0Mks+nlkdQIxKqabMxULGpC5mJn5Y1un++pljkX+GWI3/dJHRS+Hn7lYV5E1kpAjplGnkbKaRqdXPK0Rd8rVACMQUBU5I/zUS/2XRQdGTHvd7q91/oV4221+NuGcb04rqtFqVlVSQFYKfxE7slM6gqGocpYGl1uLcH5X8v5tHxjUQsgeXUrNCrMKVZRw+JnVb7gUJp3ltr+Pazix/qp5C7sY4zmY31pRAAMAoAAGy0Wo4kP79cDvbOpd36RYcqc76V9VyI2Xw6MgaCgYb7R6OeeSJcxyhTWOmQhlK+HByRyZpyeDDI7uwkyUBRiF8XSaafMZUjF4KgA0N9baibY3oUIdvr128RTRiPp94ssU+iyIducH4Cwmnlysb8HPwNlbjF/EKmn03dzdwpaYcV/6H2cP9G90Y2HjS1HYB8Dagx/V+f/2gAIAQEBBj8AmmSOR8xPb6yduTxIsymXsVmMtTYBlMzYIIwqHYIDHJTKlgUlL/QohzDWqBTKlE3CQDGJ15/izZi+L/rrz/FmzF8X/XXn+LNmL4v+uvP8WbMXxf8AXXn+LNmL4v8Arrz/ABZsxfF/115/izZi+L/rrz/FmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/668/xZsxfF/wBdef4s2Yvi/wCuvP8AFmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/668/xZsxfF/115/izZi+L/rrz/FmzF8X/AF15/izZi+L/AK68/wAWbMXxf9def4s2Yvi/668/xZsxfF/115/izZi+L/rrz/FmzF8X/XXn+LNmL4v+uvP8WbMXxf8AXXn+LNmL4v8Arrz/ABZsxfF/115/izZi+L/rrz/FmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/668/xZsxfF/wBdef4s2Yvi/wCuvP8AFmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/6ery4gXTC7ltYnP3O3DxKzQi5UFM3z5jYY7InxkBguXFYXJhURj80oFAUKiZIQrQAom4TeZnX6pjJ4XmO+rk5EZA3Iybhk2guS8wsrRttmJva6OxZSMR619nbhU7woS4di5/IPZAZ/uJWpqCVyTR5pFMAIHbmU6f8/wD3VcdfFW10/wCf/uq46+Ktrp/z/wDdVx18VbXT/n/7quOvira6f8//AHVcdfFW10/5/wDuq46+Ktrp/wA//dVx18VbXT/n/wC6rjr4q2un/P8A91XHXxVtdP8An/7quOvira6f8/8A3VcdfFW10/5/+6rjr4q2un/P/wB1XHXxVtdP+f8A7quOvira6f8AP/3VcdfFW10/5/8Auq46+Ktrp/z/APdVx18VbXT/AJ/+6rjr4q2un/P/AN1XHXxVtdP+f/uq46+Ktrp/z/8AdVx18VbXT/n/AO6rjr4q2un/AD/91XHXxVtdP+f/ALquOvira6f8/wD3VcdfFW10/wCf/uq46+Ktrp/z/wDdVx18VbXT/n/7quOvira6f8//AHVcdfFW10/5/wDuq46+Ktrp/wA//dVx18VbXT/n/wC6rjr4q2un/P8A91XHXxVtdP8An/7quOvira6f8/8A3VcdfFW10/5/+6rjr4q2un/P/wB1XHXxVtdP+f8A7quOvira6f8AP/3VcdfFW1kbmLZu7mW8rudaBO0hIyyXMndnnODOPti30ttbZ8K+s8UsRCZMr63j06rToh32LsoUvOcZA4Bv58Pu6vg5Yp+ZnX6pjJ4XmO+r+fD7ur4OWKemTydvk7GPAhIxcCmzM+TyTM1nyIA5RHI6T2SfWFjfbHScSKkOU7Eqkkqxn4RFwMLiBikKX9AH+0X0AFDyA4EAR2Af94rvuPKPnj9j7Ia228gWP2tvKHbf+Pxbf5dbFHyBB+XsD/vE+z/mT1yF8gMAfOKb/wDjaKI/7gjhDcCht5RT+EdgAw/8pg0AcPkCxAexxh5Q8C/5OBTi/wA+uz5BNUdx25n/AHhwcvn788VAP+XQEFPyB4pF7BRDyhgrAP8A2Vyp7f8Aa1+gD/aL6/QB/tF9foA/2i+pDPbI3w8iFfyJNF1LoQGumk0gHlCoC7N0si0lOnIoQmzEtlaEisdhq6gNtO5GZ1FF0igZRwrlBPWm/QB/tF9foA/2i+v0Af7RfX6AP9ovr9AH+0X1+gD/AGi+v0Af7RfX6AP9ovr9AH+0X1+gD/aL6/QB/tF9foA/2i+v0Af7RfUhs+03L/4devu/EmRmlcrto2TDPBxnsaiUg5xKPvz9Ay1J5QxR+RVAgBHJVMElB5QERDk/QB/tF9foA/2i+v0Af7RfX6AP9ovr9AH+0X1+gD/aL6/QB/tF9foA/wBovr9AH+0X1+gD/aL6e/J2+UTY8CFTGwKc8z4xJMMmfIgTmEMjoxZJiYXx9vjJwIkQhSPqqqSTGTiEG8wOImMcps6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/SHeYXbsCURL/Dsb7PL6IPP0e49yE3FzqHZzRZItFmJE/shk8hqOcKlQ0RVKddIonBIDGqziBUwEBHzhFO0zxF32zNw3cRLEWqZPzNXNEwUESgLawPFCgkmrIkSGAwtvCCglARLvsOtyn4iGKAlNw8PIIAIcg8vn6TOX0OxtvtCADycuw9nQXBvfL6SNN9fVkb2eiIQ9S/SNzE23eiPsyVLVLPdasmYRBNMu+wed2dPjDamYuJJpHKdNydoRJ2WqYJKDafZJF3SRBIqDkyHOqBAVKoYAN6IoCGwCKg82RMSgAbCb0Q8noQ3876iXS42XpM1DN1/b3xMl1faDHHMGAY7OFGk9pwgnNIKPw2mHdqB7KA9+wKB9xEfr2QXUF6BrT9Hfyjv4VDrBf3Cf1c/jfrfzA/0h2s6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/SHeYZP/ALwNw/7IcX+kNRZ6tKUHO4tlq9+kzXFedTTGVtji0K9+mJs5w4F9kipWyk71jwbc7uUR2NrYBcGR/Ya4oAHbtrizObGr2R24DFeynJyj9n7PnMOL+Tr1T018CJIN1vJxWlLQUN228gpkpGJzIhTJoUU+pUk+U5zgD0HbB913BSvubcxwJW11QWooIXEqarqKWQzmSn3Okzsgetqgm/EQCqVaheaoCdubYvai83Yus6cVScTUsTjFIVMrBC42cwG7ztJkkkSrHFTtjqGLxqGHcfO0llING5slorcxyQx3vzVmIBZ5J35sOz95GoDgcztSxdJAzgocCmADjRgAjvpPmzbgkUxSDsYOLiUMc3IJx224x7O/1EulxsvSZqGbr+3viZLq+0GOOYMAx2cKNJ7ThBOaQUfhtMO7UD2UB79gUD7iI/XsguoL0DWn6O/lHfwqHWC/uE/q5/G/W/mB/pDtZ1+qYyeF5jvq/nw+7q+Dlin5mdfqmMnheY76v58Pu6vg5Yp6+YH+kO8whv8ArF8/l+z/AJvP0oAn2KYNjBwm5Q5Q7O4jp7ydxhZKalvcigrXXBg1CJW+gu22o8Y1T62HWqE0KOfUiKXIUhAB7DtTfddhUDcHBkf2KvMIj27a4szmxqb7BvwGK9lOnyB9n7PnM0rvnO3WdvbIwN8daKtwSTRLTULUbjVVORApCmXXWMJ1FB3OcxuUdU87m9K4xXGqKvJPZVKCpGpXCbunO8JoXC0k1kTrENsIPLmmPE1G2IUBOI8MSt9b5mborC4g1JtcfjzVSKUzbR0SZCplTp0+cWPTkDgDYu47f5dGpycm4F4R7PnlOPIO3+nzKipqFkaampwGqrKmpEAIUNhETiIiUpdgDs+dyAAaE0vygx3i23nSa9trmgfP86plBNXSuBQZ/QvORvt7eC65pbeantIy4+I26i7E7d/GeDPkFTSQAY/B40QvNSxRMCvqBu+BTmATGKr688ofjVUGQ5RFmnISTi35O1COIVRTj53IP+XV17t45X8YbrW5sWub21JPHI/Nk2yJHTjyslMiAv0YQUfTFj6Z1DC0lWAQ3D0QgUBCiyklspN9lix1yHKH/wAGUWwh+r736xyf57JoBjl3zLcSse4G8xV2BNON1U7AjAyPwJnfTjHWcTAIcI8QcJdgNrm6a3ebT4bffiaLP2oTHz/OkF/6PfWRWRthre3yjUOxlI6+zVou1GoRGpO9ChBVbg8MbTiNzJ1TCClI0KF3OqXcSl2KO+4cNHiTlbW7/wD3ittQ3+f3ExW1k5kTbGztybcMuLpHRSUxuaVzFUvEj4IO+T8QYFY2sukCiqLIKextj8R9+Xl11IcgvdEgH/1esn8jIJZO4NrmbF4HIz/HJU8sjy7yYpIM93BOViUjgcIKHQYjJ7GDiExtw5AHQlccSsq6Ef8A8PW2pcgH+ADzCnHbbWQmQdobfXotvDsblVhm1JdJmhLe7ORaeELT0TMSMUlszJUJgwMp+IBOmPKAhvuAhwuLlkrDjfZk1kiqB/8ApOWzLWWWQ2Oc0w4kFnobY+21JJpw2WgupbnPRQWRF9kMgC877cGKw2nkFiYkmnsxd5yvJUlSmKYU1OQUgh/lC8RaqrqCAFI3SS98HgrrXD2DFSYLgP8AEqs59w5AAo7/AGtFkMFmUWnTMtuTv1DJCyyZqMcQEQKm7x1RdIREA84d/rPzA/0h2s6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/SHeYXjLvtuBR4hDcN/sB2NcvJt6EvKPJt/rfb05XOubWc9W15Vm+IQ2lrKwkhnMh246dnZR9bLopnMdIAPVqcKVATtjjwdqM+vtL2OPR5+nzuDzXNcVakaKgpOEBKXnFUyJGkC3AGxnQ3bqDy/YDQcn/hDz/wCDsaheGl3jR639x4q2Ix20T420TczRm5raCqJUY2CNIUoUtwUCk7cTbEeN+cMIuIGA5ROhsAF7cOdAeXiEN+Tl5R2Hk1VUqR16CoqaYUe+NMqHrykMZHtVCEMB0wOUNgAduzy/b1KXS4/lc3yZ0bu+uDqaVyuLXXl8wfhExi9+ZCg/3a5j2QHNsBt3hTbYRA4BvrK+xUiycSyFpsqzFBwe/ahWt+MNL7CH6BLU6ZRulODSkD077uJhMzj2gl8/cqRpVmlkU6cP3wVjhNsI0Ih2e1CpTl5SD/lN/DrKSHY5ZUzHLW3177uzy2tx5g9WufLQNEfcbcoSC3bzBWS38pFWpM+Rrv2ZJ7egKZnfT8Ipp82XhDdxj+RUqP8AYe74GTDb/wDLEWiOw6u3aHGi3kjj0AvoYiV1GiRXGms2GQpgxPUfMQFJFIVhYgVj74ZM4tQIGMHnblKbX+w4IRBcwD6KR3SyFk/J/BJbsVmp1AMZrAwezUNuasRS4UbjVI7mb5oCTIswEI+g/L1Bzf7I7mTEAHtyCIcvbAXjQ8m/hfU8v/lfHC1bubf+CQRdfs6ksSsTjnYiy0TmK5zTaL2ks5BbZRuYnGn7y/8AnAxxON0lO+mBDcgCoU25TbCIgceIw0GGeJzd647PrHHS0rcJh7PKCcSLsP2uTT2w20tPbK3rRIBOtIWaFQOOxttej80dLiemWPUiCT4oKapijzgGESmEN+UQ11aLA+45b/8AJjT2ww22NuoWzyAyiryyxWCx+PNb0YEjE4nloYaanp3w4EUMA84BtyiIefrd1wxxPcuX/wC3Y52ncv8A6SImHfbUxgFp8fbK2vgM/QUprhwu2trYVBoxNUzspGISSFgjEcpKd9MSPjzBOPiHgDg7BjaE7z5O7GqkEBDkjMGLBR8/sexNWKf6NZl4xY/W4wftZY+7GO0ZopPCrUXJufKvKC0fs/LIY5IVrtHuDLZeMAsZUpnP7GiNPNEF6KKhi7lAAWrIJczLi2FSIgNG3Ntw4DK4wjuAjudCT2qqpOsJhHkDv0ABrMvHXHG/btLLi5De2C824uhO4nTxdW3srWtWSCW9O8oxtZYX2niUpEXQzimmmc/H2hAEAES1NgMtqjKqLN5xKdko75sd5kaZtEwm5sI9mxFIkoHNENylZRObcNyjtrJrMPyvtmqex8oxjdbgKU8PbrYP1rriT+31voDHJEm/rx6WyoY1WSWdyp8UZGM7ULKxnUIA7DuJgoI6w3tVsHc104qaitVkxSNttHiucT8IgLDOvZHW2qkSu5B5tBN6F3VHlBMBMBR+p+YH+kO1nX6pjJ4XmO+r+fD7ur4OWKfmZ1+qYyeF5jvq/nw+7q+Dlinr5gf6Q7zCU4jucROO+whsYd9uxuA8n29XIvPMU112eARdzk1VS0She+FaNMn/ACS0U6ZkFyeuJG9gSgRA2xRUOACOwjs83Zuu6gapOb1pE4vSlRKxQqNcmzM1CikiCp9w4jKGLxKHHcRHVNM56k5RLGqLOonl0mSTNSuk3ciHACwqGJpKFUMVU5gK8uZBAzUbYpAE+4lUu5hpC2WHXFt9H6GmfrVR6kUbmi5MVZmzmgUYAVUKWmuFSEAvoQ2eC7iYe+Oxj/8AlFikcfr9+XnGtzY3RhV32Dfm1AfU1Eex6IDfb7Bsc73qmrL5w6OJu7FLkym5q4sRZTooKmdUkKRQyc9jxOH1yYxgK6lAVigA8WwFGo3Eu/3Pmjcu5f8AX2+3v9RLpcbL0mahm6/t74mS6vtBjjmDAMdnCjSe04QTmkFH4bTDu1A9lAe/YFA+4iP17ILqC9A1p+jv5R38Kh1gv7hP6ufxv1DtEpvF2KYxN+ojUL5GZQ0NEijT42nAo82+MT8mdGqSDblTOBi8RQEd9gAH6S2RiCuFl4K3iq6CRWXb0z2rrXTiESA+2HWMjEUGHnBARKxHYB37IiHZx0ik3abr5vTdpuJQwlze03icMsDblJDIVZA/JFm7+lNW+zUOjETEWqPM4lAHd64TAnsdzMm2XzxomwvlAJ02ybwF1U72XBtjLCFIutHJ1HUl1DsxxRpBMiqUTNLwXtklDAJvqPmB/pDtZ1+qYyeF5jvq/nw+7q+Dlin5mdfqmMnheY76v58Pu6vg5Yp6+YH+kO8xIB7BinAf85g35OXk31cKycxTVGP3EjjlGq9ekKQrq3mqAIVrems4rogFZHHgqdegY4mKVUhR7HJpKoulfSOPdmG56LVp0kWYayjnEpbB4hKy1ST1XmjsZTA5A3EgvImLybhvqN2+gLG2ROHxVopmdjjrNQhRtbfQogUCIUyBBOWnIQfOL54/b1TKCXkKA7H3NyCBhHfhDs8ohqovjjr7H4XfGuW2mbI5pnb4vcdIypQM81FQKvCzTxIygbLFTAroQAKqO4cWqvILISojLU9NkbcoxCYZFnxOSV1LWvihjPj29vRKlJlVVWZkCJJkTTHbcw77+iWN2APsP/Lv9n6iXS42XpM1DN1/b3xMl1faDHHMGAY7OFGk9pwgnNIKPw2mHdqB7KA9+wKB9xEfr2QXUF6BrT9Hfyjv4VDrBf3Cf1c/jfqpZbK5cTjk8gE3Y3JglMNl7Qg7RmQsz5yLM78yVIGTqEjlMBR4g325Q2NyhBbs+TpkDUXAG51I5uN36O6kpIo2w+0Iv1D7N7CP7MStVk8olCaqvfa3zwQgiVQpAdTGCgcu+Pm/MD/SHazr9Uxk8LzHfV/Ph93V8HLFPzM6/VMZPC8x31fz4fd1fByxT18wP9Id5hTmDs8QAG5uTbs9jb7OvRbGAPsCO/Jyfa7GiiZHhAR3A/OAPn9nhD7ehOam5BHcFOe7PY5eEOxqmOI8Rtz86b7kH/W2IHD2OQv2Ps6qBKHBuJObHtDbhxhv2exyfZ12yvGAdwBf9H8Gvtf8/wBRLpcbL0mahm6/t74mS6vtBjjmDAMdnCjSe04QTmkFH4bTDu1A9lAe/YFA+4iP17ILqC9A1p+jv5R38Kh1gv7hP6ufxv1eZ6FjbiTy1V4I7YOfTu306tlKXmFTqie7bsoXD7yMUkjp6evYV5ihGTM4mBQo83XiO4DsOpTE7mSmSTKbWDyLuLCFJNJXp1kUpeIrPkGC8DLVPsgfVVpDVq+yiePiRTHMJeaSDYQDkDzPmB/pDtZ1+qYyeF5jvq/nw+7q+Dlin5mdfqmMnheY76v58Pu6vg5Yp6+YH+kO+uy6XGy9JmoZuv7e+Jkur7QY45gwDHZwo0ntOEE5pBR+G0w7tQPZQHv2BQPuIj9eyC6gvQNafo7+Ud/CodYL+4T+rn8b9XcaCU6tOgvOIPK4mA1ZTGbymkbCuwCKgAG/AUq3IHKIcQ/Z1kbAbr3et5deovFOIhL2atgTc/t7ewpRqPPrAuR39kJEFDGW4yiHCUxS7cIjuHm/MD/SHazr9Uxk8LzHfV/Ph93V8HLFPzM6/VMZPC8x31fz4fd1fByxT18wP9Id9dl0uNl6TNQzdf298TJdX2gxxzBgGOzhRpPacIJzSCj8Nph3ageygPfsCgfcRH69kF1Bega0/R38o7+FQ6wX9wn9XP436vOq59M6qsjrVWRltt4tW0dURsc6KXXo5qz8cqmJRESnM+UshnJHMpyl49kxEeQoCDHdC91zbm3Nrrr36uu+wRwuZM5BOlGC3kVFgtwVjYxkq9QZgjqsrgT+qREnIU9eYQHYSgHmfMD/AEh2s6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/AEh311/kWT/lVLFXMcl7vX2oWO4F5YpCcJJP3pgcjMmpatitBJF4fIrkFs8cStQvLUgcX0xt9jGNw6QTdM1mGT1tYXYwW1tzdmfIk5dtjusYtuugAdjYQPvqooSWXzte0EKrhpnVuthYrvbWCUO2Ahn/AChpqkCgPYMJC7hygAarKWWqZP2ApKek56leLuWVaXZpcT8OwcKdjpleiREOJtuUyIAIbj52mY8X8oDjyzA8U3ryn9s6VGsyag+57im8kvJTQk7KoIjwgmfYwj2PO3ZJ3bKaxC4cLk1ERyZJdApYyyuLSBtMUd3Vif42rW0z4TsF3TOJOIeQexv9YyC6gvQNafo7+Ud/CodYL+4T+rn8b9XRYjW7yOidj5e1zuJXmfmp/jQS8Jm2R1jk8ejbBIUGOT0sli8XVlT6RzM6FReQBZuAnCIbiGNeK7UtSuSdkrPQyDvDtRAINsklyLIlUT+SpJj25Sy2Xq17qJTBuBq7zfmB/pDtZ1+qYyeF5jvq/nw+7q+Dlin5mdfqmMnheY76v58Pu6vg5Yp6+YH+kO+s17y+V9AzsjVRjVuLs51abc2t7cUB4zqrKHImmUoE27YS8uwb9gNK0tJkETKCYicpUIpiaVjvEjymKHOqTpOSxe1fMlKO4gV9MrybAUR5NKNuGmNlq7KtZgr0auW3orXi8c4ricLX3oqGFmjowWJxapTU9ciKbmnIE1SG5DJmLsapG7ubF7zMlbQr0K0DtzJV7OW/qmwzsm+ERf4Da/2GxKTAUU+IhnhN3VKHa8fIXZph0Cic4u1c6bPfrJji8OY32eXAlry9DznAyMDCjUSaTvypxMbhKVQTm5BDl5WaTZDye1eIcKcqc1bU0UkqlLoXkpSCkKoKIW9ia1NEFBMJRKZJ0mTOoUTFHYQEeGhGYZ7XNeJEnuasqo3Y+Gs7OcTbjsRlfplLlRAoBsAGU/hDz9VFTY7P1fvrSs1aNGyXYsYUGpxein3KU8li9zCVEbYFOLlMDK9KcvLvvp5lt3rFrTezrMkuNdfSx1Ync+2FEkXmxVfJAZIlNMbeR0gAAFc5AysZNxAvIIgGqeWWduncq1Uio61trCyG2k2fYM7JOTJzpmVRN7jNVTrCemEwmIBhEvEIjv5+mRgLkXS5ARRp9ampGLJiMJ3Tcq1MTdqm83CIpFLwvwcPIInfzCbk7YeyLEyZp4ozmCvRW5pbX+eY5v7TO4u4PByJGe5AS3tw6mEySKx8ipNwbivkhXTIBigavEQDTcjjJljZ65Upc6AXElvEpMMaur3tQIUyiprRy9KKXQSSTI5AAKHZuADbFHt+ER+pyC6gvQNafo7+Ud/CodYL+4T+rn8b9UKy5gRTKAbibzt+xvtvq4GXkQfpEnjHhaWrr4W+srq8UDQ5QGzxlrf2cZUnpMhygneO5z64TAzWpwAo0HcU+UQ5fN+YH+kO1nX6pjJ4XmO+r+fD7ur4OWKfmZ1+qYyeF5jvq/nw+7q+DlinqcXMuG+tcPgduP8Ah3pTcGcSp3T5lujcRjGeashkj6+KE4wJSRyPswqqj2xuAm4ecGusBAup/wDn+/fzh1O/fAek9HHddnuNdYCBdT/8/wB+/nDqd++A9J6OO67Pca6wEC6n/wCf79/OHU798B6T0cd12e411gIF1P8A8/37+cOp374D0no47rs9xrrAQLqf/n+/fzh1O/fAek9HHddnuNdYCBdT/wDP9+/nDqd++A9J6OO67PcahUuvVlxbeFNNzLJxjIW2oijIa55uDZyfAuWMzqBx9ijlRJpQMnP91I3NaaruBQ4wSANh1URTydtgqNup/XSxF705LJd8HKsbCi7onLH7O2/k6RGE3GFEom6OshUOJRMUzSHIYs2PObs3ryNpYjEZTdebRtN9TidirT22gpqiQSe4MjjdMvDbE2xh0QTJSiu7uZGkgHGhKooY4pgLXKM8vKC2ZsoyrYftflAPaosZWnufcAcNxESPd8JBcCQRtK1UYjdNzfGVVnLNEzcYD2NUt5ni3tt8qJ9+a/Dcobbsd9XBe+M/yCtncYKm39oZpHIBJYylaIiV2ZU/oBzibG1JNRgO5ikkRvE6cvl7mjA2au9gr1O5s4trEvB8acO8Z7LsJ+/r6ZNgLIxtlYOzsVKB+IAOo8vK4bg6PbkHr+5C9gcq7MZEXkZLZXXyUu9k092Rm1mrn0GM9t3puj04e6ekn6dRKWKxsOkzEJFTtahGZ5XICokVNscOsBAup/8An+/fzh1O/fAek9HHddnuNdYCBdT/APP9+/nDqd++A9J6OO67Pca6wEC6n/5/v384dTv3wHpPRx3XZ7jQorX8tusjUYdmzvOU1cYCjhsPor8jumA+1qbsc4Ib9kOHztVOTHkupZZeJXeo8TPz+rm4rw0VI3Hbq4Xc0milk1Y6OU9OnFYv635opBZUhaU30nEdInfg3NubXgf5T611lL14OXHdpGS3cjvXa6PXJdcWLsXDTQZKiR2/k7+lVyW3FrpuBFCvvekpTsr2YjukdtEXZSurXKxORbvh1O/zR3HPk1DDJS+XLtcGI4OhlFr/AD3b25hauUFtyRQRIkVnkDICYBuFBvsAEfbE3kslldD0MXRz9ZprY2cmi1wWLDNMpTMeRz9b+4ZIjIo7GVTbGL3ld38xDcO48g6pIQleNe+MCo6Voqm+2+WzS+3QpG1sdWVJVkOwPwymJXTZmAkeOkZFrRfwZCAXiBMOMBGijOUTPKcKbigmQe+Enqai5dmnMSlOidBouFFY2hJGBdT0we/LE005CCUO+JxDVW4MeSNsXqjpcYH7Naqqmt9BwL+alHnioYXy95lEKJQgROPyGjVoTmMbjKYohwiICBesBAup/wDn+/fzh1O/fAek9HHddnuNdYCBdT/8/wB+/nDqd++A9J6OO67Pcavrdle5nk+aK2Ll5Pu3+WdFce3zC/KZuOWOUeXppI9XTv7OAjvsYLjZTRV/b3OOtvGLuUzkKgJkLw79YCBdT/8AP9+/nDqd++A9J6OO67Pca6wEC6n/AOf79/OHU798B6T0cd12e411gIF1P/z/AH7+cOp374D0no47rs9xrrAQLqf/AJ/v384dTv3wHpPRx3XZ7jXWAgXU/wDz/fv5w6nfvgPSejjuuz3GmWxF/wDNKP2qac0sajSmCSWMOD43vDxY680LkTcwXWZpunF5XRRJKTx9mrwZnV24d1SAAAZTh1eSAWWyzZrlnu7ZD/eZPc1nxSt0yJg8wMZWW3twFamNxwEnu1sNIq4qlcilIcyjnVj3uJxCGusBAup/+f79/OHU798B6T0cd12e411gIF1P/wA/37+cOp374D0no47rs9xrrAQLqf8A5/v384dTv3wHpPRx3XZ7jUHuZbx9a5hA7j/8O9FrgweVNCfPN0kiMnzzSkMbfWNQ/AB6SRx95BVIe1NwH3Hzw1nX6pjJ4XmO+r+fD7ur4OWKfmZ1+qYyeF5jvq/nw+7q+Dlinpzjz+3UDwzO3/D+OTe9NbvRp1tA4Nzx5Qk5FGd3SU55M9OZNQQEDAPEUR7O/L0b2+6O/ap/oUxdF39nH3r0a/zN+Ce510b2+6O/ap/oUxdF39nH3r0a/wAzfgnuddG9vujv2qf6FMXRd/Zx969Gv8zfgnuddG9vujv2qf6FMXRd/Zx969Gv8zfgnudI02UsztFH5rV2uLbdntBE4Qzzi78gtWcoKI29C38aj6isethUlEwppvAtEeNwCXcBAA1KbX4NY8WsxTtg9WyPZEbqP8aYJNki42mFNMRhrKcpE4RbGMLxs5m87KQj+KanEdsc0z8oRy5tLBZsy2vnoNdbV5S5MPbq1RRxiybMZBjkbEeRq1tzrm0itNTFbGU7G1PCXEoUDmoEycYMU5yaUr83ruNdSo6esp9H0Y1YKiVBVNJGmLZwlRKvZIFMOxTd/Hd3p3kB3FtTApg1SscZsvayMs1Dbj2nqZoZrdQtsa6O0BQ5bVpU1PHypp22ENx7zgXvRvyATsa6N7fdHftU/wBCmLou/s4+9ejX+ZvwT3OmjFGzTSzNlpsHYqnaev8AY7QMzc3P92E0wUlLHuziiVSM2ZKoMUZWpUoCwvhH7vaIEcjAZoabq28iddk1kAyKyPJOvd2hlcnBua5IRMELEKuyyBllYtDI+VNJ4agOqzrPp64xQOU/EMzlxr726zURap/e/HpS7B8TmXGgIlaSMzMyKuKRIOMapzv9t7Pju1AcAFmfNgESm7OpLZvyelhrQZCTqLRl7sbK74zyDoBYeitswrODCpaqBUsbUb5PdK3CMkWNzZSKtMJMkUDNouSagHCoO/5Fq27ZKlqVh7dFbEQe39jm6PWp5tZJmsc3vluI5GJo+WNoCqiROKu7u7s65CEO5kr1dz6PVXtj1gswbe1URbbUu8ZuVZy2kAk7baLjA6tqoHPrYxCIox2MVPAH8lO7M/MKY0gCVt5TDp0QtDb+NWzvtCLXNVv7k493Di8SSlUctGsJinYrfvKdOpFbm2NTrQKkbvSUpUChRmdmtrCubSn6N7fdHftU/wBCmLou/s4+9ejX+ZvwT3OopmrYuFNcKsJk5WBFLhRqMMbWzROB5CMrEd6HvCyMtPTUzCx3djkeXdiJpmUU78tz0qYwEUITUcC50QY5HfnGmM02G94JHJmZheZJcO07UxU79bsz2+VQVlQ+xGWRBQrc6tjocSLPjc4qKAHGBj9G9vujv2qf6FMXRd/Zx969Gv8AM34J7nSMLyQxas1cKgb4k2Q6NOzhDGRsncCizSYDtTHb64cfSQmdvEKQTcKfeZ1p+03AO1HhCX3D8nHd8zpTUjfXurbjZf4yJXSvrTc6qvHoLfhE9EwH55ICFYU3tmR5o/I6PAgInCjbZfGbpY4vTwg50zxaW57EpJsf75QghmAJ3GnpjOpXWtvXEZMigi0vajMudVIw8JHGiMBThQwjyiWNkKxymZLXJWkq74Wot6tcCzb7boiqxlIA+QFGPSu61vLcrEUImRlSCZsgm4jm9YAJSC1XRsXV2Mu5bqRW8qLUM01gKUJlEdrLeF4Uz2qI8sRVyFilOY4cTKOyRR5RJy7DkDEPYx5N40RpcXrWQOgjkAYWpTPNGJLgRnXhl/2MyQU5cYfW6RSRxs25oTAUmwgHCHRvb7o79qn+hTF0Xf2cfevRr/M34J7nXRvb7o79qn+hTF0Xf2cfevRr/M34J7nXRvb7o79qn+hTF0Xf2cfevRr/ADN+Ce510b2+6O/ap/oUxdF39nH3r0a/zN+Ce50sqtbm3aCFPbkbWbjEmIpS2nD/ANHhzjSpkLbQoBysw/yQABvw7AOzcxRRtb6ryemE7AwxZvK0UQt8UkeO9mnw5QbEhpyFp108jLnvZiMqe9OoWEHAClEzYoAdF1vg2tz7UvJBo5yWpD/0WctN2ttw2/A3IzB/3euje33R37VP9CmLou/s4+9ejX+ZvwT3Ouje33R37VP9CmLou/s4+9ejX+ZvwT3Ouje33R37VP8AQpi6Lv7OPvXo1/mb8E9zpsjzA3UDOzNP/D+NreytbRRp0VA3tzP5QkhE2doST5lMlOVNMAACgHCUA7G3JnX6pjJ4XmO+r+fD7ur4OWKfmZ1+qYyeF5jvq/nw+7q+Dlinr5gf6Q7zS1mTd82ponFYiZWNWXh6ZZteWSAUiyoClA2Y4GjrMomlsR1e1GZkMYCl748ZygLzb7DFrLhpaGsc3agpJi3OASXI6WxdKmImmR4nCiJovbJRU9SLiIsKQPbOYnCR6MQpz1w3XvY0yDGe1s+c3KXSi/GSqbu53OmrvJqhF2kMgZLS1ciSupLpHKE3ozwDk+GY2d73MYHQxjcJopLqW0qORN+Y5TnNV3iyAFaUim6LKFSUc43aoFlLUxoKZcBMzKAzKvtOXcO+hzCY/wBRei+D6tTU7JZ21lwrsPpqyo4aMrTAIU+yVcTGECgRMU2Tcdth5B25dWMlFx13OdjEbjSfMy/Upc6lNRycXS3r6SfpSORAb8NGmF+XxhbVuXiOLoIiXk8xLBCzGcMkymnF9bjXvfb939ZrBK40kasemSbT62gYppR6nTQWfiFlcacGt+dEwKR7ZG4AOJmt0EDx3OXP+PV7zZF+rnklhseVqhZpLdZtT/2Ut2p4+x2TISZG2icko60jE0fclX09D30UN3nUTK6NsCtTAIhbGFsyYkaIhAosyxWMtwCG29OxR5KmpiCI+iEpQAdg35Q304RfJ6xTFJXmpQOVmu5GaQIpeSHOpmqojVK7xy4TFtKUzoc8mcWp278MCve5MHJuVKQCjFEWG4a7RMYPVEuni3khFW6Pt9BcOIL1IsZpCeL8/LzMS/ARyZJFE3oyqJi+uiG74tLimo42Jyxt5xNrLdWJoOL0wn3MrEp0yuRmKeQo5lNhMEXlbPXtwKAJgVTKU4CO+sqbDt7FSySbvNsXSbWjoSEphV9tq3iQ3EgKLO7K8CbGrLJAwd6TuBhJ9ycDgIiA8JpRYitfKmhi+UdgZYyDFxrTNzW83Ds4oncmNSH1ucv8syCLwtklqaYgAAVNyrjcoBy+a7WzvbbCFXgt8/lIDxDbgxZmlEZrxIPEArMsgKslxgYNwNtuHLsPKOqqYeTznquMM3QbU1EbQXNcZzcuzMgckzGNzYT59qJfdi3wrc+HOKCnIybEACNxexoZICN6sSXKWVjW3pSmN1LDOrBXcMzio+sSFdWE9ldpLk1FGn68WTaHZNR3ZiKCYxEzGULqTy3yilkbAWFcZta+HQqoyox/sBIXa6L69x93AwpXnkBJPKZrU2uTZD8TM0NDO9maFREOMUzbA0XNsnc6E3bt7IExOyzO30pZ5VF3ECiAfcHthUqEOMDcghxbhuG4cofUWBjd34JJL1vuQUpdqJ3t1C3CNklEUtNHwWJJLjKx6QF5mSKKySrb2liaFjsyL4IVpwdCC3GAZ1c7FTHFqxwHKFSFXSuJFaJjc4q798isfOMDG9QQ6i9DACxNJ6r/AORWrm2pB0cK8QIBjgYfqPmB/pDtZ1+qYyeF5jvq/nw+7q+Dlin5mdfqmMnheY76v58Pu6vg5Yp6+YH+kO1UX5ykmrxCoAR4pmNn9j8Wkkxe5HJVwqAamFhaY6guILH2E4mcxQaSiACZQu4CL5bHByPOOHdqatZyoaq4FbWssiyMmDYKhBKPfxNA8Ws6KlOY5TEZ++zwRQpTEeOyB6/ItyuDE7ZWOks3dayWZDXLlAXLncxlqzwm+Tg7Rb+PSMsrk0uOo9GcVzPbnH06g1Zv30Ocxh00y+3VtFbq3voC0NYN/b4JNM1njc8IqUy5TwRoGnTidujkOioBFGdqSeDEWEh3JXYNvqc95dHBQFyd7Vxi1FaWp24e8t/bs27sjJxMPY4Sxi4ddsH2QDWXMmqKKlqH9hxmaWxrq1OSvoWuR3VjZ34pB5R+6KR2iEwBt523L5l10JlkC8X+bXu90QsWw3fC3idtQ9h0cdo/AEkGG3KZ1U4+SKqFrSbmAO/CyZnMwAZwHULtTAGajjMJttDYvCYJG2mlJRtsfiEZZU2CPsbGQClEhKJjZyplKBhEhShygHm2yvZXt9MFwLH5HRhtiUhJTkO5kil2mKRR2fx0qoKrc0wymqj7A5H4RAxlGij7G+2sh7RVzi4uftUZPqvbPTVonM1sUYuTBIzUFZWMTBsQCSWNOTmoH+u4fZ30dFUOJJYvCIdjcB5dv8u2sYK6HM9EVspM9wsO2sYCPe9sid5pvIMdFBT9CmBYrGrgmMTsjuQPt7/UvVvriQ6MXDhUroFGuSQ6ZMDLK4w/NhikKKUgY5AmvTvdP2hdwOUwCIAO24AOsiY3g1enFLGRxjFu4BcCJ4zoXAm85nIuklKulJF7pW9qPXUnsda+V1S5hYXZo78tBeAzcm1ABkzt8khDPPHrHC8VCiy1cpbYZNIZO7WXMiivrs0bdn9h45XC5U0qIPBladN5ayvDOWvHYjcsYShHLUeUCtyrYa41aLU1UV5rRN0gnFnZQ6CuIGI/QMEpZdG3orGEpQ5s8hJvxGOdvDk1T19KIL09VSlrKUQAO2ASAYNh5djDxgH+fVTWkQqKoaalNVes6QoGr6sSEHYgF3JxGHsAH2f4NtX3zrzrtHO7aWZw3m7SRlsjd2Lu7M7sT1Hk1xx5sL3ikCJDlCJpAeYSbmgMkd7OBhTDv/xB9T8wP9IdrOv1TGTwvMd9X8+H3dXwcsU/Mzr9Uxk8LzHfV/Ph93V8HLFPXzA/0h2nWNSdlbZFHX2gO3vLO8NyTo2V7asG52t2Z1gOicpiKDyGKIDtyhybad7iYUOFPhpd+rqK6vPCqdudJJjnKnBQ+4kGFca0itmYgF2KZhHvKkUA2aT7gOkZoZW6uMdW6ydGMs944JXpSWwV4zx5WROzFTVVWKEltdcdAaenqnZBhlrSd4RTOJ+9qYgoBWu3PlKLZja56R9YN6eRljmR3k0BcuApiHWn1pkxq5lGCAmO4rMh33nFDmArZQAXi0zXVsLdGCXft29BtQTG38raJQ0Kc2lxqFVWYCVHC+EEwApQGApijyCADsA/UZ928WTrlj0mOsuubQUjTRi4uDm+2DMje2MtBEygKhudlMAoy8nbjuIBvuOslrdVFOuNfN8T3R+o6rYeb2gV17ckMQwCA7CJJIOweeJfteZcu+0Fv6xZN000nNBeRju4Noxs8V1lMBkjxbuRML7bo1JEzUq8MuVaRxaTKFACyAG4HUu41485ZPKa2avrmK3sgDVMk6QVU166NvAkKjJIM8GTMXZ/hknJXtau24c5QmEBEBAw+ZYjBRpq6OvuJdS4zffiYUe5t49bW3SUhjsdFYDDuCk0mD6YETF7UAj1YHII6kF2HpKnL+cXktcacxOoCnEDHiEBZ43ZkpjCAhucstgL+UBDh5DbdkR3r3atMBaRro3CsqvtER3V27A+iIUQ1io4DSOtIyrZNyzJcxaOnNzrYNnfZXkVH03rYxy8x7JoxQNpzhsUOcL9kN/qVzZJ33aPbF7386yWQgQIzi8sjMREFE//ADHZFeGMo1BEjCRzezMzQYR4QU4ti6uFIcO7bW9wfb5u0UcHfb1QSKsVZmhc63cbKcY4yT/IAiJZCwRkeAriizspCHYjmMmV3cSjxHTufktSPeJNpZK4pSl9nd9qd7c73XEM+KVK0gdI7aQ6yUrO/riIrKOcuMxgYa8qhBcR4iloHmw1oEn27QNgUDvfe7Nd7N7wORtj8SjS9CSmjFuxUIbhUJFGllTVKUOIBHl8zFTycPkv1YzM8oam4EUcL0tD7HGKSxl/rbgkRJbywT6ZdQq0dYjRiQBLJG7kVZjsrKFAqDsAd9CEZPZn3o9lXedp9lPsd5/2O+yPvQn397x9/fu3sf53fmd+35vfj7fj+q+YH+kO1nX6pjJ4XmO+r+fD7ur4OWKfmZ1+qYyeF5jvq/nw+7q+Dlinr5gf6Q7zXeGT6KsMzhr/AESlA+xaVNDPI4y9tioAJknxjfUFUapIohylMUwcRQEdxANn+5GCcmSxJu3WSJ3eqyB1ou8oxyk6q5OOqY2RgU3ldlipv6oKEOznemVmKBm9FnAnANArLSEu5jG+1TgVnj957XOfsksLd9ro++qjNRneV6ertlclKp4BdQikrau+yJBTOu10BwDhidu/KM2KOgX1spTPmSthTjw1LgHDUUikhsLUpDwlMBjndnNme9gNsCbQAGKUKO52LF9rf3thThRoVyldEnrd6jZVAOQtNNYS+I0swt7IilT4+9j00tS5N+2Jyh5sjiEioCOjBK2R1jj21D6GvaH1E7M8pHAd+0NTLmARDlADCPZ1Cna8YDUVeHuR0rtpd+vYGvvh3+tI/wBM/wBup5No5Hlvu505Pa2emdmInGUw8aW/bcgUzi31NNXN1bRhV0VXS1BVG+roVChwnA5RMkYokOHnCH2+yAP1yLJZTRvNfLjGjIfIFK1l2l8cWnG50msMYnt9JIMN1Gw6UPJTKxGpLRAySt1OdmeXig3PzSbmdyLP7RyyDvc8sHWS13or4YtScykIf4bd9tCNMT5N4y+yGLryKNXShpI53pe2ZYpGZ3KU6ShCKFb3Fuon2UZITe0b1UcQVVvp7j1fNzkjYoUCiUqtbbG21wIgsCm/IYjubbbl050GELZJMurtO1BzDA4SGLTe0Fm40dZrKKbtKqi40ch1z39alqVCiVoa2RNN3TKYAd243AJphJphNHeQPksdGCV5S5WSBhZDRa18SFmQjsdKWOR8sTjdTJlovHiNUaiLQCKioN/KDc0N7m5N0AsnaWON8Rtla+MNMLhcbbEDc01tDETmSJF3EwjxiTiN2RFQwm88ADImlMuK03ykZHXFa31CRTj9dDeCPP1NPXjYOE6KMatik+nIcu+y3rQBMAmDbIvM15oaIIJZ605LIRZSuIuVwrLpXbe4zJlnVgWEg05PYjbiEVxKgpy8QhIqMUx5DCHm1jDc689Jcm8tHSCqhYqyYITmfCc5eAEXxRJdOH29UAA3Aj08NKigAIgBtuSphGOVAlhFa51oCtjpTW3lp5reh/BUViKk9uVWMxCoi5QWWTURPEmhgeUhLwmclC8gBc+99JX4fWjkK676e5N7md0c7qzdd6IJ3V5j9oFZFFJOqiZcgLHr3w7MRcK7iTNXgBubu9BbaNmIF1XSAWgtNKIpMpjNnm5HlHIVKjrLEfpBcK35UqW09mbYyxBf+QXWIMjG8PIABHVRzBMDF8xNkb5XGorMZYR2ZLemkaRXOkrJkLI9O5A7wC+xpeTqJ0iR69VuIqn9xo1DcRdinJlPnh5QCYRO8+Tsom81bbNzthcTPlA4NdwalaQXHvqYqiNKoxSWcmeRak206QHZUC15SidKuTN9X8wP9IdrOv1TGTwvMd9X8+H3dXwcsU/Mzr9Uxk8LzHfV/Ph93V8HLFPXzA/0h31LxGpawssnjMhojN7vHJG2ouzW+tSpD8TW8Mj4kpTqEUE+/CoUQEwAIgG2wyy4eIw1OGl7K6lVr2eORsRfMc5DKUqpdY6L5bsx6iQ29Rq+cK3l9iTszsrLwlUBocDAJD0V4lYPdeC+10CbtHsv8a3KWSi2TbQCZBkOurcWMoIVVvi1NUqq196JgRjXd6cxSC3GTHc0Ygmf0GbcoreEcE6Jxu7AqZhgl/mhnKY5uNaPJlidqri8wWm7QDAwLq8W7i5HMIDpjbbK5HxNhuY8pNyXtH3gqkbT3iUeFm5V+GPscbkoooXIq4+kUxlBiDk+oJiB91OENzahvlO7VQwqzK7NrVazK6sb+ZTLQPrCLHG7O3TfwEpznUk7ConElTgYoEBvZChuZQeGMeThvtOCNeQljmfvbj5XSN0RalbuWLjNOmdihLDVVNTu/wBxbPIIHpzNFOkBzwiloVCeve9rsoSXS42XpM1DN1/b3xMl1faDHHMGAY7OFGk9pwgnNIKPw2mHdqB7KA9+wKB9xEdC/X0tsrD7vIUp6RC/Np1GqF3XOJWYWNoZ5FIVI3VBceN0frk/N07uVUCAUCJmIUe1darF/Na2cwbqyVHBpjN/rdyG31axQox6o6JnSe21PdunksnokRovQMLKR5Axz7N3peiyXLrKKdZCMdFUtldR2ztxD0rHxqv7ZVV3Z5o+hKZzLX2hVAlIJDNKsfVKYg7mHi7Vks/jjZ2D2ctswFMehi0KaCtjeZzONGos9vp9jVEjki6iRBUc3RRR2UEnbGNuOn+dTmTMkKh0OZnSVSmZyZ5ao7GY9G2VAXh8e5G+vigoskeQIkIrKGNwpJk4hEpQ4gjsasHTSCYWQgb/AO0XifCqSmIk83AkEmkJWWQzkrGqRU4SG78nChTYS9oJGKgbU1EyOnfANWSxpUpGiluWRsPcO/zqzopl7/X0uARBed7PdOdH2RoQ9IlFFWV0MAKLMUfoBNyiO79PrnzeI24hkcoQcX2bz6WM0UicebUw4Qd3yRSJWkjTCTfftjmAo/Z7IBI4jYh0keZN2WsjxTUlLaFHvPZVvekO8iyZJDeaTimD5HVUnOrMRwh7PIgOagUSN6yKYqhnGzcclkktra+5lH7DGvFzFtjdaaomTc8UVUlVx9+kEeUq7u3GCYsKvMvbQo6Cx1BAECtaQcZdQ+4WWdKrhlYmuqkXB6bJtRATI6RRtQQOoWPWk5pQlv11DpCmYZeZmqGc3Cp3qcSCJDUD3YizaD/dumbhonC/N2l/ZzeNwObiEyzQ9GRRjVuxWIIFVJE2hlTUKXtiiO4jrILqC9A1p+jv5R38Kh1gv7hP6ufxvmLLrq8xT0wdsbkACgABuI8giP8ABq2dgseJnLYbhFhlIXN6Jd+Bv7u0rUkVjr+wqXEv3GH5jMC7HLrwSFubmaBLEMIJpEoXMQABcgBChSFcyFJSlpwNU1J6xw7UoFLzigipxmAPPEw78nIAB9X8wP8ASHazr9Uxk8LzHfV/Ph93V8HLFPzM6/VMZPC8x31fz4fd1fByxT18wP8ASHfViiuUFkzAG4G8/bsb7baqn9stOfFK6tbWLVAz3GfvFAWyuUEr6dMsntQtHq21b6J1Xf18uqgytMiWOGwuwFAwC8vmNLtBsyLfocNZRUrDXIW1vEmnwp84D1b6VyAIwqpxHNwi0yB2UPsPalDTPbJ7nN/oIzNhWtOlx3zKg83dY5RMDKoiAMkajN60UZbbaOnTOmAlYVmTiGsEeTtR1I7H+UewSqZNB55CHCE3PqLAvrTKo/Nmp9Z3mkf6ILR3QkMPOxxyqTNRlMIzdZUCiocpgMUuqqZeT5yIuHNrUNbxG7i2Ous5t8tttfq2bmZFB6Qjk4OrTRAULl2+kqQ/y0wGFjeylI5IAicxm5vTsB5Ua75odfVzkVdURTJKWtNvoDZV+ZlDMiTLDJK9xtgi1BbSRoivXmO6PBCspkiCYzpQiKSQUD+wuje8sjrRhWt7s1Vabg2uDeYAMVRJZIxkjgYD9koiIDuA+eHm1N1co72QazMVKlVjQBLXzd5lDohTnWKywKGU3Oyy4D8BSlEWtoRWW4BE3DsAmCmsDj+zzOxGHFC6VlS8Mb1IqBtuJfd1SNSmZKm7KUaqVo9HojFueEqMTB2d0VagBdHFRRQjcRrrs4smELp5EZfURJTFbC2AtVBWk0YsamixU6S92Z7cO5tRCIvUTWbmUrmtlKwi+ex5kUUUFNxcq7gaXSOYm2ItXjez1BXAhJjMqxe+1ziGI5iLPUMgrpQu2jEZNI/CoRZkf+IQAxT7FETUcscIrlVlRTudZWVTNcy7NY9RuwMOAxiA8pxiTSgYvZyLp0xnji71MIpn5sxgBvNxABaeU5+5Mrsi1QRZT2q8XEEXFyok/wDZV0FH27Vyomqn35AnOAq1t0OUL2uxXMeIB0u34l42W8tG41FKtRvUyompWTXPf2hQ4LHY326srUllzH9hIugU6Tcs7nSIIdqUOLl83ILqC9A1p+jv5R38Kh1gv7hP6ufxvmW5wczVmLuwVOY0DmMWqqBjpZALcxW7ki5rcAM/kECq6aZW9ZJ4Z/r21mdWoBMCrfXGMo381zmrqw3GKikawXfnpZ5JpLOK1ne5eLXSop0cXhCj3RRxv5+KQlA1cLQU4cYqulac5jHNx/WPmB/pDtZ1+qYyeF5jvq/nw+7q+Dlin5mdfqmMnheY76v58Pu6vg5Yp6+YH+kO+tK28v8A2dtjeaB1Fek6FiF1IPG51F++yQmUQdBZJHRLlI8l4h2UKAHJ5wgO+jPto6C6eJEqU9f1RSWfmYSWDuVW5lakjDIIRcz2aHMgRIo8CTG7sCe9WIm5woFAtU54tZFWNv3GaehXqxY7kt8gsZOT1BHYp0GNnT4J7D5EVJnEDqua72wlMYDFKQobbuE7h2Kd67uW8apJcWKuFwbFwp4vnFm52tA9nj86I9O1sE5YEYJFzFHcXgrRuTtihsUdUVLZy9GSGL6FSd1diQN4I/Ndvn3nTfdHhW0FyKVe2MpWKY+xTmZlNg5A331QNlffG200qaYAIZ5lNhbXev64vYKIljEYiKID5wiBAE2qht/OxQto2VrK5MzjSWotPa2GuRhFQQLUoSNWJrzBgfRAoGBRqeEjB2uxeTbVLNl7aZm5b3ClVENchJlYZeu/MpkLWAiYahKR+tpdInumDbs84YChy77aYHeqxzYbAxmRJtzhSPeRdw2WDd7Wx5McSqSGBx1WZXZjgkAAIo2KsJXlMT7c2I7bs7zmVmnUmcjJ0Qv0AxngfBQUR+EphIx3hueQ/foDgIhueEpiUfOHfTNUw/EGCXOm7bTNPFcrIxML4SRwemfZWnfQY7hGXhcVkPEn3wOZhYmUoKB2oF4QDSKCCXMU9MHal5AAoAA7AHKIj/D9VkF1Bega0/R38o7+FQ6wX9wn9XP43V179TqmfKqF2dt/KrjyiijLMo8SerZ4szKv1WVjYymIdd8EiY82QQ5VBDi233LePyz2YzINZayz1ykHKz8PcgVcI1X3YZqRNS28GjxqkTHPFsbIyZudgHtedfTN5tzj3xKH1j5gf6Q7WdfqmMnheY76v58Pu6vg5Yp+ZnX6pjJ4XmO+r+fD7ur4OWKevmB/pDvrsulxsvSZqGbr+3viZLq+0GOOYMAx2cKNJ7ThBOaQUfhtMO7UD2UB79gUD7iI6CmeGptc6YezTOtAi5FDl+wsKhQ/5dVLo8+TmwSdHBwXGrrnFwxCx7cnStrTAAGNULLW0UUWMJSjucTCYR5R7IjpyerFYjYw2Sfnek9ZvDxaOwtrbZuNbQF4u1UPE4pQqLpcvoTiICPZ87QIoFBFMoDsBfO37O2+/wBayC6gvQNafo7+Ud/CodYL+4T+rn8bqwHkx8O7Iw3I5R6kDNB8jlK56e2p5YJZPE2J+5iBzhpqKmMMCFnrd7vUiUc2h6LudRtAG81Cc5l41bqERC30bqX51lTgxQyOMsZZlJPIntR+kD8dpZE0yrvcofqgyhzjxHOcOyJgApvrHzA/0h2s6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/SHfXZdLjZekzUM3X9vfEyXV9oMccwYBjs4UaT2nCCc0go/DaYd2oHsoD37AoH3ER+vZwOGOsb8nJLr9U2IMQPaGNN7r7Hs5nG4IHfyRkmUT2t6VjT7JuEY/twBxAblKJt9ZH5+eUIiT0x5hXVnVw4NEmyfmaa+WtzJXSAX+7l2TqEOukaRXkmICVF0KchjMVAcye7a57D9Z+YH+kO1nX6pjJ4XmO+r+fD7ur4OWKfmZ1+qYyeF5jvq/nw+7q+Dlinr5gf6Q767LpcbL0mahm6/t74mS6vtBjjmDAMdnCjSe04QTmkFH4bTDu1A9lAe/YFA+4iP16GY3eTtnLJY9Kwz4haa9uQ9poS1JSufwC2pY7JMgU7+PL+KqV5YvaKVx6uiceZnshmMr8l9zERcREfrXzA/wBIdrOv1TGTwvMd9X8+H3dXwcsU/Mzr9Uxk8LzHfV/Ph93V8HLFPXzA/wBId9dl0uNl6TNQzdf298TJdX2gxxzBgGOzhRpPacIJzSCj8Nph3ageygPfsCgfcRH66qyr3NZLSyS4IOsFt1JXesYyHSuI/sb+aOAxMsiMgSTyFISGciNG5hVCgMGwkKcRzabbkZIYgZJ3BnNu4ooxvMWlkgNmdH4q/Tdd/UerrWokfPhbK313K1KiWqA79yDvw9tdGIOWxdg+tfMD/SHazr9Uxk8LzHfV/Ph93V8HLFPzM6/VMZPC8x31fz4fd1fByxT18wP9Id9dl0uNl6TNQzdf298TJdX2gxxzBgGOzhRpPacIJzSCj8Nph3ageygPfsCgfcRH67g55HSyr0AHaZVD324ZKE6gJN92Lxm4GN5f0zGNxFs9Y05nohwEuyUjrQENwAQunbSLfmJnjtvMUceIJFyw6qqHLykYMcbBJgYQyYdjbmqLHlRQ2jggAgKoiYAABEv1v5gf6Q7WdfqmMnheY76v58Pu6vg5Yp+ZnX6pjJ4XmO+r+fD7ur4OWKerjsln39kil2nP/h0pTRWukslZhkEUi9x187Xr2AyWQsAc0V9YYvJvWaiqQAAqELty8QhrrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3eusZYTqC+1r0QuXyifvj/AEXQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3eusZYTqC+1r0QuXyifvj/RdBX4pemd3rrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P8ARdBX4pemd3rrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3eusZYTqC+1r0QuXyifvj/RdBX4pemd3rrGWE6gvta9ELl8on74/wBF0Ffil6Z3eusZYTqC+1r0QuXyifvj/RdBX4pemd3q6M6jXlNLFZeRqktJkFZtnn1Xh472OCCZ7R6cGSZXlaPhRxVSVWOs3R/yPsUhFJEJSuIHDfk6xlhOoL7WvRC5fKJ++P8ARdBX4pemd3rrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3eusZYTqC+1r0QuXyifvj/RdBX4pemd3rrGWE6gvta9ELl8on74/wBF0Ffil6Z3eusZYTqC+1r0QuXyifvj/RdBX4pemd3q1FgLg52YlRG9F8sBXS2ln7avsEM3Sy4nlFI+QVH7JOOMexlVrGJE5QiQCJhMAgAmMAhrrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3eusZYTqC+1r0QuXyifvj/AEXQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3el66tySsHSU1L5Pw0DrKuptW4gFH5RICiJ8keUNhsMAByxHtVeTs6uD5V/F3ygWOuUuQ75hrKI8+zWPvjJcqMWu8pNcWFngad2fYHF0UzQSxPsXCuBnh71u+EROYgnMQm2r409JfHyaZMgU/JrQOEyCQQSAMx8uF8sDs0fJGr3X3i5EizYmI1PKiOZ2BmO9HIoU6ZCFKJBNrrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P8ARdBX4pemd3rrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3eusZYTqC+1r0QuXyifvj/RdBX4pemd3rrGWE6gvta9ELl8on74/wBF0Ffil6Z3eusZYTqC+1r0QuXyifvj/RdBX4pemd3rrGWE6gvta9ELl8on74/0XQV+KXpnd66xlhOoL7WvRC5fKJ++P9F0Ffil6Z3eusZYTqC+1r0QuXyifvj/AEXQV+KXpnd6twyXgf2SV3abP+HSi1FdGSxpmGPxSUXHQztZfZ9JY8wDzpWJhlEm9eKJJCAimQ23JwgGs6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/AEh312XS42XpM1DN1/b3xMl1faDHHMGAY7OFGk9pwgnNIKPw2mHdqB7KA9+wKB9xEfqna991a9KUTaQrukcsdZVtcO9kqu1cFJMTJp8ZhFZgi8SUMRSQPBy8yzpcJQKo5qNzcrJsu7v3Fdq68jy7t0ii71HK53i5LZljVeFVB2K0xElvXMQY4WcoCzlTU5wA3V5wXE5lNN2K2UL7QMecNvWBIza71vNtzVktC48BjezSOhumRO50WKXeQs48IrBs6tfEkDkRr83Pu5zXWVLY7sWJl8qOM1tIBAUa5dIoHIo7GHcgb9sZOTPlEf7ICX7Yjq6t116RAj1enKqXCNWTbiWiNvIFb+MMCKwH5eJGTqv5w27IV223Jy5BdQXoGtP0d/KO/hUOsF/cJ/Vz+N+t/MD/AEh2s6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/AEh31t8vzklOzx1mQUqGyEw1lRK4zu58uIUhkYVAWI9QkL++GARKocwkaGgp+dclUkigbQTazjgvE7rRalp0ryWCktcULgWvduI21UJaYyaMottU1vGLM+oEKiqU4EVI2uQGbk5dLjZekzUM3X9vfEyXV9oMccwYBjs4UaT2nCCc0go/DaYd2oHsoD37AoH3ER+pleRl+XIqtJSFqWSAQJtrDEl10Z+ZE1WywuNI80oAGVWS413MwCizJgKhx/6hpXkVkA8KHc3U6jPC4U2LcUUtZBShUrs0IhKKoCBWSmJUHMoqYedd1DnUObiNyailzLcyZ9g89hD40yqGS+NVhmt5j8oYFefYnpmXKBVCKoLJlHcA7O+/JuURtVeFyZ4bm1a5rS9sOLlHvY0XkjQHKma69vWYDmR5sTlL3+aEwAGJQeMv8mnJt5l9bU5e3DpbT44TOMNtBdS4NfNGC2xI3GkZAwPia1RP5UmrF45zkhpaMnOK/czBsTthNtqHPtrMo/bCxFp7py+O28ntHLWG8U9uRcWRTpT2ctMdNbqLw9CVGhJlDGOVuS4SMjdxiJgKBlLt3UtVK/JzXCtvP8a7JSuDTOy9Wm6Z8yNlfjBzL3fs6YlKNiFkzFGNbCBgNyG2MAl+t/MD/SHazr9Uxk8LzHfV/Ph93V8HLFPzM6/VMZPC8x31fz4fd1fByxT18wP9Id9aWnV0qsksvBKqZ1RslYForiDcC4rwmJTd+lQOtzUXtlSVhid+X1UBImQpiJkcHQStyj1fvJGdGfHmoBRshENbkT0MBtdEBTVBGGQBhVXW7wMICtsqcwnXd1dlnE6h+2CGX+xyuE821upCa712zSdmqE1RcETiCb3H5G0KIczJIxKCJcCzY5piisntuADsbTtbDIe/DbLM7mKTTuXP1v3SFxS2KVdaxV7IvG6e0SceIdO4kchsdVEiygk7+pHT2dAOXgdXHzZjkfkNKwjkGiFKYtFR0y6XsmnMqMBlmKFQtmVMkV9kMnUIZMpSnApQ3MYQKBzJvt9LuuqjNHGormwWSs3QuJqqI2XgHObhHGBTnEAkEnlRUgVkTyqUovixS9oCKbc3N/mwW89lZk72/ujb14QkkQl0eq6ZN0bXMp/RFABMkomonumaiOUxTFOYBDlHdNJ2O0QDLe2Dc2JXus3S1xzBWgnvTku3b0BRFZ+tjLBOUFOIAOwPKgtivEXvY6OmsxWS/wDNqCJjeGytxbU2kZk1qUZVMr1PrCopb5kYWHnTVD5TpSlKkc3sSlKVJkTUOcBABEYnC3qQvLtFYOLyWExysr1AaY37JXQHx9UZGbbhRCRVJgOfYA4zm5REALsvRXdirPLMc7wAzRi5csoYs2Ol3bVNVM9AvTvUCklOn7KJBDSSJ2O5PkR7cinCZybSA484FdEbo2yl7FO7bz1ga5XC5pGq1J2jklZH4AMyPTE8p8SSpF0hAQ4eUonDkAfrXzA/0h2s6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/SHfWauAR5Vtu9mhLmLvhAbOA4qKtUMa6sqyjLOrvVBDEPHo32ocw0lFJ8euECpnTT4nEk0vzkZPni5d1J5XDVPcmeVk0zUKZR4GSPx5pSpTJRqNRgivAi2NpCopE3DYR3HzYnc+1kqfoDcaDvjZIYXNIu7LtMkjj2ybhTvDG9oGTCnVIoBuESmEB5C8pQEBj+MWXdY0WxzLQpC0EYkAh3rt/kmUifIeNoiKicTuiACUFWQTgi8GNzjT2TNrfqc5E3/m7ZA7TWyYjvb871Z0+fqOdE6DVHY6ykUIvIZTKqs5G5nbUwFRRUQAB35NVc+lHfSD2IgFQ6stgrIA7pqtcNia6iwKSSSdsJZDc6XgmAvTnsHAUCNyQgiQgD9TA8jMepo6QO59tnpJwYXimVVM2V6JOZK8x+RsZ6gUpHFpVTmFJ4bDlMQ6Kg9gQLtTXKgSjTFcgYRSo0l9LCrSAhXaFTBNMxUnin4QLUK2umBkzHY3c5T9qKianE40CpAuunnsz19r7h2eeXuCxXHs1csETshEQX5xmY4UKogSUpzKmCidhlZOIJGVVNyTAzWZvKn5jXj9fpyf5ngtP5CRV+ZkVVa17x9fn1ZABujAgFQtQrFlV+E0jYycipDC6Ngd8+cTcopce3coY5zAJqxNUqhkwjlai7xyRMr8UqjI8MrykKiCyayBwMAk3EvH2N+T6z8wP9IdrOv1TGTwvMd9X8+H3dXwcsU/Mzr9Uxk8LzHfV/Ph93V8HLFPXzA/0h31FBJciL8WZsLHHWpVo2uQXouhCLWsjlVoGpiLUtA6zh8YqCsqUTVqIGImoYxRWJuHbF3brhWauXb+7cBd9+9M4tjMo5PYg6cJElTd7pLFXJ1Za3hTWIYeaXNsU5R7Ah5shxsw573XFy/qaRWgkEr5vv/AsdeIpiiq/ICKZJbczhEwJNHENO0m+6OnFsVtrpXdW5z5MLg3DnT25yKYzWXuNY7ySRvb1yrPD29VPEepWUUMAjxG2/6obF2ADEK21nIP8A3R+T/wCLoN26s29SP/y8mtjN1aI7b+lH/wCcPO0KANdabhEOTmTiPZ8/tdQKNVDwqyXJmT1SFtuyUhak8jdneiUpRb12inbkFlqarQXMUAXV5tLne1A/GG2o1OPKr3BiLTN4Qx9+nyXSOqNTSJgtbTqNHsLWvW7GNzNRebnFTlXOjuocBoCn4nT1+IqUMfLI43h9aJzr6KxNslwI3i9ui1OVrebvzoScKdZLZKIKJtCSgCViZVOaKAKKOR3AUwba0RAQ/wDmVP8Ao0Ye9tbyfxKgf8w6Ex26sAADf0o4b/5wHbXMHoqkp/sCmf8Ag+x9nQCjQ1Ztw35Ejef9vbQgVsrB2/ijh/k7HZ1xi21vZ/7o/wD8nsag2R2OD67Qy6EArxrG+r4lga3xqWEhX2GzFkTBFKRRaVJoc3UNqh+AxRAQ7YpTlY8h7StTVY3yjFkI8LHXtDzXGTq6d1MVV1WtPPllAKaSWvllQatcIXJC7qsqigl2Ju7N4ym2NxIk/wAQnsKeXCNyuKvVKahdGd2ZzCDu0uiZBAecTENuQR387kEBEFEqGsMAhuAlSOPZ5f8AV+xooC3VvbDsG6R/+jTVjtfdSVTjCOdvpKirbgGprXnHx/dhTKpNoACglqjxWsqxA8hZCGAp+2c2woOPOkcmWWRZ6bJDGZK1UL6xv7NUFrmd3b3cpTNbg2OJROmcDo8IhtuJeIOQB0hd7Lm9cUsnAa11FiaXSQJPTq6SF8Cgq3QzNFonFWp/l8qdSN1CqsanbqCqWKmQREoBtukukbjSWTIqkbYxeJNQoHIbhMBTF4imAdhABD6r5gf6Q7WdfqmMnheY76v58Pu6vg5Yp+ZnX6pjJ4XmO+r+fD7ur4OWKevmB/pDvqPKuXvvDQUj9knZXN+RYv2+GRp0rm7WdxThNqLdONoGy3KNVRc7CI/dmqlT+/OilAdPv5W1Bj1QqGQLtch5wRtrbdaqyF8mjfLJPIKzEikcntvYyquvYG5cRb4RkVL0IJFJeZmm8mj8hcY+uvRNRVZIrTpJVK1MqdVyS8h9MHu1OM1Bb3ymajs0XokDU53TGZxiZNkEuXNahhtfburXUZIxGaWgijYoR8dpXJKqrWqaqlFopipJVyuZmKbCxYdWJb7AXgitu5PcOBzO+k6umtau5Ns2W4jMWy8qr4pFo25XRp258Q75yJ2a4wm0AuAMtNWVhe+NLZm7EC9pWYjdHLWyGOVwaG5blcmonDBX3zldNHotKWpoY4pSRZ9aa0UXMKhc8nSrG9SlSHvfVEW7TyqMQoanFB5X8mDZOA5FqS6rszdtsQv5Ari2LfL7tcICFo36cVLPyxrjkNd6VV3M+yukqHElOkDeiioerJjpZuDw6URGV3ww4Ys05DKWHD3J7OyngcJmj1RxOCRc9qMT6NtnNSL7LEXZGuf66tbG9pp21MSoVtVXU9JryaKTnjtbWx1Tm3dK49krlsl8IvfRnu/amfW3Suco4ulNYmVRW0tdRw16jkEo5KyGcpEDg6UrqRuXQbtgdh8rQ5FfLZRe9Xk8rypWlpLlW+ta/wBFG7pQ95G2tRSvTPD5RdeQu9o5uox3ITA6xniU09LUIKcyHGKVQnbZgdLr47uExn0dyQlQSZDEm8twZLJK20TVbJzgUGhWH1ocm5zfhyLMiTV1Ve5dQvL0xxilYTKVyCZ62kTU/wCHPydlidFDo/eHPKM3bcoR3zcXeF27qmmzN2wfauOU7kZY9BSOEgbFnFNIhTLphzIKLLLkFUb/AFzbXr26La/FthqrlN9orovU/Z0500taVSi8z6rp4RFHyilMrY6k1KRvYnJ2jlMjT1h1Ea/nUjpqWDxNbnnF2g/OQwyrstI3cdzsrdNyNalyikraYbKLXPsLpL+N/tuUle9SxoGikSDtDRQoT1VQo1LLIpUS+DGQDyvZ6x0iyunl6bcyYAtPcvJ56RkllXG5MYURsfi1ay4EHv8AXprJ3Kbefc6BlqHCpj9DWcdSNUciJaryaWUcKtHju0tWcGXlPhpPCSequn36iNwqy6V2Lft0lhlvCNLYT2I1jXZh1cFyucoFzoKuqpaE1KsUFqwuZ9kzWuYL5XxxMbsernLymyVpZ8tH3/GrIB9I11t3amxCM4nFwk5FZOmanheRxugkzh65pqJOsp3BOkNVqUSb5Eby2lvNCK6auLGx3Yt9CJtblmUZUVaECezi1spdp7ObczVjLVmB3ZT1jouhwFOiZYqqfF5T11qCYvtzj5OKMNNxaJqoIjdu50evXDq6zFBfXvIWZucnsS9wN8qII60woOC0YcEwcjK0itARJMlatbixVsopIYpJpfh9Dct5DKmvCzLPO1vjKF0nmvYLZ28dYFiO2tstYKN0rI86rOMprV/WtIghTp0rfX1C6iNN5Oy592bdsVgLS5dXHr7A31txcuwNw2y9uO+Q5Kd4NAYTUVkjuzCUFWW/K0Zcyx6rdY03VDdU06FNUo1JKstWlYBzrqVnuIfMq+tyoXjjKbP4cX5uG5N9hbW0MzmNVfZ4x4tbdu7V2Ls1s2tUzs0ga4+y1rKWlpX0qla4pUtJVVSWSWbdk7YNUOm2Jt34/Ansl/LK5T4qs+UWPdwJfbWDRS4cIx3vDFGyZBSOMvuhQ0riySCUNhGZSgXqqJzrFATKFfktdouJ8Ry5Z7lySP0pcdqi6bhEF7HUgNxIHB79PE+itFNZFe+GNnPm9kLayU1FXUfBT0VGpSERFHyhN/5RGcVTV3k6spG2w81tQ1MV25I23UYCv1mI5JnGM3ir36A1kWdmJa7lPU0tVWwKqBzRIoQ9BQqU5fXd6MSby09g5NWQnCCPZtRCfwtjfrPMLS3uMyuBAHq21wTXJuTNWc6bRJ4QoKcnByZaFRuAKqoo6QVTo0tLjUg+WufVZ35OxyzKhd5Ypi3eqBQmD3AoJu3W/cIA1FubdusjmWtsWV1kFOdGeQt8aWhzVo6qlKkjUEVTp8VZw5zm3N/T5qzSw9oMf43cKFy628fstfzIN+np6qQXHmrNcq5tbNbbtcXidc9VdIwsMSMso2Go6Glp1qznzeVKYsnHmw1w4pQWfs49WavLYS3Ens6xzeikNxmD2aR19tpM8g8jZC1usIcGuiOm4d+U6JzpXVPmUgUQXAivk/sjjY8ydkk+BdDmZbiX2WgtzII9RSoabxstnZTa2YHm9z7kN1wUaeoeS1dFIKSli5qhNAeca0jK8CX1PzA/0h2s6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9X8+H3dXwcsU9fMD/SHfUHyrtjda+eJuSjpFKCDTi7+Nj7b1vrLsRBlACRpmu/bu8ds7y2VuapEKc6yLO4O8YqnVrQXMnTVSZCIAlfCfz2WTW9Nw72xNdgv1kHkLI4/Xz6U22jre40Iwxavhcat7AbbWzZE3mvqkI/FWWPslPWV1TVFpgXUMoFg7S2Py5zwm8IwLmkrecSpfT3VxibmG2S8jbZIwy2IxVrecPJES6UBVbZIekoHOXC8SKmp0wI3V9PRHEam6d4LdTzJJ6mt731ufLsU13bg48y6Iv1XGYmxQaEKsLPavE2xT7GVonEo9T0CY99atKsRIClWmtViepPFYLcWTZJw+vh93YVeyPOtlLkWBjjApP7WVlO9Wjf3+O3dxOvs+ONZAZGrXVQI0b42trojXCjW0a4IpHDMSRvmRediJ89bUsdm8j6BO4mERU3230UiddbuJMMbW/3epDxcrBa2QO8cCqQKavqaNzPVr1B3RCmr0rEOVDdvKyNXixgtxIbGWoyMgl0rARy7rtYB2dk3dpsveNidMVpPj/dKJRKqoqUzeqaCt1eVelLUqLnqzqVB8bZLLL95mITHFmeSe5lt3lnuzjc501dP5dUyenfJZK07l4f3IkDjVVcRlS7IRtpnWijrfQJIg3NtCKKXBmNBpHOMt7rwjyhBnupyChcpufjrRu1TcWsJDUYvce1chtXiFbZxhsphlPCG9CmpKxN7YqtJMRq25dU51jW/wAvcusk8pbIXGtjbO7kVlVw3O51qqWcPmOV5KaIoSa2t7Tq2MGERdzrkorTnpzwBlhb9RVSoqpVSTooqdPHjGm2N584K21+Dj5IH/FFxcbn4k0VSzSirppLSs8wnTfX4NP0hk5G5CUVlMk0ne6dA9AcpDAnUJp1JLtWXvM43pbYZd1iPD5JWWRuFaiDPtdEHEy4ySNulVdfH7IChUb3sxaUxV22maXKlNTfc6rhUMXVo8g6PJ/OZrurZ6w71jnDHYs3wXq25otzI6ZqrHdOmZ6zyeatFVPCs2jzc/kqXErgCdZSetuAW9VWkPjpDre5C5qxqtxIll9XzHOepXRxeGdwOP5R0hSZBW7r6ylw4oI7J4tcF3Mo5I1tQ2EkzDWK/wAlO1GmRMhMIrHYdsflD5XZTHXyoVt8v6O4sHsdLckXyw9pGkuQ0uvTImS8ETxRm9pFjW6mtwqasQb5m3yN2qAcDKL0rlTJVPBduTt93Ms17w3jl1vrgzfJqM3stxCMjn98tk2lYoa0u1RWY+SOxVPAm2LrVLeEWpLdt7KgSqVVSpUakTKmmkga6mVSOpupd6UXlunJpRIY8vPrhzqbOFLUSyUP7xHIbGoVQyJ5p6JIg96Y42NFOYgDTtqSf3HWVqNZd/OpoZ83YWjCcgW0t38La9R6ZKOGR62DVSx2uL5O2gPGiUNqGMY6Y6JDVC1NUDVisDmUtdqz0uQutlnH75Y/Wqe7BQPI2DXTx8jlz5bj3VPbxI4xZm+ETd8TZZj5cyMwB3dQXaKqmg7I6pLolXUqVKoxlxu3ineJGW3Qtbc+P0dBVuEgn1UrcBomMdm7ZcGGXFoZpXNznVoyGNSNsEqZEEqZHvdUrUSIU9MYpCQi210WeasqVoZuwXJsLcOxVxGy012rHTdgj1dD066ByJ5hFyYeuwvMRcFG1yZnePubZW0xUwMkBkiGC6lj7t3SzRn8Ouw7xVxmLi1Xvxyj8ukrRDnaFSlii7mo74XTKAxhooprbpndw9hcdh5l6ynV9d+uSVdWVZtmTPIZXNotXcLVO2WWucXReZ9FBqlTIIPVdFIfFIbRyljQVD1m40bHQ09MqQw+tCkPVUhspLj2LzJzwyOtpmrcIt98mIU3SfCGKTyWXGoFo28Tli4WnAusCGTKkdITH6yrYWtJt5wjOgagMmhWqpOstvXdO9+Xl0pPcvFN4wjvbFZvOcUGWHXGxykccnTe/RZSmtdhfbSWRKR1EyuG4yineWp3p6ymdVAp/ujURNuJZXIFiuplXcmfWYsN+aY3JXeu9Z54jMjxbpa5gcGO0b1HbeY5Wxomw8crI+mtTvbP3rdaxdQyzkpXrbKaPitWVeSc/wAe44526klk2+V37h9BdfGiX2mkMik1vZXYm5cCshC2pqfYzXS5zQSrpDH5I51DbV+sqqrqKVJBJK4mFuT2W+dLZjtfxygbBN5qa6GMEgkjHD47VSFypYvWNh8NGy37BGnCTO1HXu7tGWGPSSqFophWra6mTOipbDyhlJnLlhdq5THj0xWAZqtzJhmta+fWFc3hkmtQwulFbzEOG1tZRTCetiUiq3Roc21zTqzmQo6ilaxJQF+p+YH+kO1nX6pjJ4XmO+r+fD7ur4OWKfmZ1+qYyeF5jvq/nw+7q+Dlinr5gf6Q76iX3avBNY7b22UAZlX6azOTVoNzRHmdEAAy9QqICCZAEQAOXfcwbAPnSOweKy0ktThexVYUVTUVC6zHP8jKhJQ5hkc52MKkbt0PCHeWLAHOnARcnU3OCm3NfNhXVIgPJtzxuXzv9bVCkcamoGoWTL6Ixh7Y3Y8/s76rGi1kXpJ5P6Bu5xvgpZ1byDOT2+r0dPVs8XRe7kSuIRZufH/14gFIjV1qKixVimIU4bbwy98VjLsws84oXyqoWoa4XZSkTZZK9Ro5VHCnpKJFc6izKY5uBMCkE3CAnAOM1SFTTOpQKobslXAOyP2ft69akpnE6hxVMcwgZQxjpF5xdVZRQwAmkQvbGMI7AHKPniDZ5QjNl6jzhPaWMUtwLWRuurCO8NszFK+lpq5unz0u3mr6SV3Kc6NdNVmQRMqk1JqFMnxuRyGb1YfCGiUQDFaCOq9RC4GY1RSO02dClFH2wrjGREU1XfhA3eluATotKZh2EygnMY3rhvczl4+E25VxDlEPs6hZq62s+pmKfRSQS2LT8GcV4E5Fi8oRiT5GhkVPVKlo5lRV6xVxbF0kqgaES1IAKR0zHA7QnVV1IFRVUoVNCt65p/XFBVLUNahz1OKiYrUVbTqIql34k1UzENsYogBFRpHcvbB5y+/Z30qiqR1LukICA8/2AL9sNVJVwrx3OcogJld+z9vbVMROlr1RUVKAbFUHsmD7Q6lt3n5kcqtqiFNFED0Sa6dEq4PE6m8XtvEGtFeoAwEF0mExoEVDkTWOhTnVXFMxET7SOKSk0Hc6xsUZVGuRWnm0gnsDlDPIYdGpZTuLQ7SeB2xltBWtdS/rNLm3OrC3V1C6ttSkZMxAIocyqFC5m4zCPaprDvuP2dtUiZG91EDqAUQ5tcA7Pn8gaurctrgNVOBtJbiRXPfIr7MITCXVxicOoheJdWMtTP5BHqF2qY5GqerdF6KjNVOK1HRLetqaoWAiJ8f78MtnbjV0PyEaYvXU77FGc0rjNt62V22NcxtRuHIEO9yzEz1zamejonFSjIhWV3AiUCnPwhXvMdo62d2VfHigYb5WjScCKlq0/WNLUkemIqRlKaNXEj1HVI1CIn4DK06paRUvNKFOWo8pz5OhTv6SSMCs1vbayL0qyYytvSSJUPFyI4yFExmOexopawswazFS5/mhVKQHAtcNeoivV1hDJnENhVUDsb/b7PJrjNW1Bh+2sb/p0PDVrhxdnZU3/TqP4t5eSNxk2G81eS0MemFWeprnzGh9ezlAsibDDxL1FramrEQf2rc3ej8JtZdxcUXJlk8SfWSSRuQ0APDM/wAfcEnZqeWyoIQEnRoeKZQ9MqQwKBsYpjhy7b8m/wBT8wP9IdrOv1TGTwvMd9X8+H3dXwcsU/Mzr9Uxk8LzHfV/Ph93V8HLFPXzA/0h3myrITJiettv7XQymAXGvrFQF1e3ZUVgZ45G2RIqK0jk0o24EWwnbmOYOQAAxgWYEKmvtdiTDnZSutXYlureLviSoKfmpzeFUgFLJrnFIcQ5sBOyMIBzbZxGFVyctF/98X/SGopVOrfQOdPTujevUN7gNUSjrkkl01FKOrPQVVDXkpqohRIoKK6KwFMPAchtjBmuvTFdIrK4/nI1tFsIypf6+dSwqUUox5tdLko0W2Emu27QecHbhQeKprqnVpc3pvom8xKarJSt6SdP5B6+MQuFdell9+PKEMuMN34vU3UmFVaF9s1dOY5SIuMbq7LKuQ2up69qq4FT11E8pNRHz1xULitWLAFMFN5TdCikGNlqbkYzZWTW21oX25OX2T9pHm01urUHiTlEnuQ4y27xnuRYW58GyEihK1wM8TJ+IqepdjFpaprpmzhW8oLe29UcXp7pGxIvBKrfxlsepDG6y3IsEOcZA3Vb44Rx0aKp1eXSqb0yVTVUnUoDNgrUdajUFqaqmT8lTjPZmbqPeP8AkJOJOjeFvyEz/wArIzTuNwoXira6ZW2tO45NELkze2xjRdoz+LlHY7FaVqpxFnClazUHfasqFnlzrskaWL3DhPlMrQ2+hrXj1kC75AsUWsVfSa2pCP2cv/c67+P1pb93Bm9pxdnFRI1TVNJXlkdqUHYjimZEU/Jt2xtdl3mtQxe8mTN27Q3Ze5Nd63Mmlr9HHS29x7irSVCR01lmA9NOmptqkWlmCsScIqzC30ddTsIVSaxqiz+MTneTIi81gbg+TIdnNwhV5bv1LoqhN2nIW1VknKatEttuy2ul4T2RNRK5zUe6uurHqhcnOpJQVdLQcxRI4w3jg8lc45MLjzyxcGyMmdTeG480XtVYucZXye19yr2x+GTuey6IWkLHka9NkqXSPNDPSouNcgsvxVqRFBoMb7Jzy9DHYy/GDU+uXOkGe87jemTY7Xcik/Yopb2f23uPkmhkFLY03XYj1U4JAyO1TX09VUUlTWtpkTUonQjly6/KHJl3y7yHxuKvZpxdsgZhC7awC88Uen6tt/QNsfhD7BKiuRuqFGWOSZwlbpJAMdyCvpEqEaWkRp4Lc1qtpJ7XDbm2catdLmh8uJfuorZDfVkF3RuuWURefXUkMcfgtx65pI6RzXakqxyd6Svqao9RUoIVOsKIRdFCtTsXfy1+Qc0IgyXAuNZ9a4V17XzSKQ6itbS3JtDMYBcNudIrEnxeUnpG54pfXfrij9cor0yZ0V8zbbyKT3JuVb7FfyqVjbTY7XYdbw3IoZFN7IPN2rFi+Qq4kht/MYuz3urLXSJ9cWimkjyhXvLa6UpjU9XSuVEdROOWBM4XOjsVnj6lb9ok0WulXya6cNXnUgBvpH1suLf9qv09SSrjizwY9MD4DmsZJJNLnyFIUSzXyglNem7U+vkrbigh7pRXAnVEpae1cJkmZLFa1+vA3RWht7KpGnMYRDH6rqauQ1ISFajpypmQbyUNJ6yNlbfeX3NtZBsfnnDqAPtuba465uX0zwvjT3ok964PbKOX1thOMqbTY9SGFWqulSXNaWSoUpX+vYWR2VSdacCpq+tk/wDiLsfpWWljMesRhBEJHauz5srbnZnntI+XSw2vxU3QZKW+d6aSnuPWurhUtDdUvjIqrXNseeDrUlBVVNPw1VT/AMMa9sV3bktcAuvZC3luLw2ObXtiZ7QTE7DgTJp9TyKW0rHHGufyF+WeiUiRqZwkNUx05W6nXpW+nrgVq1fKK2ylcnn8Fe3vyjXlCcdYVJm3KzJyklEBaYzcRlqYRNI9FksgGljkE2tf6woXGqcqujqHV5aj1FM71NZR1ZyDZCzt+0cj4bUYF3YuXGM3koDlNltH2q514m6SossBqXZrob6pQm/MNqKBhPPK+kcmytpa1nc2xnIqqz1CjcaSeVL8mQ/wS8uOzlWPdRkNELKPbNMWC2TwgoKEiuBCwhq9VT0UaZqpQSSlgOJKiLrBzhkyNwqEbzk+wP8A4PtfY82lPiVk/ci0NJUuJjniKcqoa21jk5LKJkFaTW7uINZaeqOJDBvXujQbmh4tjbAbWTF6vKX2SjlgI3jlRNldTXEpYXOreGuRGWeCyC5Fwp8qwSWpUjB49TRhBtc0nllMDI8JuQgmAEKXTK2WkyzgUfnjqCVBSWqvTVlszcVZ5OHKzszHPvW9PKqhQpQMIMjo8gHYAeTzfmB/pDtZ1+qYyeF5jvq/nw+7q+Dlin5mdfqmMnheY76v58Pu6vg5Yp6+YH+kO8x0vhkTNTUhjg4tdvbaNayy9wbvS8qSdQhHIIxnFNRTjESis6qCRoZkjAZU5QEhTOFzb2O6TTb5gWd26zVjo7VqVFurUsi47iamIYBGTy6ppTF78vigFUdVOQpE24qTeTzAH7A76oF0KgUvW6iZgHi7HCJR5NU8quvbPGy5svrIK323ksvuJjHjrM5bOoQ2sbZG6CNXKk0jtg5PtzW+gYWelpUAkFQ5HRRpyAQxeENFiH5kOBblS1zg5rtbBQ4LYlnLTvr62szQ71kfo6OziYsrk6ULFQEWWoQRWUGkSOIidMpgJnp5VG2OMjbLrfQppkcYdbv2Csq6z6wEBjdOmiwVEqu05QCvuaMupaM5EWxhRdebbEjFp+bNXG5uhqAsmoENxwhvskYYzDJSysUhTuY0yhjcIrJnq70Uk7e9xd/opPHnWqo0Y/XUtZRU1FUKEVIcxjiMktJ7UuOCtnZa8kkz7Y+rxzsPV2IqZGRRRZN8prH1dvVrTtTsmqqYxV6RnQUKJh2NyjvQwd0xow3ksKjrm4u8Th0xxAxgmcUhte7UbbQuZoTHJZah4Z4ZTuFI0UpVkGtGkp1OYKJiCIb6Y4XMcbcQZuzQ+KGgULNPMTcapw+QyFE9detIrD5TK7XPEoi7Ez+uz976agrKdNtAQ9agjwE4Yxd0LOY0UV6oo5Rx3ZL4NeN1gma+NK6RNnpo+wOK15mq3dHc9wraBjo0qQVal1WOtTplIqJygAanjzBLeWEgvts0zjS3aY4RYaykPhl2UXgtYDwF04DHII2Qe46jx3xWGrUem+uPUioIqGMO2pJGYtYnFiNQib040c0tmwYw48s9o5aiZNNAysltDQW1p7ZPlZzSRS+uKlpUqA4Q7fk1diqsI846Ye3EpGplmcGZoLizGY1a+40vbHqPs7k0OEcx/Ttu0xibJQ869c1Otc2VbdV1TaWkr1acixVwp2Wlf3B3PSjVVLi+OtatWvMjfnSuqXaRyl8rV1lV65+lD/XVLhXLnMYy1XUqHERE2qu0s2YrU3WtXWyJCWqW3vlZ60l94JSyumoztqUoZ4peOFzliYpL3uP63PX0KFPVqIACZlBIUoAyQJwsnipMIdFFl6mHRK5eKmNV1YzBz1KCdPUU8EYblWslbVB21RFEpRpGlKjpQKUABPRKFtitqHGIEZqmMhb2X2ltfP7W+xuqphoTsRrWTqJSO3R2lCjHm6enFs5qlKBeZAnCAg9utrrfWKtISWtx2yYx60NibLWngkxb1W9ZqqaGYW3t1BYzAJVSVzbUqU9Sm4NlQWpRMJVQOXk1NY1CrDYswmFXLZaiPXJt3DcZMf4na+4jJUkpk122eWwj9uG630wQVJRpcXfFtqREUiDvuUogsynxbwwXYquINsBro/WYi4z10fcYSxyVCZMEVcmGttau0uLFHZVTEr26mXRUSb6ovHTgkIju1NCOI+D1HTR5aqViyzdhri22uUPUrHpWRLHhbw32mpnaHG7+1B6wgti9JzdQcVCcJhEdT6f1TvYWw16JtBpcpVZBIY1xeudZ5OGtgO6wxlvs9WaoYRdabskpkLLRty7vU1T1XNh1yVXrdZNNQNHlDhPTSm6rnMFbmS6erUxeN8uArVUdQg5INLlUPCFMyx+ja6FsaqBUy6NI0NtLS9smkADMLaZWHizjiLlJcB2ktyFGaGROJNdnbnzdX+U7pNMBgcej8TpIROFEyhJWukoUSDv3zKXjKom4Vd+PJi3bxnh+ON4KAk9o4Nc+aTNrj0VrJAcXU5bOyS2tsrvsUltdLKSpB0ZCCKQNCRgImJ0+bEOn3yf/ALqmRPira6ffJ/8AuqZE+Ktrp98n/wC6pkT4q2pnhZn9LcMcqcDpHEZUxR2E0U1ujPp3AWx+p16V+gCbBciwUSjMoszNAOYyjS5OpO8wn+5cZTnSK5P+P1fcXDCfViP+ylgjgNzbUg5gADztRb64NR7JRApicQFaH9lT7I8PZDQY5XRvi8X8lg3Rlcyo5Eu8y9SLRiJKpsMdjkFgTE+qLjGI3Sx6PFdTthDHTB8da8QMYvbF18wP9IdrOv1TGTwvMd9X8+H3dXwcsU/Mzr9Uxk8LzHfV/Ph93V8HLFPXzA/0h2pjLcf8c5BkxeCgoyJQizzTOLaWyTkbqpxFBZ+ntypREozHY2gIlFU4Cs7gUwcDeoIGAsmv/kvi7VS2WO5xoWBpo8jsT2mEW+iyZ1TtEFt7HF76ppRuOU5T8vEYVahQRVr1Fq8yhx6jHxmcOvGA11GPjM4deMBrqMfGZw68YDXUY+Mzh14wGt0sHDFEPsZNYdeMBoASwnWIAdjbJvDzk+MDqgy+z6jra75S0Dg5FtHZgzqyzKMWHRpqhREZs/PcarZXE5LdSoBAFGRRqVOgxJnA26jmcO9ddYZs8nxmVCMQ7YrFeIHBrU2qfL5ttzHUNlguZc+4GOxrhWyeJOqbfmWRJ7OWOlOYpy98RVMPEXybflBgH7WHuRX+Geu18nD5QkP/AFPsi/8ADP7Wl5LaTDbL27Mdbn90ilbJbbY23onLM3ShhSIEhYFXyNxZSnSlMZMJCqtplOJI/ow/1tv93D5Qj/2Pci/4f7M9tAH+7i8oRyfYw9yL/wAM9cvk4fKE/wDsfZF/4Z6Kf/dweUIHb/8Ax7kX/o9rTQlHyb3lCR3DbqeZF/4ZbcmjGP5NfygwiYRERHD3Irs/wjbLfW6Xk3PKDk5d+TD3IoP/AOM9bD5N/wAoOIfYHD3Iv/DPW/8Au3fKDb/A8yK/wz12vk3/ACg4bfYw9yL/AMM9bh5OLyhIf+p9kX/hnrk8nJ5Qr/2Psi/8NNAYfJyeUKHYeX/+n2Re/wD+2mpHaJuwwzCeLsRFibJXJ7WN2Nt6nK4Meir/AMJWCQSOCJxUJXH43JVS7JOKiZUz7CUg78gjx+Tb8oQbffs4e5F/4ZBoTKeTW8oIYTfZw8yJ/wAMtRfEPM3BnyhL5hhJnejY7fzV7xAyMcnfFx7qDmAqqaqlthVWsbWcIFfGsd+8hxFzbCgHfBNb6v5gf6Q7WdfqmMnheY76v58Pu6vg5Yp+ZnX6pjJ4XmO+r+fD7ur4OWKemTP3D/AI2b1tnXyZrfiC70IZX2PxmGOz5fKqT3ieVCK3OWrpM9Gp4vH2sggDKKCh3XiK5AaiMnr93bD9bZh3+SWv3dsP1tmHf5Ja/d2w/W2Yd/klr93bD9bZh3+SWv3dsP1tmHf5Ja/d2w/W2Yd/klr93bD9bZh3+SWv3dsP1tmHf5Ja/d2w/W2Yd/klr93bD9bZh3+SWv3dsP1tmHf5Ja/d2w/W2Yd/klp2juQXkaxybmVVcGXyFjuEbyh+BlmlWODSJ6VVg1vhi8PitRHao0IYzmbO/HCVd7MHOHAphENfu7YfrbMO/wAktfu7YfrbMO/yS1+7th+tsw7/ACS1+7th+tsw7/JLX7u2H62zDv8AJLX7u2H62zDv8ktfu7YfrbMO/wAktfu7YfrbMO/yS1+7th+tsw7/ACS1+7th+tsw7/JLX7u2H62zDv8AJLX7u2H62zDv8ktfu7YfrbMO/wAktSC77P8A8MzAmi7UrYmaKS259H5TfCainsnibEJlWKPv86prapSt7jsbUAeabTqKJoiAbF3HYf3dsP1tmHf5Ja/d2w/W2Yd/klr93bD9bZh3+SWv3dsP1tmHf5Ja/d2w/W2Yd/klr93bD9bZh3+SWv3dsP1tmHf5Ja/d2w/W2Yd/klr93bD9bZh3+SWv3dsP1tmHf5Jae8/cwMAjYQ22avJmuGILRQjlfY/JkZFPkMqoxeJmUOrbFahkzKaoi8gdCAAsoIJnauIzkJq0qes6/VMZPC8x31fz4fd1fByxT8zOv1TGTwvMd9XTs1mJkUnZ25csy9uHc+OxwbR3wuCaqgb7aTH6JNT936tpa+ZxmmMaSQNwKUiihVf9iA3AUpi8XXn+LNmL4v8Arrz/ABZsxfF/115/izZi+L/rrz/FmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/668/xZsxfF/wBdef4s2Yvi/wCuvP8AFmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/668/xZsxfF/115/izZi+L/rrz/FmzF8X/AF15/izZi+L/AK68/wAWbMXxf9def4s2Yvi/668/xZsxfF/115/izZi+L/rrz/FmzF8X/XXn+LNmL4v+uvP8WbMXxf8AXXn+LNmL4v8Arrz/ABZsxfF/115/izZi+L/rrz/FmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/668/xZsxfF/wBdef4s2Yvi/wCuvP8AFmzF8X/XXn+LNmL4v+uvP8WbMXxf9def4s2Yvi/668/xZsxfF/115/izZi+L/rKjGXGvKobiXmuUWx5odDAstkREe/QRfI6z1wpEIyC4lqYdF6caWNxquU4TOhROUvCQDCIAF/Ph93V8HLFPzLpYf3okU7jVsLvlgIyp3tg6sTNN6AYHPYzcZmUYXmUxmZR5A6knhFCChRaTbpcYbbn5On/P/wB1XHXxVtdP+f8A7quOvira6f8AP/3VcdfFW10/5/8Auq46+Ktrp/z/APdVx18VbXT/AJ/+6rjr4q2un/P/AN1XHXxVtdP+f/uq46+Ktrp/z/8AdVx18VbXT/n/AO6rjr4q2un/AD/91XHXxVtdP+f/ALquOvira6f8/wD3VcdfFW10/wCf/uq46+Ktrp/z/wDdVx18VbXT/n/7quOvira6f8//AHVcdfFW10/5/wDuq46+Ktrp/wA//dVx18VbXT/n/wC6rjr4q2un/P8A91XHXxVtdP8An/7quOvira6f8/8A3VcdfFW10/5/+6rjr4q2un/P/wB1XHXxVtdP+f8A7quOvira6f8AP/3VcdfFW10/5/8Auq46+Ktrp/z/APdVx18VbXT/AJ/+6rjr4q2un/P/AN1XHXxVtdP+f/uq46+Ktrp/z/8AdVx18VbXT/n/AO6rjr4q2un/AD/91XHXxVtdP+f/ALquOvira6f8/wD3VcdfFW10/wCf/uq46+Ktrp/z/wDdVx18VbXT/n/7quOvira6f8//AHVcdfFW1L8esephd6ZwibXceLyODpd97h0jlCcrkUIgMAXaU1oFbqFR5ONAx2/oRIUWwTpGMYwnP2ol/wDc3//Z\" alt=\"\" /></p>\n<p class=\"MsoNormal\" style=\"mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: normal;\"><br /></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">So imagine you are </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"http://www.psychologytoday.com/blog/mental-mishaps/201404/the-dangers-going-autopilot\"><span style=\"color: blue;\">driving on autopilot</span></a><span style=\"color: black;\">, as we all do much of the time. Suddenly the car in front of you cuts you off quite unexpectedly. You slam your brakes and feel scared and indignant. Maybe you flash your lights or honk your horn at the other car. What&rsquo;s your gut feeling about the other driver? I know my first reaction is that the driver is rude and obnoxious. </span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><span style=\"color: black;\"><br /></span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">Now imagine a different situation. You&rsquo;re driving on autopilot, minding your own business, and you suddenly realize you need to turn right at the next intersection. You quickly switch lanes and suddenly hear someone behind you honking their horn. You now realize that there was someone in your blind spot and you forgot to check it in the rush to switch lanes. So you cut them off pretty badly. Do you feel that you are a rude driver? The vast majority of us do not. After all, we did not deliberately cut that car off, we just failed to see the driver. Or let&rsquo;s imagine another situation: say your friend hurt herself and you are rushing her to the emergency room. You are driving aggressively, cutting in front of others. Are you a rude driver? Not generally. You&rsquo;re merely doing the right thing for the situation. </span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\"><br /></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">So why do we give ourselves a pass, while attributing an obnoxious status to others? Why does our gut always make us out to be the good guys, and other people bad guys? Clearly, there is a disconnect between our gut reaction and reality here. It turns out that this pattern is not a coincidence. Basically, our immediate gut reaction attributes the behavior of others to </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"https://www.youtube.com/watch?v=drjSN9FrZtk\"><span style=\"color: blue;\">their personality and not to the situation</span></a><span style=\"color: black;\"> in which the behavior occurs. The scientific name for this type of error in thinking and feeling is called the </span><a href=\"http://en.wikipedia.org/wiki/Fundamental_attribution_error\"><span style=\"color: blue;\">fundamental attribution error</span></a><span style=\"color: black;\">, also called the </span><a href=\"http://www.wjh.harvard.edu/%7Edtg/Gilbert%20&amp;%20Malone%20%28CORRESPONDENCE%20BIAS%29.pdf\"><span style=\"color: blue;\">correspondence bias</span></a><span style=\"color: black;\">. So if we see someone behaving rudely, we immediately and intuitively feel that this person IS rude. We don&rsquo;t automatically stop to consider whether an unusual situation may cause someone to act this way. With the driver example, maybe the person who cut you off did not see you. Or maybe they were driving their friend to the emergency room. But that&rsquo;s not what our automatic reaction tells us. On the other hand, we attribute our own behavior to the situation, and not our personality. Much of the time we feel like we have valid explanations for our actions.</span></span></p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 12.0pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><span style=\"color: black;\"><br /></span></span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">Learning about the fundamental attribution error helped me quite a bit. I became less judgmental about others. I realized that the people around me were not nearly as bad as my gut feelings immediately and intuitively assumed. This decreased my stress levels, and I gained more peace and calm. Moreover, I became more humble. I realized that my intuitive self-evaluation is excessively positive and that in reality I am not quite the good guy as my gut reaction tells me. Additionally, I realized that those around me who are unaware of this thinking and feeling error, are more judgmental of me than my intuition suggested. So I am striving to be more mindful and thoughtful about the impression I make on others.</span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\"><br /></span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">The fundamental attribution error is one of many </span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\"><span style=\"color: blue;\">problems in our natural thinking and feeling</span></a><span style=\"color: black;\"> patterns. It is certainly very helpful to learn about all of these errors, but it&rsquo;s hard to focus on avoiding all of them in our daily life. A more effective strategy for </span><a href=\"https://www.youtube.com/watch?v=7A_xa7UPAFQ&amp;list=UUYoi6XbNHiZtLh2o6efP13Q\"><span style=\"color: blue;\">evaluating reality more intentionally</span></a><span style=\"color: black;\"> to have more clarity and </span><a href=\"http://intentionalinsights.org/living-intentionally-3-steps-to-gaining-agency\"><span style=\"color: blue;\">thus gain greater agency</span></a><span style=\"color: black;\"> is known as </span><a href=\"http://wiki.lesswrong.com/wiki/Map_and_territory\"><span style=\"color: blue;\">&ldquo;map and territory</span></a><span style=\"color: black;\">.&rdquo; This strategy involves recognizing the difference between the mental map of the world that we have in our heads and the reality of the actual world as it exists &ndash; the territory. </span></span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><span style=\"color: black;\"><br /></span></span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">For myself, internalizing this concept has not been easy. It&rsquo;s been painful to realize that my understanding of the world is by definition never perfect, as my map will never match the territory. At the same time, this realization was strangely freeing. It made me recognize that no one is perfect, and that I do not have to strive for perfection in my view of the world. Instead, what would most benefit me is to try to refine my map to make it more accurate. This more intentional approach made me more willing to admit to myself that though I intuitively and emotionally feel something is right, I may be mistaken. At the same time, the concept of map and territory makes me really optimistic, because it provides a constant opportunity to learn and improve my assessment of the situation.</span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\"><br /></span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;; color: black;\">Now, what are the strategies for most effectively learning this information, and internalizing the behaviors and mental patterns that can help you succeed? Well, educational psychology research illustrates that engaging with this information</span><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><a href=\"http://rer.sagepub.com/content/56/4/411.short\"><span style=\"color: black; text-decoration: none; text-underline: none;\"> </span><span style=\"color: #1155cc;\">actively</span></a><span style=\"color: black;\">, personalizing it to</span><a href=\"http://rer.sagepub.com/content/60/4/531.abstract\"><span style=\"color: black; text-decoration: none; text-underline: none;\"> </span><span style=\"color: #1155cc;\">your life</span></a><span style=\"color: black;\">, linking it to</span><a href=\"http://link.springer.com/chapter/10.1007/978-1-4612-3618-4_4#page-1\"><span style=\"color: black; text-decoration: none; text-underline: none;\"> </span><span style=\"color: #1155cc;\">your goals</span></a><span style=\"color: black;\">, and deciding on a</span><a href=\"http://books.google.com/books?id=JAYoZ3jmUzYC&amp;printsec=frontcover&amp;dq=inauthor:%22Ian+Ayres%22&amp;hl=en&amp;sa=X&amp;ei=4pxrVKj7F9TLsAS4-4LICA&amp;ved=0CFQQ6AEwCA#v=onepage&amp;q&amp;f=false\"><span style=\"color: black; text-decoration: none; text-underline: none;\"> </span><span style=\"color: #1155cc;\">plan and specific next steps</span></a><span style=\"color: black;\"> you will take are the best practices for this purpose. So take the time to answer the questions below to gain long-lasting benefit from reading this article:</span></span></p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\"><span style=\"color: black;\"><br /></span></span></p>\n<ul style=\"margin-top: 0in;\" type=\"disc\">\n<li class=\"MsoNormal\" style=\"color: black; margin-bottom: .0001pt; line-height: normal; mso-list: l0 level1 lfo1; tab-stops: list .5in; vertical-align: baseline;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">What do you think of the      concept of map and territory? </span></li>\n<li class=\"MsoNormal\" style=\"color: black; margin-bottom: .0001pt; line-height: normal; mso-list: l0 level1 lfo1; tab-stops: list .5in; vertical-align: baseline;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">How can it be used to address      the fundamental attribution error?</span></li>\n<li class=\"MsoNormal\" style=\"color: black; margin-bottom: .0001pt; line-height: normal; mso-list: l0 level1 lfo1; tab-stops: list .5in; vertical-align: baseline;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">Where can the notion of map and      territory help you in your life? </span></li>\n<li class=\"MsoNormal\" style=\"color: black; margin-bottom: .0001pt; line-height: normal; mso-list: l0 level1 lfo1; tab-stops: list .5in; vertical-align: baseline;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">What challenges might arise in      applying this concept, and how can these challenges be addressed? </span></li>\n<li class=\"MsoNormal\" style=\"color: black; mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: normal; mso-list: l0 level1 lfo1; tab-stops: list .5in; vertical-align: baseline;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; mso-fareast-font-family: &quot;Times New Roman&quot;;\">What plan can you make and what      specific steps can you take to internalize these strategies?</span></li>\n</ul>\n<p class=\"MsoNormal\" style=\"margin-bottom: .0001pt; line-height: normal;\"><span style=\"font-size: 10.0pt; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\n<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\"   DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\"   LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]>\n<style>\n /* Style Definitions */\n table.MsoNormalTable\n\t{mso-style-name:\"Table Normal\";\n\tmso-tstyle-rowband-size:0;\n\tmso-tstyle-colband-size:0;\n\tmso-style-noshow:yes;\n\tmso-style-priority:99;\n\tmso-style-parent:\"\";\n\tmso-padding-alt:0in 5.4pt 0in 5.4pt;\n\tmso-para-margin-top:0in;\n\tmso-para-margin-right:0in;\n\tmso-para-margin-bottom:10.0pt;\n\tmso-para-margin-left:0in;\n\tline-height:115%;\n\tmso-pagination:widow-orphan;\n\tfont-size:11.0pt;\n\tfont-family:\"Calibri\",\"sans-serif\";\n\tmso-ascii-font-family:Calibri;\n\tmso-ascii-theme-font:minor-latin;\n\tmso-hansi-font-family:Calibri;\n\tmso-hansi-theme-font:minor-latin;}\n</style>\n<![endif]-->", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q99ksjGxPxuYiGrmQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "27887", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DB6wbyrMugYMK5o6a", "pEzzx54xeHLwjNAMv", "LdXqsEJ6Gnnk9LFgZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-10T00:01:56.848Z", "modifiedAt": null, "url": null, "title": "New LW Meetups: Paris, San Francisco", "slug": "new-lw-meetups-paris-san-francisco", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:06.935Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BPGPmYwjoKLjLeXZ7/new-lw-meetups-paris-san-francisco", "pageUrlRelative": "/posts/BPGPmYwjoKLjLeXZ7/new-lw-meetups-paris-san-francisco", "linkUrl": "https://www.lesswrong.com/posts/BPGPmYwjoKLjLeXZ7/new-lw-meetups-paris-san-francisco", "postedAtFormatted": "Saturday, January 10th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20LW%20Meetups%3A%20Paris%2C%20San%20Francisco&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20LW%20Meetups%3A%20Paris%2C%20San%20Francisco%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBPGPmYwjoKLjLeXZ7%2Fnew-lw-meetups-paris-san-francisco%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20LW%20Meetups%3A%20Paris%2C%20San%20Francisco%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBPGPmYwjoKLjLeXZ7%2Fnew-lw-meetups-paris-san-francisco", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBPGPmYwjoKLjLeXZ7%2Fnew-lw-meetups-paris-san-francisco", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 572, "htmlBody": "<p><strong>This summary was posted to LW main on January 2nd. The following week's summary is <a href=\"/lw/lio/new_lw_meetup_dallas/\">here</a>.</strong></p>\n<p>New meetups (or meetups with a hiatus of more than a year) are happening in:</p>\n<ul>\n<li><a href=\"/meetups/18c\">Paris LW Meetup - LHC Exhibit:&nbsp;<span class=\"date\">17 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/18f\">San Francisco Meetup:&nbsp;<span class=\"date\">12 January 2015 06:00PM</span></a></li>\n</ul>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/186\">Bangalore Meetup:&nbsp;<span class=\"date\">10 January 2015 11:02AM</span></a></li>\n<li><a href=\"/meetups/15w\">European Community Weekend 2015:&nbsp;<span class=\"date\">12 June 2015 12:00PM</span></a></li>\n<li><a href=\"/meetups/188\">[Frankfurt] New Year meetup Frankfurt:&nbsp;<span class=\"date\">11 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/187\">[Munich] January Meetup in Munich:&nbsp;<span class=\"date\">17 January 2015 03:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<li><a href=\"/meetups/17c\">Utrecht: a critique of effective altruism:&nbsp;<span class=\"date\">04 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/18a\">Warsaw January Meetup:&nbsp;<span class=\"date\">13 January 2015 06:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX - Caffe Medici:&nbsp;<span class=\"date\">03 January 2026 01:30PM</span></a></li>\n<li><a href=\"/meetups/18b\">London First 2015 Meetup, 04/01/2015:&nbsp;<span class=\"date\">04 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/189\">[Melbourne] January 2015 Rationality Dojo - How to learn faster and teach more effectively and teaching:&nbsp;<span class=\"date\">04 January 2015 03:30PM</span></a></li>\n<li><a href=\"/meetups/18e\">Vienna:&nbsp;<span class=\"date\">24 January 2015 03:00PM</span></a></li>\n<li><a href=\"/meetups/18d\">West LA&mdash;What Is FAI?:&nbsp;<span class=\"date\">07 January 2015 07:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\">Berlin</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Boston.2C_MA\">Boston</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Brussels.2C_Belgium\">Brussels</a></strong><strong>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Buffalo.2C_NY\">Buffalo</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Canberra\">Canberra</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Columbus.2C_OH\">Columbus</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Moscow.2C_Russia\">Moscow</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Philadelphia.2C_PA\">Philadelphia</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Research_Triangle.2C_NC_.28Raleigh.2FDurham.2FChapel_Hill.29\">Research Triangle NC</a>,</strong><strong>&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Sydney\">Sydney</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a></strong><strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington DC</strong></a></strong>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.</p>\n<p><a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview is posted on the front page every Friday. These are an attempt to collect information on all the meetups happening in upcoming weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll also have the benefit of having your meetup mentioned in a weekly overview. These overview posts are moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cincinnati</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cleveland</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> </strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tel_Aviv.2C_Israel\">Tel Aviv</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Warsaw.2C_Poland\">Warsaw</a></strong><strong>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BPGPmYwjoKLjLeXZ7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 2.3553215308887575e-06, "legacy": true, "legacyId": "27830", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dwcGzSbv2nPC3mTgb", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-10T01:04:28.000Z", "modifiedAt": null, "url": null, "title": "\"Evil\" decision problems in provability logic", "slug": "evil-decision-problems-in-provability-logic", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benja_Fallenstein", "createdAt": "2009-05-28T03:11:28.292Z", "isAdmin": false, "displayName": "Benya_Fallenstein"}, "userId": "w8WLipzZMmA5FNyc8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5bd75cc58225bf0670374e8c/evil-decision-problems-in-provability-logic", "pageUrlRelative": "/posts/5bd75cc58225bf0670374e8c/evil-decision-problems-in-provability-logic", "linkUrl": "https://www.lesswrong.com/posts/5bd75cc58225bf0670374e8c/evil-decision-problems-in-provability-logic", "postedAtFormatted": "Saturday, January 10th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Evil%22%20decision%20problems%20in%20provability%20logic&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Evil%22%20decision%20problems%20in%20provability%20logic%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374e8c%2Fevil-decision-problems-in-provability-logic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Evil%22%20decision%20problems%20in%20provability%20logic%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374e8c%2Fevil-decision-problems-in-provability-logic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5bd75cc58225bf0670374e8c%2Fevil-decision-problems-in-provability-logic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1637, "htmlBody": "<html><head><style type=\"text/css\">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></head><body><p>A while ago, drnickbone showed in a LessWrong post that <a href=\"http://lesswrong.com/lw/cl2/problematic_problems_for_tdt/\">for any decision theory, there is a \"fair\" decision problem on which that decision theory fails</a>---that is, gets a low reward, even though a simple alternative decision theory gets a high reward. Although drnickbone's argument was given in words, it's intuitively clear that it could be formalized as math---except, what exactly do \"decision theory\" and \"decision problem\" mean in this context?</p>\n<p>In this post, I'll propose definitions of these notions in the context of provability logic, as used in <a href=\"/item?id=4\">Vladimir Slepnev's modal version of UDT</a>, and give a formalization of drnickbone's result. This implies that no single modal decision theory, including UDT, can behave optimally on all \"fair\" decision problems. But in my next post, I'll show that modal UDT is nevertheless optimal in a weaker sense: For every provably \"fair\" modal decision problem, there is a finite set of true axioms that can be added to PA, such that modal UDT using this extension of PA performs optimally on that decision problem. (This is a modal logic version of a result which Kenny Easwaran, Nate Soares and I recently showed in the context of bounded proof length, and which hasn't been published yet.)</p>\n<p><strong>Prerequisite:</strong> <a href=\"/item?id=41\">A primer on provability logic.</a></p>\n<h1>Background</h1>\n<p>Here's an example of how we usually talk about decision problems (Vladimir Slepnev's formalization of <a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a> from \"<a href=\"http://lesswrong.com/lw/8wc/a_model_of_udt_with_a_halting_oracle/\">A model of UDT with a halting oracle</a>\"):</p>\n<pre><code>  def U():\n    # Fill boxes, according to predicted action.\n    box1 = 1000\n    box2 = 1000000 if (A() == 1) else 0\n    # Compute reward, based on actual action.\n    return box2 if (A() == 1) else (box1 + box2)\n</code></pre>\n<p>In other words, we have a universe program, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U()\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, which makes calls to an agent program, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A()\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>.</p>\n<p>The agent program, in turn, uses quining to refer to the source code of the universe program. But while the universe is allowed to call the agent to figure out how it will behave, the agent can't just call the universe---or we'll have an infinite regress. Instead, we generally consider agents that use abstract reasoning in the form of proofs to reason about the universe they're in.</p>\n<p>So a universe is a parameterless program, and a decision problem is a universe <em>with a slot in it for an agent program</em>. Similarly, an agent is a parameterless program, and a decision theory is an agent <em>with a slot in it for the universe program</em>. The universe can refer to the agent by calling it, but the agent can refer to the universe's source (and to its own source) only inside quoted formulas.</p>\n<h1>Definitions</h1>\n<p><span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span></p>\n<p>Let's say that a sequence of modal formulas <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_1,\\dotsc,\\varphi_n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span> are <em>provably mutually exclusive and exhaustive</em>, or p.m.e.e. for short, if <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span></span></span></span></span> proves that exactly one of them is true: For example, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span>, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span> and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span></span></span></span></span> are p.m.e.e. if\n<span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\GL\\,\\vdash\\, (\\varphi_1\\wedge\\neg\\varphi_2\\wedge\\neg\\varphi_3) \\,\\vee\\, (\\neg\\varphi_1\\wedge\\varphi_2\\wedge\\neg\\varphi_3) \\,\\vee\\, (\\neg\\varphi_1\\wedge\\neg\\varphi_2\\wedge\\varphi_3).\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></p>\n<p>We'll say that a <em>(<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span>-outcome) modal universe</em> is a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_1,\\dotsc,O_k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec O\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.215em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span></span></span></span></span></span></span></span></span> for short, of closed p.m.e.e. formulas, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> is interpreted as the proposition that the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span>'th of the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span> possible outcomes occurs.</p>\n<p>Given a preference ranking on these <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span> possible outcomes, which has <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\\le k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2264</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span> equivalence classes, we'll write <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> for the modal formula asserting that one of the outcomes in the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span>'th ranked equivalence class has occurred; for example, if the preference ordering is such that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span>, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span></span></span></span></span></span> and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_7\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">7</span></span></span></span></span></span></span></span> are the most preferred outcomes, then <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U_1\\equiv O_2\\vee O_5\\vee O_7\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">7</span></span></span></span></span></span></span></span>. Clearly, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U_1,\\dotsc,U_n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span> (or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec U\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span></span></span></span></span> for short) is a sequence of p.m.e.e. formulas; for brevity, we can avoid talking about <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec O\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.215em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span></span></span></span></span></span></span></span></span>, and call the sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec U\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span></span></span></span></span> an <em><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level universe</em>.</p>\n<p>(I'm using <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\equiv\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span></span></span></span></span> to mean \"same formula\".)</p>\n<p>Similarly, an <em>(<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action) modal agent</em> is a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A_1,\\dotsc,A_m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span> for short, of closed p.m.e.e. formulas, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> is interpreted as saying that the agent takes its <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span>'th available action.</p>\n<p>A <em>modal (<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level) decision problem</em> is an <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level universe with a slot for an <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action agent <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>: that is, a p.m.e.e. sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_1(\\vec a),\\dotsc,P_n(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for short, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\\equiv(a_1,\\dotsc,a_m)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>.</p>\n<p>Similarly, a decision theory is an agent with a slot for a universe. However, the definition of decision theories isn't exactly analogous to that of decision problems, because we want to reflect the idea that the agent can't directly simulate the universe it's living in, but can only make reference to it inside quoted formulas; in the modal logic world, this translates to: \"inside boxes\". Thus, we define a <em>modal (<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level) decision theory</em> to be a p.m.e.e. sequence of <em>fully modalized</em> formulas <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_1(\\vec u),\\dotsc,T_m(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for short, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec u = (u_1,\\dotsc,u_n)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>.</p>\n<p><em>(Aside: We could require one of these to be provably mutually exclusive and exhaustive only under the assumption that its argument is p.m.e.e., but my current guess is that it's not worth it.)</em></p>\n<h1>Fixed points</h1>\n<p>Now we can use the fixed point theorem to show that any modal decision theory has a well-defined output on any modal decision problem, and vice versa: Since <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> is fully modalized, so is <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec P(\\vec a))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>---if we substitute the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"u_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span>, and all instances of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"u_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> were inside boxes, then all instances of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> in the resulting formula will be inside boxes as well. Thus, we can find a fixed point <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span> satisfying <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec A\\leftrightarrow\\vec T(\\vec P(\\vec A))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> (which I'm using as shorthand for stating that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash A_i\\leftrightarrow T_i(\\vec P(\\vec A))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> holds for <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i=1,\\dotsc,m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>).</p>\n<p>By the uniqueness theorem, for any <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> satisfying <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec B\\leftrightarrow\\vec T(\\vec P(\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, we have <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec A\\leftrightarrow\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span>, so our decision theory's action is well-defined. Moreover, by the rule about substitution of equivalent formulas, it follows that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash \\vec P(\\vec A)\\leftrightarrow\\vec P(\\vec B)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, meaning that the preference level <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec U :\\equiv \\vec P(\\vec A)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> that our decision theory achieves on this decision problem is well-defined as well.</p>\n<p>Thus, for every pair of sequences <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\vec T(\\vec u),\\vec P(\\vec a))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, there's a pair <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\vec A,\\vec U)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> such that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec A\\lr T(\\vec U)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec U\\lr P(\\vec A)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>; and this pair is unique up to provable equivalence.</p>\n<h1>Extensional (= \"fair\") decision problems</h1>\n<p>drnickbone's result states that for every decision theory, there is a \"fair\" decision problem which on which this decision theory fails, where \"fair\" means that an agent's reward depends only on its actions, not on its source code: Any two agents which output the same actions will achieve the same outcome. We can formalize this in modal logic as\n<span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\big(\\vec a\\leftrightarrow\\vec b\\big)\\,\\to\\,\\big(\\vec P(\\vec a)\\leftrightarrow\\vec P(\\vec b)\\big),\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mstyle MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span></span></span></span></span>\nwhere I'm writing <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec\\varphi\\leftrightarrow\\vec\\psi\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.16em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.186em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span></span></span></span></span></span></span></span></span></span> for the conjunction of the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_i\\leftrightarrow\\psi_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span>. We'll say that a modal decision problem is <em>provably extensional</em> if GL proves the above fairness condition.</p>\n<p>There is one case in which provable extensionality is easy to show: If all occurrences of propositional variables in <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> are <em>outside</em> boxes, then the fairness condition is a simple propositional tautology, and all such tautologies are provable in GL.</p>\n<p><em>(Aside: One might wonder whether provable extensionality doesn't follow for all decision problems from the rule about substitution of equivalent formulas, but that's only an inference rule: if you can prove in GL that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi\\leftrightarrow\\varphi'\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span></span></span></span></span>, and you can also prove <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\psi(\\varphi)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, then it follows that you can prove <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\psi(\\varphi')\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, but GL does</em> not <em>in general prove <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\varphi\\leftrightarrow\\varphi')\\to(\\psi(\\varphi)\\leftrightarrow\\psi(\\varphi'))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>. Here's a counterexample: Note that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\box\\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span> says \"PA proves a contradiction\", so <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\neg\\box\\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span> says \"PA is consistent\". Hence, GL does not prove that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\top\\leftrightarrow\\neg\\box\\bot)\\to(\\box\\top\\leftrightarrow\\box(\\neg\\box\\bot))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, because that reduces to <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\neg\\box\\bot\\to\\box\\neg\\box\\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span>, which says \"if PA is consistent, then PA proves its own consistency\". That statement is false, and by soundness, GL only proves true things.)</em></p>\n<h1>Evil problems</h1>\n<p>Intuitively, given a <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level decision theory <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> (where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m,n\\ge 2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2265</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span>), drnickbone's \"evil\" extensional decision problem <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> works as follows: First, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> checks what <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> would do on this same decision problem. Then it checks whether <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> does the same thing. If so, the agent gets the second-best outcome; but if <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> differs from <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>'s action, the agent gets the best outcome.</p>\n<p>To implement this idea, we first define a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_1(\\vec a,\\vec b),\\dotsc,F_m(\\vec a,\\vec b)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> stands for the action of the actual agent and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec b\\equiv(b_1,\\dotsc,b_m)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> stands for the action that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> would have taken, as follows:</p>\n<ul>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_1(\\vec a,\\vec b) :\\equiv \\neg\\big(\\vec a \\leftrightarrow \\vec b\\big)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></span></span></span>;</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_2(\\vec a,\\vec b) :\\equiv \\phantom{\\neg}\\big(\\vec a \\leftrightarrow \\vec b\\big)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mphantom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></span></span></span>; and</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_{j+2}(\\vec a,\\vec b) :\\equiv \\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">j</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span>.</li>\n</ul>\n<p>Now, we use the fixed point theorem to find a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> such that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash B_i\\lr T_i(\\vec F(\\vec B,\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i=1,\\dotsc,m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>. Finally, we let <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a) :\\equiv \\vec F(\\vec a,\\vec B)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>. It's clear from the definition of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec F(\\vec a,\\vec b)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> that the formulas in <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> are p.m.e.e., as required for a decision problem; and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> only occurs outside boxes in <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, so <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> is provably extensional.</p>\n<p>The point of this is that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> is now clearly the action of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> on the decision problem <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>: <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"B_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> is equivalent to <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_i(\\vec F(\\vec B,\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, which is equivalent to <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_i(\\vec P(\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec B\\lr\\vec T(\\vec P(\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> is exactly the defining condition of \"<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> says what <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> does on <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>\". Therefore, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> now implements the intuitive definition of the evil problem: it checks whether <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> takes the same action as <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>; if so, it returns the second-best outcome; otherwise, it returns the best.</p>\n<p>So <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> gets only the second best outcome, but the following decision theory <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T'(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 1.042em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> gets the best one:</p>\n<ul>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T'_1(\\vec u) :\\equiv \\neg T_1(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.291em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>;</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T'_2(\\vec u) :\\equiv \\phantom{\\neg}T_1(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.291em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mphantom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>;</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T'_{j+2}(\\vec u) :\\equiv \\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.291em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">j</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span>.</li>\n</ul>\n</body></html>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5bd75cc58225bf0670374e8c", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": null, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<style type=\"text/css\">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style><p>A while ago, drnickbone showed in a LessWrong post that <a href=\"http://lesswrong.com/lw/cl2/problematic_problems_for_tdt/\">for any decision theory, there is a \"fair\" decision problem on which that decision theory fails</a>---that is, gets a low reward, even though a simple alternative decision theory gets a high reward. Although drnickbone's argument was given in words, it's intuitively clear that it could be formalized as math---except, what exactly do \"decision theory\" and \"decision problem\" mean in this context?</p>\n<p>In this post, I'll propose definitions of these notions in the context of provability logic, as used in <a href=\"/item?id=4\">Vladimir Slepnev's modal version of UDT</a>, and give a formalization of drnickbone's result. This implies that no single modal decision theory, including UDT, can behave optimally on all \"fair\" decision problems. But in my next post, I'll show that modal UDT is nevertheless optimal in a weaker sense: For every provably \"fair\" modal decision problem, there is a finite set of true axioms that can be added to PA, such that modal UDT using this extension of PA performs optimally on that decision problem. (This is a modal logic version of a result which Kenny Easwaran, Nate Soares and I recently showed in the context of bounded proof length, and which hasn't been published yet.)</p>\n<p><strong>Prerequisite:</strong> <a href=\"/item?id=41\">A primer on provability logic.</a></p>\n<h1 id=\"Background\">Background</h1>\n<p>Here's an example of how we usually talk about decision problems (Vladimir Slepnev's formalization of <a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a> from \"<a href=\"http://lesswrong.com/lw/8wc/a_model_of_udt_with_a_halting_oracle/\">A model of UDT with a halting oracle</a>\"):</p>\n<pre><code>  def U():\n    # Fill boxes, according to predicted action.\n    box1 = 1000\n    box2 = 1000000 if (A() == 1) else 0\n    # Compute reward, based on actual action.\n    return box2 if (A() == 1) else (box1 + box2)\n</code></pre>\n<p>In other words, we have a universe program, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U()\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, which makes calls to an agent program, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A()\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>.</p>\n<p>The agent program, in turn, uses quining to refer to the source code of the universe program. But while the universe is allowed to call the agent to figure out how it will behave, the agent can't just call the universe---or we'll have an infinite regress. Instead, we generally consider agents that use abstract reasoning in the form of proofs to reason about the universe they're in.</p>\n<p>So a universe is a parameterless program, and a decision problem is a universe <em>with a slot in it for an agent program</em>. Similarly, an agent is a parameterless program, and a decision theory is an agent <em>with a slot in it for the universe program</em>. The universe can refer to the agent by calling it, but the agent can refer to the universe's source (and to its own source) only inside quoted formulas.</p>\n<h1 id=\"Definitions\">Definitions</h1>\n<p><span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span>\n<span class=\"mjpage mjpage__block\"></span></p>\n<p>Let's say that a sequence of modal formulas <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_1,\\dotsc,\\varphi_n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span> are <em>provably mutually exclusive and exhaustive</em>, or p.m.e.e. for short, if <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span></span></span></span></span> proves that exactly one of them is true: For example, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span>, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span> and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span></span></span></span></span> are p.m.e.e. if\n<span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\GL\\,\\vdash\\, (\\varphi_1\\wedge\\neg\\varphi_2\\wedge\\neg\\varphi_3) \\,\\vee\\, (\\neg\\varphi_1\\wedge\\varphi_2\\wedge\\neg\\varphi_3) \\,\\vee\\, (\\neg\\varphi_1\\wedge\\neg\\varphi_2\\wedge\\varphi_3).\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2227</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></p>\n<p>We'll say that a <em>(<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span>-outcome) modal universe</em> is a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_1,\\dotsc,O_k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec O\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.215em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span></span></span></span></span></span></span></span></span> for short, of closed p.m.e.e. formulas, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> is interpreted as the proposition that the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span>'th of the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span> possible outcomes occurs.</p>\n<p>Given a preference ranking on these <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span> possible outcomes, which has <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\\le k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2264</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span> equivalence classes, we'll write <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> for the modal formula asserting that one of the outcomes in the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span>'th ranked equivalence class has occurred; for example, if the preference ordering is such that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span>, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span></span></span></span></span></span> and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O_7\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">7</span></span></span></span></span></span></span></span> are the most preferred outcomes, then <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U_1\\equiv O_2\\vee O_5\\vee O_7\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">\u2228</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">7</span></span></span></span></span></span></span></span>. Clearly, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U_1,\\dotsc,U_n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.084em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span> (or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec U\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span></span></span></span></span> for short) is a sequence of p.m.e.e. formulas; for brevity, we can avoid talking about <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec O\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.215em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span></span></span></span></span></span></span></span></span></span>, and call the sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec U\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span></span></span></span></span> an <em><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level universe</em>.</p>\n<p>(I'm using <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\equiv\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span></span></span></span></span> to mean \"same formula\".)</p>\n<p>Similarly, an <em>(<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action) modal agent</em> is a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A_1,\\dotsc,A_m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span> for short, of closed p.m.e.e. formulas, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> is interpreted as saying that the agent takes its <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span>'th available action.</p>\n<p>A <em>modal (<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level) decision problem</em> is an <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level universe with a slot for an <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action agent <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>: that is, a p.m.e.e. sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_1(\\vec a),\\dotsc,P_n(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for short, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\\equiv(a_1,\\dotsc,a_m)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>.</p>\n<p>Similarly, a decision theory is an agent with a slot for a universe. However, the definition of decision theories isn't exactly analogous to that of decision problems, because we want to reflect the idea that the agent can't directly simulate the universe it's living in, but can only make reference to it inside quoted formulas; in the modal logic world, this translates to: \"inside boxes\". Thus, we define a <em>modal (<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level) decision theory</em> to be a p.m.e.e. sequence of <em>fully modalized</em> formulas <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_1(\\vec u),\\dotsc,T_m(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, or <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for short, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec u = (u_1,\\dotsc,u_n)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>.</p>\n<p><em>(Aside: We could require one of these to be provably mutually exclusive and exhaustive only under the assumption that its argument is p.m.e.e., but my current guess is that it's not worth it.)</em></p>\n<h1 id=\"Fixed_points\">Fixed points</h1>\n<p>Now we can use the fixed point theorem to show that any modal decision theory has a well-defined output on any modal decision problem, and vice versa: Since <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> is fully modalized, so is <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec P(\\vec a))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>---if we substitute the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"u_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span>, and all instances of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"u_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> were inside boxes, then all instances of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> in the resulting formula will be inside boxes as well. Thus, we can find a fixed point <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span> satisfying <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec A\\leftrightarrow\\vec T(\\vec P(\\vec A))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> (which I'm using as shorthand for stating that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash A_i\\leftrightarrow T_i(\\vec P(\\vec A))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> holds for <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i=1,\\dotsc,m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>).</p>\n<p>By the uniqueness theorem, for any <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> satisfying <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec B\\leftrightarrow\\vec T(\\vec P(\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, we have <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec A\\leftrightarrow\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span>, so our decision theory's action is well-defined. Moreover, by the rule about substitution of equivalent formulas, it follows that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash \\vec P(\\vec A)\\leftrightarrow\\vec P(\\vec B)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, meaning that the preference level <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec U :\\equiv \\vec P(\\vec A)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> that our decision theory achieves on this decision problem is well-defined as well.</p>\n<p>Thus, for every pair of sequences <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\vec T(\\vec u),\\vec P(\\vec a))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, there's a pair <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\vec A,\\vec U)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> such that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec A\\lr T(\\vec U)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec U\\lr P(\\vec A)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.241em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.264em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>; and this pair is unique up to provable equivalence.</p>\n<h1 id=\"Extensional_____fair___decision_problems\">Extensional (= \"fair\") decision problems</h1>\n<p>drnickbone's result states that for every decision theory, there is a \"fair\" decision problem which on which this decision theory fails, where \"fair\" means that an agent's reward depends only on its actions, not on its source code: Any two agents which output the same actions will achieve the same outcome. We can formalize this in modal logic as\n<span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\big(\\vec a\\leftrightarrow\\vec b\\big)\\,\\to\\,\\big(\\vec P(\\vec a)\\leftrightarrow\\vec P(\\vec b)\\big),\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"></span><span class=\"mjx-mstyle MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span></span></span></span></span>\nwhere I'm writing <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec\\varphi\\leftrightarrow\\vec\\psi\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.16em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.186em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span></span></span></span></span></span></span></span></span></span> for the conjunction of the <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi_i\\leftrightarrow\\psi_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span>. We'll say that a modal decision problem is <em>provably extensional</em> if GL proves the above fairness condition.</p>\n<p>There is one case in which provable extensionality is easy to show: If all occurrences of propositional variables in <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> are <em>outside</em> boxes, then the fairness condition is a simple propositional tautology, and all such tautologies are provable in GL.</p>\n<p><em>(Aside: One might wonder whether provable extensionality doesn't follow for all decision problems from the rule about substitution of equivalent formulas, but that's only an inference rule: if you can prove in GL that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\varphi\\leftrightarrow\\varphi'\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span></span></span></span></span>, and you can also prove <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\psi(\\varphi)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, then it follows that you can prove <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\psi(\\varphi')\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, but GL does</em> not <em>in general prove <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\varphi\\leftrightarrow\\varphi')\\to(\\psi(\\varphi)\\leftrightarrow\\psi(\\varphi'))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03c8</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>. Here's a counterexample: Note that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\box\\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span> says \"PA proves a contradiction\", so <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\neg\\box\\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span> says \"PA is consistent\". Hence, GL does not prove that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\top\\leftrightarrow\\neg\\box\\bot)\\to(\\box\\top\\leftrightarrow\\box(\\neg\\box\\bot))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, because that reduces to <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\neg\\box\\bot\\to\\box\\neg\\box\\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u25a1</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span>, which says \"if PA is consistent, then PA proves its own consistency\". That statement is false, and by soundness, GL only proves true things.)</em></p>\n<h1 id=\"Evil_problems\">Evil problems</h1>\n<p>Intuitively, given a <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>-action, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span>-level decision theory <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> (where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"m,n\\ge 2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2265</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span>), drnickbone's \"evil\" extensional decision problem <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> works as follows: First, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> checks what <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> would do on this same decision problem. Then it checks whether <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> does the same thing. If so, the agent gets the second-best outcome; but if <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> differs from <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>'s action, the agent gets the best outcome.</p>\n<p>To implement this idea, we first define a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_1(\\vec a,\\vec b),\\dotsc,F_m(\\vec a,\\vec b)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, where <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> stands for the action of the actual agent and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec b\\equiv(b_1,\\dotsc,b_m)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2261</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> stands for the action that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> would have taken, as follows:</p>\n<ul>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_1(\\vec a,\\vec b) :\\equiv \\neg\\big(\\vec a \\leftrightarrow \\vec b\\big)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></span></span></span>;</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_2(\\vec a,\\vec b) :\\equiv \\phantom{\\neg}\\big(\\vec a \\leftrightarrow \\vec b\\big)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mphantom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">(</span></span></span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></span></span></span>; and</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_{j+2}(\\vec a,\\vec b) :\\equiv \\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">j</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span>.</li>\n</ul>\n<p>Now, we use the fixed point theorem to find a sequence <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> such that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash B_i\\lr T_i(\\vec F(\\vec B,\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> for <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"i=1,\\dotsc,m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">\u2026</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span>. Finally, we let <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a) :\\equiv \\vec F(\\vec a,\\vec B)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>. It's clear from the definition of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec F(\\vec a,\\vec b)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\" style=\"padding-left: 0.036em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> that the formulas in <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> are p.m.e.e., as required for a decision problem; and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> only occurs outside boxes in <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, so <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> is provably extensional.</p>\n<p>The point of this is that <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> is now clearly the action of <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> on the decision problem <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>: <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"B_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span> is equivalent to <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_i(\\vec F(\\vec B,\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.302em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, which is equivalent to <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_i(\\vec P(\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>, and <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\GL\\vdash\\vec B\\lr\\vec T(\\vec P(\\vec B))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">G</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">L</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a2</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2194</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> is exactly the defining condition of \"<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span></span></span> says what <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> does on <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>\". Therefore, <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec P(\\vec a)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.305em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> now implements the intuitive definition of the evil problem: it checks whether <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec a\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.015em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span></span></span></span></span></span></span></span></span> takes the same action as <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>; if so, it returns the second-best outcome; otherwise, it returns the best.</p>\n<p>So <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> gets only the second best outcome, but the following decision theory <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\vec T'(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.288em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 1.042em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span> gets the best one:</p>\n<ul>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T'_1(\\vec u) :\\equiv \\neg T_1(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.291em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>;</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T'_2(\\vec u) :\\equiv \\phantom{\\neg}T_1(\\vec u)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.291em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mphantom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">\u00ac</span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span>;</li>\n<li><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T'_{j+2}(\\vec u) :\\equiv \\bot\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.291em; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">j</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.248em; padding-bottom: 0.06em; padding-left: 0.064em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-vec-R\" style=\"padding-top: 0.519em; padding-bottom: 0.225em;\">\u2192</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">\u2261</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u22a5</span></span></span></span></span></span>.</li>\n</ul>\n", "sections": [{"title": "Background", "anchor": "Background", "level": 1}, {"title": "Definitions", "anchor": "Definitions", "level": 1}, {"title": "Fixed points", "anchor": "Fixed_points", "level": 1}, {"title": "Extensional (= \"fair\") decision problems", "anchor": "Extensional_____fair___decision_problems", "level": 1}, {"title": "Evil problems", "anchor": "Evil_problems", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": true, "version": "1.0.0", "pingbacks": {"Posts": ["3GyQXTy2WhYcaBgS2", "Bj244uWzDBXvE2N2S"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-10T09:48:33.654Z", "modifiedAt": null, "url": null, "title": "Meetup : Less Wrong Israel Meetup: Social and Board Games", "slug": "meetup-less-wrong-israel-meetup-social-and-board-games", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanArmak", "createdAt": "2009-08-05T23:08:24.020Z", "isAdmin": false, "displayName": "DanArmak"}, "userId": "7KSbntzeQ2RNZq6Jw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tPXB9jafDYpi8gXgy/meetup-less-wrong-israel-meetup-social-and-board-games", "pageUrlRelative": "/posts/tPXB9jafDYpi8gXgy/meetup-less-wrong-israel-meetup-social-and-board-games", "linkUrl": "https://www.lesswrong.com/posts/tPXB9jafDYpi8gXgy/meetup-less-wrong-israel-meetup-social-and-board-games", "postedAtFormatted": "Saturday, January 10th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Less%20Wrong%20Israel%20Meetup%3A%20Social%20and%20Board%20Games&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Less%20Wrong%20Israel%20Meetup%3A%20Social%20and%20Board%20Games%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtPXB9jafDYpi8gXgy%2Fmeetup-less-wrong-israel-meetup-social-and-board-games%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Less%20Wrong%20Israel%20Meetup%3A%20Social%20and%20Board%20Games%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtPXB9jafDYpi8gXgy%2Fmeetup-less-wrong-israel-meetup-social-and-board-games", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtPXB9jafDYpi8gXgy%2Fmeetup-less-wrong-israel-meetup-social-and-board-games", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 138, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18r'>Less Wrong Israel Meetup: Social and Board Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 January 2015 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Google, Electra Tower, 98 Yigal Alon Street, Tel Aviv</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This time we're going to have a social meetup! It's going to be a game night full of people talking about physics, friendly AI, and how to effectively save the world.\nPlease bring any games you'd like to play.\nContact: If you can't find us, call Anatoly, who is graciously hosting us, at 054-245-1060; or Joshua at 054-569-1165.\nThere's a Facebook <a href=\"https://www.facebook.com/events/1578939379016207/\" rel=\"nofollow\">event</a> for the meetup. Please RSVP if you have Facebook, to help us get a sense of what to expect, and you can also join the LessWrong Israel <a href=\"https://www.facebook.com/groups/480249315379682/\" rel=\"nofollow\">Facebook group</a> where we publish new events.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18r'>Less Wrong Israel Meetup: Social and Board Games</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tPXB9jafDYpi8gXgy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 2.3567250909591437e-06, "legacy": true, "legacyId": "27890", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Less_Wrong_Israel_Meetup__Social_and_Board_Games\">Discussion article for the meetup : <a href=\"/meetups/18r\">Less Wrong Israel Meetup: Social and Board Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 January 2015 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Google, Electra Tower, 98 Yigal Alon Street, Tel Aviv</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This time we're going to have a social meetup! It's going to be a game night full of people talking about physics, friendly AI, and how to effectively save the world.\nPlease bring any games you'd like to play.\nContact: If you can't find us, call Anatoly, who is graciously hosting us, at 054-245-1060; or Joshua at 054-569-1165.\nThere's a Facebook <a href=\"https://www.facebook.com/events/1578939379016207/\" rel=\"nofollow\">event</a> for the meetup. Please RSVP if you have Facebook, to help us get a sense of what to expect, and you can also join the LessWrong Israel <a href=\"https://www.facebook.com/groups/480249315379682/\" rel=\"nofollow\">Facebook group</a> where we publish new events.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Less_Wrong_Israel_Meetup__Social_and_Board_Games1\">Discussion article for the meetup : <a href=\"/meetups/18r\">Less Wrong Israel Meetup: Social and Board Games</a></h2>", "sections": [{"title": "Discussion article for the meetup : Less Wrong Israel Meetup: Social and Board Games", "anchor": "Discussion_article_for_the_meetup___Less_Wrong_Israel_Meetup__Social_and_Board_Games", "level": 1}, {"title": "Discussion article for the meetup : Less Wrong Israel Meetup: Social and Board Games", "anchor": "Discussion_article_for_the_meetup___Less_Wrong_Israel_Meetup__Social_and_Board_Games1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-10T15:38:28.607Z", "modifiedAt": null, "url": null, "title": "Meetup : Montreal Effective Altruism: Global Poverty", "slug": "meetup-montreal-effective-altruism-global-poverty", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bartimaeus", "createdAt": "2013-05-07T17:14:04.389Z", "isAdmin": false, "displayName": "bartimaeus"}, "userId": "mqWrbcZHzhfPLnJqg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NuSdjYvgpe6PcHgsM/meetup-montreal-effective-altruism-global-poverty", "pageUrlRelative": "/posts/NuSdjYvgpe6PcHgsM/meetup-montreal-effective-altruism-global-poverty", "linkUrl": "https://www.lesswrong.com/posts/NuSdjYvgpe6PcHgsM/meetup-montreal-effective-altruism-global-poverty", "postedAtFormatted": "Saturday, January 10th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Montreal%20Effective%20Altruism%3A%20Global%20Poverty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Montreal%20Effective%20Altruism%3A%20Global%20Poverty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNuSdjYvgpe6PcHgsM%2Fmeetup-montreal-effective-altruism-global-poverty%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Montreal%20Effective%20Altruism%3A%20Global%20Poverty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNuSdjYvgpe6PcHgsM%2Fmeetup-montreal-effective-altruism-global-poverty", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNuSdjYvgpe6PcHgsM%2Fmeetup-montreal-effective-altruism-global-poverty", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 108, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18s'>Montreal Effective Altruism: Global Poverty</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 January 2015 10:38:11AM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1720 st-denis, montreal</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>There are a few causes that have the potential to do lots of good in the world per dollar spent.  Global poverty is a problem that is:</p>\n\n<p>-Neglected (so there are lots of low-hanging fruit)\n-Large-scale (billions are affected by it)\n-Progress is easy to measure</p>\n\n<p>We'll talk about the problem, what some of the most effective solutions are and which organisations seem to be doing the best work towards improving the conditions of the poorest people on the planet.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18s'>Montreal Effective Altruism: Global Poverty</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NuSdjYvgpe6PcHgsM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3575630216178886e-06, "legacy": true, "legacyId": "27891", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Montreal_Effective_Altruism__Global_Poverty\">Discussion article for the meetup : <a href=\"/meetups/18s\">Montreal Effective Altruism: Global Poverty</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 January 2015 10:38:11AM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1720 st-denis, montreal</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>There are a few causes that have the potential to do lots of good in the world per dollar spent.  Global poverty is a problem that is:</p>\n\n<p>-Neglected (so there are lots of low-hanging fruit)\n-Large-scale (billions are affected by it)\n-Progress is easy to measure</p>\n\n<p>We'll talk about the problem, what some of the most effective solutions are and which organisations seem to be doing the best work towards improving the conditions of the poorest people on the planet.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Montreal_Effective_Altruism__Global_Poverty1\">Discussion article for the meetup : <a href=\"/meetups/18s\">Montreal Effective Altruism: Global Poverty</a></h2>", "sections": [{"title": "Discussion article for the meetup : Montreal Effective Altruism: Global Poverty", "anchor": "Discussion_article_for_the_meetup___Montreal_Effective_Altruism__Global_Poverty", "level": 1}, {"title": "Discussion article for the meetup : Montreal Effective Altruism: Global Poverty", "anchor": "Discussion_article_for_the_meetup___Montreal_Effective_Altruism__Global_Poverty1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-10T16:36:57.680Z", "modifiedAt": null, "url": null, "title": "Productivity poll: how frequently do you think you *should* check email?", "slug": "productivity-poll-how-frequently-do-you-think-you-should", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:33.372Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "tog", "createdAt": "2011-10-04T12:54:07.164Z", "isAdmin": false, "displayName": "tog"}, "userId": "b4f6teTtsKfegjTaH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YHvgrr9XaNBTyN2id/productivity-poll-how-frequently-do-you-think-you-should", "pageUrlRelative": "/posts/YHvgrr9XaNBTyN2id/productivity-poll-how-frequently-do-you-think-you-should", "linkUrl": "https://www.lesswrong.com/posts/YHvgrr9XaNBTyN2id/productivity-poll-how-frequently-do-you-think-you-should", "postedAtFormatted": "Saturday, January 10th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Productivity%20poll%3A%20how%20frequently%20do%20you%20think%20you%20*should*%20check%20email%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProductivity%20poll%3A%20how%20frequently%20do%20you%20think%20you%20*should*%20check%20email%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYHvgrr9XaNBTyN2id%2Fproductivity-poll-how-frequently-do-you-think-you-should%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Productivity%20poll%3A%20how%20frequently%20do%20you%20think%20you%20*should*%20check%20email%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYHvgrr9XaNBTyN2id%2Fproductivity-poll-how-frequently-do-you-think-you-should", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYHvgrr9XaNBTyN2id%2Fproductivity-poll-how-frequently-do-you-think-you-should", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<p>How frequently do you think you *should* check email? You can also say how frequently you do in comments.</p>\n<p>Personally I'm sold on thinking you should check it around once a day, not necessarily without fail. That increases focus on both email and non-email, and minimises getting sucked into distractions. But some people I know disagree. Some believe in getting notifications whenever a new email comes in.</p>\n<p>For anyone who'd like to check email less often and uses GMail, I recommend using&nbsp;http://inboxpause.com/ and this full screen compose link:&nbsp;https://mail.google.com/mail/u/0/?ui=2&amp;view=cm&amp;fs=1&amp;tf=1&amp;shva=1</p>\n<p><strong>Edited to add: </strong>I'd recommend everyone at least try checking only once a day, at least for a few days, to see if you find it more productive and/or relaxing. That'd be a big enough win to make experimenting worthwhile.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YHvgrr9XaNBTyN2id", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 3, "extendedScore": null, "score": 2.357703123798774e-06, "legacy": true, "legacyId": "27892", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-10T19:09:43.882Z", "modifiedAt": null, "url": null, "title": "Existential Risk and Existential Hope: Definitions", "slug": "existential-risk-and-existential-hope-definitions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:30.992Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "owencb", "createdAt": "2013-05-12T09:01:14.360Z", "isAdmin": false, "displayName": "owencb"}, "userId": "QDNJ93vrjoaRBesk2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JjY8Yq9YdEAHc7Lkb/existential-risk-and-existential-hope-definitions", "pageUrlRelative": "/posts/JjY8Yq9YdEAHc7Lkb/existential-risk-and-existential-hope-definitions", "linkUrl": "https://www.lesswrong.com/posts/JjY8Yq9YdEAHc7Lkb/existential-risk-and-existential-hope-definitions", "postedAtFormatted": "Saturday, January 10th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Existential%20Risk%20and%20Existential%20Hope%3A%20Definitions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExistential%20Risk%20and%20Existential%20Hope%3A%20Definitions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJjY8Yq9YdEAHc7Lkb%2Fexistential-risk-and-existential-hope-definitions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Existential%20Risk%20and%20Existential%20Hope%3A%20Definitions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJjY8Yq9YdEAHc7Lkb%2Fexistential-risk-and-existential-hope-definitions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJjY8Yq9YdEAHc7Lkb%2Fexistential-risk-and-existential-hope-definitions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<p>I'm pleased to announce&nbsp;<a href=\"http://www.fhi.ox.ac.uk/Existential-risk-and-existential-hope.pdf\">Existential Risk and Existential Hope: Definitions</a>, a short new FHI technical report.</p>\n<div>Abstract:</div>\n<blockquote>\n<div>We look at the strengths and weaknesses of two existing&nbsp;definitions of existential risk, and suggest a new definition&nbsp;based on expected value. This leads to a parallel concept:&nbsp;&lsquo;existential hope&rsquo;, the chance of something extremely good happening.</div>\n</blockquote>\n<div><br /></div>\n<div>I think MIRI and CSER may be naturally understood as organisations trying to reduce existential risk and increase existential hope respectively (although if MIRI is aiming to build a safe AI this is also seeking to increase existential hope). What other world states could we aim for that increase existential hope?</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Rz5jb3cYHTSRmqNnN": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JjY8Yq9YdEAHc7Lkb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 5.7e-05, "legacy": true, "legacyId": "27893", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-10T20:04:48.129Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta January Meetup: Boring Advice & Stupid Questions", "slug": "meetup-atlanta-january-meetup-boring-advice-and-stupid", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexdewey", "createdAt": "2014-08-17T20:42:56.400Z", "isAdmin": false, "displayName": "alexdewey"}, "userId": "d3uJfhrEiqrzv7Gid", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6Qto8kG4mQWLSL35G/meetup-atlanta-january-meetup-boring-advice-and-stupid", "pageUrlRelative": "/posts/6Qto8kG4mQWLSL35G/meetup-atlanta-january-meetup-boring-advice-and-stupid", "linkUrl": "https://www.lesswrong.com/posts/6Qto8kG4mQWLSL35G/meetup-atlanta-january-meetup-boring-advice-and-stupid", "postedAtFormatted": "Saturday, January 10th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta%20January%20Meetup%3A%20Boring%20Advice%20%26%20Stupid%20Questions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%20January%20Meetup%3A%20Boring%20Advice%20%26%20Stupid%20Questions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Qto8kG4mQWLSL35G%2Fmeetup-atlanta-january-meetup-boring-advice-and-stupid%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%20January%20Meetup%3A%20Boring%20Advice%20%26%20Stupid%20Questions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Qto8kG4mQWLSL35G%2Fmeetup-atlanta-january-meetup-boring-advice-and-stupid", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Qto8kG4mQWLSL35G%2Fmeetup-atlanta-january-meetup-boring-advice-and-stupid", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 133, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18t'>Atlanta January Meetup: Boring Advice &amp; Stupid Questions</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 January 2015 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Norgate Manor, 2388 Lawrenceville Highway Unit L, Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This meetup we'll be talking about the Boring Advice Repository and giving our own suggestions and input. We'll also be asking any \"stupid\" questions we have that seem obvious or silly. If you'd like, take a look at these posts in advance for an idea of what we'll be discussing:\n<a href=\"http://lesswrong.com/r/discussion/lw/lih/2015_repository_reruns_boring_advice_repository/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/lih/2015_repository_reruns_boring_advice_repository/</a>\n<a href=\"http://lesswrong.com/r/discussion/lw/lgn/stupid_questions_january_2015/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/lgn/stupid_questions_january_2015/</a></p>\n\n<p>Please park in a spot labeled visitor, because parking in a numbered spot can get your car towed. There are cats at the location.\nAs usual, there will be snacks, games, and good conversation. Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18t'>Atlanta January Meetup: Boring Advice &amp; Stupid Questions</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6Qto8kG4mQWLSL35G", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 2.3582011344245674e-06, "legacy": true, "legacyId": "27894", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta_January_Meetup__Boring_Advice___Stupid_Questions\">Discussion article for the meetup : <a href=\"/meetups/18t\">Atlanta January Meetup: Boring Advice &amp; Stupid Questions</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 January 2015 07:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Norgate Manor, 2388 Lawrenceville Highway Unit L, Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This meetup we'll be talking about the Boring Advice Repository and giving our own suggestions and input. We'll also be asking any \"stupid\" questions we have that seem obvious or silly. If you'd like, take a look at these posts in advance for an idea of what we'll be discussing:\n<a href=\"http://lesswrong.com/r/discussion/lw/lih/2015_repository_reruns_boring_advice_repository/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/lih/2015_repository_reruns_boring_advice_repository/</a>\n<a href=\"http://lesswrong.com/r/discussion/lw/lgn/stupid_questions_january_2015/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/lgn/stupid_questions_january_2015/</a></p>\n\n<p>Please park in a spot labeled visitor, because parking in a numbered spot can get your car towed. There are cats at the location.\nAs usual, there will be snacks, games, and good conversation. Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Atlanta_January_Meetup__Boring_Advice___Stupid_Questions1\">Discussion article for the meetup : <a href=\"/meetups/18t\">Atlanta January Meetup: Boring Advice &amp; Stupid Questions</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta January Meetup: Boring Advice & Stupid Questions", "anchor": "Discussion_article_for_the_meetup___Atlanta_January_Meetup__Boring_Advice___Stupid_Questions", "level": 1}, {"title": "Discussion article for the meetup : Atlanta January Meetup: Boring Advice & Stupid Questions", "anchor": "Discussion_article_for_the_meetup___Atlanta_January_Meetup__Boring_Advice___Stupid_Questions1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["w8BDunkugbkiTEBk8", "fx2QFp8ra8TCHZ4xB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-11T05:19:17.376Z", "modifiedAt": null, "url": null, "title": "How Islamic terrorists reduced terrorism in the US", "slug": "how-islamic-terrorists-reduced-terrorism-in-the-us", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:25.000Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/duwC6TR56R4MrrfpN/how-islamic-terrorists-reduced-terrorism-in-the-us", "pageUrlRelative": "/posts/duwC6TR56R4MrrfpN/how-islamic-terrorists-reduced-terrorism-in-the-us", "linkUrl": "https://www.lesswrong.com/posts/duwC6TR56R4MrrfpN/how-islamic-terrorists-reduced-terrorism-in-the-us", "postedAtFormatted": "Sunday, January 11th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Islamic%20terrorists%20reduced%20terrorism%20in%20the%20US&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Islamic%20terrorists%20reduced%20terrorism%20in%20the%20US%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FduwC6TR56R4MrrfpN%2Fhow-islamic-terrorists-reduced-terrorism-in-the-us%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Islamic%20terrorists%20reduced%20terrorism%20in%20the%20US%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FduwC6TR56R4MrrfpN%2Fhow-islamic-terrorists-reduced-terrorism-in-the-us", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FduwC6TR56R4MrrfpN%2Fhow-islamic-terrorists-reduced-terrorism-in-the-us", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 756, "htmlBody": "<p>Yesterday I was using the <a href=\"http://www.start.umd.edu/gtd/\">Global Terrorism Database</a> to check some suprisingly low figures on what percentage of terrorist acts are committed by Muslims. (Short answer: Worldwide since 2000, about 80%, rather than 0.4 - 6% as given in various sources.) But I found some odd patterns in the data for the United States. Look at this chart of terrorist acts in the US which meet GTD criteria I-III and are listed as \"unambiguous\":</p>\n<div><br /></div>\n<div><img style=\"vertical-align: middle;\" src=\"http://s25.postimg.org/yqyp21va7/Terrorist_acts_in_US_1970_2013.jpg\" alt=\"\" width=\"573\" height=\"338\" /></div>\n<div><br /></div>\n<div>There were over 200 bombings in the US in 1970 alone, by all sorts of political groups (the Puerto Rican Liberation Front, the Jewish Defense League, the Weathermen, the Black Panthers, anti-Castro groups, white supremacists, etc., etc.) There was essentially no religious terrorism; that came in the 80s and 90s. But let's zoom in on 1978 onward, after the crazy period we inaccurately call \"the sixties\". First, a count of Islamic terrorist acts worldwide:</div>\n<div><br /></div>\n<div><img style=\"vertical-align: middle;\" src=\"http://s25.postimg.org/rdjb33b8f/Terrorist_acts_worldwide_Islamic_300_groups.jpg\" alt=\"Islamic terrorist acts worldwide\" width=\"582\" height=\"356\" /></div>\n<div>This is incomplete, because the database contains over 400 Islamic terrorist groups, but only let me select 300 groups at a time. (Al Qaeda is one of the groups not included here.) Also, this doesn't list any acts committed without direct supervision from a recognized terrorist group, nor acts whose perpetrators were not identified (about 77% of the database, estimated from a sample of 100, with the vast majority of those unknowns in Muslim countries). But we can see there's an increase after 2000.</div>\n<div><br /></div>\n<div>Now let's look at terrorist acts of all kinds in the US:</div>\n<div><br /></div>\n<div><img style=\"vertical-align: middle;\" src=\"http://s25.postimg.org/mqd91bnvj/Terrorist_acts_in_US_1978_2013.jpg\" alt=\"Terrorist acts in the US, 1970-2013\" width=\"580\" height=\"360\" /><br /></div>\n<div><br /></div>\n<div>We see a dramatic drop in terrorist acts in the US after 2000. Sampling them, I found that except for less than a handful of white supremacists, there are only 3 types of terrorists still active in the US: Nutcases, animal liberation activists, and Muslims. If we exclude cases of property damage (which has never terrified me), it's basically just nutcases and Muslims.</div>\n<div><br /></div>\n<div>Going by body count, it may still be an increase, because even if you exclude 9/11, just a handful of Muslim attacks still accounted for 50% of US fatalities in terrorist attacks from 2000 through 2013. But counting incidents, by 2005 there were about 1/3 as many per year as just before 2000. From 2000 to 2013 there were only 6 violent terrorist attacks in the US by non-Islamic terrorist groups that were not directed solely at property damage, resulting in 2 fatalities over those 14 years. Violent non-Islamic organized terrorism in the US has been effectively eliminated.</div>\n<div><br /></div>\n<div>Some of this reduction is because we've massively expanded our counter-terrorism agencies. But if that were the explanation, given that homeland security doesn't stop all of the Islamic attacks they're focused on, surely we would see more than 6 attacks by other groups in 14 years.</div>\n<div><br /></div>\n<div>Much of the reduction might be for non-obvious reasons, like whatever happened around 1980. But I think the most-obvious hypothesis is that Islamic terrorists gave terrorism a bad name. In the sixties, terrorism was almost cool. You could conceivably get laid by blowing up an Army recruiting center. Now, though, there's such a stigma associated with terrorism that even the Ku Klux Klan doesn't want to be associated with it. Islamists made terrorism un-American. In doing so, they reduced the total incidence of terrorism in America. Talk about unintended consequences.</div>\n<div><br /></div>\n<div>\n<hr />\n</div>\n<div><br /></div>\n<div>On a completely different note, I couldn't help but notice one other glaring thing in the US data: terrorist acts attributed to \"Individual\" (a lone terrorist not part of an organization). I checked 200 cases from other countries and did not find one case tagged \"Individual\". But half of all attributed cases in the US from 2000-2013 are tagged \"Individual\". The lone gunman thing, where someone flips out and shoots up a Navy base, or bombs a government building because of a conspiracy theory, is distinctively American.</div>\n<div><br /></div>\n<div>Perhaps Americans really are more enterprising than people of other nations. Perhaps other countries can't do the detective work to attribute acts to individuals. Perhaps their rate of non-lone wolf terrorism is so high that the lone wolf terrorists disappear in the data. Perhaps we're more accepting of \"defending our freedom\" as an excuse for shooting people. Perhaps psychotic delusions of being oppressed don't thrive well in countries that have plenty of highly-visible oppression. But perhaps Americans really do have a <a href=\"http://www.webmd.com/mental-health/news/20040601/rate-of-mental-illness-is-staggering\">staggeringly-higher rate of mental illness than everyone else in the world</a>. (Yes, suspicious study is suspicious, but... it is possible.)</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jKAkRrhnHedfowNYy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "duwC6TR56R4MrrfpN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 23, "extendedScore": null, "score": 2.3595306615463356e-06, "legacy": true, "legacyId": "27895", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 73, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-11T06:26:58.471Z", "modifiedAt": null, "url": null, "title": "Who are your favorite \"hidden rationalists\"?", "slug": "who-are-your-favorite-hidden-rationalists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:35:35.214Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "aarongertler", "createdAt": "2017-06-17T00:54:32.818Z", "isAdmin": false, "displayName": "aarongertler"}, "userId": "8mnQfaaqwi2mevNtq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GFddqSQsZjMkbeeHu/who-are-your-favorite-hidden-rationalists", "pageUrlRelative": "/posts/GFddqSQsZjMkbeeHu/who-are-your-favorite-hidden-rationalists", "linkUrl": "https://www.lesswrong.com/posts/GFddqSQsZjMkbeeHu/who-are-your-favorite-hidden-rationalists", "postedAtFormatted": "Sunday, January 11th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Who%20are%20your%20favorite%20%22hidden%20rationalists%22%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWho%20are%20your%20favorite%20%22hidden%20rationalists%22%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGFddqSQsZjMkbeeHu%2Fwho-are-your-favorite-hidden-rationalists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Who%20are%20your%20favorite%20%22hidden%20rationalists%22%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGFddqSQsZjMkbeeHu%2Fwho-are-your-favorite-hidden-rationalists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGFddqSQsZjMkbeeHu%2Fwho-are-your-favorite-hidden-rationalists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 551, "htmlBody": "<p>Quick summary: \"Hidden rationalists\" are what I call authors who espouse rationalist principles, and probably think of themselves as rational people, but don't always write on \"traditional\" Less Wrong-ish topics and probably haven't heard of Less Wrong.</p>\n<p>I've noticed that a lot of my rationalist friends seem to read the same ten blogs, and while it's great to have a core set of favorite authors, it's also nice to stretch out a bit and see how everyday rationalists are doing cool stuff in their own fields of expertise. I've found many people who push my rationalist buttons in fields of interest to me (journalism, fitness, etc.), and I'm sure other LWers have their own people in their own fields.</p>\n<p>So I'm setting up this post as a place to link to/summarize the work of your favorite hidden rationalists. Be liberal with your suggestions!</p>\n<p>Another way to phrase this:&nbsp;<strong>Who are the people/sources who give you the same feelings you get when you read your favorite LW posts, but who many of us probably haven't heard of?</strong></p>\n<p>&nbsp;</p>\n<p>Here's my list, to kick things off:</p>\n<p>&nbsp;</p>\n<ul>\n<li><a href=\"http://psandman.com\">Peter Sandman</a>, professional risk communication consultant. Often writes alongside Jody Lanard. Specialties: Effective communication, dealing with irrational people in a kind and efficient way, carefully weighing risks and benefits. My favorite recent post of his deals with <a href=\"http://www.psandman.com/col/Ebola-1.htm\">empathy for Ebola victims</a> and is a major, Slate Star Codex-esque <em>tour de force. </em>His \"guestbook comments\" page is better than his collection of web articles, but both are quite good.</li>\n<li><a href=\"http://www.bodybyscience.net/home.html/\">Doug McGuff, MD</a>, fitness guru and author of the exercise book with the highest citation-to-page ratio of any I've seen. His big thing is \"superslow training\", where you perform short and extremely intense workouts (<a href=\"https://www.youtube.com/watch?v=FVhhbC51_3k\">video here</a>). I've been moving in this direction for about 18 months now, and I've been able to cut my workout time approximately in half without losing strength. May not work for everyone, but reminds me of Leverage Research's sleep experiments; if it happens to work for you, you gain a heck of a lot of time. I also love the way he emphasizes the utility of strength training for all ages/genders -- very different from what you'd see on a lot of weightlifting sites.</li>\n<li><a href=\"http://thephilosophersmail.com\">Philosophers' Mail</a>. A website maintained by applied philosophers at the School of Life, which reminds me of a hippy-dippy European version of CFAR (in a good way). Not much science, but a lot of clever musings on the ways that philosophy can help us live, and some excellent summaries of philosophers who are hard to read in the original. (Their <a href=\"http://thephilosophersmail.com/perspective/the-great-artists-johannes-vermeer/\">piece on Vermeer</a> is a personal favorite, as is <a href=\"http://thephilosophersmail.com/capitalism/simon-cowell-on-holiday-in-barbados-proves-that-suffering-is-part-of-the-human-condition/\">this essay on Simon Cowell</a>.) This recently stopped posting new material, but the School of Life now collects similar work through <a href=\"http://www.thebookoflife.org/\">The Book of Life</a>.&nbsp;</li>\n</ul>\n<div><br /></div>\n<div>Finally, I'll mention something many more people are probably aware of: <a href=\"http://www.reddit.com/r/iama\">I Am A</a>, where people with interesting lives and experiences answer questions about those things. Few sites are better for broadening one's horizons; lots of concentrated honesty. Plus, the chance to update on beliefs you didn't even know you had.</div>\n<div><br /></div>\n<div><br /></div>\n<div><br /></div>\n<div>Once more:&nbsp;<strong>Who are the people/sources who give you the same feeling you get when you read your favorite LW posts, but who many of us probably haven't heard of?</strong></div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GFddqSQsZjMkbeeHu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 25, "extendedScore": null, "score": 2.3596930444031163e-06, "legacy": true, "legacyId": "27897", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-11T19:02:52.830Z", "modifiedAt": null, "url": null, "title": "The guardian article on longevity research [link]", "slug": "the-guardian-article-on-longevity-research-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:24.840Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ike", "createdAt": "2014-04-24T17:15:10.503Z", "isAdmin": false, "displayName": "ike"}, "userId": "u9qB4z7MjAsqx9yp8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N2PwwQ6ptCfH4SLLX/the-guardian-article-on-longevity-research-link", "pageUrlRelative": "/posts/N2PwwQ6ptCfH4SLLX/the-guardian-article-on-longevity-research-link", "linkUrl": "https://www.lesswrong.com/posts/N2PwwQ6ptCfH4SLLX/the-guardian-article-on-longevity-research-link", "postedAtFormatted": "Sunday, January 11th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20guardian%20article%20on%20longevity%20research%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20guardian%20article%20on%20longevity%20research%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN2PwwQ6ptCfH4SLLX%2Fthe-guardian-article-on-longevity-research-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20guardian%20article%20on%20longevity%20research%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN2PwwQ6ptCfH4SLLX%2Fthe-guardian-article-on-longevity-research-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN2PwwQ6ptCfH4SLLX%2Fthe-guardian-article-on-longevity-research-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 25, "htmlBody": "<p>Saw this on HN.</p>\n<p><a title=\"Live forever: Scientists say they&rsquo;ll soon extend life &lsquo;well beyond 120&rsquo;\" href=\"http://www.theguardian.com/science/2015/jan/11/-sp-live-forever-extend-life-calico-google-longevity\">Live forever: Scientists say they&rsquo;ll soon extend life &lsquo;well beyond 120&rsquo;</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N2PwwQ6ptCfH4SLLX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 2.36150788326807e-06, "legacy": true, "legacyId": "27898", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-11T19:52:19.313Z", "modifiedAt": null, "url": null, "title": "Research Priorities for Artificial Intelligence: An Open Letter", "slug": "research-priorities-for-artificial-intelligence-an-open", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.198Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GZ9tpsLRNL9R6h6oE/research-priorities-for-artificial-intelligence-an-open", "pageUrlRelative": "/posts/GZ9tpsLRNL9R6h6oE/research-priorities-for-artificial-intelligence-an-open", "linkUrl": "https://www.lesswrong.com/posts/GZ9tpsLRNL9R6h6oE/research-priorities-for-artificial-intelligence-an-open", "postedAtFormatted": "Sunday, January 11th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Research%20Priorities%20for%20Artificial%20Intelligence%3A%20An%20Open%20Letter&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AResearch%20Priorities%20for%20Artificial%20Intelligence%3A%20An%20Open%20Letter%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZ9tpsLRNL9R6h6oE%2Fresearch-priorities-for-artificial-intelligence-an-open%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Research%20Priorities%20for%20Artificial%20Intelligence%3A%20An%20Open%20Letter%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZ9tpsLRNL9R6h6oE%2Fresearch-priorities-for-artificial-intelligence-an-open", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZ9tpsLRNL9R6h6oE%2Fresearch-priorities-for-artificial-intelligence-an-open", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p>The Future of Life Institute has published their document <a href=\"http://futureoflife.org/static/data/documents/research_priorities.pdf\">Research priorities for robust and beneficial artificial intelligence</a>&nbsp;and written an <a href=\"http://futureoflife.org/misc/open_letter\">open letter</a>&nbsp;for people to sign indicating their support.</p>\n<blockquote>\n<p>Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to research how to maximize these benefits while avoiding potential pitfalls. This document gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial.</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"CL9NePP9FejkQo6jn": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GZ9tpsLRNL9R6h6oE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 38, "extendedScore": null, "score": 2.361626672014884e-06, "legacy": true, "legacyId": "27899", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-12T00:39:20.888Z", "modifiedAt": null, "url": null, "title": "Open thread, Jan. 12 - Jan. 18, 2015", "slug": "open-thread-jan-12-jan-18-2015", "viewCount": null, "lastCommentedAt": "2015-05-15T01:55:56.482Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gondolinian", "createdAt": "2014-11-27T03:36:46.447Z", "isAdmin": false, "displayName": "Gondolinian"}, "userId": "vozTv6uFcpbADwJqL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6Q65DfnpPKX5oQv7u/open-thread-jan-12-jan-18-2015", "pageUrlRelative": "/posts/6Q65DfnpPKX5oQv7u/open-thread-jan-12-jan-18-2015", "linkUrl": "https://www.lesswrong.com/posts/6Q65DfnpPKX5oQv7u/open-thread-jan-12-jan-18-2015", "postedAtFormatted": "Monday, January 12th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20Jan.%2012%20-%20Jan.%2018%2C%202015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20Jan.%2012%20-%20Jan.%2018%2C%202015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Q65DfnpPKX5oQv7u%2Fopen-thread-jan-12-jan-18-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20Jan.%2012%20-%20Jan.%2018%2C%202015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Q65DfnpPKX5oQv7u%2Fopen-thread-jan-12-jan-18-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6Q65DfnpPKX5oQv7u%2Fopen-thread-jan-12-jan-18-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<div id=\"entry_t3_lf8\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<div id=\"entry_t3_le3\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px; font-weight: bold;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><a href=\"/r/discussion/lw/lht/open_thread_jan_511_2015/\">Previous Open Thread</a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><a href=\"/r/discussion/lw/lk6/open_thread_jan_19_jan_25_2015/\">Next Open Thread</a></p>\n<hr />\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the <a href=\"/r/discussion/new/\" target=\"_blank\">list-of-threads page</a> before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">3.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should be posted in Discussion, and not Main.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\"><span style=\"line-height: 19px;\">4.&nbsp;</span><span style=\"line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6Q65DfnpPKX5oQv7u", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 2.3623164956563163e-06, "legacy": true, "legacyId": "27901", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 155, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hgoN3zTzMkgbaWFKz", "8nzTHoWH4RezFXw5b"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2015-01-12T00:39:20.888Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-12T17:10:50.617Z", "modifiedAt": null, "url": null, "title": "Misapplied economics and overwrought estimates", "slug": "misapplied-economics-and-overwrought-estimates", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:31.649Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "erratim", "createdAt": "2013-12-15T01:12:59.930Z", "isAdmin": false, "displayName": "Timothy Telleen-Lawton"}, "userId": "DeTtX86GPntE5znsf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gjie7bsCT2gaHHQqp/misapplied-economics-and-overwrought-estimates", "pageUrlRelative": "/posts/gjie7bsCT2gaHHQqp/misapplied-economics-and-overwrought-estimates", "linkUrl": "https://www.lesswrong.com/posts/gjie7bsCT2gaHHQqp/misapplied-economics-and-overwrought-estimates", "postedAtFormatted": "Monday, January 12th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Misapplied%20economics%20and%20overwrought%20estimates&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMisapplied%20economics%20and%20overwrought%20estimates%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgjie7bsCT2gaHHQqp%2Fmisapplied-economics-and-overwrought-estimates%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Misapplied%20economics%20and%20overwrought%20estimates%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgjie7bsCT2gaHHQqp%2Fmisapplied-economics-and-overwrought-estimates", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgjie7bsCT2gaHHQqp%2Fmisapplied-economics-and-overwrought-estimates", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1208, "htmlBody": "<p>I believe that a small piece of rationalist community doctrine is incorrect, and I'd like your help correcting it (or me).&nbsp;<a href=\"/lw/lgy/how_much_does_consumption_affect_production/\">Arguing the point by intuition has largely failed</a>, so here I make the case by leaning heavily on the authority of conventional economic wisdom.</p>\n<h2>The question:</h2>\n<p>How does an industry's total output respond to decreases in a consumer's purchases; does it shrink by a similar amount, a lesser amount, or not at all?</p>\n<h2>(Short-run) Answers from the rationalist community:</h2>\n<p>The consensus answer in the few cases I've seen cited in the broader LW community appears to be that production is reduced by an amount that's smaller than the original decrease in consumption.</p>\n<p><a href=\"http://www.animalcharityevaluators.org/research/foundational-research/effects-of-diet-choices-on-animals/\">Animal Charity Evaluators</a>&nbsp;(ACE):</p>\n<blockquote>\n<p>Fewer people in the market for meat leads to a drop in prices, which causes some other people to buy more meat. The drop in prices does also reduce the amount of meat produced and ultimately consumed, but not by as much as was consumed by people who have left the market.</p>\n</blockquote>\n<p><a href=\"http://everydayutilitarian.com/essays/how-much-suffering-is-in-the-standard-american-diet/\">Peter Hurford</a>:</p>\n<blockquote>\n<p class=\"p1\"><span class=\"s1\">As is commonly known by economists, when you choose to not buy a product, you lower the demand ever so slightly, which lowers the price ever so slightly, which turns out to re-increase the demand ever so slightly. Therefore, forgoing one pound of meat means that less than one pound of meat actually gets prevented from being factory farmed.</span></p>\n</blockquote>\n<p><a href=\"http://smile.amazon.com/Compassion-Pound-Economics-Animal-Welfare/dp/0199551162\">Compassion, by the Pound</a>:</p>\n<blockquote>\n<p>The key points to note are that a permanent decision to reduce meat consumption (1) does ultimately reduce the number of animals on the farm and the amount of meat produced (2), but it has&nbsp;less&nbsp;than a&nbsp;1-to-1&nbsp;effect on the&nbsp;amount of meat produced.<span style=\"font-family: AdvP83EB; font-size: 10pt;\">&nbsp;</span></p>\n</blockquote>\n<p class=\"p1\"><span class=\"s1\">These answers are all correct in the short-run (ie, when the &ldquo;supply curve&rdquo; doesn&rsquo;t have time to shift). If there is less demand for a product, the price will fall, and some other consumers will consume more because of the better deal. One intuitive justification for this is that when producers don&rsquo;t have time to fully react to a change in demand, the total amount of production and consumption is somewhat &lsquo;anchored&rsquo; to prior expectations of demand, so any change in demand will have less than a 1:1 effect on production. </span></p>\n<p class=\"p1\"><span class=\"s1\">For example, a chicken producer who begins to have negative profits due to the drop in price isn't going to immediately yank their chickens from the shelves; they will sell what they've already produced, and maybe even finish raising the chickens they've already invested in (if the remaining marginal cost is less than the expected sale price), even if they plan to shut down soon.</span></p>\n<h2>(Long-run) Answers from neoclassical economics:</h2>\n<p>In the long-run, however, the chicken producer has time to shrink or shut down the money-losing operation, which reduces the number of chickens on the market (shifts the \"supply curve\" to the left). The price rises again and the consumers that were only eating chicken because of the sale prices return to other food sources.</p>\n<p>As a couple of online economics resources put it:</p>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\"><a href=\"http://www.policonomics.com/lp-perfect-competition1-long-run-supply-curve/\">Policonomics</a>:</p>\n<blockquote>\n<p class=\"p1\"><span class=\"s1\">The long-run market equilibrium is conformed of successive short-run equilibrium points. The supply curve in the long run will be totally elastic as a result of the flexibility derived from the factors of production and the free entry and exit of firms.</span></p>\n<p class=\"p1\"><span class=\"s1\">&nbsp;</span><img src=\"http://images.lesswrong.com/t3_lj0_0.png\" alt=\"\" width=\"270\" height=\"232\" /></p>\n</blockquote>\n<p><a href=\"http://www.amosweb.com/cgi-bin/awb_nav.pl?s=wpd&amp;c=dsp&amp;k=perfect%20competition,%20long-run%20production%20analysis\">AmosWEB</a>*:</p>\n<blockquote>\n<p><span style=\"font-family: verdana, geneva, arial, sans-serif; font-size: 13px;\">The increase in demand causes the equilibrium price of zucchinis [to] increase... and the equilibrium quantity [to] rise... The higher price and larger quantity is achieved as each existing firm in the industry responds to the demand shock.</span></p>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\">However, the higher price leads to above-normal economic profit for existing firms. And with freedom of entry and exit, economic profit attracts kumquat, cucumber, and carrot producers into this zucchini industry. An increase in the number of firms in the zucchini industry then causes the market supply curve to shift. How far this curve shifts and where it intersects the new demand curve... determines if the zucchini market is an increasing-cost, decreasing-cost, [or] constant-cost industry.</p>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\">Constant-Cost Industry: An industry with a horizontal long-run industry supply curve that results because expansion of the industry causes no change in production cost or resource prices. A constant-cost industry occurs because the entry of new firms, prompted by an increase in demand, does not affect the long-run average cost curve of individual firms, which means the minimum efficient scale of production does not change.</p>\n</blockquote>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\">[I left out the similar explanations of the increasing- and decreasing-cost cases from the quote above.]</p>\n<p><strong> In other words, while certain market characteristics (increasing-cost industries) would lead us to expect that production will fall by less than consumption in the long-run, it could also fall by an equal amount, or even more. </strong></p>\n<h2>Short-run versus long-run</h2>\n<p class=\"p1\"><span class=\"s1\">Economists define the long-run as a scope of time in which producers and consumers have time to react to market dynamics. As such, a change in the market (e.g. reduction in demand) can have one effect in the short-run (reduced price), and a different effect in the long-run (reduced, constant, or increased price). In the real world, there will be many changes to the market in the short-run before the long-run has a chance to react to to any one of them; but we should still expect it to react to the net effect of all of them eventually.</span></p>\n<p class=\"p1\"><span class=\"s1\">Why do economists even bother measuring short-run dynamics (such as&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/31190/1/23020558.pdf\">short-run elasticity estimates</a>) on industries if they know that a longer view will render them obsolete? Probably because the demand for such research comes from producers who have to react to the short-run. Producers can't just wait for the long-run to come true; they actively realize it by reacting to short-run changes (otherwise the market would be 'stuck' in the short-run equilibrium).</span></p>\n<p>So <strong>if we care about long-run effects, but we don't have any data to know whether the industries and increasing-cost, constant-cost, or decreasing-cost, what prior should we use for our estimates?</strong> Basic intuition suggests we should assume an industry is constant-cost in the absence of industry-specific evidence. The rationalist-cited pieces I quoted above are welcome to make an argument that animal industries in particular are increasing-cost, but they haven't done that yet, or even acknowledged that the opposite is also possible.</p>\n<h2>Are there broader lessons to learn?</h2>\n<p>Have we really been messing up our cost-effectiveness estimates simply by confusing the short-run and long-run in economics data? If so, why haven't we noticed it before?</p>\n<p>I'm not sure. But I wouldn't be surprised if one issue is, <strong>in the process of trying to create precise cost-effectiveness-style estimates it's tempting to use data<em> simply because it's there</em></strong>.</p>\n<p>How can we identify and prevent this bias in other estimates? Perhaps we should treat quantitative estimates as chains that are no stronger than their weakest link. If you're tempted to build a chain with a particularly weak link, consider if there's a way to build a similar chain without it (possibly gaining robustness at the cost of artificial precision or completeness) or <a href=\"http://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/\">whether chain-logic is even appropriate</a> for the purpose.</p>\n<p>For example, perhaps it should have raised flags that <a href=\"https://docs.google.com/spreadsheet/ccc?key=0AvhKlkBMF1aQdGFfcEM5d3FtVlM2a2kweFFHcVQySlE&amp;usp=sharing#gid=0\">ACE's estimates</a> for the above effect on broiler chicken production (which they call \"<a href=\"http://www.animalcharityevaluators.org/wp-content/uploads/2013/12/cef.pdf\">cumulative elasticity factor</a>\" or CEF) ranged by more than a factor of 10x, adding almost as much uncertainty to the final calculation for broiler chickens as the 5 other factors combined. (To be fair, the CEF estimates of the other animal products were not as lopsided.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gjie7bsCT2gaHHQqp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "27900", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I believe that a small piece of rationalist community doctrine is incorrect, and I'd like your help correcting it (or me).&nbsp;<a href=\"/lw/lgy/how_much_does_consumption_affect_production/\">Arguing the point by intuition has largely failed</a>, so here I make the case by leaning heavily on the authority of conventional economic wisdom.</p>\n<h2 id=\"The_question_\">The question:</h2>\n<p>How does an industry's total output respond to decreases in a consumer's purchases; does it shrink by a similar amount, a lesser amount, or not at all?</p>\n<h2 id=\"_Short_run__Answers_from_the_rationalist_community_\">(Short-run) Answers from the rationalist community:</h2>\n<p>The consensus answer in the few cases I've seen cited in the broader LW community appears to be that production is reduced by an amount that's smaller than the original decrease in consumption.</p>\n<p><a href=\"http://www.animalcharityevaluators.org/research/foundational-research/effects-of-diet-choices-on-animals/\">Animal Charity Evaluators</a>&nbsp;(ACE):</p>\n<blockquote>\n<p>Fewer people in the market for meat leads to a drop in prices, which causes some other people to buy more meat. The drop in prices does also reduce the amount of meat produced and ultimately consumed, but not by as much as was consumed by people who have left the market.</p>\n</blockquote>\n<p><a href=\"http://everydayutilitarian.com/essays/how-much-suffering-is-in-the-standard-american-diet/\">Peter Hurford</a>:</p>\n<blockquote>\n<p class=\"p1\"><span class=\"s1\">As is commonly known by economists, when you choose to not buy a product, you lower the demand ever so slightly, which lowers the price ever so slightly, which turns out to re-increase the demand ever so slightly. Therefore, forgoing one pound of meat means that less than one pound of meat actually gets prevented from being factory farmed.</span></p>\n</blockquote>\n<p><a href=\"http://smile.amazon.com/Compassion-Pound-Economics-Animal-Welfare/dp/0199551162\">Compassion, by the Pound</a>:</p>\n<blockquote>\n<p>The key points to note are that a permanent decision to reduce meat consumption (1) does ultimately reduce the number of animals on the farm and the amount of meat produced (2), but it has&nbsp;less&nbsp;than a&nbsp;1-to-1&nbsp;effect on the&nbsp;amount of meat produced.<span style=\"font-family: AdvP83EB; font-size: 10pt;\">&nbsp;</span></p>\n</blockquote>\n<p class=\"p1\"><span class=\"s1\">These answers are all correct in the short-run (ie, when the \u201csupply curve\u201d doesn\u2019t have time to shift). If there is less demand for a product, the price will fall, and some other consumers will consume more because of the better deal. One intuitive justification for this is that when producers don\u2019t have time to fully react to a change in demand, the total amount of production and consumption is somewhat \u2018anchored\u2019 to prior expectations of demand, so any change in demand will have less than a 1:1 effect on production. </span></p>\n<p class=\"p1\"><span class=\"s1\">For example, a chicken producer who begins to have negative profits due to the drop in price isn't going to immediately yank their chickens from the shelves; they will sell what they've already produced, and maybe even finish raising the chickens they've already invested in (if the remaining marginal cost is less than the expected sale price), even if they plan to shut down soon.</span></p>\n<h2 id=\"_Long_run__Answers_from_neoclassical_economics_\">(Long-run) Answers from neoclassical economics:</h2>\n<p>In the long-run, however, the chicken producer has time to shrink or shut down the money-losing operation, which reduces the number of chickens on the market (shifts the \"supply curve\" to the left). The price rises again and the consumers that were only eating chicken because of the sale prices return to other food sources.</p>\n<p>As a couple of online economics resources put it:</p>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\"><a href=\"http://www.policonomics.com/lp-perfect-competition1-long-run-supply-curve/\">Policonomics</a>:</p>\n<blockquote>\n<p class=\"p1\"><span class=\"s1\">The long-run market equilibrium is conformed of successive short-run equilibrium points. The supply curve in the long run will be totally elastic as a result of the flexibility derived from the factors of production and the free entry and exit of firms.</span></p>\n<p class=\"p1\"><span class=\"s1\">&nbsp;</span><img src=\"http://images.lesswrong.com/t3_lj0_0.png\" alt=\"\" width=\"270\" height=\"232\"></p>\n</blockquote>\n<p><a href=\"http://www.amosweb.com/cgi-bin/awb_nav.pl?s=wpd&amp;c=dsp&amp;k=perfect%20competition,%20long-run%20production%20analysis\">AmosWEB</a>*:</p>\n<blockquote>\n<p><span style=\"font-family: verdana, geneva, arial, sans-serif; font-size: 13px;\">The increase in demand causes the equilibrium price of zucchinis [to] increase... and the equilibrium quantity [to] rise... The higher price and larger quantity is achieved as each existing firm in the industry responds to the demand shock.</span></p>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\">However, the higher price leads to above-normal economic profit for existing firms. And with freedom of entry and exit, economic profit attracts kumquat, cucumber, and carrot producers into this zucchini industry. An increase in the number of firms in the zucchini industry then causes the market supply curve to shift. How far this curve shifts and where it intersects the new demand curve... determines if the zucchini market is an increasing-cost, decreasing-cost, [or] constant-cost industry.</p>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\">Constant-Cost Industry: An industry with a horizontal long-run industry supply curve that results because expansion of the industry causes no change in production cost or resource prices. A constant-cost industry occurs because the entry of new firms, prompted by an increase in demand, does not affect the long-run average cost curve of individual firms, which means the minimum efficient scale of production does not change.</p>\n</blockquote>\n<p style=\"font-size: 13px; font-family: verdana, geneva, arial, sans-serif;\">[I left out the similar explanations of the increasing- and decreasing-cost cases from the quote above.]</p>\n<p><strong id=\"In_other_words__while_certain_market_characteristics__increasing_cost_industries__would_lead_us_to_expect_that_production_will_fall_by_less_than_consumption_in_the_long_run__it_could_also_fall_by_an_equal_amount__or_even_more__\"> In other words, while certain market characteristics (increasing-cost industries) would lead us to expect that production will fall by less than consumption in the long-run, it could also fall by an equal amount, or even more. </strong></p>\n<h2 id=\"Short_run_versus_long_run\">Short-run versus long-run</h2>\n<p class=\"p1\"><span class=\"s1\">Economists define the long-run as a scope of time in which producers and consumers have time to react to market dynamics. As such, a change in the market (e.g. reduction in demand) can have one effect in the short-run (reduced price), and a different effect in the long-run (reduced, constant, or increased price). In the real world, there will be many changes to the market in the short-run before the long-run has a chance to react to to any one of them; but we should still expect it to react to the net effect of all of them eventually.</span></p>\n<p class=\"p1\"><span class=\"s1\">Why do economists even bother measuring short-run dynamics (such as&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/31190/1/23020558.pdf\">short-run elasticity estimates</a>) on industries if they know that a longer view will render them obsolete? Probably because the demand for such research comes from producers who have to react to the short-run. Producers can't just wait for the long-run to come true; they actively realize it by reacting to short-run changes (otherwise the market would be 'stuck' in the short-run equilibrium).</span></p>\n<p>So <strong>if we care about long-run effects, but we don't have any data to know whether the industries and increasing-cost, constant-cost, or decreasing-cost, what prior should we use for our estimates?</strong> Basic intuition suggests we should assume an industry is constant-cost in the absence of industry-specific evidence. The rationalist-cited pieces I quoted above are welcome to make an argument that animal industries in particular are increasing-cost, but they haven't done that yet, or even acknowledged that the opposite is also possible.</p>\n<h2 id=\"Are_there_broader_lessons_to_learn_\">Are there broader lessons to learn?</h2>\n<p>Have we really been messing up our cost-effectiveness estimates simply by confusing the short-run and long-run in economics data? If so, why haven't we noticed it before?</p>\n<p>I'm not sure. But I wouldn't be surprised if one issue is, <strong>in the process of trying to create precise cost-effectiveness-style estimates it's tempting to use data<em> simply because it's there</em></strong>.</p>\n<p>How can we identify and prevent this bias in other estimates? Perhaps we should treat quantitative estimates as chains that are no stronger than their weakest link. If you're tempted to build a chain with a particularly weak link, consider if there's a way to build a similar chain without it (possibly gaining robustness at the cost of artificial precision or completeness) or <a href=\"http://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/\">whether chain-logic is even appropriate</a> for the purpose.</p>\n<p>For example, perhaps it should have raised flags that <a href=\"https://docs.google.com/spreadsheet/ccc?key=0AvhKlkBMF1aQdGFfcEM5d3FtVlM2a2kweFFHcVQySlE&amp;usp=sharing#gid=0\">ACE's estimates</a> for the above effect on broiler chicken production (which they call \"<a href=\"http://www.animalcharityevaluators.org/wp-content/uploads/2013/12/cef.pdf\">cumulative elasticity factor</a>\" or CEF) ranged by more than a factor of 10x, adding almost as much uncertainty to the final calculation for broiler chickens as the 5 other factors combined. (To be fair, the CEF estimates of the other animal products were not as lopsided.)</p>", "sections": [{"title": "The question:", "anchor": "The_question_", "level": 1}, {"title": "(Short-run) Answers from the rationalist community:", "anchor": "_Short_run__Answers_from_the_rationalist_community_", "level": 1}, {"title": "(Long-run) Answers from neoclassical economics:", "anchor": "_Long_run__Answers_from_neoclassical_economics_", "level": 1}, {"title": "In other words, while certain market characteristics (increasing-cost industries) would lead us to expect that production will fall by less than consumption in the long-run, it could also fall by an equal amount, or even more. ", "anchor": "In_other_words__while_certain_market_characteristics__increasing_cost_industries__would_lead_us_to_expect_that_production_will_fall_by_less_than_consumption_in_the_long_run__it_could_also_fall_by_an_equal_amount__or_even_more__", "level": 2}, {"title": "Short-run versus long-run", "anchor": "Short_run_versus_long_run", "level": 1}, {"title": "Are there broader lessons to learn?", "anchor": "Are_there_broader_lessons_to_learn_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "31 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BvLpXNBevSZe32bXd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-12T18:58:16.791Z", "modifiedAt": null, "url": null, "title": "What topics are appropriate for LessWrong?", "slug": "what-topics-are-appropriate-for-lesswrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:03.628Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "tog", "createdAt": "2011-10-04T12:54:07.164Z", "isAdmin": false, "displayName": "tog"}, "userId": "b4f6teTtsKfegjTaH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GGCb4eqmdT3LcQ8YZ/what-topics-are-appropriate-for-lesswrong", "pageUrlRelative": "/posts/GGCb4eqmdT3LcQ8YZ/what-topics-are-appropriate-for-lesswrong", "linkUrl": "https://www.lesswrong.com/posts/GGCb4eqmdT3LcQ8YZ/what-topics-are-appropriate-for-lesswrong", "postedAtFormatted": "Monday, January 12th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20topics%20are%20appropriate%20for%20LessWrong%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20topics%20are%20appropriate%20for%20LessWrong%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGGCb4eqmdT3LcQ8YZ%2Fwhat-topics-are-appropriate-for-lesswrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20topics%20are%20appropriate%20for%20LessWrong%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGGCb4eqmdT3LcQ8YZ%2Fwhat-topics-are-appropriate-for-lesswrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGGCb4eqmdT3LcQ8YZ%2Fwhat-topics-are-appropriate-for-lesswrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 160, "htmlBody": "<p>For example, what would be inappropriately off topic to post to LessWrong discussion about?</p>\n<p>I couldn't find an answer in the <a href=\"http://wiki.lesswrong.com/wiki/FAQ\">FAQ</a>. (Perhaps it'd be worth adding one.) The closest I could find was this:</p>\n<blockquote>\n<p><strong>What is Less Wrong?</strong></p>\n<p>Less Wrong is an online community for discussion of rationality. Topics of interest include decision theory, philosophy, self-improvement, cognitive science, psychology, artificial intelligence, game theory, metamathematics, logic, evolutionary psychology, economics, and the far future.</p>\n</blockquote>\n<p>However \"rationality\" can be interpreted broadly enough that rational discussion of anything would count, and my experience reading LW is compatible with this interpretation being applied by posters. Indeed my experience seems to suggest that practically everything is on topic; political discussion of certain sorts is frowned upon, but not due to being off topic. People often post about things far removed from the topics of interest. And some of these topics are very broad: it seems that a lot of material about self-improvement is acceptable, for instance.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GGCb4eqmdT3LcQ8YZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 2.3649609083541986e-06, "legacy": true, "legacyId": "27904", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 107, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-12T20:22:31.530Z", "modifiedAt": null, "url": null, "title": "Apptimize -- rationalist startup hiring engineers", "slug": "apptimize-rationalist-startup-hiring-engineers", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:22.596Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "nancyhua", "user": {"username": "nancyhua", "createdAt": "2012-09-20T15:19:16.187Z", "isAdmin": false, "displayName": "nancyhua"}, "userId": "iMArbgvsqQr2GupAA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8dt3PJXcYTsHtJnje/apptimize-rationalist-startup-hiring-engineers", "pageUrlRelative": "/posts/8dt3PJXcYTsHtJnje/apptimize-rationalist-startup-hiring-engineers", "linkUrl": "https://www.lesswrong.com/posts/8dt3PJXcYTsHtJnje/apptimize-rationalist-startup-hiring-engineers", "postedAtFormatted": "Monday, January 12th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Apptimize%20--%20rationalist%20startup%20hiring%20engineers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApptimize%20--%20rationalist%20startup%20hiring%20engineers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8dt3PJXcYTsHtJnje%2Fapptimize-rationalist-startup-hiring-engineers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Apptimize%20--%20rationalist%20startup%20hiring%20engineers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8dt3PJXcYTsHtJnje%2Fapptimize-rationalist-startup-hiring-engineers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8dt3PJXcYTsHtJnje%2Fapptimize-rationalist-startup-hiring-engineers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 577, "htmlBody": "<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><a href=\"http://apptimize.com\" target=\"_blank\">Apptimize</a> is a 2-year old startup closely connected with the rationalist community, <a href=\"/lw/lfg/cfar_in_2014_continuing_to_climb_out_of_the/\" target=\"_blank\">one of the first founded by CFAR alumni</a></span><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">. &nbsp;We make &ldquo;lean&rdquo; possible for mobile apps -- our software lets mobile developers update or A/B test their apps in minutes, without submitting to the App Store. Our customers include big companies such as Nook and Ebay, as well as Top 10 apps such as Flipagram. When companies evaluate our product against competitors, they&rsquo;ve chosen us every time.</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\"><br /></span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">We work incredibly hard, and we&rsquo;re striving to build the strongest engineering team in the Bay Area. If you&rsquo;re a good developer, we have a lot to offer.</span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Team</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><a href=\"http://apptimize.com/company/team/\" target=\"_blank\">Our team of 14</a> includes 7 MIT alumni, 3 ex-Googlers, 1 Wharton MBA, 1 CMU CS alum, 1 Stanford alum, 2 MIT Masters, 1 MIT Ph. D. candidate, and 1 &ldquo;20 Under 20&rdquo; Thiel Fellow. Our CEO was also just named to the <a href=\"http://www.forbes.com/pictures/mll45kfhf/nancy-hua-29/\" target=\"_blank\">Forbes &ldquo;30 Under 30</a>&rdquo;</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><a href=\"/user/DavidLS/overview/\" target=\"_blank\">David Salamon</a>, Anna Salamon&rsquo;s brother, built much of our early product</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Our CEO is <a href=\"/user/nancyhua/overview\" target=\"_blank\">Nancy Hua</a>, while our Android lead is \"20 under 20\" Thiel Fellow <a href=\"/user/Darmani/overview/\" target=\"_blank\">James Koppel</a>. They met after James spoke at the Singularity Summit</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">HP:MoR is required reading for the entire company</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">We evaluate candidates on <a href=\"/lw/ily/a_concise_version_of_twelve_virtues_of/\" target=\"_blank\">curiosity</a> even before evaluating them technically</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Seriously, our team is badass. <a href=\"http://apptimize.com/team\" target=\"_blank\">Just look</a> </span></p>\n</li>\n</ul>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Self Improvement</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">You will have huge autonomy and ownership over your part of the product. You can set up new infrastructure and tools, expense business products and services, and even subcontract some of your tasks if you think it's a good idea</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">You will learn to be a more goal-driven agent, and understand the impact of everything you do on the rest of the business</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Access to our library of over 50 books and audiobooks, and the freedom to purchase more</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Everyone shares insights they&rsquo;ve had every week</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Self-improvement is so important to us that we only hire people committed to it. When we say that it&rsquo;s a company value, we mean it</span></p>\n</li>\n</ul>\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: bold; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The Job</span></p>\n<ul style=\"margin-top: 0pt; margin-bottom: 0pt;\">\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Our mobile engineers dive into the dark, undocumented corners of iOS and Android, while our backend crunches data from billions of requests per day</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Engineers get giant monitors, a top-of-the-line MacBook pro, and we&rsquo;ll pay for whatever else is needed to get the job done</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">We don&rsquo;t demand prior experience, but we do demand the fearlessness to jump outside your comfort zone and job description. That said, our website uses AngularJS, jQuery, and nginx, while our backend uses AWS, Java (the good parts), and PostgreSQL</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">We don&rsquo;t have gratuitous perks, but we have what counts: Free snacks and catered meals, an excellent health and dental plan, and free membership to a gym across the street</span></p>\n</li>\n<li style=\"list-style-type: disc; font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\" dir=\"ltr\">\n<p style=\"line-height: 1.15; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 15px; font-family: Arial; color: #000000; background-color: transparent; font-weight: normal; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Seriously, working here is awesome. As one engineer puts it, &ldquo;we&rsquo;re like a family bent on taking over the world&rdquo;</span></p>\n</li>\n</ul>\n<p><br /><span style=\"font-size: 15px; font-family: Arial; vertical-align: baseline; white-space: pre-wrap; background-color: transparent;\">If you&rsquo;re interested, send some Bayesian evidence that you&rsquo;re a good match to jobs@apptimize.com</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8dt3PJXcYTsHtJnje", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 76, "baseScore": 93, "extendedScore": null, "score": 0.000277, "legacy": true, "legacyId": "27905", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-10-04T22:01:54.606Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": true, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 71, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.2.0", "pingbacks": {"Posts": ["KDGnsReYomusL89Rs", "TNyEe3bzonreRW9nB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-12T23:38:33.864Z", "modifiedAt": null, "url": null, "title": "Ethical Diets", "slug": "ethical-diets", "viewCount": null, "lastCommentedAt": "2017-06-26T22:58:40.532Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pcm", "createdAt": "2017-06-17T00:51:23.973Z", "isAdmin": false, "displayName": "pcm"}, "userId": "9bxscuK69SnmpBqSA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zD9467yaW4cmPEJFy/ethical-diets", "pageUrlRelative": "/posts/zD9467yaW4cmPEJFy/ethical-diets", "linkUrl": "https://www.lesswrong.com/posts/zD9467yaW4cmPEJFy/ethical-diets", "postedAtFormatted": "Monday, January 12th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ethical%20Diets&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEthical%20Diets%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzD9467yaW4cmPEJFy%2Fethical-diets%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ethical%20Diets%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzD9467yaW4cmPEJFy%2Fethical-diets", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzD9467yaW4cmPEJFy%2Fethical-diets", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 783, "htmlBody": "<p>[Cross-posted from <a href=\"http://www.bayesianinvestor.com/blog/index.php/2015/01/08/ethical-diets/\">my blog</a>.]</p>\n<p>I've seen some <a href=\"https://meteuphoric.wordpress.com/2014/11/21/when-should-an-effective-altruist-be-vegetarian/\">discussion</a> of whether effective altruists have an obligation to be vegan or vegetarian.</p>\n<p>The carnivores appear to underestimate the long-term effects of their actions. I see a nontrivial chance that we're headed toward a society in which humans are less powerful than some other group of agents. This could result from slow AGI takeoff producing a heterogeneous society of superhuman agents. Or there could be a long period in which the world is dominated by <em>ems</em> before <em>de novo</em> AGI becomes possible. Establishing ethical (and maybe legal) rules that protect less powerful agents may influence how AGIs treat humans or how high-speed <em>ems</em> treat low-speed <em>ems</em> and biological humans [0]. A one in a billion chance that I can alter this would be worth some of my attention. There are probably other similar ways that an expanding circle of ethical concern can benefit future people.</p>\n<p>I see very real costs to adopting an ethical diet, but it seems implausible that EAs are merely choosing alternate ways of being altruistic. How much does it cost MealSquares customers to occasionally bemoan MealSquares use of products from apparently factory-farmed animals? Instead, it seems like EAs have some tendency to actively raise the status of MealSquares [1].</p>\n<p>I don't find it useful to compare a more ethical diet to GiveWell donations for my personal choices, because I expect my costs to be mostly inconveniences, and the marginal value of my time seems small [2], with little fungibility between them.</p>\n<p>I'm reluctant to adopt a vegan diet due to the difficulty of evaluating the <a href=\"http://ajcn.nutrition.org/content/70/3/516s.full\">health effects</a> and due to the difficulty of evaluating whether it would mean fewer animals living lives that they'd <a href=\"http://hanson.gmu.edu/meat.html\">prefer</a> to <a href=\"http://marginalrevolution.com/marginalrevolution/2010/03/the-philosophical-cow.html\">nonexistence</a>.</p>\n<p>But there's little dispute that most factory-farmed animals are much less happy than pasture-raised animals. And everything I know about the nutritional differences suggests that avoiding factory-farmed animals improves my health [3].</p>\n<p>I plan not to worry about factory-farmed invertebrates for now (shrimp, oysters, <a href=\"http://www.bayesianinvestor.com/blog/index.php/2014/07/17/crickets/\">insects</a>), partly because some of the harmful factory-farm practices such as confining animals to cages not much bigger than the animals in question aren't likely with animals that small.</p>\n<p>So my diet will consist of vegan food plus shellfish, insects, wild-caught fish, <a href=\"http://rockridgemarkethall.com/msf\">pasture-raised birds/mammals</a> (and their eggs/whey/butter). I will assume vertebrate animals are raised in cruel conditions unless they're clearly marked as wild-caught, grass-fed, or pasture-raised [4].</p>\n<p>I've made enough changes to my diet for health reasons that this won't require large changes. I already eat at home mostly, and the biggest change to that part of my diet will involve replacing QuestBars with a home-made version using whey protein from grass-fed cows (my experiments so far indicate it's inconvenient and hard to get a decent texture). I also have some uncertainty about pork belly [5] - the pasture-raised version I've tried didn't seem as good, but that might be because I didn't know it needed to be sliced very thin.</p>\n<p>My main concern is large social gatherings. It has taken me a good deal of willpower to stick to a healthy diet under those conditions, and I expect it to take more willpower to observe ethical constraints.</p>\n<p>A 100% pure diet would be much harder for me to achieve than an almost pure diet, and it takes some time for me to shift my habits. So for this year I plan to estimate how many calories I eat that don't fit this diet, and aim to keep that less than 120 calories per month (about 0.2%) [6]. I'll re-examine the specifics of this plan next Jan 1.</p>\n<p>Does anyone know a convenient name for my planned diet?</p>\n<p>&nbsp;</p>\n<h4>footnotes</h4>\n<p>&nbsp;</p>\n<p>0. With no one agent able to conquer the world, it's costly for a single agent to repudiate an existing rule. A homogeneous group of superhuman agents might coordinate to overcome this, but with heterogeneous agents the coordination costs may matter.</p>\n<p>1. I bought 3 orders of MealSquares, but have stopped buying for now. If they sell a version whose animal products are ethically produced (which I'm guessing would cost $50/order more), I'll resume buying them occasionally.</p>\n<p>2. The average financial value of my time is unusually high, but I often have trouble estimating whether spending more time earning money has positive or negative financial results. I expect financial concerns will be more important to many people.</p>\n<p>3. With the probable exception of factory-farmed insects, oysters, and maybe other shellfish.</p>\n<p>4. In most restaurants, this will limit me to vegan food and shellfish.</p>\n<p>5. Pork belly is unsliced bacon without the harm caused by smoking.</p>\n<p>6. Yes, I'll have some incentive to fudge those estimates. My experience from tracking food for health reasons suggests possible errors of 25%. That's not too bad compared to other risks such as lack of willpower.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zD9467yaW4cmPEJFy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 6, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "27906", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T00:04:00.237Z", "modifiedAt": null, "url": null, "title": "How subjective is attractiveness?", "slug": "how-subjective-is-attractiveness", "viewCount": null, "lastCommentedAt": "2015-01-16T16:51:30.186Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X3jz5mriJeWi2uLdF/how-subjective-is-attractiveness", "pageUrlRelative": "/posts/X3jz5mriJeWi2uLdF/how-subjective-is-attractiveness", "linkUrl": "https://www.lesswrong.com/posts/X3jz5mriJeWi2uLdF/how-subjective-is-attractiveness", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20subjective%20is%20attractiveness%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20subjective%20is%20attractiveness%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX3jz5mriJeWi2uLdF%2Fhow-subjective-is-attractiveness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20subjective%20is%20attractiveness%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX3jz5mriJeWi2uLdF%2Fhow-subjective-is-attractiveness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX3jz5mriJeWi2uLdF%2Fhow-subjective-is-attractiveness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1272, "htmlBody": "<p>Consider the two statements:</p>\n<ul>\n<li>There is a universal standard for beauty.</li>\n<li>Beauty is in the eye of the beholder.</li>\n</ul>\n<p>Most people would agree that there's some truth to each of these statements. At&nbsp;<a href=\"http://thingofthings.wordpress.com/\">Thing of Things</a>&nbsp;Ozy wrote:</p>\n<blockquote>\n<p>As for the beauty thing&hellip; well, yeah, everyone&rsquo;s beautiful in the sense that everyone is sexually attractive to someone, and that human bodies in general are pretty cool-looking. But conventional attractiveness is still a thing. While I&rsquo;m fairly conventionally attractive (thin, white, clear skin, symmetrical features), I doubt hairy legs, bound chests, and haircuts that make one look like a teenage boy are going to be all the rage at Cosmo any time soon.</p>\n</blockquote>\n<p>This post explores the question of the <em>extent</em>&nbsp;to which each of the two statements is true, using data from <a href=\"http://andrewgelman.com/2008/01/21/the_speeddating_1/\">a study of speed dating events</a>&nbsp;conducted by&nbsp;Raymond Fisman and Sheena Iyengar.&nbsp;</p>\n<p>The basic facts &nbsp;that I describe here are:</p>\n<ul>\n<li>Attractiveness as defined by group consensus can be modeled well using a <a href=\"http://en.wikipedia.org/wiki/Normal_distribution\">normal distribution</a>.</li>\n<li>The group consensus on somebody's attractiveness accounted for&nbsp;<strong>roughly 60%&nbsp;</strong>of the variance in people's perceptions of the person's relative attractiveness.</li>\n<li>The distribution of people's perceptions of the relative attractiveness of a fixed person&nbsp;can be modeled well using a normal distribution. Moreover, the standard deviations of these distributions tend to be quite close to one another (across different people), so that it's often possible to approximate the entire distribution of perceptions of somebody's relative attractiveness using only the mean of the distribution, which is just the group consensus on the person's attractiveness.&nbsp;</li>\n</ul>\n<p>There's much more to say about how to interpret the group consensus and its implications, which I'll go into in a later post.</p>\n<p><a id=\"more\"></a></p>\n<p>Each event involved ~15 men and ~15 women, and everybody of a given gender went on speed dates with everyone of opposite gender. Each participant on each date rated his or her partner on a number of dimensions, including attractiveness, on a scale from 1 to 10. For the purpose of this post, I focused on how attractive raters found a ratee <em>relative to other ratees</em>. For this reason, I scaled each rater's ratings so that the averages are the same for all raters <em>of a given gender</em>.&nbsp;</p>\n<h2>Gender differences</h2>\n<p>One sees essentially the same phenomena when the raters are men and the ratees are women as one does when the genders are reversed. There is however one <strong>very important</strong>&nbsp;<strong>difference</strong>: the average of the ratings that men gave women was ~6.5, and the average of the ratings that women gave men was ~5.9. The standard deviations were the (interestingly) same in both cases, and in terms of standard deviations, women were rated 0.5 SD higher than men were. This fact may have profound ramifications. I've pictured the distributions of average attractiveness ratings of men and of women below:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_0.png?v=4fcbf0fac01c1c3af1ff5be64ccdf932\" alt=\"\" width=\"702\" height=\"517\" /></p>\n<p>The main difference between the distributions is that the one for women is shifted to the right relative to the one for men. The shapes of the distributions are also a little bit different, but one can verify that the difference within the range of what one would expect by chance.</p>\n<h2>Hierarchical modeling</h2>\n<p>We're interested in what the average ratings would be if a sufficiently large number of raters rated a given ratee.</p>\n<p>The ratees who are rated highest and lowest are also the ratees whose ratings are most likely to be unrepresentative of the entire population's consensus on their attractiveness: there's regression to the mean.</p>\n<p>A methodology that allows us to correct for this is <em>Bayesian hierarchical modeling</em>, which involves simultaneously estimating the \"true\" distribution of average attractiveness ratings of <em>all</em>&nbsp;hypothetical ratees together with the true average attractiveness ratings of the <em>particular ratees</em> in the dataset. The default assumption in Bayesian hierarchical modeling is that the true distribution is a normal distribution with mean and standard deviation to be determined. The histograms above suggest that this is close to being true in our setting.</p>\n<p>If we use Bayesian hierarchical modeling to generate refined estimates for the averages, we get distributions that look something like the following:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_1.png?v=8c735e5cf3daf5bd5e881695e6443935\" alt=\"\" width=\"702\" height=\"517\" /></p>\n<p>Note that the in contrast with the actual averages, the refined estimates are never below 4.5 or above 8 &ndash; &nbsp;the participants weren't rated by enough people for us to be confident that any participant is that far away from average.</p>\n<p>The standard deviations of the distributions are nearly identical: 0.6 points on the 10 point scale.</p>\n<h2>The distribution of ratings for a fixed person</h2>\n<p>The image below shows the ratings of 18 women by 17 men.</p>\n<ul>\n<li>The columns correspond to ratees and the first 17 rows correspond to raters.&nbsp;</li>\n<li>Blue corresponds to \"below average in the eyes of the raters\" and red corresponds to \"above average in the eyes of the rater.\"&nbsp;</li>\n<li>The numbers in the side bar correspond to the number of points that a rating is above or below average.&nbsp;</li>\n<li>The final three rows give the median, minimum and maximum ratings of a ratee.</li>\n</ul>\n<p>&nbsp;</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_4.png?v=0478fb77bdb1b035e546271e05e35fc7\" alt=\"\" width=\"702\" height=\"517\" /></p>\n<p>One sees that with the exception of the ratees in columns 10 and 16, all ratees had <em>at least one </em>rater who perceived her attractiveness to be <em>noticeably</em> <em>above average</em> and <em>at least one</em> rater who perceived her attractiveness to be <em>noticeably</em> <em>below average</em>.&nbsp;</p>\n<p>The graph below shows the median rating (black), maximum rating (red) and minimum rating (blue) for all ratees in the study, together with best fit curves:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_6.png?v=98a1742b1562a499ff2d76553eb521ad\" alt=\"\" width=\"552\" height=\"507\" /></p>\n<p>Here too, one sees that there are very few people who are consistently rated as being above average or below average.</p>\n<p>This is consistent with the fact that the fact that <em>the standard deviation of the ratings that an individual was given was roughly the same as the standard deviation of average ratings of the population of ratees</em>. I've plotted the standard deviations for individual ratees below:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_7.png?v=cf1e3d6828df119ae37728a568323eab\" alt=\"\" width=\"552\" height=\"507\" /></p>\n<p>We see that the standard deviations have a strong central tendency, with mean equal to ~0.7 points.</p>\n<p>The average standard deviation being 0.7 points overstates the variability in perceptions of an individual's attractiveness. Some reasons for this are:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Ratings on a 10 point scale are imprecise: for example, raters were not allowed to give numerical ratings of 6.5.</li>\n<li>Individual raters may inaccurately convey their perceptions of the person's attractiveness on account of not devoting their full attention to the task of reporting on it.</li>\n</ul>\n<p>&nbsp;</p>\n<p>In order to estimate the true standard deviation of the distribution of perceptions of a given person's attractiveness, I examined the relative predictive power of:</p>\n<p>(i) Our refined estimate of the group consensus on ratees' attractiveness</p>\n<p>(ii) The extent to which a rater's rating deviates from this estimate</p>\n<p>in the context of predicting a rater's decisions as to whether or not to see a ratee again.</p>\n<p>I found that 60% of the predictive power comes from the group consensus and 40% of the predictive power comes from deviations from the group consensus, suggesting that the standard deviation of variation in perceptions of a ratee's attractiveness is about 2/3 that of the standard deviation of the group consensus across ratees. In terms of points on a 10 point scale, this is about 0.45 points.</p>\n<h2>To be continued...</h2>\n<p>In subsequent posts, I'll describe how the data bears on the following questions:</p>\n<p>&nbsp;</p>\n<ul>\n<li>How do people vary with respect to how much their perceptions are in line with the group consensus?</li>\n<li>What characteristics do people whose perceptions agree with the group consensus have?</li>\n<li>Is there just <em>one</em>&nbsp;group consensus, or does the population split into subgroups, each of which has its own consensus?</li>\n<li>What are the relative roles of physical appearance and personality traits in determining people's perceptions of somebody's attractiveness</li>\n<li>How much were people's decisions concerning whether or not to see somebody again driven by attractiveness?</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bh7uxTTqmsQ8jZJdB": 1, "W9aNkPwtPhMrcfgj7": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X3jz5mriJeWi2uLdF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 36, "extendedScore": null, "score": 0.00012, "legacy": true, "legacyId": "27902", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Consider the two statements:</p>\n<ul>\n<li>There is a universal standard for beauty.</li>\n<li>Beauty is in the eye of the beholder.</li>\n</ul>\n<p>Most people would agree that there's some truth to each of these statements. At&nbsp;<a href=\"http://thingofthings.wordpress.com/\">Thing of Things</a>&nbsp;Ozy wrote:</p>\n<blockquote>\n<p>As for the beauty thing\u2026 well, yeah, everyone\u2019s beautiful in the sense that everyone is sexually attractive to someone, and that human bodies in general are pretty cool-looking. But conventional attractiveness is still a thing. While I\u2019m fairly conventionally attractive (thin, white, clear skin, symmetrical features), I doubt hairy legs, bound chests, and haircuts that make one look like a teenage boy are going to be all the rage at Cosmo any time soon.</p>\n</blockquote>\n<p>This post explores the question of the <em>extent</em>&nbsp;to which each of the two statements is true, using data from <a href=\"http://andrewgelman.com/2008/01/21/the_speeddating_1/\">a study of speed dating events</a>&nbsp;conducted by&nbsp;Raymond Fisman and Sheena Iyengar.&nbsp;</p>\n<p>The basic facts &nbsp;that I describe here are:</p>\n<ul>\n<li>Attractiveness as defined by group consensus can be modeled well using a <a href=\"http://en.wikipedia.org/wiki/Normal_distribution\">normal distribution</a>.</li>\n<li>The group consensus on somebody's attractiveness accounted for&nbsp;<strong>roughly 60%&nbsp;</strong>of the variance in people's perceptions of the person's relative attractiveness.</li>\n<li>The distribution of people's perceptions of the relative attractiveness of a fixed person&nbsp;can be modeled well using a normal distribution. Moreover, the standard deviations of these distributions tend to be quite close to one another (across different people), so that it's often possible to approximate the entire distribution of perceptions of somebody's relative attractiveness using only the mean of the distribution, which is just the group consensus on the person's attractiveness.&nbsp;</li>\n</ul>\n<p>There's much more to say about how to interpret the group consensus and its implications, which I'll go into in a later post.</p>\n<p><a id=\"more\"></a></p>\n<p>Each event involved ~15 men and ~15 women, and everybody of a given gender went on speed dates with everyone of opposite gender. Each participant on each date rated his or her partner on a number of dimensions, including attractiveness, on a scale from 1 to 10. For the purpose of this post, I focused on how attractive raters found a ratee <em>relative to other ratees</em>. For this reason, I scaled each rater's ratings so that the averages are the same for all raters <em>of a given gender</em>.&nbsp;</p>\n<h2 id=\"Gender_differences\">Gender differences</h2>\n<p>One sees essentially the same phenomena when the raters are men and the ratees are women as one does when the genders are reversed. There is however one <strong>very important</strong>&nbsp;<strong>difference</strong>: the average of the ratings that men gave women was ~6.5, and the average of the ratings that women gave men was ~5.9. The standard deviations were the (interestingly) same in both cases, and in terms of standard deviations, women were rated 0.5 SD higher than men were. This fact may have profound ramifications. I've pictured the distributions of average attractiveness ratings of men and of women below:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_0.png?v=4fcbf0fac01c1c3af1ff5be64ccdf932\" alt=\"\" width=\"702\" height=\"517\"></p>\n<p>The main difference between the distributions is that the one for women is shifted to the right relative to the one for men. The shapes of the distributions are also a little bit different, but one can verify that the difference within the range of what one would expect by chance.</p>\n<h2 id=\"Hierarchical_modeling\">Hierarchical modeling</h2>\n<p>We're interested in what the average ratings would be if a sufficiently large number of raters rated a given ratee.</p>\n<p>The ratees who are rated highest and lowest are also the ratees whose ratings are most likely to be unrepresentative of the entire population's consensus on their attractiveness: there's regression to the mean.</p>\n<p>A methodology that allows us to correct for this is <em>Bayesian hierarchical modeling</em>, which involves simultaneously estimating the \"true\" distribution of average attractiveness ratings of <em>all</em>&nbsp;hypothetical ratees together with the true average attractiveness ratings of the <em>particular ratees</em> in the dataset. The default assumption in Bayesian hierarchical modeling is that the true distribution is a normal distribution with mean and standard deviation to be determined. The histograms above suggest that this is close to being true in our setting.</p>\n<p>If we use Bayesian hierarchical modeling to generate refined estimates for the averages, we get distributions that look something like the following:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_1.png?v=8c735e5cf3daf5bd5e881695e6443935\" alt=\"\" width=\"702\" height=\"517\"></p>\n<p>Note that the in contrast with the actual averages, the refined estimates are never below 4.5 or above 8 \u2013 &nbsp;the participants weren't rated by enough people for us to be confident that any participant is that far away from average.</p>\n<p>The standard deviations of the distributions are nearly identical: 0.6 points on the 10 point scale.</p>\n<h2 id=\"The_distribution_of_ratings_for_a_fixed_person\">The distribution of ratings for a fixed person</h2>\n<p>The image below shows the ratings of 18 women by 17 men.</p>\n<ul>\n<li>The columns correspond to ratees and the first 17 rows correspond to raters.&nbsp;</li>\n<li>Blue corresponds to \"below average in the eyes of the raters\" and red corresponds to \"above average in the eyes of the rater.\"&nbsp;</li>\n<li>The numbers in the side bar correspond to the number of points that a rating is above or below average.&nbsp;</li>\n<li>The final three rows give the median, minimum and maximum ratings of a ratee.</li>\n</ul>\n<p>&nbsp;</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_4.png?v=0478fb77bdb1b035e546271e05e35fc7\" alt=\"\" width=\"702\" height=\"517\"></p>\n<p>One sees that with the exception of the ratees in columns 10 and 16, all ratees had <em>at least one </em>rater who perceived her attractiveness to be <em>noticeably</em> <em>above average</em> and <em>at least one</em> rater who perceived her attractiveness to be <em>noticeably</em> <em>below average</em>.&nbsp;</p>\n<p>The graph below shows the median rating (black), maximum rating (red) and minimum rating (blue) for all ratees in the study, together with best fit curves:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_6.png?v=98a1742b1562a499ff2d76553eb521ad\" alt=\"\" width=\"552\" height=\"507\"></p>\n<p>Here too, one sees that there are very few people who are consistently rated as being above average or below average.</p>\n<p>This is consistent with the fact that the fact that <em>the standard deviation of the ratings that an individual was given was roughly the same as the standard deviation of average ratings of the population of ratees</em>. I've plotted the standard deviations for individual ratees below:</p>\n<p><img src=\"http://images.lesswrong.com/t3_lj2_7.png?v=cf1e3d6828df119ae37728a568323eab\" alt=\"\" width=\"552\" height=\"507\"></p>\n<p>We see that the standard deviations have a strong central tendency, with mean equal to ~0.7 points.</p>\n<p>The average standard deviation being 0.7 points overstates the variability in perceptions of an individual's attractiveness. Some reasons for this are:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Ratings on a 10 point scale are imprecise: for example, raters were not allowed to give numerical ratings of 6.5.</li>\n<li>Individual raters may inaccurately convey their perceptions of the person's attractiveness on account of not devoting their full attention to the task of reporting on it.</li>\n</ul>\n<p>&nbsp;</p>\n<p>In order to estimate the true standard deviation of the distribution of perceptions of a given person's attractiveness, I examined the relative predictive power of:</p>\n<p>(i) Our refined estimate of the group consensus on ratees' attractiveness</p>\n<p>(ii) The extent to which a rater's rating deviates from this estimate</p>\n<p>in the context of predicting a rater's decisions as to whether or not to see a ratee again.</p>\n<p>I found that 60% of the predictive power comes from the group consensus and 40% of the predictive power comes from deviations from the group consensus, suggesting that the standard deviation of variation in perceptions of a ratee's attractiveness is about 2/3 that of the standard deviation of the group consensus across ratees. In terms of points on a 10 point scale, this is about 0.45 points.</p>\n<h2 id=\"To_be_continued___\">To be continued...</h2>\n<p>In subsequent posts, I'll describe how the data bears on the following questions:</p>\n<p>&nbsp;</p>\n<ul>\n<li>How do people vary with respect to how much their perceptions are in line with the group consensus?</li>\n<li>What characteristics do people whose perceptions agree with the group consensus have?</li>\n<li>Is there just <em>one</em>&nbsp;group consensus, or does the population split into subgroups, each of which has its own consensus?</li>\n<li>What are the relative roles of physical appearance and personality traits in determining people's perceptions of somebody's attractiveness</li>\n<li>How much were people's decisions concerning whether or not to see somebody again driven by attractiveness?</li>\n</ul>\n<p>&nbsp;</p>", "sections": [{"title": "Gender differences", "anchor": "Gender_differences", "level": 1}, {"title": "Hierarchical modeling", "anchor": "Hierarchical_modeling", "level": 1}, {"title": "The distribution of ratings for a fixed person", "anchor": "The_distribution_of_ratings_for_a_fixed_person", "level": 1}, {"title": "To be continued...", "anchor": "To_be_continued___", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "38 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T02:00:11.506Z", "modifiedAt": null, "url": null, "title": "Superintelligence 18: Life in an algorithmic economy", "slug": "superintelligence-18-life-in-an-algorithmic-economy", "viewCount": null, "lastCommentedAt": "2020-08-29T23:31:26.137Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iZNcMkS6ghqBQA24E/superintelligence-18-life-in-an-algorithmic-economy", "pageUrlRelative": "/posts/iZNcMkS6ghqBQA24E/superintelligence-18-life-in-an-algorithmic-economy", "linkUrl": "https://www.lesswrong.com/posts/iZNcMkS6ghqBQA24E/superintelligence-18-life-in-an-algorithmic-economy", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Superintelligence%2018%3A%20Life%20in%20an%20algorithmic%20economy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuperintelligence%2018%3A%20Life%20in%20an%20algorithmic%20economy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiZNcMkS6ghqBQA24E%2Fsuperintelligence-18-life-in-an-algorithmic-economy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Superintelligence%2018%3A%20Life%20in%20an%20algorithmic%20economy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiZNcMkS6ghqBQA24E%2Fsuperintelligence-18-life-in-an-algorithmic-economy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiZNcMkS6ghqBQA24E%2Fsuperintelligence-18-life-in-an-algorithmic-economy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1863, "htmlBody": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr />\n<p>Welcome. This week we discuss the eighteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Life in an algorithmic economy</strong></em>. This corresponds to the middle of Chapter 11.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: &ldquo;Life in an algorithmic economy&rdquo; from Chapter 11</p>\n<hr />\n<h1>Summary</h1>\n<ol>\n<li>In a multipolar scenario, <strong>biological humans&nbsp;might lead poor and meager lives.</strong> (p166-7)</li>\n<li>The <strong>AIs might be worthy of moral consideration</strong>, and if so their wellbeing might be more important than that of the relatively few humans. (p167)</li>\n<li><strong>AI minds might be much like slaves</strong>, even if they are not literally. They may be selected for liking this. (p167)</li>\n<li>Because brain emulations would be very cheap to copy, <strong>it will often be convenient to make a copy and then later turn it off</strong> (in a sense killing a person). (p168)</li>\n<li>There are various other reasons that very short lives might be optimal for some applications. (p168-9)</li>\n<li><strong>It isn't obvious whether brain emulations would be happy</strong> working all of the time. Some relevant considerations are current human emotions in general and regarding work, probable selection for pro-work individuals, evolutionary adaptiveness of happiness in the past and future -- e.g. does happiness help you work harder?--and absence of present sources of unhappiness such as injury. (p169-171)</li>\n<li><strong>In the long run, artificial minds may not even be conscious, or have valuable experiences</strong>, if these are not the most effective ways for them to earn wages. If such minds replace humans, <strong>Earth might have an advanced civilization with nobody there to benefit</strong>. (p172-3)</li>\n<li>In the long run, <strong>artificial minds may outsource many parts of their thinking</strong>, thus becoming decreasingly differentiated as individuals. (p172)</li>\n<li><strong>Evolution does not imply positive progress.</strong>&nbsp;Even those good things that evolved in the past may not withstand evolutionary selection in a new circumstance. (p174-6)</li>\n</ol>\n<h1>Another view</h1>\n<p><a href=\"http://www.overcomingbias.com/2013/03/on-disowning-descendants.html#sthash.uP5O5usO.dpuf\">Robin Hanson</a> on others' hasty distaste for a future of emulations:&nbsp;</p>\n<blockquote>\n<p>Parents sometimes disown their children, on the grounds that those children have betrayed key parental values. And if parents have the sort of values that kids could deeply betray, then it does make sense for parents to watch out for such betrayal, ready to go to extremes like disowning in response.</p>\n<p>But surely parents who feel inclined to disown their kids should be encouraged to study their kids carefully before making such a choice. For example, parents considering whether to disown their child for refusing to fight a war for their nation, or for working for a cigarette manufacturer, should wonder to what extend national patriotism or anti-smoking really are core values, as opposed to being mere revisable opinions they collected at one point in support of other more-core values. Such parents would be wise to study the lives and opinions of their children in some detail before choosing to disown them.</p>\n<p>I&rsquo;d like people to think similarly about my attempts to analyze likely futures. The lives of our descendants in the next great era after this our industry era may be as different from ours&rsquo; as ours&rsquo; are from farmers&rsquo;, or farmers&rsquo; are from foragers&rsquo;. When they have lived as neighbors, foragers have often strongly criticized farmer culture, as farmers have often strongly criticized industry culture. Surely many have been tempted to disown any descendants who adopted such despised new ways. And while such disowning might hold them true to core values, if asked we would advise them to consider the lives and views of such descendants carefully, in some detail, before choosing to disown.</p>\n<p>Similarly, many who live industry era lives and share industry era values, may be disturbed to see forecasts of descendants with life styles that appear to reject many values they hold dear. Such people may be tempted to reject such outcomes, and to fight to prevent them, perhaps preferring a continuation of our industry era to the arrival of such a very different era, even if that era would contain far more creatures who consider their lives worth living, and be far better able to prevent the extinction of Earth civilization. And such people may be correct that such a rejection and battle holds them true to their core values.</p>\n<p>But I advise such people to first try hard to see this new era in some detail from the point of view of its typical residents. See what they enjoy and what fills them with pride, and listen to their criticisms of your era and values. I hope that my future analysis can assist such soul-searching examination. If after studying such detail, you still feel compelled to disown your likely descendants, I cannot confidently say you are wrong. My job, first and foremost, is to help you see them clearly.</p>\n</blockquote>\n<p>More on whose lives are worth living&nbsp;<a href=\"http://www.overcomingbias.com/2012/04/jiro-lives-worth-living.html\">here</a> and <a href=\"http://www.overcomingbias.com/2011/04/are-workaholics-human.html\">here</a>.</p>\n<h1>Notes</h1>\n<p>1. Robin Hanson is probably the foremost researcher on what the finer details of an economy of&nbsp;<a href=\"http://en.wikipedia.org/wiki/Mind_uploading\">emulated human minds</a>&nbsp;would be like. For instance, which company employees would run how fast, how big cities would be, whether people would hang out with their copies. See a&nbsp;<a href=\"https://www.youtube.com/watch?v=9qcIsjrHENU\">TEDx talk</a>, and writings&nbsp;<a href=\"http://hanson.gmu.edu/IEEESpectrum-6-08.pdf\">here</a>,&nbsp;<a href=\"http://hanson.gmu.edu/Futurist.pdf\">here</a>,&nbsp;<a href=\"http://hanson.gmu.edu/IntelligenceUnbound.pdf\">here</a>&nbsp;and&nbsp;<a href=\"http://www.overcomingbias.com/tag/ems\">here</a>&nbsp;(some overlap - sorry). He is also writing a book on the subject, which you can&nbsp;<a href=\"http://www.overcomingbias.com/2013/09/wanted-know-it-some-critics.html\">read</a>&nbsp;early if you ask him.&nbsp;</p>\n<p>2. Bostrom says,</p>\n<blockquote>\n<p>Life for biological humans in a post-transition Malthusian state need not resemble any of the historical states of man...the majority of humans in this scenario might be idle rentiers who eke out a marginal living on their savings. They would be very poor, yet derive what little income they have from savings or state subsidies. They would live in a world with &nbsp;extremely advanced technology, including not only superintelligent machines but also anti-aging medicine, virtual reality, and various enhancement technologies and pleasure drugs: yet these might be generally unaffordable....(p166)</p>\n</blockquote>\n<p>It's true this might happen, but it doesn't seem like an especially likely scenario to me. As Bostrom has pointed out in various places earlier, biological humans would do quite well if they have some investments in capital, do not have too much of their property stolen or artfully manouvered away from them, and do not undergo too massive population growth themselves. These risks don't seem so large to me.</p>\n<div>3. Paul Christiano has an <a href=\"http://rationalaltruist.com/2014/05/14/machine-intelligence-and-capital-accumulation/\">interesting article</a> on capital accumulation in a world of machine intelligence.</div>\n<div><br /></div>\n<div>4. In discussing worlds of brain emulations, we often talk about selecting people for having various characteristics - for instance, being extremely productive, hard-working, not minding frequent 'death', being willing to work for free and donate any proceeds to their employer (p167-8). However there are only so many humans to select from, so we can't necessarily select for all the characteristics we might want. Bostrom also talks of using other motivation selection methods, and modifying code, but it is interesting to ask how far you could get using only selection. It is not obvious to what extent one could meaningfully modify brain emulation code initially.&nbsp;</div>\n<div><br /></div>\n<div>I'd guess less than one in a thousand people would be willing to donate everything to their employer, given a random employer. This means to get this characteristic, you would have to lose a factor of 1000 on selecting for other traits. All together you have about 33 bits of selection power in the present world (that is, 7 billion is about 2^33; you can divide the world in half about 33 times before you get to a single person). Lets suppose you use 5 bits in getting someone who both doesn't mind their copies dying (I guess 1 bit, or half of people) and who is willing to work an 80h/week (I guess 4 bits, or one in sixteen people). Lets suppose you are using the rest of your selection (28 bits) on intelligence, for the sake of argument. You are getting a person of IQ <a href=\"http://www.iqcomparisonsite.com/iqtable.aspx\">186</a>. If instead you use 10 bits (2^10 = ~1000) on getting someone to donate all their money to their employer, you can only use 18 bits on intelligence, getting a person of IQ <a href=\"http://www.iqcomparisonsite.com/iqtable.aspx\">167</a>. Would it not often be better to have the worker who is twenty IQ points smarter and pay them above subsistance?</div>\n<div><br /></div>\n<div>5. A variety of valuable uses for cheap to copy, short-lived brain emulations are discussed in&nbsp;<a href=\"http://intelligence.org/files/WBE-Superorgs.pdf\">Whole brain emulation and the evolution of superorganisms</a>, <a href=\"/lw/hfd/the_impact_of_whole_brain_emulation/\">LessWrong discussion on the impact of whole brain emulation</a>, and Robin's work cited above.</div>\n<div><br /></div>\n<div>6. Anders Sandberg <a href=\"http://www.aleph.se/papers/Ethics%20of%20brain%20emulations%20draft.pdf\">writes about</a> moral implications of emulations of animals and humans.</div>\n<div><br /></div>\n<h1>In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>Is the first functional whole brain emulation likely to be (1) an emulation of low-level functionality that doesn&rsquo;t require much understanding of human cognitive neuroscience at the computational level, as described in <a href=\"http://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf\">Sandberg &amp; Bostrom (2008)</a>, or is it more likely to be (2) an emulation that makes heavy use of advanced human cognitive neuroscience, as described by (e.g.) <a href=\"https://intelligence.org/2014/09/09/hayworth/\">Ken Hayworth</a>, or is it likely to be (3) something else?</li>\n<li>Extend and update our understanding of when brain emulations might appear (see&nbsp;<a href=\"http://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf\">Sandberg &amp; Bostrom (2008)</a>).</li>\n<li>Investigate the likelihood of a multipolar outcome?</li>\n<li>Follow Robin Hanson (see above) in working out the social implications of an emulation scenario</li>\n<li>What kinds of responses to the default low-regulation multipolar outcome outlined in this section are likely to be made? e.g. is any strong regulation likely to emerge that avoids the features detailed in the current section?</li>\n<li>What measures are useful for ensuring good multipolar outcomes?</li>\n<li>What qualitatively different kinds of multipolar outcomes might we expect? e.g. brain emulation outcomes are one class.</li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1>How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about the possibility of a multipolar outcome turning into a singleton later. To prepare,&nbsp;<strong>read</strong>&nbsp;&ldquo;Post-transition formation of a singleton?&rdquo; from Chapter 11<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 19 January. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1, "tdt83ChxnEgwwKxi6": 1, "PDJ6KqJBRzvKPfuS3": 1, "jQytxyauJ7kPhhGj3": 1, "5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iZNcMkS6ghqBQA24E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 2.365977566962664e-06, "legacy": true, "legacyId": "27563", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>This is part of a weekly reading group on&nbsp;<a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a>'s book,&nbsp;<a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111\">Superintelligence</a>. For more information about the group, and an index of posts so far see the&nbsp;<a href=\"/lw/kw4/superintelligence_reading_group/\">announcement post</a>. For the schedule of future topics, see&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">MIRI's reading guide</a>.</em></p>\n<hr>\n<p>Welcome. This week we discuss the eighteenth section in the&nbsp;<a href=\"https://intelligence.org/wp-content/uploads/2014/08/Superintelligence-Readers-Guide-early-version.pdf\">reading guide</a>:&nbsp;<em><strong>Life in an algorithmic economy</strong></em>. This corresponds to the middle of Chapter 11.</p>\n<p>This post summarizes the section, and offers a few relevant notes, and ideas for further investigation. Some of my own thoughts and questions for discussion are in the comments.</p>\n<p>There is no need to proceed in order through this post, or to look at everything. Feel free to jump straight to the discussion. Where applicable and I remember, page numbers indicate the rough part of the chapter that is most related (not necessarily that the chapter is being cited for the specific claim).</p>\n<p><strong>Reading</strong>: \u201cLife in an algorithmic economy\u201d from Chapter 11</p>\n<hr>\n<h1 id=\"Summary\">Summary</h1>\n<ol>\n<li>In a multipolar scenario, <strong>biological humans&nbsp;might lead poor and meager lives.</strong> (p166-7)</li>\n<li>The <strong>AIs might be worthy of moral consideration</strong>, and if so their wellbeing might be more important than that of the relatively few humans. (p167)</li>\n<li><strong>AI minds might be much like slaves</strong>, even if they are not literally. They may be selected for liking this. (p167)</li>\n<li>Because brain emulations would be very cheap to copy, <strong>it will often be convenient to make a copy and then later turn it off</strong> (in a sense killing a person). (p168)</li>\n<li>There are various other reasons that very short lives might be optimal for some applications. (p168-9)</li>\n<li><strong>It isn't obvious whether brain emulations would be happy</strong> working all of the time. Some relevant considerations are current human emotions in general and regarding work, probable selection for pro-work individuals, evolutionary adaptiveness of happiness in the past and future -- e.g. does happiness help you work harder?--and absence of present sources of unhappiness such as injury. (p169-171)</li>\n<li><strong>In the long run, artificial minds may not even be conscious, or have valuable experiences</strong>, if these are not the most effective ways for them to earn wages. If such minds replace humans, <strong>Earth might have an advanced civilization with nobody there to benefit</strong>. (p172-3)</li>\n<li>In the long run, <strong>artificial minds may outsource many parts of their thinking</strong>, thus becoming decreasingly differentiated as individuals. (p172)</li>\n<li><strong>Evolution does not imply positive progress.</strong>&nbsp;Even those good things that evolved in the past may not withstand evolutionary selection in a new circumstance. (p174-6)</li>\n</ol>\n<h1 id=\"Another_view\">Another view</h1>\n<p><a href=\"http://www.overcomingbias.com/2013/03/on-disowning-descendants.html#sthash.uP5O5usO.dpuf\">Robin Hanson</a> on others' hasty distaste for a future of emulations:&nbsp;</p>\n<blockquote>\n<p>Parents sometimes disown their children, on the grounds that those children have betrayed key parental values. And if parents have the sort of values that kids could deeply betray, then it does make sense for parents to watch out for such betrayal, ready to go to extremes like disowning in response.</p>\n<p>But surely parents who feel inclined to disown their kids should be encouraged to study their kids carefully before making such a choice. For example, parents considering whether to disown their child for refusing to fight a war for their nation, or for working for a cigarette manufacturer, should wonder to what extend national patriotism or anti-smoking really are core values, as opposed to being mere revisable opinions they collected at one point in support of other more-core values. Such parents would be wise to study the lives and opinions of their children in some detail before choosing to disown them.</p>\n<p>I\u2019d like people to think similarly about my attempts to analyze likely futures. The lives of our descendants in the next great era after this our industry era may be as different from ours\u2019 as ours\u2019 are from farmers\u2019, or farmers\u2019 are from foragers\u2019. When they have lived as neighbors, foragers have often strongly criticized farmer culture, as farmers have often strongly criticized industry culture. Surely many have been tempted to disown any descendants who adopted such despised new ways. And while such disowning might hold them true to core values, if asked we would advise them to consider the lives and views of such descendants carefully, in some detail, before choosing to disown.</p>\n<p>Similarly, many who live industry era lives and share industry era values, may be disturbed to see forecasts of descendants with life styles that appear to reject many values they hold dear. Such people may be tempted to reject such outcomes, and to fight to prevent them, perhaps preferring a continuation of our industry era to the arrival of such a very different era, even if that era would contain far more creatures who consider their lives worth living, and be far better able to prevent the extinction of Earth civilization. And such people may be correct that such a rejection and battle holds them true to their core values.</p>\n<p>But I advise such people to first try hard to see this new era in some detail from the point of view of its typical residents. See what they enjoy and what fills them with pride, and listen to their criticisms of your era and values. I hope that my future analysis can assist such soul-searching examination. If after studying such detail, you still feel compelled to disown your likely descendants, I cannot confidently say you are wrong. My job, first and foremost, is to help you see them clearly.</p>\n</blockquote>\n<p>More on whose lives are worth living&nbsp;<a href=\"http://www.overcomingbias.com/2012/04/jiro-lives-worth-living.html\">here</a> and <a href=\"http://www.overcomingbias.com/2011/04/are-workaholics-human.html\">here</a>.</p>\n<h1 id=\"Notes\">Notes</h1>\n<p>1. Robin Hanson is probably the foremost researcher on what the finer details of an economy of&nbsp;<a href=\"http://en.wikipedia.org/wiki/Mind_uploading\">emulated human minds</a>&nbsp;would be like. For instance, which company employees would run how fast, how big cities would be, whether people would hang out with their copies. See a&nbsp;<a href=\"https://www.youtube.com/watch?v=9qcIsjrHENU\">TEDx talk</a>, and writings&nbsp;<a href=\"http://hanson.gmu.edu/IEEESpectrum-6-08.pdf\">here</a>,&nbsp;<a href=\"http://hanson.gmu.edu/Futurist.pdf\">here</a>,&nbsp;<a href=\"http://hanson.gmu.edu/IntelligenceUnbound.pdf\">here</a>&nbsp;and&nbsp;<a href=\"http://www.overcomingbias.com/tag/ems\">here</a>&nbsp;(some overlap - sorry). He is also writing a book on the subject, which you can&nbsp;<a href=\"http://www.overcomingbias.com/2013/09/wanted-know-it-some-critics.html\">read</a>&nbsp;early if you ask him.&nbsp;</p>\n<p>2. Bostrom says,</p>\n<blockquote>\n<p>Life for biological humans in a post-transition Malthusian state need not resemble any of the historical states of man...the majority of humans in this scenario might be idle rentiers who eke out a marginal living on their savings. They would be very poor, yet derive what little income they have from savings or state subsidies. They would live in a world with &nbsp;extremely advanced technology, including not only superintelligent machines but also anti-aging medicine, virtual reality, and various enhancement technologies and pleasure drugs: yet these might be generally unaffordable....(p166)</p>\n</blockquote>\n<p>It's true this might happen, but it doesn't seem like an especially likely scenario to me. As Bostrom has pointed out in various places earlier, biological humans would do quite well if they have some investments in capital, do not have too much of their property stolen or artfully manouvered away from them, and do not undergo too massive population growth themselves. These risks don't seem so large to me.</p>\n<div>3. Paul Christiano has an <a href=\"http://rationalaltruist.com/2014/05/14/machine-intelligence-and-capital-accumulation/\">interesting article</a> on capital accumulation in a world of machine intelligence.</div>\n<div><br></div>\n<div>4. In discussing worlds of brain emulations, we often talk about selecting people for having various characteristics - for instance, being extremely productive, hard-working, not minding frequent 'death', being willing to work for free and donate any proceeds to their employer (p167-8). However there are only so many humans to select from, so we can't necessarily select for all the characteristics we might want. Bostrom also talks of using other motivation selection methods, and modifying code, but it is interesting to ask how far you could get using only selection. It is not obvious to what extent one could meaningfully modify brain emulation code initially.&nbsp;</div>\n<div><br></div>\n<div>I'd guess less than one in a thousand people would be willing to donate everything to their employer, given a random employer. This means to get this characteristic, you would have to lose a factor of 1000 on selecting for other traits. All together you have about 33 bits of selection power in the present world (that is, 7 billion is about 2^33; you can divide the world in half about 33 times before you get to a single person). Lets suppose you use 5 bits in getting someone who both doesn't mind their copies dying (I guess 1 bit, or half of people) and who is willing to work an 80h/week (I guess 4 bits, or one in sixteen people). Lets suppose you are using the rest of your selection (28 bits) on intelligence, for the sake of argument. You are getting a person of IQ <a href=\"http://www.iqcomparisonsite.com/iqtable.aspx\">186</a>. If instead you use 10 bits (2^10 = ~1000) on getting someone to donate all their money to their employer, you can only use 18 bits on intelligence, getting a person of IQ <a href=\"http://www.iqcomparisonsite.com/iqtable.aspx\">167</a>. Would it not often be better to have the worker who is twenty IQ points smarter and pay them above subsistance?</div>\n<div><br></div>\n<div>5. A variety of valuable uses for cheap to copy, short-lived brain emulations are discussed in&nbsp;<a href=\"http://intelligence.org/files/WBE-Superorgs.pdf\">Whole brain emulation and the evolution of superorganisms</a>, <a href=\"/lw/hfd/the_impact_of_whole_brain_emulation/\">LessWrong discussion on the impact of whole brain emulation</a>, and Robin's work cited above.</div>\n<div><br></div>\n<div>6. Anders Sandberg <a href=\"http://www.aleph.se/papers/Ethics%20of%20brain%20emulations%20draft.pdf\">writes about</a> moral implications of emulations of animals and humans.</div>\n<div><br></div>\n<h1 id=\"In_depth_investigations\">In-depth investigations</h1>\n<p>If you are particularly interested in these topics, and want to do further research, these are a few plausible directions, some inspired by Luke Muehlhauser's&nbsp;<a href=\"http://lukemuehlhauser.com/some-studies-which-could-improve-our-strategic-picture-of-superintelligence/\">list</a>, which contains many suggestions related to parts of&nbsp;<em>Superintelligence.&nbsp;</em>These projects could be attempted at various levels of depth.</p>\n<ol>\n<li>Is the first functional whole brain emulation likely to be (1) an emulation of low-level functionality that doesn\u2019t require much understanding of human cognitive neuroscience at the computational level, as described in <a href=\"http://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf\">Sandberg &amp; Bostrom (2008)</a>, or is it more likely to be (2) an emulation that makes heavy use of advanced human cognitive neuroscience, as described by (e.g.) <a href=\"https://intelligence.org/2014/09/09/hayworth/\">Ken Hayworth</a>, or is it likely to be (3) something else?</li>\n<li>Extend and update our understanding of when brain emulations might appear (see&nbsp;<a href=\"http://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf\">Sandberg &amp; Bostrom (2008)</a>).</li>\n<li>Investigate the likelihood of a multipolar outcome?</li>\n<li>Follow Robin Hanson (see above) in working out the social implications of an emulation scenario</li>\n<li>What kinds of responses to the default low-regulation multipolar outcome outlined in this section are likely to be made? e.g. is any strong regulation likely to emerge that avoids the features detailed in the current section?</li>\n<li>What measures are useful for ensuring good multipolar outcomes?</li>\n<li>What qualitatively different kinds of multipolar outcomes might we expect? e.g. brain emulation outcomes are one class.</li>\n</ol>\n<div>If you are interested in anything like this, you might want to mention it in the comments, and see whether other people have useful thoughts.</div>\n<h1 id=\"How_to_proceed\">How to proceed</h1>\n<p>This has been a collection of notes on the chapter.&nbsp;&nbsp;<strong>The most important part of the reading group though is discussion</strong>, which is in the comments section. I pose some questions for you there, and I invite you to add your own. Please remember that this group contains a variety of levels of expertise: if a line of discussion seems too basic or too incomprehensible, look around for one that suits you better!</p>\n<p>Next week, we will talk about the possibility of a multipolar outcome turning into a singleton later. To prepare,&nbsp;<strong>read</strong>&nbsp;\u201cPost-transition formation of a singleton?\u201d from Chapter 11<em>.&nbsp;</em>The discussion will go live at 6pm Pacific time next Monday 19 January. Sign up to be notified&nbsp;<a href=\"http://intelligence.us5.list-manage.com/subscribe?u=353906382677fa789a483ba9e&amp;id=28cb982f40\">here</a>.</p>", "sections": [{"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Another view", "anchor": "Another_view", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "In-depth investigations", "anchor": "In_depth_investigations", "level": 1}, {"title": "How to proceed", "anchor": "How_to_proceed", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "52 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QDmzDZ9CEHrKQdvcn", "3AXpysm7emgWQ2BKe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T05:23:39.024Z", "modifiedAt": null, "url": null, "title": "LW-ish meetup in Boulder, CO", "slug": "lw-ish-meetup-in-boulder-co", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fowlertm", "createdAt": "2012-01-07T20:35:26.490Z", "isAdmin": false, "displayName": "fowlertm"}, "userId": "gDAt4FezxH8dDr5EY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gNFsaB59cBWaGt4aG/lw-ish-meetup-in-boulder-co", "pageUrlRelative": "/posts/gNFsaB59cBWaGt4aG/lw-ish-meetup-in-boulder-co", "linkUrl": "https://www.lesswrong.com/posts/gNFsaB59cBWaGt4aG/lw-ish-meetup-in-boulder-co", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW-ish%20meetup%20in%20Boulder%2C%20CO&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW-ish%20meetup%20in%20Boulder%2C%20CO%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgNFsaB59cBWaGt4aG%2Flw-ish-meetup-in-boulder-co%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW-ish%20meetup%20in%20Boulder%2C%20CO%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgNFsaB59cBWaGt4aG%2Flw-ish-meetup-in-boulder-co", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgNFsaB59cBWaGt4aG%2Flw-ish-meetup-in-boulder-co", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 46, "htmlBody": "<p>This Saturday I'm giving a presentation at the Boulder Future Salon, topic will be non-religious spirituality. The more LWians that can make it the better, because I'm really trying to get some community building done in the Boulder/Denver area. There's an insane amount of potential here.</p>\n<p><a href=\"http://www.meetup.com/future-51/events/219787671/\">Details</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gNFsaB59cBWaGt4aG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 2.366468106842611e-06, "legacy": true, "legacyId": "27907", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T09:38:26.332Z", "modifiedAt": null, "url": null, "title": "Meetup : MelbLW: January Social Meetup", "slug": "meetup-melblw-january-social-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MelbourneLW", "createdAt": "2014-07-15T07:42:47.692Z", "isAdmin": false, "displayName": "MelbourneLW"}, "userId": "fnAEhR2GNN3t6PmFc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YZ4nkCmwtuHjN5nzg/meetup-melblw-january-social-meetup", "pageUrlRelative": "/posts/YZ4nkCmwtuHjN5nzg/meetup-melblw-january-social-meetup", "linkUrl": "https://www.lesswrong.com/posts/YZ4nkCmwtuHjN5nzg/meetup-melblw-january-social-meetup", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20MelbLW%3A%20January%20Social%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20MelbLW%3A%20January%20Social%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYZ4nkCmwtuHjN5nzg%2Fmeetup-melblw-january-social-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20MelbLW%3A%20January%20Social%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYZ4nkCmwtuHjN5nzg%2Fmeetup-melblw-january-social-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYZ4nkCmwtuHjN5nzg%2Fmeetup-melblw-january-social-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18u'>MelbLW: January Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 January 2015 06:30:00PM (+0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">The Bull & Bear Tavern, 347 Flinders Lane, Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>January's social meetup is scheduled for this Friday (16th January) at 6:30pm as usual. This month, we will be returning to the Bull &amp; Bear Tavern on Flinders Lane.</p>\n\n<p>Our social meetups are relaxed, informal events where we chat and often play games. The start and finish times are very loose - people will be coming and going throughout the night, so don't worry if you are coming later or have to leave early.</p>\n\n<p><strong>Where?</strong>  The Bull &amp; Bear Tavern, 347 Flinders Lane, Melbourne (on Flinders Lane between Queen and Elizabeth)</p>\n\n<p><strong>When?</strong>  From 6:30pm until late, Friday January 16th.</p>\n\n<p><strong>Contact?</strong>  If you have any questions, just text or call Richard on 0421231789</p>\n\n<p><strong>Dinner?</strong>  The Bull &amp; Bear serve typical pub food until 9pm. Some of us will most likely go for our traditional post-meetup souvlakis at Stalactites, some time around 11-12.</p>\n\n<p><strong>Games?</strong>  We will have our own section of the Bull &amp; Bear with tables and chairs, and can bring board games to play. If you'd like to play something, bring it along and you should be able to rustle up a group easily.</p>\n\n<p>To organise similar events, please send an email to melbournelw@gmail.com</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18u'>MelbLW: January Social Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YZ4nkCmwtuHjN5nzg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3670826570116703e-06, "legacy": true, "legacyId": "27908", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___MelbLW__January_Social_Meetup\">Discussion article for the meetup : <a href=\"/meetups/18u\">MelbLW: January Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 January 2015 06:30:00PM (+0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">The Bull &amp; Bear Tavern, 347 Flinders Lane, Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>January's social meetup is scheduled for this Friday (16th January) at 6:30pm as usual. This month, we will be returning to the Bull &amp; Bear Tavern on Flinders Lane.</p>\n\n<p>Our social meetups are relaxed, informal events where we chat and often play games. The start and finish times are very loose - people will be coming and going throughout the night, so don't worry if you are coming later or have to leave early.</p>\n\n<p><strong>Where?</strong>  The Bull &amp; Bear Tavern, 347 Flinders Lane, Melbourne (on Flinders Lane between Queen and Elizabeth)</p>\n\n<p><strong>When?</strong>  From 6:30pm until late, Friday January 16th.</p>\n\n<p><strong>Contact?</strong>  If you have any questions, just text or call Richard on 0421231789</p>\n\n<p><strong>Dinner?</strong>  The Bull &amp; Bear serve typical pub food until 9pm. Some of us will most likely go for our traditional post-meetup souvlakis at Stalactites, some time around 11-12.</p>\n\n<p><strong>Games?</strong>  We will have our own section of the Bull &amp; Bear with tables and chairs, and can bring board games to play. If you'd like to play something, bring it along and you should be able to rustle up a group easily.</p>\n\n<p>To organise similar events, please send an email to melbournelw@gmail.com</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___MelbLW__January_Social_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/18u\">MelbLW: January Social Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : MelbLW: January Social Meetup", "anchor": "Discussion_article_for_the_meetup___MelbLW__January_Social_Meetup", "level": 1}, {"title": "Discussion article for the meetup : MelbLW: January Social Meetup", "anchor": "Discussion_article_for_the_meetup___MelbLW__January_Social_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T13:35:19.718Z", "modifiedAt": null, "url": null, "title": "'Dumb' AI observes and manipulates controllers", "slug": "dumb-ai-observes-and-manipulates-controllers", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:38.208Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X3j7HMeQshr8Sz9hc/dumb-ai-observes-and-manipulates-controllers", "pageUrlRelative": "/posts/X3j7HMeQshr8Sz9hc/dumb-ai-observes-and-manipulates-controllers", "linkUrl": "https://www.lesswrong.com/posts/X3j7HMeQshr8Sz9hc/dumb-ai-observes-and-manipulates-controllers", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20'Dumb'%20AI%20observes%20and%20manipulates%20controllers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A'Dumb'%20AI%20observes%20and%20manipulates%20controllers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX3j7HMeQshr8Sz9hc%2Fdumb-ai-observes-and-manipulates-controllers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text='Dumb'%20AI%20observes%20and%20manipulates%20controllers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX3j7HMeQshr8Sz9hc%2Fdumb-ai-observes-and-manipulates-controllers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX3j7HMeQshr8Sz9hc%2Fdumb-ai-observes-and-manipulates-controllers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 492, "htmlBody": "<p>The argument that AIs provided with a reward channel will observe their controllers and learn to manipulate them is a valid one. Unfortunately, it's often framed in a way that feels counterintuitive or extreme, especially to AI designers. It typically starts with the standard reinforcement learning scenario, then posits that the AI becomes superintelligent and either manipulates the controller with super-social powers, or breaks out and gains control of its reward channel, killing or threatening its controllers.</p>\n<p>And that is a fair argument. But conceptually, it leaps from a standard reinforcement learning scenario, to a science-fiction-sounding scenario. It might help to have intermediate scenarios: to show that even lower intelligence AIs might start exhibiting the same sort of behaviour, long before it gets to superintelligence.</p>\n<p>So consider the following scenario. Some complex, trainable AI is tasked with writing <a href=\"http://metro.co.uk/2014/07/10/meet-the-robots-writing-your-news-articles-the-rise-of-automated-journalism-4792284/\">automated news stories</a>&nbsp;for a student newspaper. It trawls the web and composes its stories, then gets reward and feedback from the editors. Assume there are two editors for this newspaper, and they work on alternate days. The two editors have somewhat different ideas as to what constitutes a good story, so their feedbacks are different. After a while, the AI finds that it gets higher reward by using a certain style on Monday, Wednesday and Friday, and another style on Tuesday and Thursdays - this is a simple consequence of its reward mechanism.</p>\n<p>But the rota isn't perfect. Sometime the Monday editor will edit a story so late on Monday that it's Tuesday, and sometimes the Tuesday editor will be up early and edit a story at the same time. This pattern is more common during the holidays, when the editors go to different time zones, often travel, and become more irregular in their editing.</p>\n<p>So if the AI complex and skilled enough, then, simply through simple feedback, it will start building up a picture of its editors. It will figure out when they are likely to stick to a schedule, and when they will be more irregular. It will figure out the difference between holidays and non-holidays. Given time, it may be able to track the editors moods and it will certainly pick up on any major change in their lives - such as romantic relationships and breakups, which will radically change whether and how it should present stories with a romantic focus.</p>\n<p>It will also likely learn the correlation between stories and feedbacks - maybe presenting a story define roughly as \"positive\" will increase subsequent reward for the rest of the day, on all stories. Or maybe this will only work on a certain editor, or only early in the term. Or only before lunch.</p>\n<p>Thus the simple trainable AI with a particular focus - write automated news stories - will be trained, through feedback, to learn about its editors/controllers, to distinguish them, to get to know them, and, in effect, to manipulate them.</p>\n<p>This may be a useful \"bridging example\" between standard RL agents and the superintelligent machines.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZFrgTgzwEfStg26JL": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X3j7HMeQshr8Sz9hc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 52, "extendedScore": null, "score": 6.731119892951443e-05, "legacy": true, "legacyId": "27909", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T15:55:44.577Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels February meetup: Words", "slug": "meetup-brussels-february-meetup-words", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Roxolan", "createdAt": "2011-10-23T19:06:17.298Z", "isAdmin": false, "displayName": "Roxolan"}, "userId": "jXG7tMhkQMNpCCXPN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M7pKL4cs6hn9sMCYD/meetup-brussels-february-meetup-words", "pageUrlRelative": "/posts/M7pKL4cs6hn9sMCYD/meetup-brussels-february-meetup-words", "linkUrl": "https://www.lesswrong.com/posts/M7pKL4cs6hn9sMCYD/meetup-brussels-february-meetup-words", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20February%20meetup%3A%20Words&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20February%20meetup%3A%20Words%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM7pKL4cs6hn9sMCYD%2Fmeetup-brussels-february-meetup-words%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20February%20meetup%3A%20Words%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM7pKL4cs6hn9sMCYD%2Fmeetup-brussels-february-meetup-words", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM7pKL4cs6hn9sMCYD%2Fmeetup-brussels-february-meetup-words", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 278, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18v'>Brussels February meetup: Words</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">14 February 2015 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This February, we will talk about the way we talk.</p>\n\n<p>Yudkowsky has written quite a lot on that topic in the early days of LessWrong, collected into the sequence <a href=\"http://wiki.lesswrong.com/wiki/A_Human%27s_Guide_to_Words\">A human&#39;s guide to words</a> (also available as a 5$ <a href=\"http://castify.co/channels/16-less-wrong-a-human-s-guide-to-words\" rel=\"nofollow\">podcast</a>). My personal favourite is the more practical <a href=\"http://lesswrong.com/lw/nu/taboo_your_words\">Taboo Your Words</a>. I have, on many occasions, attempted to resolve an apparent conflict by asking someone to replace a word with its definition and <em>it never works because not enough people have read the damn article and the <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">inferential distance</a> is too damn big</em>.</p>\n\n<p><em>notices anger, snaps fingers</em></p>\n\n<p>tugce also suggested the movie <a href=\"http://www.rottentomatoes.com/m/is_the_man_who_is_tall_happy_an_animated_conversation_with_noam_chomsky/\" rel=\"nofollow\">Is the Man Who Is Tall Happy?</a>, an animated conversation between Michel Gondry and Noam Chomsky. I have to admit I know almost nothing of Chomsky. If anyone can recommend a good starting point, by next month I will feel very guilty about not having read it.</p>\n\n<p>This meetup marks the third-year anniversary of LessWrong Brussels. There will be an item of soft sweet food made from a mixture of flour, fat, eggs, sugar, and other ingredients, baked and possibly iced or decorated.</p>\n\n<hr />\n\n<p>We will meet at 1 pm at \"La Fleur en papier dor\u00e9, close to the Brussels Central station. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform\" rel=\"nofollow\">this one minute form</a> to share your contact information.</p>\n\n<p>The Brussels meetup group communicates through a <a href=\"https://groups.google.com/forum/#!forum/lesswrong-brussels\">Google Group</a>.</p>\n\n<p>Meetup announcements are also mirrored on <a href=\"http://www.meetup.com/LWBrussels/\" rel=\"nofollow\">meetup.com</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18v'>Brussels February meetup: Words</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M7pKL4cs6hn9sMCYD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3679932338494562e-06, "legacy": true, "legacyId": "27910", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels_February_meetup__Words\">Discussion article for the meetup : <a href=\"/meetups/18v\">Brussels February meetup: Words</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">14 February 2015 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This February, we will talk about the way we talk.</p>\n\n<p>Yudkowsky has written quite a lot on that topic in the early days of LessWrong, collected into the sequence <a href=\"http://wiki.lesswrong.com/wiki/A_Human%27s_Guide_to_Words\">A human's guide to words</a> (also available as a 5$ <a href=\"http://castify.co/channels/16-less-wrong-a-human-s-guide-to-words\" rel=\"nofollow\">podcast</a>). My personal favourite is the more practical <a href=\"http://lesswrong.com/lw/nu/taboo_your_words\">Taboo Your Words</a>. I have, on many occasions, attempted to resolve an apparent conflict by asking someone to replace a word with its definition and <em>it never works because not enough people have read the damn article and the <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">inferential distance</a> is too damn big</em>.</p>\n\n<p><em>notices anger, snaps fingers</em></p>\n\n<p>tugce also suggested the movie <a href=\"http://www.rottentomatoes.com/m/is_the_man_who_is_tall_happy_an_animated_conversation_with_noam_chomsky/\" rel=\"nofollow\">Is the Man Who Is Tall Happy?</a>, an animated conversation between Michel Gondry and Noam Chomsky. I have to admit I know almost nothing of Chomsky. If anyone can recommend a good starting point, by next month I will feel very guilty about not having read it.</p>\n\n<p>This meetup marks the third-year anniversary of LessWrong Brussels. There will be an item of soft sweet food made from a mixture of flour, fat, eggs, sugar, and other ingredients, baked and possibly iced or decorated.</p>\n\n<hr>\n\n<p>We will meet at 1 pm at \"La Fleur en papier dor\u00e9, close to the Brussels Central station. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform\" rel=\"nofollow\">this one minute form</a> to share your contact information.</p>\n\n<p>The Brussels meetup group communicates through a <a href=\"https://groups.google.com/forum/#!forum/lesswrong-brussels\">Google Group</a>.</p>\n\n<p>Meetup announcements are also mirrored on <a href=\"http://www.meetup.com/LWBrussels/\" rel=\"nofollow\">meetup.com</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels_February_meetup__Words1\">Discussion article for the meetup : <a href=\"/meetups/18v\">Brussels February meetup: Words</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels February meetup: Words", "anchor": "Discussion_article_for_the_meetup___Brussels_February_meetup__Words", "level": 1}, {"title": "Discussion article for the meetup : Brussels February meetup: Words", "anchor": "Discussion_article_for_the_meetup___Brussels_February_meetup__Words1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WBdvyyHLdxZSAMmoz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T17:19:27.909Z", "modifiedAt": null, "url": null, "title": "Less exploitable value-updating agent", "slug": "less-exploitable-value-updating-agent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.276Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pc62o5ihd9hTiWAry/less-exploitable-value-updating-agent", "pageUrlRelative": "/posts/pc62o5ihd9hTiWAry/less-exploitable-value-updating-agent", "linkUrl": "https://www.lesswrong.com/posts/pc62o5ihd9hTiWAry/less-exploitable-value-updating-agent", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20exploitable%20value-updating%20agent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20exploitable%20value-updating%20agent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpc62o5ihd9hTiWAry%2Fless-exploitable-value-updating-agent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20exploitable%20value-updating%20agent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpc62o5ihd9hTiWAry%2Fless-exploitable-value-updating-agent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpc62o5ihd9hTiWAry%2Fless-exploitable-value-updating-agent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 640, "htmlBody": "<p>My <a href=\"/lw/jxa/proper_value_learning_through_indifference/\">indifferent value learning agent design</a> is in some ways too good. The agent transfer perfectly from u maximisers to v maximisers - but this makes them exploitable, as Benja has pointed out.</p>\n<p>For instance, if u values paperclips and v values staples, and everyone knows that the agent will soon transfer from a u-maximiser to a v-maximiser, then an enterprising trader can sell the agent paperclips in exchange for staples, then wait for the utility change, and sell the agent back staples for paperclips, pocketing a profit each time. More prosaically, they could \"borrow\" &pound;1,000,000 from the agent, promising to pay back &pound;2,000,000 tomorrow <em>if the agent is still a u-maximiser</em>. And the currently u-maximising agent will accept, even though everyone knows it will change to a v-maximiser before tomorrow.</p>\n<p>One could argue that exploitability is inevitable, given the change in utility functions. And I haven't yet found any principled way of avoiding exploitability which preserves the indifference. But here is a tantalising quasi-example.</p>\n<p>As before, u values paperclips and v values staples. Both are defined in terms of extra paperclips/staples over those existing in the world (and negatively in terms of destruction of existing/staples), with their zero being at the current situation. Let's put some diminishing returns on both utilities: for each paperclips/stables created/destroyed up to the first five, u/v will gain/lose one utilon. For each subsequent paperclip/staple destroyed above five, they will gain/lose one half utilon.</p>\n<p>We now construct our world and our agent. The world lasts two days, and has a machine that can create or destroy paperclips and staples for the cost of &pound;1 apiece. Assume there is a tiny&nbsp;&epsilon; chance that the machine stops working at any given time. This &epsilon; will be ignored in all calculations; it's there only to make the agent act sooner rather than later when the choices are equivalent (a discount rate could serve the same purpose).</p>\n<p>The agent owns &pound;10 and has utility function u+Xv. The value of X is unknown to the agent: it is either +1 or -1, with 50% probability, and this will be revealed at the end of the first day (you can imagine X is the output of some slow computation, or is written on the underside of a rock that will be lifted).</p>\n<p>So what will the agent do? It's easy to see that it can never get more than 10 utilons, as each &pound;1 generates at most 1 utilon (we really need a unit symbol for the utilon!). And it can achieve this: it will spend &pound;5 immediately, creating 5 paperclips, wait until X is revealed, and spend another &pound;5 creating or destroying staples (depending on the value of X).</p>\n<p>This looks a lot like a resource-conserving value-learning agent. I doesn't seem to be \"exploitable\" in the sense Benja demonstrated. It will still accept some odd deals - one extra paperclip on the first day in exchange for all the staples in the world being destroyed, for instance. But it won't give away resources for no advantage. And it's not a perfect value-learning agent. But it still seems to have interesting features of non-exploitable and value-learning that are worth exploring.</p>\n<p>Note that this property does not depend on v being symmetric around staple creation and destruction. Assume v hits diminishing returns after creating 5 staples, but after destroying only 4 of them. Then the agent will have the same behaviour as above (in that specific situation; in general, this will cause a slight change, in that the agent will slightly overvalue having money on the first day compared to the original v), and will expect to get 9.75 utilons (50% chance of 10 for X=+1, 50% chance of 9.5 for X=-1). Other changes to u and v will shift how much money is spent on different days, but the symmetry of v is not what is powering this example.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pc62o5ihd9hTiWAry", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 2.3681953710110867e-06, "legacy": true, "legacyId": "27911", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["btLPgsGzwzDk9DgJG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T20:02:20.732Z", "modifiedAt": "2020-02-14T02:21:22.062Z", "url": null, "title": "Why you should consider buying Bitcoin right now (Jan 2015) if you have high risk tolerance", "slug": "why-you-should-consider-buying-bitcoin-right-now-jan-2015-if", "viewCount": null, "lastCommentedAt": "2021-04-12T20:49:09.575Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ander", "createdAt": "2013-11-25T22:31:01.872Z", "isAdmin": false, "displayName": "Ander"}, "userId": "TAWyrYP37Zvbiok2Y", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tsoAwbDZ54GXtfcjh/why-you-should-consider-buying-bitcoin-right-now-jan-2015-if", "pageUrlRelative": "/posts/tsoAwbDZ54GXtfcjh/why-you-should-consider-buying-bitcoin-right-now-jan-2015-if", "linkUrl": "https://www.lesswrong.com/posts/tsoAwbDZ54GXtfcjh/why-you-should-consider-buying-bitcoin-right-now-jan-2015-if", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20you%20should%20consider%20buying%20Bitcoin%20right%20now%20(Jan%202015)%20if%20you%20have%20high%20risk%20tolerance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20you%20should%20consider%20buying%20Bitcoin%20right%20now%20(Jan%202015)%20if%20you%20have%20high%20risk%20tolerance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtsoAwbDZ54GXtfcjh%2Fwhy-you-should-consider-buying-bitcoin-right-now-jan-2015-if%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20you%20should%20consider%20buying%20Bitcoin%20right%20now%20(Jan%202015)%20if%20you%20have%20high%20risk%20tolerance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtsoAwbDZ54GXtfcjh%2Fwhy-you-should-consider-buying-bitcoin-right-now-jan-2015-if", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtsoAwbDZ54GXtfcjh%2Fwhy-you-should-consider-buying-bitcoin-right-now-jan-2015-if", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2405, "htmlBody": "<p>LessWrong is where I learned about Bitcoin, several years ago, and my greatest regret is that I did not investigate it more as soon as possible, that people here did not yell at me louder that it was important, and to go take a look at it.&nbsp; In that spirit, I will do so now.</p>\n<p>&nbsp;</p>\n<p>First of all, several caveats:</p>\n<p>* You should not go blindly buying anything that you do not understand.&nbsp; If you don't know about Bitcoin, you should start by reading about its history, read Satoshi's whitepaper, etc.&nbsp; I will assume that hte rest of the readers who continue reading this have a decent idea of what Bitcoin is.</p>\n<p>* Under absolutely no circumstances should you invest money into Bitcoin that you cannot afford to lose.&nbsp; \"Risk money\" only!&nbsp; That means that if you were to lose 100% of you money, it would not particularly damage your life.&nbsp; Do not spend money that you will need within the next several years, or ever.&nbsp; You might in fact want to mentally write off the entire thing as a 100% loss from the start, if that helps.</p>\n<p>* Even more strongly, under absolutely no circumstances whatsoever will you borrow money in order to buy Bitcoins, such as using margin, credit card loans, using your student loan, etc.&nbsp; This is very much similar to taking out a loan, going to a casino and betting it all on black on the roulette wheel.&nbsp; You would either get very lucky or potentially ruin your life.&nbsp; Its not worth it, this is reality, and there are no laws of the universe preventing you from losing.</p>\n<p>* This post is not \"investment advice\".</p>\n<p>* I own Bitcoins, which makes me biased.&nbsp; You should update to reflect that I am going to present a pro-Bitcoin case.</p>\n<p>&nbsp;</p>\n<p>So why is this potentially a time to buy Bitcoins?&nbsp; One could think of markets like a pendulum, where price swings from one extreme to another over time, with a very high price corresponding to over-enthusiasm, and a very low price corresponding to despair.&nbsp; As Warren Buffett said, Mr. Market is like a manic depressive.&nbsp; One day he walks into your office and is exuberant, and offers to buy your stocks at a high price.&nbsp; Another day he is depressed and will sell them for a fraction of that.&nbsp;</p>\n<p>The root cause of this phenomenon is confirmation bias.&nbsp; When things are going well, and the fundamentals of a stock or commodity are strong, the price is driven up, and this results in a positive feedback loop.&nbsp; Investors receive confirmation of their belief that things are going good from the price increase, confirming their bias.&nbsp; The process repeats and builds upon itself during a bull market, until it reaches a point of euphoria, in which bad news is completely ignored or disbelieved in.</p>\n<p>The same process happens in reverse during a price decline, or bear market.&nbsp; Investors receive the feedback that the price is going down =&gt; things are bad, and good news is ignored and disbelieved.&nbsp; Both of these processes run away for a while until they reach enough of an extreme that the \"smart money\" (most well informed and intelligent agents in the system) realizes that the process has gone too far and switches sides.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Bitcoin at this point is certainly somewhere in the despair side of the pendulum.&nbsp; I don't want to imply in any way that it is not possible for it to go lower.&nbsp; Picking a bottom is probably the most difficult thing to do in markets, especially before it happens, and everyone who has claimed that Bitcoin was at a bottom for the past year has been repeatedly proven wrong.&nbsp; (In fact, I feel a tremendous amount of fear in sticking my neck out to create this post, well aware that I could look like a complete idiot weeks or months or years from now and utterly destroy my reputation, yet I will continue anyway).</p>\n<p>&nbsp;</p>\n<p>First of all, lets look at the fundamentals of Bitcoin.&nbsp; On one hand, things are going well.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Use of Bitcoin (network effect):</p>\n<p>One measurement of Bitcoin's value is the strenght of its network effect.&nbsp; By Metcalfe's law, the value of a network is proporitonal to the square of the number of nodes in the network.&nbsp;</p>\n<p>http://en.wikipedia.org/wiki/Metcalfe%27s_law</p>\n<p>Over the long term, Bitcoin's price has generally followed this law (though with wild swings to both the upside and downside as the pendulum swings).&nbsp;</p>\n<p>In terms of network effect, Bitcoin is doing well.</p>\n<p>&nbsp;</p>\n<p>Bitcoin transactions are hitting all time highs:&nbsp; (28 day average of number of transactions).</p>\n<p>https://blockchain.info/charts/n-transactions-excluding-popular?timespan=2year&amp;showDataPoints=false&amp;daysAverageString=28&amp;show_header=true&amp;scale=0&amp;address=</p>\n<p>&nbsp;</p>\n<p>Number of Bitcoin addresses are hitting all time highs:</p>\n<p>https://blockchain.info/charts/n-unique-addresses?timespan=2year&amp;showDataPoints=false&amp;daysAverageString=28&amp;show_header=true&amp;scale=0&amp;address=</p>\n<p>&nbsp;</p>\n<p>Merchant adoption continues to hit new highs:</p>\n<p>BitPay/Coinbase continue to report 10% monthly growth in the number of merchants that accept Bitcoin.</p>\n<p>Prominent companies that began accepting Bitcoin in the past year include: Dell, Overstock, Paypal, Microsoft, etc.</p>\n<p>&nbsp;</p>\n<p>On the other hand, due to the sustained price decline, many Btcoin businesses that started up in the past two years with venture capital funding have shut down.&nbsp; This is more of an effect of the price decline than a cause however.&nbsp; In the past month especially there has been a number of bearish news stories, such as Bitpay laying off employees, exchanges Vault of Satoshi and CEX.io deciding to shut down, exchange Bitstamp being hacked and shut down for 3 days, but ultimately is back up without losing customer funds, etc.</p>\n<p>&nbsp;</p>\n<p>The cost to mine a Bitcoin is commonly seen as one indicator of price.&nbsp;&nbsp; Note that the cost to mine a Bitcoin does not directly determine the *value* or usefulness of a Bitcoin.&nbsp;&nbsp; I do not believe in the labor theory of value: http://en.wikipedia.org/wiki/Labor_theory_of_value</p>\n<p>However, there is a stabilizing effect in commodities, in which over time, the price of an item will often converge towards the cost to produce it due to market forces.&nbsp;</p>\n<p>&nbsp;</p>\n<p>If a Bitcoin is being priced at a value much greater than the cost (in mining equipment and electricity) to create it, people will invest in mining equipment.&nbsp; This results in increased 'difficulty' of mining and drives down the amount of Bitcoin that you can create with a particular piece of mining equipment.&nbsp; (The amount of Bitcoins created is a fixed amount per unit of time, and thus the more mining equipment that exists, the less Bitcoin each miner will get).</p>\n<p>If Bitcoin is being priced at a value below the cost to create it, people will stop investing in mining equipment.&nbsp; This may be a signal that the price is getting too low, and could rise.</p>\n<p>&nbsp;</p>\n<p>Historically, the one period of time where Bitcoin was priced significantly below the cost to produce it was in late 2011.&nbsp; It was noted on LessWrong.&nbsp; The price has not currently fallen to quite the same extent as it did back then (which may indicate that it has further to fall), however the current price relative to the mining cost indicates we are very much in the bearish side of the pendulum.</p>\n<p>&nbsp;</p>\n<p>It is difficult to calculate an exact cost to mine a Bitcoin, because this depends on the exact hardware used, your cost of electricity, and a prediction of the future difficulty adjustments that will occur.&nbsp; However, we can make estimates with websites such as http://www.vnbitcoin.org/bitcoincalculator.php</p>\n<p>According to this site, every available Bitcoin miner will never give you back as much money as it cost, factoring in the hardware cost and electricity cost.&nbsp;&nbsp; Upcoming more efficient miners which have not yet released yet are estimated to pay off in about a year, if difficulty grows extremely slowly, and that is for upcoming technology which has not yet even been released.&nbsp;</p>\n<p>&nbsp;</p>\n<p>There are two important breakpoints when discussing Bitcoin mining profitability.&nbsp; The first is the point at which your return is enough that it pays for both the electricity and the hardware.&nbsp; The second is the point at which you make more than your electricity costs, but cannot recover the hardware cost.</p>\n<p>&nbsp;</p>\n<p>For example, lets say Alice pays $1000 on Bitcoin mining equipment.&nbsp; Every day, this mining equipment can return $10 worth of Bitcoin, but it costs $5 of electricity to run.&nbsp; Her gain for the day is $5, and it would take 200 days at this rate before the mining equipment paid for itself.&nbsp; Once she has made the decision to purchase the mining equipment, the money spent on the miner is a sunk cost.&nbsp; The money spent on electricity is not a sunk cost, she continues to have the decision every day of whether or not to run her mining equipment.&nbsp; The optimal decision is to continue to run the miner as long as it returns more than the electricity cost.&nbsp;</p>\n<p>Over time, the payout she will receive from this hardware will decline, as the difficulty of mining Bitcoin increases.&nbsp; Eventually, her payout will decline below the electricity cost, and she should shut the miner down.&nbsp; At this point, if her total gain from running the equipment was higher than the hardware cost, it was a good investment.&nbsp; If it did not recoup its cost, then it was worse than simply spending the money buying Bitcoin on an exchange in the first place.</p>\n<p>&nbsp;</p>\n<p>This process creates a feedback into the market price of Bitcoins.&nbsp; Imagine that Bitcoin investors have two choices, either they can buy Bitcoins (the commodity which has already been produced by others), or they can buy miners, and produce Bitcoins for themself. &nbsp; If the Bitcoin price falls sufficiently that mining equipment will not recover its costs over time, investment money that would have gone into miners instead goes into Bitcoin, helping to support the price.&nbsp; As you can see from mining cost calculators, we have passed this point already.&nbsp; (In fact, we passed it months ago already).</p>\n<p>&nbsp;</p>\n<p>The second breakpoint is when the Bitcoin price falls so low that it falls below the electricity cost of running mining equipment.&nbsp; We have passed this point for many of the less efficient ways to mine.&nbsp; For example, Cointerra recently shut down its cloud mining pool because it was losing money.&nbsp; We have not yet passed this point for more recent and efficient miners, but we are getting fairly close to it. Crossing this point has occurred once in Bitcoin's history, in late 2011 when the price bottomed out near $2, before giving birth to the massive bull run of 2012-2013 in which the price rose by a factor of 500.</p>\n<p>&nbsp;</p>\n<p>Market Sentiment:&nbsp;</p>\n<p>I was not active in Bitcoin back in 2011, so I cannot compare the present time to the sentiment at the November 2011 bottom.&nbsp; However, sentiment currently is the worst that I have seen by a significant margin. Again, this does not mean that things could not get much, much worse before they get better!&nbsp; After all, sentiment has been growing worse for months now as the price declines, and everyone who predicted that it was as bad as it could get and the price could not possibly go below $X has been wrong.&nbsp; We are in a feedback loop which is strongly pumping bearishness into all market participants, and that feedback loop can continue and has continued for quite a while.</p>\n<p>&nbsp;</p>\n<p>A look at market indicators tells us that Bitcoin is very, very oversold, almost historically oversold.&nbsp; Again, this does not mean that it could not get worse before it gets better.&nbsp;</p>\n<p>&nbsp;</p>\n<p>As I write this, the price of Bitcoin is $230.&nbsp; For perspective, this is down over 80% from the all time high of $1163 in November 2013.&nbsp; It is still higher than the roughly $100 level it spent most of mid 2013 at.</p>\n<p>* The average price of a Bitcoin since the last time it moved is $314.</p>\n<p>https://www.reddit.com/r/BitcoinMarkets/comments/2ez90b/and_the_average_bitcoin_cost_basis_is/</p>\n<p>The current price is a multiple of .73 of this price.&nbsp; This is very low historically, but not the lowest it has ever ben.&nbsp; THe lowest was about .39 in late 2011.&nbsp;</p>\n<p>&nbsp;</p>\n<p>* Short interest (the number of Bitcoins that were borrowed and sold, and must be rebought later) hit all time highs this week, according to data on the exchange Bitfinex, at more than 25000 Bitcoins sold short:</p>\n<p>http://www.bfxdata.com/swaphistory/totals.php</p>\n<p>&nbsp;</p>\n<p>* Weekly RSI (relative strength index), an indicator which tells if a stock or commodity is 'overbought' or 'oversold' relative to its history, just hit its lowest value ever.</p>\n<p>&nbsp;</p>\n<p>Many indicators are telling us that Bitcoin is at or near historical levels in terms of the depth of this bear market.&nbsp; In percentage terms, the price decline is surpassed only by the November 2011 low.&nbsp; In terms of length, the current decline is more than twice as long as the previous longest bear market.</p>\n<p>&nbsp;</p>\n<p><strong>To summarize: At the present time, the market is pricing in a significant probability that Bitcoin is dying. </strong></p>\n<p>But there are some indicators (such as # of transactions) which say it is not dying.&nbsp; Maybe it continues down into oblivion, and the remaining fundamentals which looked bullish turn downwards and never recover.&nbsp; Remember that this is reality, and anything can happen, and nothing will save you.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Given all of this, we now have a choice.&nbsp; People have often compared Bitcoin to making a bet in which you have a 50% chance of losing everything, and a 50% chance of making multiples (far more than 2x) of what you started with.&nbsp;</p>\n<p>There are times when the payout on that bet is much lower, when everyone is euphoric and has been convinced by the positive feedback loop that they will win.&nbsp; And there are times when the payout on that bet is much higher, when everyone else is extremely fearful and is convinced it will not pay off.&nbsp;</p>\n<p>&nbsp;</p>\n<p>This is a time to be good rationalists, and investigate a possible opportunity, comparing the present situation to historical examples, and making an informed decision.&nbsp;&nbsp; Either Bitcoin has begun the process of dying, and this decline will continue in stages until it hits zero (or some incredibly low value that is essentially the same for our purposes), or it will live.&nbsp; Based on the new all time high being hit in number of transactions, and ways to spend Bitcoin, I think there is at least a reasonable chance it will live.&nbsp; Enough of a chance that it is worth taking some money that you can 100% afford to lose, and making a bet.&nbsp; A rational gamble that there is a decent probability that it will survive, at a time when a large number of others are betting that it will fail.</p>\n<p>&nbsp;</p>\n<p>And then once you do that, try your hardest to mentally write it off as a complete loss, like you had blown the money on a vacation or a consumer good, and now it is gone, and then wait a long time.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jgcAJnksReZRuvgzp": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tsoAwbDZ54GXtfcjh", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 8, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "27912", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 139, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2015-01-13T20:02:20.732Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T21:12:19.339Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington, D.C.: Fun & Games", "slug": "meetup-washington-d-c-fun-and-games", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Dq8S8SBWTbTyuwaPs/meetup-washington-d-c-fun-and-games", "pageUrlRelative": "/posts/Dq8S8SBWTbTyuwaPs/meetup-washington-d-c-fun-and-games", "linkUrl": "https://www.lesswrong.com/posts/Dq8S8SBWTbTyuwaPs/meetup-washington-d-c-fun-and-games", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%2C%20D.C.%3A%20Fun%20%26%20Games&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%2C%20D.C.%3A%20Fun%20%26%20Games%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDq8S8SBWTbTyuwaPs%2Fmeetup-washington-d-c-fun-and-games%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%2C%20D.C.%3A%20Fun%20%26%20Games%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDq8S8SBWTbTyuwaPs%2Fmeetup-washington-d-c-fun-and-games", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDq8S8SBWTbTyuwaPs%2Fmeetup-washington-d-c-fun-and-games", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 217, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18w'>Washington, D.C.: Fun &amp; Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 January 2015 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>hang out, play games, and engage in fun conversation.</strong></p>\n\n<p><em>Note:</em> Feel free to send an email to the Google Group - lesswrong-dc - if you have a game you wish to recruit people to play in advance. This is especially useful for games that take 3+ hours, as you will want to start playing by 3:30 to be sure of finishing by 7:00.</p>\n\n<p><em>Edit: <a href=\"http://wmata.com/rider_tools/metro_service_status/advisories.cfm?AID=4732\" rel=\"nofollow\">WMATA has posted the weekend service adjustment advisory - trains will be running less often on all lines</a>.</em> <a href=\"http://verizoncenter.monumentalnetwork.com/events/\" rel=\"nofollow\">The Verizon Center</a> has no events scheduled for the 18th.</p>\n\n<p><strong>Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 25: Fermi Estimates</strong> (calculating approximate answers to random questons)</li>\n<li><strong>Feb. 1: Performance of Masculinity discussion</strong> (read and discuss a pair of articles about male gender roles in U.S.)</li>\n<li><strong>Feb. 8: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n<li><strong>Feb. 15: Book Swap</strong> (lend books, borrow books, talk about books)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18w'>Washington, D.C.: Fun &amp; Games</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Dq8S8SBWTbTyuwaPs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 2.368757737240642e-06, "legacy": true, "legacyId": "27913", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Fun___Games\">Discussion article for the meetup : <a href=\"/meetups/18w\">Washington, D.C.: Fun &amp; Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 January 2015 03:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the Kogod Courtyard of the National Portrait Gallery (8th and F Sts or 8th and G Sts NW, go straight past the information desk from either entrance) to <strong>hang out, play games, and engage in fun conversation.</strong></p>\n\n<p><em>Note:</em> Feel free to send an email to the Google Group - lesswrong-dc - if you have a game you wish to recruit people to play in advance. This is especially useful for games that take 3+ hours, as you will want to start playing by 3:30 to be sure of finishing by 7:00.</p>\n\n<p><em>Edit: <a href=\"http://wmata.com/rider_tools/metro_service_status/advisories.cfm?AID=4732\" rel=\"nofollow\">WMATA has posted the weekend service adjustment advisory - trains will be running less often on all lines</a>.</em> <a href=\"http://verizoncenter.monumentalnetwork.com/events/\" rel=\"nofollow\">The Verizon Center</a> has no events scheduled for the 18th.</p>\n\n<p><strong id=\"Upcoming_meetups_\">Upcoming meetups:</strong></p>\n\n<ul>\n<li><strong>Jan. 25: Fermi Estimates</strong> (calculating approximate answers to random questons)</li>\n<li><strong>Feb. 1: Performance of Masculinity discussion</strong> (read and discuss a pair of articles about male gender roles in U.S.)</li>\n<li><strong>Feb. 8: Fun &amp; Games</strong> (bring games, play games, converse, socialize, or any combination thereof)</li>\n<li><strong>Feb. 15: Book Swap</strong> (lend books, borrow books, talk about books)</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington__D_C___Fun___Games1\">Discussion article for the meetup : <a href=\"/meetups/18w\">Washington, D.C.: Fun &amp; Games</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington, D.C.: Fun & Games", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Fun___Games", "level": 1}, {"title": "Upcoming meetups:", "anchor": "Upcoming_meetups_", "level": 2}, {"title": "Discussion article for the meetup : Washington, D.C.: Fun & Games", "anchor": "Discussion_article_for_the_meetup___Washington__D_C___Fun___Games1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T21:41:04.301Z", "modifiedAt": null, "url": null, "title": "[meta] New LW moderator: NancyLebovitz", "slug": "meta-new-lw-moderator-nancylebovitz", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:26.651Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Viliam_Bur", "createdAt": "2011-08-23T08:46:37.137Z", "isAdmin": false, "displayName": "Viliam_Bur"}, "userId": "yaaPhHzrvrPf7je22", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N7bQBjRHZpgLsGgzi/meta-new-lw-moderator-nancylebovitz", "pageUrlRelative": "/posts/N7bQBjRHZpgLsGgzi/meta-new-lw-moderator-nancylebovitz", "linkUrl": "https://www.lesswrong.com/posts/N7bQBjRHZpgLsGgzi/meta-new-lw-moderator-nancylebovitz", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Bmeta%5D%20New%20LW%20moderator%3A%20NancyLebovitz&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Bmeta%5D%20New%20LW%20moderator%3A%20NancyLebovitz%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN7bQBjRHZpgLsGgzi%2Fmeta-new-lw-moderator-nancylebovitz%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Bmeta%5D%20New%20LW%20moderator%3A%20NancyLebovitz%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN7bQBjRHZpgLsGgzi%2Fmeta-new-lw-moderator-nancylebovitz", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN7bQBjRHZpgLsGgzi%2Fmeta-new-lw-moderator-nancylebovitz", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 105, "htmlBody": "<p>During the following months my time and attention will be heavily occupied by some personal stuff, so I will be unable to function as a LW moderator. The new LW moderator is... <a href=\"/user/NancyLebovitz/overview/\">NancyLebovitz</a>!</p>\n<p>From today, please direct all your complaints and investigation requests to Nancy. Please <em>not</em> everyone during the first week. That can be a bit frightening for a new moderator.</p>\n<p>There are a few old requests I haven't completed yet. I will try to close everything during the following days, but if I don't do it till the end of January, then I will forward the unfinished cases to Nancy, too.</p>\n<p>Long live the new moderator!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hGzywXvWhSdJi5F2a": 1, "MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N7bQBjRHZpgLsGgzi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 43, "extendedScore": null, "score": 2.368827185278302e-06, "legacy": true, "legacyId": "27914", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-13T23:21:55.848Z", "modifiedAt": null, "url": null, "title": "I'm the new moderator", "slug": "i-m-the-new-moderator", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:30.955Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/E8e2dFH5MkJbr8MCf/i-m-the-new-moderator", "pageUrlRelative": "/posts/E8e2dFH5MkJbr8MCf/i-m-the-new-moderator", "linkUrl": "https://www.lesswrong.com/posts/E8e2dFH5MkJbr8MCf/i-m-the-new-moderator", "postedAtFormatted": "Tuesday, January 13th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I'm%20the%20new%20moderator&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI'm%20the%20new%20moderator%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE8e2dFH5MkJbr8MCf%2Fi-m-the-new-moderator%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I'm%20the%20new%20moderator%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE8e2dFH5MkJbr8MCf%2Fi-m-the-new-moderator", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FE8e2dFH5MkJbr8MCf%2Fi-m-the-new-moderator", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<p>Viliam Bur <a href=\"/lw/lje/meta_new_lw_moderator_nancylebovitz/\">made the announcement</a>&nbsp;in Main, but not everyone checks main, so I'm repeating it here.</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">During the following months my time and attention will be heavily occupied by some personal stuff, so I will be unable to function as a LW moderator. The new LW moderator is...</span><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">&nbsp;</span><a style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify; color: #8a8a8b;\" href=\"/user/NancyLebovitz/overview/\">NancyLebovitz</a><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">!</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">From today, please direct all your complaints and investigation requests to Nancy. Please&nbsp;<em>not</em>&nbsp;everyone during the first week. That can be a bit frightening for a new moderator.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">There are a few old requests I haven't completed yet. I will try to close everything during the following days, but if I don't do it till the end of January, then I will forward the unfinished cases to Nancy, too.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19.5px; text-align: justify;\">Long live the new moderator!</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "hGzywXvWhSdJi5F2a": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "E8e2dFH5MkJbr8MCf", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 92, "baseScore": 134, "extendedScore": null, "score": 0.0008086007445996062, "legacy": true, "legacyId": "27915", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-05-07T19:08:55.700Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": true, "hideFrontpageComments": false, "maxBaseScore": 87, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["N7bQBjRHZpgLsGgzi"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-14T00:06:56.290Z", "modifiedAt": null, "url": null, "title": "Quantum cat-stencil interference projection? What is this?", "slug": "quantum-cat-stencil-interference-projection-what-is-this", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:30.190Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pre", "createdAt": "2009-02-27T14:35:32.511Z", "isAdmin": false, "displayName": "pre"}, "userId": "XCwdovczssgYqBwT2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vu7gjGeaH8w8QtTZE/quantum-cat-stencil-interference-projection-what-is-this", "pageUrlRelative": "/posts/vu7gjGeaH8w8QtTZE/quantum-cat-stencil-interference-projection-what-is-this", "linkUrl": "https://www.lesswrong.com/posts/vu7gjGeaH8w8QtTZE/quantum-cat-stencil-interference-projection-what-is-this", "postedAtFormatted": "Wednesday, January 14th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Quantum%20cat-stencil%20interference%20projection%3F%20What%20is%20this%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuantum%20cat-stencil%20interference%20projection%3F%20What%20is%20this%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvu7gjGeaH8w8QtTZE%2Fquantum-cat-stencil-interference-projection-what-is-this%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Quantum%20cat-stencil%20interference%20projection%3F%20What%20is%20this%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvu7gjGeaH8w8QtTZE%2Fquantum-cat-stencil-interference-projection-what-is-this", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvu7gjGeaH8w8QtTZE%2Fquantum-cat-stencil-interference-projection-what-is-this", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p>Sorry I don't hang around here much. I keep meaning to. You're still the ones I come to when I have no clue at all what a quantum-physics article I come across means though.<br /><br />http://io9.com/heres-a-photo-of-something-that-cant-be-photographed-1678918200<br /><br />So. Um. What?<br /><br />They have some kind of double-slit experiment that gets double-slitted again then passed through a stencil before being recombined and recombined again to give a stencil-shaped interference pattern?<br /><br />Is that even right?</p>\n<p>Can someone many-worlds-interpretation describe that at me, even if it turns out its just a thought-experiment with a graphics mock-up?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vu7gjGeaH8w8QtTZE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 2.3691796015721074e-06, "legacy": true, "legacyId": "27916", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-14T03:47:32.618Z", "modifiedAt": null, "url": null, "title": "Meetup : Raleigh, NC (RTLW) Discussion Meetup", "slug": "meetup-raleigh-nc-rtlw-discussion-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.343Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9iB7KSbW7TpsgFHkf/meetup-raleigh-nc-rtlw-discussion-meetup", "pageUrlRelative": "/posts/9iB7KSbW7TpsgFHkf/meetup-raleigh-nc-rtlw-discussion-meetup", "linkUrl": "https://www.lesswrong.com/posts/9iB7KSbW7TpsgFHkf/meetup-raleigh-nc-rtlw-discussion-meetup", "postedAtFormatted": "Wednesday, January 14th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Raleigh%2C%20NC%20(RTLW)%20Discussion%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Raleigh%2C%20NC%20(RTLW)%20Discussion%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9iB7KSbW7TpsgFHkf%2Fmeetup-raleigh-nc-rtlw-discussion-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Raleigh%2C%20NC%20(RTLW)%20Discussion%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9iB7KSbW7TpsgFHkf%2Fmeetup-raleigh-nc-rtlw-discussion-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9iB7KSbW7TpsgFHkf%2Fmeetup-raleigh-nc-rtlw-discussion-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 113, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18x'>Raleigh, NC (RTLW) Discussion Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 May 2022 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Triangle area LessWrong meetup is held the 1st, 3rd, and 5th Thursdays of the month, usually in either Durham or Raleigh. For dates, topics, and locations, please <a href=\"https://groups.google.com/forum/#!forum/rtlw\" rel=\"nofollow\">join our mailing list</a> for the most up to date information, or <a href=\"mailto:rcfreese@gmail.com\" rel=\"nofollow\">email Ruthan</a>.</p>\n\n<p>Our next meeting will be 5/5, probably at a place, and we'll do a thing. If you'd like to influence the specificity of \"place\" and \"thing\", <a href=\"https://docs.google.com/document/u/1/d/1_6gtYA4t8f29A0BUDs5C_NzHJ8wq6znUQASYT0ERgrw/pub\" rel=\"nofollow\">our scheduling document, Shotgun Rules for RTLW Meetings, can be found here</a>.</p>\n\n<p>Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18x'>Raleigh, NC (RTLW) Discussion Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9iB7KSbW7TpsgFHkf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "27919", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Raleigh__NC__RTLW__Discussion_Meetup\">Discussion article for the meetup : <a href=\"/meetups/18x\">Raleigh, NC (RTLW) Discussion Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 May 2022 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Triangle area LessWrong meetup is held the 1st, 3rd, and 5th Thursdays of the month, usually in either Durham or Raleigh. For dates, topics, and locations, please <a href=\"https://groups.google.com/forum/#!forum/rtlw\" rel=\"nofollow\">join our mailing list</a> for the most up to date information, or <a href=\"mailto:rcfreese@gmail.com\" rel=\"nofollow\">email Ruthan</a>.</p>\n\n<p>Our next meeting will be 5/5, probably at a place, and we'll do a thing. If you'd like to influence the specificity of \"place\" and \"thing\", <a href=\"https://docs.google.com/document/u/1/d/1_6gtYA4t8f29A0BUDs5C_NzHJ8wq6znUQASYT0ERgrw/pub\" rel=\"nofollow\">our scheduling document, Shotgun Rules for RTLW Meetings, can be found here</a>.</p>\n\n<p>Hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Raleigh__NC__RTLW__Discussion_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/18x\">Raleigh, NC (RTLW) Discussion Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Raleigh, NC (RTLW) Discussion Meetup", "anchor": "Discussion_article_for_the_meetup___Raleigh__NC__RTLW__Discussion_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Raleigh, NC (RTLW) Discussion Meetup", "anchor": "Discussion_article_for_the_meetup___Raleigh__NC__RTLW__Discussion_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-14T08:42:51.489Z", "modifiedAt": null, "url": null, "title": "Selfish preferences and self-modification", "slug": "selfish-preferences-and-self-modification", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:26.185Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Manfred", "createdAt": "2010-10-12T17:53:38.361Z", "isAdmin": false, "displayName": "Manfred"}, "userId": "kmqiDCH9S5EGXxjGg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zgbZNwW7f3C89ZgGK/selfish-preferences-and-self-modification", "pageUrlRelative": "/posts/zgbZNwW7f3C89ZgGK/selfish-preferences-and-self-modification", "linkUrl": "https://www.lesswrong.com/posts/zgbZNwW7f3C89ZgGK/selfish-preferences-and-self-modification", "postedAtFormatted": "Wednesday, January 14th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Selfish%20preferences%20and%20self-modification&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelfish%20preferences%20and%20self-modification%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzgbZNwW7f3C89ZgGK%2Fselfish-preferences-and-self-modification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Selfish%20preferences%20and%20self-modification%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzgbZNwW7f3C89ZgGK%2Fselfish-preferences-and-self-modification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzgbZNwW7f3C89ZgGK%2Fselfish-preferences-and-self-modification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 570, "htmlBody": "<p>One question I've had recently is \"Are agents acting on selfish preferences doomed to having conflicts with other versions of themselves?\" A major motivation of TDT and UDT was the ability to just do the right thing without having to be tied up with precommitments made by your past self - and to trust that your future self would just do the right thing, without you having to tie them up with precommitments. Is this an impossible dream in anthropic problems?</p>\n<p>&nbsp;</p>\n<p>In my <a href=\"/lw/lg2/treating_anthropic_selfish_preferences_as_an/\">recent post</a>, I talked about preferences where \"if you are one of two copies and I give the other copy a candy bar, your selfish desires for eating candy are unfulfilled.\" If you would buy a candy bar for a dollar but not buy your copy a candy bar, this is exactly a case of strategy ranking depending on indexical information.</p>\n<p>This dependence on indexical information is inequivalent with UDT, and thus incompatible with peace and harmony.</p>\n<p>&nbsp;</p>\n<p>To be thorough, consider an experiment where I am forked into two copies, A and B. Both have a button in front of them, and 10 candies in their account. If A presses the button, it deducts 1 candy from A. But if B presses the button, it removes 1 candy from B and gives 5 candies to A.</p>\n<p>Before the experiment begins, I want my descendants to press the button 10 times (assuming candies come in units such that my utility is linear). In fact, after the copies wake up but before they know which is which, they want to press the button!</p>\n<p>The model of selfish preferences that is not UDT-compatible looks like this: once A and B know who is who, A wants B to press the button but B doesn't want to do it. And so earlier, I should try and make precommitments to force B to press the button.</p>\n<p>But suppose that we simply decided to use a different model. A model of peace and harmony and, like, free love, where I just maximize the average (or total, if we specify an arbitrary zero point) amount of utility that myselves have. And so B just presses the button.</p>\n<p>(It's like non-UDT selfish copies can make all Pareto improvements, but not all average improvements)</p>\n<p>&nbsp;</p>\n<p>Is the peace-and-love model still a selfish preference? It sure seems different from the every-copy-for-themself algorithm. But on the other hand, I'm <a href=\"/lw/kwd/rationality_quotes_september_2014/bdv2\">doing it for myself</a>, in a sense.</p>\n<p>And at least this way I don't have to waste time with precomittment. In fact, self-modifying to this form of preferences is such an effective action that conflicting preferences are self-destructive. If I have selfish preferences now but I want my copies to cooperate in the future, I'll try to become an agent who values copies of myself - so long as they date from after the time of my self-modification.</p>\n<p>&nbsp;</p>\n<p>If you recall, I made an argument in favor of averaging the utility of future causal descendants when calculating expected utility, based on this being the fixed point of selfish preferences under modification when confronted with Jan's tropical paradise. But if selfish preferences are unstable under self-modification in a more intrinsic way, this rather goes out the window.</p>\n<p>&nbsp;</p>\n<p>Right now I think of selfish values as a somewhat anything-goes space occupied by non-self-modified agents like me and you. But it feels uncertain. On the mutant third hand, what sort of arguments would convince me that the peace-and-love model actually captures my selfish preferences?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2, "dPPATLhRmhdJtJM2t": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zgbZNwW7f3C89ZgGK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 2.370426819248448e-06, "legacy": true, "legacyId": "27903", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gTmWZEu3CcEQ6fLLM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-14T17:49:45.075Z", "modifiedAt": null, "url": null, "title": "Meetup : London Social Meetup, 18/01/2015", "slug": "meetup-london-social-meetup-18-01-2015", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:12.850Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tenoke", "createdAt": "2012-04-10T21:37:29.739Z", "isAdmin": false, "displayName": "Tenoke"}, "userId": "CRSZPEg9dHyMspTzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zKqsrqWkXpP7t3kKs/meetup-london-social-meetup-18-01-2015", "pageUrlRelative": "/posts/zKqsrqWkXpP7t3kKs/meetup-london-social-meetup-18-01-2015", "linkUrl": "https://www.lesswrong.com/posts/zKqsrqWkXpP7t3kKs/meetup-london-social-meetup-18-01-2015", "postedAtFormatted": "Wednesday, January 14th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Social%20Meetup%2C%2018%2F01%2F2015&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Social%20Meetup%2C%2018%2F01%2F2015%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzKqsrqWkXpP7t3kKs%2Fmeetup-london-social-meetup-18-01-2015%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Social%20Meetup%2C%2018%2F01%2F2015%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzKqsrqWkXpP7t3kKs%2Fmeetup-london-social-meetup-18-01-2015", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzKqsrqWkXpP7t3kKs%2Fmeetup-london-social-meetup-18-01-2015", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 200, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18y'>London Social Meetup, 18/01/2015</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 January 2015 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Shakespeare's Head, Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having another meetup this Sunday (18/01) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:</p>\n\n<p>We run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18y'>London Social Meetup, 18/01/2015</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zKqsrqWkXpP7t3kKs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "27920", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Social_Meetup__18_01_2015\">Discussion article for the meetup : <a href=\"/meetups/18y\">London Social Meetup, 18/01/2015</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 January 2015 02:00:00PM (+0000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Shakespeare's Head, Shakespeare's Head, Africa House, 64-68 Kingsway, London WC2B 6BG, UK-68 Kingsway, London WC2B 6BG, UK</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>LessWrong London is having another meetup this Sunday (18/01) at 2:00 PM. We are meeting at our usual venue - The Shakespeare's Head by Holborn tube station. There is no fixed topic of discussion nor is there anything planned so be prepared for anything. There will be a sign identifying us and if you have any problems feel free to contact me on 07425168803.</p>\n\n<p>About London LessWrong:</p>\n\n<p>We run this meetup almost every week; these days we tend to get in the region of 5-15 people in attendance. By default, meetups are just unstructured social discussion about whatever strikes our fancy: books we're reading, recent posts on LW/related blogs, logic puzzles, toilet usage statistics....\nSometimes we play The Resistance or other games. We usually finish around 7pm, give or take an hour, but people arrive and leave whenever suits them.</p>\n\n<p><em>If you want more information about the meetup or anything else come by our <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">google group</a> or alternatively our <a href=\"https://www.facebook.com/groups/380103898766356/\" rel=\"nofollow\">facebook group</a>.</em></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_Social_Meetup__18_01_20151\">Discussion article for the meetup : <a href=\"/meetups/18y\">London Social Meetup, 18/01/2015</a></h2>", "sections": [{"title": "Discussion article for the meetup : London Social Meetup, 18/01/2015", "anchor": "Discussion_article_for_the_meetup___London_Social_Meetup__18_01_2015", "level": 1}, {"title": "Discussion article for the meetup : London Social Meetup, 18/01/2015", "anchor": "Discussion_article_for_the_meetup___London_Social_Meetup__18_01_20151", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-15T04:02:44.807Z", "modifiedAt": null, "url": null, "title": "Meetup : Canberra: the Hedonic Treadmill", "slug": "meetup-canberra-the-hedonic-treadmill", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanielFilan", "createdAt": "2014-01-30T11:04:39.341Z", "isAdmin": false, "displayName": "DanielFilan"}, "userId": "DgsGzjyBXN8XSK22q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oogM4DvTKgSkyMbER/meetup-canberra-the-hedonic-treadmill", "pageUrlRelative": "/posts/oogM4DvTKgSkyMbER/meetup-canberra-the-hedonic-treadmill", "linkUrl": "https://www.lesswrong.com/posts/oogM4DvTKgSkyMbER/meetup-canberra-the-hedonic-treadmill", "postedAtFormatted": "Thursday, January 15th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Canberra%3A%20the%20Hedonic%20Treadmill&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Canberra%3A%20the%20Hedonic%20Treadmill%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoogM4DvTKgSkyMbER%2Fmeetup-canberra-the-hedonic-treadmill%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Canberra%3A%20the%20Hedonic%20Treadmill%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoogM4DvTKgSkyMbER%2Fmeetup-canberra-the-hedonic-treadmill", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoogM4DvTKgSkyMbER%2Fmeetup-canberra-the-hedonic-treadmill", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/18z'>Canberra: the Hedonic Treadmill</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 January 2015 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">108 North Road, Acton, ACT, 0200</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I will be giving a brief talk about what does and doesn't make us happier in the long run, introducing the idea of the 'hedonic treadmill'. Discussion will (hopefully) ensue afterwards. Vegan snacks will be provided.</p>\n\n<p>General meetup info:</p>\n\n<ul>\n<li>If you use Facebook, please join our <a href=\"https://www.facebook.com/groups/lwcanberra/\" rel=\"nofollow\">group</a>.</li>\n<li>Structured meetups are (usually) held on the second Saturday and fourth Friday of each month from 6 pm until late in the CSIT building, room N101.</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/18z'>Canberra: the Hedonic Treadmill</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb186": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oogM4DvTKgSkyMbER", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.37323505332353e-06, "legacy": true, "legacyId": "27921", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Canberra__the_Hedonic_Treadmill\">Discussion article for the meetup : <a href=\"/meetups/18z\">Canberra: the Hedonic Treadmill</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 January 2015 06:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">108 North Road, Acton, ACT, 0200</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I will be giving a brief talk about what does and doesn't make us happier in the long run, introducing the idea of the 'hedonic treadmill'. Discussion will (hopefully) ensue afterwards. Vegan snacks will be provided.</p>\n\n<p>General meetup info:</p>\n\n<ul>\n<li>If you use Facebook, please join our <a href=\"https://www.facebook.com/groups/lwcanberra/\" rel=\"nofollow\">group</a>.</li>\n<li>Structured meetups are (usually) held on the second Saturday and fourth Friday of each month from 6 pm until late in the CSIT building, room N101.</li>\n</ul></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Canberra__the_Hedonic_Treadmill1\">Discussion article for the meetup : <a href=\"/meetups/18z\">Canberra: the Hedonic Treadmill</a></h2>", "sections": [{"title": "Discussion article for the meetup : Canberra: the Hedonic Treadmill", "anchor": "Discussion_article_for_the_meetup___Canberra__the_Hedonic_Treadmill", "level": 1}, {"title": "Discussion article for the meetup : Canberra: the Hedonic Treadmill", "anchor": "Discussion_article_for_the_meetup___Canberra__the_Hedonic_Treadmill1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-15T06:31:51.232Z", "modifiedAt": null, "url": null, "title": "Meetup : San Francisco Meetup: Unconference", "slug": "meetup-san-francisco-meetup-unconference", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LaLfWzAou45YSXTT8/meetup-san-francisco-meetup-unconference", "pageUrlRelative": "/posts/LaLfWzAou45YSXTT8/meetup-san-francisco-meetup-unconference", "linkUrl": "https://www.lesswrong.com/posts/LaLfWzAou45YSXTT8/meetup-san-francisco-meetup-unconference", "postedAtFormatted": "Thursday, January 15th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20San%20Francisco%20Meetup%3A%20Unconference&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20San%20Francisco%20Meetup%3A%20Unconference%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLaLfWzAou45YSXTT8%2Fmeetup-san-francisco-meetup-unconference%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20San%20Francisco%20Meetup%3A%20Unconference%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLaLfWzAou45YSXTT8%2Fmeetup-san-francisco-meetup-unconference", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLaLfWzAou45YSXTT8%2Fmeetup-san-francisco-meetup-unconference", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/190'>San Francisco Meetup: Unconference</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">19 January 2015 06:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">219 6th st. , San Francisco, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>THE LOCATION MAY HAVE CHANGED SINCE YOU LAST LOOKED AT THIS POST!</p>\n\n<p>We'll be having an unconference! People will have the opportunity to give short presentations on something that interests them. We'll probably devolve to general conversation afterwards.\nCall (301-458-0764)  if you have any trouble.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/190'>San Francisco Meetup: Unconference</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LaLfWzAou45YSXTT8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.373596487012111e-06, "legacy": true, "legacyId": "27922", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___San_Francisco_Meetup__Unconference\">Discussion article for the meetup : <a href=\"/meetups/190\">San Francisco Meetup: Unconference</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">19 January 2015 06:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">219 6th st. , San Francisco, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>THE LOCATION MAY HAVE CHANGED SINCE YOU LAST LOOKED AT THIS POST!</p>\n\n<p>We'll be having an unconference! People will have the opportunity to give short presentations on something that interests them. We'll probably devolve to general conversation afterwards.\nCall (301-458-0764)  if you have any trouble.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___San_Francisco_Meetup__Unconference1\">Discussion article for the meetup : <a href=\"/meetups/190\">San Francisco Meetup: Unconference</a></h2>", "sections": [{"title": "Discussion article for the meetup : San Francisco Meetup: Unconference", "anchor": "Discussion_article_for_the_meetup___San_Francisco_Meetup__Unconference", "level": 1}, {"title": "Discussion article for the meetup : San Francisco Meetup: Unconference", "anchor": "Discussion_article_for_the_meetup___San_Francisco_Meetup__Unconference1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-15T08:27:23.571Z", "modifiedAt": null, "url": null, "title": "Je suis Charlie", "slug": "je-suis-charlie", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:36.604Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "LQxXyeYY8tAyoJ4m9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7qyzjFJcD8AM2uvEH/je-suis-charlie", "pageUrlRelative": "/posts/7qyzjFJcD8AM2uvEH/je-suis-charlie", "linkUrl": "https://www.lesswrong.com/posts/7qyzjFJcD8AM2uvEH/je-suis-charlie", "postedAtFormatted": "Thursday, January 15th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Je%20suis%20Charlie&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJe%20suis%20Charlie%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7qyzjFJcD8AM2uvEH%2Fje-suis-charlie%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Je%20suis%20Charlie%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7qyzjFJcD8AM2uvEH%2Fje-suis-charlie", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7qyzjFJcD8AM2uvEH%2Fje-suis-charlie", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<p dir=\"ltr\">After the terrorist attacks at Charlie Hebdo, conspiracy theories quickly arose about who was behind the attacks.<br /> People who are critical to the west easily swallow such theories while pro-vest people just as easily find them ridiculous.</p>\n<p dir=\"ltr\">I guess we can agree that the most rational response would be to enter a state of aporia until sufficient evidence is at hand.</p>\n<p dir=\"ltr\">Yet very few people do so. People are guided by their  previous understanding of the world, when judging new information. It  sounds like a fine Bayesian approach for getting through life, but for  real scientific knowledge, we can't rely on *prior* reasonings (even  though these might involve Bayesian reasoning). Real science works by  investigating evidence.</p>\n<p dir=\"ltr\">So, how do we characterise the human tendency to jump to  conclusions that have simply been supplied by their sense of  normativity. Is their a previously described bias that covers this case?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7qyzjFJcD8AM2uvEH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": -34, "extendedScore": null, "score": 2.3738766190148254e-06, "legacy": true, "legacyId": "27923", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 72, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-15T16:33:48.640Z", "modifiedAt": null, "url": null, "title": "Elon Musk donates $10M to the Future of Life Institute to keep AI beneficial ", "slug": "elon-musk-donates-usd10m-to-the-future-of-life-institute-to", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.180Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FuCZdbQ3h6782bnY6/elon-musk-donates-usd10m-to-the-future-of-life-institute-to", "pageUrlRelative": "/posts/FuCZdbQ3h6782bnY6/elon-musk-donates-usd10m-to-the-future-of-life-institute-to", "linkUrl": "https://www.lesswrong.com/posts/FuCZdbQ3h6782bnY6/elon-musk-donates-usd10m-to-the-future-of-life-institute-to", "postedAtFormatted": "Thursday, January 15th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Elon%20Musk%20donates%20%2410M%20to%20the%20Future%20of%20Life%20Institute%20to%20keep%20AI%20beneficial%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AElon%20Musk%20donates%20%2410M%20to%20the%20Future%20of%20Life%20Institute%20to%20keep%20AI%20beneficial%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFuCZdbQ3h6782bnY6%2Felon-musk-donates-usd10m-to-the-future-of-life-institute-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Elon%20Musk%20donates%20%2410M%20to%20the%20Future%20of%20Life%20Institute%20to%20keep%20AI%20beneficial%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFuCZdbQ3h6782bnY6%2Felon-musk-donates-usd10m-to-the-future-of-life-institute-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFuCZdbQ3h6782bnY6%2Felon-musk-donates-usd10m-to-the-future-of-life-institute-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 329, "htmlBody": "<p style=\"padding-left: 30px;\">We are delighted to report that technology inventor Elon Musk, creator of Tesla and SpaceX, has decided to donate $10M to the Future of Life Institute to run a global research program aimed at keeping AI beneficial to humanity.&nbsp;</p>\n<p style=\"padding-left: 30px;\">There is now a broad consensus that AI research is progressing steadily, and that its impact on society is likely to increase. A long list of leading AI-researchers have signed an <a href=\"http://futureoflife.org/misc/open_letter\">open letter</a> calling for research aimed at ensuring that AI systems are robust and beneficial, doing what we want them to do. Musk's donation aims to support precisely this type of research: <em>\"Here are all these leading AI researchers saying that AI safety is important\"</em>, says Elon Musk. <em>\"I agree with them, so I'm today committing $10M to support research aimed at keeping AI beneficial for humanity.\"&nbsp;</em></p>\n<p style=\"padding-left: 30px;\">[...] The $10M program will be administered by the Future of Life Institute, a non-profit organization whose scientific advisory board includes AI-researchers Stuart Russell and Francesca Rossi. [...]</p>\n<p style=\"padding-left: 30px;\">The research supported by the program will be carried out around the globe via an open grants competition, through an application portal at <a href=\"http://futureoflife.org\">http://futureoflife.org</a> that will open by Thursday January 22. The plan is to award the majority of the grant funds to AI researchers, and the remainder to AI-related research involving other fields such as economics, law, ethics and policy &nbsp;(a detailed list of examples can be found <a href=\"http://futureoflife.org/static/data/documents/research_priorities.pdf\">here</a>&nbsp;[PDF]). <em>\"Anybody can send in a grant proposal, and the best ideas will win regardless of whether they come from academia, industry or elsewhere\"</em>, says FLI co-founder Viktoriya Krakovna.&nbsp;</p>\n<p style=\"padding-left: 30px;\">[...] Along with research grants, the program will also include meetings and outreach programs aimed at bringing together academic AI researchers, industry AI developers and other key constituents to continue exploring how to maximize the societal benefits of AI; one such meeting was held in Puerto Rico last week with many of the open-letter signatories.&nbsp;</p>\n<p><a href=\"http://futureoflife.org/misc/ai\">Elon Musk donates $10M to keep AI beneficial, Future of Life Institute, Thursday January 15, 2015</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZFrgTgzwEfStg26JL": 1, "qAvbtzdG2A2RBn7in": 1, "CL9NePP9FejkQo6jn": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FuCZdbQ3h6782bnY6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 57, "baseScore": 78, "extendedScore": null, "score": 0.000216, "legacy": true, "legacyId": "27924", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 57, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-15T22:47:55.625Z", "modifiedAt": null, "url": null, "title": "Vingean Reflection: Reliable Reasoning for Self-Improving Agents", "slug": "vingean-reflection-reliable-reasoning-for-self-improving", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:33.220Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "So8res", "createdAt": "2012-01-10T05:50:18.713Z", "isAdmin": false, "displayName": "So8res"}, "userId": "xSfc2APSi8WzFxp7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iWwaJ5wPGLZJWjPAL/vingean-reflection-reliable-reasoning-for-self-improving", "pageUrlRelative": "/posts/iWwaJ5wPGLZJWjPAL/vingean-reflection-reliable-reasoning-for-self-improving", "linkUrl": "https://www.lesswrong.com/posts/iWwaJ5wPGLZJWjPAL/vingean-reflection-reliable-reasoning-for-self-improving", "postedAtFormatted": "Thursday, January 15th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Vingean%20Reflection%3A%20Reliable%20Reasoning%20for%20Self-Improving%20Agents&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVingean%20Reflection%3A%20Reliable%20Reasoning%20for%20Self-Improving%20Agents%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWwaJ5wPGLZJWjPAL%2Fvingean-reflection-reliable-reasoning-for-self-improving%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Vingean%20Reflection%3A%20Reliable%20Reasoning%20for%20Self-Improving%20Agents%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWwaJ5wPGLZJWjPAL%2Fvingean-reflection-reliable-reasoning-for-self-improving", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWwaJ5wPGLZJWjPAL%2Fvingean-reflection-reliable-reasoning-for-self-improving", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2744, "htmlBody": "<p>I'm pleased to announce a new paper from MIRI: <em><a href=\"http://intelligence.org/files/VingeanReflection.pdf\">Vingean Reflection: Reliable Reasoning for Self-Improving Agents</a></em>.</p>\n<p>Abstract:</p>\n<blockquote>\n<p>Today, human-level machine intelligence is in the domain of futurism, but there is every reason to expect that it will be developed eventually. Once artificial agents become able to improve themselves further, they may far surpass human intelligence, making it vitally important to ensure that the result of an \"intelligence explosion\" is aligned with human interests. In this paper, we discuss one aspect of this challenge: ensuring that the initial agent's reasoning about its future versions is reliable, even if these future versions are far more intelligent than the current reasoner. We refer to reasoning of this sort as <em>Vingean Reflection</em>.</p>\n<p>A self-improving agent must reason about the behavior of its smarter successors in abstract terms, since if it could predict their actions in detail, it would already be as smart as them. This is called the <em>Vingean principle</em>, and we argue that theoretical work on Vingean reflection should focus on formal models that reflect this principle. However, the framework of expected utility maximization, commonly used to model rational agents, fails to do so. We review a body of work which instead investigates agents that use formal proofs to reason about their successors. While it is unlikely that real-world agents would base their behavior entirely on formal proofs, this appears to be the best currently available formal model of abstract reasoning, and work in this setting may lead to insights applicable to more realistic approaches to Vingean reflection.</p>\n</blockquote>\n<p>This is the fourth in a series of six papers discussing various components of MIRI's&nbsp;<a href=\"https://intelligence.org/files/TechnicalAgenda.pdf\">technical research agenda</a>. It motivates the field of <em>Vingean reflection</em>, which studies methods by which agents can reason reliably about agents that are more intelligent than themselves. Toy models used to study this problem in the past include the \"<a href=\"http://intelligence.org/files/TilingAgentsDraft.pdf\">tiling agent</a>\" models that have been discussed on LessWrong in the past. The introduction to the paper runs as follows:</p>\n<p><a id=\"more\"></a></p>\n<hr />\n<p>In a 1965 article, I.J. Good introduced the concept of an \"intelligence explosion\" (Good 1965):</p>\n<blockquote>\n<p>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an 'intelligence explosion,' and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make.</p>\n</blockquote>\n<p>Almost fifty years later, a machine intelligence that is smart in the way humans are remains the subject of futurism and science fiction. But barring global catastrophe, there seems to be little reason to doubt that humanity will&nbsp;<em>eventually</em>&nbsp;create a smarter-than-human machine. Whether machine intelligence can really leave the intelligence of biological humans far behind is less obvious, but there is some reason to think that this may be the case (Bostrom 2014): First, the hardware of human brains is nowhere close to physical limits; and second, not much time has passed on an evolutionary timescale since humans developed language, suggesting that we possess the&nbsp;<em>minimal</em>&nbsp;amount of general intelligence necessary to develop a technological civilization, not the theoretical optimum.</p>\n<p>It's not hard to see that if building an artificial superintelligent agent will be possible at some point in the future, this could be both a great boon to humanity and a great danger if this agent does not work as intended (Bostrom 2014, Yudkowsky 2008). Imagine, for example, a system built to operate a robotic laboratory for finding a cure for cancer; if this is its only goal, and the system becomes far smarter than any human, then its best course of action (to maximize the probability of achieving its goal) may well be to convert all of Earth into more computers and robotic laboratories&mdash;and with sufficient intelligence, it may well find a way to do so. This argument generalizes, of course: While there is no reason to think that an artificial intelligence would be driven by human motivations like a lust for power,&nbsp;<em>any</em>&nbsp;goals that are not quite ours would place it at odds with our interests.</p>\n<p>How, then, can we ensure that self-improving smarter-than-human machine intelligence, if and when it is developed, is beneficial to humanity?</p>\n<p>Extensive testing may not be sufficient. A smarter-than-human agent would have an incentive to pretend during testing that its goals are aligned with ours, even if they are not, because we might otherwise attempt to modify it or shut it down (Bostrom 2014). Hence, testing would only give reliable information if the system is not yet sufficiently intelligent to deceive us. If, at this point, it is also not yet intelligent enough to realize that its goals are at odds with ours, a misaligned agent might pass even very extensive tests.</p>\n<p>Moreover, the test environment may be very different from the environment in which the system will actually operate. It may be infeasible to set up a testing environment which allows a smarter-than-human system to be tested in the kinds of complex, unexpected situations that it might encounter in the real world as it gains knowledge and executes strategies that its programmers never conceived of.</p>\n<p>For these reasons, it seems important to have a theoretical understanding of why the system is expected to work, so as to gain high confidence in a system that will face a wide range of unanticipated challenges (Soares and Fallenstein, 2014a). By this we mean two things: (1) a formal specification of the problem faced by the system; and (2) a firm understanding of why the system (which must inevitably use practical heuristics) is expected to perform well on this problem.</p>\n<p>It may seem odd to raise these questions today, with smarter-than-human machines still firmly in the domain of futurism; we can hardly verify that the heuristics employed by an artificial agent work as intended before we even know what these heuristics are. However, Soares and Fallenstein (2014a) argue that there is&nbsp;<em>foundational</em>&nbsp;research we can do today that can help us understand the operation of a smarter-than-human agent on an abstract level.</p>\n<p>For example, although the expected utility maximization framework of neoclassical economics has serious shortcomings in describing the behavior of a realistic artificial agent, it is a useful starting point for asking whether it's possible to avoid giving a misaligned agent incentives for manipulating its human operators (Soares 2015). Similarly, it allows us to ask what sorts of models of the environment would be able to deal with the complexities of the real world (Hutter 2000). Where this framework falls short, we can ask how to extend it to capture more aspects of reality, such as the fact that an agent is a part of its environment (Orseau 2012), and the fact that a real agent cannot be logically omniscient (Gaifman 2004, Soares and Fallenstein 2015). Moreover, even when more realistic models are available, simple models can clarify conceptual issues by idealizing away difficulties not relevant to a particular problem under consideration.</p>\n<p>In this paper, we review work on one foundational issue that would be particularly relevant in the context of an intelligence explosion&mdash;that is, if humanity does not create a superintelligent agent directly, but instead creates an agent that attains superintelligence through a sequence of successive self-improvements. In this case, the resulting superintelligent system may be quite different from the initial verified system. The behavior of the final system would depend entirely upon the ability of the initial system to reason correctly about the construction of systems more intelligent than itself.</p>\n<p>This is no trouble if the initial system is extremely reliable: if the reasoning of the initial agent were at least as good as a team of human AI researchers in all domains, then the system itself would be at least as safe as anything designed by a team of human researchers. However, if the system were only known to reason well in&nbsp;<em>most</em>&nbsp;cases, then it seems prudent to verify its reasoning specifically in the critical case where the agent reasons about self-modifications.</p>\n<p>At least intuitively, reasoning about the behavior of an agent which is more intelligent than the reasoner seems qualitatively more difficult than reasoning about the behavior of a less intelligent system. Verifying that a military drone obeys certain rules of engagement is one thing; verifying that an artificial general would successfully run a war, identifying clever strategies never before conceived of and deploying brilliant plans as appropriate, seems like another thing entirely. It is certainly possible that this intuition will turn out to be wrong, but it seems as if we should at least&nbsp;<em>check</em>: if extremely high confidence must be placed on the ability of self-modifying systems to reason about agents which are smarter than the reasoner, then it seems prudent to develop a theoretical understanding of satisfactory reasoning about smarter agents. In honor of Vinge (1993), who emphasizes the difficulty of predicting the behavior of smarter-than-human agents with human intelligence, we refer to reasoning of this sort as&nbsp;<em>Vingean reflection</em>.</p>\n<h2>Vingean Reflection</h2>\n<p>The simplest and cleanest formal model of intelligent agents is the framework of expected utility maximization. Given that this framework has been a productive basis for theoretical work both in artificial intelligence in general, and on smarter-than-human agents in particular, it is natural to ask whether it can be used to model the reasoning of self-improving agents.</p>\n<p>However, although it can be useful to consider models that idealize away part of the complexity of the real world, it is not difficult to see that in the case of self-improvement, expected utility maximization idealizes away too much. An agent that can literally maximize expected utility is&nbsp;<em>already</em>&nbsp;reasoning optimally; it may lack information about its environment, but it can only fix this problem by observing the external world, not by improving its own reasoning processes.</p>\n<p>A particularly illustrative example of the mismatch between the classical theory and the problem of Vingean reflection is provided by the standard technique of&nbsp;<em>backward induction</em>, which finds the optimal policy of an agent facing a sequential decision problem by considering every node in the agent's entire decision tree. Backward induction starts with the leaves, figuring out the action an optimal agent would take in the last timestep (for every possible history of what happened in the previous timesteps). It then proceeds to compute how an optimal agent would behave in the second-to-last timestep, given the behavior in the last timestep, and so on backward to the root of the decision tree.</p>\n<p>A self-improving agent is supposed to become more intelligent as time goes on. An agent using backward induction to choose its action, however, would have to compute its exact actions in every situation it might face in the future in the very first timestep&mdash;but if it is able to do that, its initial version could hardly be called less intelligent than the later ones!</p>\n<p>Since we are interested in theoretical understanding, the reason we see this as a problem is not that backward induction is impractical as an implementation technique. For example, we may not actually be able to run an agent which uses backward induction (since this requires effort exponential in the number of timesteps), but it can still be useful to ask how such an agent would behave, say in a situation where it may have an incentive to manipulate its human operators (Soares 2015). Rather, the problem is that we are trying to understand conceptually how an agent can reason about the behavior of a more intelligent successor, and an \"idealized\" model that requires the original agent to already be as smart as its successors seems to idealize away the very issue we are trying to investigate.</p>\n<p>The programmers of the famous chess program Deep Blue, for example, couldn't have evaluated different heuristics by predicting, in their own heads, where each heuristic would make Deep Blue move in every possible situation; if they had been able to do so, they would have been able to play world-class chess themselves. But this does not imply that they knew nothing about Deep Blue's operation: their abstract knowledge of the code allowed them to know that Deep Blue was trying to win the game rather than to lose it, for example.</p>\n<p>Like Deep Blue's programmers, any artificial agent reasoning about smarter successors will have to do so using abstract reasoning, rather than by computing out what these successors would do in every possible situation. Yudkowsky and Herreshoff (2013) call this observation the&nbsp;<em>Vingean principle</em>, and it seems to us that progress on Vingean reflection will require formal models that implement this principle, instead of idealizing the problem away.</p>\n<p>This is not to say that expected utility maximization has no role to play in the study of Vingean reflection. Intuitively, the reason the classical framework is unsuitable is that it demands logical omniscience: It assumes that although an agent may be uncertain about its environment, it must have perfect knowledge of all mathematical facts, such as which of two algorithms is more efficient on a given problem or which of two bets leads to a higher expected payoff under a certain computable (but intractable) probability distribution. Real agents, on the other hand, must deal with&nbsp;<em>logical uncertainty</em>&nbsp;(Soares and Fallenstein 2015). But many proposals for dealing with uncertainty about mathematical facts involve assigning probabilities to them, which might make it possible to maximize expected utility with respect to the resulting probability distribution.</p>\n<p>However, while there is some existing work on formal models of logical uncertainty (see Soares and Fallenstein [2015] for an overview), none of the approaches the authors are aware of are models of abstract reasoning. It is clear that any agent performing Vingean reflection will need to have some way of dealing with logical uncertainty, since it will have to reason about the behavior of computer programs it cannot run (in particular, future versions of itself). At present, however, formal models of logical uncertainty do not yet seem up to the task of studying abstract reasoning about more intelligent successors.</p>\n<p>In this paper, we review a body of work which instead considers agents that use formal proofs to reason about their successors, an approach first proposed by Yudkowsky and Herreshoff (2013). In particular, following these authors, we consider agents which will only perform actions (such as self-modifications) if they can prove that these actions are, in some formal sense, \"safe''. We do not argue that this is a realistic way for smarter-than-human agents to reason about potential actions; rather, formal proofs seem to be the best formal model of abstract reasoning available at present, and hence currently the most promising vehicle for studying Vingean reflection.</p>\n<p>There is, of course, no guarantee that results obtained in this setting will generalize to whatever forms of reasoning realistic artificial agents will employ. However, there is some reason for optimism: at least one such result (the&nbsp;<em>procrastination paradox</em>&nbsp;[Yudkowsky 2013], discussed in Section 4) both has an intuitive interpretation that makes it seem likely to be relevant beyond the domain of formal proofs, and has been shown to apply to one existing model of self-referential reasoning under logical uncertainty (Fallenstein 2014b).</p>\n<p>The study of Vingean reflection in a formal logic framework also has merit in its own right. While formal logic is not a good tool for reasoning about a complex environment, it is a useful tool for reasoning about the properties of computer programs. Indeed, when humans require extremely high confidence in a computer program, they often resort to systems based on formal logic, such as model checkers and theorem provers (US DoD 1985; UK MoD 1991). Smarter-than-human machines attempting to gain high confidence in a computer program may need to use similar techniques. While smarter-than-human agents must ultimately reason under logical uncertainty, there is some reason to expect that high-confidence logically uncertain reasoning about computer programs will require something akin to formal logic.</p>\n<p>The remainder of this paper is structured as follows. In the next section, we discuss in more detail the idea of requiring an agent to produce formal proofs that its actions are safe, and discuss a problem that arises in this context, the&nbsp;<em>L&ouml;bian obstacle</em>&nbsp;(Yudkowsky and Herreshoff 2013): Due to G&ouml;del's second incompleteness theorem, an agent using formal proofs cannot trust the reasoning of future versions using the same proof system. In Section 4, we discuss the&nbsp;<em>procrastination paradox</em>, an intuitive example of what can go wrong in a system that trusts its own reasoning too much. In Section 5, we introduce a concrete toy model of self-rewriting agents, and discuss the L&ouml;bian obstacle in this context. Section 6 reviews partial solutions to this problem, and Section 7 concludes.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 1, "NrvXXL3iGjjxu5B7d": 1, "wBoHTJs9iQzczNtW3": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iWwaJ5wPGLZJWjPAL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 36, "extendedScore": null, "score": 0.000103, "legacy": true, "legacyId": "27925", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T01:54:30.945Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, January 16-31", "slug": "group-rationality-diary-january-16-31", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:35.915Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uqTmqJAfW5JN3rDjY/group-rationality-diary-january-16-31", "pageUrlRelative": "/posts/uqTmqJAfW5JN3rDjY/group-rationality-diary-january-16-31", "linkUrl": "https://www.lesswrong.com/posts/uqTmqJAfW5JN3rDjY/group-rationality-diary-january-16-31", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20January%2016-31&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20January%2016-31%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuqTmqJAfW5JN3rDjY%2Fgroup-rationality-diary-january-16-31%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20January%2016-31%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuqTmqJAfW5JN3rDjY%2Fgroup-rationality-diary-january-16-31", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuqTmqJAfW5JN3rDjY%2Fgroup-rationality-diary-january-16-31", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<h2 style=\"margin: 0px 0px 0.75em; color: #333333; font-size: 1.3333em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"line-height: 24.2727279663086px; font-size: small; color: #000000; font-weight: normal;\">This is the public group rationality diary for January 16-31.</span></h2>\n<div id=\"entry_t3_l4c\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px; line-height: 18px;\">\n<div class=\"md\">\n<div id=\"entry_t3_l1z\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<blockquote style=\"line-height: 24.2727279663086px;\">\n<p style=\"margin: 0px 0px 1em;\">It's a place to record and chat about it if you have done, or are actively doing, things like:&nbsp;</p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating.</p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Previous diary:&nbsp;<a href=\"/lw/lgv/group_rationality_diary_january_115/\">January 1-15</a></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\">Next diary: <a href=\"/r/discussion/lw/ln6/group_rationality_diary_february_114/\">February 1-14</a></p>\n<p style=\"margin: 0px 0px 1em; line-height: 24.2727279663086px;\"><a style=\"color: #8a8a8b;\" href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality diaries archive</a></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uqTmqJAfW5JN3rDjY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "27926", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tmDoJPSkyqkHgYABW", "yHL9gCFpbXNFABAqr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T03:51:53.875Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA\u2014Keep Your Identity Small", "slug": "meetup-west-la-keep-your-identity-small", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OpenThreadGuy", "createdAt": "2012-01-16T00:21:00.929Z", "isAdmin": false, "displayName": "OpenThreadGuy"}, "userId": "qe9iZjEvuKegW4Twy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MBu74ZTTxMZ9wqL6j/meetup-west-la-keep-your-identity-small", "pageUrlRelative": "/posts/MBu74ZTTxMZ9wqL6j/meetup-west-la-keep-your-identity-small", "linkUrl": "https://www.lesswrong.com/posts/MBu74ZTTxMZ9wqL6j/meetup-west-la-keep-your-identity-small", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%E2%80%94Keep%20Your%20Identity%20Small&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%E2%80%94Keep%20Your%20Identity%20Small%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBu74ZTTxMZ9wqL6j%2Fmeetup-west-la-keep-your-identity-small%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%E2%80%94Keep%20Your%20Identity%20Small%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBu74ZTTxMZ9wqL6j%2Fmeetup-west-la-keep-your-identity-small", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMBu74ZTTxMZ9wqL6j%2Fmeetup-west-la-keep-your-identity-small", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/191'>West LA\u2014Keep Your Identity Small</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 January 2015 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">11066 Santa Monica Blvd, Los Angeles, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>How to Find Us</strong>: Go into <a href=\"https://www.google.com/maps/place/Del+Taco/@34.047464,-118.443286,974m/data=!3m2!1e3!4b1!4m2!3m1!1s0x80c2bb777277de93:0x99f58a53b04bb89c?hl=en\" rel=\"nofollow\">this</a> Del Taco. We will be in the back room if possible.</p>\n\n<p><strong>Parking</strong> is free in the lot out front or on the street nearby.</p>\n\n<p><strong>Discussion</strong>: We often repeat the mantra \"Keep your identity small,\" and for good reason. What is that reason? Well, maybe you should show up to this meetup and find out. Or read the recommended reading. You know, either way. Preferably both</p>\n\n<p><strong>Recommended Reading</strong>:</p>\n\n<ul>\n<li><strong><a href=\"http://www.paulgraham.com/identity.html\" rel=\"nofollow\">Keep Your Identity Small</a></strong> by Paul Graham</li>\n<li><strong><a href=\"http://lesswrong.com/lw/4e/cached_selves/\">Cached Selves</a></strong></li>\n<li><a href=\"http://www.overcomingbias.com/2009/08/a-theory-of-identity.html\">A Theory of Identity</a></li>\n<li><a href=\"http://lesswrong.com/lw/2g0/the_identity_hack/\">The Identity Hack</a>, <a href=\"http://lesswrong.com/lw/8gv/the_curse_of_identity/\">The Curse of Identity</a></li>\n<li><a href=\"http://www.spencergreenberg.com/2011/09/your-beliefs-as-a-temple/\" rel=\"nofollow\">Your Beliefs as Temple</a></li>\n<li><a href=\"http://casnocha.com/2008/12/easier-to-deny-or-rationalize-behavior-than-evolve-your-own-identity.html\" rel=\"nofollow\">Easier to Deny or Rationalize Behavior Than Evolve Your Own Identity</a></li>\n<li><a href=\"http://lesswrong.com/lw/o4/leave_a_line_of_retreat/\">Leave a Line of Retreat</a></li>\n</ul>\n\n<p><em>No prior exposure to Less Wrong is required</em>; this will be generally accessible. And remember, keep your secret identity small.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/191'>West LA\u2014Keep Your Identity Small</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MBu74ZTTxMZ9wqL6j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 2.376703308706302e-06, "legacy": true, "legacyId": "27927", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Keep_Your_Identity_Small\">Discussion article for the meetup : <a href=\"/meetups/191\">West LA\u2014Keep Your Identity Small</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 January 2015 07:00:00PM (-0800)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">11066 Santa Monica Blvd, Los Angeles, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>How to Find Us</strong>: Go into <a href=\"https://www.google.com/maps/place/Del+Taco/@34.047464,-118.443286,974m/data=!3m2!1e3!4b1!4m2!3m1!1s0x80c2bb777277de93:0x99f58a53b04bb89c?hl=en\" rel=\"nofollow\">this</a> Del Taco. We will be in the back room if possible.</p>\n\n<p><strong>Parking</strong> is free in the lot out front or on the street nearby.</p>\n\n<p><strong>Discussion</strong>: We often repeat the mantra \"Keep your identity small,\" and for good reason. What is that reason? Well, maybe you should show up to this meetup and find out. Or read the recommended reading. You know, either way. Preferably both</p>\n\n<p><strong>Recommended Reading</strong>:</p>\n\n<ul>\n<li><strong><a href=\"http://www.paulgraham.com/identity.html\" rel=\"nofollow\">Keep Your Identity Small</a></strong> by Paul Graham</li>\n<li><strong><a href=\"http://lesswrong.com/lw/4e/cached_selves/\">Cached Selves</a></strong></li>\n<li><a href=\"http://www.overcomingbias.com/2009/08/a-theory-of-identity.html\">A Theory of Identity</a></li>\n<li><a href=\"http://lesswrong.com/lw/2g0/the_identity_hack/\">The Identity Hack</a>, <a href=\"http://lesswrong.com/lw/8gv/the_curse_of_identity/\">The Curse of Identity</a></li>\n<li><a href=\"http://www.spencergreenberg.com/2011/09/your-beliefs-as-a-temple/\" rel=\"nofollow\">Your Beliefs as Temple</a></li>\n<li><a href=\"http://casnocha.com/2008/12/easier-to-deny-or-rationalize-behavior-than-evolve-your-own-identity.html\" rel=\"nofollow\">Easier to Deny or Rationalize Behavior Than Evolve Your Own Identity</a></li>\n<li><a href=\"http://lesswrong.com/lw/o4/leave_a_line_of_retreat/\">Leave a Line of Retreat</a></li>\n</ul>\n\n<p><em>No prior exposure to Less Wrong is required</em>; this will be generally accessible. And remember, keep your secret identity small.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Keep_Your_Identity_Small1\">Discussion article for the meetup : <a href=\"/meetups/191\">West LA\u2014Keep Your Identity Small</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA\u2014Keep Your Identity Small", "anchor": "Discussion_article_for_the_meetup___West_LA_Keep_Your_Identity_Small", "level": 1}, {"title": "Discussion article for the meetup : West LA\u2014Keep Your Identity Small", "anchor": "Discussion_article_for_the_meetup___West_LA_Keep_Your_Identity_Small1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BHYBdijDcAKQ6e45Z", "wTrgm2meHePfn3ykT", "tAXrD8Y6hcJ8dt6Nt", "3XgYbghWruBMrPTAL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T06:10:06.483Z", "modifiedAt": null, "url": null, "title": "An example and discussion of extension neglect", "slug": "an-example-and-discussion-of-extension-neglect", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:26.100Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "emr", "createdAt": "2014-12-12T23:27:47.248Z", "isAdmin": false, "displayName": "emr"}, "userId": "bxGFENDCWWL8pCRWH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/svjC22YAkcydMoS4Q/an-example-and-discussion-of-extension-neglect", "pageUrlRelative": "/posts/svjC22YAkcydMoS4Q/an-example-and-discussion-of-extension-neglect", "linkUrl": "https://www.lesswrong.com/posts/svjC22YAkcydMoS4Q/an-example-and-discussion-of-extension-neglect", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20example%20and%20discussion%20of%20extension%20neglect&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20example%20and%20discussion%20of%20extension%20neglect%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsvjC22YAkcydMoS4Q%2Fan-example-and-discussion-of-extension-neglect%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20example%20and%20discussion%20of%20extension%20neglect%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsvjC22YAkcydMoS4Q%2Fan-example-and-discussion-of-extension-neglect", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsvjC22YAkcydMoS4Q%2Fan-example-and-discussion-of-extension-neglect", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 360, "htmlBody": "<p>I recently used an automatic tracker to learn how I was spending my time online. I learned that my perceptions were systemically biased: I spend less time than I thought on purely non-productive sites, and far more time on sites that are quasi-productive. <br /><br />For example, I felt that I was spending too much time reading the news, but I learned that I spend hardly time doing so. I didn't feel that I was spending much time reading Hacker News, but I was spending a huge amount of time there!<br /><br />Is this a specific case of a more general error? <br /><br />A general framing: \"Paying too much attention to the grouping whose items have the most extreme quality, when the value of focusing on this grouping is eclipsed by the value of focusing on a larger grouping of less extreme items\".</p>\n<p>So in this case, once I had formed the desire to be more productive, I overestimated how much potential productive time I could gain by focusing on those sites that I felt were maximally non-productive, and underestimated the potential of focusing on marginally more productive sites.</p>\n<p>In pseudo-technical terms: We think about items in groups. But then we think of the total value of a group as being closer to <em>average_value</em> than to<em> average_value * size_of_group</em>.</p>\n<p>This falls under the category of <a href=\"http://en.wikipedia.org/wiki/Extension_neglect\">Extension Neglect</a>, which includes errors caused by ignoring the size of a set. Other patterns in this category are:</p>\n<ul>\n<li>Base rate neglect: Inferring the category of an item as if all categories were the same size. </li>\n<li>The peak-end rule: Giving the value of the ordered group as a function of <em>max_value</em> and <em>end_value</em>.</li>\n<li>Not knowing how set size interacts with randomness.</li>\n</ul>\n<p>For the error given above, some specific examples might be:</p>\n<ul>\n<li>Health: Focusing too much on eating desert at your favorite restaurant; and not enough on eating pizza three times a week. </li>\n<li>Love: Fights and romantic moments; daily interaction.</li>\n<li>Stress: Public speaking; commuting</li>\n<li>Ethics: Improbable dilemmas; reducing suffering (or doing anything externally visible)</li>\n<li>Crime: Serial killers; domestic violence</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "svjC22YAkcydMoS4Q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 17, "extendedScore": null, "score": 2.377039191763285e-06, "legacy": true, "legacyId": "27928", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T09:36:33.983Z", "modifiedAt": null, "url": null, "title": "Learn Three Things Every Day", "slug": "learn-three-things-every-day", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.045Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "helltank", "createdAt": "2013-12-21T02:40:37.538Z", "isAdmin": false, "displayName": "helltank"}, "userId": "JDXAeDsvr2SFo4u29", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kRQCwkk8B2wA7jyWP/learn-three-things-every-day", "pageUrlRelative": "/posts/kRQCwkk8B2wA7jyWP/learn-three-things-every-day", "linkUrl": "https://www.lesswrong.com/posts/kRQCwkk8B2wA7jyWP/learn-three-things-every-day", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Learn%20Three%20Things%20Every%20Day&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALearn%20Three%20Things%20Every%20Day%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkRQCwkk8B2wA7jyWP%2Flearn-three-things-every-day%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Learn%20Three%20Things%20Every%20Day%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkRQCwkk8B2wA7jyWP%2Flearn-three-things-every-day", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkRQCwkk8B2wA7jyWP%2Flearn-three-things-every-day", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 816, "htmlBody": "<p>In the Game of Thrones series, there is an ongoing side plot in which a character is trained by a secretive organization to become an assassin. As part of her training, one of the senior assassins demands that she report to him three new things she has learnt every day. by making a natural inference from the title of the article, you might infer or assume that I am going to suggest that you do the same. I am, but with a crucial difference.</p>\n<p>You see, my standards are higher than the Faceless Men. Instead of filling up your list of learnt things with only marginally useful things like gossip or other insignificant things, I am going to take it up a notch and demand that you learn three USEFUL things a day. This is, of course, an entirely self-enforced challenge, and I'll let you decide on the definition of useful. Personally, I use the condition of [&gt;50% probability that X will enrich my life in a significant way], but if you want, you can make up your own criteria for \"useful\".</p>\n<p>This may seem trite or useless, or even obvious(if you're an eager and fast learner, like most LWers). Now stop and think hard. For the entire of the past 30 days, have you ever had a day or two where you just slacked off and didn't learn much? Maybe it was New Year's Day, or your birthday, and instead of learning you decided to spend the whole day partying. Perhaps it was just a lazy Sunday and you couldn't be bothered to learn something and instead just spent the day playing video games or mountain skiing(although there are useful things to be learnt from those, too) or whatever you like to do in your spare time.</p>\n<p>I haven't taken an official survey, but my belief(and do correct me if I am very wrong about this) is that on average there's at least one day in thirty in which you did not learn thirty new, useful things. I would consider that day as pretty much wasted from a truth-seeker's point of view. You did not move forward in your quest for knowledge, you did not sharpen your rationality skills(and they always need sharpening, no matter how good you are) and you did not become stronger mentally. That's 12 days in a year, which is more than enough for the average LWer to pick up at least one new skill: say, learning about game theory, to pick a random example. In that year, you have had a chance to gain the knowledge of game theory, and you threw it away.</p>\n<p>The point of this exercise is not to make you sweat and do a \"mental workout\" every day. The point is to prevent days that are wasted. There is a nearly infinite amount of knowledge to collect, and we do not have nearly infinite time. Maybe it's just my Asian mentality speaking here, but every second counts and you are in effect racing against time to gain as much knowledge as possible and put it to good use before you die.</p>\n<p>When doing this, you are not allowed to merely work on your projects, unless they also teach you something. If you are a non-programmer, and you begin learning Python, that's a new thing. If you're already fluent in Python, and you program in Python, that's not counted. With one exception: if you learn something through programming(maybe you thought up a nifty new way to sanitize user inputs while working on a database) then that counts. If you're a writer, and you write, that doesn't count. Unless, of course, by writing you learn things about worldbuilding, or plot development, or character development, that you didn't know before. Yes, this counts, even though it's not directly rationality-related, because it enriches your life: it helps you achieve your writing goals(that's also a good condition for usefulness, and is a good example of instrumental rationality).</p>\n<p>Today, I've learn about the concept of centered worlds, I have learnt about the policy of indifference in similar worlds and I have learnt the technique of \"super-rationality\" as a means to predict the behavior of other agents in acausal trade. What have you learnt today?</p>\n<p>Do it now. Don't wait, or you will waste this day, which is 86400 countable seconds in which to learn things. In fact, I've given you a head start today, because you can count this article in your list of learnt things.</p>\n<p>Good luck to you. Let's learn together.</p>\n<p>[This is my first post on LW and I hope that I taught you something interesting and useful. Again, I'm new to posting, so if I violated some unspoken rule of etiquette, or if you think this post is obvious and shitty, feel free to vote me down. But do leave a comment explaining why you did, so I can add it to my list of learnt things.]</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kRQCwkk8B2wA7jyWP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": -8, "extendedScore": null, "score": -2.7e-05, "legacy": true, "legacyId": "27930", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T11:17:23.647Z", "modifiedAt": null, "url": null, "title": "Slides online from \"The Future of AI: Opportunities and Challenges\"", "slug": "slides-online-from-the-future-of-ai-opportunities-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:31.935Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TJSRiqBJxbcwEo7AR/slides-online-from-the-future-of-ai-opportunities-and", "pageUrlRelative": "/posts/TJSRiqBJxbcwEo7AR/slides-online-from-the-future-of-ai-opportunities-and", "linkUrl": "https://www.lesswrong.com/posts/TJSRiqBJxbcwEo7AR/slides-online-from-the-future-of-ai-opportunities-and", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Slides%20online%20from%20%22The%20Future%20of%20AI%3A%20Opportunities%20and%20Challenges%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASlides%20online%20from%20%22The%20Future%20of%20AI%3A%20Opportunities%20and%20Challenges%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTJSRiqBJxbcwEo7AR%2Fslides-online-from-the-future-of-ai-opportunities-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Slides%20online%20from%20%22The%20Future%20of%20AI%3A%20Opportunities%20and%20Challenges%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTJSRiqBJxbcwEo7AR%2Fslides-online-from-the-future-of-ai-opportunities-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTJSRiqBJxbcwEo7AR%2Fslides-online-from-the-future-of-ai-opportunities-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 108, "htmlBody": "<p>In the first weekend of this year, the Future of Life institute hosted a landmark conference in Puerto Rico: \"<a href=\"http://futureoflife.org/misc/ai_conference\">The Future of AI: Opportunities and Challenges</a>\". The conference was unusual in that it was not made public until it was over, and the discussions were under <a href=\"https://en.wikipedia.org/wiki/Chatham_House_Rule\">Chatham House rules</a>. The&nbsp;<a href=\"http://futureoflife.org/misc/ai_conference\">slides from the conference</a>&nbsp;are now available. The <a href=\"http://futureoflife.org/PDF/attendees.pdf\">list of attenders</a> includes a great many famous names as well as lots of names familiar to those of us on Less Wrong: Elon Musk, Sam Harris, Margaret Boden, Thomas Dietterich, all three DeepMind founders, and many more.</p>\n<p>This is shaping up to be another extraordinary year for AI risk concerns going mainstream!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TJSRiqBJxbcwEo7AR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 21, "extendedScore": null, "score": 2.377786269947243e-06, "legacy": true, "legacyId": "27931", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T16:08:19.223Z", "modifiedAt": null, "url": null, "title": "LINK: Guinea worm disease close to eradication", "slug": "link-guinea-worm-disease-close-to-eradication", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:26.575Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "polymathwannabe", "createdAt": "2013-08-29T03:03:37.800Z", "isAdmin": false, "displayName": "polymathwannabe"}, "userId": "NkxHWoA85iw2PpxSt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XpXcJoWfpPDNWTr4H/link-guinea-worm-disease-close-to-eradication", "pageUrlRelative": "/posts/XpXcJoWfpPDNWTr4H/link-guinea-worm-disease-close-to-eradication", "linkUrl": "https://www.lesswrong.com/posts/XpXcJoWfpPDNWTr4H/link-guinea-worm-disease-close-to-eradication", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20Guinea%20worm%20disease%20close%20to%20eradication&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20Guinea%20worm%20disease%20close%20to%20eradication%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXpXcJoWfpPDNWTr4H%2Flink-guinea-worm-disease-close-to-eradication%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20Guinea%20worm%20disease%20close%20to%20eradication%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXpXcJoWfpPDNWTr4H%2Flink-guinea-worm-disease-close-to-eradication", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXpXcJoWfpPDNWTr4H%2Flink-guinea-worm-disease-close-to-eradication", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<p>The <em>disease</em>, that is, maybe not the worm itself. Anyway, Team Human scores its second point against Team Disease:</p>\n<p>http://www.sciencealert.com/guys-we-re-really-close-to-eradicating-the-second-disease-ever-from-the-planet</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XpXcJoWfpPDNWTr4H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "27932", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T17:11:53.030Z", "modifiedAt": null, "url": null, "title": "New LW Meetup: Dallas", "slug": "new-lw-meetup-dallas", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dwcGzSbv2nPC3mTgb/new-lw-meetup-dallas", "pageUrlRelative": "/posts/dwcGzSbv2nPC3mTgb/new-lw-meetup-dallas", "linkUrl": "https://www.lesswrong.com/posts/dwcGzSbv2nPC3mTgb/new-lw-meetup-dallas", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20LW%20Meetup%3A%20Dallas&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20LW%20Meetup%3A%20Dallas%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdwcGzSbv2nPC3mTgb%2Fnew-lw-meetup-dallas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20LW%20Meetup%3A%20Dallas%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdwcGzSbv2nPC3mTgb%2Fnew-lw-meetup-dallas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdwcGzSbv2nPC3mTgb%2Fnew-lw-meetup-dallas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 586, "htmlBody": "<p><strong>This summary was posted to LW Main on January 9th. The following week's summary is <a href=\"/lw/ljx/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>New meetups (or meetups with a hiatus of more than a year) are happening in:</p>\n<ul>\n<li><a href=\"/meetups/18l\">Dallas, TX:&nbsp;<span class=\"date\">10 January 2015 01:00PM</span></a></li>\n<li><a href=\"/meetups/18c\">Paris LW Meetup - LHC Exhibit:&nbsp;<span class=\"date\">17 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/18f\">San Francisco Meetup:&nbsp;<span class=\"date\">12 January 2015 06:00PM</span></a></li>\n</ul>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<div id=\"siteTable\" class=\"sitetable\" style=\"clear: none;\">\n<li><a href=\"/meetups/186\">Bangalore Meetup:&nbsp;<span class=\"date\">10 January 2015 11:02AM</span></a></li>\n<li><a href=\"/meetups/15w\">European Community Weekend 2015:&nbsp;<span class=\"date\">12 June 2015 12:00PM</span></a></li>\n<li><a href=\"/meetups/188\">[Frankfurt] New Year meetup Frankfurt:&nbsp;<span class=\"date\">11 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/187\">[Munich] January Meetup in Munich:&nbsp;<span class=\"date\">17 January 2015 03:00PM</span></a></li>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<li><a href=\"/meetups/18a\">Warsaw January Meetup:&nbsp;<span class=\"date\">13 January 2015 06:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX - Caffe Medici:&nbsp;<span class=\"date\">10 January 2026 01:30PM</span></a></li>\n<li><a href=\"/meetups/18p\">Brussels - Mindfulness and mental habits:&nbsp;<span class=\"date\">10 January 2015 01:00PM</span></a></li>\n<li><a href=\"/meetups/18q\">Moscow LW lecture centre meetup: The New Foundation:&nbsp;<span class=\"date\">25 January 2015 02:00PM</span></a></li>\n<li><a href=\"/meetups/18m\">Sydney Meetup - January:&nbsp;<span class=\"date\">28 January 2015 06:30PM</span></a></li>\n<li><a href=\"/meetups/18o\">Sydney Rationality Dojo - How bad statistics can ruin your life:&nbsp;<span class=\"date\">01 February 2015 04:00PM</span></a></li>\n<li><a href=\"/meetups/18e\">Vienna:&nbsp;<span class=\"date\">24 January 2015 03:00PM</span></a></li>\n<li><a href=\"/meetups/18n\">Washington, D.C.: Meta Meetup:&nbsp;<span class=\"date\">11 January 2015 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\">Berlin</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Boston.2C_MA\">Boston</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Brussels.2C_Belgium\">Brussels</a></strong><strong>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Buffalo.2C_NY\">Buffalo</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Canberra\">Canberra</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Columbus.2C_OH\">Columbus</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Moscow.2C_Russia\">Moscow</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Philadelphia.2C_PA\">Philadelphia</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Research_Triangle.2C_NC_.28Raleigh.2FDurham.2FChapel_Hill.29\">Research Triangle NC</a>,</strong><strong>&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Sydney\">Sydney</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a></strong><strong><strong>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington DC</strong></a></strong>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.</p>\n<p><a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview is posted on the front page every Friday. These are an attempt to collect information on all the meetups happening in upcoming weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll also have the benefit of having your meetup mentioned in a weekly overview. These overview posts are moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong><strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong><strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cincinnati</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Cleveland</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> </strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tel_Aviv.2C_Israel\">Tel Aviv</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Warsaw.2C_Poland\">Warsaw</a></strong><strong>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dwcGzSbv2nPC3mTgb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2.3786486265516247e-06, "legacy": true, "legacyId": "27888", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Zwssk8AdR8cFvkWvy", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-16T23:38:35.755Z", "modifiedAt": null, "url": null, "title": "... And Everyone Loses Their Minds", "slug": "and-everyone-loses-their-minds", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:32.630Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ritalin", "createdAt": "2012-05-01T18:00:25.863Z", "isAdmin": false, "displayName": "Ritalin"}, "userId": "ACGKS9W7iQQywxrWW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P6vFmjRkHwGAhJGGE/and-everyone-loses-their-minds", "pageUrlRelative": "/posts/P6vFmjRkHwGAhJGGE/and-everyone-loses-their-minds", "linkUrl": "https://www.lesswrong.com/posts/P6vFmjRkHwGAhJGGE/and-everyone-loses-their-minds", "postedAtFormatted": "Friday, January 16th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20...%20And%20Everyone%20Loses%20Their%20Minds&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A...%20And%20Everyone%20Loses%20Their%20Minds%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP6vFmjRkHwGAhJGGE%2Fand-everyone-loses-their-minds%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=...%20And%20Everyone%20Loses%20Their%20Minds%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP6vFmjRkHwGAhJGGE%2Fand-everyone-loses-their-minds", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP6vFmjRkHwGAhJGGE%2Fand-everyone-loses-their-minds", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 272, "htmlBody": "<p>Chris Nolan's Joker is a very clever guy, almost Monroesque in his ability to identify hypocrisy and inconsistency. <a href=\"https://www.youtube.com/watch?v=h-gf29nuYYA\">One of his most interesting scenes</a> in the film has him point out how people estimate horrible things differently depending on whether they're part of what's \"normal\", what's \"expected\", rather than on how inherently horrifying they are, or how many people are involved.</p>\n<p>Soon <a href=\"http://knowyourmeme.com/memes/everyone-loses-their-minds\">people extrapolated this observation</a> to other such apparent inconsistencies in human judgment, where a behaviour that once was acceptable, with a simple tweak or change in context, becomes the subject of a much more serious reaction.</p>\n<p>I think there's rationalist merit in giving these inconsistencies a serious look. I intuit that there's some sort of underlying pattern to them, something that makes psychological sense, in the roundabout way that most irrational things do. I think that much good could come out of figuring out what that root cause is, and how to predict this effect and manage it.</p>\n<p>Phenomena that come to mind, are, for instance, from an Effective Altruism point of view, the expenses incurred in counter-terrorism (including some wars that were very expensive in treasure and lives), and the number of lives said expenses save, compared with the number of lives that could be saved by spending that same amount into improving road safety, increasing public helathcare expense where it would do the most good, building better lightning rods (<a href=\"http://reason.com/archives/2011/09/06/how-scared-of-terrorism-should\">in the USA you're four times more likely to be struck by thunder than by terrorists</a>), or legalizing drugs.</p>\n<p>What do y'all think? Why do people have their priorities all jumbled-up? How can we predict these effects? How can we work around them?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P6vFmjRkHwGAhJGGE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 21, "extendedScore": null, "score": 8.2e-05, "legacy": true, "legacyId": "27934", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2015-01-17T16:03:57.849Z", "modifiedAt": null, "url": null, "title": "LINK: Diseases not sufficiently researched", "slug": "link-diseases-not-sufficiently-researched", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:34.904Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "polymathwannabe", "createdAt": "2013-08-29T03:03:37.800Z", "isAdmin": false, "displayName": "polymathwannabe"}, "userId": "NkxHWoA85iw2PpxSt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yui83PK68MX3s2hkv/link-diseases-not-sufficiently-researched", "pageUrlRelative": "/posts/yui83PK68MX3s2hkv/link-diseases-not-sufficiently-researched", "linkUrl": "https://www.lesswrong.com/posts/yui83PK68MX3s2hkv/link-diseases-not-sufficiently-researched", "postedAtFormatted": "Saturday, January 17th 2015", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20Diseases%20not%20sufficiently%20researched&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20Diseases%20not%20sufficiently%20researched%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyui83PK68MX3s2hkv%2Flink-diseases-not-sufficiently-researched%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20Diseases%20not%20sufficiently%20researched%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyui83PK68MX3s2hkv%2Flink-diseases-not-sufficiently-researched", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyui83PK68MX3s2hkv%2Flink-diseases-not-sufficiently-researched", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 97, "htmlBody": "<p><a href=\"http://io9.com/this-chart-shows-the-worst-diseases-that-dont-get-enoug-1680028725\">This Chart Shows The Worst Diseases That Don't Get Enough Research Money</a></p>\n<p>We have already covered this topic several times on LW, but what prompted me to link this was this remark:</p>\n<blockquote>\n<p><span style=\"color: #222222; font-family: Georgia, serif; font-size: 15px; line-height: 24px;\">Of course, where research dollars flow isn't &mdash;and shouldn't be&mdash; dictated simply in terms of which diseases lay claim to the most years, but also by, perhaps most importantly, where researchers see the most potential for a breakthrough.</span></p>\n</blockquote>\n<p><span style=\"font-family: mceinline;\"><span style=\"font-family: mceinline;\">[Edit: a former, dumber version of me had asked, \"I wonder what criterion the author would prefer,\" before the correct syntax of the sentence was pointed out to me.]</span></span></p>\n<p>Opinions?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yui83PK68MX3s2hkv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "27935", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}