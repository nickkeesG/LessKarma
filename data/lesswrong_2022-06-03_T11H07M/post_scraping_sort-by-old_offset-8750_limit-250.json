{"results": [{"createdAt": null, "postedAt": "2013-04-10T04:20:56.258Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Rationality is Systematized Winning", "slug": "seq-rerun-rationality-is-systematized-winning", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C3nhZ8amddMfMKv8x/seq-rerun-rationality-is-systematized-winning", "pageUrlRelative": "/posts/C3nhZ8amddMfMKv8x/seq-rerun-rationality-is-systematized-winning", "linkUrl": "https://www.lesswrong.com/posts/C3nhZ8amddMfMKv8x/seq-rerun-rationality-is-systematized-winning", "postedAtFormatted": "Wednesday, April 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Rationality%20is%20Systematized%20Winning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Rationality%20is%20Systematized%20Winning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC3nhZ8amddMfMKv8x%2Fseq-rerun-rationality-is-systematized-winning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Rationality%20is%20Systematized%20Winning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC3nhZ8amddMfMKv8x%2Fseq-rerun-rationality-is-systematized-winning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC3nhZ8amddMfMKv8x%2Fseq-rerun-rationality-is-systematized-winning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 189, "htmlBody": "<p>Today's post, <a href=\"/lw/7i/rationality_is_systematized_winning/\">Rationality is Systematized Winning</a> was originally published on 03 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries#Rationality_is_Systematized_Winning\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The idea behind the statement \"Rationalists should win\" is not that rationality will make you invincible. It means that if someone who isn't behaving according to your idea of rationality is outcompeting you, predictably and consistently, you should consider that you're not the one being rational.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h65/seq_rerun_selecting_rationalist_groups/\">Selecting Rationalist Groups</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C3nhZ8amddMfMKv8x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.1641321482000772e-06, "legacy": true, "legacyId": "22263", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4ARtkT3EYox3THYjF", "tJvNKsygrHoWSj9N5", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-10T13:59:19.201Z", "modifiedAt": null, "url": null, "title": "\"I know what she has to offer already\" is almost always false", "slug": "i-know-what-she-has-to-offer-already-is-almost-always-false", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:37.695Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/T2F6Rw5MgLmgQ2bqN/i-know-what-she-has-to-offer-already-is-almost-always-false", "pageUrlRelative": "/posts/T2F6Rw5MgLmgQ2bqN/i-know-what-she-has-to-offer-already-is-almost-always-false", "linkUrl": "https://www.lesswrong.com/posts/T2F6Rw5MgLmgQ2bqN/i-know-what-she-has-to-offer-already-is-almost-always-false", "postedAtFormatted": "Wednesday, April 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22I%20know%20what%20she%20has%20to%20offer%20already%22%20is%20almost%20always%20false&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22I%20know%20what%20she%20has%20to%20offer%20already%22%20is%20almost%20always%20false%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FT2F6Rw5MgLmgQ2bqN%2Fi-know-what-she-has-to-offer-already-is-almost-always-false%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22I%20know%20what%20she%20has%20to%20offer%20already%22%20is%20almost%20always%20false%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FT2F6Rw5MgLmgQ2bqN%2Fi-know-what-she-has-to-offer-already-is-almost-always-false", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FT2F6Rw5MgLmgQ2bqN%2Fi-know-what-she-has-to-offer-already-is-almost-always-false", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1080, "htmlBody": "<p>Interacting with people is very hard for some, for others it comes naturally, and for a third group, usually called extroverts, it is the very way in which they recharge batteries.</p>\n<p>&nbsp;</p>\n<p>Oddly, after spending years on the far end of the curve's tail of how much I try to interact with people, I have noticed a pattern, in almost any group, that seems very unfruitful, and would do well to go extinct. I could try and devise a general version of it, but I'll only mention people who are curiosity driven or very goal oriented.Obviously, I'm deploying an stereotypical approximation, not a double blind large N study.</p>\n<p>For those two groups, when two new people get to know each other, frequently the following happens:</p>\n<p>1) Tell each other coarse grained info about their background and interests</p>\n<p>2) Interact for some amount of time on a shared interest (which could be the interest both share in the fact that currently they disagree about some topic, such as transhumanism)</p>\n<p>3) If one finds the other person interesting, try together to refine some specific ideas, or advocate for most strongly held beliefs.This goes on for a bit.</p>\n<p>4) Activate or fail to activate the trigger of \"friendship\" or \"good person to interact with\" - <strong>And though this is beautiful, here the danger begins</strong></p>\n<p>If both failed to activate the trigger, the interaction resumes, or people let go of important topics and enter other mental modes. <em>Yet, in most of those cases, they have only interacted about coarse grained descriptions of their interests, and a few things both felt worth advocating, </em>at no point the topic \"Hey, what about we tell each other the things we most think we could help each other with, calibrate with the other's opinion and tell each other about <em>that</em>?\" comes up naturally to their minds.</p>\n<p>What about the other case, in which they decide to keep it going?</p>\n<p>5) Both usually feel that they co-activated the trigger. Relieved and relaxed (and under parasympathetic system's influence), they slowly fade away from relevant things, and talk about lower stake topics. High stake topics are worthy in the pursuit of friendship or alliance. Once alliance has been achieved, it becomes a <em>cost</em> (in their minds) basically because now your opinions can put you outside the circle of that person's interest much more likely than deeper inside.</p>\n<p>This problem with the stakes of pushing and pulling the \"friendship\" trigger is multiplicative in a very peculiar way, with some of the associated math being <a href=\"http://www.nickbostrom.com/papers/unilateralist.pdf\">here</a>. Or <a href=\"http://en.wikipedia.org/wiki/Winner%27s_curse\">here</a>.</p>\n<p>6) Though topics in which the highest information flow could be achieved are usually abandoned, they are brought back in the beggining of new interactions if the people keep seeing each other for a few days, still as usual they slowly fade away.</p>\n<p>7) When the button of friendship is really surely deep down pushed, they talk almost always about what doesn't matter, such as niche gossip, daily events, what they did since last interaction - I mean, <em>how likely is it that in those 26 years, the best I've done happened in the last 2 days?</em> - This obviously is a bad thing, and under our assumption that they either want to know more or do better, it is a cost for both.</p>\n<p>8) Also, concomitantly with 7, when people actually do take the trouble of disagreeing, their disagreement frequently is narrow. By narrow here I mean it is something that is distinct mostly at much more coarse grained levels than the one in which they are disagreeing. Basically, in topics that <em>even if one of them changed their mind</em> this would in no way affect their lives very significantly, nor their friendship.</p>\n<p>Having a good group of friends is fantastic, one of the most important things you can do for your happiness (Seligman), <a href=\"http://www.plosmedicine.org/article/info%3Adoi%2F10.1371%2Fjournal.pmed.1000316\">health</a>, <a href=\"http://www.econstor.eu/bitstream/10419/35451/1/522164196.pdf\">work</a>, attractiveness and networking. Activating the friendship button should be very high on your list of priorities, specially for adults, who don't experience the child/teenage feeling of \"getting a new friend\" so often.</p>\n<p>The recommendation here is just to keep pushing the information flow upwards and talking about what matters most even after the button has been pushed. The risk is substantially lower than your emotion is programmed to tell you. It is lower than what it feels from the inside for the same reason that approach anxiety (engaging a very attractive member of the desired gender) <em>should </em>be substantially less than what it feels from the inside. Namely our brains didn't have time to catch up with the fact that we live in a world which:</p>\n<p>a) Has 10&sup3; or more times more accessible people than our natural state.</p>\n<p>b) Alliances and friendships are not a matter of daily life and death anymore</p>\n<p>c) Social hierarchies are more fluid</p>\n<p>d) People are nicer, the better angels of their nature are the ones activated by our environment</p>\n<p>e) If you are a LWer, you are likely to be surrounded by people who are <em>particularly</em> nicer, given many of them want to save the world, aid the miserable, or help those who don't exist yet. Your brain is not totally aware of that selection effect. Specially if the person is spatially far from you.</p>\n<p>Back to our title question: For two years I had been going to a conference for cryonicists and talking about positive psychology. People's image of me was strongly associated with that idea, and that's what they'd usually engage me about, I suspect they had no idea there were other layers besides that one, so this year to avoid repetition I wore the Effective Altruist hat most of the time. Another attendee goes by the name of Jolly here in LW. I have heard him talk thoroughly about lifestyle, health and diet last few years, but even though I don't know which one, I'll bet he's got good stuff to say about one among: architecture, bronze age, cosmology, dinosaurs, evolution, farms, geology, hydrocarbon, islands, jingles, Korn, liabilities, meta, etc....</p>\n<p>Nowadays I get to know awesome people more frequently than in school days, my brain better calibrate for their awesomeness or else I may miss it. All this only works, obviously, when you train your brain to keep finding people's best, and help them to do the same, for instance by <a href=\"/lw/4ku/use_curiosity/\">using curiosity</a>.&nbsp;</p>\n<p>&nbsp;</p>\n<p>The take away message is, make more friends, engage them more thoroughly, keep the information flow up (in quality, importance, and quantity). And make sure to <em>always tell yourself that you are very unlikely to really, really, already know what that person has to offer. </em></p>\n<p>In doubt, ask for more</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "T2F6Rw5MgLmgQ2bqN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 8, "extendedScore": null, "score": 1.1645298219778655e-06, "legacy": true, "legacyId": "22266", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WrSe4aB8sWBy3Nphm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-10T19:54:18.267Z", "modifiedAt": null, "url": null, "title": "LW Women Submissions: On Misogyny", "slug": "lw-women-submissions-on-misogyny", "viewCount": null, "lastCommentedAt": "2017-08-10T01:05:08.278Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pYnjatHi3dupFgCQe/lw-women-submissions-on-misogyny", "pageUrlRelative": "/posts/pYnjatHi3dupFgCQe/lw-women-submissions-on-misogyny", "linkUrl": "https://www.lesswrong.com/posts/pYnjatHi3dupFgCQe/lw-women-submissions-on-misogyny", "postedAtFormatted": "Wednesday, April 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20Women%20Submissions%3A%20On%20Misogyny&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20Women%20Submissions%3A%20On%20Misogyny%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpYnjatHi3dupFgCQe%2Flw-women-submissions-on-misogyny%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20Women%20Submissions%3A%20On%20Misogyny%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpYnjatHi3dupFgCQe%2Flw-women-submissions-on-misogyny", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpYnjatHi3dupFgCQe%2Flw-women-submissions-on-misogyny", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2386, "htmlBody": "<h2><span style=\"font-size: 16px; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">Standard Intro</span></h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong>The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">Seven women submitted, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong>Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<hr />\n<p>[Note from daenerys- These two submissions might actually be one submission that had some sort of separation (such as a line of asteriks). If I processed them as separate when they were supposed to be a single entry, this is completely my mistake, and not at all the fault of the submitters. Sorry for the confusion.]</p>\n<h2>Submitter A</h2>\n<p><a href=\"http://blogs.scientificamerican.com/unofficial-prognosis/2012/09/23/study-shows-gender-bias-in-science-is-real-heres-why-it-matters/\" target=\"_blank\">Here's a webpage</a> with more on how misogyny works, including examples in the comments of \"mansplaining\" minimalizing problems.</p>\n<p>Under the article, there's a comment about Stieg Larrson's book, originally named \"Men who Hate Women.\" &nbsp;To see what motivated such a name, I Googled and found <a href=\"http://abcnews.go.com/Entertainment/stieg-larsson-guilt-gang-rape-lisbeth-fueled-millennium/story?id=11324859#.UGQOq66Ph8S\" target=\"_blank\">this article</a> about his experiences and guilt. &nbsp;Guilt is something that many have felt and tried to assuage in various ways, including asking for forgiveness. &nbsp;I've come to the conclusion that we should never forgive, only demand solutions, so as not to suffer continual sinning and forgiving. &nbsp;With solutions comes absolution, so forgiveness is unnecessary but for allowing the guilty get away with crimes (like the rapists in the article).</p>\n<p>The article about Larsson also has a bit about his partner's contributions not being credited to her, which seems to be typical of man-woman partnerships. &nbsp;Besides seeing it in other stories, I've experienced it in my own life. &nbsp;I gave my ex much input and feedback for his works, but others will never know. &nbsp;Meanwhile, he trivialized and hindered my work. &nbsp;He recently admitted to purposely discouraging me from going to college or doing well while I was there. &nbsp;I suspected as much, like when he guilt-tripped me the morning I had to cram for an AP exam in high school, BSing that my not celebrating his birthday with him meant that I didn't love him. &nbsp;This was when he was in grad school -- he knew what he was doing. &nbsp;He wanted to keep me for himself, and often said so. &nbsp;That thinking--a woman serving one men--was a justification for him to rape, physically assault, psychologically manipulate, and limit me (such as when or what I was allowed to write). &nbsp;Similar thinking exists in other persons' head, including in some women who blame themselves if their partners beat them, cheat on them, etc. &nbsp;But we can't happily serve one being; we absorb, process, and optimize much, much more than one being, who cannot be processed separate from the rest of the cosmos anyways. &nbsp;Forcing or planning a body to serve just one body (even one's own body) will involve abuse. &nbsp;</p>\n<p>Due to how our bodies work, a person tends to not respect a partner who is focused on pleasing just that person. &nbsp;Some poor souls are caught in a vicious cycle of doting on their partners, who in turn, don't love them much or disrespect them and eventually leave, giving imprecise, useless explanations like \"the person isn't intellectual enough,\" as can be seen <a href=\"http://ask.metafilter.com/115248/How-do-you-break-up-with-someone-who-loves-you\" target=\"_blank\">here</a>. &nbsp;\"Someone who loves you\" doesn't necessarily love You, but rather a narrow understanding of You. &nbsp;In other words, you don't love a person you don't know. &nbsp;</p>\n<p>The men who abuse women and claim they love those women do not know those women, any more than my ex understood my work for the-world-as-I-know-it, which is quite different from the world-as-he-knows-it, a world where women are whores when, to me, many women are slaves to idiots who don't know what's good, like people who perceive rape as cool or fun. &nbsp;My ex wrote a song called, \"Son of Whore,\" basically saying his mother and other mothers are whores, and also called me a whore, though he was the one forcing sex on me. &nbsp;On other occasions, he claimed I was the love of his life. &nbsp;You might think my ex was a sociopath, but no -- he's a normal male, working as a university professor. &nbsp;His thinking, like most humans', is outdated or out of touch with reality; his map misrepresents the territory. &nbsp;So now he has to deal with losing the love of his life, whom he neither really knew nor loved. &nbsp;Plus, he has to deal with my corrective writing to prevent him from harming another person. &nbsp;In that way, I'm still self-sacrificing to make him and his work better. &nbsp;How sub-optimal of me when I should be focusing on work helpful to more people.</p>\n<p><br /><br />.....</p>\n<h2>Submitter B</h2>\n<p>[note from daenerys- I think I somehow lost the links in this one. Very sorry!]</p>\n<blockquote>\n<p>&ldquo;Note that with a lot of the above issues, one of the biggest problems in figuring out what is going on isn't purposeful misogyny or anything.&rdquo;</p>\n</blockquote>\n<p>Those LWers who define rationality as for &ldquo;winning&rdquo; can play self-serving games. I'd like to think there's no such thing as purposeful misogyny, but PUA literature (in addition to other things my body has absorbed in my life) has left no room for that na&iuml;vet&eacute;. To be clear, by \"misogyny\" I don't mean &ldquo;hatred of women,&rdquo; which is a useless definition except for denying it exists. Some PUAs point out they \"love\" women, like some anti-gays point out they love gays and that's why they're trying to prevent gays from committing sins and thereby damning themselves and/or invoking God's wrath towards society. Similarly, PUAs and MRAs can believe themselves to be saving the world from irrational women. They have fallacious utility-maximization rationalizations, like someone I personally know who justified molestation of his biological daughter, with explanations from \"she likes it\" to [paraphrasing] &ldquo;it&rsquo;ll hasten the child's puberty changes and increase her bust size to make her more attractive to potential male mates.&rdquo; Other family members, including the victim&rsquo;s biological mother (abuser&rsquo;s wife) and paternal grandmother accepted the abuser's rationalizations, and hence did not intervene. The molestation escalated into raping the child, which the family members excused. I&rsquo;ve seen similar stories in the news, where a na&iuml;ve consumer of such news might be at a loss for why persons close to the abuser didn&rsquo;t intervene (e.g. Sandusky&rsquo;s wife).</p>\n<p>So, &ldquo;misogyny,&rdquo; to have a definition that points to real phenomena, can be said to be apologetics of abusing females, with messages (not just in natural language) or actions anywhere from seemingly benign and rational to full out demeaning or violent. And many females' brains accept and internalize such messages and actions, hence excusing the abusers, blaming the victims, forgiving abuses rather than taking actions to prevent them, or even letting themselves be abused (under some notion that the dynamics are unchangeable). In this news piece on a school spanking and in its comment field, you can see examples of people rationalizing hitting kids and/or letting themselves be hit, even though, as one commenter pointed out, we don&rsquo;t use corporal punishment on prisoners.</p>\n<p>My grandmother used to beat my younger brother to vent her frustrations with the world, including having to serve everyone while my grandfather stayed on the couch in front of the TV all day because he wouldn&rsquo;t do &ldquo;women&rsquo;s work&rdquo; and he was retired from &ldquo;men&rsquo;s work.&rdquo; Her brain rationalized the beating as necessary for disciplining my brother, even though the only &ldquo;disciplining&rdquo; effects were to force my brother to finish eating what she served him. She has come to regret what she did, but I&rsquo;m not sure she&rsquo;s aware of the dynamics behind what happened, including the patriarchal inequity and her brain&rsquo;s imprecise narrative about making my brother well-behaved.</p>\n<p>In case you don&rsquo;t have much history with abuse, perhaps the phenomena I&rsquo;m discussing will be more concrete to you if you&rsquo;ve had experiences dealing with men&rsquo;s porn and meditate on those experiences. This article, &ldquo;Being Porn,&rdquo; refers to women internalizing and enacting men&rsquo;s porn views, rather than trying to enlighten men so they make better use of resources and don&rsquo;t become or stay addicted to porn. To be fair, though, it&rsquo;s difficult to enlighten others if one is not good at brain-hacking herself. For example: On the HLN channel, there was a criminal investigations episode on an Evangelical Christian ex-military man who, addicted to porn, used varying excuses like &lsquo;it&rsquo;s research to save our sex life and marriage&rsquo; whenever she tried to get him to stop. Fed up, she asked for divorce, and instead of going through the pains of divorce, he murdered her and their daughter (age 6) in their sleep, put their bodies in the dumpster at his workplace and pretended they went missing. Cases like that illustrate how apologetics can get out of control (talk about affective death spirals), with a person operating on wrong confabulations upon wrong assumptions, while other not very enlightened persons (like the wife and the Evangelical church she tried to get help from) cannot effectively enlighten the outta control person.</p>\n<p>Given that brains perform apologetics, how rational can we be in cultures based more on some men&rsquo;s analyses than on others&rsquo; analyses, esp. when others&rsquo; analyses parrot so much of those men&rsquo;s&mdash;in cultures like LW&rsquo;s? There&rsquo;s potential for your female narratives project to change LW&rsquo;s stupid (read: &ldquo;low-effort thought&rdquo;) analyses, if the women don&rsquo;t end up affirming what the men have already said. I&rsquo;ve seen at least one LW woman use some men&rsquo;s stupid analyses of creepiness as exclusion or dislike of low-status or unattractive persons. Such over-simplified analysis doesn&rsquo;t account for what I know, which includes not being creeped out when an unattractive guy touches me in a platonic manner and being a little creeped out when an attractive college dormmate poked me on Facebook and then just stared at me for a long time at a social function&mdash;even my gay guy friend indentified that behavior as creepy. (The behavior could&rsquo;ve been called &ldquo;rapey eyes&rdquo; if the guy wasn&rsquo;t shy but rather objectifying me, like I&rsquo;ve seen some men do. I give them back the evil eyes to remind them to do no evil, and they turn away in shame. I first learned of the evil-eyes&rsquo; effectiveness when I got angry at bullying of my brother when I was first grade.</p>\n<p>The evil-eyes was just part of the indignation expression, and uses of it made bullies stop in their tracks. This reminds me of an angry-looking deity in some East Asian cultures, icons of which are customarily put in places of business. I used to wonder why, but now I see it may be to remind people to do no evil.) Back to the dormmate&hellip;I decided against getting involved with him, as I already had a bf and a lot of stressful things to deal with, and the dormmate (with his possible obsessive desire and my body&rsquo;s possible compliance despite my better judgment) would complicate things.</p>\n<p>My creepy/danger alert was much higher at a meeting with a high-status (read: supposedly utility-generating, which includes attractive in the sense of pleasing or exciting to look at, but mostly the utility is supposed to be from actions, like work or play) man who was supposed to be my boss for an internship. The way he talked about the previous intern, a female, the sleazy way he looked while reminiscing and then had to smoke a cigarette, while in a meeting with me, my father (an employer who was abusive), and the internship program director, plus the fact that when I was walking towards the meeting room, the employees of the company, all men, stared at me and remarked, &ldquo;It&rsquo;s a girl,&rdquo; well, I became so creeped out that I didn&rsquo;t want to go back. It was hard, as a less articulate 16 year-old, to explain to the internship director all that stuff without sounding irrational. But not being able to explain my brain&rsquo;s priors (including abuses that it had previously been too na&iuml;ve/ignorant to warn against and prevent) wasn&rsquo;t going to change them or decrease the avoidance-inducing fear and anxiety. So after some awkward attempts to answer the internship director&rsquo;s question of why I didn&rsquo;t want to work there, I asked for a placement with a different company, which she couldn&rsquo;t do, unfortunately.</p>\n<p>Given all my data, I can say approximately that identification of creepiness is a brain making predictions about someone&rsquo;s brain (could even be one&rsquo;s own brain, being introspective about whether you&rsquo;re being creepy) running on a stupid/unenlightened/unwise apologetic program that could possibly escalate into actions unpleasant or of low utility to the target and/or to him/her/one&rsquo;s self (e.g. energy-wasting, abuse, heartbreak, etc.). This analysis is backed up by data from studies I link to in this comment.</p>\n<p>Back to LWers&rsquo; analyses. Tony Robbins said on an episode of Oprah&rsquo;s LifeClass that women tend to be too affirming, rather than challenging like men. While I&rsquo;d like to think that&rsquo;s not true, since my body&rsquo;s tendency for as far back as I can remember has been to challenge wrong or unnecessary confabulations (I have to remind my body to be positively reinforcing of good actions), Robbins was talking about the same kind of phenomenon I&rsquo;m writing about here, which in effect, amounts to women not doing more to move people to become less wrong. Unlike Robbins, though I&rsquo;d say that this is in part due to women using men&rsquo;s explanations, with men being less challenging than apologetic. I regularly have to counter BS from men in my life or online. The Chinese equivalent of &ldquo;bullshit&rdquo; translated into English is bull fart. Not that females don&rsquo;t make info-poor, self-serving abstractions in public language.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pYnjatHi3dupFgCQe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 61, "baseScore": 45, "extendedScore": null, "score": 0.000124, "legacy": true, "legacyId": "20263", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Standard_Intro\"><span style=\"font-size: 16px; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">Standard Intro</span></h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong id=\"The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_\">The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">Seven women submitted, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\"><strong id=\"Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_\">Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<hr>\n<p>[Note from daenerys- These two submissions might actually be one submission that had some sort of separation (such as a line of asteriks). If I processed them as separate when they were supposed to be a single entry, this is completely my mistake, and not at all the fault of the submitters. Sorry for the confusion.]</p>\n<h2 id=\"Submitter_A\">Submitter A</h2>\n<p><a href=\"http://blogs.scientificamerican.com/unofficial-prognosis/2012/09/23/study-shows-gender-bias-in-science-is-real-heres-why-it-matters/\" target=\"_blank\">Here's a webpage</a> with more on how misogyny works, including examples in the comments of \"mansplaining\" minimalizing problems.</p>\n<p>Under the article, there's a comment about Stieg Larrson's book, originally named \"Men who Hate Women.\" &nbsp;To see what motivated such a name, I Googled and found <a href=\"http://abcnews.go.com/Entertainment/stieg-larsson-guilt-gang-rape-lisbeth-fueled-millennium/story?id=11324859#.UGQOq66Ph8S\" target=\"_blank\">this article</a> about his experiences and guilt. &nbsp;Guilt is something that many have felt and tried to assuage in various ways, including asking for forgiveness. &nbsp;I've come to the conclusion that we should never forgive, only demand solutions, so as not to suffer continual sinning and forgiving. &nbsp;With solutions comes absolution, so forgiveness is unnecessary but for allowing the guilty get away with crimes (like the rapists in the article).</p>\n<p>The article about Larsson also has a bit about his partner's contributions not being credited to her, which seems to be typical of man-woman partnerships. &nbsp;Besides seeing it in other stories, I've experienced it in my own life. &nbsp;I gave my ex much input and feedback for his works, but others will never know. &nbsp;Meanwhile, he trivialized and hindered my work. &nbsp;He recently admitted to purposely discouraging me from going to college or doing well while I was there. &nbsp;I suspected as much, like when he guilt-tripped me the morning I had to cram for an AP exam in high school, BSing that my not celebrating his birthday with him meant that I didn't love him. &nbsp;This was when he was in grad school -- he knew what he was doing. &nbsp;He wanted to keep me for himself, and often said so. &nbsp;That thinking--a woman serving one men--was a justification for him to rape, physically assault, psychologically manipulate, and limit me (such as when or what I was allowed to write). &nbsp;Similar thinking exists in other persons' head, including in some women who blame themselves if their partners beat them, cheat on them, etc. &nbsp;But we can't happily serve one being; we absorb, process, and optimize much, much more than one being, who cannot be processed separate from the rest of the cosmos anyways. &nbsp;Forcing or planning a body to serve just one body (even one's own body) will involve abuse. &nbsp;</p>\n<p>Due to how our bodies work, a person tends to not respect a partner who is focused on pleasing just that person. &nbsp;Some poor souls are caught in a vicious cycle of doting on their partners, who in turn, don't love them much or disrespect them and eventually leave, giving imprecise, useless explanations like \"the person isn't intellectual enough,\" as can be seen <a href=\"http://ask.metafilter.com/115248/How-do-you-break-up-with-someone-who-loves-you\" target=\"_blank\">here</a>. &nbsp;\"Someone who loves you\" doesn't necessarily love You, but rather a narrow understanding of You. &nbsp;In other words, you don't love a person you don't know. &nbsp;</p>\n<p>The men who abuse women and claim they love those women do not know those women, any more than my ex understood my work for the-world-as-I-know-it, which is quite different from the world-as-he-knows-it, a world where women are whores when, to me, many women are slaves to idiots who don't know what's good, like people who perceive rape as cool or fun. &nbsp;My ex wrote a song called, \"Son of Whore,\" basically saying his mother and other mothers are whores, and also called me a whore, though he was the one forcing sex on me. &nbsp;On other occasions, he claimed I was the love of his life. &nbsp;You might think my ex was a sociopath, but no -- he's a normal male, working as a university professor. &nbsp;His thinking, like most humans', is outdated or out of touch with reality; his map misrepresents the territory. &nbsp;So now he has to deal with losing the love of his life, whom he neither really knew nor loved. &nbsp;Plus, he has to deal with my corrective writing to prevent him from harming another person. &nbsp;In that way, I'm still self-sacrificing to make him and his work better. &nbsp;How sub-optimal of me when I should be focusing on work helpful to more people.</p>\n<p><br><br>.....</p>\n<h2 id=\"Submitter_B\">Submitter B</h2>\n<p>[note from daenerys- I think I somehow lost the links in this one. Very sorry!]</p>\n<blockquote>\n<p>\u201cNote that with a lot of the above issues, one of the biggest problems in figuring out what is going on isn't purposeful misogyny or anything.\u201d</p>\n</blockquote>\n<p>Those LWers who define rationality as for \u201cwinning\u201d can play self-serving games. I'd like to think there's no such thing as purposeful misogyny, but PUA literature (in addition to other things my body has absorbed in my life) has left no room for that na\u00efvet\u00e9. To be clear, by \"misogyny\" I don't mean \u201chatred of women,\u201d which is a useless definition except for denying it exists. Some PUAs point out they \"love\" women, like some anti-gays point out they love gays and that's why they're trying to prevent gays from committing sins and thereby damning themselves and/or invoking God's wrath towards society. Similarly, PUAs and MRAs can believe themselves to be saving the world from irrational women. They have fallacious utility-maximization rationalizations, like someone I personally know who justified molestation of his biological daughter, with explanations from \"she likes it\" to [paraphrasing] \u201cit\u2019ll hasten the child's puberty changes and increase her bust size to make her more attractive to potential male mates.\u201d Other family members, including the victim\u2019s biological mother (abuser\u2019s wife) and paternal grandmother accepted the abuser's rationalizations, and hence did not intervene. The molestation escalated into raping the child, which the family members excused. I\u2019ve seen similar stories in the news, where a na\u00efve consumer of such news might be at a loss for why persons close to the abuser didn\u2019t intervene (e.g. Sandusky\u2019s wife).</p>\n<p>So, \u201cmisogyny,\u201d to have a definition that points to real phenomena, can be said to be apologetics of abusing females, with messages (not just in natural language) or actions anywhere from seemingly benign and rational to full out demeaning or violent. And many females' brains accept and internalize such messages and actions, hence excusing the abusers, blaming the victims, forgiving abuses rather than taking actions to prevent them, or even letting themselves be abused (under some notion that the dynamics are unchangeable). In this news piece on a school spanking and in its comment field, you can see examples of people rationalizing hitting kids and/or letting themselves be hit, even though, as one commenter pointed out, we don\u2019t use corporal punishment on prisoners.</p>\n<p>My grandmother used to beat my younger brother to vent her frustrations with the world, including having to serve everyone while my grandfather stayed on the couch in front of the TV all day because he wouldn\u2019t do \u201cwomen\u2019s work\u201d and he was retired from \u201cmen\u2019s work.\u201d Her brain rationalized the beating as necessary for disciplining my brother, even though the only \u201cdisciplining\u201d effects were to force my brother to finish eating what she served him. She has come to regret what she did, but I\u2019m not sure she\u2019s aware of the dynamics behind what happened, including the patriarchal inequity and her brain\u2019s imprecise narrative about making my brother well-behaved.</p>\n<p>In case you don\u2019t have much history with abuse, perhaps the phenomena I\u2019m discussing will be more concrete to you if you\u2019ve had experiences dealing with men\u2019s porn and meditate on those experiences. This article, \u201cBeing Porn,\u201d refers to women internalizing and enacting men\u2019s porn views, rather than trying to enlighten men so they make better use of resources and don\u2019t become or stay addicted to porn. To be fair, though, it\u2019s difficult to enlighten others if one is not good at brain-hacking herself. For example: On the HLN channel, there was a criminal investigations episode on an Evangelical Christian ex-military man who, addicted to porn, used varying excuses like \u2018it\u2019s research to save our sex life and marriage\u2019 whenever she tried to get him to stop. Fed up, she asked for divorce, and instead of going through the pains of divorce, he murdered her and their daughter (age 6) in their sleep, put their bodies in the dumpster at his workplace and pretended they went missing. Cases like that illustrate how apologetics can get out of control (talk about affective death spirals), with a person operating on wrong confabulations upon wrong assumptions, while other not very enlightened persons (like the wife and the Evangelical church she tried to get help from) cannot effectively enlighten the outta control person.</p>\n<p>Given that brains perform apologetics, how rational can we be in cultures based more on some men\u2019s analyses than on others\u2019 analyses, esp. when others\u2019 analyses parrot so much of those men\u2019s\u2014in cultures like LW\u2019s? There\u2019s potential for your female narratives project to change LW\u2019s stupid (read: \u201clow-effort thought\u201d) analyses, if the women don\u2019t end up affirming what the men have already said. I\u2019ve seen at least one LW woman use some men\u2019s stupid analyses of creepiness as exclusion or dislike of low-status or unattractive persons. Such over-simplified analysis doesn\u2019t account for what I know, which includes not being creeped out when an unattractive guy touches me in a platonic manner and being a little creeped out when an attractive college dormmate poked me on Facebook and then just stared at me for a long time at a social function\u2014even my gay guy friend indentified that behavior as creepy. (The behavior could\u2019ve been called \u201crapey eyes\u201d if the guy wasn\u2019t shy but rather objectifying me, like I\u2019ve seen some men do. I give them back the evil eyes to remind them to do no evil, and they turn away in shame. I first learned of the evil-eyes\u2019 effectiveness when I got angry at bullying of my brother when I was first grade.</p>\n<p>The evil-eyes was just part of the indignation expression, and uses of it made bullies stop in their tracks. This reminds me of an angry-looking deity in some East Asian cultures, icons of which are customarily put in places of business. I used to wonder why, but now I see it may be to remind people to do no evil.) Back to the dormmate\u2026I decided against getting involved with him, as I already had a bf and a lot of stressful things to deal with, and the dormmate (with his possible obsessive desire and my body\u2019s possible compliance despite my better judgment) would complicate things.</p>\n<p>My creepy/danger alert was much higher at a meeting with a high-status (read: supposedly utility-generating, which includes attractive in the sense of pleasing or exciting to look at, but mostly the utility is supposed to be from actions, like work or play) man who was supposed to be my boss for an internship. The way he talked about the previous intern, a female, the sleazy way he looked while reminiscing and then had to smoke a cigarette, while in a meeting with me, my father (an employer who was abusive), and the internship program director, plus the fact that when I was walking towards the meeting room, the employees of the company, all men, stared at me and remarked, \u201cIt\u2019s a girl,\u201d well, I became so creeped out that I didn\u2019t want to go back. It was hard, as a less articulate 16 year-old, to explain to the internship director all that stuff without sounding irrational. But not being able to explain my brain\u2019s priors (including abuses that it had previously been too na\u00efve/ignorant to warn against and prevent) wasn\u2019t going to change them or decrease the avoidance-inducing fear and anxiety. So after some awkward attempts to answer the internship director\u2019s question of why I didn\u2019t want to work there, I asked for a placement with a different company, which she couldn\u2019t do, unfortunately.</p>\n<p>Given all my data, I can say approximately that identification of creepiness is a brain making predictions about someone\u2019s brain (could even be one\u2019s own brain, being introspective about whether you\u2019re being creepy) running on a stupid/unenlightened/unwise apologetic program that could possibly escalate into actions unpleasant or of low utility to the target and/or to him/her/one\u2019s self (e.g. energy-wasting, abuse, heartbreak, etc.). This analysis is backed up by data from studies I link to in this comment.</p>\n<p>Back to LWers\u2019 analyses. Tony Robbins said on an episode of Oprah\u2019s LifeClass that women tend to be too affirming, rather than challenging like men. While I\u2019d like to think that\u2019s not true, since my body\u2019s tendency for as far back as I can remember has been to challenge wrong or unnecessary confabulations (I have to remind my body to be positively reinforcing of good actions), Robbins was talking about the same kind of phenomenon I\u2019m writing about here, which in effect, amounts to women not doing more to move people to become less wrong. Unlike Robbins, though I\u2019d say that this is in part due to women using men\u2019s explanations, with men being less challenging than apologetic. I regularly have to counter BS from men in my life or online. The Chinese equivalent of \u201cbullshit\u201d translated into English is bull fart. Not that females don\u2019t make info-poor, self-serving abstractions in public language.</p>", "sections": [{"title": "Standard Intro", "anchor": "Standard_Intro", "level": 1}, {"title": "The following section will be at the top of all posts in the LW Women series.", "anchor": "The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_", "level": 2}, {"title": "Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.", "anchor": "Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_", "level": 2}, {"title": "Submitter A", "anchor": "Submitter_A", "level": 1}, {"title": "Submitter B", "anchor": "Submitter_B", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "469 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 473, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T00:53:04.207Z", "modifiedAt": null, "url": null, "title": "Open Request for Writing Assistance", "slug": "open-request-for-writing-assistance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:39.560Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "apophenia", "createdAt": "2010-04-13T14:09:52.433Z", "isAdmin": false, "displayName": "apophenia"}, "userId": "2rgiaLhZS8w2Fekt9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sjasNnTRhnLZPuy79/open-request-for-writing-assistance", "pageUrlRelative": "/posts/sjasNnTRhnLZPuy79/open-request-for-writing-assistance", "linkUrl": "https://www.lesswrong.com/posts/sjasNnTRhnLZPuy79/open-request-for-writing-assistance", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Request%20for%20Writing%20Assistance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Request%20for%20Writing%20Assistance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsjasNnTRhnLZPuy79%2Fopen-request-for-writing-assistance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Request%20for%20Writing%20Assistance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsjasNnTRhnLZPuy79%2Fopen-request-for-writing-assistance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsjasNnTRhnLZPuy79%2Fopen-request-for-writing-assistance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<p>I have several rough drafts of things I'd like to post to Less Wrong. &nbsp;The one I'm currently working on is about Solomonoff Induction. &nbsp;I seem to be best-motivated by active feedback while writing; this thread is mainly to request feedback while writing in the future. &nbsp;If you'd be interesting in reading what I'm writing every few paragraphs (either because you'd find it interesting or in order to cause it to be written), I would very much appreciate that.</p>\n<p>As long as I'm making that request, I might as well make two more: I would also like to hire someone who can edit writing for flow, and someone who can copy-edit. &nbsp;These could be two people or maybe you're amazing and can be both people. &nbsp;I will be willing to pay around $10/hr to anyone interested. &nbsp;If you're editing for flow I'd like to see a sample of your writing.</p>\n<p>Thanks in advance to any volunteer readers!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sjasNnTRhnLZPuy79", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 2, "extendedScore": null, "score": 1.164979605243775e-06, "legacy": true, "legacyId": "22268", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T01:28:46.351Z", "modifiedAt": null, "url": null, "title": "Post Request Thread", "slug": "post-request-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:58.637Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bTcReSNrW3xSJ6Yrt/post-request-thread", "pageUrlRelative": "/posts/bTcReSNrW3xSJ6Yrt/post-request-thread", "linkUrl": "https://www.lesswrong.com/posts/bTcReSNrW3xSJ6Yrt/post-request-thread", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Post%20Request%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APost%20Request%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbTcReSNrW3xSJ6Yrt%2Fpost-request-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Post%20Request%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbTcReSNrW3xSJ6Yrt%2Fpost-request-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbTcReSNrW3xSJ6Yrt%2Fpost-request-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 228, "htmlBody": "<p>This thread is another experiment roughly in the vein of the <a href=\"/lw/gx5/boring_advice_repository/\">Boring Advice Repository</a> and the <a href=\"/lw/h2m/solved_problems_repository/\">Solved Problems Repository</a>.</p>\n<p>There are some topics I'd like to see more LW posts on, but I feel underqualified to post about them relative to my estimate of the most qualified LWer on the topic. I would guess that I am not the only one. I would further guess that there are some LWers who are really knowledgeable about various topics and might like to write about one of them but are unsure which one to choose.&nbsp;</p>\n<p>If my guesses are right, these people should be made aware of each other. In this thread, please comment with a <strong>request for a LW post (Discussion or Main) on a particular topic</strong>. Please upvote such a comment if you would also like to see such a post, and comment on such a comment if you plan on writing such a post. If you leave a writing-plan comment, please edit it once you <strong>actually write the post</strong>&nbsp;and link to the post so as to avoid duplication of effort in the future.&nbsp;</p>\n<p>Let's see what happens!&nbsp;</p>\n<p>Edit: it just occurred to me that it might also be reasonable to comment indicating what topics you'd be interested in writing about and then asking people to tell you which ones they'd like you to write about the most. So try that too!&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bTcReSNrW3xSJ6Yrt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 30, "extendedScore": null, "score": 1.1650041775101767e-06, "legacy": true, "legacyId": "22270", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 100, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HEn2qiMxk5BggN83J", "iTzvJ7kKK2TYJhYHB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T02:15:38.954Z", "modifiedAt": null, "url": null, "title": "Pick Up Artists(PUAs) my view", "slug": "pick-up-artists-puas-my-view", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:33.697Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "roland", "createdAt": "2009-02-27T23:03:47.279Z", "isAdmin": false, "displayName": "roland"}, "userId": "p2C9rpg32LHrGwer8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vcR4Skp3jhYSssvAN/pick-up-artists-puas-my-view", "pageUrlRelative": "/posts/vcR4Skp3jhYSssvAN/pick-up-artists-puas-my-view", "linkUrl": "https://www.lesswrong.com/posts/vcR4Skp3jhYSssvAN/pick-up-artists-puas-my-view", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pick%20Up%20Artists(PUAs)%20my%20view&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APick%20Up%20Artists(PUAs)%20my%20view%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvcR4Skp3jhYSssvAN%2Fpick-up-artists-puas-my-view%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pick%20Up%20Artists(PUAs)%20my%20view%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvcR4Skp3jhYSssvAN%2Fpick-up-artists-puas-my-view", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvcR4Skp3jhYSssvAN%2Fpick-up-artists-puas-my-view", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1264, "htmlBody": "<p>The issue of PU(pick up) or PUAs(Pick up artists) has been discussed several times here and I often see objections against it. So I would like to present my view on it which is rather positive.</p>\n<p>Disclaimer: I'm a male.</p>\n<p><strong>1.</strong> <strong>Why is PU hated so much?<br /></strong></p>\n<p>&nbsp;</p>\n<p>It are usually women(correct me if I'm wrong) who object against PU and present a variety of reasons. As often when it concerns humans the presented reasons are rationalizations and the real causes of the antagonism is some deeper feeling that originates for entirely different reasons than the ones presented. I suspect this is also the case with PU. For the moment I will ignore the presented reasons some of which I will address later and instead focus on what I think is the real underlying cause.</p>\n<p>The real reason that women have a problem with PU is that it empowers men and dis-empowers women. Allow me to explain.</p>\n<p>Good looking women will have no problem attracting lots of interested males. Usually women do the choosing, while males compete for the attention. A big part of the power a woman has over her mate is the threat of withdrawing from him sexually and/or emotionally. It usually involves great effort for a man to find another woman, this was especially true in past times when people lived in small villages with very few unmarried attractive women. A woman on the other hand will not have much problems finding another male if she is good looking.</p>\n<p>Even in modern society women usually still have more power in relationships because even though there is nowadays an abundance of women(if you live in a big city there are literally thousands of them available) most men are still limited in that they meet women mostly through their social circle.</p>\n<p>&nbsp;</p>\n<p>What changed with PU?</p>\n<p>Picture this, a PUA(call him P) is in a relationship with women W. Say he has enough skills that he will be able to get laid or start a relationship with 1 in 50 women he approaches. Now there is some kind of tension in his current relationship, W threatens to withdraw or W has done something that upset him and he is considering finishing the relationship on his part. Since he is a PUA he knows that if he goes out 3 nights a week approaching 10 women each night he will meet 60 women in two weeks and will get laid once or be able to start a new relationship for sure. If W knows her partner well enough she will know it too. Suddenly the power balance has shifted. I still believe that women in general tend to have more power but PU shifted this towards men. W will have to consider \"If I withdraw he can find another woman in two weeks.\", she clearly has lost bargaining power. P knows it too and will weigh if it is worth the hassle to remain in the relationship if he can find another woman very quickly. P has more power for being a PUA than he would have if he weren't.</p>\n<p>&nbsp;</p>\n<p>If you followed this reasoning, can we expect women to like PU? Of course not, it is clear that woman have to dislike PU.</p>\n<p>&nbsp;</p>\n<p>Yet the thing is I never see this argument presented when PU is criticized. Why not? Because it is a power struggle and in such every gain in power by one side is a loss of power on the other side. To bring up this point women would have to admit that what they really dislike is the loss of power.</p>\n<p>&nbsp;</p>\n<p><strong>2. PUAs depiction of women<br /></strong></p>\n<p>&nbsp;</p>\n<p>One of the presented arguments against PU is that the depiction of women is often perceived as demeaning.</p>\n<p>&nbsp;</p>\n<p>Quoting from&nbsp; one comment:</p>\n<p>http://lesswrong.com/lw/fmv/lw_women_submissions_on_misogyny/8qnn</p>\n<p>&gt; I think PUA memes are especially dangerous because they are half-truths, which makes them compelling and \"sticky\" - but that is an opinion, and I admit only passing familiarity with PUA memes which I've picked up from visiting their forums</p>\n<p>&nbsp;</p>\n<p>I agree that a lot of those memes are half-truths or plain wrong, but some are correct. You also have to be careful with the source of the memes, there is a lot of nonsense written in forums. Yet if you look at the presentation of PU as done by Mystery in his writings and presented to an audience in shows like \"The PU artist\" I don't think there is anything there that really could be considered offensive.</p>\n<p>Also, some depictions may be offensive, yet still true, consider:</p>\n<p>&gt;Humans are greedy.</p>\n<p>&nbsp;</p>\n<p>Some people will consider this offensive.</p>\n<p>&nbsp;</p>\n<p>Another quote from:</p>\n<p>http://lesswrong.com/lw/fmv/lw_women_submissions_on_misogyny/8qnn</p>\n<p>&gt; You've got to show that you are assertive- even if it means being an asshole and playing on people's insecurities sometimes.\"...etc</p>\n<p>I agree this is extremely offensive. Yet at the same time I suspect there is a grain of truth to it. The quote can equally be applied to women asking for a refund in a shop and it could be good advice depending on the context. How bad is that? We can't change the way the world works. Is it wrong to be an asshole if that will enable you to get a refund? Should we judge someone for being an asshole if it works for him?</p>\n<p>&nbsp;</p>\n<p><strong>3. PU as a skillset and activity<br /></strong></p>\n<p>At the end it doesn't matter what PUAs write in forums but how they actually engage and interact with women in real life. And&nbsp; most guys who write in forums don't actually practice PU. Any PUA who is disrespectful will not get very far in conquering a woman's heart, on the contrary the art of PU is in making the woman feel good, why would she stay with a man who doesn't make her feel good?</p>\n<p>A point never mentioned much by criticizers is that actually PUAs are the ones who are often disrespected. Some have been killed for talking to the wrong woman, I've personally heard insults, was threatened by boyfriends(the women were alone, I didn't know they had a boyfriend until he showed up) and have to put up will all kind of rude behavior(hearing stuff like \"I don't give a fuck about you\", etc...)</p>\n<p><strong><br /></strong></p>\n<p><strong>4. Presented reasons against PU<br /></strong></p>\n<p>&nbsp;</p>\n<p>PU is manipulation as exemplified in this quote:</p>\n<p>http://lesswrong.com/lw/fmv/lw_women_submissions_on_misogyny/8qnn</p>\n<p>&gt; The above aside...I dunno. This statement <em>feels</em> like <em>manipulation</em> via false signalling, and I find that distasteful. I think that's mostly in the phrasing though, since there is nothing intrinsically wrong in wanting to be attractive.</p>\n<p>&nbsp;</p>\n<p>There is a lot of truth to that, but isn't it also manipulation for women to wear make-up, high heels, fake breasts, painted hair, plastic surgery? Yet I seldom see the latter criticized. It is simply accepted, even encouraged.</p>\n<p>Consider a webpage titled \"10 good ways for charming a woman\" and you can imagine comments(mostly from women) along the lines of: \"Guys, stop the bullshit just be yourselves and let the woman like you for who you are.\"</p>\n<p>Yet if it is about \"10 good ways to prepare for the job interview\" I usually don't read this kind of objections. On the contrary it is assumed that when going for an interview candidates will dress as well as they can, have polished their CVs and often waded through lists of common questions/problems and their solutions(speaking as a computer programmer here). Not doing so would be considered sloppy. It is rare to hear: \"People, just go to the interview and present yourself as you are, if the company likes you it will take you.\"</p>\n<p>&nbsp;</p>\n<p>EDIT: I'm still being throttled even when commenting on my own post. So I won't be able to address all the comments. Sorry, this is not something I can fix.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vcR4Skp3jhYSssvAN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": -43, "extendedScore": null, "score": -0.00012, "legacy": true, "legacyId": "22269", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<p>The issue of PU(pick up) or PUAs(Pick up artists) has been discussed several times here and I often see objections against it. So I would like to present my view on it which is rather positive.</p>\n<p>Disclaimer: I'm a male.</p>\n<p><strong>1.</strong> <strong>Why is PU hated so much?<br></strong></p>\n<p>&nbsp;</p>\n<p>It are usually women(correct me if I'm wrong) who object against PU and present a variety of reasons. As often when it concerns humans the presented reasons are rationalizations and the real causes of the antagonism is some deeper feeling that originates for entirely different reasons than the ones presented. I suspect this is also the case with PU. For the moment I will ignore the presented reasons some of which I will address later and instead focus on what I think is the real underlying cause.</p>\n<p>The real reason that women have a problem with PU is that it empowers men and dis-empowers women. Allow me to explain.</p>\n<p>Good looking women will have no problem attracting lots of interested males. Usually women do the choosing, while males compete for the attention. A big part of the power a woman has over her mate is the threat of withdrawing from him sexually and/or emotionally. It usually involves great effort for a man to find another woman, this was especially true in past times when people lived in small villages with very few unmarried attractive women. A woman on the other hand will not have much problems finding another male if she is good looking.</p>\n<p>Even in modern society women usually still have more power in relationships because even though there is nowadays an abundance of women(if you live in a big city there are literally thousands of them available) most men are still limited in that they meet women mostly through their social circle.</p>\n<p>&nbsp;</p>\n<p>What changed with PU?</p>\n<p>Picture this, a PUA(call him P) is in a relationship with women W. Say he has enough skills that he will be able to get laid or start a relationship with 1 in 50 women he approaches. Now there is some kind of tension in his current relationship, W threatens to withdraw or W has done something that upset him and he is considering finishing the relationship on his part. Since he is a PUA he knows that if he goes out 3 nights a week approaching 10 women each night he will meet 60 women in two weeks and will get laid once or be able to start a new relationship for sure. If W knows her partner well enough she will know it too. Suddenly the power balance has shifted. I still believe that women in general tend to have more power but PU shifted this towards men. W will have to consider \"If I withdraw he can find another woman in two weeks.\", she clearly has lost bargaining power. P knows it too and will weigh if it is worth the hassle to remain in the relationship if he can find another woman very quickly. P has more power for being a PUA than he would have if he weren't.</p>\n<p>&nbsp;</p>\n<p>If you followed this reasoning, can we expect women to like PU? Of course not, it is clear that woman have to dislike PU.</p>\n<p>&nbsp;</p>\n<p>Yet the thing is I never see this argument presented when PU is criticized. Why not? Because it is a power struggle and in such every gain in power by one side is a loss of power on the other side. To bring up this point women would have to admit that what they really dislike is the loss of power.</p>\n<p>&nbsp;</p>\n<p><strong id=\"2__PUAs_depiction_of_women\">2. PUAs depiction of women<br></strong></p>\n<p>&nbsp;</p>\n<p>One of the presented arguments against PU is that the depiction of women is often perceived as demeaning.</p>\n<p>&nbsp;</p>\n<p>Quoting from&nbsp; one comment:</p>\n<p>http://lesswrong.com/lw/fmv/lw_women_submissions_on_misogyny/8qnn</p>\n<p>&gt; I think PUA memes are especially dangerous because they are half-truths, which makes them compelling and \"sticky\" - but that is an opinion, and I admit only passing familiarity with PUA memes which I've picked up from visiting their forums</p>\n<p>&nbsp;</p>\n<p>I agree that a lot of those memes are half-truths or plain wrong, but some are correct. You also have to be careful with the source of the memes, there is a lot of nonsense written in forums. Yet if you look at the presentation of PU as done by Mystery in his writings and presented to an audience in shows like \"The PU artist\" I don't think there is anything there that really could be considered offensive.</p>\n<p>Also, some depictions may be offensive, yet still true, consider:</p>\n<p>&gt;Humans are greedy.</p>\n<p>&nbsp;</p>\n<p>Some people will consider this offensive.</p>\n<p>&nbsp;</p>\n<p>Another quote from:</p>\n<p>http://lesswrong.com/lw/fmv/lw_women_submissions_on_misogyny/8qnn</p>\n<p>&gt; You've got to show that you are assertive- even if it means being an asshole and playing on people's insecurities sometimes.\"...etc</p>\n<p>I agree this is extremely offensive. Yet at the same time I suspect there is a grain of truth to it. The quote can equally be applied to women asking for a refund in a shop and it could be good advice depending on the context. How bad is that? We can't change the way the world works. Is it wrong to be an asshole if that will enable you to get a refund? Should we judge someone for being an asshole if it works for him?</p>\n<p>&nbsp;</p>\n<p><strong id=\"3__PU_as_a_skillset_and_activity\">3. PU as a skillset and activity<br></strong></p>\n<p>At the end it doesn't matter what PUAs write in forums but how they actually engage and interact with women in real life. And&nbsp; most guys who write in forums don't actually practice PU. Any PUA who is disrespectful will not get very far in conquering a woman's heart, on the contrary the art of PU is in making the woman feel good, why would she stay with a man who doesn't make her feel good?</p>\n<p>A point never mentioned much by criticizers is that actually PUAs are the ones who are often disrespected. Some have been killed for talking to the wrong woman, I've personally heard insults, was threatened by boyfriends(the women were alone, I didn't know they had a boyfriend until he showed up) and have to put up will all kind of rude behavior(hearing stuff like \"I don't give a fuck about you\", etc...)</p>\n<p><strong><br></strong></p>\n<p><strong id=\"4__Presented_reasons_against_PU\">4. Presented reasons against PU<br></strong></p>\n<p>&nbsp;</p>\n<p>PU is manipulation as exemplified in this quote:</p>\n<p>http://lesswrong.com/lw/fmv/lw_women_submissions_on_misogyny/8qnn</p>\n<p>&gt; The above aside...I dunno. This statement <em>feels</em> like <em>manipulation</em> via false signalling, and I find that distasteful. I think that's mostly in the phrasing though, since there is nothing intrinsically wrong in wanting to be attractive.</p>\n<p>&nbsp;</p>\n<p>There is a lot of truth to that, but isn't it also manipulation for women to wear make-up, high heels, fake breasts, painted hair, plastic surgery? Yet I seldom see the latter criticized. It is simply accepted, even encouraged.</p>\n<p>Consider a webpage titled \"10 good ways for charming a woman\" and you can imagine comments(mostly from women) along the lines of: \"Guys, stop the bullshit just be yourselves and let the woman like you for who you are.\"</p>\n<p>Yet if it is about \"10 good ways to prepare for the job interview\" I usually don't read this kind of objections. On the contrary it is assumed that when going for an interview candidates will dress as well as they can, have polished their CVs and often waded through lists of common questions/problems and their solutions(speaking as a computer programmer here). Not doing so would be considered sloppy. It is rare to hear: \"People, just go to the interview and present yourself as you are, if the company likes you it will take you.\"</p>\n<p>&nbsp;</p>\n<p>EDIT: I'm still being throttled even when commenting on my own post. So I won't be able to address all the comments. Sorry, this is not something I can fix.</p>", "sections": [{"title": "2. PUAs depiction of women", "anchor": "2__PUAs_depiction_of_women", "level": 1}, {"title": "3. PU as a skillset and activity", "anchor": "3__PU_as_a_skillset_and_activity", "level": 1}, {"title": "4. Presented reasons against PU", "anchor": "4__Presented_reasons_against_PU", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "95 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 95, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T05:58:55.393Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Incremental Progress and the Valley", "slug": "seq-rerun-incremental-progress-and-the-valley", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2smbn9mPheS4gdigC/seq-rerun-incremental-progress-and-the-valley", "pageUrlRelative": "/posts/2smbn9mPheS4gdigC/seq-rerun-incremental-progress-and-the-valley", "linkUrl": "https://www.lesswrong.com/posts/2smbn9mPheS4gdigC/seq-rerun-incremental-progress-and-the-valley", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Incremental%20Progress%20and%20the%20Valley&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Incremental%20Progress%20and%20the%20Valley%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2smbn9mPheS4gdigC%2Fseq-rerun-incremental-progress-and-the-valley%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Incremental%20Progress%20and%20the%20Valley%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2smbn9mPheS4gdigC%2Fseq-rerun-incremental-progress-and-the-valley", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2smbn9mPheS4gdigC%2Fseq-rerun-incremental-progress-and-the-valley", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 223, "htmlBody": "<p>Today's post, <a href=\"/lw/7k/incremental_progress_and_the_valley/\"> was originally published on 04 April 2009.  A summary (taken from the </a><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The optimality theorems for probability theory and decision theory, are for perfect probability theory and decision theory. There is no theorem that incremental changes toward the ideal, starting from a flawed initial form, must yield incremental progress at each step along the way. Since perfection is unattainable, why dare to try for improvement? But my limited experience with specialized applications suggests that given enough progress, one can achieve huge improvements over baseline - it just takes a lot of progress to get there.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h6f/seq_rerun_rationality_is_systematized_winning/\">Rationality is Systematized Winning</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2smbn9mPheS4gdigC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.1651901391839457e-06, "legacy": true, "legacyId": "22272", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oZNXmHcdhb4m7vwsv", "C3nhZ8amddMfMKv8x", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T06:30:29.165Z", "modifiedAt": null, "url": null, "title": "g, a Statistical Myth", "slug": "g-a-statistical-myth", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:29.036Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "smoofra", "createdAt": "2009-03-06T05:09:13.052Z", "isAdmin": false, "displayName": "smoofra"}, "userId": "v6xFjPq5z6RPDpyed", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6E9m6bJroLrvP5T8Q/g-a-statistical-myth", "pageUrlRelative": "/posts/6E9m6bJroLrvP5T8Q/g-a-statistical-myth", "linkUrl": "https://www.lesswrong.com/posts/6E9m6bJroLrvP5T8Q/g-a-statistical-myth", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20g%2C%20a%20Statistical%20Myth&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Ag%2C%20a%20Statistical%20Myth%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6E9m6bJroLrvP5T8Q%2Fg-a-statistical-myth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=g%2C%20a%20Statistical%20Myth%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6E9m6bJroLrvP5T8Q%2Fg-a-statistical-myth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6E9m6bJroLrvP5T8Q%2Fg-a-statistical-myth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 12, "htmlBody": "<p><a href=\"http://vserver1.cscs.lsa.umich.edu/~crshalizi/weblog/523.html\">I found this post very interesting</a></p>\n<p>It's about statistics, causal inference, and<a href=\"http://en.wikipedia.org/wiki/G_factor_%28psychometrics%29\"> 'g'</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6E9m6bJroLrvP5T8Q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": -7, "extendedScore": null, "score": -4e-06, "legacy": true, "legacyId": "22273", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T14:13:08.712Z", "modifiedAt": null, "url": null, "title": "Meetup : April Atlanta Meetup! Friday, April 19th", "slug": "meetup-april-atlanta-meetup-friday-april-19th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:00.590Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nova_Division", "createdAt": "2011-03-14T15:21:15.124Z", "isAdmin": false, "displayName": "Nova_Division"}, "userId": "eFXLR4aNaxDBCDatT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yeE7CZMedfNa7rKLC/meetup-april-atlanta-meetup-friday-april-19th", "pageUrlRelative": "/posts/yeE7CZMedfNa7rKLC/meetup-april-atlanta-meetup-friday-april-19th", "linkUrl": "https://www.lesswrong.com/posts/yeE7CZMedfNa7rKLC/meetup-april-atlanta-meetup-friday-april-19th", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20April%20Atlanta%20Meetup!%20Friday%2C%20April%2019th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20April%20Atlanta%20Meetup!%20Friday%2C%20April%2019th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyeE7CZMedfNa7rKLC%2Fmeetup-april-atlanta-meetup-friday-april-19th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20April%20Atlanta%20Meetup!%20Friday%2C%20April%2019th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyeE7CZMedfNa7rKLC%2Fmeetup-april-atlanta-meetup-friday-april-19th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyeE7CZMedfNa7rKLC%2Fmeetup-april-atlanta-meetup-friday-april-19th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 410, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/le\">April Atlanta Meetup! Friday, April 19th</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">19 April 2013 07:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1314 Hosea L Williams Drive NE, Atlanta, GA 30317</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p><em>Note: The date for this meetup was previously incorrect. The correct date is Friday, April 19th.</em></p>\n<p>This meetup will focus on instrumental rationality and life-hacking skills.</p>\n<hr />\n<p>If you are a quiet, introverted person who hasn't yet made the leap from online-Lesswrong to Lesswrong-in-the-flesh, and you feel intimidated or worried that you'll feel out of place at our meetup, worry no more! Give it a shot this month and see what you think. :)</p>\n<p>If you're an energetic, outgoing person and you're worried that rationalist fraternizing might prove pedantic or tedious, I have some truly lovely people I'd like to introduce you to!</p>\n<p>We have rapid-fire, large group discussions--and intimate, small group discussions.</p>\n<p>We have time to reflect quietly on what we are learning--and time to physically express our excitement by bouncing around like bubble balls in a hopper.</p>\n<p>We have large group, bawdy games (Operant conditioning or Cards Against Humanity, anyone?)-- and quiet, relaxing, noncompetitive games (cooperative Set is my favorite! And have you tried Aquarius?).</p>\n<p>Whatever your taste for socializing, there's a niche in ATLesswrong for you. =D</p>\n<hr />\n<h1>Agenda</h1>\n<ul>\n<li>\n<p>Mini-presentations. Anyone is invited to give a mini-presentation on a topic of their choice! A whiteboard is available if needed.</p>\n</li>\n<li>\n<p>What went down at Teens &amp; Twenties 4. We will give a short summary of the recent Teens and Twenties 4 cryonics conference for those interested in hearing more.</p>\n</li>\n<li>\n<p>Soylent samples! For those interested in life-hacking via DIY meal-replacement drinks.</p>\n</li>\n<li>\n<p>Biased board gaming. There was a lot of interest last time in this idea, so we're making it happen.</p>\n</li>\n<li>\n<p>Post-meetup social time! Games, cuddling, kittens! No, seriously, there will be KITTENS.</p>\n</li>\n<li>\n<p>Post-post-meetup out on the town time! If you're up for a late night, lets do random acts of kindness and mayhem in Atlanta.</p>\n</li>\n<li>\n<p>Please bring a laptop or other device that can view Google Docs. That way we can share notes and avoid the need for printouts.</p>\n</li>\n</ul>\n<hr />\n<p>Snacks and drinks will be provided! As always, snacks will be vegan with gluten-free and soy-free options.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/le\">April Atlanta Meetup! Friday, April 19th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yeE7CZMedfNa7rKLC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 1.1655304791031881e-06, "legacy": true, "legacyId": "22276", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___April_Atlanta_Meetup__Friday__April_19th\">Discussion article for the meetup : <a href=\"/meetups/le\">April Atlanta Meetup! Friday, April 19th</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">19 April 2013 07:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1314 Hosea L Williams Drive NE, Atlanta, GA 30317</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p><em>Note: The date for this meetup was previously incorrect. The correct date is Friday, April 19th.</em></p>\n<p>This meetup will focus on instrumental rationality and life-hacking skills.</p>\n<hr>\n<p>If you are a quiet, introverted person who hasn't yet made the leap from online-Lesswrong to Lesswrong-in-the-flesh, and you feel intimidated or worried that you'll feel out of place at our meetup, worry no more! Give it a shot this month and see what you think. :)</p>\n<p>If you're an energetic, outgoing person and you're worried that rationalist fraternizing might prove pedantic or tedious, I have some truly lovely people I'd like to introduce you to!</p>\n<p>We have rapid-fire, large group discussions--and intimate, small group discussions.</p>\n<p>We have time to reflect quietly on what we are learning--and time to physically express our excitement by bouncing around like bubble balls in a hopper.</p>\n<p>We have large group, bawdy games (Operant conditioning or Cards Against Humanity, anyone?)-- and quiet, relaxing, noncompetitive games (cooperative Set is my favorite! And have you tried Aquarius?).</p>\n<p>Whatever your taste for socializing, there's a niche in ATLesswrong for you. =D</p>\n<hr>\n<h1 id=\"Agenda\">Agenda</h1>\n<ul>\n<li>\n<p>Mini-presentations. Anyone is invited to give a mini-presentation on a topic of their choice! A whiteboard is available if needed.</p>\n</li>\n<li>\n<p>What went down at Teens &amp; Twenties 4. We will give a short summary of the recent Teens and Twenties 4 cryonics conference for those interested in hearing more.</p>\n</li>\n<li>\n<p>Soylent samples! For those interested in life-hacking via DIY meal-replacement drinks.</p>\n</li>\n<li>\n<p>Biased board gaming. There was a lot of interest last time in this idea, so we're making it happen.</p>\n</li>\n<li>\n<p>Post-meetup social time! Games, cuddling, kittens! No, seriously, there will be KITTENS.</p>\n</li>\n<li>\n<p>Post-post-meetup out on the town time! If you're up for a late night, lets do random acts of kindness and mayhem in Atlanta.</p>\n</li>\n<li>\n<p>Please bring a laptop or other device that can view Google Docs. That way we can share notes and avoid the need for printouts.</p>\n</li>\n</ul>\n<hr>\n<p>Snacks and drinks will be provided! As always, snacks will be vegan with gluten-free and soy-free options.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___April_Atlanta_Meetup__Friday__April_19th1\">Discussion article for the meetup : <a href=\"/meetups/le\">April Atlanta Meetup! Friday, April 19th</a></h2>", "sections": [{"title": "Discussion article for the meetup : April Atlanta Meetup! Friday, April 19th", "anchor": "Discussion_article_for_the_meetup___April_Atlanta_Meetup__Friday__April_19th", "level": 2}, {"title": "Agenda", "anchor": "Agenda", "level": 1}, {"title": "Discussion article for the meetup : April Atlanta Meetup! Friday, April 19th", "anchor": "Discussion_article_for_the_meetup___April_Atlanta_Meetup__Friday__April_19th1", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T14:53:32.039Z", "modifiedAt": null, "url": null, "title": "Columbus Mega-meetup Planning- RSVPs wanted", "slug": "columbus-mega-meetup-planning-rsvps-wanted", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:29.618Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bjmciXt3zJK82KdFm/columbus-mega-meetup-planning-rsvps-wanted", "pageUrlRelative": "/posts/bjmciXt3zJK82KdFm/columbus-mega-meetup-planning-rsvps-wanted", "linkUrl": "https://www.lesswrong.com/posts/bjmciXt3zJK82KdFm/columbus-mega-meetup-planning-rsvps-wanted", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Columbus%20Mega-meetup%20Planning-%20RSVPs%20wanted&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AColumbus%20Mega-meetup%20Planning-%20RSVPs%20wanted%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbjmciXt3zJK82KdFm%2Fcolumbus-mega-meetup-planning-rsvps-wanted%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Columbus%20Mega-meetup%20Planning-%20RSVPs%20wanted%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbjmciXt3zJK82KdFm%2Fcolumbus-mega-meetup-planning-rsvps-wanted", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbjmciXt3zJK82KdFm%2Fcolumbus-mega-meetup-planning-rsvps-wanted", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 368, "htmlBody": "<p>This October 11-13, Columbus, Ohio will be holding our first mega-meetup. The theme will be:</p>\n<h1>\"Leveling Up\"</h1>\n<p>The site will be the HCCO conference room, and attendance will be limited to 60. &nbsp;Tickets will be sold in advance and will cover lunch (Tickets will be extremely cheap to buy in advance, and will pretty much just be the cost of lunch, rounded up. Their sole purpose is to reserve seats for attendees in a reasonable manner.)</p>\n<p>If you think you might be coming, please leave a comment, along with a confidence estimation. Yes, I know the event is pretty far in the future, but an early RSVP will be <em>extremely helpful</em>&nbsp;to me! &nbsp;For example if you would be bringing two guests, and are 75% certain you will come:</p>\n<blockquote>\n<p>J. Doe +2, 75%</p>\n</blockquote>\n<h3><br /></h3>\n<h3>Talks:</h3>\n<p><strong>Note- October is far enough out in advance that all the details are tentative at this point.</strong></p>\n<p>Down the Rabbit Hole: Magic as Psychic Entertainment -Jack Strauss&nbsp;</p>\n<p>Magician/Mentalist Jack Strauss will present a stage act as a psychic entertainer. Afterwards, there will be a sit-down talkback with the audience. Topics will be determined by audience questions and may include: ethics of performing on stage with a psychic persona, psychology of deception, techniques of cold reading, etc. The only topic off the table will be the specifics of how the act you just saw is performed.</p>\n<p>Jesse Galef- Defense Against the Dark Arts</p>\n<p>Elissa Caffery Fleming- Effective Altruism (tentative)</p>\n<p>Amanda Metskas- The Next Generation (tentative)</p>\n<p>Eric Huff- Applications of Models</p>\n<p>Demitri Muna- Instrumental Improv workshop</p>\n<p>Erica Edelman- Intro to Rationality</p>\n<h3><br /></h3>\n<h3>Other Events:</h3>\n<h3><span style=\"font-size: small; font-weight: normal;\">Friday we may do a swing dance class. Sunday we may go shopping.</span></h3>\n<p><span style=\"font-size: small; font-weight: normal;\"><br /></span></p>\n<h3>Approximate Drive Times:</h3>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Dayton, OH- 1:00&nbsp;<br />Cincinnati, OH- 1:30&nbsp;<br />Cleveland, OH- 2:10&nbsp;<br />Toledo, OH- 2:20&nbsp;<br />Indianapolis, IN- 2:40&nbsp;<br />Fort Wayne, IN- 2:45&nbsp;<br />Pittsburgh, PA- 2:50&nbsp;<br />Lexington, KY- 3:00&nbsp;<br />Louisville, KY- 3:10&nbsp;<br />Detroit, MI- 3:15</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">Grand Rapids, MI- 4:50&nbsp;<br />Buffalo, MI- 5:00&nbsp;<br />Knoxville, TN- 5:15&nbsp;<br />Chicago, IL- 5:20&nbsp;<br />Nashville, TN- 5:30&nbsp;<br />Springfield, IL- 5:50&nbsp;<br />Rochester, NY- 6:00&nbsp;<br />Washington DC- 6:15&nbsp;<br />St Louis, MO- 6:20&nbsp;<br />Toronto, Canada- 6:30&nbsp;<br />Charlotte, NC- 6:40&nbsp;<br />Milwuakee, WI- 6:50&nbsp;<br />Philadelphia, PA- 7:15</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">NYC- 8:00</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bjmciXt3zJK82KdFm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 1.165558300091373e-06, "legacy": true, "legacyId": "22277", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This October 11-13, Columbus, Ohio will be holding our first mega-meetup. The theme will be:</p>\n<h1 id=\"_Leveling_Up_\">\"Leveling Up\"</h1>\n<p>The site will be the HCCO conference room, and attendance will be limited to 60. &nbsp;Tickets will be sold in advance and will cover lunch (Tickets will be extremely cheap to buy in advance, and will pretty much just be the cost of lunch, rounded up. Their sole purpose is to reserve seats for attendees in a reasonable manner.)</p>\n<p>If you think you might be coming, please leave a comment, along with a confidence estimation. Yes, I know the event is pretty far in the future, but an early RSVP will be <em>extremely helpful</em>&nbsp;to me! &nbsp;For example if you would be bringing two guests, and are 75% certain you will come:</p>\n<blockquote>\n<p>J. Doe +2, 75%</p>\n</blockquote>\n<h3><br></h3>\n<h3 id=\"Talks_\">Talks:</h3>\n<p><strong id=\"Note__October_is_far_enough_out_in_advance_that_all_the_details_are_tentative_at_this_point_\">Note- October is far enough out in advance that all the details are tentative at this point.</strong></p>\n<p>Down the Rabbit Hole: Magic as Psychic Entertainment -Jack Strauss&nbsp;</p>\n<p>Magician/Mentalist Jack Strauss will present a stage act as a psychic entertainer. Afterwards, there will be a sit-down talkback with the audience. Topics will be determined by audience questions and may include: ethics of performing on stage with a psychic persona, psychology of deception, techniques of cold reading, etc. The only topic off the table will be the specifics of how the act you just saw is performed.</p>\n<p>Jesse Galef- Defense Against the Dark Arts</p>\n<p>Elissa Caffery Fleming- Effective Altruism (tentative)</p>\n<p>Amanda Metskas- The Next Generation (tentative)</p>\n<p>Eric Huff- Applications of Models</p>\n<p>Demitri Muna- Instrumental Improv workshop</p>\n<p>Erica Edelman- Intro to Rationality</p>\n<h3><br></h3>\n<h3 id=\"Other_Events_\">Other Events:</h3>\n<h3 id=\"Friday_we_may_do_a_swing_dance_class__Sunday_we_may_go_shopping_\"><span style=\"font-size: small; font-weight: normal;\">Friday we may do a swing dance class. Sunday we may go shopping.</span></h3>\n<p><span style=\"font-size: small; font-weight: normal;\"><br></span></p>\n<h3 id=\"Approximate_Drive_Times_\">Approximate Drive Times:</h3>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Dayton, OH- 1:00&nbsp;<br>Cincinnati, OH- 1:30&nbsp;<br>Cleveland, OH- 2:10&nbsp;<br>Toledo, OH- 2:20&nbsp;<br>Indianapolis, IN- 2:40&nbsp;<br>Fort Wayne, IN- 2:45&nbsp;<br>Pittsburgh, PA- 2:50&nbsp;<br>Lexington, KY- 3:00&nbsp;<br>Louisville, KY- 3:10&nbsp;<br>Detroit, MI- 3:15</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; \">Grand Rapids, MI- 4:50&nbsp;<br>Buffalo, MI- 5:00&nbsp;<br>Knoxville, TN- 5:15&nbsp;<br>Chicago, IL- 5:20&nbsp;<br>Nashville, TN- 5:30&nbsp;<br>Springfield, IL- 5:50&nbsp;<br>Rochester, NY- 6:00&nbsp;<br>Washington DC- 6:15&nbsp;<br>St Louis, MO- 6:20&nbsp;<br>Toronto, Canada- 6:30&nbsp;<br>Charlotte, NC- 6:40&nbsp;<br>Milwuakee, WI- 6:50&nbsp;<br>Philadelphia, PA- 7:15</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">NYC- 8:00</p>\n<p>&nbsp;</p>", "sections": [{"title": "\"Leveling Up\"", "anchor": "_Leveling_Up_", "level": 1}, {"title": "Talks:", "anchor": "Talks_", "level": 2}, {"title": "Note- October is far enough out in advance that all the details are tentative at this point.", "anchor": "Note__October_is_far_enough_out_in_advance_that_all_the_details_are_tentative_at_this_point_", "level": 3}, {"title": "Other Events:", "anchor": "Other_Events_", "level": 2}, {"title": "Friday we may do a swing dance class. Sunday we may go shopping.", "anchor": "Friday_we_may_do_a_swing_dance_class__Sunday_we_may_go_shopping_", "level": 2}, {"title": "Approximate Drive Times:", "anchor": "Approximate_Drive_Times_", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "16 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-11T17:52:28.708Z", "modifiedAt": null, "url": null, "title": "Fermi Estimates", "slug": "fermi-estimates", "viewCount": null, "lastCommentedAt": "2021-07-11T16:17:06.343Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PsEppdvgRisz5xAHG/fermi-estimates", "pageUrlRelative": "/posts/PsEppdvgRisz5xAHG/fermi-estimates", "linkUrl": "https://www.lesswrong.com/posts/PsEppdvgRisz5xAHG/fermi-estimates", "postedAtFormatted": "Thursday, April 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fermi%20Estimates&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFermi%20Estimates%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPsEppdvgRisz5xAHG%2Ffermi-estimates%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fermi%20Estimates%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPsEppdvgRisz5xAHG%2Ffermi-estimates", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPsEppdvgRisz5xAHG%2Ffermi-estimates", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3992, "htmlBody": "<p>Just before the <a href=\"http://is.gd/NeBfVu\">Trinity test</a>, Enrico Fermi decided he wanted a rough estimate of the blast's power before the diagnostic data came in. So he dropped some pieces of paper from his hand as the blast wave passed him, and used this to estimate that the blast was equivalent to 10 kilotons of TNT. His guess was remarkably accurate for having so little data: the true answer turned out to be 20 kilotons of TNT.</p>\n<p>Fermi had a knack for making roughly-accurate estimates with very little data, and therefore such an estimate is known today as a <a href=\"http://en.wikipedia.org/wiki/Fermi_problem\">Fermi estimate</a>.</p>\n<p>Why bother with Fermi estimates, if your estimates are likely to be off by a factor of 2 or even 10? Often, getting an estimate within a factor of 10 or 20 is enough to make a decision. So Fermi estimates can save you a lot of time, especially as you gain more practice at making them.</p>\n<p>&nbsp;</p>\n<h3>Estimation tips</h3>\n<p><small>These first two sections are adapted from <em><a href=\"http://www.amazon.com/Guesstimation-2-0-Solving-Todays-Problems/dp/069115080X/\">Guestimation 2.0</a></em>.</small></p>\n<p><strong>Dare to be imprecise.</strong> Round things off enough to do the calculations in your head. I call this the <a href=\"http://en.wikipedia.org/wiki/Spherical_cow\">spherical cow principle</a>, after a joke about how physicists oversimplify things to make calculations feasible:</p>\n<blockquote>\n<p>Milk production at a dairy farm was low, so the farmer asked a local university for help. A multidisciplinary team of professors was assembled, headed by a theoretical physicist. After two weeks of observation and analysis, the physicist told the farmer, \"I have the solution, but it only works in the case of spherical cows in a vacuum.\"</p>\n</blockquote>\n<p>By the spherical cow principle, there are 300 days in a year, people are six feet (or 2 meters) tall, the circumference of the Earth is 20,000 mi (or 40,000 km), and cows are spheres of meat and bone 4 feet (or 1 meter) in diameter.</p>\n<p><strong>Decompose the problem.</strong> Sometimes you can give an estimate in one step, within a factor of 10. (How much does a new compact car cost? $20,000.) But in most cases, you'll need to break the problem into several pieces, estimate each of them, and then recombine them. I'll give several examples below.</p>\n<p><strong>Estimate by bounding.</strong> Sometimes it is easier to give lower and upper bounds than to give a point estimate. How much time per day does the average 15-year-old watch TV? I don't spend any time with 15-year-olds, so I haven't a clue. It could be 30 minutes, or 3 hours, or 5 hours, but I'm pretty confident it's more than 2 minutes and less than 7 hours (400 minutes, by the spherical cow principle).</p>\n<p>Can we convert those bounds into an estimate? You bet. But we don't do it by taking the <em>average</em>. That would give us (2 mins + 400 mins)/2 = 201 mins, which is within a factor of 2 from our upper bound, but a factor <em>100</em> greater than our lower bound. Since our goal is to estimate the answer within a factor of 10, we'll probably be way off.</p>\n<p>Instead, we take the <em>geometric mean</em> &mdash; the square root of the product of our upper and lower bounds. But square roots often require a calculator, so instead we'll take the <em>approximate</em> geometric mean (AGM). To do that, we average the coefficients and exponents of our upper and lower bounds.</p>\n<p>So what is the AGM of 2 and 400? Well, 2 is 2&times;10<sup>0</sup>, and 400 is 4&times;10<sup>2</sup>. The average of the coefficients (2 and 4) is 3; the average of the exponents (0 and 2) is 1. So, the AGM of 2 and 400 is 3&times;10<sup>1</sup>, or 30. The precise geometric mean of 2 and 400 turns out to be 28.28. Not bad.</p>\n<p>What if the sum of the exponents is an odd number? Then we round the resulting exponent down, and multiply the final answer by three. So suppose my lower and upper bounds for how much TV the average 15-year-old watches had been 20 mins and 400 mins. Now we calculate the AGM like this: 20 is 2&times;10<sup>1</sup>, and 400 is still 4&times;10<sup>2</sup>. The average of the coefficients (2 and 4) is 3; the average of the exponents (1 and 2) is 1.5. So we round the exponent down to 1, and we multiple the final result by three: 3(3&times;10<sup>1</sup>) = 90 mins. The precise geometric mean of 20 and 400 is 89.44. Again, not bad.</p>\n<p><strong>Sanity-check your answer</strong>. You should always sanity-check your final estimate by comparing it to some reasonable analogue. You'll see examples of this below.</p>\n<p><strong>Use Google as needed</strong>. You can often quickly find the exact quantity you're trying to estimate on Google, or at least some <em>piece</em> of the problem. In those cases, it's probably not worth trying to estimate it <em>without</em> Google.</p>\n<p><a id=\"more\"></a></p>\n<h3><br /></h3>\n<h3>Fermi estimation failure modes</h3>\n<p>Fermi estimates go wrong in one of three ways.</p>\n<p>First, we might badly overestimate or underestimate a quantity. Decomposing the problem, estimating from bounds, and looking up particular pieces on Google should protect against this. Overestimates and underestimates for the different pieces of a problem <a href=\"http://en.wikipedia.org/wiki/Fermi_problem#Explanation\">should roughly cancel out</a>, especially when there are many pieces.</p>\n<p>Second, we might model the problem incorrectly. If you estimate teenage deaths per year on the assumption that most teenage deaths are from suicide, your estimate will probably be way off, because most teenage deaths are caused by accidents. To avoid this, try to decompose each Fermi problem by using a model you're fairly confident of, even if it means you need to use more pieces or give wider bounds when estimating each quantity.</p>\n<p>Finally, we might choose a nonlinear problem. Normally, we assume that if one object can get some result, then two objects will get twice the result. Unfortunately, this doesn't hold true for nonlinear problems. If one motorcycle on a highway can transport a person at 60 miles per hour, then 30 motorcycles can transport 30 people at 60 miles per hour. However, 10<sup>4</sup> motorcycles cannot transport 10<sup>4</sup> people at 60 miles per hour, because there will be a huge traffic jam on the highway. This problem is difficult to avoid, but with practice you will get better at recognizing when you're facing a nonlinear problem.</p>\n<p>&nbsp;</p>\n<h3>Fermi practice</h3>\n<p>When getting started with Fermi practice, I recommend estimating quantities that you can easily look up later, so that you can see how accurate your Fermi estimates tend to be. Don't look up the answer before constructing your estimates, though! Alternatively, you might allow yourself to look up particular pieces of the problem &mdash; e.g. the <a href=\"http://en.wikipedia.org/wiki/List_of_religious_populations#Adherent_estimates\">number of Sikhs</a> in the world, the formula for <a href=\"http://en.wikipedia.org/wiki/Escape_velocity\">escape velocity</a>, or the <a href=\"http://en.wikipedia.org/wiki/Gross_world_product\">gross world product</a>&nbsp;&mdash; but not the final quantity you're trying to estimate.</p>\n<p>Most books about Fermi estimates are filled with examples done by Fermi estimate experts, and in many cases the estimates were probably adjusted after the author looked up the true answers. This post is different. My examples below are estimates I made <em>before</em> looking up the answer online, so you can get a realistic picture of how this works from someone who isn't \"cheating.\" Also, there will be no selection effect: I'm going to do four Fermi estimates for this post, and I'm not going to throw out my estimates if they are way off. Finally, I'm not all that practiced doing \"Fermis\" myself, so you'll get to see what it's like for a relative newbie to go through the process. In short, I hope to give you a realistic picture of what it's like to do Fermi practice when you're just getting started.</p>\n<p>&nbsp;</p>\n<h3>Example 1: How many new passenger cars are sold each year in the USA?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/aMD9a4s.jpg\" alt=\"\" />The classic Fermi problem is \"How many piano tuners are there in Chicago?\" This kind of estimate is useful if you want to know the approximate size of the customer base for a new product you might develop, for example. But I'm not sure anyone knows how many piano tuners there <em>really</em> are in Chicago, so let's try a different one we probably <em>can</em> look up later: \"How many new passenger cars are sold each year in the USA?\"</p>\n<p>As with all Fermi problems, there are many different models we could build. For example, we could estimate how many new cars a dealership sells per month, and then we could estimate how many dealerships there are in the USA. Or we could try to estimate the annual demand for new cars from the country's population. Or, if we happened to have read how many Toyota Corollas were sold last year, we could try to build our estimate from there.</p>\n<p>The second model looks more robust to me than the first, since I know roughly how many Americans there are, but I have no idea how many new-car dealerships there are. Still, let's try it both ways. (I <em>don't</em> happen to know how many new Corollas were sold last year.)</p>\n<h4>Approach #1: Car dealerships</h4>\n<p>How many new cars does a dealership sell per month, on average? Oofta, I dunno. To support the dealership's existence, I assume it has to be at least 5. But it's probably not more than 50, since most dealerships are in small towns that don't get much action. To get my point estimate, I'll take the AGM of 5 and 50. 5 is 5&times;10<sup>0</sup>, and 50 is 5&times;10<sup>1</sup>. Our exponents sum to an odd number, so I'll round the exponent down to 0 and multiple the final answer by 3. So, my estimate of how many new cars a new-car dealership sells per month is 3(5&times;10<sup>0</sup>) = 15.</p>\n<p>Now, how many new-car dealerships are there in the USA? This could be tough. I know several towns of only 10,000 people that have 3 or more new-car dealerships. I don't recall towns much smaller than that having new-car dealerships, so let's exclude them. How many cities of 10,000 people or more are there in the USA? I have no idea. So let's decompose this problem a bit more.</p>\n<p>How many <em>counties</em> are there in the USA? I remember seeing a map of counties colored by which national ancestry was dominant in that county. (Germany was the most common.) Thinking of that map, there were definitely more than 300 counties on it, and definitely less than 20,000. What's the AGM of 300 and 20,000? Well, 300 is 3&times;10<sup>2</sup>, and 20,000 is 2&times;10<sup>4</sup>. The average of coefficients 3 and 2 is 2.5, and the average of exponents 2 and 4 is 3. So the AGM of 300 and 20,000 is 2.5&times;10<sup>3</sup> = 2500.</p>\n<p>Now, how many towns of 10,000 people or more are there per county? I'm pretty sure the average must be larger than 10 and smaller than 5000. The AGM of 10 and 5000 is 300. (I won't include this calculation in the text anymore; you know how to do it.)</p>\n<p>Finally, how many car dealerships are there in cities of 10,000 or more people, on average? Most such towns are pretty small, and probably have 2-6 car dealerships. The largest cities will have many more: maybe 100-ish. So I'm pretty sure the average number of car dealerships in cities of 10,000 or more people must be between 2 and 30. The AGM of 2 and 30 is 7.5.</p>\n<p>Now I just multiply my estimates:</p>\n<p>[15 new cars sold per month per dealership] &times; [12 months per year] &times; [7.5 new-car dealerships per city of 10,000 or more people] &times; [300 cities of 10,000 or more people per county] &times; [2500 counties in the USA] = 1,012,500,000.</p>\n<p>A sanity check immediately invalidates this answer. There's no way that 300 million American citizens buy a <em>billion</em> new cars per year. I suppose they <em>might</em> buy 100 million new cars per year, which would be within a factor of 10 of my estimate, but I doubt it.</p>\n<p>As I suspected, my first approach was problematic. Let's try the second approach, starting from the population of the USA.</p>\n<h4>Approach #2: Population of the USA</h4>\n<p>There are about 300 million Americans. How many of them own a car? Maybe 1/3 of them, since children don't own cars, many people in cities don't own cars, and many households share a car or two between the adults in the household.</p>\n<p>Of the 100 million people who own a car, how many of them bought a <em>new</em> car in the past 5 years? Probably less than half; most people buy used cars, right? So maybe 1/4 of car owners bought a new car in the past 5 years, which means 1 in 20 car owners bought a new car in the past <em>year</em>.</p>\n<p>100 million / 20 = 5 million new cars sold each year in the USA. That doesn't seem crazy, though perhaps a bit low. I'll take this as my estimate.</p>\n<p>Now is your last chance to try this one on your own; in the next paragraph I'll reveal the true answer.</p>\n<p>&hellip;</p>\n<p>&hellip;</p>\n<p>...</p>\n<p>Now, I Google <a href=\"https://www.google.com/#hl=en&amp;output=search&amp;sclient=psy-ab&amp;q=new+cars+sold+per+year+in+the+USA&amp;oq=new+cars+sold+per+year+in+the+USA\">new cars sold per year in the USA</a>. Wikipedia is the first result, and it <a href=\"http://en.wikipedia.org/wiki/Passenger_vehicles_in_the_United_States#Sales\">says</a> \"In the year 2009, about 5.5 million new passenger cars were sold in the United States according to the U.S. Department of Transportation.\"</p>\n<p>Boo-yah!</p>\n<p>&nbsp;</p>\n<h3>Example 2: How many fatalities from passenger-jet crashes have there been in the past 20 years?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/TyoL5r1.jpg\" alt=\"\" />Again, there are multiple models I could build. I could try to estimate how many passenger-jet flights there are per year, and then try to estimate the frequency of crashes and the average number of fatalities per crash. Or I could just try to guess the total number of passenger-jet crashes around the world per year and go from there.</p>\n<p>As far as I can tell, passenger-jet crashes (with fatalities) almost always make it on the TV news and (more relevant to me) the front page of Google News. Exciting footage and multiple deaths will do that. So working just from memory, it feels to me like there are about 5 passenger-jet crashes (with fatalities) per year, so maybe there were about 100 passenger jet crashes with fatalities in the past 20 years.</p>\n<p>Now, how many fatalities per crash? From memory, it seems like there are usually two kinds of crashes: ones where <em>everybody</em> dies (meaning: about 200 people?), and ones where only about 10 people die. I think the \"everybody dead\" crashes are less common, maybe 1/4 as common. So the average crash with fatalities should cause (200&times;1/4)+(10&times;3/4) = 50+7.5 = 60, by the spherical cow principle.</p>\n<p>60 fatalities per crash &times; 100 crashes with fatalities over the past 20 years = 6000 passenger fatalities from passenger-jet crashes in the past 20 years.</p>\n<p>Last chance to try this one on your own...</p>\n<p>&hellip;</p>\n<p>&hellip;</p>\n<p>&hellip;</p>\n<p>A Google search again brings me to Wikipedia, which reveals that an organization called ACRO <a href=\"http://en.wikipedia.org/wiki/Aviation_accidents_and_incidents#Aircraft_Crashes_Record_Office_.28ACRO.29\">records</a> the number of airline fatalities each year. Unfortunately for my purposes, they include fatalities from cargo flights. After more Googling, I tracked down Boeing's \"<a href=\"http://www.boeing.com/news/techissues/pdf/statsum.pdf\">Statistical Summary of Commercial Jet Airplane Accidents, 1959-2011</a>,\" but that report excludes jets lighter than 60,000 pounds, and excludes crashes caused by hijacking or terrorism.</p>\n<p>It appears it would be a major research project to figure out the true answer to our question, but let's at least estimate it from the ACRO data. Luckily, ACRO has statistics on which percentage of accidents are from passenger and other kinds of flights, which I'll take as a proxy for which percentage of <em>fatalities</em> are from different kinds of flights. According to <a href=\"http://www.baaa-acro.com/Statistiques%20diverses.htm\">that page</a>, 35.41% of accidents are from \"regular schedule\" flights, 7.75% of accidents are from \"private\" flights, 5.1% of accidents are from \"charter\" flights, and 4.02% of accidents are from \"executive\" flights. I think that captures what I had in mind as \"passenger-jet flights.\" So we'll guess that 52.28% of fatalities are from \"passenger-jet flights.\" I won't round this to 50% because we're not doing a Fermi estimate right now; we're trying to <em>check</em> a Fermi estimate.</p>\n<p>According to ACRO's <a href=\"http://www.baaa-acro.com/archives/Accidents.htm\">archives</a>, there were 794 fatalities in 2012, 828 fatalities in 2011, and... well, from 1993-2012 there were a total of 28,021 fatalities. And 52.28% of that number is 14,649.</p>\n<p>So my estimate of 6000 was off by less than a factor of 3!</p>\n<p>&nbsp;</p>\n<h3>Example 3: How much does the New York state government spends on K-12 education every year?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/N5zf5d3.jpg\" alt=\"\" />How might I estimate this? First I'll estimate the number of K-12 students in New York, and then I'll estimate how much this should cost.</p>\n<p>How many people live in New York? I seem to recall that NYC's greater metropolitan area is about 20 million people. That's probably most of the state's population, so I'll guess the total is about 30 million.</p>\n<p>How many of those 30 million people attend K-12 public schools? I can't remember what the United States' <a href=\"http://en.wikipedia.org/wiki/Population_pyramid\">population pyramid</a> looks like, but I'll guess that about 1/6 of Americans (and hopefully New Yorkers) attend K-12 at any given time. So that's 5 million kids in K-12 in New York. The number attending private schools probably isn't large enough to matter for factor-of-10 estimates.</p>\n<p>How much does a year of K-12 education cost for one child? Well, I've heard teachers don't get paid much, so after benefits and taxes and so on I'm guessing a teacher costs about $70,000 per year. How big are class sizes these days, 30 kids? By the spherical cow principle, that's about $2,000 per child, per year on teachers' salaries. But there are lots of other expenses: buildings, transport, materials, support staff, etc. And maybe some money goes to private schools or other organizations. Rather than estimate all those things, I'm just going to guess that about $10,000 is spent per child, per year.</p>\n<p>If that's right, then New York spends $50 billion per year on K-12 education.</p>\n<p>Last chance to make your own estimate!</p>\n<p>&hellip;</p>\n<p>&hellip;</p>\n<p>&hellip;</p>\n<p>Before I did the Fermi estimate, I had <a href=\"http://www.juliagalef.com/\">Julia Galef</a> check Google to find this statistic, but she didn't give me any hints about the number. Her two sources were <a href=\"http://www.wolframalpha.com/input/?i=new+york+state+spending+education+k-12\">Wolfram Alpha</a> and a <a href=\"http://governor.ny.gov/citizenconnects/?q=content/web-chat-deputy-secretary-education-david-wakelyn\">web chat</a> with New York's Deputy Secretary for Education, both of which put the figure at approximately $53 billion.</p>\n<p>Which is definitely within a factor of 10 from $50 billion. :)</p>\n<p>&nbsp;</p>\n<h3>Example 4: How many plays of My Bloody Valentine's \"Only Shallow\" have been reported to last.fm?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/sr8R6T5.jpg\" alt=\"\" /><a href=\"http://en.wikipedia.org/wiki/Last.fm\">Last.fm</a> makes a record of every audio track you play, if you enable the relevant feature or plugin for the music software on your phone, computer, or other device. Then, the service can show you charts and statistics about your listening patterns, and make personalized music recommendations from them. My own charts are <a href=\"http://www.last.fm/user/lukeprog/charts\">here</a>. (Chuck Wild / <a href=\"http://www.liquidmindmusic.com/\">Liquid Mind</a> dominates my charts because I used to listen to that artist while sleeping.)</p>\n<p>My Fermi problem is: How many plays of \"<a href=\"http://www.youtube.com/watch?v=FyYMzEplnfU\">Only Shallow</a>\" have been reported to last.fm?</p>\n<p>My Bloody Valentine is a popular \"indie\" rock band, and \"Only Shallow\" is probably one of their most popular tracks. How can I estimate how many plays it has gotten on last.fm?</p>\n<p>What do I know that might help?</p>\n<ul>\n<li>I know last.fm is popular, but I don't have a sense of whether they have 1 million users, 10 million users, or 100 million users. </li>\n<li>I accidentally saw on Last.fm's Wikipedia page that just over 50 billion track plays have been recorded. We'll consider that to be one piece of data I looked up to help with my estimate. </li>\n<li>I seem to recall reading that major music services like iTunes and Spotify have about 10 million tracks. Since last.fm records songs that people play from their private collections, whether or not they exist in popular databases, I'd guess that the total number of different tracks named in last.fm's database is an order of magnitude larger, for about 100 million tracks named in its database.</li>\n</ul>\n<p>I would guess that track plays obey a <a href=\"http://en.wikipedia.org/wiki/Power_law\">power law</a>, with the most popular tracks getting vastly more plays than tracks of average popularity. I'd also guess that there are maybe 10,000 tracks more popular than \"Only Shallow.\"</p>\n<p>Next, I simulated being good at math by having <a href=\"/user/Qiaochu_Yuan/overview/\">Qiaochu Yuan</a> show me how to do the calculation. I also allowed myself to use a calculator. Here's what we do:</p>\n<blockquote>\n<p>Plays(rank) = C/(rank<sup>P</sup>)</p>\n</blockquote>\n<p>P is the exponent for the power law, and C is the proportionality constant. We'll guess that P is 1, a common power law exponent for empirical data. And we calculate C like so:</p>\n<blockquote>\n<p>C &asymp; [total plays]/ln(total songs) &asymp; 2.5 billion</p>\n</blockquote>\n<p>So now, assuming the song's rank is 10,000, we have:</p>\n<blockquote>\n<p>Plays(10<sup>4</sup>) = 2.5&times;10<sup>9</sup>/(10<sup>4</sup>)</p>\n<p>Plays(\"Only Shallow\") = 250,000</p>\n</blockquote>\n<p>That seems high, but let's roll with it. Last chance to make your own estimate!</p>\n<p>&hellip;</p>\n<p>&hellip;</p>\n<p>...</p>\n<p>And when I <a href=\"http://www.last.fm/music/My+Bloody+Valentine/_/Only+Shallow\">check the answer</a>, I see that \"Only Shallow\" has about 2 million plays on last.fm.</p>\n<p>My answer was off by less than a factor of 10, which for a Fermi estimate is called <em>victory</em>!</p>\n<p>Unfortunately, last.fm doesn't publish all-time track rankings or other data that might help me to determine which parts of my model were correct and incorrect.</p>\n<p>&nbsp;</p>\n<h3>Further examples</h3>\n<p>I focused on examples that are similar in structure to the kinds of quantities that entrepreneurs and CEOs might want to estimate, but of course there are all kinds of things one can estimate this way. Here's a sampling of Fermi problems featured in various books and websites on the subject:</p>\n<p><a href=\"http://www.fermiquestions.com/\">Play Fermi Questions</a>: 2100 Fermi problems and counting.</p>\n<p><em><a href=\"http://www.amazon.com/Guesstimation-Solving-Worlds-Problems-Cocktail/dp/0691129495/\">Guesstimation</a></em> (2008): If all the humans in the world were crammed together, how much area would we require? What would be the mass of all 10<sup>8</sup> MongaMillions lottery tickets? On average, how many people are airborne over the US at any given moment? How many cells are there in the human body? How many people in the world are picking their nose right now? What are the relative costs of fuel for NYC rickshaws and automobiles?</p>\n<p><em><a href=\"http://www.amazon.com/Guesstimation-2-0-Solving-Todays-Problems/dp/069115080X/\">Guesstimation 2.0</a> (2011): If we launched a trillion one-dollar bills into the atmosphere, what fraction of sunlight hitting the Earth could we block with those dollar bills? If a million monkeys typed randomly on a million typewriters for a year, what is the longest string of consecutive correct letters of *The Cat in the Hat</em> (starting from the beginning) would they likely type? How much energy does it take to crack a nut? If an airline asked its passengers to urinate before boarding the airplane, how much fuel would the airline save per flight? What is the radius of the largest rocky sphere from which we can reach escape velocity by jumping?</p>\n<p><em><a href=\"http://www.amazon.com/How-Many-Licks-Estimate-Anything/dp/0762435607/\">How Many Licks?</a></em> (2009): What fraction of Earth's volume would a <a href=\"http://en.wikipedia.org/wiki/Mole_(unit)\">mole</a> of hot, sticky, chocolate-jelly doughnuts be? How many miles does a person walk in a lifetime? How many times can you outline the continental US in shoelaces? How long would it take to read every book in the library? How long can you shower and still make it more environmentally friendly than taking a bath?</p>\n<p><em><a href=\"http://www.amazon.com/Ballparking-Practical-Impractical-Sports-Questions/dp/0762443456/\">Ballparking</a></em> (2012): How many bolts are in the floor of the Boston Garden basketball court? How many lanes would you need for the outermost lane of a running track to be the length of a marathon? How hard would you have to hit a baseball for it to never land?</p>\n<p><a href=\"http://www.physics.umd.edu/perg/fermi/fermi.htm\">University of Maryland Fermi Problems Site</a>: How many sheets of letter-sized paper are used by all students at the University of Maryland in one semester? How many blades of grass are in the lawn of a typical suburban house in the summer? How many golf balls can be fit into a typical suitcase?</p>\n<p><a href=\"http://www.stupidcalculations.com/\">Stupid Calculations</a>: a blog of silly-topic Fermi estimates.</p>\n<p>&nbsp;</p>\n<h3>Conclusion</h3>\n<p>Fermi estimates can help you become more efficient in your day-to-day life, and give you increased confidence in the decisions you face. If you want to become proficient in making Fermi estimates, I recommend practicing them 30 minutes per day for three months. In that time, you should be able to make about (2 Fermis per day)&times;(90 days) = 180 Fermi estimates.</p>\n<p>If you'd like to write down your estimation attempts and then publish them here, please do so as a reply to <a href=\"/lw/h5e/fermi_estimates/8ppa\">this comment</a>. One Fermi estimate per comment, please!</p>\n<p>Alternatively, post your Fermi estimates to the <a href=\"http://www.reddit.com/r/estimation/\">dedicated subreddit</a>.</p>\n<p><em>Update 03/06/2017: I keep getting requests from professors to use this in their classes, so: I license anyone to use this article noncommercially, so long as its authorship is noted (me = Luke Muehlhauser).</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bh7uxTTqmsQ8jZJdB": 3, "AeqCtS3BaY3cwzKAs": 12}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PsEppdvgRisz5xAHG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 70, "baseScore": 103, "extendedScore": null, "score": 0.000237, "legacy": true, "legacyId": "22226", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 103, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Just before the <a href=\"http://is.gd/NeBfVu\">Trinity test</a>, Enrico Fermi decided he wanted a rough estimate of the blast's power before the diagnostic data came in. So he dropped some pieces of paper from his hand as the blast wave passed him, and used this to estimate that the blast was equivalent to 10 kilotons of TNT. His guess was remarkably accurate for having so little data: the true answer turned out to be 20 kilotons of TNT.</p>\n<p>Fermi had a knack for making roughly-accurate estimates with very little data, and therefore such an estimate is known today as a <a href=\"http://en.wikipedia.org/wiki/Fermi_problem\">Fermi estimate</a>.</p>\n<p>Why bother with Fermi estimates, if your estimates are likely to be off by a factor of 2 or even 10? Often, getting an estimate within a factor of 10 or 20 is enough to make a decision. So Fermi estimates can save you a lot of time, especially as you gain more practice at making them.</p>\n<p>&nbsp;</p>\n<h3 id=\"Estimation_tips\">Estimation tips</h3>\n<p><small>These first two sections are adapted from <em><a href=\"http://www.amazon.com/Guesstimation-2-0-Solving-Todays-Problems/dp/069115080X/\">Guestimation 2.0</a></em>.</small></p>\n<p><strong>Dare to be imprecise.</strong> Round things off enough to do the calculations in your head. I call this the <a href=\"http://en.wikipedia.org/wiki/Spherical_cow\">spherical cow principle</a>, after a joke about how physicists oversimplify things to make calculations feasible:</p>\n<blockquote>\n<p>Milk production at a dairy farm was low, so the farmer asked a local university for help. A multidisciplinary team of professors was assembled, headed by a theoretical physicist. After two weeks of observation and analysis, the physicist told the farmer, \"I have the solution, but it only works in the case of spherical cows in a vacuum.\"</p>\n</blockquote>\n<p>By the spherical cow principle, there are 300 days in a year, people are six feet (or 2 meters) tall, the circumference of the Earth is 20,000 mi (or 40,000 km), and cows are spheres of meat and bone 4 feet (or 1 meter) in diameter.</p>\n<p><strong>Decompose the problem.</strong> Sometimes you can give an estimate in one step, within a factor of 10. (How much does a new compact car cost? $20,000.) But in most cases, you'll need to break the problem into several pieces, estimate each of them, and then recombine them. I'll give several examples below.</p>\n<p><strong>Estimate by bounding.</strong> Sometimes it is easier to give lower and upper bounds than to give a point estimate. How much time per day does the average 15-year-old watch TV? I don't spend any time with 15-year-olds, so I haven't a clue. It could be 30 minutes, or 3 hours, or 5 hours, but I'm pretty confident it's more than 2 minutes and less than 7 hours (400 minutes, by the spherical cow principle).</p>\n<p>Can we convert those bounds into an estimate? You bet. But we don't do it by taking the <em>average</em>. That would give us (2 mins + 400 mins)/2 = 201 mins, which is within a factor of 2 from our upper bound, but a factor <em>100</em> greater than our lower bound. Since our goal is to estimate the answer within a factor of 10, we'll probably be way off.</p>\n<p>Instead, we take the <em>geometric mean</em> \u2014 the square root of the product of our upper and lower bounds. But square roots often require a calculator, so instead we'll take the <em>approximate</em> geometric mean (AGM). To do that, we average the coefficients and exponents of our upper and lower bounds.</p>\n<p>So what is the AGM of 2 and 400? Well, 2 is 2\u00d710<sup>0</sup>, and 400 is 4\u00d710<sup>2</sup>. The average of the coefficients (2 and 4) is 3; the average of the exponents (0 and 2) is 1. So, the AGM of 2 and 400 is 3\u00d710<sup>1</sup>, or 30. The precise geometric mean of 2 and 400 turns out to be 28.28. Not bad.</p>\n<p>What if the sum of the exponents is an odd number? Then we round the resulting exponent down, and multiply the final answer by three. So suppose my lower and upper bounds for how much TV the average 15-year-old watches had been 20 mins and 400 mins. Now we calculate the AGM like this: 20 is 2\u00d710<sup>1</sup>, and 400 is still 4\u00d710<sup>2</sup>. The average of the coefficients (2 and 4) is 3; the average of the exponents (1 and 2) is 1.5. So we round the exponent down to 1, and we multiple the final result by three: 3(3\u00d710<sup>1</sup>) = 90 mins. The precise geometric mean of 20 and 400 is 89.44. Again, not bad.</p>\n<p><strong>Sanity-check your answer</strong>. You should always sanity-check your final estimate by comparing it to some reasonable analogue. You'll see examples of this below.</p>\n<p><strong>Use Google as needed</strong>. You can often quickly find the exact quantity you're trying to estimate on Google, or at least some <em>piece</em> of the problem. In those cases, it's probably not worth trying to estimate it <em>without</em> Google.</p>\n<p><a id=\"more\"></a></p>\n<h3><br></h3>\n<h3 id=\"Fermi_estimation_failure_modes\">Fermi estimation failure modes</h3>\n<p>Fermi estimates go wrong in one of three ways.</p>\n<p>First, we might badly overestimate or underestimate a quantity. Decomposing the problem, estimating from bounds, and looking up particular pieces on Google should protect against this. Overestimates and underestimates for the different pieces of a problem <a href=\"http://en.wikipedia.org/wiki/Fermi_problem#Explanation\">should roughly cancel out</a>, especially when there are many pieces.</p>\n<p>Second, we might model the problem incorrectly. If you estimate teenage deaths per year on the assumption that most teenage deaths are from suicide, your estimate will probably be way off, because most teenage deaths are caused by accidents. To avoid this, try to decompose each Fermi problem by using a model you're fairly confident of, even if it means you need to use more pieces or give wider bounds when estimating each quantity.</p>\n<p>Finally, we might choose a nonlinear problem. Normally, we assume that if one object can get some result, then two objects will get twice the result. Unfortunately, this doesn't hold true for nonlinear problems. If one motorcycle on a highway can transport a person at 60 miles per hour, then 30 motorcycles can transport 30 people at 60 miles per hour. However, 10<sup>4</sup> motorcycles cannot transport 10<sup>4</sup> people at 60 miles per hour, because there will be a huge traffic jam on the highway. This problem is difficult to avoid, but with practice you will get better at recognizing when you're facing a nonlinear problem.</p>\n<p>&nbsp;</p>\n<h3 id=\"Fermi_practice\">Fermi practice</h3>\n<p>When getting started with Fermi practice, I recommend estimating quantities that you can easily look up later, so that you can see how accurate your Fermi estimates tend to be. Don't look up the answer before constructing your estimates, though! Alternatively, you might allow yourself to look up particular pieces of the problem \u2014 e.g. the <a href=\"http://en.wikipedia.org/wiki/List_of_religious_populations#Adherent_estimates\">number of Sikhs</a> in the world, the formula for <a href=\"http://en.wikipedia.org/wiki/Escape_velocity\">escape velocity</a>, or the <a href=\"http://en.wikipedia.org/wiki/Gross_world_product\">gross world product</a>&nbsp;\u2014 but not the final quantity you're trying to estimate.</p>\n<p>Most books about Fermi estimates are filled with examples done by Fermi estimate experts, and in many cases the estimates were probably adjusted after the author looked up the true answers. This post is different. My examples below are estimates I made <em>before</em> looking up the answer online, so you can get a realistic picture of how this works from someone who isn't \"cheating.\" Also, there will be no selection effect: I'm going to do four Fermi estimates for this post, and I'm not going to throw out my estimates if they are way off. Finally, I'm not all that practiced doing \"Fermis\" myself, so you'll get to see what it's like for a relative newbie to go through the process. In short, I hope to give you a realistic picture of what it's like to do Fermi practice when you're just getting started.</p>\n<p>&nbsp;</p>\n<h3 id=\"Example_1__How_many_new_passenger_cars_are_sold_each_year_in_the_USA_\">Example 1: How many new passenger cars are sold each year in the USA?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/aMD9a4s.jpg\" alt=\"\">The classic Fermi problem is \"How many piano tuners are there in Chicago?\" This kind of estimate is useful if you want to know the approximate size of the customer base for a new product you might develop, for example. But I'm not sure anyone knows how many piano tuners there <em>really</em> are in Chicago, so let's try a different one we probably <em>can</em> look up later: \"How many new passenger cars are sold each year in the USA?\"</p>\n<p>As with all Fermi problems, there are many different models we could build. For example, we could estimate how many new cars a dealership sells per month, and then we could estimate how many dealerships there are in the USA. Or we could try to estimate the annual demand for new cars from the country's population. Or, if we happened to have read how many Toyota Corollas were sold last year, we could try to build our estimate from there.</p>\n<p>The second model looks more robust to me than the first, since I know roughly how many Americans there are, but I have no idea how many new-car dealerships there are. Still, let's try it both ways. (I <em>don't</em> happen to know how many new Corollas were sold last year.)</p>\n<h4 id=\"Approach__1__Car_dealerships\">Approach #1: Car dealerships</h4>\n<p>How many new cars does a dealership sell per month, on average? Oofta, I dunno. To support the dealership's existence, I assume it has to be at least 5. But it's probably not more than 50, since most dealerships are in small towns that don't get much action. To get my point estimate, I'll take the AGM of 5 and 50. 5 is 5\u00d710<sup>0</sup>, and 50 is 5\u00d710<sup>1</sup>. Our exponents sum to an odd number, so I'll round the exponent down to 0 and multiple the final answer by 3. So, my estimate of how many new cars a new-car dealership sells per month is 3(5\u00d710<sup>0</sup>) = 15.</p>\n<p>Now, how many new-car dealerships are there in the USA? This could be tough. I know several towns of only 10,000 people that have 3 or more new-car dealerships. I don't recall towns much smaller than that having new-car dealerships, so let's exclude them. How many cities of 10,000 people or more are there in the USA? I have no idea. So let's decompose this problem a bit more.</p>\n<p>How many <em>counties</em> are there in the USA? I remember seeing a map of counties colored by which national ancestry was dominant in that county. (Germany was the most common.) Thinking of that map, there were definitely more than 300 counties on it, and definitely less than 20,000. What's the AGM of 300 and 20,000? Well, 300 is 3\u00d710<sup>2</sup>, and 20,000 is 2\u00d710<sup>4</sup>. The average of coefficients 3 and 2 is 2.5, and the average of exponents 2 and 4 is 3. So the AGM of 300 and 20,000 is 2.5\u00d710<sup>3</sup> = 2500.</p>\n<p>Now, how many towns of 10,000 people or more are there per county? I'm pretty sure the average must be larger than 10 and smaller than 5000. The AGM of 10 and 5000 is 300. (I won't include this calculation in the text anymore; you know how to do it.)</p>\n<p>Finally, how many car dealerships are there in cities of 10,000 or more people, on average? Most such towns are pretty small, and probably have 2-6 car dealerships. The largest cities will have many more: maybe 100-ish. So I'm pretty sure the average number of car dealerships in cities of 10,000 or more people must be between 2 and 30. The AGM of 2 and 30 is 7.5.</p>\n<p>Now I just multiply my estimates:</p>\n<p>[15 new cars sold per month per dealership] \u00d7 [12 months per year] \u00d7 [7.5 new-car dealerships per city of 10,000 or more people] \u00d7 [300 cities of 10,000 or more people per county] \u00d7 [2500 counties in the USA] = 1,012,500,000.</p>\n<p>A sanity check immediately invalidates this answer. There's no way that 300 million American citizens buy a <em>billion</em> new cars per year. I suppose they <em>might</em> buy 100 million new cars per year, which would be within a factor of 10 of my estimate, but I doubt it.</p>\n<p>As I suspected, my first approach was problematic. Let's try the second approach, starting from the population of the USA.</p>\n<h4 id=\"Approach__2__Population_of_the_USA\">Approach #2: Population of the USA</h4>\n<p>There are about 300 million Americans. How many of them own a car? Maybe 1/3 of them, since children don't own cars, many people in cities don't own cars, and many households share a car or two between the adults in the household.</p>\n<p>Of the 100 million people who own a car, how many of them bought a <em>new</em> car in the past 5 years? Probably less than half; most people buy used cars, right? So maybe 1/4 of car owners bought a new car in the past 5 years, which means 1 in 20 car owners bought a new car in the past <em>year</em>.</p>\n<p>100 million / 20 = 5 million new cars sold each year in the USA. That doesn't seem crazy, though perhaps a bit low. I'll take this as my estimate.</p>\n<p>Now is your last chance to try this one on your own; in the next paragraph I'll reveal the true answer.</p>\n<p>\u2026</p>\n<p>\u2026</p>\n<p>...</p>\n<p>Now, I Google <a href=\"https://www.google.com/#hl=en&amp;output=search&amp;sclient=psy-ab&amp;q=new+cars+sold+per+year+in+the+USA&amp;oq=new+cars+sold+per+year+in+the+USA\">new cars sold per year in the USA</a>. Wikipedia is the first result, and it <a href=\"http://en.wikipedia.org/wiki/Passenger_vehicles_in_the_United_States#Sales\">says</a> \"In the year 2009, about 5.5 million new passenger cars were sold in the United States according to the U.S. Department of Transportation.\"</p>\n<p>Boo-yah!</p>\n<p>&nbsp;</p>\n<h3 id=\"Example_2__How_many_fatalities_from_passenger_jet_crashes_have_there_been_in_the_past_20_years_\">Example 2: How many fatalities from passenger-jet crashes have there been in the past 20 years?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/TyoL5r1.jpg\" alt=\"\">Again, there are multiple models I could build. I could try to estimate how many passenger-jet flights there are per year, and then try to estimate the frequency of crashes and the average number of fatalities per crash. Or I could just try to guess the total number of passenger-jet crashes around the world per year and go from there.</p>\n<p>As far as I can tell, passenger-jet crashes (with fatalities) almost always make it on the TV news and (more relevant to me) the front page of Google News. Exciting footage and multiple deaths will do that. So working just from memory, it feels to me like there are about 5 passenger-jet crashes (with fatalities) per year, so maybe there were about 100 passenger jet crashes with fatalities in the past 20 years.</p>\n<p>Now, how many fatalities per crash? From memory, it seems like there are usually two kinds of crashes: ones where <em>everybody</em> dies (meaning: about 200 people?), and ones where only about 10 people die. I think the \"everybody dead\" crashes are less common, maybe 1/4 as common. So the average crash with fatalities should cause (200\u00d71/4)+(10\u00d73/4) = 50+7.5 = 60, by the spherical cow principle.</p>\n<p>60 fatalities per crash \u00d7 100 crashes with fatalities over the past 20 years = 6000 passenger fatalities from passenger-jet crashes in the past 20 years.</p>\n<p>Last chance to try this one on your own...</p>\n<p>\u2026</p>\n<p>\u2026</p>\n<p>\u2026</p>\n<p>A Google search again brings me to Wikipedia, which reveals that an organization called ACRO <a href=\"http://en.wikipedia.org/wiki/Aviation_accidents_and_incidents#Aircraft_Crashes_Record_Office_.28ACRO.29\">records</a> the number of airline fatalities each year. Unfortunately for my purposes, they include fatalities from cargo flights. After more Googling, I tracked down Boeing's \"<a href=\"http://www.boeing.com/news/techissues/pdf/statsum.pdf\">Statistical Summary of Commercial Jet Airplane Accidents, 1959-2011</a>,\" but that report excludes jets lighter than 60,000 pounds, and excludes crashes caused by hijacking or terrorism.</p>\n<p>It appears it would be a major research project to figure out the true answer to our question, but let's at least estimate it from the ACRO data. Luckily, ACRO has statistics on which percentage of accidents are from passenger and other kinds of flights, which I'll take as a proxy for which percentage of <em>fatalities</em> are from different kinds of flights. According to <a href=\"http://www.baaa-acro.com/Statistiques%20diverses.htm\">that page</a>, 35.41% of accidents are from \"regular schedule\" flights, 7.75% of accidents are from \"private\" flights, 5.1% of accidents are from \"charter\" flights, and 4.02% of accidents are from \"executive\" flights. I think that captures what I had in mind as \"passenger-jet flights.\" So we'll guess that 52.28% of fatalities are from \"passenger-jet flights.\" I won't round this to 50% because we're not doing a Fermi estimate right now; we're trying to <em>check</em> a Fermi estimate.</p>\n<p>According to ACRO's <a href=\"http://www.baaa-acro.com/archives/Accidents.htm\">archives</a>, there were 794 fatalities in 2012, 828 fatalities in 2011, and... well, from 1993-2012 there were a total of 28,021 fatalities. And 52.28% of that number is 14,649.</p>\n<p>So my estimate of 6000 was off by less than a factor of 3!</p>\n<p>&nbsp;</p>\n<h3 id=\"Example_3__How_much_does_the_New_York_state_government_spends_on_K_12_education_every_year_\">Example 3: How much does the New York state government spends on K-12 education every year?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/N5zf5d3.jpg\" alt=\"\">How might I estimate this? First I'll estimate the number of K-12 students in New York, and then I'll estimate how much this should cost.</p>\n<p>How many people live in New York? I seem to recall that NYC's greater metropolitan area is about 20 million people. That's probably most of the state's population, so I'll guess the total is about 30 million.</p>\n<p>How many of those 30 million people attend K-12 public schools? I can't remember what the United States' <a href=\"http://en.wikipedia.org/wiki/Population_pyramid\">population pyramid</a> looks like, but I'll guess that about 1/6 of Americans (and hopefully New Yorkers) attend K-12 at any given time. So that's 5 million kids in K-12 in New York. The number attending private schools probably isn't large enough to matter for factor-of-10 estimates.</p>\n<p>How much does a year of K-12 education cost for one child? Well, I've heard teachers don't get paid much, so after benefits and taxes and so on I'm guessing a teacher costs about $70,000 per year. How big are class sizes these days, 30 kids? By the spherical cow principle, that's about $2,000 per child, per year on teachers' salaries. But there are lots of other expenses: buildings, transport, materials, support staff, etc. And maybe some money goes to private schools or other organizations. Rather than estimate all those things, I'm just going to guess that about $10,000 is spent per child, per year.</p>\n<p>If that's right, then New York spends $50 billion per year on K-12 education.</p>\n<p>Last chance to make your own estimate!</p>\n<p>\u2026</p>\n<p>\u2026</p>\n<p>\u2026</p>\n<p>Before I did the Fermi estimate, I had <a href=\"http://www.juliagalef.com/\">Julia Galef</a> check Google to find this statistic, but she didn't give me any hints about the number. Her two sources were <a href=\"http://www.wolframalpha.com/input/?i=new+york+state+spending+education+k-12\">Wolfram Alpha</a> and a <a href=\"http://governor.ny.gov/citizenconnects/?q=content/web-chat-deputy-secretary-education-david-wakelyn\">web chat</a> with New York's Deputy Secretary for Education, both of which put the figure at approximately $53 billion.</p>\n<p>Which is definitely within a factor of 10 from $50 billion. :)</p>\n<p>&nbsp;</p>\n<h3 id=\"Example_4__How_many_plays_of_My_Bloody_Valentine_s__Only_Shallow__have_been_reported_to_last_fm_\">Example 4: How many plays of My Bloody Valentine's \"Only Shallow\" have been reported to last.fm?</h3>\n<p><img style=\"float: right; padding: 10px;\" src=\"http://i.imgur.com/sr8R6T5.jpg\" alt=\"\"><a href=\"http://en.wikipedia.org/wiki/Last.fm\">Last.fm</a> makes a record of every audio track you play, if you enable the relevant feature or plugin for the music software on your phone, computer, or other device. Then, the service can show you charts and statistics about your listening patterns, and make personalized music recommendations from them. My own charts are <a href=\"http://www.last.fm/user/lukeprog/charts\">here</a>. (Chuck Wild / <a href=\"http://www.liquidmindmusic.com/\">Liquid Mind</a> dominates my charts because I used to listen to that artist while sleeping.)</p>\n<p>My Fermi problem is: How many plays of \"<a href=\"http://www.youtube.com/watch?v=FyYMzEplnfU\">Only Shallow</a>\" have been reported to last.fm?</p>\n<p>My Bloody Valentine is a popular \"indie\" rock band, and \"Only Shallow\" is probably one of their most popular tracks. How can I estimate how many plays it has gotten on last.fm?</p>\n<p>What do I know that might help?</p>\n<ul>\n<li>I know last.fm is popular, but I don't have a sense of whether they have 1 million users, 10 million users, or 100 million users. </li>\n<li>I accidentally saw on Last.fm's Wikipedia page that just over 50 billion track plays have been recorded. We'll consider that to be one piece of data I looked up to help with my estimate. </li>\n<li>I seem to recall reading that major music services like iTunes and Spotify have about 10 million tracks. Since last.fm records songs that people play from their private collections, whether or not they exist in popular databases, I'd guess that the total number of different tracks named in last.fm's database is an order of magnitude larger, for about 100 million tracks named in its database.</li>\n</ul>\n<p>I would guess that track plays obey a <a href=\"http://en.wikipedia.org/wiki/Power_law\">power law</a>, with the most popular tracks getting vastly more plays than tracks of average popularity. I'd also guess that there are maybe 10,000 tracks more popular than \"Only Shallow.\"</p>\n<p>Next, I simulated being good at math by having <a href=\"/user/Qiaochu_Yuan/overview/\">Qiaochu Yuan</a> show me how to do the calculation. I also allowed myself to use a calculator. Here's what we do:</p>\n<blockquote>\n<p>Plays(rank) = C/(rank<sup>P</sup>)</p>\n</blockquote>\n<p>P is the exponent for the power law, and C is the proportionality constant. We'll guess that P is 1, a common power law exponent for empirical data. And we calculate C like so:</p>\n<blockquote>\n<p>C \u2248 [total plays]/ln(total songs) \u2248 2.5 billion</p>\n</blockquote>\n<p>So now, assuming the song's rank is 10,000, we have:</p>\n<blockquote>\n<p>Plays(10<sup>4</sup>) = 2.5\u00d710<sup>9</sup>/(10<sup>4</sup>)</p>\n<p>Plays(\"Only Shallow\") = 250,000</p>\n</blockquote>\n<p>That seems high, but let's roll with it. Last chance to make your own estimate!</p>\n<p>\u2026</p>\n<p>\u2026</p>\n<p>...</p>\n<p>And when I <a href=\"http://www.last.fm/music/My+Bloody+Valentine/_/Only+Shallow\">check the answer</a>, I see that \"Only Shallow\" has about 2 million plays on last.fm.</p>\n<p>My answer was off by less than a factor of 10, which for a Fermi estimate is called <em>victory</em>!</p>\n<p>Unfortunately, last.fm doesn't publish all-time track rankings or other data that might help me to determine which parts of my model were correct and incorrect.</p>\n<p>&nbsp;</p>\n<h3 id=\"Further_examples\">Further examples</h3>\n<p>I focused on examples that are similar in structure to the kinds of quantities that entrepreneurs and CEOs might want to estimate, but of course there are all kinds of things one can estimate this way. Here's a sampling of Fermi problems featured in various books and websites on the subject:</p>\n<p><a href=\"http://www.fermiquestions.com/\">Play Fermi Questions</a>: 2100 Fermi problems and counting.</p>\n<p><em><a href=\"http://www.amazon.com/Guesstimation-Solving-Worlds-Problems-Cocktail/dp/0691129495/\">Guesstimation</a></em> (2008): If all the humans in the world were crammed together, how much area would we require? What would be the mass of all 10<sup>8</sup> MongaMillions lottery tickets? On average, how many people are airborne over the US at any given moment? How many cells are there in the human body? How many people in the world are picking their nose right now? What are the relative costs of fuel for NYC rickshaws and automobiles?</p>\n<p><em><a href=\"http://www.amazon.com/Guesstimation-2-0-Solving-Todays-Problems/dp/069115080X/\">Guesstimation 2.0</a> (2011): If we launched a trillion one-dollar bills into the atmosphere, what fraction of sunlight hitting the Earth could we block with those dollar bills? If a million monkeys typed randomly on a million typewriters for a year, what is the longest string of consecutive correct letters of *The Cat in the Hat</em> (starting from the beginning) would they likely type? How much energy does it take to crack a nut? If an airline asked its passengers to urinate before boarding the airplane, how much fuel would the airline save per flight? What is the radius of the largest rocky sphere from which we can reach escape velocity by jumping?</p>\n<p><em><a href=\"http://www.amazon.com/How-Many-Licks-Estimate-Anything/dp/0762435607/\">How Many Licks?</a></em> (2009): What fraction of Earth's volume would a <a href=\"http://en.wikipedia.org/wiki/Mole_(unit)\">mole</a> of hot, sticky, chocolate-jelly doughnuts be? How many miles does a person walk in a lifetime? How many times can you outline the continental US in shoelaces? How long would it take to read every book in the library? How long can you shower and still make it more environmentally friendly than taking a bath?</p>\n<p><em><a href=\"http://www.amazon.com/Ballparking-Practical-Impractical-Sports-Questions/dp/0762443456/\">Ballparking</a></em> (2012): How many bolts are in the floor of the Boston Garden basketball court? How many lanes would you need for the outermost lane of a running track to be the length of a marathon? How hard would you have to hit a baseball for it to never land?</p>\n<p><a href=\"http://www.physics.umd.edu/perg/fermi/fermi.htm\">University of Maryland Fermi Problems Site</a>: How many sheets of letter-sized paper are used by all students at the University of Maryland in one semester? How many blades of grass are in the lawn of a typical suburban house in the summer? How many golf balls can be fit into a typical suitcase?</p>\n<p><a href=\"http://www.stupidcalculations.com/\">Stupid Calculations</a>: a blog of silly-topic Fermi estimates.</p>\n<p>&nbsp;</p>\n<h3 id=\"Conclusion\">Conclusion</h3>\n<p>Fermi estimates can help you become more efficient in your day-to-day life, and give you increased confidence in the decisions you face. If you want to become proficient in making Fermi estimates, I recommend practicing them 30 minutes per day for three months. In that time, you should be able to make about (2 Fermis per day)\u00d7(90 days) = 180 Fermi estimates.</p>\n<p>If you'd like to write down your estimation attempts and then publish them here, please do so as a reply to <a href=\"/lw/h5e/fermi_estimates/8ppa\">this comment</a>. One Fermi estimate per comment, please!</p>\n<p>Alternatively, post your Fermi estimates to the <a href=\"http://www.reddit.com/r/estimation/\">dedicated subreddit</a>.</p>\n<p><em>Update 03/06/2017: I keep getting requests from professors to use this in their classes, so: I license anyone to use this article noncommercially, so long as its authorship is noted (me = Luke Muehlhauser).</em></p>", "sections": [{"title": "Estimation tips", "anchor": "Estimation_tips", "level": 1}, {"title": "Fermi estimation failure modes", "anchor": "Fermi_estimation_failure_modes", "level": 1}, {"title": "Fermi practice", "anchor": "Fermi_practice", "level": 1}, {"title": "Example 1: How many new passenger cars are sold each year in the USA?", "anchor": "Example_1__How_many_new_passenger_cars_are_sold_each_year_in_the_USA_", "level": 1}, {"title": "Approach #1: Car dealerships", "anchor": "Approach__1__Car_dealerships", "level": 2}, {"title": "Approach #2: Population of the USA", "anchor": "Approach__2__Population_of_the_USA", "level": 2}, {"title": "Example 2: How many fatalities from passenger-jet crashes have there been in the past 20 years?", "anchor": "Example_2__How_many_fatalities_from_passenger_jet_crashes_have_there_been_in_the_past_20_years_", "level": 1}, {"title": "Example 3: How much does the New York state government spends on K-12 education every year?", "anchor": "Example_3__How_much_does_the_New_York_state_government_spends_on_K_12_education_every_year_", "level": 1}, {"title": "Example 4: How many plays of My Bloody Valentine's \"Only Shallow\" have been reported to last.fm?", "anchor": "Example_4__How_many_plays_of_My_Bloody_Valentine_s__Only_Shallow__have_been_reported_to_last_fm_", "level": 1}, {"title": "Further examples", "anchor": "Further_examples", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "108 comments"}], "headingsCount": 13}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 110, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-12T01:56:59.745Z", "modifiedAt": null, "url": null, "title": "Pay other people to go vegetarian for you?", "slug": "pay-other-people-to-go-vegetarian-for-you", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.128Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HxqXTzuamd3hZ5nMQ/pay-other-people-to-go-vegetarian-for-you", "pageUrlRelative": "/posts/HxqXTzuamd3hZ5nMQ/pay-other-people-to-go-vegetarian-for-you", "linkUrl": "https://www.lesswrong.com/posts/HxqXTzuamd3hZ5nMQ/pay-other-people-to-go-vegetarian-for-you", "postedAtFormatted": "Friday, April 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pay%20other%20people%20to%20go%20vegetarian%20for%20you%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APay%20other%20people%20to%20go%20vegetarian%20for%20you%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHxqXTzuamd3hZ5nMQ%2Fpay-other-people-to-go-vegetarian-for-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pay%20other%20people%20to%20go%20vegetarian%20for%20you%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHxqXTzuamd3hZ5nMQ%2Fpay-other-people-to-go-vegetarian-for-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHxqXTzuamd3hZ5nMQ%2Fpay-other-people-to-go-vegetarian-for-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 261, "htmlBody": "<p>I <a href=\"http://www.jefftk.com/news/2012-04-11\">notice</a> that a large fraction of Effective Altruism people are vegetarian.  This makes sense: in general Effective Altruists take moral issues seriously, even when that means changing your lifestyle.  I'm not sure it's a good <a href=\"http://www.jefftk.com/news/2012-06-22\">balance</a>, though.</p>\n<p>One way to think about this is to convert it into money.  How much would I need to be paid to give up eating meat?  All animal products? How much money would I need to spend on myself to be about as happy as I would be with less money but continuing to eat animals?  I'd probably be willing to go vegetarian for about $500/year, vegan for maybe $2000/year.</p>\n<p>It turns out you can probably pay to convince other people to be vegetarian much more cheaply than that.  I estimate the cost of a vegetarian-year at <a href=\"http://www.jefftk.com/news/2011-11-10\">$4.29 to $536</a> while Brian Tomasik estimates <a href=\"http://www.utilitarian-essays.com/veg-ads.html\">$11</a> with better methodology (which I <a href=\"http://www.jefftk.com/news/2012-03-07\">looked</a> <a href=\"http://www.jefftk.com/news/2012-03-18\">at</a>).  This is by <a href=\"http://www.effectiveanimalactivism.org/veg-ads\">placing ads</a> on facebook for a <a href=\"http://www.whosagainstanimalcruelty.org/\">site</a><a></a> where people can watch an animial cruelty video and ideally become vegetarian or vegan.</p>\n<p>If you would get more than $11/year worth of enjoyment out of continuing to eat meat, why not give $11/year to convince someone else to not eat meat for you?  Or give $50/year and be on the safe side?</p>\n<p>(While you're giving money, you should probably give it to the organization that you think will do the most good with it, which I think is probably one of GiveWell's <a href=\"http://www.givewell.org/charities/top-charities\">top charities</a>.  The nice thing about money as opposed to actions is that it's easy to redirect.)</p>\n<p><small><em>I also posted this <a href=\"http://www.jefftk.com/news/2013-04-11\">on my blog</a>.</em></small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HxqXTzuamd3hZ5nMQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 19, "extendedScore": null, "score": 1.1660154809202348e-06, "legacy": true, "legacyId": "22278", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 92, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-12T03:04:13.611Z", "modifiedAt": null, "url": null, "title": "Meetup : Cincinnati near-Schelling day", "slug": "meetup-cincinnati-near-schelling-day", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RolfAndreassen", "createdAt": "2009-04-17T19:37:23.246Z", "isAdmin": false, "displayName": "RolfAndreassen"}, "userId": "KLJmn2HYWEu4tBKcC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CToBhcLCBt97fobhC/meetup-cincinnati-near-schelling-day", "pageUrlRelative": "/posts/CToBhcLCBt97fobhC/meetup-cincinnati-near-schelling-day", "linkUrl": "https://www.lesswrong.com/posts/CToBhcLCBt97fobhC/meetup-cincinnati-near-schelling-day", "postedAtFormatted": "Friday, April 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cincinnati%20near-Schelling%20day&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cincinnati%20near-Schelling%20day%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCToBhcLCBt97fobhC%2Fmeetup-cincinnati-near-schelling-day%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cincinnati%20near-Schelling%20day%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCToBhcLCBt97fobhC%2Fmeetup-cincinnati-near-schelling-day", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCToBhcLCBt97fobhC%2Fmeetup-cincinnati-near-schelling-day", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lf'>Cincinnati near-Schelling day</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 April 2013 04:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">3060 Marshall Avenue, apartment 414, Cincinnati</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It turns out that Schelling Day is not, in fact, a Schelling point locally; but we will run the ritual anyway, with better snacks.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lf'>Cincinnati near-Schelling day</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CToBhcLCBt97fobhC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 1.1660618264752257e-06, "legacy": true, "legacyId": "22279", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cincinnati_near_Schelling_day\">Discussion article for the meetup : <a href=\"/meetups/lf\">Cincinnati near-Schelling day</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 April 2013 04:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">3060 Marshall Avenue, apartment 414, Cincinnati</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It turns out that Schelling Day is not, in fact, a Schelling point locally; but we will run the ritual anyway, with better snacks.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cincinnati_near_Schelling_day1\">Discussion article for the meetup : <a href=\"/meetups/lf\">Cincinnati near-Schelling day</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cincinnati near-Schelling day", "anchor": "Discussion_article_for_the_meetup___Cincinnati_near_Schelling_day", "level": 1}, {"title": "Discussion article for the meetup : Cincinnati near-Schelling day", "anchor": "Discussion_article_for_the_meetup___Cincinnati_near_Schelling_day1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-12T05:33:14.994Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Real-Life Anthropic Weirdness", "slug": "seq-rerun-real-life-anthropic-weirdness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:36.694Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iYnKzCACJvHg4nEcH/seq-rerun-real-life-anthropic-weirdness", "pageUrlRelative": "/posts/iYnKzCACJvHg4nEcH/seq-rerun-real-life-anthropic-weirdness", "linkUrl": "https://www.lesswrong.com/posts/iYnKzCACJvHg4nEcH/seq-rerun-real-life-anthropic-weirdness", "postedAtFormatted": "Friday, April 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Real-Life%20Anthropic%20Weirdness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Real-Life%20Anthropic%20Weirdness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYnKzCACJvHg4nEcH%2Fseq-rerun-real-life-anthropic-weirdness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Real-Life%20Anthropic%20Weirdness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYnKzCACJvHg4nEcH%2Fseq-rerun-real-life-anthropic-weirdness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYnKzCACJvHg4nEcH%2Fseq-rerun-real-life-anthropic-weirdness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Today's post, <a href=\"/lw/7w/reallife_anthropic_weirdness/\">Real-Life Anthropic Weirdness</a> was originally published on 05 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries#Real-Life_Anthropic_Weirdness\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Extremely rare events can create bizarre circumstances in which people may not be able to effectively communicate about improbability.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h6o/seq_rerun_incremental_progress_and_the_valley/\">Incremental Progress and the Valley</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iYnKzCACJvHg4nEcH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.1661645666986505e-06, "legacy": true, "legacyId": "22280", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kKAmxmQq9umJiMFSp", "2smbn9mPheS4gdigC", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-12T10:49:25.000Z", "modifiedAt": null, "url": null, "title": "Noisy Poll Results And Reptilian Muslim Climatologists from Mars", "slug": "noisy-poll-results-and-reptilian-muslim-climatologists-from", "viewCount": null, "lastCommentedAt": "2019-01-10T19:52:25.792Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CsKrQdQJJCFPjfKjF/noisy-poll-results-and-reptilian-muslim-climatologists-from", "pageUrlRelative": "/posts/CsKrQdQJJCFPjfKjF/noisy-poll-results-and-reptilian-muslim-climatologists-from", "linkUrl": "https://www.lesswrong.com/posts/CsKrQdQJJCFPjfKjF/noisy-poll-results-and-reptilian-muslim-climatologists-from", "postedAtFormatted": "Friday, April 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Noisy%20Poll%20Results%20And%20Reptilian%20Muslim%20Climatologists%20from%20Mars&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANoisy%20Poll%20Results%20And%20Reptilian%20Muslim%20Climatologists%20from%20Mars%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCsKrQdQJJCFPjfKjF%2Fnoisy-poll-results-and-reptilian-muslim-climatologists-from%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Noisy%20Poll%20Results%20And%20Reptilian%20Muslim%20Climatologists%20from%20Mars%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCsKrQdQJJCFPjfKjF%2Fnoisy-poll-results-and-reptilian-muslim-climatologists-from", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCsKrQdQJJCFPjfKjF%2Fnoisy-poll-results-and-reptilian-muslim-climatologists-from", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1590, "htmlBody": "<p><b>Beware of Phantom Lizardmen</b></p>\n<p>I have only done a little bit of social science research, but it was enough to make me hate people. One study I helped with analyzed whether people from different countries had different answers on a certain psychological test. So we put up a website where people answered some questions about themselves (like &#8220;what country are you from?&#8221;) and then took the psychological test.</p>\n<p>And so of course people screwed it up in every conceivable way. There were the merely dumb, like the guy who put &#8220;male&#8221; as his nationality and &#8220;American&#8221; as his gender. But there were also the actively malicious or at least annoying, like the people (yes, more than one) who wrote in &#8220;Martian&#8221;.</p>\n<p>I think we all probably know someone like this, maybe a couple people like this.</p>\n<p>I also think most of us <i>don&#8217;t</i> know someone who believes reptilian aliens in human form control all the major nations of Earth.</p>\n<p>Public Policy Polling&#8217;s recent <a href=\"http://www.publicpolicypolling.com/main/2013/04/conspiracy-theory-poll-results-.html\">poll on conspiracy theories</a> mostly showed up on my Facebook feed as &#8220;Four percent of Americans believe lizardmen are running the Earth&#8221;.</p>\n<p>(of note, an additional 7% of Americans are &#8220;not sure&#8221; whether lizardmen are running the Earth or not.)</p>\n<p>Imagine the situation. You&#8217;re at home, eating dinner. You get a call from someone who says &#8220;Hello, this is Public Policy Polling. Would you mind answering some questions for us?&#8221; You say &#8220;Sure&#8221;. An extremely dignified sounding voice says &#8211; and this is the exact wording of the question &#8211; &#8220;Do you believe that shape-shifting reptilian people control our world by taking on human form and gaining political power to manipulate our society, or not?&#8221; Then it urges you to press 1 if yes, press 2 if no, press 3 if not sure.</p>\n<p>So first we get the people who think &#8220;Wait, was 1 the one for if I did believe in lizardmen, or if I didn&#8217;t? I&#8217;ll just press 1 and move on to the next question.&#8221;</p>\n<p>Then we get the people who are like &#8220;I never heard it before, but if this nice pollster thinks it&#8217;s true, I might as well go along with them.&#8221;</p>\n<p>Then we get the people who are all &#8220;F#&amp;k you, polling company, I don&#8217;t want people calling me when I&#8217;m at dinner. You screw with me, I tell you what I&#8217;m going to do. I&#8217;m going to tell you I believe lizard people are running the planet.&#8221;</p>\n<p>And <i>then</i> we get the people who put &#8220;Martian&#8221; as their nationality in psychology experiments. Because some men just want to watch the world burn.</p>\n<p>Do these three groups total 4% of the US population? Seems plausible.</p>\n<p>I really wish polls like these would include a control question, something utterly implausible even by lizard-people standards, something like &#8220;Do you believe Barack Obama is a hippopotamus?&#8221; Whatever percent of people answer yes to the hippo question get subtracted out from the other questions.</p>\n<p><b>Poll Answers As Attire<br />\n</b></p>\n<p>Alas, not all weird poll answers can be explained that easily. On the same poll, 13% of Americans claimed to believe Barack Obama was the Anti-Christ. Subtracting our Lizardman&#8217;s Constant of 4%, that leaves 9% of Americans who apparently gave this answer with something approaching sincerity.</p>\n<p>(a friend on Facebook pointed out that 5% of <i>Obama voters</i> claimed to believe that Obama was the Anti-Christ, which seems to be another piece of evidence in favor of a Lizardman&#8217;s Constant of 4-5%. On the other hand, I do enjoy picturing someone standing in a voting booth, thinking to themselves &#8220;Well, on the one hand, Obama is the Anti-Christ. On the other, do I really want four years of Romney?&#8221;)</p>\n<p>Some pollsters are starting to consider these sorts of things symptomatic of what they term <a href=\"www.publicpolicypolling.com/main/2013/04/conspiracy-theory-poll-results-.html\">symbolic belief</a>, which seems to be kind of what the Less Wrong sequences call <a href=\"http://lesswrong.com/lw/i6/professing_and_cheering/\">Professing and Cheering</a> or <a href=\"http://lesswrong.com/lw/i7/belief_as_attire/\">Belief As Attire</a>. Basically, people are being emotivists rather than realists about belief. &#8220;Obama is the Anti-Christ&#8221; is another way of just saying &#8220;Boo Obama!&#8221;, rather than expressing some sort of proposition about the world.</p>\n<p>And the same is true of &#8220;Obama is a Muslim&#8221; or &#8220;Obama was not born in America&#8221;.</p>\n<p><b>Never Attribute To Stupidity What Can Be Adequately Explained By Malice</b></p>\n<p>But sometimes it&#8217;s not some abstruse subtle bias. Sometimes it&#8217;s not a good-natured joke. Sometimes people might just be actively working to corrupt your data.</p>\n<p>Another link I&#8217;ve seen on my Facebook wall a few times is this one: <a href=\"http://www.guardian.co.uk/environment/blog/2012/jul/27/climate-sceptics-conspiracy-theorists\">Are Climate Change Sceptics More Likely To Be Conspiracy Theorists?</a> It&#8217;s based on a paper by Stephen Lewandowsky et al called <a href=\"websites.psychology.uwa.edu.au/labs/cogscience/documents/FLskyetalPsychScienceinPressClimateConspiracy.pdf\">NASA Faked The Moon Landing, Therefore Climate Science Is A Hoax &#8211; An Analysis Of The Motivated Rejection Of Science</a>.</p>\n<p>The paper&#8217;s thesis was that climate change skeptics are motivated by conspiracy ideation &#8211; a belief that there are large groups of sinister people out to deceive them. This seems sort of reasonable on the face of it &#8211; being a climate change skeptic requires going against the belief of the entire scientific establishment. My guess is that there probably is a significant link here waiting to be discovered.</p>\n<p>Unfortunately, it&#8217;s&#8230;possible Stephan Lewandowsky wasn&#8217;t the best person to investigate this? Aside from being a professor of cognitive science, he also runs Shaping Tomorrow&#8217;s World, a group that promotes &#8220;re-examining some of the assumptions we make about our technological, social and economic systems&#8221; and which seems to be largely about promoting global warming activism. While I think it&#8217;s admirable that he is involved in that, it raises conflict of interest questions. And the way his paper is written &#8211; starting with the over-the-top title &#8211; doesn&#8217;t do him any favors.</p>\n<p>(if the conflict of interest angle doesn&#8217;t make immediate and obvious sense to you, imagine how sketchy it would be if a professional global warming <i>denier</i> was involved in researching the motivations of global warming <i>supporters</i>)</p>\n<p>But enough of my personal opinions. What&#8217;s the paper look like?</p>\n<p>The methodology goes like this: they send requests to several popular climate blogs, both believer and skeptic, asking them to link their readers to an online survey. The survey asks people their beliefs on global warming and on lots of conspiracy theories and fringe beliefs.</p>\n<p>On first glance, the results are extremely damning. People who rejected climate science were wildly more likely to reject pretty much every other form of science as well, including the &#8220;theory&#8221; that HIV causes AIDS and the &#8220;theory&#8221; that cigarettes cause cancer. They were more willing to believe aliens landed at Roswell, that 9-11 was an inside job, and, yes, that NASA faked the moon landing. The conclusion: climate skeptics are just really stupid people.</p>\n<p>But a bunch of global warming skeptics started re-analyzing the data and coming up with their own interpretations. They found that many large pro-global-warming blogs posted the link to the survey, but very few anti-global-warming blogs did. This then devolved into literally the <a href=\"http://www.climatedepot.com/2012/09/13/the-lewandowsky-conspiracy-paper-reveals-how-warmists-are-desperate-study-ignores-prominent-warmist-promoters-who-appear-to-believe-in-911-conspiracies/\">worst</a> <a href=\"http://climateaudit.org/2013/03/28/lewandowsky-doubles-down/\">flame</a> <a href=\"http://watchingthedeniers.wordpress.com/2012/09/13/watts-explains-why-lewandowsky-paper-on-conspiracy-theories-is-wrong-its-a-conspiracy-between-john-cook-and-the-prof/\">war</a> I have ever seen on the Internet, centering around accusations about whether the study authors deliberately excluded large anti-global warming blogs, or whether the authors asked the writers of anti-global-warming blogs and these writers just ignored the request (my impression is that most people now agree it was the latter). In either case, it ended up with most people taking the survey being from the pro-global-warming blogs, and only a few skeptics.</p>\n<p>More interestingly, <a href=\"http://climateaudit.org/2012/09/08/lewandowsky-scam/\">they found</a> that pretty much all of the link between global warming skepticism and stupidity was a couple of people (there were so few skeptics, <i>and</i> so few conspiracy believers, that these couple of people made up a pretty big proportion of them, and way more than enough to get a &#8220;significant&#8221; difference with the global warming believers). Further, most of these couple of people had given the maximally skeptical answer to every single question about global warming, and the maximally credulous answer to every single question about conspiracies.</p>\n<p>The danger here now seems obvious. Global warming believer blogs publish a link to this study, saying gleefully that it&#8217;s going to prove that global warming skeptics are idiots who also think NASA faked the moon landing and the world is run by lizardmen or whatever. Some global warming believers decide to help this process along by pretending to be super-strong global warming skeptics and filling in the stupidest answers they can to every question. The few real global warming skeptics who take the survey aren&#8217;t enough signal to completely drown out this noise. Therefore, they do the statistics and triumphantly announce that global warming skepticism is linked to stupid beliefs.</p>\n<p>The global warming skeptic blogosphere has in my opinion done more than enough work to present a very very strong case that this is what happened (somebody else do an independent look at the controversy and double-check this for me?) And Professor Lewandowsky&#8217;s answer was&#8230;</p>\n<p>&#8230;to publish a second paper, saying his results had been confirmed because climate skeptics were so obsessed with conspiracy theories that they had accused his data proving they were obsessed with conspiracies of being part of a conspiracy. The name of the paper? <a href=\"http://www.frontiersin.org/Personality_Science_and_Individual_Differences/10.3389/fpsyg.2013.00073/abstract\">Recursive Fury</a>. I have to hand it to him, this is possibly<i> the most chutzpah I have ever seen a single human being display.</i></p>\n<p>(the paper is now partially offline as the journal investigates it for ethical something something)</p>\n<p>The lesson from all three of the cases in this post seems clear. When we&#8217;re talking about very unpopular beliefs, polls can only give a weak signal. Any possible source of noise &#8211; jokesters, cognitive biases, or deliberate misbehavior &#8211; can easily overwhelm the signal. Therefore, polls that rely on detecting very weak signals should be taken with a grain of salt.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 1, "bh7uxTTqmsQ8jZJdB": 1, "3uE2pXvbcnS9nnZRE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CsKrQdQJJCFPjfKjF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 33, "extendedScore": null, "score": 7.7e-05, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "BQBqPowfxjvoee8jw", "canonicalCollectionSlug": "codex", "canonicalBookId": "YhQ39PPHNrRCgYXcs", "canonicalNextPostSlug": "two-dark-side-statistics-papers", "canonicalPrevPostSlug": "debunked-and-well-refuted", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><b id=\"Beware_of_Phantom_Lizardmen\">Beware of Phantom Lizardmen</b></p>\n<p>I have only done a little bit of social science research, but it was enough to make me hate people. One study I helped with analyzed whether people from different countries had different answers on a certain psychological test. So we put up a website where people answered some questions about themselves (like \u201cwhat country are you from?\u201d) and then took the psychological test.</p>\n<p>And so of course people screwed it up in every conceivable way. There were the merely dumb, like the guy who put \u201cmale\u201d as his nationality and \u201cAmerican\u201d as his gender. But there were also the actively malicious or at least annoying, like the people (yes, more than one) who wrote in \u201cMartian\u201d.</p>\n<p>I think we all probably know someone like this, maybe a couple people like this.</p>\n<p>I also think most of us <i>don\u2019t</i> know someone who believes reptilian aliens in human form control all the major nations of Earth.</p>\n<p>Public Policy Polling\u2019s recent <a href=\"http://www.publicpolicypolling.com/main/2013/04/conspiracy-theory-poll-results-.html\">poll on conspiracy theories</a> mostly showed up on my Facebook feed as \u201cFour percent of Americans believe lizardmen are running the Earth\u201d.</p>\n<p>(of note, an additional 7% of Americans are \u201cnot sure\u201d whether lizardmen are running the Earth or not.)</p>\n<p>Imagine the situation. You\u2019re at home, eating dinner. You get a call from someone who says \u201cHello, this is Public Policy Polling. Would you mind answering some questions for us?\u201d You say \u201cSure\u201d. An extremely dignified sounding voice says \u2013 and this is the exact wording of the question \u2013 \u201cDo you believe that shape-shifting reptilian people control our world by taking on human form and gaining political power to manipulate our society, or not?\u201d Then it urges you to press 1 if yes, press 2 if no, press 3 if not sure.</p>\n<p>So first we get the people who think \u201cWait, was 1 the one for if I did believe in lizardmen, or if I didn\u2019t? I\u2019ll just press 1 and move on to the next question.\u201d</p>\n<p>Then we get the people who are like \u201cI never heard it before, but if this nice pollster thinks it\u2019s true, I might as well go along with them.\u201d</p>\n<p>Then we get the people who are all \u201cF#&amp;k you, polling company, I don\u2019t want people calling me when I\u2019m at dinner. You screw with me, I tell you what I\u2019m going to do. I\u2019m going to tell you I believe lizard people are running the planet.\u201d</p>\n<p>And <i>then</i> we get the people who put \u201cMartian\u201d as their nationality in psychology experiments. Because some men just want to watch the world burn.</p>\n<p>Do these three groups total 4% of the US population? Seems plausible.</p>\n<p>I really wish polls like these would include a control question, something utterly implausible even by lizard-people standards, something like \u201cDo you believe Barack Obama is a hippopotamus?\u201d Whatever percent of people answer yes to the hippo question get subtracted out from the other questions.</p>\n<p><b id=\"Poll_Answers_As_Attire_\">Poll Answers As Attire<br>\n</b></p>\n<p>Alas, not all weird poll answers can be explained that easily. On the same poll, 13% of Americans claimed to believe Barack Obama was the Anti-Christ. Subtracting our Lizardman\u2019s Constant of 4%, that leaves 9% of Americans who apparently gave this answer with something approaching sincerity.</p>\n<p>(a friend on Facebook pointed out that 5% of <i>Obama voters</i> claimed to believe that Obama was the Anti-Christ, which seems to be another piece of evidence in favor of a Lizardman\u2019s Constant of 4-5%. On the other hand, I do enjoy picturing someone standing in a voting booth, thinking to themselves \u201cWell, on the one hand, Obama is the Anti-Christ. On the other, do I really want four years of Romney?\u201d)</p>\n<p>Some pollsters are starting to consider these sorts of things symptomatic of what they term <a href=\"www.publicpolicypolling.com/main/2013/04/conspiracy-theory-poll-results-.html\">symbolic belief</a>, which seems to be kind of what the Less Wrong sequences call <a href=\"http://lesswrong.com/lw/i6/professing_and_cheering/\">Professing and Cheering</a> or <a href=\"http://lesswrong.com/lw/i7/belief_as_attire/\">Belief As Attire</a>. Basically, people are being emotivists rather than realists about belief. \u201cObama is the Anti-Christ\u201d is another way of just saying \u201cBoo Obama!\u201d, rather than expressing some sort of proposition about the world.</p>\n<p>And the same is true of \u201cObama is a Muslim\u201d or \u201cObama was not born in America\u201d.</p>\n<p><b id=\"Never_Attribute_To_Stupidity_What_Can_Be_Adequately_Explained_By_Malice\">Never Attribute To Stupidity What Can Be Adequately Explained By Malice</b></p>\n<p>But sometimes it\u2019s not some abstruse subtle bias. Sometimes it\u2019s not a good-natured joke. Sometimes people might just be actively working to corrupt your data.</p>\n<p>Another link I\u2019ve seen on my Facebook wall a few times is this one: <a href=\"http://www.guardian.co.uk/environment/blog/2012/jul/27/climate-sceptics-conspiracy-theorists\">Are Climate Change Sceptics More Likely To Be Conspiracy Theorists?</a> It\u2019s based on a paper by Stephen Lewandowsky et al called <a href=\"websites.psychology.uwa.edu.au/labs/cogscience/documents/FLskyetalPsychScienceinPressClimateConspiracy.pdf\">NASA Faked The Moon Landing, Therefore Climate Science Is A Hoax \u2013 An Analysis Of The Motivated Rejection Of Science</a>.</p>\n<p>The paper\u2019s thesis was that climate change skeptics are motivated by conspiracy ideation \u2013 a belief that there are large groups of sinister people out to deceive them. This seems sort of reasonable on the face of it \u2013 being a climate change skeptic requires going against the belief of the entire scientific establishment. My guess is that there probably is a significant link here waiting to be discovered.</p>\n<p>Unfortunately, it\u2019s\u2026possible Stephan Lewandowsky wasn\u2019t the best person to investigate this? Aside from being a professor of cognitive science, he also runs Shaping Tomorrow\u2019s World, a group that promotes \u201cre-examining some of the assumptions we make about our technological, social and economic systems\u201d and which seems to be largely about promoting global warming activism. While I think it\u2019s admirable that he is involved in that, it raises conflict of interest questions. And the way his paper is written \u2013 starting with the over-the-top title \u2013 doesn\u2019t do him any favors.</p>\n<p>(if the conflict of interest angle doesn\u2019t make immediate and obvious sense to you, imagine how sketchy it would be if a professional global warming <i>denier</i> was involved in researching the motivations of global warming <i>supporters</i>)</p>\n<p>But enough of my personal opinions. What\u2019s the paper look like?</p>\n<p>The methodology goes like this: they send requests to several popular climate blogs, both believer and skeptic, asking them to link their readers to an online survey. The survey asks people their beliefs on global warming and on lots of conspiracy theories and fringe beliefs.</p>\n<p>On first glance, the results are extremely damning. People who rejected climate science were wildly more likely to reject pretty much every other form of science as well, including the \u201ctheory\u201d that HIV causes AIDS and the \u201ctheory\u201d that cigarettes cause cancer. They were more willing to believe aliens landed at Roswell, that 9-11 was an inside job, and, yes, that NASA faked the moon landing. The conclusion: climate skeptics are just really stupid people.</p>\n<p>But a bunch of global warming skeptics started re-analyzing the data and coming up with their own interpretations. They found that many large pro-global-warming blogs posted the link to the survey, but very few anti-global-warming blogs did. This then devolved into literally the <a href=\"http://www.climatedepot.com/2012/09/13/the-lewandowsky-conspiracy-paper-reveals-how-warmists-are-desperate-study-ignores-prominent-warmist-promoters-who-appear-to-believe-in-911-conspiracies/\">worst</a> <a href=\"http://climateaudit.org/2013/03/28/lewandowsky-doubles-down/\">flame</a> <a href=\"http://watchingthedeniers.wordpress.com/2012/09/13/watts-explains-why-lewandowsky-paper-on-conspiracy-theories-is-wrong-its-a-conspiracy-between-john-cook-and-the-prof/\">war</a> I have ever seen on the Internet, centering around accusations about whether the study authors deliberately excluded large anti-global warming blogs, or whether the authors asked the writers of anti-global-warming blogs and these writers just ignored the request (my impression is that most people now agree it was the latter). In either case, it ended up with most people taking the survey being from the pro-global-warming blogs, and only a few skeptics.</p>\n<p>More interestingly, <a href=\"http://climateaudit.org/2012/09/08/lewandowsky-scam/\">they found</a> that pretty much all of the link between global warming skepticism and stupidity was a couple of people (there were so few skeptics, <i>and</i> so few conspiracy believers, that these couple of people made up a pretty big proportion of them, and way more than enough to get a \u201csignificant\u201d difference with the global warming believers). Further, most of these couple of people had given the maximally skeptical answer to every single question about global warming, and the maximally credulous answer to every single question about conspiracies.</p>\n<p>The danger here now seems obvious. Global warming believer blogs publish a link to this study, saying gleefully that it\u2019s going to prove that global warming skeptics are idiots who also think NASA faked the moon landing and the world is run by lizardmen or whatever. Some global warming believers decide to help this process along by pretending to be super-strong global warming skeptics and filling in the stupidest answers they can to every question. The few real global warming skeptics who take the survey aren\u2019t enough signal to completely drown out this noise. Therefore, they do the statistics and triumphantly announce that global warming skepticism is linked to stupid beliefs.</p>\n<p>The global warming skeptic blogosphere has in my opinion done more than enough work to present a very very strong case that this is what happened (somebody else do an independent look at the controversy and double-check this for me?) And Professor Lewandowsky\u2019s answer was\u2026</p>\n<p>\u2026to publish a second paper, saying his results had been confirmed because climate skeptics were so obsessed with conspiracy theories that they had accused his data proving they were obsessed with conspiracies of being part of a conspiracy. The name of the paper? <a href=\"http://www.frontiersin.org/Personality_Science_and_Individual_Differences/10.3389/fpsyg.2013.00073/abstract\">Recursive Fury</a>. I have to hand it to him, this is possibly<i> the most chutzpah I have ever seen a single human being display.</i></p>\n<p>(the paper is now partially offline as the journal investigates it for ethical something something)</p>\n<p>The lesson from all three of the cases in this post seems clear. When we\u2019re talking about very unpopular beliefs, polls can only give a weak signal. Any possible source of noise \u2013 jokesters, cognitive biases, or deliberate misbehavior \u2013 can easily overwhelm the signal. Therefore, polls that rely on detecting very weak signals should be taken with a grain of salt.</p>", "sections": [{"title": "Beware of Phantom Lizardmen", "anchor": "Beware_of_Phantom_Lizardmen", "level": 1}, {"title": "Poll Answers As Attire\n", "anchor": "Poll_Answers_As_Attire_", "level": 1}, {"title": "Never Attribute To Stupidity What Can Be Adequately Explained By Malice", "anchor": "Never_Attribute_To_Stupidity_What_Can_Be_Adequately_Explained_By_Malice", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RmCjazjupRGcHSm5N", "nYkMLFpx77Rz3uo9c"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 5, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-12T13:11:36.365Z", "modifiedAt": null, "url": null, "title": "NES-game playing AI [video link and AI-boxing-related comment]", "slug": "nes-game-playing-ai-video-link-and-ai-boxing-related-comment", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:31.087Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2hyX4AMC7wJq3qBs9/nes-game-playing-ai-video-link-and-ai-boxing-related-comment", "pageUrlRelative": "/posts/2hyX4AMC7wJq3qBs9/nes-game-playing-ai-video-link-and-ai-boxing-related-comment", "linkUrl": "https://www.lesswrong.com/posts/2hyX4AMC7wJq3qBs9/nes-game-playing-ai-video-link-and-ai-boxing-related-comment", "postedAtFormatted": "Friday, April 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20NES-game%20playing%20AI%20%5Bvideo%20link%20and%20AI-boxing-related%20comment%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANES-game%20playing%20AI%20%5Bvideo%20link%20and%20AI-boxing-related%20comment%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2hyX4AMC7wJq3qBs9%2Fnes-game-playing-ai-video-link-and-ai-boxing-related-comment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=NES-game%20playing%20AI%20%5Bvideo%20link%20and%20AI-boxing-related%20comment%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2hyX4AMC7wJq3qBs9%2Fnes-game-playing-ai-video-link-and-ai-boxing-related-comment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2hyX4AMC7wJq3qBs9%2Fnes-game-playing-ai-video-link-and-ai-boxing-related-comment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<p>\"Pretty simple\" algorithm playing games quite impressively.<br /><a href=\"http://www.youtube.com/watch?v=xOCurBYI_gY\"></a></p>\n<p><a href=\"http://www.youtube.com/watch?v=xOCurBYI_gY\">http://www.youtube.com/watch?v=xOCurBYI_gY</a><br /><br />First, this is awesome - enjoy!<br /><br />Paper here&nbsp;<a href=\"http://www.cs.cmu.edu/~tom7/mario/mario.pdf\">http://www.cs.cmu.edu/~tom7/mario/mario.pdf</a><br /><br />One interesting observation made by Tom Murphy is that the AI found and exploited playable bugs in the game not (commonly) known to human players. I think it's a good example to have available suggesting what a really smart AI might look for to win.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 1, "sYm3HiWcfZvrGu3ui": 1, "HFou6RHqFagkyrKkW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2hyX4AMC7wJq3qBs9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 42, "extendedScore": null, "score": 1.1664806692276973e-06, "legacy": true, "legacyId": "22286", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-12T15:20:18.308Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, Brussels, Cambridge UK, Frankfurt, Moscow, Vancouver", "slug": "weekly-lw-meetups-austin-brussels-cambridge-uk-frankfurt", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zEoyFSLyQyHJ5pbCd/weekly-lw-meetups-austin-brussels-cambridge-uk-frankfurt", "pageUrlRelative": "/posts/zEoyFSLyQyHJ5pbCd/weekly-lw-meetups-austin-brussels-cambridge-uk-frankfurt", "linkUrl": "https://www.lesswrong.com/posts/zEoyFSLyQyHJ5pbCd/weekly-lw-meetups-austin-brussels-cambridge-uk-frankfurt", "postedAtFormatted": "Friday, April 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20Brussels%2C%20Cambridge%20UK%2C%20Frankfurt%2C%20Moscow%2C%20Vancouver&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20Brussels%2C%20Cambridge%20UK%2C%20Frankfurt%2C%20Moscow%2C%20Vancouver%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzEoyFSLyQyHJ5pbCd%2Fweekly-lw-meetups-austin-brussels-cambridge-uk-frankfurt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20Brussels%2C%20Cambridge%20UK%2C%20Frankfurt%2C%20Moscow%2C%20Vancouver%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzEoyFSLyQyHJ5pbCd%2Fweekly-lw-meetups-austin-brussels-cambridge-uk-frankfurt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzEoyFSLyQyHJ5pbCd%2Fweekly-lw-meetups-austin-brussels-cambridge-uk-frankfurt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 491, "htmlBody": "<p><strong>This summary was posted to LW main on March 15th. The following week's summary is <a href=\"/lw/h1f/weekly_lw_meetups_atlanta_austin_berlin_durham/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/kb\">2. Frankfurt am Main meetup:&nbsp;<span class=\"date\">15 March 2013 06:30PM</span></a></li>\n<li><a href=\"/meetups/jq\">Brussels meetup:&nbsp;<span class=\"date\">16 March 2013 01:00PM</span></a></li>\n<li><a href=\"/meetups/jp\"></a><a href=\"/meetups/ka\">Vancouver Extraordinary Evidence and Bayes:&nbsp;<span class=\"date\">16 March 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/k5\">Moscow, Theory and Practice:&nbsp;<span class=\"date\">17 March 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/kd\">London Meetup, 24th March: Steelmanning:&nbsp;<span class=\"date\">24 March 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/jp\">Munich Meetup (updated):&nbsp;<span class=\"date\">01 April 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/k9\">Vienna Meetup #2 - :&nbsp;<span class=\"date\">13 April 2013 07:06PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">16 March 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/kg\">(Cambridge, UK) Meetup [Reading Group, HAEFB-06]:&nbsp;<span class=\"date\">17 March 2013 11:00AM</span></a><a href=\"/meetups/k7\"></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong></strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zEoyFSLyQyHJ5pbCd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 1.166569453035573e-06, "legacy": true, "legacyId": "22028", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4u5jnMENLgYKFPbYi", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-12T19:05:27.221Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels meetup", "slug": "meetup-brussels-meetup-4", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Axel", "createdAt": "2010-11-03T17:32:46.091Z", "isAdmin": false, "displayName": "Axel"}, "userId": "vi498nAvek8eWuMWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BPkPQ67jkG9teBxta/meetup-brussels-meetup-4", "pageUrlRelative": "/posts/BPkPQ67jkG9teBxta/meetup-brussels-meetup-4", "linkUrl": "https://www.lesswrong.com/posts/BPkPQ67jkG9teBxta/meetup-brussels-meetup-4", "postedAtFormatted": "Friday, April 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBPkPQ67jkG9teBxta%2Fmeetup-brussels-meetup-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBPkPQ67jkG9teBxta%2Fmeetup-brussels-meetup-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBPkPQ67jkG9teBxta%2Fmeetup-brussels-meetup-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lg'>Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 April 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are once again meeting at 'la fleur en papier dor\u00e9e' close to the Brussels Central station. If you feel like an intelligent discussion and are in the neighborhood, consider dropping by. As always, I'll have a sign. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform?pli=1\" rel=\"nofollow\">this</a> one minute form, to share your contact information.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lg'>Brussels meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BPkPQ67jkG9teBxta", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1667248018797996e-06, "legacy": true, "legacyId": "22288", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup\">Discussion article for the meetup : <a href=\"/meetups/lg\">Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 April 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are once again meeting at 'la fleur en papier dor\u00e9e' close to the Brussels Central station. If you feel like an intelligent discussion and are in the neighborhood, consider dropping by. As always, I'll have a sign. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform?pli=1\" rel=\"nofollow\">this</a> one minute form, to share your contact information.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup1\">Discussion article for the meetup : <a href=\"/meetups/lg\">Brussels meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup", "level": 1}, {"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-13T03:48:56.513Z", "modifiedAt": null, "url": null, "title": "Optimal rudeness", "slug": "optimal-rudeness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:58.908Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EZS5oTePDnNL9Ln2v/optimal-rudeness", "pageUrlRelative": "/posts/EZS5oTePDnNL9Ln2v/optimal-rudeness", "linkUrl": "https://www.lesswrong.com/posts/EZS5oTePDnNL9Ln2v/optimal-rudeness", "postedAtFormatted": "Saturday, April 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Optimal%20rudeness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOptimal%20rudeness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEZS5oTePDnNL9Ln2v%2Foptimal-rudeness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Optimal%20rudeness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEZS5oTePDnNL9Ln2v%2Foptimal-rudeness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEZS5oTePDnNL9Ln2v%2Foptimal-rudeness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 282, "htmlBody": "<p>On LessWrong, we often get cross, and then rude, with each other. Sometimes, someone then observes this rudeness is counterproductive.</p>\n<p>Is it?</p>\n<p>As a general rule, emotional responses are winning strategies (at least for your genes).&nbsp; That's why you have those emotions.</p>\n<p>Granted, insulting someone during your rebuttal of their argument makes it less likely that they will see your point. But it appears to be an effective tactic when carrying on an argument in public.</p>\n<p>It's my impression that on LessWrong, a comment or a post written with a certain amount of disdain is more-likely to get voted up than a completely objective comment. A good way to obtain upvotes, if that is your goal, is to make other readers wish to identify with you and disassociate themselves from whomever you're arguing against.&nbsp; A great many up-voted comments, including some of my own, suggest, subtly or not subtly, with or without evidence, that the person being responded to is ignorant or stupid.</p>\n<p>The correct amount of derision appears be slight, and to depend on status. Someone with more status should be more rude. Retaliations against rudeness may really be retaliations for an attempt to claim high status.</p>\n<p>What's the optimal response if someone says something especially rude to you?&nbsp; Is a polite or a rude response to a rude comment more likely to be upvoted/downvoted?&nbsp; Not ideally, but in reality.&nbsp; I think, in general, when dealing with humans, responding to skillful rudeness, and especially humorous rudeness, with politeness, is a losing strategy.</p>\n<p>My expectation is that rudeness is a better strategy for poor and unpopular arguments than for good or popular ones, because rudeness adds noise.&nbsp; The lower a comment's expected karma, the ruder it should be.</p>\n<p>You jerk.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EZS5oTePDnNL9Ln2v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": -20, "extendedScore": null, "score": -3e-05, "legacy": true, "legacyId": "22289", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 51, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-13T04:27:04.146Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Extenuating Circumstances", "slug": "seq-rerun-extenuating-circumstances", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:53.128Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C2Jc6tpYZzYfmGwTC/seq-rerun-extenuating-circumstances", "pageUrlRelative": "/posts/C2Jc6tpYZzYfmGwTC/seq-rerun-extenuating-circumstances", "linkUrl": "https://www.lesswrong.com/posts/C2Jc6tpYZzYfmGwTC/seq-rerun-extenuating-circumstances", "postedAtFormatted": "Saturday, April 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Extenuating%20Circumstances&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Extenuating%20Circumstances%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC2Jc6tpYZzYfmGwTC%2Fseq-rerun-extenuating-circumstances%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Extenuating%20Circumstances%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC2Jc6tpYZzYfmGwTC%2Fseq-rerun-extenuating-circumstances", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC2Jc6tpYZzYfmGwTC%2Fseq-rerun-extenuating-circumstances", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 160, "htmlBody": "<p>Today's post, <a href=\"/lw/92/extenuating_circumstances/\">Extenuating Circumstances</a> was originally published on 06 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries#Extenuating_Circumstances\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>You can excuse other people's shortcomings on the basis of extenuating circumstances, but you shouldn't do that with yourself.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h6w/seq_rerun_reallife_anthropic_weirdness/\">Real-Life Anthropic Weirdness</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C2Jc6tpYZzYfmGwTC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.1671124669704161e-06, "legacy": true, "legacyId": "22290", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XYrcTJFJoYKX2DxNL", "iYnKzCACJvHg4nEcH", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-13T18:33:23.799Z", "modifiedAt": null, "url": null, "title": "Estimate Stability", "slug": "estimate-stability", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:08.762Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K33mYmEk9LoTbN92L/estimate-stability", "pageUrlRelative": "/posts/K33mYmEk9LoTbN92L/estimate-stability", "linkUrl": "https://www.lesswrong.com/posts/K33mYmEk9LoTbN92L/estimate-stability", "postedAtFormatted": "Saturday, April 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Estimate%20Stability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEstimate%20Stability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK33mYmEk9LoTbN92L%2Festimate-stability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Estimate%20Stability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK33mYmEk9LoTbN92L%2Festimate-stability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK33mYmEk9LoTbN92L%2Festimate-stability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 594, "htmlBody": "<p>I've been trying to get clear on something you might call \"estimate stability.\" Steven Kaas recently <a href=\"http://stats.stackexchange.com/questions/55800/stability-of-estimates\">posted my question to StackExchange</a>, but we might as well post it here as well:</p>\n<blockquote>I'm trying to reason about something I call \"estimate stability,\" and I'm hoping you can tell me whether there&rsquo;s some relevant technical language...</blockquote>\n<blockquote>What do I mean by \"estimate stability?\" Consider these three different propositions:</blockquote>\n<blockquote><ol>\n<li>We&rsquo;re 50% sure that a coin (known to be fair) will land on heads.</li>\n<li>We&rsquo;re 50% sure that Matt will show up at the party.</li>\n<li>We&rsquo;re 50% sure that Strong AI will be invented by 2080.</li>\n</ol></blockquote>\n<blockquote>These estimates feel different. One reason they feel different is that the estimates have different degrees of \"stability.\" In case (1) we don't expect to gain information that will change our probability estimate. But for cases (2) and (3), we may well come upon some information that causes us to adjust the estimate either up or down.</blockquote>\n<blockquote>So estimate (1) is more \"stable,\" but I'm not sure how this should be quantified. Should I think of it in terms of running a Monte Carlo simulation of what future evidence might be, and looking at something like the variance of the distribution of the resulting estimates? What happens when it&rsquo;s a whole probability distribution for e.g. the time Strong AI is invented? (Do you do calculate the stability of the probability density for every year, then average the result?)</blockquote>\n<blockquote>Here are some other considerations that would be useful to relate more formally to considerations of estimate stability:</blockquote>\n<blockquote>\n<ul>\n<li>If we&rsquo;re estimating some variable, having a narrow probability distribution (prior to future evidence with respect to which we&rsquo;re trying to assess the stability) corresponds to having a lot of data. New data, in that case, would make less of a contribution in terms of changing the mean and reducing the variance.</li>\n<li>There are differences in model uncertainty between the three cases. I know what model to use when predicting a coin flip. My method of predicting whether Matt will show up at a party is shakier, but I have some idea of what I&rsquo;m doing. With the Strong AI case, I don&rsquo;t really have any good idea of what I&rsquo;m doing. Presumably model uncertainty is related to estimate stability, because the more model uncertainty we have, the more we can change our estimate by reducing our model uncertainty.</li>\n<li>Another difference between the three cases is the degree to which our actions allow us to improve our estimates, increasing their stability. For example, we can reduce the uncertainty and increase the stability of our estimate about Matt by calling him, but we don&rsquo;t really have any good ways to get better estimates of Strong AI timelines (other than by waiting).</li>\n<li>Value-of-information affects how we should deal with delay. Estimates that are unstable in the face of evidence we expect to get in the future seem to imply higher VoI. This creates a reason to accept delays in our actions. Or if we can easily gather information that will make our estimates more accurate and stable, that means we have more reason to pay the cost of gathering that information. If we expect to forget information, or expect our future selves not to take information into account, dynamic inconsistency becomes important. This is another reason why estimates might be unstable. One possible strategy here is to precommit to have our estimates regress to the mean.</li>\n</ul>\n</blockquote>\n<blockquote>Thanks for any thoughts!</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K33mYmEk9LoTbN92L", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 11, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "22292", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-13T20:35:24.067Z", "modifiedAt": null, "url": null, "title": "Worth remembering (when comparing \u2018the US\u2019 to \u2018Europe\u2019)", "slug": "worth-remembering-when-comparing-the-us-to-europe", "viewCount": null, "lastCommentedAt": "2018-10-31T13:56:03.253Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Curiousguy", "createdAt": "2013-04-13T19:25:51.378Z", "isAdmin": false, "displayName": "Curiousguy"}, "userId": "kKSGGQ22NoxSm8FFR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Hifamb4LTgQooDBYj/worth-remembering-when-comparing-the-us-to-europe", "pageUrlRelative": "/posts/Hifamb4LTgQooDBYj/worth-remembering-when-comparing-the-us-to-europe", "linkUrl": "https://www.lesswrong.com/posts/Hifamb4LTgQooDBYj/worth-remembering-when-comparing-the-us-to-europe", "postedAtFormatted": "Saturday, April 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Worth%20remembering%20(when%20comparing%20%E2%80%98the%20US%E2%80%99%20to%20%E2%80%98Europe%E2%80%99)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWorth%20remembering%20(when%20comparing%20%E2%80%98the%20US%E2%80%99%20to%20%E2%80%98Europe%E2%80%99)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHifamb4LTgQooDBYj%2Fworth-remembering-when-comparing-the-us-to-europe%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Worth%20remembering%20(when%20comparing%20%E2%80%98the%20US%E2%80%99%20to%20%E2%80%98Europe%E2%80%99)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHifamb4LTgQooDBYj%2Fworth-remembering-when-comparing-the-us-to-europe", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHifamb4LTgQooDBYj%2Fworth-remembering-when-comparing-the-us-to-europe", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1149, "htmlBody": "<p>I posted the post below on my own blog <a href=\"http://econstudentlog.wordpress.com/2011/11/17/worth-remembering-when-comparing-the-us-to-europe/\" target=\"_blank\">a while back</a>, but a friend of mine suggested that it might be a good idea to cross-post a little bit of my stuff here as well. I've made a few changes to the post at the bottom, but it's pretty much the same post as the one I posted back then. Okay, here goes:</p>\n<p>...</p>\n<p>People often note that it&rsquo;s a bad idea to compare small European countries with a country that is so big that it is comparable in size to the continent that the small country is a part of. I&rsquo;ll go into a bit more detail about the differences in this post.</p>\n<p>So, in a comment I left over at <a href=\"http://marginalrevolution.com/marginalrevolution/2011/11/switzerland-fact-of-the-day.html\">MR</a> I noted that:</p>\n<p>&lsquo;The United States is 3 times as big as EU-15 used to be, and EU-15 included pretty much all of the countries in Western Europe that people from the US like to compare to their own country (Italy, Germany, Spain, France, UK, Sweden&hellip;)&rsquo;</p>\n<p>Here&rsquo;s the map:</p>\n<p><a href=\"http://econstudentlog.files.wordpress.com/2011/11/680px-eu15-1995_european_union_map-svg.png\"><img class=\"aligncenter size-full wp-image-8122\" title=\"680px-EU15-1995_European_Union_map.svg\" src=\"http://econstudentlog.files.wordpress.com/2011/11/680px-eu15-1995_european_union_map-svg.png?w=680&amp;h=520\" alt=\"\" width=\"680\" height=\"520\" /></a></p>\n<p>It&rsquo;s not &lsquo;completely true&rsquo;, but it&rsquo;s very close &ndash; the area of EU-15 was 3,367,154 km<sup>2</sup> (<a href=\"http://en.wikipedia.org/wiki/1995_enlargement_of_the_European_Union\">link</a>). The area of the United States is 9.83 million km<sup>2</sup>.</p>\n<p>Some more random numbers, I used wikipedia&rsquo;s numbers and I couldn&rsquo;t be bothered to add links because it would have taken forever and nobody would follow them anyway &ndash; you can look it up if something sounds really wrong. Texas: 696,200 km<sup>2</sup>. France: 674,843 km<sup>2</sup>. (<a href=\"http://en.wikipedia.org/wiki/Metropolitan_France\">Metropolitan France</a> &ndash; i.e. &lsquo;France-France (+Corsica)&rsquo;: 551,695 km<sup>2</sup>). Spain: 504,030 km<sup>2</sup>. California: 423,970 km<sup>2</sup>. Germany: 357,021 km<sup>2</sup>. Denmark: 43,075 km<sup>2</sup>. Netherlands: 41,543 km<sup>2</sup>.</p>\n<p>The red bit in the picture below is larger than any country in Europe which is not Russia (or another way to visualize it: That bit is actually significantly larger than the Iberian Peninsula in the map above). Maybe the scales aren&rsquo;t completely similar, but they&rsquo;re actually not really <em>that</em> far off:</p>\n<p><a href=\"http://econstudentlog.files.wordpress.com/2011/11/800px-texas_in_united_states-svg.png\"><img class=\"aligncenter size-full wp-image-8123\" title=\"800px-Texas_in_United_States.svg\" src=\"http://econstudentlog.files.wordpress.com/2011/11/800px-texas_in_united_states-svg.png?w=682&amp;h=486\" alt=\"\" width=\"682\" height=\"486\" /></a></p>\n<p>If you take a trip in Europe from Venezia, Italy to Amsterdam, Netherlands, you&rsquo;ll travel ~1200-1300 kilometers depending on the route. The lenght and width of Texas are both in the neighbourhood of ~1,250 km.</p>\n<p>Now, Arizona is another southern US state with an area of 295,254 km<sup>2</sup> and a population of 6,4 million people. The Netherlands&rsquo; population is estimated at 16.85 million. If you combine the populations of Netherlands (16,85), Denmark (5,5) and Belgium (11 mill), those 33 million people are distributed over an area of ~115.000 km<sup>2</sup>. The (smaller) combined populations of Texas (25,1) and Arizona (6,4) have roughly a million square kilometers to deal with.</p>\n<p>Does it make better sense to compare Texas with France? And those small countries with, say, the state of New York? It probably would. But it&rsquo;s really hard to find good matches here, in particular due to the problem with population density differences. If you do find areas that match on this metric, odds are they don&rsquo;t exactly match on other key metrics. The population density of the United States as a whole is 33,7/km<sup>2</sup>. If you scale that up by a factor of ten, you get to the third <a href=\"http://en.wikipedia.org/wiki/List_of_U.S._states_by_population_density\">most densely populated state</a>, Massachusetts (324.1 /km<sup>2</sup>). The population density of Massachusetts is somewhat lower than both Belgium&rsquo;s (354.7/km<sup>2</sup>) and Netherlands&rsquo; (403/km<sup>2</sup>). The population density of Germany (229/km<sup>2</sup>) is comparable to that of Maryland (229.7/km<sup>2</sup>), <em>which is in the US top five</em> &ndash; Germany is almost 7 times as densely populated as &lsquo;the US as a whole&rsquo;. The population density of Great Britain is 277/km<sup>2</sup>, comparable to Connecticut&rsquo;s (285.0/km<sup>2</sup>) &ndash; the state of Connecticut is btw. #4 on the US list. Italy is at 201.2/km<sup>2</sup>, between Delaware and Maryland &ndash; it would be on the top 6 if it was a US state. Americans like to use the expression &lsquo;France and Germany&rsquo;, but at least in terms of population density, there&rsquo;s a huge difference between these two countries that I&rsquo;m not sure they&rsquo;re aware of: The population density of France is much lower (116/km<sup>2</sup>) than that of Germany, and rather more comparable to that of Spain (93/km<sup>2</sup>). All US states outside the top ten have population densities well below 100/km<sup>2</sup>, so note that even though Spain and France are relatively sparcely populated in a Western European context, France would be well within the top 10 and Spain just outside top 10 if the two countries were US states. The average population density of the entire <a href=\"http://en.wikipedia.org/wiki/European_Union\">European Union</a>, including a lot of Eastern European countries most Americans couldn&rsquo;t find on a map, is about the same as that of France, 116.2/km<sup>2</sup>; 3.5 times as high as the US average.</p>\n<p>The population density of Iceland is 3.1/km<sup>2</sup>. As mentioned, the US average is 33.7/km<sup>2</sup> and Belgium&rsquo;s density is 354.7/km<sup>2</sup>. Remember these magnitudes. And yes, I know that the US population density is not homogenous and that a lot of it is almost empty. The population density of Europe isn&rsquo;t homogenous either &ndash; to take an example, approximately one eighth of the German population &ndash; 10 million people &ndash; live in the very small <a href=\"http://en.wikipedia.org/wiki/Rhine-Ruhr\">Rhine-Ruhr metropolitan region</a> (7,110 square kilometers, or less than 2% of the area). A fifth (12+ mill) of the French population live in the Paris metropolitan area. On the other hand, the population density of Norway, which even though she is a bit of an outlier is still very much a part of Western Europe, is 12,5/km<sup>2</sup>, comparable on that metric to, say, Nevada (9.02/km<sup>2</sup>) in the US.</p>\n<p>If you look at differences in the US internally, when it comes to the 10 most densely populated states the one that is situated the most to the west of these is Ohio (the state border of which is still within 500 km of the Atlantic Ocean). Here&rsquo;s a map:</p>\n<p><a href=\"http://econstudentlog.files.wordpress.com/2011/11/800px-usagraphmap-svg.png\"><img class=\"aligncenter size-full wp-image-8141\" title=\"800px-Usagraphmap.svg\" src=\"http://econstudentlog.files.wordpress.com/2011/11/800px-usagraphmap-svg.png?w=732&amp;h=497\" alt=\"\" width=\"732\" height=\"497\" /></a></p>\n<p>Remember here that these numbers are people/sq mile, so to compare the numbers there with the rest of the numbers in this post you need to divide by ~2,6 or so. I found this comparable map of Europe convenient both because it gives density limits in sq. miles and because it&rsquo;s a lot more fine grained than just data on the national level:</p>\n<p><a href=\"http://econstudentlog.files.wordpress.com/2011/11/europepop1.jpg\"><img class=\"aligncenter size-full wp-image-8144\" title=\"europepop\" src=\"http://econstudentlog.files.wordpress.com/2011/11/europepop1.jpg?w=647&amp;h=648\" alt=\"\" width=\"647\" height=\"648\" /></a></p>\n<p>Last of all: Languages! Here&rsquo;s the European <a href=\"http://www.eurominority.eu/version/maps/map-european-languages.asp\">map</a>:</p>\n<p><a href=\"http://econstudentlog.files.wordpress.com/2011/11/europe-languages-continant.gif\"><img class=\"aligncenter size-full wp-image-8128\" title=\"europe-languages-continant\" src=\"http://econstudentlog.files.wordpress.com/2011/11/europe-languages-continant.gif?w=688&amp;h=635\" alt=\"\" width=\"688\" height=\"635\" /></a></p>\n<p>Let&rsquo;s just say that a map of the US would look different. Yeah, a lot has been written about the Spanish/English-thing going on in the US. Well, intranational language barriers and -linguistic diversity aren&rsquo;t exactly unknown phenomena in Europe either, despite the small size of the countries involved. A thing worth remembering here is also that in many of the bilingual regions of Europe highlighted here, English is the <em>third</em> language. If you&rsquo;re a US tourist visiting some European bilingual region and you&rsquo;re annoyed people don&rsquo;t speak much English, ask yourself how many areas of the US you can think of where people can hold conversations in, say, English, Spanish <em>and</em> French.</p>\n<p>&hellip;</p>\n<p>Did you know that 90 percent of the human population lives on the Northern Hemisphere? I didn&rsquo;t, before I wrote <a href=\"http://econstudentlog.wordpress.com/2011/10/09/earth-some-stuff-you-should-know/\">this</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Hifamb4LTgQooDBYj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 20, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "22294", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-13T20:46:53.228Z", "modifiedAt": null, "url": null, "title": "Meetup : Munich Meetup", "slug": "meetup-munich-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:05.999Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Teobaldo", "createdAt": "2012-10-28T17:25:26.852Z", "isAdmin": false, "displayName": "Teobaldo"}, "userId": "BhijBsy7WLfpnsZGJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pB4Aps4n8TSyTg4TA/meetup-munich-meetup", "pageUrlRelative": "/posts/pB4Aps4n8TSyTg4TA/meetup-munich-meetup", "linkUrl": "https://www.lesswrong.com/posts/pB4Aps4n8TSyTg4TA/meetup-munich-meetup", "postedAtFormatted": "Saturday, April 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Munich%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Munich%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpB4Aps4n8TSyTg4TA%2Fmeetup-munich-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Munich%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpB4Aps4n8TSyTg4TA%2Fmeetup-munich-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpB4Aps4n8TSyTg4TA%2Fmeetup-munich-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lh'>Munich Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 May 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Caf\u00e9 at Gasteig, Rosenheimer Stra\u00dfe 5, 81667 M\u00fcnchen</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Munich meetup will take place on May 4th. We will discuss the epistemology sequence and do some fun probability theory quiz. You are highly welcome to come and say hi, no matter how long you\u2019ve been reading LessWrong. If you plan to attend, please (optionally) post a comment saying what topics you\u2019d like to discuss. Also if you on Facebook, think about joining the group (see comments to the previous meetup).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lh'>Munich Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pB4Aps4n8TSyTg4TA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1677893497524783e-06, "legacy": true, "legacyId": "22295", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Munich_Meetup\">Discussion article for the meetup : <a href=\"/meetups/lh\">Munich Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 May 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Caf\u00e9 at Gasteig, Rosenheimer Stra\u00dfe 5, 81667 M\u00fcnchen</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Munich meetup will take place on May 4th. We will discuss the epistemology sequence and do some fun probability theory quiz. You are highly welcome to come and say hi, no matter how long you\u2019ve been reading LessWrong. If you plan to attend, please (optionally) post a comment saying what topics you\u2019d like to discuss. Also if you on Facebook, think about joining the group (see comments to the previous meetup).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Munich_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/lh\">Munich Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Munich Meetup", "anchor": "Discussion_article_for_the_meetup___Munich_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Munich Meetup", "anchor": "Discussion_article_for_the_meetup___Munich_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-13T20:47:29.405Z", "modifiedAt": null, "url": null, "title": "Reinforcement and Short-Term Rewards as Anti-Akratic", "slug": "reinforcement-and-short-term-rewards-as-anti-akratic", "viewCount": null, "lastCommentedAt": "2013-05-20T10:08:09.092Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Intrism", "createdAt": "2013-03-05T16:41:08.154Z", "isAdmin": false, "displayName": "Intrism"}, "userId": "pj7GE4aJifZfjLgD9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Gne4dR4iec3QkWiyv/reinforcement-and-short-term-rewards-as-anti-akratic", "pageUrlRelative": "/posts/Gne4dR4iec3QkWiyv/reinforcement-and-short-term-rewards-as-anti-akratic", "linkUrl": "https://www.lesswrong.com/posts/Gne4dR4iec3QkWiyv/reinforcement-and-short-term-rewards-as-anti-akratic", "postedAtFormatted": "Saturday, April 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reinforcement%20and%20Short-Term%20Rewards%20as%20Anti-Akratic&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReinforcement%20and%20Short-Term%20Rewards%20as%20Anti-Akratic%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGne4dR4iec3QkWiyv%2Freinforcement-and-short-term-rewards-as-anti-akratic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reinforcement%20and%20Short-Term%20Rewards%20as%20Anti-Akratic%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGne4dR4iec3QkWiyv%2Freinforcement-and-short-term-rewards-as-anti-akratic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGne4dR4iec3QkWiyv%2Freinforcement-and-short-term-rewards-as-anti-akratic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1358, "htmlBody": "<p><strong>Related:&nbsp;</strong><a href=\"/lw/6jw/time_and_effort_discounting/\">Time and Effort Discounting</a>,<strong>&nbsp;</strong><a href=\"/lw/6c/akrasia_hyperbolic_discounting_and_picoeconomics/\">Akrasia, Hyperbolic Discounting, and Picoeconomics</a>,&nbsp;<a href=\"/lw/cu2/the_power_of_reinforcement/\">The Power of Reinforcement</a>, <a href=\"/lw/6iu/basics_of_animal_reinforcement/\">Basics of Animal Reinforcement</a>, <a href=\"/lw/6ja/basics_of_human_reinforcement/\">Basics of Human Reinforcement</a></p>\n<p>I built a robot that feeds me candy when I get work done, to try to solve my akrasia problem. And, so far, it seems like it might actually work.</p>\n<p>Naturally, the story starts with procrastination. I finish things the night before they're due. Or, sometimes, I don't. I'd like to fix that. One theory explains procrastination as a result of&nbsp;<a href=\"/lw/6jw/time_and_effort_discounting/\">discounting</a>,&nbsp;the idea that human brains discount long-term rewards in favor of short-term ones. For instance, my brain prefers watching <em>Neon Genesis Evangelion</em> now over nearly missing my project deadline in a few days. The same principle applies to consequences, and there are already tools like <a href=\"https://www.beeminder.com\">BeeMinder</a>&nbsp;that are built to combat it.&nbsp;Its tagline, \"bring long-term consequences near,\" is a very concise description of a clever way to short-circuit discounting. It's very interesting, but I'm not really comfortable with paying money as a consequence. Instead, I'm going to try a similar technique: bringing long-term <em>rewards</em> near.</p>\n<p>There are already a lot of techniques about bringing long-term rewards near. Generally, they're called <a href=\"/lw/cu2/the_power_of_reinforcement/\">reinforcement learning</a>. The classic reward in reinforcement is candy, which seems like a good idea: I like it, and I'm more than willing to abuse my youthful metabolism for productivity. And, in fact, there are a wide variety of folk solutions of that sort - advice to reward yourself with some candy once your work is done. I've tried those already, but they never seem to work out for me - I always seem to wind up cheating. I need to do something trickier.</p>\n<p>CFAR describes reinforcement in a very striking way in some of their course materials: they call it&nbsp;<a href=\"http://appliedrationality.org/wp-content/uploads/2013/01/checklist_of_rationality_habits.pdf\">\"training your inner pigeon.\"</a>&nbsp;Not only is that a nice, snappy turn of phrase, it illustrates the problem with attempting to self-administer rewards very nicely.&nbsp;Did Skinner's pigeons self-administer their rewards? No, of course they didn't. I shouldn't expect <em>my</em> inner pigeon to, either. So, my next step is to build a robot that gives me candy when I get stuff done.</p>\n<p>Why do I think I can keep from cheating on the machine, when I couldn't restrain myself from cheating on regular old bags of candy? Well, I'm far from certain; it's my biggest worry with the project, in fact. But I am reasonably confident, because the machine will give me an easy way to establish a <a href=\"/lw/ase/schelling_fences_on_slippery_slopes/\">Schelling fence</a>. Where taking a handful of candy out of the bag is sometimes right and sometimes wrong, taking a handful of candy out of the hopper is <em>always wrong</em>, since the machine will dispense the candy when I deserve it. Precommitting to never take candy out of the machine seems like it'll be a lot easier than precommitting to only sometimes take candy out of the bag.</p>\n<p>Now, the description \"robot\" for my machine is a bit fanciful. It's actually an automatic dog feeder, modified and connected to the Internet. It has a small screen mounted on the front, which tells me how many rewards I've earned. If I've got any, I can press a button on the screen to dispense them. Not counting parts I already owned, the device cost me around $50 to build. To provide the data, I linked the device to an earlier productivity hack that I already had around, a custom webapp integrating a task list with a&nbsp;<a href=\"/lw/gp4/the_power_of_pomodoros/\">Pomodoro</a>&nbsp;timer.</p>\n<p>Rewards are given based on a few simple rules. When I finish a task early, it gives me the number of days early in rewards; if I finish tasks out of order, it gives me the nearer task's number of rewards, so I've got an incentive to finish tasks in order. I also get an extra reward for my first Pomodoro in a week for each of my projects, so that I have an incentive not to forget old projects. The system can also take away rewards. If I get distracted during a Pomodoro, I lose a reward. I'm blocked from redeeming rewards if I have a task within a day of its deadline. If I finish a task more than a day late, I lose any rewards in the system.</p>\n<p>Results have been mixed so far. My greatest concern seems to have been unjustified: I haven't cheated on the machine once. However, it seems like the rules need some more work. The system has definitely helped some, but there are a lot of problems that could be improved.</p>\n<p>The system doesn't account for the difficulty of tasks, meaning that I get more reward for less effort if I do easier work. As a result, I've done all of the reading up to next Tuesday for my literature class, but my Computer Science assignment due on Friday is unfinished, and my \"research\" for an exceptionally abhorrent humanities course is languishing on the vine.</p>\n<p>The point of the system was to bring long-term rewards near, but there are a lot of circumstances in which it doesn't seem to bring them quite near enough. For deadlined tasks, I get no rewards until I've actually completed the task; if I think a task will take me more than a day to finish, that's more than a day of work which earns me no short-term rewards. This gets even worse if I happen to have a long task (or, many short tasks) that have reached the day before their deadline. Then, I don't get <em>any&nbsp;</em>rewards until I finish all of those tasks. While this is quite motivating, it's still a <em>long-term </em>motivation, i.e. it doesn't work very well.</p>\n<p>I deliberately built the system to encourage doing tasks in order, but this seems to have backfired a little bit. Since I would be giving up rewards, I don't want to work on a task that's due later if there's another that's due sooner. However, if I really don't want to do the nearer task, I'll end up wasting time, since I get no rewards for that either way. Nyan_sandwich describes a similar failure mode in his <a href=\"/r/lesswrong/lw/8s9/an_akrasia_case_study/\">Akrasia Case Study</a>: if I know I have something more urgent to do, but I don't want to do it, I wind up procrastinating instead of doing less urgent things.</p>\n<p>I get sick of candy more quickly than I expected. The portion my machine emits (about a small handful) tends to stop motivating me after about 4 in a day. Additionally, I seem to be entirely incapable of pacing myself; if the reward is in the system, I tend not to wait very long before using it. This has crippled all of the rules about involving taking away rewards - unless the rewards are blocked, they don't stick around in the system long enough to be taken away.</p>\n<p>Not all of the things I want to change are a result of problems, though. There are a wide variety of interesting improvements I could make. Many of these are expansions: aside from my task list, what else can I connect to? Can I track note-taking in class? Can I set it up to reward continuing effort towards a task, like writing a few hundred words a day? Can I use it to create new, more rational habits? There are all kinds of possibilities to consider. If you've got anything you'd like to suggest, let me know - I'm open to anything interesting.</p>\n<p>There are also a lot of techniques to research; I'm sure the program isn't nearly as effective as it could be. Operant conditioning techniques like <a href=\"/lw/6iu/basics_of_animal_reinforcement/\">variable-ratio schedules</a> might help improve performance per candy. Or, I could look into <a href=\"http://en.wikipedia.org/wiki/Gamification\">gamification</a>, basically a form of applied human operant conditioning; it's not a standard tool on the site, but if you've ever watched an experience bar rise, you know what I'm talking about. Again, if you happen to have some relevant ideas, let me know.</p>\n<p>Obviously, I'm going to be making some rule changes in the near future. Expect another post in a few weeks about what's changed and how the changes have worked out for me.</p>\n<p>Also, does anyone want to help me think of a good name for the system? Right now it's called the \"extrinsic motivator.\" While descriptive, this name isn't snappy <em>at all</em>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"r7qAjcbfhj2256EHH": 1, "dqx5k65wjFfaiJ9sQ": 1, "AodfCFefLAuwDyj7Z": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Gne4dR4iec3QkWiyv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 35, "extendedScore": null, "score": 8.3e-05, "legacy": true, "legacyId": "22100", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 35, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7iDtkfyn322nPzTP4", "geNZ6ZpfFce5intER", "GGn8MBiY8Xz6NdNdH", "EMJ3egz48BtZS8Pws", "BfaAADSQ88cuxLQoD", "Kbm6QnJv9dgWsPHQP", "4iLk2rxTguFqHHs3Y", "xpLXck2nXbE4K3xdE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-14T00:05:09.000Z", "modifiedAt": null, "url": null, "title": "Proving Too Much", "slug": "proving-too-much", "viewCount": null, "lastCommentedAt": "2019-07-01T22:17:42.495Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/G5eMM3Wp3hbCuKKPE/proving-too-much", "pageUrlRelative": "/posts/G5eMM3Wp3hbCuKKPE/proving-too-much", "linkUrl": "https://www.lesswrong.com/posts/G5eMM3Wp3hbCuKKPE/proving-too-much", "postedAtFormatted": "Sunday, April 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Proving%20Too%20Much&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProving%20Too%20Much%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5eMM3Wp3hbCuKKPE%2Fproving-too-much%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Proving%20Too%20Much%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5eMM3Wp3hbCuKKPE%2Fproving-too-much", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5eMM3Wp3hbCuKKPE%2Fproving-too-much", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 662, "htmlBody": "<p>The fallacy of <a href=\"http://en.wikipedia.org/wiki/Proving_too_much\">Proving Too Much</a> is when you challenge an argument because, in addition to proving its intended conclusion, it also proves obviously false conclusions. For example, if someone says &#8220;You can&#8217;t be an atheist, because it&#8217;s impossible to disprove the existence of God&#8221;, you can answer &#8220;That argument proves too much. If we accept it, we must also accept that you can&#8217;t disbelieve in Bigfoot, since it&#8217;s impossible to disprove his existence as well.&#8221;</p>\n<p>I love this tactic <i>so much</i>. I only learned it had a name quite recently, but it&#8217;s been my default style of argument for years. It neatly cuts through complicated issues that might otherwise be totally irresolvable.</p>\n<p>Because here is a fundamental principle of the <a href=\"http://wiki.lesswrong.com/wiki/Dark_arts\">Dark Arts</a> &#8211; you don&#8217;t need an argument that can&#8217;t be disproven, only an argument that can&#8217;t be disproven in the amount of time your opponent has available.</p>\n<p>In a presidential debate, where your opponent has three minutes, that means all you need to do is come up with an argument whose disproof is <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">inferentially distant</a> enough from your audience that it will take your opponent more than three minutes to explain it, or your audience more than three minutes&#8217; worth of mental effort to understand the explanation.</p>\n<p>The <a href=\"http://lesswrong.com/lw/e95/the_noncentral_fallacy_the_worst_argument_in_the/\">noncentral fallacy</a> is the easiest way to do this. &#8220;Martin Luther King was a criminal!&#8221; &#8220;Although what you say is technically correct, categories don&#8217;t work in the way your statement is impl &#8211; &#8221; &#8220;Oh, sorry, time&#8217;s up.&#8221;</p>\n<p>But pretty much anything that assumes a classical Aristotelian view of concepts/objects is gold here. The same is true of any deontological rules your audience might be attached to.</p>\n<p>I tend to get stuck in the position of having argue against those Dark Artsy tactics pretty often. And the great thing about Proving Too Much is that it can demolish an entire complicated argument based on all sorts of hard-to-tease-apart axioms in a split second. For example, <i>After Virtue</i> gave (though it does not endorse) this example of deontological reasoning:</p>\n<blockquote><p>I cannot will that my mother should have had an abortion when she was pregnant with me, except perhaps if it had been certain that the embryo was dead or gravely damaged. But if I cannot will this in my own case, how can I consistently deny to others the right to life that I claim for myself? I would break the so-called Golden Rule unless I denied that a mother in general has a right to an abortion.</p></blockquote>\n<p>It seemed unfair for me to move on in the book without at least checking whether this argument was correct and I should re-evaluate my pro-choice position. But that would require sorting through all the weird baggage here, like what it means to will something, and whether your obligations to potential people are the same as your obligations to real people, and how to apply the Golden Rule across different levels of potentiality.</p>\n<p>Instead I just thought to myself: &#8220;Imagine my mother had raped my father, leading to my conception. I cannot will that a policeman had prevented this rape, but I also do not want to enshrine the general principle that policemen in general have no right to prevent rape. Therefore, this argument proves too much.&#8221; It took all of five seconds.</p>\n<p>Sometimes a quick Proving Too Much can tear apart extremely subtle philosophical arguments that have been debated for centuries. For example, <a href=\"http://en.wikipedia.org/wiki/Pascal%27s_Wager\">Pascal&#8217;s Wager</a> also proves <a href=\"http://wiki.lesswrong.com/wiki/Pascal%27s_mugging\">Pascal&#8217;s Mugging</a> (they may both be correct, but bringing the Mugging in at least proves ignoring their correctness to be a reasonable and impossible-to-critique life choice). And <a href=\"http://en.wikipedia.org/wiki/Ontological_argument#Anselm\">Anselm&#8217;s Ontological Argument</a> seems much less foreboding when you realize it can double as a method for <a href=\"http://machall.com/view.php?date=2003-04-21\">creating jelly donuts on demand</a>.</p>\n<p>Interestingly, I think that one of the examples of proving too much <a href=\"http://en.wikipedia.org/wiki/Proving_too_much\">on Wikipedia</a> can itself be demolished by a proving too much argument, but I&#8217;m not going to say which one it is because I want to see if other people independently come to the same conclusion.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "dJ6eJxJrCEget7Wb6": 8}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "G5eMM3Wp3hbCuKKPE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 59, "baseScore": 75, "extendedScore": null, "score": 0.000174, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "XsMTxdQ6fprAQMoKi", "canonicalCollectionSlug": "codex", "canonicalBookId": "jF58hKP9ZLzgy22Jr", "canonicalNextPostSlug": "beware-isolated-demands-for-rigor", "canonicalPrevPostSlug": "the-virtue-of-silence", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 75, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yCWPkLi8wJvewPbEp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-14T03:15:31.187Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Whining-Based Communities", "slug": "seq-rerun-whining-based-communities", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:53.296Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xC8eECrGoGNXsEByo/seq-rerun-whining-based-communities", "pageUrlRelative": "/posts/xC8eECrGoGNXsEByo/seq-rerun-whining-based-communities", "linkUrl": "https://www.lesswrong.com/posts/xC8eECrGoGNXsEByo/seq-rerun-whining-based-communities", "postedAtFormatted": "Sunday, April 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Whining-Based%20Communities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Whining-Based%20Communities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxC8eECrGoGNXsEByo%2Fseq-rerun-whining-based-communities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Whining-Based%20Communities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxC8eECrGoGNXsEByo%2Fseq-rerun-whining-based-communities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxC8eECrGoGNXsEByo%2Fseq-rerun-whining-based-communities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 279, "htmlBody": "<p>Today's post, <a href=\"/lw/8t/whiningbased_communities/\">Whining-Based Communities</a> was originally published on 07 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Many communities feed emotional needs by offering their members someone or something to blame for failure - say, those looters who don't approve of your excellence. You can easily imagine some group of \"rationalists\" congratulating themselves on how reasonable they were, while blaming the surrounding unreasonable society for keeping them down. But this is not how real rationality works - there's no assumption that other agents are rational. We all face unfair tests (and yes, they are unfair to different degrees for different people); and how well you do with your unfair tests, is the test of your existence. Rationality is there to help you win anyway, not to provide a self-handicapping excuse for losing. There are no first-person extenuating circumstances. There is absolutely no point in going down the road of mutual bitterness and consolation, about anything, ever.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h76/seq_rerun_extenuating_circumstances/\">Extenuating Circumstances</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xC8eECrGoGNXsEByo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 1.1680580192964968e-06, "legacy": true, "legacyId": "22296", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rg7vPTtyLMfT6Qqud", "C2Jc6tpYZzYfmGwTC", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-14T05:59:14.460Z", "modifiedAt": null, "url": null, "title": "Bitcoin Cryonics Fund", "slug": "bitcoin-cryonics-fund", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:16.659Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lsparrish", "createdAt": "2010-06-30T19:05:11.515Z", "isAdmin": false, "displayName": "lsparrish"}, "userId": "xgc8giekPig6tYf2X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/68TGNutjDcBcq6PCZ/bitcoin-cryonics-fund", "pageUrlRelative": "/posts/68TGNutjDcBcq6PCZ/bitcoin-cryonics-fund", "linkUrl": "https://www.lesswrong.com/posts/68TGNutjDcBcq6PCZ/bitcoin-cryonics-fund", "postedAtFormatted": "Sunday, April 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bitcoin%20Cryonics%20Fund&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABitcoin%20Cryonics%20Fund%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F68TGNutjDcBcq6PCZ%2Fbitcoin-cryonics-fund%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bitcoin%20Cryonics%20Fund%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F68TGNutjDcBcq6PCZ%2Fbitcoin-cryonics-fund", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F68TGNutjDcBcq6PCZ%2Fbitcoin-cryonics-fund", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 282, "htmlBody": "<p>The bitcoins that I had set aside for a Cryonics contest two years ago (and were unredeemed) are suddenly worth a lot more.</p>\n<p>Details: I had added 10 bitcoins to get things started, and there were 4.75 worth of additional donations. These were partially lost when the hosted online wallet that I was using (MyBitcoin) was hacked, but 49% was recovered. As of today, after refunding part of the donated money, it is now worth 5.2675. I will be adding from my personal store to bring it up to an even 5.5. At $140 per coin, the new total is $770.</p>\n<p>I've decided to follow the buy-and-hold strategy for at least another year, since it worked so well. I don't have exact details on what I'll do with it, but it will not be converted or spent for at least one year, and will eventually be used for promoting cryonics in some way.</p>\n<p style=\" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;\">Some things I have in mind if it gets big include:</p>\n<ul>\n<li> subsidizing cryonics dues for low-income people</li>\n<li>covering funding shortfalls for those unable to obtain life insurance due medical problems</li>\n<li>cryonics scholarships to support the development of expertise in neural cryobiology, the dying process, and other neglected areas of concern to cryonics</li>\n<li>hiring a public relations team <em>professionally</em> to repair the image of cryonics</li>\n<li>research to improve viability and reduce dehydration</li>\n<li>empirical validation through scanning the connectome</li>\n</ul>\n<p>Contributions can be made to:</p>\n<p><a href=\"https://blockchain.info/address/1Jdn36JUwvJdr3Qiie4aAseFdcoTsND9Qo\">1Jdn36JUwvJdr3Qiie4aAseFdcoTsND9Qo</a></p>\n<p>(Updated, since the previous address was attached to my personal wallet on an outdated client, which was causing money to be moved out of it by accident. The above is a brainwallet with a reasonably secure passphrase, generated using <a href=\"http://blockchain.info/\">Blockchain.info</a>.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "68TGNutjDcBcq6PCZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 11, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "22245", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-14T09:28:39.349Z", "modifiedAt": null, "url": null, "title": "Grad Student Advice Repository", "slug": "grad-student-advice-repository", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:25.183Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stabilizer", "createdAt": "2011-12-02T09:36:56.841Z", "isAdmin": false, "displayName": "Stabilizer"}, "userId": "Qa3pLZx3o2TApyfgq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9iofKNvYKZe3T7MpS/grad-student-advice-repository", "pageUrlRelative": "/posts/9iofKNvYKZe3T7MpS/grad-student-advice-repository", "linkUrl": "https://www.lesswrong.com/posts/9iofKNvYKZe3T7MpS/grad-student-advice-repository", "postedAtFormatted": "Sunday, April 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Grad%20Student%20Advice%20Repository&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGrad%20Student%20Advice%20Repository%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9iofKNvYKZe3T7MpS%2Fgrad-student-advice-repository%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Grad%20Student%20Advice%20Repository%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9iofKNvYKZe3T7MpS%2Fgrad-student-advice-repository", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9iofKNvYKZe3T7MpS%2Fgrad-student-advice-repository", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 249, "htmlBody": "<p>There was <a href=\"/r/discussion/lw/h6m/post_request_thread/8qsg\">some support</a>&nbsp;for the idea of starting an advice repository for grad students much in the same tradition as the <a href=\"/lw/gx5/boring_advice_repository/\">Boring Advice Repository</a> and the <a href=\"/lw/h2m/solved_problems_repository/\">Solved Problems Repository</a>&nbsp;started earlier by <a href=\"/user/Qiaochu_Yuan/overview/\">Qiaochu_Yuan</a>. So here goes.</p>\n<p>Please share any advice, boring or otherwise, for succeeding at grad school. I realize that succeeding might mean different things to different people, but I believe most people largely agree with what it means in this context. Feel free to elaborate on what you believe it should mean, if you have views on the subject.</p>\n<p>I am a theoretical physics grad student, so I'm personally more interested in advice for mathy disciplines (i.e. physics, math, CS), and I also suspect that there are many grad students from these disciplines on LessWrong; but advice for any discipline is welcome as well.&nbsp;</p>\n<p>Advice is welcome from anyone, but please do mention your background for providing the advice so that people can weight the advice accordingly. For example, I would be more be open to listening to <a href=\"http://calnewport.com/blog/\">advice from someone who has completed a very successful PhD</a>, than from someone who has simply interacted with a lot of grad students but has never been to grad school.&nbsp;</p>\n<p>Also, feel free to link to advice from other sources, and maybe quote the most useful parts in what you read. Remember, this is meant to be a repository, so that people can come and find the advice, so don't worry if it seems to be something most people would've already read or known.</p>\n<p>Thanks!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1, "fkABsGCJZ6y9qConW": 1, "Eha62RrqBtEbpcEza": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9iofKNvYKZe3T7MpS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 1.1683160786397447e-06, "legacy": true, "legacyId": "22297", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HEn2qiMxk5BggN83J", "iTzvJ7kKK2TYJhYHB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-14T11:11:37.440Z", "modifiedAt": null, "url": null, "title": "[LINK] Climate change and food security", "slug": "link-climate-change-and-food-security", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:55.506Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "Zwqz6uaZMhJ7uqHae", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2XwNtcp26r2RTiDEN/link-climate-change-and-food-security", "pageUrlRelative": "/posts/2XwNtcp26r2RTiDEN/link-climate-change-and-food-security", "linkUrl": "https://www.lesswrong.com/posts/2XwNtcp26r2RTiDEN/link-climate-change-and-food-security", "postedAtFormatted": "Sunday, April 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Climate%20change%20and%20food%20security&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Climate%20change%20and%20food%20security%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2XwNtcp26r2RTiDEN%2Flink-climate-change-and-food-security%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Climate%20change%20and%20food%20security%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2XwNtcp26r2RTiDEN%2Flink-climate-change-and-food-security", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2XwNtcp26r2RTiDEN%2Flink-climate-change-and-food-security", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 112, "htmlBody": "<p>A Guardian <a title=\"article\" href=\"http://www.guardian.co.uk/global-development/2013/apr/13/climate-change-millions-starvation-scientists\">article</a> on the impact of climate change on food security. This is worrying (albeit perhaps not a global&nbsp;catastrophic (or existential) risk). It has the potential to wipe out the gains made against extreme poverty in the last few decades.</p>\n<p>Should we be so pessimistic? Climate change might be averted through government action or a technological fix; or the poorest might get rich enough to be protected from this insecurity; or we could see a second 'Green Revolution' with GM, etc. I've also seen some discussion that climate change could in fact increase food cultivation - in Russia and Canada for example.</p>\n<p>How do people feel about this - optimistic or pessimistic?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"frcrRgCk9PDbEScua": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2XwNtcp26r2RTiDEN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 0, "extendedScore": null, "score": 4e-06, "legacy": true, "legacyId": "22299", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-14T19:50:24.765Z", "modifiedAt": null, "url": null, "title": "I Thought Free Will Would Be Easy to Distinguish from Determinism, but I Was Wrong", "slug": "i-thought-free-will-would-be-easy-to-distinguish-from", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:55.558Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alrenous", "createdAt": "2013-04-08T20:57:31.783Z", "isAdmin": false, "displayName": "Alrenous"}, "userId": "wodzkPT6PcuqaaMbK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wRsALjq9rLwdhtQog/i-thought-free-will-would-be-easy-to-distinguish-from", "pageUrlRelative": "/posts/wRsALjq9rLwdhtQog/i-thought-free-will-would-be-easy-to-distinguish-from", "linkUrl": "https://www.lesswrong.com/posts/wRsALjq9rLwdhtQog/i-thought-free-will-would-be-easy-to-distinguish-from", "postedAtFormatted": "Sunday, April 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%20Thought%20Free%20Will%20Would%20Be%20Easy%20to%20Distinguish%20from%20Determinism%2C%20but%20I%20Was%20Wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%20Thought%20Free%20Will%20Would%20Be%20Easy%20to%20Distinguish%20from%20Determinism%2C%20but%20I%20Was%20Wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwRsALjq9rLwdhtQog%2Fi-thought-free-will-would-be-easy-to-distinguish-from%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%20Thought%20Free%20Will%20Would%20Be%20Easy%20to%20Distinguish%20from%20Determinism%2C%20but%20I%20Was%20Wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwRsALjq9rLwdhtQog%2Fi-thought-free-will-would-be-easy-to-distinguish-from", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwRsALjq9rLwdhtQog%2Fi-thought-free-will-would-be-easy-to-distinguish-from", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2552, "htmlBody": "<p>I decided LessWrong would be more impressive to me with a particular, well-defined change. I decided I would be the change I want to see in the world, and see what happens. As a bonus, if someone is already doing this and I just haven't noticed, (due to insufficient diligence, due to constructive laziness,) or I'm wasting both our times for some other reason, I understand there's a downvote button.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>First, I should define the explanandum. I feel like I'm free. I have a direct sensation of basic freedom-ness. Most evidence seems to suggest my actions are pre-determined, which feels entirely different to believe.</p>\n<p>Distinguishing all other differently-feeling things is easy - there's always an actual objective (if sometimes illusory) difference that the different sensations correspond to, and causing that property to converge causes the different corresponding sensations to converge.</p>\n<p>For example, food prepared by my hated enemy is not something I want to eat. Food cooked by someone I somewhat dislike I prefer to avoid eating. I'm fine with food made by someone I don't know is my hated enemy. These dishes might be atom-for-atom identical, this might be an irrational feeling, but even so, there is an objective property that my feeling is a function of. Similarly, if I mistakenly believe the chef is my hated enemy, simply informing me otherwise will repair my perception of the comestibles. There's experiments you can do to safely predict my reaction.</p>\n<p>Based on this long standing, unviolated pattern I concluded that, obviously, there must be some experiment that can predict what causes me to like freedom, and dislike determinism. It may be a rationally irrelevant feature. I may care about it simply because I care about it, pre-rationally.</p>\n<p>I cannot find any such experiment. I can find one feature, but it only shows I shouldn't be able to tell the difference.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Like most children, I was naive. I can prove I have free will by doing something against my self-interest right? Ha ha, silly mini-Alrenous! This only shows that I value proving my freedom more than whatever I'm sacrificing, no matter what I'm sacrificing. I cannot act against my self-interest. (You can argue with me about psychological egoism, but I won't change my mind, 99.5% &plusmn; 0.3%, by observation.) Similarly, if you find a decision I apparently cannot make, it doesn't prove I lack free will, it just proves I care more about not doing that thing than about your opinion.</p>\n<p>This line of logic generalizes tremendously, so I tried turning the question around. What can't I physically do without free will? This question is very easy in answer in the age of computers, and the answer is nothing. Anything I can do, you can program a computer to copy. Heck, most if not all of it can happen by pure chance. (If you can think of a counter-example, please let me know.)</p>\n<p>Perhaps, I asked myself, I can think things - make calculations - that are not possible for a computer? And therefore, while I wouldn't have access to different actions, I would choose better ones.</p>\n<p>So, what, I can be illogical? Either I'm concluding what the evidence shows, or I'm not. And, again, no matter how advanced my epistemology, once I come up with it, you can simply extract the rules and teach them to a computer. If I'm concluding something the evidence doesn't show (but is truer) ... well, I'm just not, free will isn't clairvoyance. (Though it amuses me to imagine it. Learn things you can't know, with Free Will&trade;!) Note this conclusion is recursive. If you can copy my epistemology, you can also copy my method for learning about or inventing epistemologies.</p>\n<p>&nbsp;</p>\n<p>This conclusion is bolstered by a second line of evidence. What are the consequences of assuming free will vs. determinism? In a stochastic universe, there are no consequences at all. (In a non-random universe, decisions would be obviously acausal, barring certain special conditions.)</p>\n<p>For example, naive mini-Alrenous, like most, thought that determinism invalidates the legal system and the idea of responsibility. (Experiments I'm too lazy to reference show that believing in determinism increases asocial behaviour, which I interpret to mean they think they can get away with it or there's no reason not to.) This is true in the sense that it invalidates classical responsibility, however, it immediately replaces it with a bit-for-bit identical consequence. Instead of punishing crime to encourage the decision against further crime, you punish crime to deterministically lower the odds of it happening again. Instead of punishing crime so that criminals see a bad future in crime and decide not to, you punish crime to alter the incentives which cause criminals to perpetrate. (Is it hard for you to tell these descriptions apart, or just me? My perspective, having concluded they're the same, is clouding my judgment.) In both cases, I can transform the 'responsible' party from one who is physically responsible for the undesired outcome, into being the party who needs to be punished if you want to safely expect less crime in the future. Under free will, it is the decision-maker. Under determinism, it's usually the biological entity who instantiated the act - in other words the exact same entity.</p>\n<p>(Constructive criticism request: Did I beat that one into the ground? Did I not explain it enough? Did I make the common programmer mistake of minutely describing the obvious and glossing over the difficult bit? Should I have asked for constructive criticism elsewhere?)</p>\n<p>&nbsp;</p>\n<p>I feel like doing another example. Free will apparently gives me the option to choose, out of any possible future world I have the power to reach, the one I value most. Determinism will cause me to choose the possible future I most value.</p>\n<p>&nbsp;</p>\n<p>There are many further examples, if this isn't enough for you. I didn't stop looking once I'd disproven my hypothesis; for my own use I intentionally beat it into the ground.</p>\n<p>&nbsp;</p>\n<p>When informed that it wasn't cooked by my hated enemy, and was not only atom-for-atom identical (or close enough as far as I can measure) to a meal I'd like to eat, but had the same history as a meal I'd like to eat, my perception of the hospitality changed to be bit-for-bit identical to one of a meal I'd like to eat.</p>\n<p>When informed that determinism is identical to free will, the needle didn't even quiver. Free will is great and boo to determinism, and screw you if you try to change my mind.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>That's not all.</p>\n<p>Free will is still different from determinism. Actually, I was correct, if in a very, very limited sense.</p>\n<p>If an electron has free will, it can violate statistics. If, instead of (insert your account of stochasticity) determining whether I will measure it as spin up or spin down, it decides. If it wants, it can pick spin down ten times, a hundred, a thousand - however many in a row it wants. It can, according to my statistics, be arbitrarily unlikely.</p>\n<p>This is because my so-called statistics for a free will electron were bunk. I can collate all the decisions it made in the past, add them up and divide [down] by [total], but it doesn't mean anything. A free will electron doesn't have a probability. It is not likely or unlikely to pick either. There is not only no fact of the matter about which it will pick, there's no probabilistic fact of the matter. Again, as demonstrated by the fact that no matter what distribution you measure or derive, the electron has the power to prove you arbitrarily wrong.</p>\n<p>This is another reason I earlier needed the disclaimer, 'in a stochastic universe.' In principle, proving that humans have free will in this sense is straightforward, if perhaps somewhat expensive. In practice, humans are a chaotic system embedded in a chaotic environment with true-random inputs and it is impossible to distinguish that from a human with free will. Similarly, you could put humans in an environment where most chaos cancels out, but even a good-faith critic can always say there's too much chaos.</p>\n<p>Assume Foundation. Hari Seldon. Psychohistory. I accurately predict the behaviour of large chunks of humans for a reasonable amount of time, and my model isn't just overtuned or something. Then, suddenly, the humans deviate. Did they just make a free will decision, and my statistics were bogus? Did I simply not have enough decimal points to forecast out that far? Or were my statistics simply unable to cope with the accumulated weight of the random walk amplified by the chaotic system?</p>\n<p>But let's assume I'm wrong about this conclusion too. Let's say I get all the decimal points. Yes, yes, a universe cannot simulate itself. Actually, it can - it cannot predict itself, but it can retrodict, by simulating one half of itself and then simulating the other half and then combining the simulations. So, I use parts of human technology to retrodict the rest of human existence. If my audited retrodiction, starting from the actual initial conditions, successfully replicates the events, then I have successfully modelled humanity and can safely say I understand it, and it is deterministic.</p>\n<p>Only, in a stochastic universe, this is a lot like a cloaked singularity. Technically speaking, in a world idealized to within an inch of its life, I can retrodict humanity. In practice, the combinatorics grow...fast. Exponentially? Hyper exponentially? Whatever the exact order, it is correctly summed up as 'fucking fast.' However much computing power I throw at the problem, it will become negligible in short order. How far can retrodict with a computer on the verge of collapsing into a black hole, before civilization collapses catastrophically enough to destroy the machine? That far, plus a femtosecond further, will take many orders of magnitude longer to compute.</p>\n<p>Actually doing even part of this computation is way beyond the possible, even assuming all the decimal places.</p>\n<p>&nbsp;</p>\n<p>This time, while free will and determinism aren't actually identical, they're still indistinguishable. The evidence may exist, but I can't gather it.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Here's a further problem. I know a (pretty abstract) blueprint for a free-will machine. (I estimate you can play with a bank of these for about $100 000, peanuts for serious physics labs.)</p>\n<p>The goal is to make statistics meaningless, with the test that, no matter how much data you accumulate, the machine will be able to prove you arbitrarily wrong.</p>\n<p>Imagine a spontaneous event. A statue of liberty made of butter appears in a near Earth orbit.</p>\n<p>Okay, say scientists. That was pretty unexpected. But, we can say that, if, for some unknown reason, a statue of liberty made of butter (solmb) appears, 100% of the time it will appear in near Earth orbit. We don't have much data so we're not very confident of this conclusion, but it's the best we can do right now. (You see where this is going?)</p>\n<p>The next solmb appears in far Earth orbit. Okay, 50% near, 50% far. The next, Alpha Centauri. The next, mediumish orbit. Perhaps next, there's a cluster around a particular planet in Alpha Centauri, scientists stop panicking, start building some distribution...but this is a truly spontaneous event. Solmbs can appear anywhere. No matter what description or distribution you make up, in an infinite universe, the solmbs can and will appear in places infinitely unlikely. (Even if you can't detect them right now, the true distribution changes.) Solmbs keep popping up at random intervals at random places, making a total mockery of both science and the law of conservation of energy.</p>\n<p>To do this for real, with no conservation violation, hook up a quantum particle to a measurement device, and hook that in double-recursion to a computation device. The instrument measures the particle's random collapse from superposition, and feeds it in bit form to the computer, which produces some output, which is then used to A) set the probabilities on the various possible quantum outcomes and B) re-program itself, so it computes something different next time.</p>\n<p>This machine can random-walk to any output bit stream, (which is necessary - it needs an infinite possibility space because I'm going to divide by it) and because of the double-recursion, the probability of all future states depends on all past states, directly contradicting the fundamental law of probability.</p>\n<p>Technically it needs an infinite number of transistors, but you don't actually have to run it until it starts bumping up into physical limits. You can add more transistors, or simply reset the device, whatever you want. If it can run infinitely, the probability of any particular state would be infinitesimal, which is physically equivalent to zero. Doesn't matter, you say? Cloaked singularity? The machine can't know how long it has been computing for, that would be serious nonlocality. It might have reached the current state by traversing every possible state, used infinite transistors, and then dropping most of them. Or you might have just switched it on. It is atom-for-atom the same state, with the same output, bit-for-bit.</p>\n<p>If its probability is meaningless at some future time, it must be meaningless right now.</p>\n<p>Free will in a can.</p>\n<p>Four notes.</p>\n<p>All bits of my machine are fully deterministic, at least in the stochastic sense. You can, if you&nbsp; watched the full run, both calculate the exact probability of this machine being in its current state, and, at the same time, the machine itself can't possibly have a meaningful probability. Just as the solmb has a well-defined historical distribution right now, even though by definition it doesn't have a probability. It has free will, and you can't ever measure it as having it.</p>\n<p>It is not only likely, but practically certain that such a machine exists in human brains. The components are all there, the only question is if they're hooked up right, and that will happen by accident if it doesn't on purpose.</p>\n<p>I should say and not just imply that the machine can be arbitrarily arbitrary; getting arbitrarily small probabilities in finite time is just a matter of using more states in the true-random bit generator.</p>\n<p>I humbly suggest probability is quantized like everything else, or at least has a smallest meaningful delta, so if you insist on having actually-zero probabilities, it's just a matter of 1 / [probability quanta] &lt; rand_measure_states^iterations, and therefore time to probability singularity = iterations*iteration_time, at which point the device will 'wake up.'</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>On the evidence available to me, not only can I not distinguish free will and determinism, I can still show that they're different. My feeling that free will is different from determinism is totally justified and totally meaningless. Does this legitimately break the pattern of correlation between sensations and sensed properties? I don't know, can't even begin to guess. If I completely accept the compatibilist position, it immediately reduces to determinism. I can try to say, 'wrong question,' to say I'm somehow misunderstanding that these are properties the world can have, but then I have to explain the appearance of an apparently useless yet instinctive construct, that, apparently, has strong positive adaptive/selective value. Equivalently, how my brain knows it is believing in free will when it is identical to determinism. Equivalently, how it can tell they should imply different reactions. Concluding that determinism and free will might be the same or an impossible adjective like up vs. down green does not in fact address the explanandum, at least not anything like directly.</p>\n<p>I can only respond, dear Reality, what the fucking fuck. Could you stop messing with my head? It hurts. Ow.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wRsALjq9rLwdhtQog", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -10, "extendedScore": null, "score": -2.1e-05, "legacy": true, "legacyId": "22250", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-14T21:29:10.370Z", "modifiedAt": null, "url": null, "title": "Meetup : Bielefeld Meetup April 17th", "slug": "meetup-bielefeld-meetup-april-17th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:55.537Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Just_existing", "createdAt": "2012-01-16T18:40:07.392Z", "isAdmin": false, "displayName": "Just_existing"}, "userId": "o89m5G8Hk2tbpKTxg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b8iKP3xp2foem76Bh/meetup-bielefeld-meetup-april-17th", "pageUrlRelative": "/posts/b8iKP3xp2foem76Bh/meetup-bielefeld-meetup-april-17th", "linkUrl": "https://www.lesswrong.com/posts/b8iKP3xp2foem76Bh/meetup-bielefeld-meetup-april-17th", "postedAtFormatted": "Sunday, April 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Bielefeld%20Meetup%20April%2017th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Bielefeld%20Meetup%20April%2017th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8iKP3xp2foem76Bh%2Fmeetup-bielefeld-meetup-april-17th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Bielefeld%20Meetup%20April%2017th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8iKP3xp2foem76Bh%2Fmeetup-bielefeld-meetup-april-17th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb8iKP3xp2foem76Bh%2Fmeetup-bielefeld-meetup-april-17th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/li'>Bielefeld Meetup April 17th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 April 2013 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Grill/Bar Verve, Klosterplatz 13, Bielefeld</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are meeting once again in Bielefeld.</p>\n\n<p>The topics of this evening are not yet determined, but will be in the next days, or develop during the meetup. Highly interesting talk can be expected.</p>\n\n<p>If you live in the area consider dropping by :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/li'>Bielefeld Meetup April 17th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b8iKP3xp2foem76Bh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 2, "extendedScore": null, "score": 1.1688146707658025e-06, "legacy": true, "legacyId": "22304", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Bielefeld_Meetup_April_17th\">Discussion article for the meetup : <a href=\"/meetups/li\">Bielefeld Meetup April 17th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 April 2013 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Grill/Bar Verve, Klosterplatz 13, Bielefeld</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are meeting once again in Bielefeld.</p>\n\n<p>The topics of this evening are not yet determined, but will be in the next days, or develop during the meetup. Highly interesting talk can be expected.</p>\n\n<p>If you live in the area consider dropping by :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Bielefeld_Meetup_April_17th1\">Discussion article for the meetup : <a href=\"/meetups/li\">Bielefeld Meetup April 17th</a></h2>", "sections": [{"title": "Discussion article for the meetup : Bielefeld Meetup April 17th", "anchor": "Discussion_article_for_the_meetup___Bielefeld_Meetup_April_17th", "level": 1}, {"title": "Discussion article for the meetup : Bielefeld Meetup April 17th", "anchor": "Discussion_article_for_the_meetup___Bielefeld_Meetup_April_17th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T02:43:19.453Z", "modifiedAt": null, "url": null, "title": "Looks like it was a completely different problem.... \"LW Women: Submissions on misogyny\" needs normal visibility", "slug": "looks-like-it-was-a-completely-different-problem-lw-women", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:55.736Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/m3fe4kqmc6BH9XaQh/looks-like-it-was-a-completely-different-problem-lw-women", "pageUrlRelative": "/posts/m3fe4kqmc6BH9XaQh/looks-like-it-was-a-completely-different-problem-lw-women", "linkUrl": "https://www.lesswrong.com/posts/m3fe4kqmc6BH9XaQh/looks-like-it-was-a-completely-different-problem-lw-women", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Looks%20like%20it%20was%20a%20completely%20different%20problem....%20%22LW%20Women%3A%20Submissions%20on%20misogyny%22%20needs%20normal%20visibility&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALooks%20like%20it%20was%20a%20completely%20different%20problem....%20%22LW%20Women%3A%20Submissions%20on%20misogyny%22%20needs%20normal%20visibility%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm3fe4kqmc6BH9XaQh%2Flooks-like-it-was-a-completely-different-problem-lw-women%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Looks%20like%20it%20was%20a%20completely%20different%20problem....%20%22LW%20Women%3A%20Submissions%20on%20misogyny%22%20needs%20normal%20visibility%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm3fe4kqmc6BH9XaQh%2Flooks-like-it-was-a-completely-different-problem-lw-women", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fm3fe4kqmc6BH9XaQh%2Flooks-like-it-was-a-completely-different-problem-lw-women", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 151, "htmlBody": "<p><strong>Edited to add:</strong> <a href=\"/r/discussion/lw/fmv/lw_women_submissions_on_misogyny/\">The post</a>&nbsp;was probably always in Discussion, but if \"r/discussion\" is taken out of a url, the post looks like it's in Main but without proper notification. See the comments here for a bit more detail.</p>\n<p>**********</p>\n<p><a href=\"/lw/fmv/lw_women_submissions_on_misogyny/\">LW Women: Submissions on Misogyny</a> was moved from Discussion to Main, but doesn't appear in lists of Promoted, New, or (in the right sidebar) Recent posts. Comments to it aren't showing up in Recent Comments.</p>\n<p><em>Edited to add:</em> Comments are showing up in Recent Comments for Discussion.</p>\n<p>I've brought this up twice-- in the comments and in the open thread-- and it doesn't seem to have made any difference.</p>\n<p>I assume that this is an honest mistake or a site weirdness, but I'd really like the topic to get the attention it deserves. I'm also wondering whether other posts have gotten semi-lost the same way.</p>\n<p><em>Edited to add:</em> Is there a best place for bringing up site weirdnesses?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "m3fe4kqmc6BH9XaQh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 6, "extendedScore": null, "score": 1.169032178960202e-06, "legacy": true, "legacyId": "22305", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pYnjatHi3dupFgCQe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T03:10:47.407Z", "modifiedAt": null, "url": null, "title": "Pay Other Species to Pandemize Vegetarianism for You", "slug": "pay-other-species-to-pandemize-vegetarianism-for-you", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.079Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/q48bD3hiCauuJM528/pay-other-species-to-pandemize-vegetarianism-for-you", "pageUrlRelative": "/posts/q48bD3hiCauuJM528/pay-other-species-to-pandemize-vegetarianism-for-you", "linkUrl": "https://www.lesswrong.com/posts/q48bD3hiCauuJM528/pay-other-species-to-pandemize-vegetarianism-for-you", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pay%20Other%20Species%20to%20Pandemize%20Vegetarianism%20for%20You&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APay%20Other%20Species%20to%20Pandemize%20Vegetarianism%20for%20You%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq48bD3hiCauuJM528%2Fpay-other-species-to-pandemize-vegetarianism-for-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pay%20Other%20Species%20to%20Pandemize%20Vegetarianism%20for%20You%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq48bD3hiCauuJM528%2Fpay-other-species-to-pandemize-vegetarianism-for-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq48bD3hiCauuJM528%2Fpay-other-species-to-pandemize-vegetarianism-for-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 241, "htmlBody": "<p>(This post is completely jocose. If you can't take it, don't read it. I'm making fun of Rationalists, of Me, of homo economicus, of Vegans and of things I really praise, like Consequentialism and Outsourcing. It is<em> not serious</em>. The Sheldon Sarcasm sign has been lifted, your asperger side has been warned)&nbsp;</p>\n<p>&nbsp;</p>\n<p>One of the features of rationality is that it allows you to mix different units.</p>\n<p>By rationally behaving economically, you learn, for you, how many apples costs an orange.</p>\n<p>Vegetarians and Vegans sell diminishing suffering. They claim to have the best price in the market, only Singularitarians and Existential Risk avoiding competes with their numbers. Utilitarians are a good target market.</p>\n<p>Then a Lesswronger came and noticed that, and said: Well, why not <a href=\"/r/discussion/lw/h6u/pay_other_people_to_go_vegetarian_for_you/\">buy someone to be a vegetarian for you, here. </a></p>\n<p>Awesome price actually. You shock a few humans (notice that humans are animals, who clearly would rather be shocked than eaten), one of them enough to make him vegan.</p>\n<p>So why not take this to the next level?&nbsp;</p>\n<p>Figure out the reproductive cycle and eating habits of <a href=\"http://abcnews.go.com/Health/Wellness/allergic-meat-lone-star-tick-spreading-vegetarianism/story?id=16610228#.UWtrRElLMgQ\">this beetle that makes people vegetarian</a>. Make sure the evidence is solid.</p>\n<p>Get a basement lab full of them.</p>\n<p>Ship them alive to cities where more people consume meat. Wait for population growth.</p>\n<p>Save a lot of animals!&nbsp;</p>\n<p>&nbsp;</p>\n<p>Seems straightforward, but is it?</p>\n<p>Also, are there similar strategies for other groups? Are there easy, but strange, shortcuts for selfish hedonists,<a href=\"/lw/gs7/lets_make_a_rational_immortalist_sequence/\"> immortalists</a>, <a href=\"http://rationalaltruist.com/\">rational altruists</a>? <a href=\"http://www.hedweb.com/\">Utilitarian hedonists</a>? The ancient school of <a href=\"http://www.amirrorclear.net/academic/ideas/negative-utilitarianism/index.html\">negative utilitarianists</a>? Cryonicists?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "q48bD3hiCauuJM528", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 0, "extendedScore": null, "score": 1.1690511988492108e-06, "legacy": true, "legacyId": "22306", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HxqXTzuamd3hZ5nMQ", "cnmx4TAZQdqs3dwrS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T04:19:32.885Z", "modifiedAt": null, "url": null, "title": "Meetup : Buffalo - Thursday Meetup ", "slug": "meetup-buffalo-thursday-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "StonesOnCanvas", "createdAt": "2012-06-28T17:32:49.237Z", "isAdmin": false, "displayName": "StonesOnCanvas"}, "userId": "FAfkKGH6E8BLmXW4M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DwShnJrRThzZQ3SW3/meetup-buffalo-thursday-meetup", "pageUrlRelative": "/posts/DwShnJrRThzZQ3SW3/meetup-buffalo-thursday-meetup", "linkUrl": "https://www.lesswrong.com/posts/DwShnJrRThzZQ3SW3/meetup-buffalo-thursday-meetup", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Buffalo%20-%20Thursday%20Meetup%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Buffalo%20-%20Thursday%20Meetup%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDwShnJrRThzZQ3SW3%2Fmeetup-buffalo-thursday-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Buffalo%20-%20Thursday%20Meetup%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDwShnJrRThzZQ3SW3%2Fmeetup-buffalo-thursday-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDwShnJrRThzZQ3SW3%2Fmeetup-buffalo-thursday-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lj'>Buffalo - Thursday Meetup </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 April 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">University at Buffalo - North Campus 31 Capen Hall</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Location: 31 Capen Hall is on the ground floor of Capen (under the main floor of the Capen Library). It is also near the Capen Cafe.</p>\n\n<p>Hey Everyone, \nWe are delving back into the sequences and next in line is The Virtue of Narrowness (<a href=\"http://lesswrong.com/lw/ic/the_virtue_of_narrowness/\" rel=\"nofollow\">http://lesswrong.com/lw/ic/the_virtue_of_narrowness/</a>). Its a pretty good read and I've got some good ideas for activities/games we could do to illustrate it.</p>\n\n<p>On side note, I also came across this image recently (<a href=\"http://measureofdoubt.files.wordpress.com/2013/04/simplified-map.jpg\" rel=\"nofollow\">http://measureofdoubt.files.wordpress.com/2013/04/simplified-map.jpg</a>)  which got me thinking about our individual goals. Currently, we're focusing a lot of our time on Epistemic Rationality, while not really focusing any attention on Instrumental Rationality. Look it over and let me know what you guys want to work on for future meetups.</p>\n\n<p>See you at UB!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lj'>Buffalo - Thursday Meetup </a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DwShnJrRThzZQ3SW3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1690988155186198e-06, "legacy": true, "legacyId": "22307", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Buffalo___Thursday_Meetup_\">Discussion article for the meetup : <a href=\"/meetups/lj\">Buffalo - Thursday Meetup </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 April 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">University at Buffalo - North Campus 31 Capen Hall</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Location: 31 Capen Hall is on the ground floor of Capen (under the main floor of the Capen Library). It is also near the Capen Cafe.</p>\n\n<p>Hey Everyone, \nWe are delving back into the sequences and next in line is The Virtue of Narrowness (<a href=\"http://lesswrong.com/lw/ic/the_virtue_of_narrowness/\" rel=\"nofollow\">http://lesswrong.com/lw/ic/the_virtue_of_narrowness/</a>). Its a pretty good read and I've got some good ideas for activities/games we could do to illustrate it.</p>\n\n<p>On side note, I also came across this image recently (<a href=\"http://measureofdoubt.files.wordpress.com/2013/04/simplified-map.jpg\" rel=\"nofollow\">http://measureofdoubt.files.wordpress.com/2013/04/simplified-map.jpg</a>)  which got me thinking about our individual goals. Currently, we're focusing a lot of our time on Epistemic Rationality, while not really focusing any attention on Instrumental Rationality. Look it over and let me know what you guys want to work on for future meetups.</p>\n\n<p>See you at UB!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Buffalo___Thursday_Meetup_1\">Discussion article for the meetup : <a href=\"/meetups/lj\">Buffalo - Thursday Meetup </a></h2>", "sections": [{"title": "Discussion article for the meetup : Buffalo - Thursday Meetup ", "anchor": "Discussion_article_for_the_meetup___Buffalo___Thursday_Meetup_", "level": 1}, {"title": "Discussion article for the meetup : Buffalo - Thursday Meetup ", "anchor": "Discussion_article_for_the_meetup___Buffalo___Thursday_Meetup_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yDfxTj9TKYsYiWH5o"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T05:15:53.396Z", "modifiedAt": null, "url": null, "title": "Meetup : Mountain View: Reinforcement", "slug": "meetup-mountain-view-reinforcement", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q2EbZWQdpjmnjbX7Y/meetup-mountain-view-reinforcement", "pageUrlRelative": "/posts/Q2EbZWQdpjmnjbX7Y/meetup-mountain-view-reinforcement", "linkUrl": "https://www.lesswrong.com/posts/Q2EbZWQdpjmnjbX7Y/meetup-mountain-view-reinforcement", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Mountain%20View%3A%20Reinforcement&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Mountain%20View%3A%20Reinforcement%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ2EbZWQdpjmnjbX7Y%2Fmeetup-mountain-view-reinforcement%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Mountain%20View%3A%20Reinforcement%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ2EbZWQdpjmnjbX7Y%2Fmeetup-mountain-view-reinforcement", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ2EbZWQdpjmnjbX7Y%2Fmeetup-mountain-view-reinforcement", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 182, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lk'>Mountain View: Reinforcement</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 April 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">167 Jasmine Ct, Mountain View, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I just read Karen Pryor's <em>Don't Shoot the Dog</em>. It's full of things relevant to our interests, like:</p>\n\n<ul>\n<li>how to learn skills and good habits</li>\n<li>how to unlearn unwanted behavior and bad habits</li>\n<li>how to attach behavior to a trigger</li>\n</ul>\n\n<p>and so on. I suspect this is fundamental stuff if you're interested in becoming an excellent human.</p>\n\n<p>I'll basically present the contents of <em>Don't Shoot the Dog</em>, highlighting those points most salient to our interests. I'd love to have a conversation about what it'd look like to take these ideas <em>seriously</em>..</p>\n\n<p>And also, let's play the Training Game, therein described, which sounds silly and enlightening. \"Silly and enlightening\" is my favorite combination. :D</p>\n\n<p>Hope to see you there!</p>\n\n<hr />\n\n<p>If you're in the San Francisco Bay area, consider joining the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/bayarealesswrong\">Bay Area Less Wrong mailing list</a>.\nRegular meetups in Mountain View and Berkeley, and other events, are announced and discussed there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lk'>Mountain View: Reinforcement</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q2EbZWQdpjmnjbX7Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.1691378362695e-06, "legacy": true, "legacyId": "22308", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Mountain_View__Reinforcement\">Discussion article for the meetup : <a href=\"/meetups/lk\">Mountain View: Reinforcement</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 April 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">167 Jasmine Ct, Mountain View, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I just read Karen Pryor's <em>Don't Shoot the Dog</em>. It's full of things relevant to our interests, like:</p>\n\n<ul>\n<li>how to learn skills and good habits</li>\n<li>how to unlearn unwanted behavior and bad habits</li>\n<li>how to attach behavior to a trigger</li>\n</ul>\n\n<p>and so on. I suspect this is fundamental stuff if you're interested in becoming an excellent human.</p>\n\n<p>I'll basically present the contents of <em>Don't Shoot the Dog</em>, highlighting those points most salient to our interests. I'd love to have a conversation about what it'd look like to take these ideas <em>seriously</em>..</p>\n\n<p>And also, let's play the Training Game, therein described, which sounds silly and enlightening. \"Silly and enlightening\" is my favorite combination. :D</p>\n\n<p>Hope to see you there!</p>\n\n<hr>\n\n<p>If you're in the San Francisco Bay area, consider joining the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/bayarealesswrong\">Bay Area Less Wrong mailing list</a>.\nRegular meetups in Mountain View and Berkeley, and other events, are announced and discussed there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Mountain_View__Reinforcement1\">Discussion article for the meetup : <a href=\"/meetups/lk\">Mountain View: Reinforcement</a></h2>", "sections": [{"title": "Discussion article for the meetup : Mountain View: Reinforcement", "anchor": "Discussion_article_for_the_meetup___Mountain_View__Reinforcement", "level": 1}, {"title": "Discussion article for the meetup : Mountain View: Reinforcement", "anchor": "Discussion_article_for_the_meetup___Mountain_View__Reinforcement1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T07:08:06.432Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Mandatory Secret Identities", "slug": "seq-rerun-mandatory-secret-identities", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.811Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iq7wdNZrbLWHMBybn/seq-rerun-mandatory-secret-identities", "pageUrlRelative": "/posts/iq7wdNZrbLWHMBybn/seq-rerun-mandatory-secret-identities", "linkUrl": "https://www.lesswrong.com/posts/iq7wdNZrbLWHMBybn/seq-rerun-mandatory-secret-identities", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Mandatory%20Secret%20Identities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Mandatory%20Secret%20Identities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiq7wdNZrbLWHMBybn%2Fseq-rerun-mandatory-secret-identities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Mandatory%20Secret%20Identities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiq7wdNZrbLWHMBybn%2Fseq-rerun-mandatory-secret-identities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiq7wdNZrbLWHMBybn%2Fseq-rerun-mandatory-secret-identities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 190, "htmlBody": "<p>Today's post, <a href=\"/lw/9c/mandatory_secret_identities/\">Mandatory Secret Identities</a> was originally published on 08 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>This post was not well-received, but the point was to suggest that a student must at some point leave the dojo and test their skills in the real world. The aspiration of an excellent student should not consist primarily of founding their own dojo and having their own students.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h7c/seq_rerun_whiningbased_communities/\">Whining-Based Communities</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iq7wdNZrbLWHMBybn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.1692155616212235e-06, "legacy": true, "legacyId": "22309", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gBewgmzcEiks2XdoQ", "xC8eECrGoGNXsEByo", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T14:56:51.866Z", "modifiedAt": null, "url": null, "title": "Four Tips for Public Speaking", "slug": "four-tips-for-public-speaking", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:06.574Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "palladias", "createdAt": "2012-04-03T13:45:53.766Z", "isAdmin": false, "displayName": "palladias"}, "userId": "Bv2LXWzZf96WGpqJ5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CyYM4DF7XYbKHJ5H7/four-tips-for-public-speaking", "pageUrlRelative": "/posts/CyYM4DF7XYbKHJ5H7/four-tips-for-public-speaking", "linkUrl": "https://www.lesswrong.com/posts/CyYM4DF7XYbKHJ5H7/four-tips-for-public-speaking", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Four%20Tips%20for%20Public%20Speaking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFour%20Tips%20for%20Public%20Speaking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCyYM4DF7XYbKHJ5H7%2Ffour-tips-for-public-speaking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Four%20Tips%20for%20Public%20Speaking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCyYM4DF7XYbKHJ5H7%2Ffour-tips-for-public-speaking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCyYM4DF7XYbKHJ5H7%2Ffour-tips-for-public-speaking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1581, "htmlBody": "<p><em>TL;DR, I offered and promised in the <a href=\"/lw/h6m/post_request_thread/8qp0\">Post Request Thread</a> a guide to the four highest value tips I know for doing public speaking. Here they are, with explanations below:</em></p>\n<ol>\n<li><em><strong>Fortissimo!</strong>&nbsp;Don't apologize for talking</em></li>\n<li><em>Know the first and last line of your comment before you open your mouth</em></li>\n<li><em>Think about speeches/comments as having a narrative arc</em></li>\n<li><em>Look for additional emotional tones to layer on the content</em></li>\n</ol>\n<div><br /></div>\n<div><br /></div>\n<div><strong>My background:</strong>&nbsp;I was a debater in college, but not in the Gatling-gun style of&nbsp;competitive&nbsp;debate. We did philosophical debate, where you only argued for propositions you <em>actually</em> believed. &nbsp;So, style was supposed to make it easier to get interested, but not be <em>too</em>&nbsp;Dark Arts-persuasive. &nbsp;I coached younger members on how to present their speeches and have spent a fair amount of time murderboarding people (helping people prepare for interviews or presentation). &nbsp;</div>\n<div><br /></div>\n<div>I think the tools in this post are useful both for speeches you prepare and polish ahead of time, but also to be better at speaking coherently off the cuff (long and short form). &nbsp;You can check out <a href=\"http://vimeo.com/56932073\">my speaking style here</a>. &nbsp;(I'm not using notes, and I didn't memorize a speech -- I memorized an <em>arc</em>&nbsp;which gave me room to improvise). &nbsp;So, here are the habits that help:</div>\n<div><br /></div>\n<div><br /></div>\n<div><strong>1) <em>Fortissimo! &nbsp;</em>Don't apologize for talking.</strong></div>\n<div><br /></div>\n<div>In E.L. Konigsberg's <em><a href=\"http://www.amazon.com/gp/product/1416957987/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1416957987&amp;linkCode=as2&amp;tag=unequyoked-20\">About the B'nai Bagels</a></em>, the protagonist is preparing for his bar mitzvah and asks his brother for advice on how to sing his Torah portion. &nbsp;After listening to him, his brother has the following feedback:</div>\n<div><br /></div>\n<div>\n<blockquote>\n<div>&ldquo;I have only one word of advice to give you&rdquo;</div>\n<div>&ldquo;Give already&rdquo;</div>\n<div>&ldquo;That word is fortissimo&hellip; it&rsquo;s Italian for <em>loud</em>. &nbsp;When in doubt, shout, that&rsquo;s what I&rsquo;m telling you.&rdquo;</div>\n<div>&ldquo;I should shout? Everyone will hear for sure how bad I am.&rdquo;</div>\n<div>&ldquo;But, my dear brother, if you sing loud and clear, it will be easier on the audience. &nbsp;You&rsquo;re making it doubly hard on them. &nbsp;Hard to listen to and hard to hear.&rdquo;</div>\n</blockquote>\n</div>\n<div><br /></div>\n<div>Not everyone needs to be <em>louder</em>&nbsp;when they speak, but a lot of people who are uncomfortable with public speaking signal that discomfort in posture or vocal tone (a lot of freshman and sophomores had an about-to-cry sounding tension in their voices when they were speaking). &nbsp;If you're apologizing for talking, your audience will assume there's a <em>reason</em>&nbsp;and start to resent it or feel uncomfortable.</div>\n<div><br /></div>\n<div>So, don't apologize for talking. &nbsp;Don't start with disclaimers (\"I'll be fast, I don't want to waste anyone's time\"). &nbsp;And don't apologize with your voice or your body language. &nbsp;You can get specific feedback by taping yourself talking and have a friend watch it with you and have you practice standing taller or speaking a bit more intently. &nbsp;You can pay a theatre grad student to meet with you a couple times about posture of voice projection. &nbsp;You can also just consciously review <em>why</em>&nbsp;you are talking in the first place before you open your mouth, so you remember why your comment is useful and you're giving people a <em>gift</em>&nbsp;by talking, not being an <em>imposition</em>.</div>\n<div><br /></div>\n<div><br /></div>\n<div><strong>2) Know the first and last line of your comment before you open your mouth</strong></div>\n<div><br /></div>\n<div>It's pretty obvious why you want to know the first line of your speech/answer/whatever before you start talking; you don't want an awkward lag or a spot where you might panic. &nbsp;But most people don't plan their conclusion ahead of time (totally neglecting the <a href=\"http://en.wikipedia.org/wiki/Peak%E2%80%93end_rule\">peak-end rule</a>!).</div>\n<div><br /></div>\n<div>I hear a lot of novice speakers start strong, and then kind of peter out at the end of their response. &nbsp;Sometimes people will just trail off, hoping someone else will pick up the slack. &nbsp;Sometimes people have essentially already given their closing thought, but not noticed, and then they end up repeating it awkwardly.</div>\n<div><br /></div>\n<div>If you know what your closing image/sentence/line/etc is when you <em>start</em>&nbsp;talking, you know what you're aiming at from the beginning, so you won't get diverted as easily. &nbsp;You've removed one common cause of failure/panic in speaking, so you can speak more confidently in the first place. &nbsp;And your point will be more memorable/easier to engage with if you have a strong conclusion.</div>\n<div><br /></div>\n<div><br /></div>\n<div><strong>3) Think about speeches/comments as having a narrative arc</strong></div>\n<div><br /></div>\n<div>So that's the opening and the closing of the talk, but what goes in the middle? &nbsp;In English class, you probably leaned this model:</div>\n<div>\n<ul>\n<li>Thesis</li>\n<li>Evidence 1</li>\n<li>Evidence 2</li>\n<li>Evidence 3&nbsp;</li>\n<li>Thesis restated</li>\n</ul>\n</div>\n<div>This is terribly boring and difficult for people to retain. &nbsp;It's a lot more fun and memorable if you can put things in the framework of a story. &nbsp;Here's one formula for creating a narrative structure from <a href=\"http://misssnark.blogspot.com/\">Miss Snark</a>:</div>\n<div>\n<blockquote>\n<div>X is the main guy; he wants to do:</div>\n<div>Y is the bad guy; he wants to do:</div>\n<div>they meet at Z and all L breaks loose.</div>\n<div>If they don&rsquo;t resolve Q, then R starts and if they do it&rsquo;s L squared.</div>\n</blockquote>\n</div>\n<div><br /></div>\n<div>When I'm teaching class, I tend to use one that's more like:</div>\n<blockquote>\n<div>Ever notice how you always X when you'd really like to Y? &nbsp;So did I! &nbsp;I tried Z and it turned out to work, but I wasn't sure why! &nbsp;I poked around in the literature and found A,B, and C, which caused me to tweak my solution to Z' and now I Y all the time, and you can too!</div>\n</blockquote>\n<div><br /></div>\n<div>Basically, instead of just having a point and supporting data, you take your audience through a couple emotional arcs. &nbsp;It's easier to remember stories than just data. &nbsp;It's also more fun for your listeners to repeat, so they'll get to share your idea with others. &nbsp;It helps you stay away from a monotone or totally even affect while speaking (more in the next tip) and keeps the structure of your comment really clear in your own head.</div>\n<div><br /></div>\n<div>Planning plot summaries of my speeches means I don't need to carry notes or memorize lines, anymore than I <em>recite</em>&nbsp;funny stories I share with friends. &nbsp;I can just remember the outline of the story and then expand or contract individual parts depending on what the audience responds to. &nbsp;The structure gives me a safety net. &nbsp;This way, I'm not <em>unsure</em>&nbsp;what I'm saying when I open my mouth, but I'm not stuck saying specific lines.</div>\n<div><br /></div>\n<div><br /></div>\n<div><strong>4) Look for additional emotional tones to layer on the content</strong></div>\n<div><br /></div>\n<div>It's boring to just listen to someone explain facts. &nbsp;Having a narrative arc (as above) will automatically inject some variance into your tone and affect. &nbsp;In my teaching example above, the emotional notes look something like this:</div>\n<blockquote>\n<p><em style=\"font-weight: bold;\">Frustration: </em>[Ever notice how you always X when you'd really like to Y?] &nbsp;<strong><em>Shared identity, all of us looking at the frustration together:&nbsp;</em></strong>[So did I!] &nbsp;I tried Z and it turned out to work, but <strong><em>pleased but perplexed:</em></strong>&nbsp;[I wasn't sure why!] &nbsp;I poked around in the literature and <strong><em>surprise, but increasing feeling of catharsis:</em></strong>&nbsp;[found A,B, and C, which caused me to tweak my solution to Z'] and <strong><em>triumph:</em></strong>&nbsp;[now I Y all the time], <strong><em>return of fellow feeling and pleasure at sharing something cool:</em></strong>&nbsp;[and you can too!]</p>\n</blockquote>\n<p>But there's more you can add. &nbsp;One friend of mine was explaining a counterintuitive study in a fairly matter of fact way, but it was a lot more enjoyable and memorable to hear about if she shared her surprise at how it turned out. &nbsp;A lot of the time, it's simplest to just make sure you're letting your honest reactions to what you're saying come across.</p>\n<p>But, if you're not sure what those are, or want to explore other options, you can try dividing what you're saying into beats. &nbsp;(Beats is a phrase used in theatre for subdivisions within scenes. &nbsp;In one conversation or story, the dominant emotional tone can change, and that transition is the start of a new beat). &nbsp;So, try dividing up your notes or your outline into sections and just experiment with the dominant tone for the section. &nbsp;Here's a reworking of the emotional beats in my teaching outline:</p>\n<blockquote>\n<p><em style=\"font-weight: bold;\">Sadness, regret:&nbsp;</em>[Ever notice how you always X when you'd really like to Y?] &nbsp;<strong><em>Shame shared as&nbsp;vulnerability:&nbsp;</em></strong>[So did I!] &nbsp;I tried Z and it turned out to work, but&nbsp;<strong><em>tentative, a little uncertain:</em></strong>&nbsp;[I wasn't sure why!] &nbsp;I poked around in the literature and&nbsp;<strong><em>feeling of tinkering and assembly:</em></strong>&nbsp;[found A,B, and C, which caused me to tweak my solution to Z'] and&nbsp;<strong><em>peace, tranquility:</em></strong>&nbsp;[now I Y all the time],&nbsp;<strong><em>warmth, joy:</em></strong>&nbsp;[and you can too!]</p>\n</blockquote>\n<p>Try looking at <a href=\"https://docs.google.com/file/d/0B0EaYuW_Hh07amRlUFY5aU5pb3c/edit?usp=sharing\">this list of some possible emotional tones</a>, and see what it's like when you using them as you talk through your outline. &nbsp;Try reading <em>wrong</em>&nbsp;tones to a friend, to notice why they're wrong or to catch yourself if you were unnecessarily restricting your options. &nbsp;Sometimes tone can change a number of times in one passage (as in <a href=\"https://docs.google.com/file/d/0B0EaYuW_Hh07NWE2czVkcVR3Tjg/edit?usp=sharing\">this marked up example</a>), just pay attention to what prompts the shift. &nbsp;You can try picking a speech or a sentence that already exists, and reading it deliberately with <em>different </em>tones each time to get some practise and comfort using them.</p>\n<p>&nbsp;</p>\n<p>So, if you work on these tips, people will be more comfortable listening to what you say (1), you'll open and close strongly (2), with a narrative arc that keeps you on track and makes your points memorable (3), and enough emotional variation to keep your audience engaged with you and your content (4). &nbsp;Huzzah!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CyYM4DF7XYbKHJ5H7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 55, "extendedScore": null, "score": 0.000127, "legacy": true, "legacyId": "22291", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 55, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T17:41:04.629Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, April 15-29", "slug": "group-rationality-diary-april-15-29", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:08.273Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Rb7KN7bQKJ8WetbLF/group-rationality-diary-april-15-29", "pageUrlRelative": "/posts/Rb7KN7bQKJ8WetbLF/group-rationality-diary-april-15-29", "linkUrl": "https://www.lesswrong.com/posts/Rb7KN7bQKJ8WetbLF/group-rationality-diary-april-15-29", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20April%2015-29&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20April%2015-29%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRb7KN7bQKJ8WetbLF%2Fgroup-rationality-diary-april-15-29%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20April%2015-29%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRb7KN7bQKJ8WetbLF%2Fgroup-rationality-diary-april-15-29", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRb7KN7bQKJ8WetbLF%2Fgroup-rationality-diary-april-15-29", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">T<span style=\"color: #333333;\">his is the public group instrumental rationality diary for April 15-29. &nbsp;</span></p>\n<blockquote style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\"><span style=\"color: #333333;\">It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/cata/\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating!</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/lw/hbx/group_rationality_diary_may_115/\">Next diary</a>:&nbsp; May 1-15<a href=\"/lw/hbx/group_rationality_diary_may_115/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/r/discussion/lw/h52/group_rationality_diary_april_514/\">Immediate past diary</a>:&nbsp; April 5-14<a href=\"/r/discussion/lw/h52/group_rationality_diary_april_514/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality Diaries archive</a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Rb7KN7bQKJ8WetbLF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 1.1696541486439739e-06, "legacy": true, "legacyId": "22312", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wdCpjFTirD6JRiZXc", "86ZaKtcLNfFmM8qQ3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T19:57:51.597Z", "modifiedAt": null, "url": null, "title": "Open Thread, April 15-30, 2013 ", "slug": "open-thread-april-15-30-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:41.151Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QM9Sr7jqAH9E6Wsvb/open-thread-april-15-30-2013", "pageUrlRelative": "/posts/QM9Sr7jqAH9E6Wsvb/open-thread-april-15-30-2013", "linkUrl": "https://www.lesswrong.com/posts/QM9Sr7jqAH9E6Wsvb/open-thread-april-15-30-2013", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20April%2015-30%2C%202013%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20April%2015-30%2C%202013%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQM9Sr7jqAH9E6Wsvb%2Fopen-thread-april-15-30-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20April%2015-30%2C%202013%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQM9Sr7jqAH9E6Wsvb%2Fopen-thread-april-15-30-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQM9Sr7jqAH9E6Wsvb%2Fopen-thread-april-15-30-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QM9Sr7jqAH9E6Wsvb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 1.1697489641400014e-06, "legacy": true, "legacyId": "22311", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 467, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T19:59:13.969Z", "modifiedAt": null, "url": null, "title": "Help us name the Sequences ebook", "slug": "help-us-name-the-sequences-ebook", "viewCount": null, "lastCommentedAt": "2017-06-17T04:25:33.933Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Hmc2NE6oTipCvuZdN/help-us-name-the-sequences-ebook", "pageUrlRelative": "/posts/Hmc2NE6oTipCvuZdN/help-us-name-the-sequences-ebook", "linkUrl": "https://www.lesswrong.com/posts/Hmc2NE6oTipCvuZdN/help-us-name-the-sequences-ebook", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Help%20us%20name%20the%20Sequences%20ebook&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelp%20us%20name%20the%20Sequences%20ebook%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHmc2NE6oTipCvuZdN%2Fhelp-us-name-the-sequences-ebook%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Help%20us%20name%20the%20Sequences%20ebook%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHmc2NE6oTipCvuZdN%2Fhelp-us-name-the-sequences-ebook", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHmc2NE6oTipCvuZdN%2Fhelp-us-name-the-sequences-ebook", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 135, "htmlBody": "<p>&nbsp;</p>\n<p><em><a href=\"http://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565/\">Quantum Computing Since Democritus</a></em> got me thinking that we may want a more riveting title for <em>The Sequences, 2006-2009</em> ebook we're preparing for release (like the&nbsp;<a href=\"http://intelligenceexplosion.com/ebook/\">FtIE ebook</a>). Maybe it could be something like <em>[Really Catchy Title]: The Less Wrong Sequences, 2006-2009</em>.</p>\n<p>The reason for \"2006&ndash;2009\" is that <a href=\"http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners\">Highly Advanced Epistemology 101 for Beginners</a> will be its own ebook, and future Yudkowskian LW sequences (if there are any) won't be included either.</p>\n<p>&nbsp;</p>\n<p>Example options:</p>\n<p>&nbsp;</p>\n<ul>\n<li><em>The Craft of Rationality: The Less Wrong Sequences, 2006&ndash;2009</em></li>\n<li><em>The Art of Rationality: The Less Wrong Sequences, 2006&ndash;2009</em></li>\n<li><em>Becoming Less Wrong: The Sequences, 2006&ndash;2009</em></li>\n</ul>\n<div><br /></div>\n<div>In the end, we <em>might</em>&nbsp;just call it <em>The Sequences, 2006&ndash;2009</em>, but I'd like to check whether somebody else can come up with a better name.</div>\n<div><br /></div>\n<div>Suggestions?</div>\n<div><br /></div>\n<div>(Update on 5/5/2013 is <a href=\"/lw/h7t/help_us_name_the_sequences_ebook/8x0f\">here</a>.)</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JMD7LTXTisBzGAfhX": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Hmc2NE6oTipCvuZdN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 22, "extendedScore": null, "score": 1.1697499158338458e-06, "legacy": true, "legacyId": "22313", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 149, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T21:11:23.039Z", "modifiedAt": null, "url": null, "title": "Parable of the Two Pandemics, OR Might We Be Mimicing the Wrong Memeplexes?", "slug": "parable-of-the-two-pandemics-or-might-we-be-mimicing-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:56.072Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Armok_GoB", "createdAt": "2010-04-17T10:02:06.399Z", "isAdmin": false, "displayName": "Armok_GoB"}, "userId": "7ndq2gZSo6zJELxAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NWbbR6SRsXFfnSn2f/parable-of-the-two-pandemics-or-might-we-be-mimicing-the", "pageUrlRelative": "/posts/NWbbR6SRsXFfnSn2f/parable-of-the-two-pandemics-or-might-we-be-mimicing-the", "linkUrl": "https://www.lesswrong.com/posts/NWbbR6SRsXFfnSn2f/parable-of-the-two-pandemics-or-might-we-be-mimicing-the", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Parable%20of%20the%20Two%20Pandemics%2C%20OR%20Might%20We%20Be%20Mimicing%20the%20Wrong%20Memeplexes%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AParable%20of%20the%20Two%20Pandemics%2C%20OR%20Might%20We%20Be%20Mimicing%20the%20Wrong%20Memeplexes%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNWbbR6SRsXFfnSn2f%2Fparable-of-the-two-pandemics-or-might-we-be-mimicing-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Parable%20of%20the%20Two%20Pandemics%2C%20OR%20Might%20We%20Be%20Mimicing%20the%20Wrong%20Memeplexes%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNWbbR6SRsXFfnSn2f%2Fparable-of-the-two-pandemics-or-might-we-be-mimicing-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNWbbR6SRsXFfnSn2f%2Fparable-of-the-two-pandemics-or-might-we-be-mimicing-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 182, "htmlBody": "<p>There was once two unfriendly microbiologists, who wished to maximize their exclusive genetic fitness.</p>\n<p><br />The first biologist collected all the worst pandemics of mankind, combined them, reduced their lethality and added the module to inseminate infected females with a copy of his genome. The virus spread rapidly, and hundreds of his children were born, but with time vaccines were developed for the pandemics and, through their similarity, the virus was soon defeated.</p>\n<p><br />The other biologist took samples of skin and blood, sequenced genomes, and found out which traces of foreign DNA were truly the most common amongst all humans. Finally he chose one virus, barely known, nigh impossible to track down or study, and modified it to inject his DNA in parallel with that of the infected, rigged up include the copy of hers as well as the virus during meiosis. Generations later, humanity created an AI to tile the universe with the genome they all shared.</p>\n<p>&nbsp;</p>\n<p>(EDIT: I do not necessarily endorse the obvius moral of the story, it's MOSTLY a story, with rising discussion as a nice possible bonus.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NWbbR6SRsXFfnSn2f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -19, "extendedScore": null, "score": -1.3e-05, "legacy": true, "legacyId": "22314", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-15T22:09:43.347Z", "modifiedAt": null, "url": null, "title": "The real difference between Reductionism and Emergentism", "slug": "the-real-difference-between-reductionism-and-emergentism", "viewCount": null, "lastCommentedAt": "2020-05-07T17:46:01.478Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RogerS", "createdAt": "2013-02-27T17:28:11.625Z", "isAdmin": false, "displayName": "RogerS"}, "userId": "xCQ7jDkbR33hGqyBq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wewdE655v7ibvw4zM/the-real-difference-between-reductionism-and-emergentism", "pageUrlRelative": "/posts/wewdE655v7ibvw4zM/the-real-difference-between-reductionism-and-emergentism", "linkUrl": "https://www.lesswrong.com/posts/wewdE655v7ibvw4zM/the-real-difference-between-reductionism-and-emergentism", "postedAtFormatted": "Monday, April 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20real%20difference%20between%20Reductionism%20and%20Emergentism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20real%20difference%20between%20Reductionism%20and%20Emergentism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwewdE655v7ibvw4zM%2Fthe-real-difference-between-reductionism-and-emergentism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20real%20difference%20between%20Reductionism%20and%20Emergentism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwewdE655v7ibvw4zM%2Fthe-real-difference-between-reductionism-and-emergentism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwewdE655v7ibvw4zM%2Fthe-real-difference-between-reductionism-and-emergentism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1160, "htmlBody": "<p>After trying to discover why the LW wiki &ldquo;definition&rdquo; of Reductionism appeared so <a href=\"/r/discussion/lw/h2w/removing_bias_from_the_definition_of_reductionism/\">biased</a>, I concluded from the responses that it was never really intended as a definition of the Reductionist position itself, but as a summary of what is considered to be wrong with positions critical of Reductionism.</p>\n<p>The argument goes like this. &ldquo;Emergentism&rdquo;, as the critical view is often called, points out the properties that <em>emerge</em> from a system when it is assembled from its elements, which do not themselves show such a property. From such considerations it points out various ways in which research programmes based on a reductionist approach may distort priorities and underestimate difficulties. So far, this is all a matter of degree and eventually each case must be settled on its merits. However, it gets philosophically sensitive when Emergentists claim that a Reductionist approach may be unable <em>in principle</em> to 'explain' certain emergent properties.</p>\n<p>The reponse to this claim (I think) goes like this. (1) The explanatory power of a model is a function of its ingredients. (2) Reductionism includes all the ingredients that actually exist in the real world. Therefore (3) Emergentists must be treating the &ldquo;emergent properties&rdquo; as extra ingredients, thereby confusing the &ldquo;map&rdquo; with the &ldquo;territory&rdquo;. So Reductionism is defined by EY and others as not treating emergent properties as extra ingredients (in effect).</p>\n<p>At this point it is important to distinguish &ldquo;Mind theory&rdquo; from other fields where Reductionism is debated. In this field, Reductionists apparently regard Emergentism as a form of disguised Vitalism/Dualism - if emergent properties can&rsquo;t be explained by the physical ingredients, they must exist in some non-physical realm. However, Emergentism can apply equally well to everything from chess playing programs to gearbox vibrations, neither of which involve anything like mysterious spiritual substances, so this can hardly be the whole story. And in fact I would argue that the reverse is the case: Vitalists or &ldquo;substance Dualists&rdquo; are actually unconscious Reductionists as well: when they assume an extra <em>ingredient</em> is necessary to account for the things which they believe Physicalism cannot explain, they are still reducing a system to its ingredients. Emergentists by contrast reject premise (1) of the previous paragraph, that the explanatory power of a model is a function of its ingredients. Thus it seems to me that the real difference between Reductionists &amp; Emergentists is a difference over the nature of explanation. So it seems worthwhile looking into some of the different things that can be meant by &ldquo;explanation&rdquo;.</p>\n<p>For simplicity, let us illustrate this by the banal example of a brickwork bridge. The elements are the bricks and their relative positions. Our reductionist R points out that these are the only elements you need - after all, if you remove all the bricks there is nothing left - and so proposes to become an expert in bricks. Our (Physicalist) Emergentist E suggests that this won&rsquo;t be of much use without a knowledge of the Arch (an emergent feature). R isn't stupid and agrees that this would be extremely <em>useful</em> but points out that if no expert in Arch Theory is to hand, given the very powerful computer available, such expertise isn&rsquo;t strictly <em>necessary</em>: it's not an <em>inherent</em> requirement. Simply solving the force balance equations for each brick will establish whether a given structure will fall into the river. Isn&rsquo;t that an explanation?</p>\n<p>Not in my sense, says E, as to start with it doesn&rsquo;t tell me how the bridge will be <em>designed</em>, only how an existing design will be analysed. So R explains that the computer will generate structures randomly until one is found that satisfies the requirements of equilibrium. When E enquires how stability will be checked. R replies that the force balance will be checked under all possible small deviations from the design position.</p>\n<p>E isn&rsquo;t satisfied. To claim <em>understanding</em>, R must be able to apply the results of the first design to new bridges of different span, but all (s)he can do is repeat the process again every time.</p>\n<p>On the contrary, replies R, this being the age of Big Data, the computer can generate solutions in a large number of cases and then use pattern recognition software to extract rules that can be applied to new cases.</p>\n<p>Ah, says E, but <em>explaining</em> these rules means hypothesing more general rules from which these rules can be derived, using appropriate Bayesian reasoning to confirm your hypothesis.</p>\n<p>OK, replies R, my program has a heuristic feature that has passed the Turing Test. So anything you can do along these lines, it can do just as well.</p>\n<p>So using R&rsquo;s approach, explanation even in E&rsquo;s most general sense can always be arrived at by a four-stage process: (1) construct a model using the basic elements applicable to the situation, (2) fill a substantial chunk of solution space, (3) use pattern recognition to extract pragmatic rules, (4) use hypothesis generation and testing to derive general principles from the rules. It may be a trivial illustration, but it seems to me that in a broad sense this sort of process must be applicable in almost any situation.</p>\n<p>How should we interpret this conclusion? R would say that it proves that &ldquo;explanation&rdquo; can be arrived it using a Reductionist model. E would say it proves the inadequacy of Reductionism, since Reductionist steps (1) &amp; (2) have to be supplemented by Integrationist steps (3) &amp; (4): the rules found at step (3) are precisely &ldquo;emergent features&rdquo; of the solution space. Moreover, pattern recognition is not a closed-form process with repeatable results. (Is it?) On the other hand the patterns identified in solution space might well be derivable in closed form directly from higher-level characteristics of the system in question (such as constraints in the system).</p>\n<p>I would say that the choice of interpretation is a matter of convention, though I own up that I find the Emergentist mind-set more helpful in the fields I have learnt something about. What really matters is a recognition of the huge difference between &ldquo;providing a solution&rdquo; and &ldquo;generalising from solution space&rdquo; as types of explanation. The &ldquo;Emergentist&rdquo; label is a reminder of that difference. But call yourself a &ldquo;Reductionist&rdquo; if you like so long as you acknowledge the difference.</p>\n<p>It seems to me that the sort of argument sketched here provides useful pointers to help recognize when &ldquo;Reductionism&rdquo; becomes &ldquo;Greedy Reductionism&rdquo;(A). For example, consider the claim that mapping the Human Connectome will enable the workings of the brain to be explained. Clearly, the mapping is just step (1). Consider the size of the Connectome, and then consider the size of the solution space of its activity. That makes step (1) sound utterly trivial compared with step (2). This leaves the magnitude of steps (3) &amp; (4) to be evaluated. That doesn&rsquo;t mean the project won&rsquo;t be extremely valuable, but it puts the time-frame of the claim to provide real &ldquo;understanding&rdquo; into a very different light, and underlines the continued value of working at other scales as well.</p>\n<p>(A): See e.g. <a href=\"/user/fubarobfusco/\">fubarobfusco</a>'s comment on my <a href=\"/r/discussion/lw/h2w/removing_bias_from_the_definition_of_reductionism/\">earlier discussion</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wewdE655v7ibvw4zM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 1, "extendedScore": null, "score": 2e-06, "legacy": true, "legacyId": "22303", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vkF45fWgauackWQLF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-16T06:30:20.605Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Beware of Other-Optimizing", "slug": "seq-rerun-beware-of-other-optimizing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.675Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kHsExYq6opRaNRzu7/seq-rerun-beware-of-other-optimizing", "pageUrlRelative": "/posts/kHsExYq6opRaNRzu7/seq-rerun-beware-of-other-optimizing", "linkUrl": "https://www.lesswrong.com/posts/kHsExYq6opRaNRzu7/seq-rerun-beware-of-other-optimizing", "postedAtFormatted": "Tuesday, April 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Beware%20of%20Other-Optimizing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Beware%20of%20Other-Optimizing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkHsExYq6opRaNRzu7%2Fseq-rerun-beware-of-other-optimizing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Beware%20of%20Other-Optimizing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkHsExYq6opRaNRzu7%2Fseq-rerun-beware-of-other-optimizing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkHsExYq6opRaNRzu7%2Fseq-rerun-beware-of-other-optimizing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 243, "htmlBody": "<p>Today's post, <a href=\"/lw/9v/beware_of_otheroptimizing/\">Beware of Other-Optimizing</a> was originally published on 10 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Aspiring rationalists often vastly overestimate their own ability to optimize other people's lives. They read nineteen webpages offering productivity advice that doesn't work for them... and then encounter the twentieth page, or invent a new method themselves, and wow, it really works - they've discovered the true method. Actually, they've just discovered the one method in twenty that works for them, and their confident advice is no better than randomly selecting one of the twenty blog posts. Other-Optimizing is exceptionally dangerous when you have power over the other person - for then you'll just believe that they aren't trying hard enough.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h7p/seq_rerun_mandatory_secret_identities/\">Mandatory Secret Identities</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kHsExYq6opRaNRzu7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 1.1701875677229154e-06, "legacy": true, "legacyId": "22319", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6NvbSwuSAooQxxf7f", "iq7wdNZrbLWHMBybn", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-16T07:23:13.411Z", "modifiedAt": null, "url": null, "title": "Time turners, Energy Conservation and General Relativity", "slug": "time-turners-energy-conservation-and-general-relativity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:32.479Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RaAPeFxCkvsuqjvJq/time-turners-energy-conservation-and-general-relativity", "pageUrlRelative": "/posts/RaAPeFxCkvsuqjvJq/time-turners-energy-conservation-and-general-relativity", "linkUrl": "https://www.lesswrong.com/posts/RaAPeFxCkvsuqjvJq/time-turners-energy-conservation-and-general-relativity", "postedAtFormatted": "Tuesday, April 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Time%20turners%2C%20Energy%20Conservation%20and%20General%20Relativity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATime%20turners%2C%20Energy%20Conservation%20and%20General%20Relativity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRaAPeFxCkvsuqjvJq%2Ftime-turners-energy-conservation-and-general-relativity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Time%20turners%2C%20Energy%20Conservation%20and%20General%20Relativity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRaAPeFxCkvsuqjvJq%2Ftime-turners-energy-conservation-and-general-relativity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRaAPeFxCkvsuqjvJq%2Ftime-turners-energy-conservation-and-general-relativity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1185, "htmlBody": "<p>This post is a bit of entertainment for scientifically inclined Harry Potter fans.</p>\n<p>Time turner from the Harry Potter series (and from the Eliezer Yudkowsky's venerable HPMoR fanfic) is a very useful device if you have some unfinished business in the recent past, like attending an extra class or saving a friend from a certain death. However, General Relativity has a few words to say about them, and they are not very flattering. I will only address one issue here: Energy conservation. TL;DR: if you use a time turner to vanish into the past, those around you will see you blown to tiny bits of Merlin-knows-what, quickly disappearing from view. When you appear in the past, this explosion appears in reverse.</p>\n<p>Before we get to the time turners, however, let us consider an aside.</p>\n<p>Let us start with a common question: if the Sun stop shining this instant, when would we notice? The common answer: it takes light 8.5 minutes to travel the distance of 150,000,000 km between the Sun and the Earth, so that's how long it will take. This glosses over the issue of what does \"this instant\" mean exactly at two different points in space, which is not so trivial given the relativity of simultaneity in Special Relativity. It is easily patched up, however, once we fix a global frame of reference. The Cosmic Microwave Background (CMB) is a natural one to use, and both the Earth and the Sun travel with a negligible fraction of the speed of light relative to the CMB. Anyway, the answer is still very close to 8.5 min.</p>\n<p>Now another, deceptively similar question: if the Sun disappears this instant, how long before the Earth will stop orbiting the point where it used to be? The common answer: gravity travels with the speed of light, so also 8.5 min. This answer is obvious, simple and wrong. Yes, dead wrong. Why? because static gravity is not like light, it's more like electric field, only worse.</p>\n<p>Let's first think of how you would make the Sun disappear. Maybe it turned into a black hole? Well, this would not really mean disappearance of gravity, the mass of the black hole will still be that of the Sun, and the Earth will happily (or unhappily, as the case may be) continue orbiting the Sun's corpse. So, in this case the answer is \"it won't stop orbiting\".</p>\n<p>OK, so black hole was a bad example. How about a wormhole instead? You know, the evil Vogon-like aliens need to clear the room for a hyperspace bypass, and they build a wormhole from far away and suck all the matter in the Sun through it out of the way. What would happen then? There are a couple of hints: one is that from outside a wormhole is indistinguishable from a black hole, and the other is the Gauss Law. Both hints lead one to the same answer: just like with turning the Sun into a black hole, there is very little gravitational effect on the surrounding space. The rest of the now ex-Solar system will continue merrily on its way around the point where our Sun used to be.</p>\n<p>An aside for those curious about the Gauss Law argument. The law in its integral form states that the flux of the gravitational field inward through any closed surface encompassing the Sun is proportional to the Sun's mass. To change the field, you need to remove some mass from inside this imaginary surface, by having it <strong>physically cross the surface</strong>. This last point may not be obvious, but it follows from General Relativity. Specifically, the Einstein's most misunderstood theory says that the spacetime curvature is determined by the (past and present) distribution of matter in spacetime. There are some exceptions, like the fixed-mass spherical objects, such as black holes and wormholes, which contains no matter, and gravitational radiation, which can carry away energy. But if you take a spherical object like the Sun and try to calculate what happens if you decrease its mass, General Relativity tells you that this mass has gone outward from the Sun in all directions in some form. It is not fussy about the form, as long as just the right amount of mass/energy has gone out.</p>\n<p>Let me repeat for those who skipped the above paragraph: if you take the Sun and decrease its mass, the only way it can happen if this mass leaves the Sun outward and disappears into space. This happens all the time, of course, the Sun constantly loses its mass through radiation and solar wind, or in more drastic cases through Supernova explosions. Effects like this propagate no faster than light, of course. So they take forever to propagate all the way to infinity.</p>\n<p>Now, back to the time turners. Hermione Granger might be but a small if incredibly studious girl, but she still has mass. If you were to peek at her using a time turner and disappear, her mass, small though it may be, still has to go some place, just like the disappearing Sun's mass had to go some place. The options are few: she can blow into tiny pieces flying past you, or disappear in a flash of brilliant light (and it takes a lot of light to carry away 50kg, what's with E=mc^2) . Basically, it will not be a pretty sight. What cannot happen is her simply vanishing, with no ill effects whatsoever. Well, it cannot happen if we are willing to keep Relativity around. Maybe we don't have to, what's with a certain deputy mistress turning into a cat and back, probably instantly changing her mass, with no ill effects on her or her surroundings. But if you give up on General Relativity, quite a few things will unravel, like all four Newton's laws.</p>\n<p>Also don't forget the other side of the time turner action: Hermione appearing out of thin air just before walking into her extra class. The above process has to happen in reverse: an amount of matter equivalent to her mass has to travel inwards out of nowhere and coalesce into a person. Where did this matter come from? How did it form before collapsing into a person? How did it know that it would need to time its arrival into a certain point perfectly with whatever time turner will have been set to? That's some hard-core magic right there. Also, suck it, the Second law of Thermodynamics.</p>\n<p>So, let me summarize: mass cannot just disappear, it has to spread out. mass cannot just appear, it has to coalesce. Thus time turners cannot be used inconspicuously, everyone around would be well aware of one's use, assuming they survive it. Actually, it probably cannot be used at all without breaking General Relativity and/or Thermodynamics. But hey, that's what magic is for.</p>\n<p>EDIT: this post currently sits at -2 karma with 6 downvotes. I'd appreciate if any of the people who thought \"I want less of this\" explicate their logic to me, so I can do better next time.</p>\n<p>EDIT2: OK, no one replied to my request... I'm guessing that some of you guys just quietly hate me :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RaAPeFxCkvsuqjvJq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 11, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "22320", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 169, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-16T13:56:51.113Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne Social Meetup", "slug": "meetup-melbourne-social-meetup-7", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:59.730Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Maelin", "createdAt": "2009-05-28T03:32:36.549Z", "isAdmin": false, "displayName": "Maelin"}, "userId": "CE5vuYfsSRTeG2KWd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GXMFxLrvqreqah9yS/meetup-melbourne-social-meetup-7", "pageUrlRelative": "/posts/GXMFxLrvqreqah9yS/meetup-melbourne-social-meetup-7", "linkUrl": "https://www.lesswrong.com/posts/GXMFxLrvqreqah9yS/meetup-melbourne-social-meetup-7", "postedAtFormatted": "Tuesday, April 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20Social%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20Social%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGXMFxLrvqreqah9yS%2Fmeetup-melbourne-social-meetup-7%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20Social%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGXMFxLrvqreqah9yS%2Fmeetup-melbourne-social-meetup-7", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGXMFxLrvqreqah9yS%2Fmeetup-melbourne-social-meetup-7", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 156, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ll'>Melbourne Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">19 April 2013 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Carlton, Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next regular social meetup will be held on Friday 15th March at our usual venue (Ben's house) in Carlton. All are welcome from 6:30pm.</p>\n\n<p>Our social meetups are informal events held on the third Friday of each month, where we lounge about playing boardgames and chatting, with occasional group parlour games such as Mafia/Werewolf, Resistance, or Zendo if people are interested. If you haven't been to a Melbourne meetup before/recently, the social meetup can be an unintimidating way to meet us as it's very informal and relaxed.</p>\n\n<p>Some snacks will be provided and we'll probably arrange some form of delivered food for dinner. BYO drinks and games.</p>\n\n<p>For the address or any other questions, please see the Melbourne Less Wrong google group, or feel free to SMS me (Richard) on 0421 231 789.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ll'>Melbourne Social Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GXMFxLrvqreqah9yS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1704973798771195e-06, "legacy": true, "legacyId": "22323", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Social_Meetup\">Discussion article for the meetup : <a href=\"/meetups/ll\">Melbourne Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">19 April 2013 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Carlton, Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next regular social meetup will be held on Friday 15th March at our usual venue (Ben's house) in Carlton. All are welcome from 6:30pm.</p>\n\n<p>Our social meetups are informal events held on the third Friday of each month, where we lounge about playing boardgames and chatting, with occasional group parlour games such as Mafia/Werewolf, Resistance, or Zendo if people are interested. If you haven't been to a Melbourne meetup before/recently, the social meetup can be an unintimidating way to meet us as it's very informal and relaxed.</p>\n\n<p>Some snacks will be provided and we'll probably arrange some form of delivered food for dinner. BYO drinks and games.</p>\n\n<p>For the address or any other questions, please see the Melbourne Less Wrong google group, or feel free to SMS me (Richard) on 0421 231 789.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Social_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/ll\">Melbourne Social Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne Social Meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_Social_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne Social Meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_Social_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "10 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-16T14:57:12.629Z", "modifiedAt": null, "url": null, "title": "Meetup : Vancouver CFAR Materials: Bayes practice!", "slug": "meetup-vancouver-cfar-materials-bayes-practice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:56.657Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R4XcseJ7aXbv8mdMt/meetup-vancouver-cfar-materials-bayes-practice", "pageUrlRelative": "/posts/R4XcseJ7aXbv8mdMt/meetup-vancouver-cfar-materials-bayes-practice", "linkUrl": "https://www.lesswrong.com/posts/R4XcseJ7aXbv8mdMt/meetup-vancouver-cfar-materials-bayes-practice", "postedAtFormatted": "Tuesday, April 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vancouver%20CFAR%20Materials%3A%20Bayes%20practice!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vancouver%20CFAR%20Materials%3A%20Bayes%20practice!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4XcseJ7aXbv8mdMt%2Fmeetup-vancouver-cfar-materials-bayes-practice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vancouver%20CFAR%20Materials%3A%20Bayes%20practice!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4XcseJ7aXbv8mdMt%2Fmeetup-vancouver-cfar-materials-bayes-practice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4XcseJ7aXbv8mdMt%2Fmeetup-vancouver-cfar-materials-bayes-practice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 184, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lm'>Vancouver CFAR Materials: Bayes practice!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 April 2013 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2505 W broadway, vancouver</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>CFAR's core materials have become organized to the point of being print-out-and-teachable, so I'm going to print out their book and practice from it. I encourage you to do this with me; it will be valuable and at least a little bit fun.</p>\n\n<p>The first unit, besides preamble and and such about rationality checklist, scavenger hunt, and the prediction \"markets\" game, is a collection of Bayesian exercises to teach the basics of applying probability theory.</p>\n\n<p>There's two sets of quantitative word problems, and some qualitative analysis problems. It should take us a couple hours to work through it all.</p>\n\n<p>I'll be doing this at Benny's Bagels in Kitsilano, starting at 15:00 on Saturday. This will probably be an ongoing thing; every week until we are done, which is like 24 weeks at about one unit per week. We can probably compress that, but Wow.</p>\n\n<p>See our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a> for reminders about future meetups and such.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lm'>Vancouver CFAR Materials: Bayes practice!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R4XcseJ7aXbv8mdMt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.170539271120465e-06, "legacy": true, "legacyId": "22324", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vancouver_CFAR_Materials__Bayes_practice_\">Discussion article for the meetup : <a href=\"/meetups/lm\">Vancouver CFAR Materials: Bayes practice!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 April 2013 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2505 W broadway, vancouver</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>CFAR's core materials have become organized to the point of being print-out-and-teachable, so I'm going to print out their book and practice from it. I encourage you to do this with me; it will be valuable and at least a little bit fun.</p>\n\n<p>The first unit, besides preamble and and such about rationality checklist, scavenger hunt, and the prediction \"markets\" game, is a collection of Bayesian exercises to teach the basics of applying probability theory.</p>\n\n<p>There's two sets of quantitative word problems, and some qualitative analysis problems. It should take us a couple hours to work through it all.</p>\n\n<p>I'll be doing this at Benny's Bagels in Kitsilano, starting at 15:00 on Saturday. This will probably be an ongoing thing; every week until we are done, which is like 24 weeks at about one unit per week. We can probably compress that, but Wow.</p>\n\n<p>See our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a> for reminders about future meetups and such.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vancouver_CFAR_Materials__Bayes_practice_1\">Discussion article for the meetup : <a href=\"/meetups/lm\">Vancouver CFAR Materials: Bayes practice!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vancouver CFAR Materials: Bayes practice!", "anchor": "Discussion_article_for_the_meetup___Vancouver_CFAR_Materials__Bayes_practice_", "level": 1}, {"title": "Discussion article for the meetup : Vancouver CFAR Materials: Bayes practice!", "anchor": "Discussion_article_for_the_meetup___Vancouver_CFAR_Materials__Bayes_practice_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-16T16:24:32.302Z", "modifiedAt": null, "url": null, "title": "Meetup : Berlin Social Meetup", "slug": "meetup-berlin-social-meetup-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "blob", "createdAt": "2011-12-09T17:52:34.152Z", "isAdmin": false, "displayName": "blob"}, "userId": "3Yvqo9A3euExjqhsi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gpMZGKBQisHxoAYAR/meetup-berlin-social-meetup-0", "pageUrlRelative": "/posts/gpMZGKBQisHxoAYAR/meetup-berlin-social-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/gpMZGKBQisHxoAYAR/meetup-berlin-social-meetup-0", "postedAtFormatted": "Tuesday, April 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berlin%20Social%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berlin%20Social%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgpMZGKBQisHxoAYAR%2Fmeetup-berlin-social-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berlin%20Social%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgpMZGKBQisHxoAYAR%2Fmeetup-berlin-social-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgpMZGKBQisHxoAYAR%2Fmeetup-berlin-social-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ln'>Berlin Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 April 2013 07:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">U Leinestr, 12049 Berlin, Germany</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Our next regular social meetup will be held on Saturday 20th April. We're meeting at John's place: If you're interested in coming, join our <a href=\"http://groups.google.com/group/lw-berlin\" rel=\"nofollow\">mailing list</a> to get the exact location.</p>\n\n<p>The social meetup is intended as an informal and relaxed event for chats and games. Everyone is welcome!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ln'>Berlin Social Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gpMZGKBQisHxoAYAR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.1705998848016848e-06, "legacy": true, "legacyId": "22325", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berlin_Social_Meetup\">Discussion article for the meetup : <a href=\"/meetups/ln\">Berlin Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 April 2013 07:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">U Leinestr, 12049 Berlin, Germany</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Our next regular social meetup will be held on Saturday 20th April. We're meeting at John's place: If you're interested in coming, join our <a href=\"http://groups.google.com/group/lw-berlin\" rel=\"nofollow\">mailing list</a> to get the exact location.</p>\n\n<p>The social meetup is intended as an informal and relaxed event for chats and games. Everyone is welcome!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berlin_Social_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/ln\">Berlin Social Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berlin Social Meetup", "anchor": "Discussion_article_for_the_meetup___Berlin_Social_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Berlin Social Meetup", "anchor": "Discussion_article_for_the_meetup___Berlin_Social_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-16T16:27:40.931Z", "modifiedAt": null, "url": null, "title": "Meetup : Berlin Social Meetup", "slug": "meetup-berlin-social-meetup-1", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:05.104Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "blob", "createdAt": "2011-12-09T17:52:34.152Z", "isAdmin": false, "displayName": "blob"}, "userId": "3Yvqo9A3euExjqhsi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wPA9HYx5xaDsL3M72/meetup-berlin-social-meetup-1", "pageUrlRelative": "/posts/wPA9HYx5xaDsL3M72/meetup-berlin-social-meetup-1", "linkUrl": "https://www.lesswrong.com/posts/wPA9HYx5xaDsL3M72/meetup-berlin-social-meetup-1", "postedAtFormatted": "Tuesday, April 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berlin%20Social%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berlin%20Social%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwPA9HYx5xaDsL3M72%2Fmeetup-berlin-social-meetup-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berlin%20Social%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwPA9HYx5xaDsL3M72%2Fmeetup-berlin-social-meetup-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwPA9HYx5xaDsL3M72%2Fmeetup-berlin-social-meetup-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lo'>Berlin Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 June 2013 05:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Wuhletal, 12621 Berlin</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is a long-term announcement, we are actually meeting biweekly! The intervening meetups aren't planned as far in advance, please use the mailing list!</p>\n\n<p>Our next regular social meetup will be held on Saturday 15th June. It will likely take place at my house, check our <a href=\"http://groups.google.com/group/lw-berlin\" rel=\"nofollow\">mailing list</a> for details.</p>\n\n<p>The social meetup is intended as an informal and relaxed event for chats and games. Everyone is welcome!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lo'>Berlin Social Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wPA9HYx5xaDsL3M72", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.1706020669848068e-06, "legacy": true, "legacyId": "22326", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berlin_Social_Meetup\">Discussion article for the meetup : <a href=\"/meetups/lo\">Berlin Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 June 2013 05:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Wuhletal, 12621 Berlin</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is a long-term announcement, we are actually meeting biweekly! The intervening meetups aren't planned as far in advance, please use the mailing list!</p>\n\n<p>Our next regular social meetup will be held on Saturday 15th June. It will likely take place at my house, check our <a href=\"http://groups.google.com/group/lw-berlin\" rel=\"nofollow\">mailing list</a> for details.</p>\n\n<p>The social meetup is intended as an informal and relaxed event for chats and games. Everyone is welcome!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berlin_Social_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/lo\">Berlin Social Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berlin Social Meetup", "anchor": "Discussion_article_for_the_meetup___Berlin_Social_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Berlin Social Meetup", "anchor": "Discussion_article_for_the_meetup___Berlin_Social_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-16T23:40:36.065Z", "modifiedAt": null, "url": null, "title": "What truths are actually taboo?", "slug": "what-truths-are-actually-taboo", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:58.474Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sunflowers", "createdAt": "2013-02-07T16:17:38.352Z", "isAdmin": false, "displayName": "sunflowers"}, "userId": "bob3SbFSQBSfkfu6a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JBCPbSHzSaE5qHaCa/what-truths-are-actually-taboo", "pageUrlRelative": "/posts/JBCPbSHzSaE5qHaCa/what-truths-are-actually-taboo", "linkUrl": "https://www.lesswrong.com/posts/JBCPbSHzSaE5qHaCa/what-truths-are-actually-taboo", "postedAtFormatted": "Tuesday, April 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20truths%20are%20actually%20taboo%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20truths%20are%20actually%20taboo%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBCPbSHzSaE5qHaCa%2Fwhat-truths-are-actually-taboo%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20truths%20are%20actually%20taboo%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBCPbSHzSaE5qHaCa%2Fwhat-truths-are-actually-taboo", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBCPbSHzSaE5qHaCa%2Fwhat-truths-are-actually-taboo", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 758, "htmlBody": "<p>LessWrong has been having fun lately with posts about sexism, racism, and academic openness.&nbsp;&nbsp; And here just like everywhere else, somebody inevitably claims taboo status for any number of entirely obvious truths, e.g. \"top level mathematicians and physicists are almost invariably male,\" \"black people have lower IQ scores than white people,\" and \"black people are statistically more criminal than whites.\"&nbsp; In my experience, these are not actually taboo, and I think my experience is generalizable.&nbsp; I'll illustrate.</p>\n<p>You're at a bar and you meet a fellow named Bill.&nbsp; Bill's a nice guy, but somehow the conversation strayed Hitler-game style to World War II.&nbsp; Bill thinks the war was avoidable.&nbsp; Bill thinks the Holocaust would not have happened were it not for the war, and that some of the Holocaust was a reaction to actual Jewish subterfuge and abuse.&nbsp; Bill thinks that the Holocaust was not an essential, early plan of the Nazis, because it only happened after the war began.&nbsp; Bill thinks that the number of casualties has been overestimated.&nbsp; Bill claims that Allied abuses, e.g. the bombing of Dresden, have been glossed over and ignored, while fantastic lies about <a href=\"http://en.wikipedia.org/wiki/Soap_made_from_human_corpses#Postwar\">Jews being systematically turned into soap</a> have propagated.&nbsp; Bill thinks that the Holocaust has become a sort of national religion, abused by self-interested Jews and defenders of Zionist foreign policy, and that the freedom of those who doubt it is under serious attack. Bill starts listing other things he's not allowed to say. Bill doesn't think that the end of slavery was all that good for \"the blacks,\" and that the negatives of busing and forced integration have often outweighed the positives.&nbsp; Bill has personally been the victim of black-on-white crimes and racism.&nbsp; Bill is a <a href=\"http://en.wikipedia.org/wiki/Hereditarian\">hereditarian</a>.&nbsp; Bill doesn't think that dropping an n-bomb should ruin a public career.</p>\n<p>Here's the problem:&nbsp; everything Bill has said is either true, a matter of serious debate, or otherwise a matter of high likelihood and reasonableness.&nbsp; Yet you feel <em>nervous</em>.&nbsp; Perhaps you're <em>upset</em>.&nbsp; That's the power of <em>taboo</em>, right?&nbsp; Society is punishing truth-telling!&nbsp; First they came for the realists... Rationalists, to arms!</p>\n<p>Or.</p>\n<p>We can recognize that statements like these correlate with certain false beliefs and nasty sentiments of the sort that actually <em>are</em> taboo.&nbsp; It's just like when somebody says, \"well science doesn't know everything.\"&nbsp; To this, I think, \"duh, and you're probably a creationist or medical quack or something similarly credible.\"&nbsp; Or when somebody says, \"the government lies to us.\"&nbsp; To this, I think, \"obviously, and you're likely a Truther or something.\"&nbsp; Bill is probably an anti-Semite, but Bill doesn't just say, \"I'm an anti-Semite,\" because that really is taboo.&nbsp; He might even believe that he shouldn't be considered something awful like an anti-Semite.&nbsp; Bill probably doesn't think Bill so unpleasant.</p>\n<p>That's the paradox:&nbsp; \"taboo\" statements like black crime statistics are to some extent \"taboo\" for sound, rationalist reasons. But \"taboo\" is not <em>taboo</em>:&nbsp; it's about context.&nbsp; People who think that such statements are <em>taboo</em> are probably <em>bad at communicating</em>, and people often think they're racists and misogynists because they <em>probably are</em> on good rationalist grounds.&nbsp; If you want to talk about statistical representatives on the topic of race, be ready to understand that those who are listening will have background knowledge about the other views you might hold.</p>\n<p>All this is the leadup to my question:&nbsp; what highly probable or effectively certain truths are genuinely taboo?&nbsp; I'm trying to avoid answers like \"there are fewer women in mathematics\" or \"the size of my penis,\" since these are context sensitive, but not really taboo within a reasonable range of circumstances.&nbsp; I'm also not particularly interested in value commitments or ideologies.&nbsp; Yes, employers will punish labor organizers and radical political views can get you filtered.&nbsp; But these aren't clear matters of fact.&nbsp; I also don't mean sensitive topics like abortion or religion, nor do I mean \"taboo within a political party.\"</p>\n<p>Is there really anything true that we simply cannot say?&nbsp; I have the US in mind especially, but I'm interested in other countries as well.&nbsp; I'm sure there are things that deserve the label, but I've found that the most frequently given examples don't hold water.&nbsp; I think hereditarianism is a close contender, but it's not an \"obvious truth.\"&nbsp; Rather, my understanding is that it is a serious position.&nbsp; It's also only contextually taboo.&nbsp; If it were a definitive finding, it could perhaps become taboo, though I think it more likely that it would be somewhat reluctantly accepted.</p>\n<p>Any suggestions?&nbsp; If we find some really serious examples, we might figure out a way to talk about them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JBCPbSHzSaE5qHaCa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 13, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "22327", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 295, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-17T01:39:22.722Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington DC books meetup", "slug": "meetup-washington-dc-books-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.667Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WwnPzF7gYMN39EZAK/meetup-washington-dc-books-meetup", "pageUrlRelative": "/posts/WwnPzF7gYMN39EZAK/meetup-washington-dc-books-meetup", "linkUrl": "https://www.lesswrong.com/posts/WwnPzF7gYMN39EZAK/meetup-washington-dc-books-meetup", "postedAtFormatted": "Wednesday, April 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%20DC%20books%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%20DC%20books%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWwnPzF7gYMN39EZAK%2Fmeetup-washington-dc-books-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%20DC%20books%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWwnPzF7gYMN39EZAK%2Fmeetup-washington-dc-books-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWwnPzF7gYMN39EZAK%2Fmeetup-washington-dc-books-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 58, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lp'>Washington DC books meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 April 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to talk about books we've found interesting, exchange books (so bring some!) and decide if/how we want to have a book club.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lp'>Washington DC books meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WwnPzF7gYMN39EZAK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1709851255593279e-06, "legacy": true, "legacyId": "22329", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_books_meetup\">Discussion article for the meetup : <a href=\"/meetups/lp\">Washington DC books meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 April 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to talk about books we've found interesting, exchange books (so bring some!) and decide if/how we want to have a book club.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_books_meetup1\">Discussion article for the meetup : <a href=\"/meetups/lp\">Washington DC books meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington DC books meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_books_meetup", "level": 1}, {"title": "Discussion article for the meetup : Washington DC books meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_books_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-17T02:23:23.804Z", "modifiedAt": null, "url": null, "title": "Physicists To Test If Universe Is A Computer Simulation  (link)", "slug": "physicists-to-test-if-universe-is-a-computer-simulation-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.384Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "D_Alex", "createdAt": "2009-07-17T08:21:38.505Z", "isAdmin": false, "displayName": "D_Alex"}, "userId": "Sriopfkdwx2qJBx4G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wnj9nFJtgDoakrRra/physicists-to-test-if-universe-is-a-computer-simulation-link", "pageUrlRelative": "/posts/wnj9nFJtgDoakrRra/physicists-to-test-if-universe-is-a-computer-simulation-link", "linkUrl": "https://www.lesswrong.com/posts/wnj9nFJtgDoakrRra/physicists-to-test-if-universe-is-a-computer-simulation-link", "postedAtFormatted": "Wednesday, April 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Physicists%20To%20Test%20If%20Universe%20Is%20A%20Computer%20Simulation%20%20(link)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhysicists%20To%20Test%20If%20Universe%20Is%20A%20Computer%20Simulation%20%20(link)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwnj9nFJtgDoakrRra%2Fphysicists-to-test-if-universe-is-a-computer-simulation-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Physicists%20To%20Test%20If%20Universe%20Is%20A%20Computer%20Simulation%20%20(link)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwnj9nFJtgDoakrRra%2Fphysicists-to-test-if-universe-is-a-computer-simulation-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwnj9nFJtgDoakrRra%2Fphysicists-to-test-if-universe-is-a-computer-simulation-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 44, "htmlBody": "<p>If it is... I hope they do not crash the system with the test.</p>\r\n<p><a href=\"http://www.huffingtonpost.co.uk/2012/12/12/physicists-universe-simulation-test-university-of-washington-matrix_n_2282745.html\">http://www.huffingtonpost.co.uk/2012/12/12/physicists-universe-simulation-test-university-of-washington-matrix_n_2282745.html</a></p>\r\n<p>Be sure to check out the actual reseach papers linked in the article! I would have linked to them directly, but the article is full of follow-on links of considerable interest.</p>\r\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wnj9nFJtgDoakrRra", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 5, "extendedScore": null, "score": 1.17101569806477e-06, "legacy": true, "legacyId": "22330", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-17T03:46:53.809Z", "modifiedAt": null, "url": null, "title": "Ritual Report: Schelling Day", "slug": "ritual-report-schelling-day", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.858Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qrA2e4n6JqqAoBYzE/ritual-report-schelling-day", "pageUrlRelative": "/posts/qrA2e4n6JqqAoBYzE/ritual-report-schelling-day", "linkUrl": "https://www.lesswrong.com/posts/qrA2e4n6JqqAoBYzE/ritual-report-schelling-day", "postedAtFormatted": "Wednesday, April 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ritual%20Report%3A%20Schelling%20Day&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARitual%20Report%3A%20Schelling%20Day%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqrA2e4n6JqqAoBYzE%2Fritual-report-schelling-day%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ritual%20Report%3A%20Schelling%20Day%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqrA2e4n6JqqAoBYzE%2Fritual-report-schelling-day", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqrA2e4n6JqqAoBYzE%2Fritual-report-schelling-day", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 447, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">On Sunday, April 14th, the Boston group held our first <a href=\"/lw/h2t/schelling_day_a_rationalist_holiday/\">Schelling Day</a>&nbsp;celebration. The idea was to open up and share our private selves. It was a rousing success.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">That doesn't do it justice. Let me try again.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">By all the stars, you guys. This was <em>beautiful</em>.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">About fifteen people showed up. Most of us were from the hard core of Boston's rationalist community. Two of us were new to the group. (I'm hopeful this will convince them to start attending our regular meetups.) There was a brief explanation and a few vital clarifying questions before we began the ritual, which went for maybe 90-120 minutes, including a couple of short breaks. All of us spoke at least once.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">I don't want to go into specifics about what people said, but it was powerful. I learned about sides of my friends I would never have guessed at. People went into depth about issues I had only seen from the surface. I heard things that will make me change my behavior towards my friends. I saw angst and guilt and hope and pain and wild joy. I saw compassion and uncertainty and courage. People said things they had never said before, things I might not have been brave enough even to <em>think</em>&nbsp;in their position. I had tears in my eyes more than once.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">Speaking went remarkably smoothly. I set a timer for five minutes for each speaker, but it never ran out. (Five minutes is a surprisingly long time.) Partway through, Julia suggested we leave a long moment of silence between speakers, which was a very good idea and I wish I'd done a better job of enforcing it.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">Afterwards, we had a potluck and mingled in small groups. At first we talked about our revelations, but over time our conversation started drifting towards our usual topics. Next time, in order to keep us on topic, I'll probably try adding more structure to this stage.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">The other area I wanted to improve was the ritual with the snacks. We had five categories: Struggles, Confessions, Hopes, Joys, and Other. There weren't many Hopes, and there wasn't much distinction between Struggles and Confessions. I'll change this for next time, possibly to Hardships, Joys, Histories, and Other. There's room for improvement in the specific snacks I picked, too.</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">This celebration was the most powerful thing I've experienced since the Solstice megameetup. I don't think I want to do this again soon&mdash;it was one of the most exhausting things I've ever done, even if I didn't notice until after I'd left&mdash;but I know I want to do it again <em>sometime</em>.</p>\n<p>&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">To everyone who came: I'm so proud of what you did and who you are. Thank you for your courage and sincerity.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hXTqT62YDTTiqJfxG": 1, "zcvsZQWJBFK6SxK4K": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qrA2e4n6JqqAoBYzE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 46, "extendedScore": null, "score": 0.000153, "legacy": true, "legacyId": "22333", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 116, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["z9Tc3CrZmjTfMc4jj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-17T13:08:35.630Z", "modifiedAt": null, "url": null, "title": "Cryocrastinating? Send me (or someone else) money!", "slug": "cryocrastinating-send-me-or-someone-else-money", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:03.888Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pEMhfKn8w2Pr5YgBn/cryocrastinating-send-me-or-someone-else-money", "pageUrlRelative": "/posts/pEMhfKn8w2Pr5YgBn/cryocrastinating-send-me-or-someone-else-money", "linkUrl": "https://www.lesswrong.com/posts/pEMhfKn8w2Pr5YgBn/cryocrastinating-send-me-or-someone-else-money", "postedAtFormatted": "Wednesday, April 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryocrastinating%3F%20Send%20me%20(or%20someone%20else)%20money!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryocrastinating%3F%20Send%20me%20(or%20someone%20else)%20money!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpEMhfKn8w2Pr5YgBn%2Fcryocrastinating-send-me-or-someone-else-money%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryocrastinating%3F%20Send%20me%20(or%20someone%20else)%20money!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpEMhfKn8w2Pr5YgBn%2Fcryocrastinating-send-me-or-someone-else-money", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpEMhfKn8w2Pr5YgBn%2Fcryocrastinating-send-me-or-someone-else-money", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 438, "htmlBody": "<p>I know from personal experience how hard it is to actually go through the final process to sign up for cryonics - no matter how theoretically in favour one is. For me, it was Robin Hanson's offer of an <a href=\"http://www.overcomingbias.com/2009/03/my-cryonics-hour.html\">hour</a> of chat that sealed the deal - it seemed much easier to focus on getting to that interview, than on potentially saving the whole of my future :-)</p>\n<p>Anyway, I'm offering my services to help out others who might want to get that final push over the line. What am I offering? Well, the opportunity to send me money! Simply pledge something like \"if I don't get signed up for cryonics by such and such a date, I will send Stuart Armstrong $X\".</p>\n<p>This sounds incredibly mercenary - I'm <em>offering</em> you the possibility of sending <em>me</em> money? This seems to be a misunderstanding of the whole meaning of the word \"offering\". Well, for a start, I'm certain that I will never receive that money - if someone pledges \"in a year's time, I will have signed up for cryonics, or I will send Stuart Armstrong $200\", then I read that as \"in a year's time, I will have signed up for cryonics\". Because no-one likes losing money they could keep by doing something they want to (want to) do. So what I'm offering is the possibility to make yourself sign up for cryonics.</p>\n<p>In fact, I'll do it this way: if I ever get any money from such a pledge, I'll redistribute that money to other people who took the pledge and did sign up. If it's not too many people, I can probably offer one hour chats as well, for those interested.</p>\n<p>Of course, this works just as well if you pledge to give money to someone else, not just me, so I encourage you to pledge to whoever you like! Just make sure that:</p>\n<ol>\n<li>You don't pledge the money to a charity you approve of - you should have no justification for avoiding signing up. Failure is a failure, not an act of generosity.</li>\n<li>You pledge the money to someone who will take the money from you if you fail - or else the whole thing doesn't work at all. I promise to do so!</li>\n<li>You bear in mind that these things take longer than you expect (planning&nbsp;fallacy and all that). Pledge a year, aim to have it done in six months.</li>\n</ol>\n<p>I already have one person pledged for &pound;100 in a year's time, and I'm fully confident they'll be signed up before that. If I have their permission, I'll let you know as soon as it happens.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pEMhfKn8w2Pr5YgBn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 25, "extendedScore": null, "score": 1.1714639787951527e-06, "legacy": true, "legacyId": "22336", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-17T19:27:46.154Z", "modifiedAt": null, "url": null, "title": "Cold fusion: real after all?", "slug": "cold-fusion-real-after-all", "viewCount": null, "lastCommentedAt": "2019-06-28T13:52:15.578Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ahbwramc", "createdAt": "2011-11-19T18:13:15.120Z", "isAdmin": false, "displayName": "ahbwramc"}, "userId": "D55t3WY5oDxG6Xwcc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zn8TnwERzMD6X8Dn7/cold-fusion-real-after-all", "pageUrlRelative": "/posts/Zn8TnwERzMD6X8Dn7/cold-fusion-real-after-all", "linkUrl": "https://www.lesswrong.com/posts/Zn8TnwERzMD6X8Dn7/cold-fusion-real-after-all", "postedAtFormatted": "Wednesday, April 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cold%20fusion%3A%20real%20after%20all%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACold%20fusion%3A%20real%20after%20all%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZn8TnwERzMD6X8Dn7%2Fcold-fusion-real-after-all%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cold%20fusion%3A%20real%20after%20all%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZn8TnwERzMD6X8Dn7%2Fcold-fusion-real-after-all", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZn8TnwERzMD6X8Dn7%2Fcold-fusion-real-after-all", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2802, "htmlBody": "<p>TL,DR: cold fusion is real, apparently. Yes, really -&nbsp;<em>co</em><em>ld fusion</em>. I know. I wouldn't have thought so either.</p>\n<p>- &nbsp;- &nbsp;-</p>\n<p>The point of this post is basically to promote to your attention the hypothesis that cold fusion is a real physical phenomenon. For those of you not in the know, this <em>very much</em>&nbsp;flies in the face of current scientific consensus (something I'm not usually in the habit of opposing). In this case though the evidence seems to be quite straightforwardly in favour of the cold fusion advocates.</p>\n<p>[Note: most researchers working in this area don't like the term cold fusion; partially because of the negative scientific connotations it drudges up, and partially because fusion might not be an accurate description of what's going on physically. The two preferred terms seem to be low-energy nuclear reactions (LENR) and lattice-assisted nuclear reactions (LANR). I use cold fusion in this piece mainly for convenience and name-brand recognition]</p>\n<p>Quick background - in 1989&nbsp;Stanley Pons and Martin Fleischmann, leading electrochemists of their day, announced a truly startling discovery: a tabletop apparatus of theirs had produced anomalous heat that was (according to them) orders of magnitude beyond what could be produced by chemical effects alone. The only process that can produce heat like that is a nuclear reaction, but such reactions were thought to be impossible at such low temperatures. Thinking they had discovered a new source of energy, Pons and Fleischmann were justifiably excited and hurried to publish their results. In the subsequent months a huge number of researchers tried to replicate their findings, with most being unable to do so. Of the few scientists who did get positive results, some later retracted their work, and others were criticized for sloppy experimental design. To make matters worse, errors and exaggerations were found in Pons and Fleischmann's original paper. Very quickly the scientific community as a whole had cold fusion pegged as \"pathological science\", and most researchers forgot about the whole affair and went back to their normal, non-energy-crisis-solving work. Pons and Fleischmann, disgraced, ended up quietly leaving the country to continue their work elsewhere, and that was the end of the cold fusion story, as far as most people were concerned. [1]</p>\n<p>Here's where it gets interesting. Naturally, the prospect of solving the world's energy problems proved very alluring to people, so a small number of researchers continued their work with cold fusion. During the 90's some of this work was published in peer-reviewed journals, although this became less and less common as the decade wore on. As far as I know, no mainstream peer-reviewed scientific journal currently accepts cold fusion papers for consideration. Undeterred, cold fusion researchers continued their work; research was published at conferences devoted to cold fusion, self-organized by researchers in the field. This work was generally not peer-reviewed, and much of it (I think most cold fusion researchers would be willing to admit) was not of the highest quality, scientifically. Much - but not <em>all</em>, mind you. There were some researchers at respected universities (including MIT) that conducted very rigorous and high quality studies. Anyway, together this motley band of hobbyists, engineers and scientists, over the last twenty years or so, has found...well, something. Sometimes. If you squint right.</p>\n<p>Basically there are a huge number of scattered reports of cold fusion occurring, but reproducibility is a big problem. Some people find low levels of excess heat. Some people find nothing. Some people, when conditions are \"just right\", report extremely high levels of excess heat. There are even a few cases where explosions occurred and labs have been \"blown up\" [2]. The sheer volume of claims might be enough to be suggestive that something was going on, all things being equal. But of course, all things <em>aren't</em>&nbsp;really equal in this case; given the initial inability of expert scientists to replicate the original findings in 1989, and the non-peer-reviewed nature of most cold fusion work nowadays, we have every reason to be extra skeptical of reports of cold fusion. Extraordinary claims and all that.</p>\n<p>This is why I've taken what I consider to be the two&nbsp;<em>strongest</em>&nbsp;pieces of evidence for cold fusion and provided them below. As I mentioned before, there are some scientists doing rigorous, very well controlled experiments at research universities, and they consistently find that cold fusion <em>is</em> occurring. So, without further ado, here's my proof:</p>\n<p>1. Mitchell Swartz's experiments</p>\n<p>If you have the time, I would strongly suggest you watch this video:&nbsp;<a href=\"http://www.youtube.com/watch?v=e38Y7HxD_5Y\">http://www.youtube.com/watch?v=e38Y7HxD_5Y</a>.&nbsp;It's part of a lecture from a multi-week cold fusion course put on by Swartz and others at MIT in January. It's 40 minutes long (and only the first part of five videos actually) but well worth your time. In it Swartz basically makes his case for cold fusion.</p>\n<p>I suppose I should stop here to briefly describe what a typical cold fusion experiment looks like. The standard design uses a simple piece of metal, usually Palladium or Nickel. Heavy water (Deuterium) is forced into&nbsp;the lattice of atoms that make up the metal by applying an electric field. Once a high enough loading of Deuterium is achieved in the metal lattice, what (purportedly) happens is that two Deuterons combine in a nuclear reaction to produce a single Helium(4) nucleus, plus heat. The idea is that the lattice of metal atoms is mediating the nuclear reaction in some way, making it occur at far lower temperatures than would normally be possible. Typically these experiments are done with the apparatus fully immersed in heavy water, and what you do is check for excess heat by setting up a calorimeter around the experiment. You can easily measure how much electrical energy you're putting into the system; if the calorimeter is reading higher energies than that coming out, you know cold fusion is taking place (well, that's not entirely accurate - you know <em>some</em>&nbsp;process is producing extra energy, but you don't know what it is. The reason we can confidently say it's nuclear in origin is because the energy densities involved are well beyond what could be produced by a simple chemical reaction).</p>\n<p>Anyway, if you can't watch the video, here's what Swartz has found:</p>\n<p>-Consistently measures output energy in the range of 200-400% of input energy (!)</p>\n<p>-Excess heat is <em>well</em>&nbsp;above noise level for calorimeter</p>\n<p>-Calorimeter is very well calibrated - when heat is fed into system via simple ohmic resistor, measured output heat exactly matches input energy</p>\n<p>-Chemical control experiments fail (ie using non-cold-fusion-active metals and loading materials gives no excess heat)</p>\n<p>-Two calorimeters (each of which have several redundant&nbsp;ways of measuring heat anyway) were built, just to be sure; same results</p>\n<p>-Excess heat generation occurs for days or even weeks continuously</p>\n<p>-He(4) production is observed, with amounts commensurate with heat production</p>\n<p>Mind you, this is not just a one-off experiment - he's been getting results like this for ten years or more. If you watch the video, I think you'll agree that it's a very well-controlled and well-calibrated experiment. It certainly looks that way, anyway, to my semi-informed eyes as a physics grad student (although if there are any actual experimentalists reading this who are more informed than I, I would <em>love</em>&nbsp;to hear from you - please, attack it to bits). In my eyes the only two reasonable explanations for Swartz's results are (i) cold fusion being real, and (ii) active fraud. Fraud is of course possible, but I think unlikely given what other groups have found.</p>\n<p>Oh, and if you can't watch the video, here's a 2009 paper you can read by Swartz:&nbsp;<a href=\"http://world.std.com/~mica/Swartz-SurveyJSE2009.pdf\">http://world.std.com/~mica/Swartz-SurveyJSE2009.pdf</a>. It's less focused on his own research and more of a survey of cold fusion research in general, but he does talk about his own results in Section 4. Certainly worth a look.</p>\n<p>2. Yasuhiro Iwamura's transmutation work at Mitsubishi</p>\n<p>In one of those strange quirks of fate, for some reason or another scientists in Japan ended up being particularly open to cold fusion claims [3]. There are currently several researchers in Japan, some at universities and some at different companies, who are looking in to cold fusion. I link you here to a particularly interesting paper by Iwamura, who works for a research division of Mitsubishi:&nbsp;<a href=\"http://newenergytimes.com/v2/conferences/2012/ANS2012W/2012Iwamura-ANS-LENR-Paper.pdf\">http://newenergytimes.com/v2/conferences/2012/ANS2012W/2012Iwamura-ANS-LENR-Paper.pdf</a></p>\n<p><a href=\"http://newenergytimes.com/v2/conferences/2012/ANS2012W/2012Iwamura-ANS-LENR-Paper.pdf\"></a>Iwamura uses a slightly different setup for Swartz, but the basic idea is the same: Deuterium is permeated through a Palladium lattice, magic happens, heat comes out, etc. The main difference in this experiment is that Iwamura is not actually looking for excess heat production. He's instead looking for transmutation of elements, which also has been reported to happen in certain cold fusion experiments. To do this a layer of some other material, in this case Cesium, is added on top of the Palladium, and - in a process that no one fully understands yet - that material is transmuted into an entirely different element. So just in case unlimited clean energy wasn't enough for you, we now also have just straight-up alchemy happening (I for one can't <em>fathom</em>&nbsp;why scientists are skeptical of cold fusion).</p>\n<p>But, prior probabilities be damned, Iwamura has actually gone and done this! In his experiments he does time-resolved XPS spectroscopy, and observes Praseodymium being created in the apparatus while the total amount of Cesium goes down with time - elemental transmutation (!)</p>\n<p>This work is particularly strong evidence for two reasons, I think:</p>\n<p>One, because the claim involves detecting elements, it's inherently more plausible than any claims to do with excess heat. Calorimetry can be difficult, and it's easy for a skeptic to claim that the experimenter simply made a mistake in measuring the excess heat (mind you in the case above I think the calorimetry <em>is</em>&nbsp;well done and that there <em>wasn't</em>&nbsp;a mistake, but that isn't always the case). In contrast to calorimetry, detecting elements is very straightforward. There are many independent ways to do it, and it's all rather black and white; either you find an element, or you don't. If you do find a new element, then have something of a smoking gun - it's very difficult to explain how a new element could just <em>appear</em>&nbsp;in your experiment without invoking nuclear processes. The standard skeptic's reply to experiments like this is basically to say \"contamination,\" and wave their hands. That is, they posit that the transmuted element in question was already present in the Palladium lattice at the start of the experiment (perhaps concentrate somewhere so it wasn't detected initially). I find this a less than compelling argument, to say the least - really, the experiment just <em>happens</em>&nbsp;to be contaminated with Praseodymium, of all things? And the contamination is such that the Praseodymium <em>gradually appears</em>&nbsp;to the detector over time, at the same rate that Cesium disappears? And when experiments without Cesium are run, the Praseodymium is mysteriously absent? What a strange coincidence.</p>\n<p>Sarcasm aside, though, the experimenters are well aware of this argument, and have a very good explanation for why it couldn't be contamination - namely, isotope ratios. Essentially the distribution of isotope frequencies for the transmuted elements they find are different from the natural isotope frequencies for the same element. Hence, the experiment <em>couldn't</em>&nbsp;have simply been contaminated with the natural version of that element.</p>\n<p>The second reason this research counts as strong evidence is that...well, it's actually been replicated. This was particularly bizarre for me to discover upon reading about cold fusion - I was under the impression that there were <em>no</em> clear-cut replications of any cold fusion experiments, anywhere. That's apparently not true though - researchers at Toyota have redone Iwamura's experiment and <em>also</em>&nbsp;find Praseodymium being created. Unfortunately it was presented at a conference, and there doesn't seem to be an associated paper. Here's a link to an article though that describes the replication, though, containing some slides with the Toyota researchers results:&nbsp;<a href=\"http://news.newenergytimes.net/2012/12/06/mitsubishi-reports-toyota-replication/\">http://news.newenergytimes.net/2012/12/06/mitsubishi-reports-toyota-replication/</a>. The article also mentions researchers at two universities (Osaka and Iwate) reporting similar findings.</p>\n<address><span style=\"font-style: normal;\">So to sum up: simple elemental detection experiment. Transmuted elements found. Control experiments fail. Multiple confirmations. Combined with the high-quality excess heat measurements of Swartz above, I feel </span>very<span style=\"font-style: normal;\"> confident in concluding that cold fusion is a real physical phenomenon. For an additional bit of low-weight evidence, though, I submit to you also the fact that </span>NASA<span style=\"font-style: normal;\">, of all organizations, has an active cold fusion program: see&nbsp;</span><a style=\"font-style: normal;\" href=\"http://futureinnovation.larc.nasa.gov/view/articles/futurism/bushnell/low-energy-nuclear-reactions.html\">http://futureinnovation.larc.nasa.gov/view/articles/futurism/bushnell/low-energy-nuclear-reactions.html</a><span style=\"font-style: normal;\">. To be honest I think that article overhypes the current situation; yes, cold fusion appears to be real, but I find the assertion that multiple groups have already achieved kilowatt-level heat production to be very suspect, based on what I've read. Regardless, the fact that NASA is treating this seriously and actively doing cold fusion research might serve as further evidence for skeptical readers.</span></address><address><br /></address><address><span style=\"font-style: normal;\">This concludes my case.</span></address><address><br /></address><address><span style=\"font-style: normal;\">Now, despite the (I think) fairly convincing picture I've painted here, we are still left with the nagging question of </span><span style=\"font-style: normal;\">why<span style=\"font-style: normal;\">&nbsp;so many early cold fusion experiments failed, and why so many continue to fail today. It seems clear that, real effect or no, cold fusion experiments have </span>unusually<span style=\"font-style: normal;\"> low reproducibility. Shouldn't this count against it somehow? In the words of one skeptic, nuclear physicist Richard Garwin,</span></span></address><address><br /></address><address><span style=\"font-style: normal;\"><span style=\"font-style: normal;\">\"It's absurd to claim that experiments that seem to support cold fusion are valid, while those that don't are flawed.\"</span></span></address><address><br /></address><address><span style=\"font-style: normal;\">I think Garwin misses the point here, though. What cold fusion advocates are looking for is an </span>existence<span style=\"font-style: normal;\">&nbsp;proof. They just have to show that there exists </span>some<span style=\"font-style: normal;\">&nbsp;set of experimental conditions for which cold fusion occurs. Or, to flip the quantifiers (as PhilGoetz might put it ;), they are trying to </span>disprove<span style=\"font-style: normal;\">&nbsp;the hypothesis that for all sets of experimental conditions, cold fusion </span>never<span style=\"font-style: normal;\">&nbsp;occurs. Looking at it that way, </span>of course<span style=\"font-style: normal;\">&nbsp;a few experiments would be sufficient to make the case - it's just standard Popperian falsification. When you're dealing with \"for all\" statements, its one strike and you're out. </span></address><address><br /></address><address><span style=\"font-style: normal;\">Or, to put it in Bayesian terms: the probability of getting negative experimental results, conditional on cold fusion being true, is not that low. If cold fusion is true, then </span>somewhere<span style=\"font-style: normal;\"> in the experimental parameter space there must be a region where it occurs. But that says nothing about the </span>size<span style=\"font-style: normal;\">&nbsp;of the region; it's fairly easy to imagine experimenters setting out to demonstrate cold fusion and missing some unknown key aspect of the design, giving a negative result.&nbsp;One doesn't even have to posit any experimental error - they're simply </span>looking in the wrong place<span style=\"font-style: normal;\">. On the other hand, the probability of getting positive results in a well-designed, well-controlled experiment, conditional on cold fusion being false, is </span>extremely<span style=\"font-style: normal;\">&nbsp;low. It's basically equal to the probability that the experimenter screwed up the measurement, which can be made vanishingly low with proper controls and replications.</span></address><address><br /></address><address><span style=\"font-style: normal;\">With all that said, of course, it would still be nice to know </span>where<span style=\"font-style: normal;\"> exactly previous cold fusion researchers were going wrong. Mitchell Swartz, incidentally, thinks he has this figured out. He's identified a number of necessary conditions for cold fusion that are frequently absent from failed experiments and present in successful ones. The two main culprits seem to insufficient loading of Deuterium in the metal lattice, and a non-optimal (too high or too low) level of electrical driving of the system. I have no idea if he's right about the particulars, of course. But it certainly doesn't seem implausible that this will all be sorted out in the near future, and what seemed like irreproducibility will simply turn out to be the result of an underlying, thus far opaque, pattern.</span></address><address><br /></address><address><span style=\"font-style: normal;\">Huh, this turned out much longer than I expected. I guess I'll close by noting that this topic seems like an almost perfect candidate for confirmation bias; who </span>wouldn't<span style=\"font-style: normal;\">&nbsp;want to believe in a cheap, unlimited, carbon and radiation-free energy source? That's part of the reason I made this post; </span><span style=\"font-style: normal;\">what I'd really like is for people to a) pick apart this post, looking for flaws in my logic/arguments, and b) look into this whole cold fusion thing independently, and see if they reach the same conclusions. I'm very interested in getting this right, for obvious reasons, and I think at the </span>very least<span style=\"font-style: normal;\"> I've made a sufficiently interesting case that doing some research online would be worth it.&nbsp;</span><span style=\"font-style: normal;\">I don't think I really need to mention the almost mind-boggling impact cold fusion would have, if it turned out to be real and exploitable.</span></address><address><br /></address><address><span style=\"font-style: normal;\">I'm </span>cautiously optimistic<span style=\"font-style: normal;\">&nbsp;about the future right now, LW.</span></address><address><br /></address><address><span style=\"font-style: normal;\">References:</span></address><address><br /></address><address><span style=\"font-style: normal;\">[1] This is standard history, see&nbsp;</span><a style=\"font-style: normal;\" href=\"http://en.wikipedia.org/wiki/Cold_fusion\">http://en.wikipedia.org/wiki/Cold_fusion</a></address>\n<p>[2]&nbsp;<a href=\"http://news.newenergytimes.net/2013/02/22/lenr-nasa-widom-larsen-nuclear-reactor-in-your-basement/\">http://news.newenergytimes.net/2013/02/22/lenr-nasa-widom-larsen-nuclear-reactor-in-your-basement/</a>&nbsp;</p>\n<p>Relevant quote: \"The explosions are difficult to keep secret. Most people who have been around the field know of them: Fleischmann and Pons in Utah, unidentified researchers at Lawrence Livermore National Laboratory, a group at SRI International, Tadahiko Mizuno in Japan, Jean-Paul Biberian in France, and another situation in a Russian lab a few years ago.</p>\n<p>The only lab that may have blown up was the one in Russia. In the other situations, the experiment, not the lab, blew up. SRI International researcher Andy Riley was killed, and Michael McKubre was wounded. Mizuno lost his hearing for a week and came very close to sustaining severe injuries.\"</p>\n<p>[3]&nbsp;<a href=\"http://coldfusioninformation.com/countries/cold-fusion-japan/\">http://coldfusioninformation.com/countries/cold-fusion-japan/</a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zn8TnwERzMD6X8Dn7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": -11, "extendedScore": null, "score": -1.3e-05, "legacy": true, "legacyId": "22258", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 105, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T05:06:05.490Z", "modifiedAt": null, "url": null, "title": "Litany of a Bright Dilettante", "slug": "litany-of-a-bright-dilettante", "viewCount": null, "lastCommentedAt": "2021-12-01T20:19:58.018Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SgGYcTmtLMu4rYnY9/litany-of-a-bright-dilettante", "pageUrlRelative": "/posts/SgGYcTmtLMu4rYnY9/litany-of-a-bright-dilettante", "linkUrl": "https://www.lesswrong.com/posts/SgGYcTmtLMu4rYnY9/litany-of-a-bright-dilettante", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Litany%20of%20a%20Bright%20Dilettante&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALitany%20of%20a%20Bright%20Dilettante%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSgGYcTmtLMu4rYnY9%2Flitany-of-a-bright-dilettante%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Litany%20of%20a%20Bright%20Dilettante%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSgGYcTmtLMu4rYnY9%2Flitany-of-a-bright-dilettante", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSgGYcTmtLMu4rYnY9%2Flitany-of-a-bright-dilettante", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 387, "htmlBody": "<p>So, one more litany, hopefully someone else finds it as useful.</p>\n<p>It's an understatement that humility is not a common virtue in online discussions, even, or especially when it's most needed.</p>\n<p>I'll start with my own recent example. I thought up a clear and obvious objection to one of the assertions in <a href=\"/lw/gzq/bayesian_adjustment_does_not_defeat_existential/8sp1\">Eliezer's critique</a> of the FAI effort compared with the Pascal's Wager and started writing a witty reply. ...And then I stopped. In large part because I had just gone through the same situation, but on the other side, dealing with some of the comments to my post about time-turners and General Relativity by those who know next to nothing about General Relativity. It was irritating, yet here I was, falling into the same trap. And not for the first time, far from it. The following is the resulting thought process, distilled to one paragraph.</p>\n<p>I have not spent 10,000+ hours thinking about this topic in a professional, all-out, do-the-impossible way. I probably have not spent even one hour seriously thinking about it. I probably do not have the prerequisites required to do so. I probably don't even know what prerequisites are required to think about this topic productively. In short, there are almost guaranteed to exist unknown unknowns which are bound to trip up a novice like me. The odds that I find a clever argument contradicting someone who works on this topic for a living, just by reading one or two popular explanations of it are minuscule. So if I think up such an argument, the odds of it being both new and correct are heavily stacked against me. It is true that they are non-zero, and there are popular examples of non-experts finding flaws in an established theory where there is a consensus among the experts. Some of them might even be true stories. No, Einstein was not one of these non-experts, and even if he were, I am not Einstein.</p>\n<p>And so on. So I came up with the following, rather unpolished mantra:</p>\n<p><strong>If I think up what seems like an obvious objection, I will resist assuming that I have found a <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/WeaksauceWeakness\">Weaksauce Weakness</a> in the experts' logic. Instead I may ask politely whether my argument is a valid one, and if not, where the flaw lies.</strong></p>\n<p>If you think it useful, feel free to improve the wording.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"moeYqrcakMgXnQNyF": 1, "x3zyEPFaJANB2BHmP": 1, "AXhEhCkTrHZbjXXu3": 1, "8uNFGxejo5hykCEez": 1, "YPZCAs9Axp9PtrF22": 1, "SW3euSNqpozcsxXaX": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SgGYcTmtLMu4rYnY9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 71, "baseScore": 89, "extendedScore": null, "score": 0.000233, "legacy": true, "legacyId": "22343", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 89, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 72, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T05:07:13.227Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington DC Kennedy Center Meetup with Michael Vassar", "slug": "meetup-washington-dc-kennedy-center-meetup-with-michael", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.659Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "komponisto", "createdAt": "2009-03-01T21:10:23.585Z", "isAdmin": false, "displayName": "komponisto"}, "userId": "h48TMtPzfimsEobTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LbaZytMASJuAouMA8/meetup-washington-dc-kennedy-center-meetup-with-michael", "pageUrlRelative": "/posts/LbaZytMASJuAouMA8/meetup-washington-dc-kennedy-center-meetup-with-michael", "linkUrl": "https://www.lesswrong.com/posts/LbaZytMASJuAouMA8/meetup-washington-dc-kennedy-center-meetup-with-michael", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%20DC%20Kennedy%20Center%20Meetup%20with%20Michael%20Vassar&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%20DC%20Kennedy%20Center%20Meetup%20with%20Michael%20Vassar%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLbaZytMASJuAouMA8%2Fmeetup-washington-dc-kennedy-center-meetup-with-michael%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%20DC%20Kennedy%20Center%20Meetup%20with%20Michael%20Vassar%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLbaZytMASJuAouMA8%2Fmeetup-washington-dc-kennedy-center-meetup-with-michael", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLbaZytMASJuAouMA8%2Fmeetup-washington-dc-kennedy-center-meetup-with-michael", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 132, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lq'>Washington DC Kennedy Center Meetup with Michael Vassar</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 April 2013 12:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">John F. Kennedy Center for the Performing Arts, 2700 F Street, NW, Washington, DC 20566.</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>(This is very short notice -- 11 hours from posting -- so apologies!)</p>\n\n<p>This meetup will have <strong>two \"sessions\"</strong>; people are welcome to attend <strong>either or both</strong>:</p>\n\n<ul>\n<li>12:00 pm - 2:00 pm</li>\n</ul>\n\n<p>and</p>\n\n<ul>\n<li>3:30 pm - 7:30 pm</li>\n</ul>\n\n<p>(Michael is attending an event with press at 2, hence the break.)</p>\n\n<p>We'll plan to meet in the area with tables and chairs outside the <a href=\"http://www.kennedy-center.org/visitor/restaurants/#Cafe\" rel=\"nofollow\">KC caf\u00e9</a>, which is on the upper (\"Terrace\") level of the Kennedy Center. I'll try to bring a Less Wrong sign.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lq'>Washington DC Kennedy Center Meetup with Michael Vassar</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LbaZytMASJuAouMA8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.1721305902532959e-06, "legacy": true, "legacyId": "22344", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_Kennedy_Center_Meetup_with_Michael_Vassar\">Discussion article for the meetup : <a href=\"/meetups/lq\">Washington DC Kennedy Center Meetup with Michael Vassar</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 April 2013 12:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">John F. Kennedy Center for the Performing Arts, 2700 F Street, NW, Washington, DC 20566.</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>(This is very short notice -- 11 hours from posting -- so apologies!)</p>\n\n<p>This meetup will have <strong>two \"sessions\"</strong>; people are welcome to attend <strong>either or both</strong>:</p>\n\n<ul>\n<li>12:00 pm - 2:00 pm</li>\n</ul>\n\n<p>and</p>\n\n<ul>\n<li>3:30 pm - 7:30 pm</li>\n</ul>\n\n<p>(Michael is attending an event with press at 2, hence the break.)</p>\n\n<p>We'll plan to meet in the area with tables and chairs outside the <a href=\"http://www.kennedy-center.org/visitor/restaurants/#Cafe\" rel=\"nofollow\">KC caf\u00e9</a>, which is on the upper (\"Terrace\") level of the Kennedy Center. I'll try to bring a Less Wrong sign.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_Kennedy_Center_Meetup_with_Michael_Vassar1\">Discussion article for the meetup : <a href=\"/meetups/lq\">Washington DC Kennedy Center Meetup with Michael Vassar</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington DC Kennedy Center Meetup with Michael Vassar", "anchor": "Discussion_article_for_the_meetup___Washington_DC_Kennedy_Center_Meetup_with_Michael_Vassar", "level": 1}, {"title": "Discussion article for the meetup : Washington DC Kennedy Center Meetup with Michael Vassar", "anchor": "Discussion_article_for_the_meetup___Washington_DC_Kennedy_Center_Meetup_with_Michael_Vassar1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T05:20:25.235Z", "modifiedAt": null, "url": null, "title": "Being Half-Rational About Pascal's Wager is Even Worse", "slug": "being-half-rational-about-pascal-s-wager-is-even-worse", "viewCount": null, "lastCommentedAt": "2013-05-10T18:24:23.679Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ebiCeBHr7At8Yyq9R/being-half-rational-about-pascal-s-wager-is-even-worse", "pageUrlRelative": "/posts/ebiCeBHr7At8Yyq9R/being-half-rational-about-pascal-s-wager-is-even-worse", "linkUrl": "https://www.lesswrong.com/posts/ebiCeBHr7At8Yyq9R/being-half-rational-about-pascal-s-wager-is-even-worse", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Being%20Half-Rational%20About%20Pascal's%20Wager%20is%20Even%20Worse&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeing%20Half-Rational%20About%20Pascal's%20Wager%20is%20Even%20Worse%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FebiCeBHr7At8Yyq9R%2Fbeing-half-rational-about-pascal-s-wager-is-even-worse%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Being%20Half-Rational%20About%20Pascal's%20Wager%20is%20Even%20Worse%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FebiCeBHr7At8Yyq9R%2Fbeing-half-rational-about-pascal-s-wager-is-even-worse", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FebiCeBHr7At8Yyq9R%2Fbeing-half-rational-about-pascal-s-wager-is-even-worse", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2672, "htmlBody": "<p>For so long as I can remember, I have rejected Pascal's Wager in all its forms on sheerly practical grounds: anyone who tries to plan out their life by chasing a 1 in 10,000 chance of a huge payoff is almost certainly doomed in practice. &nbsp;This&nbsp;kind of clever reasoning never pays off in real life...</p>\n<p><em>...unless</em>&nbsp;you have also underestimated the allegedly tiny chance of the large impact.</p>\n<p>For example. &nbsp;At one critical junction in history, Leo Szilard, the first physicist to see the possibility of fission chain reactions and hence practical nuclear weapons, was trying to persuade Enrico Fermi to take the issue seriously, in the company of a more prestigious friend, Isidor Rabi:</p>\n<p style=\"padding-left: 30px;\">I said to him: &nbsp;\"Did you talk to Fermi?\" &nbsp;Rabi said, \"Yes, I did.\" &nbsp;I said, \"What did Fermi say?\" &nbsp;Rabi said, \"Fermi said 'Nuts!'\" &nbsp;So I said, \"Why did he say 'Nuts!'?\" and Rabi said, \"Well, I don't know, but he is in and we can ask him.\" So we went over to Fermi's office, and Rabi said to Fermi, \"Look, Fermi, I told you what Szilard thought and you said &lsquo;Nuts!' and Szilard wants to know why you said &lsquo;Nuts!'\" So Fermi said, \"Well&hellip; there is the remote possibility that neutrons may be emitted in the fission of uranium and then of course perhaps a chain reaction can be made.\" Rabi said, \"What do you mean by &lsquo;remote possibility'?\" and Fermi said, \"Well, ten per cent.\" Rabi said, \"Ten per cent is not a remote possibility if it means that we may die of it. &nbsp;If I have pneumonia and the doctor tells me that there is a remote possibility that I might die, and it's ten percent, I get excited about it.\" &nbsp;(Quoted in 'The Making of the Atomic Bomb' by Richard Rhodes.)</p>\n<p>This might look at first like a successful application of \"multiplying a low probability by a high impact\", but I would reject that this was <em>really</em>&nbsp;going on. &nbsp;Where the heck did Fermi get that 10% figure for his 'remote possibility', especially considering that fission chain reactions <em>did in fact </em>turn out to be possible? &nbsp;If some sort of reasoning had told us that a fission chain reaction was improbable, then after it turned out to be reality, good procedure would have us go back and check our reasoning to see what went wrong, and figure out how to adjust our way of thinking so as to not make the same mistake again. &nbsp;So far as I know, there was&nbsp;no physical reason whatsoever to think a fission chain reaction was only a ten percent probability. &nbsp;They had not been demonstrated experimentally, to be sure; but they were still the default projection from what was already known. &nbsp;If you'd been told in the 1930s that fission chain reactions were impossible, you would've been told something that implied new physical facts unknown to current science (and indeed, no such facts existed). &nbsp;After reading enough historical instances of famous scientists dismissing things as impossible when there was no physical logic to say that it was even improbable, one cynically suspects that some prestigious scientists perhaps came to conceive of themselves as senior people who ought to be skeptical about things, and that Fermi was just reacting emotionally. &nbsp;The lesson I draw from this historical case is not that it's a good idea to go around multiplying ten percent probabilities by large impacts, but that Fermi should not have pulled out a number as low as ten percent.</p>\n<p>Having seen enough conversations involving made-up probabilities to become cynical, I also strongly suspect that if Fermi had foreseen how Rabi would reply, Fermi would've said \"One percent\". &nbsp;If Fermi had expected Rabi to say \"One percent is not small if...\" then Fermi would've said \"One in ten thousand\" or \"Too small to consider\" - whatever he thought would get him off the hook. &nbsp;Perhaps I am being too unkind to Fermi, who was a famously great estimator; Fermi may well have performed some sort of lawful probability estimate on the spot. &nbsp;But Fermi is also the one who said that nuclear energy was fifty years off in the unlikely event it could be done at all,&nbsp;<em>two years</em>&nbsp;(IIRC) before Fermi himself oversaw the construction of the first nuclear pile. &nbsp;Where did Fermi get that fifty-year number from? &nbsp;This sort of thing does make me more likely to believe that Fermi, in playing the role of the solemn doubter, was just Making Things Up; and this is no less a sin when you make up skeptical things. &nbsp;And if this cynicism is right, then we cannot learn the lesson that it is wise to multiply small probabilities by large impacts because this is what saved Fermi - if Fermi had known the rule, if he had seen it coming, he would have just Made Up an even smaller probability to get himself off the hook. &nbsp;It would have been so very easy and convenient to say, \"One in ten thousand, there's no experimental proof and most ideas like that are wrong! &nbsp;Think of all the conjunctive probabilities that have to be true before we actually get nuclear weapons and our own efforts actually made a difference in that!\" followed shortly by \"But it's not practical to be worried about such tiny probabilities!\" &nbsp;Or maybe Fermi would've known better, but even so I have never been a fan of trying to have two mistakes cancel each other out.</p>\n<p>I mention all this because it is dangerous to be <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">half a rationalist</a>, and only stop making one of the two mistakes. &nbsp;If you are going to reject impractical 'clever arguments' that would never work in real life, and henceforth not try to multiply tiny probabilities by huge payoffs, then you had also better reject all the clever arguments that would've led Fermi or Szilard to assign probabilities much smaller than ten percent. &nbsp;(Listing out a group of conjunctive probabilities leading up to taking an important action, and not listing any disjunctive probabilities, is one widely popular way of driving down the apparent probability of just about anything.) &nbsp;Or if you would've tried to put fission chain reactions into a reference class of 'amazing new energy sources' and then assigned it a tiny probability, or put Szilard into the reference class of 'people who think the fate of the world depends on them', or pontificated about the lack of any positive experimental evidence proving that a chain reaction was possible, blah blah blah etcetera - then your error here can perhaps be compensated for by the opposite error of then trying to multiply the resulting tiny probability by a large impact.&nbsp;&nbsp;I don't like making clever mistakes that cancel each other out - I consider that idea to also be clever - but making clever mistakes that&nbsp;<em>don't</em>&nbsp;cancel out is worse.</p>\n<p>On the other hand, if you want a general heuristic that could've led Fermi to do better, I&nbsp;would suggest reasoning that previous-historical experimental proof of a chain reaction would not be strongly be expected even in worlds where it was possible, and that to discover&nbsp;a chain reaction to be&nbsp;<em>impossible&nbsp;</em>would imply learning some new fact of physical science which was not already known. &nbsp;And this is not just 20-20 hindsight; Szilard and Rabi saw the logic in advance of the fact, not just afterward - though not in those exact terms; they just saw the physical logic, and then&nbsp;<em>didn't&nbsp;</em>adjust it downward for 'absurdity' or with more complicated rationalizations. &nbsp;But then if you are going to take this sort of reasoning at face value, <em>without </em>adjusting it downward, then it's probably <em>not </em>a good idea to panic every time you assign a 0.01% probability to something big - you'll probably run into dozens of things like that, at least, and panicking over them would leave no room to wait until you found something whose face-value probability was large.</p>\n<p>I don't believe in multiplying tiny probabilities by huge impacts. &nbsp;But I also&nbsp;believe that Fermi could have done better than saying ten percent, and that it wasn't just random luck mixed with overconfidence that led Szilard and Rabi to assign higher probabilities than that. &nbsp;Or to name a modern issue which is still open, Michael Shermer should not have dismissed the possibility of molecular nanotechnology, and Eric Drexler will not have been randomly lucky when it turns out to work: taking current physical models at face value imply that molecular nanotechnology ought to work, and if it doesn't work we've learned some new fact unknown to present physics, etcetera. &nbsp;Taking the physical logic at face value is fine, and there's no need to adjust it downward for any particular reason; if you say that Eric Drexler should 'adjust' this probability downward for whatever reason, then I think you're giving him rules that predictably give him the wrong answer. &nbsp;Sometimes surface appearances are misleading, but most of the time they're <em>not</em>.</p>\n<p>A key test I apply to any supposed rule of reasoning about high-impact scenarios is, \"Does this rule screw over the planet if Reality actually hands us a high-impact scenario?\" and if the answer is yes, I discard it and move on. &nbsp;The point of rationality is to figure out which world we actually live in and adapt accordingly, not to rule out certain sorts of worlds in advance.</p>\n<p>There's a doubly-clever form of the argument wherein everyone in a plausibly high-impact position modestly attributes only a tiny potential possibility that their face-value view of the world is sane, <em>and then</em> they multiply this tiny probability by the large impact, and so they act anyway and on average worlds in trouble are saved. &nbsp;I don't think this works in real life - I don't think I would have wanted Leo Szilard to think like that. &nbsp;I think that if your brain really actually thinks that fission chain reactions have only a tiny probability of being important, you will go off and try to invent better refrigerators or something else that might make you money. &nbsp;And if your brain does not really feel that fission chain reactions have a tiny probability, then your beliefs and aliefs are out of sync and that is not something I want to see in people trying to handle the delicate issue of nuclear weapons. &nbsp;But in any case, I deny the original premise: &nbsp;I do not&nbsp;think the world's niches for heroism must be populated by heroes who are incapable in principle<em>&nbsp;</em>of reasonably distinguishing themselves from a population of crackpots, all of whom have no choice but to continue on the tiny off-chance that they are not crackpots.</p>\n<p>I haven't written enough about what I've begun thinking of as 'heroic epistemology' - why, how can you possibly be so overconfident as to dare even try to have a huge positive impact when most people in that reference class blah blah blah - but on reflection, it seems to me that an awful lot of my answer boils down to<em>&nbsp;not trying to be clever about it.</em>&nbsp; I don't multiply tiny probabilities by huge impacts. &nbsp;I also don't <em>get</em>&nbsp;tiny probabilities by putting myself into inescapable reference classes, for this is the sort of reasoning that would screw over planets that actually were in trouble if everyone thought like that. &nbsp;In the course of any workday, on the now very rare occasions I find myself thinking about such meta-level junk instead of the math at hand, I remind myself that it is a <em>wasted motion -</em>&nbsp;where a 'wasted motion' is any thought which will, in retrospect if the problem is in fact solved, not have contributed to having solved the problem. &nbsp;If someday Friendly AI is built, will it have been terribly important that someone have spent a month fretting about what reference class they're in? &nbsp;No. &nbsp;Will it, in retrospect, have been an important step along the pathway to understanding stable self-modification, if we spend time trying to solve the Lobian obstacle? &nbsp;Possibly. &nbsp;So one of these cognitive avenues is predictably a wasted motion in retrospect, and one of them is not. &nbsp;The same would hold if I spent a lot of time trying to convince myself that I was allowed to believe that I could affect anything large, or any other form of angsting about meta. &nbsp;It is predictable that in retrospect I will think this was a waste of time compared to working on a trust criterion between a probability distribution and an improved probability distribution. &nbsp;(Apologies, this is a technical thingy I'm currently working on which has no good English description.)</p>\n<p>But if you must apply clever adjustments to things, then for Belldandy's sake don't be one-sidedly clever and have all your cleverness be on the side of arguments for inaction. &nbsp;I think you're better off without all the complicated fretting - but you're definitely not better off eliminating only <em>half</em>&nbsp;of it.</p>\n<p>And finally, I once again state that I abjure, refute, and disclaim all forms of Pascalian reasoning and multiplying tiny probabilities by large impacts when it comes to existential risk. &nbsp;We live on a planet with upcoming prospects of, among other things, human intelligence enhancement, molecular nanotechnology, sufficiently advanced biotechnology, brain-computer interfaces, and of course Artificial Intelligence in several guises. &nbsp;If something has only a tiny chance of impacting the fate of the world, there should be something with a larger probability of an equally huge impact to worry about instead. &nbsp;You cannot justifiably trade off tiny probabilities of x-risk improvement against efforts that do <em>not </em>effectuate a happy intergalactic civilization, but there is nonetheless no need to go on tracking tiny probabilities when you'd expect there to be&nbsp;<em>medium-sized</em> probabilities of x-risk reduction. &nbsp;Nonetheless I try to avoid coming up with clever reasons to do stupid things, and one example of a stupid thing would be&nbsp;<em>not</em>&nbsp;working on Friendly AI when it's in blatant need of work. &nbsp;Elaborate complicated reasoning which says we should let the Friendly AI issue just stay on fire and burn merrily away, well, any complicated reasoning which returns an output this silly is automatically suspect.</p>\n<p>If, however, you are unlucky enough to have been cleverly argued into obeying rules that make it <em>a priori</em> unreachable-in-practice for anyone to end up in an epistemic state where they try to do something about a planet which appears to be on fire - so that there are no <em>more </em>plausible x-risk reduction efforts to fall back on, because you're adjusting <em>all</em>&nbsp;the high-impact probabilities&nbsp;downward from what the surface state of the world suggests...</p>\n<p>Well, <em>that </em>would only be a good idea if Reality were not allowed to hand you a planet that was in fact on fire. &nbsp;Or if, given a planet on fire, Reality was prohibited from handing you a chance to put it out. &nbsp;There is no reason to think that Reality must <em>a priori</em> obey such a constraint.</p>\n<p>EDIT: &nbsp;To clarify, \"Don't multiply tiny probabilities by large impacts\" is something that I apply to large-scale projects and lines of historical probability. &nbsp;On a very large scale, if you think FAI stands a serious chance of saving the world, then humanity should dump a bunch of effort into it, and if nobody's dumping effort into it then you should dump more effort than currently into it. &nbsp;On a smaller scale, to compare two x-risk mitigation projects in demand of money, you need to estimate something about marginal impacts of the next added effort (where the common currency of utilons should probably not be lives saved, but \"probability of an ok outcome\", i.e., the probability of ending up with a happy intergalactic civilization). &nbsp;In this case the average marginal added dollar can only account for a very tiny slice of probability, but this is not Pascal's Wager. &nbsp;Large efforts with a success-or-failure criterion are rightly, justly, and unavoidably going to end up with small marginally increased probabilities of success per added small unit of effort. &nbsp;It would only be Pascal's Wager if the whole route-to-an-OK-outcome were assigned a tiny probability, and then a large payoff used to shut down further discussion of whether the next unit of effort should go there or to a different x-risk.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"9YFoDPFwMoWthzgkY": 1, "csMv9MvvjYJyeHqoo": 1, "Rz5jb3cYHTSRmqNnN": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ebiCeBHr7At8Yyq9R", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 55, "baseScore": 55, "extendedScore": null, "score": 0.000131, "legacy": true, "legacyId": "22342", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 55, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 166, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7FzD7pNm9X68Gp5ZC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-04-18T05:20:25.235Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T12:13:12.902Z", "modifiedAt": null, "url": null, "title": "[Link] Should Psychological Neuroscience Research Be Funded?", "slug": "link-should-psychological-neuroscience-research-be-funded", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.305Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wallowinmaya", "createdAt": "2011-03-21T00:39:18.855Z", "isAdmin": false, "displayName": "David Althaus"}, "userId": "xY8DDzk6TyvRroJEo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MN2f4zdtFvD6Rb5YM/link-should-psychological-neuroscience-research-be-funded", "pageUrlRelative": "/posts/MN2f4zdtFvD6Rb5YM/link-should-psychological-neuroscience-research-be-funded", "linkUrl": "https://www.lesswrong.com/posts/MN2f4zdtFvD6Rb5YM/link-should-psychological-neuroscience-research-be-funded", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Should%20Psychological%20Neuroscience%20Research%20Be%20Funded%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Should%20Psychological%20Neuroscience%20Research%20Be%20Funded%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMN2f4zdtFvD6Rb5YM%2Flink-should-psychological-neuroscience-research-be-funded%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Should%20Psychological%20Neuroscience%20Research%20Be%20Funded%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMN2f4zdtFvD6Rb5YM%2Flink-should-psychological-neuroscience-research-be-funded", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMN2f4zdtFvD6Rb5YM%2Flink-should-psychological-neuroscience-research-be-funded", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 678, "htmlBody": "<p><a href=\"http://popsych.org/should-psychological-neuroscience-research-be-funded/\">In this post</a>, Jesse Marczyk argues that psychological neuroscience research often doesn't add much value per dollar spent and therefore is not worth the cost.</p>\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; line-height: 14.666666984558105px;\">In my last post, when discussing some research by Singer et al (2006), I mentioned as an aside that their use of fMRI data didn&rsquo;t seem to add a whole lot to their experiment. Yes, they found that brain regions associated with empathy appear to be less active in men watching a confederate who behaved unfairly towards them receive pain; they also found that areas associated with reward seemed slightly more active. Neat; but what did that add beyond what a pencil and paper or behavioral measure might? That is, let&rsquo;s say the authors (all six of them) had subjects interact with a confederate who behaved unfairly towards them. This confederate then received a healthy dose of pain. Afterwards, the subjects were asked two questions: (1) how bad do you feel for the confederate and (2) how happy are you about what happened to them? This sounds fairly simple, likely because, well, it&nbsp;</span><em style=\"border: 0px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; color: #373737; line-height: 14.666666984558105px;\">is</em><span style=\"color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; line-height: 14.666666984558105px;\">&nbsp;fairly simple. It&rsquo;s also incredibly&nbsp;</span><em style=\"border: 0px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; color: #373737; line-height: 14.666666984558105px;\">cheap</em><span style=\"color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; line-height: 14.666666984558105px;\">, and pretty much a replication of what the authors did. The only difference is the lack of a brain scan. The question becomes, without the fMRI, how much worse is this study?</span></p>\n</blockquote>\n<blockquote>\n<p><span style=\"color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; line-height: 14.666666984558105px;\">There are two crucial questions in mind, when it comes to the above question. The first is a matter of new information: how much new and useful information has the neuroscience data given us? The second is a matter of bang-for-your-buck: how much did that neuroscience information cost? Putting the two questions together,we have the following:&nbsp;</span><em style=\"border: 0px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; color: #373737; line-height: 14.666666984558105px;\">how much additional information (in whatever unit information comes in) did we get from this study per dollar spent?</em></p>\n</blockquote>\n<blockquote>\n<p><em style=\"border: 0px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; color: #373737; line-height: 14.666666984558105px;\">...</em><span style=\"color: #373737; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; line-height: 14.666666984558105px;\">I&rsquo;ll begin my answer to it with a thought experiment: let&rsquo;s say you ran the initial same study as Singer et al did, and in addition to your short questionnaire you put people into an fMRI machine and got brain scans. In the first imaginary world, we obtained results identical to what Singer et al reported: areas thought to be related to empathy decrease in activation, areas thought to be related to pleasure increase in activation. The interpretation of these results seems fairly straightforward &ndash; that is, until one considers the second imaginary world. In this second world, we see the results of brain scan show the reverse pattern: specifically, areas thought to be related to empathy show an increase in activation and areas associated with reward show a decrease. The trick to this thought experiment, however, is that the survey responses remain the same; the only differences between the two worlds are the brain pictures.</span></p>\n</blockquote>\n<blockquote>\n<p style=\"border: 0px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; margin: 0px 0px 1.625em; outline: 0px; padding: 0px; vertical-align: baseline; color: #373737; line-height: 14.666666984558105px;\">This makes interpreting our results rather difficult. In the second world, do we conclude that the survey responses are, in some sense, wrong? The subjects&nbsp;<em style=\"border: 0px; font-family: inherit; font-size: 14px; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline;\">&ldquo;really&rdquo;</em>&nbsp;feel bad about the confederates being hurt, but they are&nbsp;<em style=\"border: 0px; font-family: inherit; font-size: 14px; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline;\">unaware</em>&nbsp;of it? This strikes me as a bit off, as far as conclusions go. Another route might be to suggest that our knowledge of what areas of the brain are associated with empathy and pleasure is somehow off: maybe increased activation means&nbsp;<em style=\"border: 0px; font-family: inherit; font-size: 14px; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline;\">less</em>&nbsp;empathy, or maybe empathy is processed elsewhere in the brain, or some other cognitive process is interfering. Hell; maybe it&rsquo;s possible that the technology employed by fMRIs&nbsp;<a style=\"border: 0px; font-family: inherit; font-size: 14px; font-style: inherit; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; color: #6585d4;\" href=\"http://www.psychologyinaction.org/2011/11/09/fmri-the-wonder-machine/\">just isn&rsquo;t sensitive to what you&rsquo;re trying to look at</a>. Though the brain scan might have highlighted our ignorance as to how the brain is working in that case, it didn&rsquo;t help us to resolve it. Further, that the second interpretative route seems like a more reasonable one than the first, it also brings to our attention a perhaps under-appreciated fact: we would be privileging the results of the survey measure above the results of the brain scan.</p>\n</blockquote>\n<blockquote>\n<p style=\"border: 0px; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; margin: 0px 0px 1.625em; outline: 0px; padding: 0px; vertical-align: baseline; color: #373737; line-height: 14.666666984558105px;\">...<span style=\"font-size: 14px; line-height: 14.666666984558105px;\">While such a thought experiment does not definitely answer the question of how much value is added by neuroscience information in psychology, it provides a tentative starting position: not the majority. The bulk of the valuable information in the study came from the survey, and all the subsequent brain information was interpreted in light of it.</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MN2f4zdtFvD6Rb5YM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 5, "extendedScore": null, "score": 1.172427034533985e-06, "legacy": true, "legacyId": "22347", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T13:20:23.564Z", "modifiedAt": null, "url": null, "title": "Meetup : Moscow, Measurements", "slug": "meetup-moscow-measurements", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.646Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Xh5JqqdLDmyCJM8hv/meetup-moscow-measurements", "pageUrlRelative": "/posts/Xh5JqqdLDmyCJM8hv/meetup-moscow-measurements", "linkUrl": "https://www.lesswrong.com/posts/Xh5JqqdLDmyCJM8hv/meetup-moscow-measurements", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Moscow%2C%20Measurements&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Moscow%2C%20Measurements%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXh5JqqdLDmyCJM8hv%2Fmeetup-moscow-measurements%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Moscow%2C%20Measurements%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXh5JqqdLDmyCJM8hv%2Fmeetup-moscow-measurements", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXh5JqqdLDmyCJM8hv%2Fmeetup-moscow-measurements", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 162, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lr'>Moscow, Measurements</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 April 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Short presentations. Two or three people will tell us about something interesting.</p></li>\n<li><p>Practical rationality. We will train useful skills.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lr'>Moscow, Measurements</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Xh5JqqdLDmyCJM8hv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 1.1724737947479303e-06, "legacy": true, "legacyId": "22348", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Moscow__Measurements\">Discussion article for the meetup : <a href=\"/meetups/lr\">Moscow, Measurements</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 April 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Short presentations. Two or three people will tell us about something interesting.</p></li>\n<li><p>Practical rationality. We will train useful skills.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Moscow__Measurements1\">Discussion article for the meetup : <a href=\"/meetups/lr\">Moscow, Measurements</a></h2>", "sections": [{"title": "Discussion article for the meetup : Moscow, Measurements", "anchor": "Discussion_article_for_the_meetup___Moscow__Measurements", "level": 1}, {"title": "Discussion article for the meetup : Moscow, Measurements", "anchor": "Discussion_article_for_the_meetup___Moscow__Measurements1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T20:01:24.746Z", "modifiedAt": null, "url": null, "title": "Meetup : mistake", "slug": "meetup-mistake", "viewCount": null, "lastCommentedAt": "2017-06-17T04:10:59.362Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "newguy", "createdAt": "2013-04-10T21:19:53.864Z", "isAdmin": false, "displayName": "newguy"}, "userId": "jaB5hYjYycqSwjdCj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xLPZ8NLTjyFPjgwy4/meetup-mistake", "pageUrlRelative": "/posts/xLPZ8NLTjyFPjgwy4/meetup-mistake", "linkUrl": "https://www.lesswrong.com/posts/xLPZ8NLTjyFPjgwy4/meetup-mistake", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20mistake&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20mistake%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxLPZ8NLTjyFPjgwy4%2Fmeetup-mistake%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20mistake%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxLPZ8NLTjyFPjgwy4%2Fmeetup-mistake", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxLPZ8NLTjyFPjgwy4%2Fmeetup-mistake", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 36, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ls'>mistake</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 July 2013 04:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">mistake</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>made this by mistake and can't eliminate it, can anyone do that? thank you, and sorry</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ls'>mistake</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xLPZ8NLTjyFPjgwy4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "22350", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___mistake\">Discussion article for the meetup : <a href=\"/meetups/ls\">mistake</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 July 2013 04:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">mistake</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>made this by mistake and can't eliminate it, can anyone do that? thank you, and sorry</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___mistake1\">Discussion article for the meetup : <a href=\"/meetups/ls\">mistake</a></h2>", "sections": [{"title": "Discussion article for the meetup : mistake", "anchor": "Discussion_article_for_the_meetup___mistake", "level": 1}, {"title": "Discussion article for the meetup : mistake", "anchor": "Discussion_article_for_the_meetup___mistake1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T20:06:06.144Z", "modifiedAt": null, "url": null, "title": "Meetup : Vienna meetup #3", "slug": "meetup-vienna-meetup-3", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.644Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ratcourse", "createdAt": "2012-11-03T10:26:05.641Z", "isAdmin": false, "displayName": "Ratcourse"}, "userId": "qwnfbBpAcbxLT4JBr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pCgMhTW4hdZJ6pBuP/meetup-vienna-meetup-3", "pageUrlRelative": "/posts/pCgMhTW4hdZJ6pBuP/meetup-vienna-meetup-3", "linkUrl": "https://www.lesswrong.com/posts/pCgMhTW4hdZJ6pBuP/meetup-vienna-meetup-3", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vienna%20meetup%20%233&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vienna%20meetup%20%233%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCgMhTW4hdZJ6pBuP%2Fmeetup-vienna-meetup-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vienna%20meetup%20%233%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCgMhTW4hdZJ6pBuP%2Fmeetup-vienna-meetup-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCgMhTW4hdZJ6pBuP%2Fmeetup-vienna-meetup-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lt'>Vienna meetup #3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 May 2013 04:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rathausstra\u00dfe 6, 1010 Wien {Vienna, Austria}</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Our own Villiam Bur will give a short lecture on which discussion will be focused. \nIt is happening in the metalab.\nhttps://metalab.at/wiki/Lage</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lt'>Vienna meetup #3</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pCgMhTW4hdZJ6pBuP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.1727562663420715e-06, "legacy": true, "legacyId": "22351", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vienna_meetup__3\">Discussion article for the meetup : <a href=\"/meetups/lt\">Vienna meetup #3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 May 2013 04:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rathausstra\u00dfe 6, 1010 Wien {Vienna, Austria}</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Our own Villiam Bur will give a short lecture on which discussion will be focused. \nIt is happening in the metalab.\nhttps://metalab.at/wiki/Lage</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vienna_meetup__31\">Discussion article for the meetup : <a href=\"/meetups/lt\">Vienna meetup #3</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vienna meetup #3", "anchor": "Discussion_article_for_the_meetup___Vienna_meetup__3", "level": 1}, {"title": "Discussion article for the meetup : Vienna meetup #3", "anchor": "Discussion_article_for_the_meetup___Vienna_meetup__31", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T22:36:36.295Z", "modifiedAt": null, "url": null, "title": "Meetup : Durham/RTLW HPMoR discussion, ch. 56-60", "slug": "meetup-durham-rtlw-hpmor-discussion-ch-56-60", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.642Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AeneYmNh47Qb9W9G5/meetup-durham-rtlw-hpmor-discussion-ch-56-60", "pageUrlRelative": "/posts/AeneYmNh47Qb9W9G5/meetup-durham-rtlw-hpmor-discussion-ch-56-60", "linkUrl": "https://www.lesswrong.com/posts/AeneYmNh47Qb9W9G5/meetup-durham-rtlw-hpmor-discussion-ch-56-60", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2056-60&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2056-60%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAeneYmNh47Qb9W9G5%2Fmeetup-durham-rtlw-hpmor-discussion-ch-56-60%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2056-60%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAeneYmNh47Qb9W9G5%2Fmeetup-durham-rtlw-hpmor-discussion-ch-56-60", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAeneYmNh47Qb9W9G5%2Fmeetup-durham-rtlw-hpmor-discussion-ch-56-60", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lu'>Durham/RTLW HPMoR discussion, ch. 56-60</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 April 2013 12:30:30PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">726 Rigsbee Avenue, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at Fullsteam about 12:30 for discussion of HPMoR chapters 56-60!</p>\n\n<p>Feel free to bring food and or coffee from surrounding establishments.</p>\n\n<p>Probably sometime midafternoon we'll adjourn from Fullsteam for a hike along the Eno. Join the RTLW Google group (<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>) for contact info/details/etc.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lu'>Durham/RTLW HPMoR discussion, ch. 56-60</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AeneYmNh47Qb9W9G5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.1728610829116659e-06, "legacy": true, "legacyId": "22352", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__56_60\">Discussion article for the meetup : <a href=\"/meetups/lu\">Durham/RTLW HPMoR discussion, ch. 56-60</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 April 2013 12:30:30PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">726 Rigsbee Avenue, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at Fullsteam about 12:30 for discussion of HPMoR chapters 56-60!</p>\n\n<p>Feel free to bring food and or coffee from surrounding establishments.</p>\n\n<p>Probably sometime midafternoon we'll adjourn from Fullsteam for a hike along the Eno. Join the RTLW Google group (<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>) for contact info/details/etc.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__56_601\">Discussion article for the meetup : <a href=\"/meetups/lu\">Durham/RTLW HPMoR discussion, ch. 56-60</a></h2>", "sections": [{"title": "Discussion article for the meetup : Durham/RTLW HPMoR discussion, ch. 56-60", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__56_60", "level": 1}, {"title": "Discussion article for the meetup : Durham/RTLW HPMoR discussion, ch. 56-60", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__56_601", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T23:26:30.330Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge: The Meaning Of Life For Beginners", "slug": "meetup-cambridge-the-meaning-of-life-for-beginners", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.639Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zkPxDcToJvjKEa9XF/meetup-cambridge-the-meaning-of-life-for-beginners", "pageUrlRelative": "/posts/zkPxDcToJvjKEa9XF/meetup-cambridge-the-meaning-of-life-for-beginners", "linkUrl": "https://www.lesswrong.com/posts/zkPxDcToJvjKEa9XF/meetup-cambridge-the-meaning-of-life-for-beginners", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%3A%20The%20Meaning%20Of%20Life%20For%20Beginners&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%3A%20The%20Meaning%20Of%20Life%20For%20Beginners%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzkPxDcToJvjKEa9XF%2Fmeetup-cambridge-the-meaning-of-life-for-beginners%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%3A%20The%20Meaning%20Of%20Life%20For%20Beginners%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzkPxDcToJvjKEa9XF%2Fmeetup-cambridge-the-meaning-of-life-for-beginners", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzkPxDcToJvjKEa9XF%2Fmeetup-cambridge-the-meaning-of-life-for-beginners", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 113, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lv'>Cambridge: The Meaning Of Life For Beginners</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 April 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">21 Ames St, Cambridge, MA, 02139</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups are at 2 PM on the first and third Sunday of every month at the MIT Whitaker Building [21 Ames St, Bldg 56], room 180. Room number subject to change based on availability. Signs will be posted with the actual room number.</p>\n\n<p>This meetup's theme is figuring out which things are most important to you and how to weigh them against one another. RSVPs at the <a href=\"http://www.meetup.com/Cambridge-Less-Wrong-Meetup/\" rel=\"nofollow\">meetup site</a> are nice but not required.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lv'>Cambridge: The Meaning Of Life For Beginners</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zkPxDcToJvjKEa9XF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 1.1728958390661938e-06, "legacy": true, "legacyId": "22353", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge__The_Meaning_Of_Life_For_Beginners\">Discussion article for the meetup : <a href=\"/meetups/lv\">Cambridge: The Meaning Of Life For Beginners</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 April 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">21 Ames St, Cambridge, MA, 02139</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cambridge/Boston-area Less Wrong meetups are at 2 PM on the first and third Sunday of every month at the MIT Whitaker Building [21 Ames St, Bldg 56], room 180. Room number subject to change based on availability. Signs will be posted with the actual room number.</p>\n\n<p>This meetup's theme is figuring out which things are most important to you and how to weigh them against one another. RSVPs at the <a href=\"http://www.meetup.com/Cambridge-Less-Wrong-Meetup/\" rel=\"nofollow\">meetup site</a> are nice but not required.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge__The_Meaning_Of_Life_For_Beginners1\">Discussion article for the meetup : <a href=\"/meetups/lv\">Cambridge: The Meaning Of Life For Beginners</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge: The Meaning Of Life For Beginners", "anchor": "Discussion_article_for_the_meetup___Cambridge__The_Meaning_Of_Life_For_Beginners", "level": 1}, {"title": "Discussion article for the meetup : Cambridge: The Meaning Of Life For Beginners", "anchor": "Discussion_article_for_the_meetup___Cambridge__The_Meaning_Of_Life_For_Beginners1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-18T23:48:03.973Z", "modifiedAt": null, "url": null, "title": "Meetup : London Meetup, 28th April", "slug": "meetup-london-meetup-28th-april", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.970Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "philh", "createdAt": "2011-06-21T10:04:52.011Z", "isAdmin": false, "displayName": "philh"}, "userId": "nrP5EZZj4vRvYwQ7b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TFReLYhevuo66PfwC/meetup-london-meetup-28th-april", "pageUrlRelative": "/posts/TFReLYhevuo66PfwC/meetup-london-meetup-28th-april", "linkUrl": "https://www.lesswrong.com/posts/TFReLYhevuo66PfwC/meetup-london-meetup-28th-april", "postedAtFormatted": "Thursday, April 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Meetup%2C%2028th%20April&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Meetup%2C%2028th%20April%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTFReLYhevuo66PfwC%2Fmeetup-london-meetup-28th-april%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Meetup%2C%2028th%20April%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTFReLYhevuo66PfwC%2Fmeetup-london-meetup-28th-april", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTFReLYhevuo66PfwC%2Fmeetup-london-meetup-28th-april", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lw'>London Meetup, 28th April</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 April 2013 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Holborn, London</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>A fortnightly meetup in the <a href=\"http://maps.google.ca/maps?q=Shakespeare%27s+Head,+Africa+House,+64-68+Kingsway,+Holborn,+London+WC2B+6BG,+United+Kingdom&amp;hl=en&amp;ll=51.516862,-0.119648&amp;spn=0.005141,0.013604&amp;sll=51.520547,-0.117545&amp;sspn=0.010281,0.027208&amp;hq=Shakespeare%27s+Head,+Africa+House,+64-68+Kingsway,+Holborn,+London+WC2B+6BG,+United+Kingdom&amp;radius=15000&amp;t=m&amp;z=16\" rel=\"nofollow\">Shakespeare&#39;s Head pub</a> by Holborn tube station. We meet every other Sunday at 2pm.</p>\n\n<p>Everyone is welcome to attend: we're a friendly group and we don't bite. If you're on the fence about coming, err on the side of showing up. It's probably safe to assume that we'd like to meet you.</p>\n\n<p>We also have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google group</a>.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lw'>London Meetup, 28th April</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TFReLYhevuo66PfwC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "22354", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Meetup__28th_April\">Discussion article for the meetup : <a href=\"/meetups/lw\">London Meetup, 28th April</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 April 2013 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Holborn, London</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>A fortnightly meetup in the <a href=\"http://maps.google.ca/maps?q=Shakespeare%27s+Head,+Africa+House,+64-68+Kingsway,+Holborn,+London+WC2B+6BG,+United+Kingdom&amp;hl=en&amp;ll=51.516862,-0.119648&amp;spn=0.005141,0.013604&amp;sll=51.520547,-0.117545&amp;sspn=0.010281,0.027208&amp;hq=Shakespeare%27s+Head,+Africa+House,+64-68+Kingsway,+Holborn,+London+WC2B+6BG,+United+Kingdom&amp;radius=15000&amp;t=m&amp;z=16\" rel=\"nofollow\">Shakespeare's Head pub</a> by Holborn tube station. We meet every other Sunday at 2pm.</p>\n\n<p>Everyone is welcome to attend: we're a friendly group and we don't bite. If you're on the fence about coming, err on the side of showing up. It's probably safe to assume that we'd like to meet you.</p>\n\n<p>We also have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google group</a>.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_Meetup__28th_April1\">Discussion article for the meetup : <a href=\"/meetups/lw\">London Meetup, 28th April</a></h2>", "sections": [{"title": "Discussion article for the meetup : London Meetup, 28th April", "anchor": "Discussion_article_for_the_meetup___London_Meetup__28th_April", "level": 1}, {"title": "Discussion article for the meetup : London Meetup, 28th April", "anchor": "Discussion_article_for_the_meetup___London_Meetup__28th_April1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-19T15:14:15.635Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Atlanta, London, Moscow, Vienna", "slug": "weekly-lw-meetups-atlanta-london-moscow-vienna", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.634Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/77TLGj3A4q4izdj3f/weekly-lw-meetups-atlanta-london-moscow-vienna", "pageUrlRelative": "/posts/77TLGj3A4q4izdj3f/weekly-lw-meetups-atlanta-london-moscow-vienna", "linkUrl": "https://www.lesswrong.com/posts/77TLGj3A4q4izdj3f/weekly-lw-meetups-atlanta-london-moscow-vienna", "postedAtFormatted": "Friday, April 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Atlanta%2C%20London%2C%20Moscow%2C%20Vienna&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Atlanta%2C%20London%2C%20Moscow%2C%20Vienna%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F77TLGj3A4q4izdj3f%2Fweekly-lw-meetups-atlanta-london-moscow-vienna%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Atlanta%2C%20London%2C%20Moscow%2C%20Vienna%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F77TLGj3A4q4izdj3f%2Fweekly-lw-meetups-atlanta-london-moscow-vienna", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F77TLGj3A4q4izdj3f%2Fweekly-lw-meetups-atlanta-london-moscow-vienna", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 462, "htmlBody": "<p><strong>This summary was posted to LW main on April 12th. The following week's summary is <a href=\"/lw/h94/weekly_lw_meetups_atlanta_austin_berlin_brussels/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/k9\">Vienna Meetup #2:&nbsp;<span class=\"date\">13 April 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/lc\">London Meetup, 14th April: Hedonic hacks:&nbsp;<span class=\"date\">14 April 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/l4\">Moscow, Applied Rationality, take two:&nbsp;<span class=\"date\">14 April 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/le\">April Atlanta Meetup! Friday, April 19th:&nbsp;<span class=\"date\">19 April 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/lf\">Cincinnati near-Schelling day:&nbsp;<span class=\"date\">21 April 2013 04:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/l9\"></a><span class=\"date\">None this week!</span></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong></strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "77TLGj3A4q4izdj3f", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.1735563131342112e-06, "legacy": true, "legacyId": "22287", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wvDERsYwz2rhKgKKA", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-19T18:13:45.279Z", "modifiedAt": null, "url": null, "title": "Bitcoins are not digital greenbacks", "slug": "bitcoins-are-not-digital-greenbacks", "viewCount": null, "lastCommentedAt": "2017-06-16T00:43:23.945Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lsparrish", "createdAt": "2010-06-30T19:05:11.515Z", "isAdmin": false, "displayName": "lsparrish"}, "userId": "xgc8giekPig6tYf2X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P9jggxRZTMJcjnaPw/bitcoins-are-not-digital-greenbacks", "pageUrlRelative": "/posts/P9jggxRZTMJcjnaPw/bitcoins-are-not-digital-greenbacks", "linkUrl": "https://www.lesswrong.com/posts/P9jggxRZTMJcjnaPw/bitcoins-are-not-digital-greenbacks", "postedAtFormatted": "Friday, April 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bitcoins%20are%20not%20digital%20greenbacks&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABitcoins%20are%20not%20digital%20greenbacks%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP9jggxRZTMJcjnaPw%2Fbitcoins-are-not-digital-greenbacks%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bitcoins%20are%20not%20digital%20greenbacks%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP9jggxRZTMJcjnaPw%2Fbitcoins-are-not-digital-greenbacks", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP9jggxRZTMJcjnaPw%2Fbitcoins-are-not-digital-greenbacks", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1465, "htmlBody": "<h2>Should you probably donate a bitcoin to your future self?<br /></h2>\n<p>Bitcoin has been in the news a bit lately. In case anyone hasn't been following recent events, its <a href=\"http://bitcoinwatch.com/\">price</a> hit $266 per coin, toppled to $50, and then climbed back to a rate which has been between $80 and $140.</p>\n<p>This goes to show its high <em>volatility</em> at the present time, which means that any individual trade you make will be something of a gamble with a noisy, hard-to-predict outcome. You could be buying in right before a boom or a bust. Buying and then selling at random intervals will probably cost you more money than you make, due to transaction fees. Trying to outsmart the market in the short term with nothing but your own human instincts and powers of induction will probably cost you even more money because <a href=\"/lw/yv/markets_are_antiinductive/\">Markets are anti-inductive</a>. The most realistic way of making much money with bitcoin -- sans owning your own exchange, having skill and resources for serious technical analysis, a faster-than-usual trading bot, or fantastic luck -- is if you can determine that the current price is <em>very poorly calibrated</em> relative to its future value, and if you buy and hold very long-term.</p>\n<p>Market swings constitute a psychological attack, assuming you know and care about them, so employing the buy-and-hold strategy can be more difficult than it looks. However, as it happens, you can render bitcoins almost purely unspendable (i.e. impossible to transfer via the network) for a finite period of time as a technical matter. You could for example create a <a href=\"http://bitcoinmagazine.com/brain-wallets-the-what-and-the-how/\">brainwallet</a> based on a lengthy memorized passphrase with a random value appended to it. The larger that appended value, the (exponentially) greater the amount of processing time needs to be spent to find out what it contains. Having access to the memorized passphrase gives you the overwhelming advantage over a brute force attacker, whereas the appended random value immunizes it against dictionary attacks. (Todo: Find or write a program for this. Prove it works, and move some of my bitcoin holdings to a wallet requiring a day or more to unlock.)</p>\n<p>Early adopters with moderate crypto skills could thus have a distinct advantage compared to the average investor and realistically hope to beat the market on that basis <em>if</em> mere human psychology and resistance against short term panic-selling is the fundamental constraint. So that's one consideration that could play to our advantage. Assuming, that is, that bitcoin is worth taking seriously to begin with, and not just a matter of geeky fun.</p>\n<p>The question that matters for that consideration (the one that differentiates long term speculation on bitcoin from various speculative bubbles in gold, real estate, tulips, etc.) is this: Of all the possible worlds, where is the probability mass concentrated with respect to the future of bitcoin, in terms of how it will actually be used? Is there an <em>overwhelming </em>tendency for bitcoin to fail and be replaced by other things (e.g. other cryptocurrencies, or fiat dollars) -- or is it actually <em>likely</em> (in at least the minimal sense of \"not overwhelmingly unlikely\") to turn into a major store of wealth in coming decades?</p>\n<p>I rather think it is the latter. But first, let's consider what I believe to be the strongest <a href=\"http://www.forbes.com/sites/steveforbes/2013/04/16/bitcoin-whatever-it-is-its-not-money/\">argument</a> <a href=\"http://www.slate.com/articles/news_and_politics/view_from_chicago/2013/04/bitcoin_is_a_ponzi_scheme_the_internet_currency_will_collapse.html\">against</a> it, which unpacks to three parts:</p>\n<ol>\n<li><strong>Deflation</strong>. Bitcoin will never be more than 21 million coins strong due to the production rate going down by half every 4 years. That implies that it will always deflate, i.e. there will be less available to buy as time goes on.</li>\n<li><strong>Volatility</strong>. This is the natural result of deflation. As scarcity increases, people buy out of the speculative belief that value will rise forever. They fear to spend because really, who wants to have bought a <a href=\"https://bitcointalk.org/index.php?topic=137.msg1195#msg1195\">million dollar pizza</a>? Eventually, when enough of the value is due solely to this belief in future growth, people abruptly begin to sell, and the bubble bursts.</li>\n<li><strong>Distrust</strong>. Currency requires trust. Volatility decreases trust. If bitcoins continue to be volatile, because of deflation, which is built into the system, it cannot be trusted well enough to compete with more stable currencies -- and will therefore eventually die out.</li>\n</ol>\n<p>Taken together, this seems like a pretty good knock-down argument. It apparently implies, as a matter of basic economic law, that some other cryptocurrency must win over it in the long term, and/or that fiat money will retain its dominance. But the thing to notice is that it's not so effective against bitcoin as a massive store of <em>wealth</em> per se, so much as a <em>currency</em> that will be directly used, in a manner directly analogous to how government-backed monetary units are used. Non-currency forms of wealth which serve some other purpose can safely handle quite a bit more volatility, because their value is not dependent on being trusted as a currency, but rather as a value storage mechanism.</p>\n<p>Here is the general scenario that I think holds more probability mass than bitcoin-as-a-traditional-currency, and yet works as a fairly realistic alternative to bitcoin-as-a-flop:</p>\n<ul>\n<li>Bitcoin will fall out of circulation as a currency because of its relative volatility.</li>\n<li>Nonetheless, alternate currencies will be built into the blockchain.</li>\n<li>These alternate currencies will be designed for stability, instead of deflation.</li>\n<li>Mechanisms for trading alternate currencies for bitcoins will be part of the protocol.</li>\n<li>Rather than a currency, bitcoin plays a role as a scarce, fungible, stabilizing commodity.</li>\n<li>The ease of turning it into these successful alternate currencies gives it the ability to outcompete traditional options like gold.</li>\n</ul>\n<p>Can this be done? Consider the following more specific scenario as an example:</p>\n<ol>\n<li>Alice puts 100 bitcoins in a currency wallet denoted \"dollars\".</li>\n<li>Alice withdraws 10,000 of a currency called \"dollars\" from an associated address.</li>\n<li>The network knows that there are 100 times as many dollars as bitcoin, and makes a note of this.</li>\n<li>The network will not allow Alice to withdraw bitcoins from the currency wallet until she replaces the dollars.</li>\n<li>Bob puts 99 bitcoins in a currency wallet also denoted \"dollars\"</li>\n<li>Bob withdraws 10000 dollars from it.</li>\n<li>In the event that Alice replaced her dollars and withdrew her bitcoins quickly, the network recognizes this as valid. But in the event that she did not, the dollar is recognized as having more value and the network will not permit Bob to withdraw that amount unless he has 101 bitcoins in the wallet.</li>\n</ol>\n<p>This is just one example I've come up with, and may not be the best. Various other schemes are possible. (For example, it could be possible for any dollar-owner to convert them back to bitcoin, as opposed to the person who originally minted them.) What the various possible models for doing this have in common is that they allow you to set up currencies which dynamically increase and decrease in supply, depending on how much bitcoin people are willing to invest into them, and how badly people want bitcoins back later on.</p>\n<p>A competing scenario to the above would be one in which a better-optimized cryptocurrency protocol implements this, or some other stability-prone algorithm and thus outcompetes the volatile, easily manipulated, \"primitive\" bitcoin protocol in use today. I used to think I could just jump on the bandwagon when this comes around, maybe strategically sell someone a pizza and end up a millionaire.</p>\n<p>However, I've somewhat lost faith in that possibility of late because I realized that bitcoin is much more powerful than it seems, and is capable of substantial self-modification if needed for compatibility with a newer and better system. The only thing locking us to the current protocol is the degree to which bitcoin-owning miners find it in their best interests to continue to use it as it is. A competing algorithm that makes bitcoins more valuable without violating existing expectations would probably not be hard to get people to update to.</p>\n<p>Another thing that makes me think bitcoin will tend to self-improve to the point of winning against competitors is that at least some people with substantial assets in bitcoin form are likely to be very proactive in defense thereof. Assuming they remain committed to the long game, and are able to acquire sufficient short-term wealth to pursue their goals, they can do a number of things to defend it against the various plausible attacks: Hiring programmers to improve the client software and render it less hackable, hiring lobbyists to protect it against regulatory interference, employing botnets to attack competitor currencies, slowing down or preventing transactions that appear to be going through anonymizing laundries that could be associated with tax-dodging and illegal drugs, and so forth.</p>\n<p>So it seems to me like owning at least one bitcoin and holding onto it for long-term purposes is <em>probably</em> a good idea.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P9jggxRZTMJcjnaPw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 11, "extendedScore": null, "score": 1.1736814735430408e-06, "legacy": true, "legacyId": "22355", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 163, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["h24JGbmweNpWZfBkM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-04-19T18:13:45.279Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-19T20:43:52.172Z", "modifiedAt": null, "url": null, "title": "Metatickle Intelligence Metrics and Friendly Utility Functions", "slug": "metatickle-intelligence-metrics-and-friendly-utility", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:23.056Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Squark", "createdAt": "2013-02-04T19:29:04.489Z", "isAdmin": false, "displayName": "Squark"}, "userId": "k4QpNYXcigqfG85t6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cL3ATdvGZ5kTy8AB4/metatickle-intelligence-metrics-and-friendly-utility", "pageUrlRelative": "/posts/cL3ATdvGZ5kTy8AB4/metatickle-intelligence-metrics-and-friendly-utility", "linkUrl": "https://www.lesswrong.com/posts/cL3ATdvGZ5kTy8AB4/metatickle-intelligence-metrics-and-friendly-utility", "postedAtFormatted": "Friday, April 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Metatickle%20Intelligence%20Metrics%20and%20Friendly%20Utility%20Functions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMetatickle%20Intelligence%20Metrics%20and%20Friendly%20Utility%20Functions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcL3ATdvGZ5kTy8AB4%2Fmetatickle-intelligence-metrics-and-friendly-utility%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Metatickle%20Intelligence%20Metrics%20and%20Friendly%20Utility%20Functions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcL3ATdvGZ5kTy8AB4%2Fmetatickle-intelligence-metrics-and-friendly-utility", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcL3ATdvGZ5kTy8AB4%2Fmetatickle-intelligence-metrics-and-friendly-utility", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1486, "htmlBody": "<p>Related to: <a href=\"/lw/h4x/intelligence_metrics_and_decision_theories/\">Intelligence Metrics and Decision Theories </a></p>\n<p>Previously I presented a formalism for dealing with the <a href=\"http://wiki.lesswrong.com/wiki/Anvil_problem\">Duality</a> and <a href=\"/lw/cze/reply_to_holden_on_tool_ai/70rt\">Ontology</a> problems associated with attempts to define a formal metric of general intelligence. It also solves the <a href=\"/lw/h4x/intelligence_metrics_and_decision_theories/8ptd\">environment distribution problem</a>. This formalism ran into problems closely related to the problems of <a href=\"http://wiki.lesswrong.com/wiki/Decision_theory\">decision theory</a>. I tried to solve these problems using a formalization of <a href=\"http://wiki.lesswrong.com/wiki/UDT\">UDT</a> suitable for this context.</p>\n<p>Here I'm going to pursue a different approach, which I believe to be analogous to the \"metatickle\" version of <a href=\"http://wiki.lesswrong.com/wiki/Evidential_Decision_Theory\">EDT</a>. I will argue that, as opposed to decision theory, metatickling is a good approach to intelligence metrics. I will also present an analogous formalism for multi-agent systems. Finally, I will suggest an approach for constructing <a href=\"http://wiki.lesswrong.com/wiki/Friendly_Artificial_Intelligence\">friendly</a> utility functions using this formalism.</p>\n<h1>Review of Quasi-Solomonoff Distributions</h1>\n<p>In this section I will remind the idea behind quasi-Solomonoff distributions, glossing over mathematical details. For more details consult the <a href=\"/lw/h4x/intelligence_metrics_and_decision_theories/\">previous article</a>.</p>\n<p>Most attempts at constructing a formal general intelligence metric are based on <a href=\"http://arxiv.org/abs/0712.3329\">Legg and Hutter</a> and involve considering an agent A interacting with an environment V through <em>actions</em> that A applies to V and <em>observations</em><strong> </strong>A makes on V (the latter being information flowing from V to A). The problem with this is that such an agent is indestructible since no process in V can force a change in the inner workings of A. Thus an AI programmed in accord with this formalism will consider it an a priori truth that its mind cannot be tampered with in any way, an obviously false assumption.</p>\n<p>In order to deal with this we can make A a part of V, as suggested by <a href=\"http://agi-conference.org/2012/wp-content/uploads/2012/12/paper_76.pdf\">Orseau and Ring</a>. This creates another problem, namely it's unclear what prior for V should we use. <a href=\"http://arxiv.org/abs/0712.3329\">Legg and Hutter</a> suggest using the Solomonoff distribution which makes sense since a perfectly rational agent is supposed to use the Solomonoff distribution as a prior. However, if A is a part of V, the Solomonoff distribution is clearly too general. For example if our A is implemented on a computing machine M, the rules according to which M works have to be part of our assumptions about V, since without making such assumptions it is impossible to program M in any sensible way.</p>\n<p>Enters the quasi-Solomonoff distribution. Suppose you are a programmer building an AI A. Then it makes sense for you to impart to A the knowledge you have about the universe, including at least the rules according to which A's hardware M works. Denoting this knowledge (the <em>tenative model</em>) D, the distribution to use is the Solomonoff distribution updated by a period <strong>t</strong> of observing D-behavior, where the time parameter <strong>t</strong> represents your own certainty about D.</p>\n<p>It is now tempting to introduce the intelligence metric</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_%7BEDT%7D%28Q%29%20=%20E%5BU%28%5Clbrace%20%5Cupsilon_i%20%5Crbrace%29%7Cq%28%5Cupsilon_t%29=Q%5D\" alt=\"\" width=\"255\" height=\"19\" /></p>\n<p>where {<strong>&upsilon;<sub>i</sub></strong>} is a sequence of natural numbers representing the universe Y, U is the utility function, Q is the data (\"program\") representing A and the expectation value is taken w.r.t. the quasi-Solomonoff distribution.</p>\n<p>I<sub>EDT</sub> suffers from problems analogous to its associated decision theory EDT. Namely, suppose a certain Q is very likely to exist in a universe containing pink unicorns (maybe because pink unicorns have a fetish for this Q). Suppose further that pink unicorns yield very high utility, even though Q itself yields little utility directly. Then I<sub>EDT</sub>(Q) might be high even though Q has few of the attributes we associate with intelligence.</p>\n<p>Alternatively we can introduce the intelligence metric</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_%7BCDT%7D%28Q%29%20=%20E_%7Bq%28%5Cupsilon_t%29%20%5Crightarrow%20Q%7D%5BU%28%5Clbrace%20%5Cupsilon_i%20%5Crbrace%29%5D\" alt=\"\" width=\"226\" height=\"20\" /></p>\n<p>This time the expectation value is unconditional however we postulated a \"divine intervention\" which brings Q into existence at time <strong>t</strong> regardless of the physics selected from the quasi-Solomonoff distribution for Y. This unphysical assumption is an artifact analogous to the use of counterfactuals in CDT.</p>\n<h1>Metatickling<br /></h1>\n<p>To make my way out of this conundrum I observe that the increase of probability of pink unicorns in the EDT example is \"unjustified\", since if you are a programmer building an AI then you know the AI came out the way it is because of <em>you,</em> not because of pink unicorns. One way to interpret this is that D isn't a sufficiently detailed model. However including a model of the AI programmer into D seems impractical. Therefore I suggest instead including a <em>generic</em> intelligence optimization process O.</p>\n<p>Denote <img src=\"http://www.codecogs.com/png.latex?p^D(R)\" alt=\"\" width=\"48\" height=\"19\" /> the probability assigned by the quasi-Solomonoff distribution to program R as the physics of Y. Then, the <em>metatickle quasi-Solomonoff distribution</em> assigns to R the probability</p>\n<p><img src=\"http://www.codecogs.com/png.latex?p^D_I(R)=Z^{-1}p^D(R)e^{\\beta E_R[I(q(\\upsilon_t))]}\" alt=\"\" /></p>\n<p>Here Z is a normalization factor, &beta; is a constant representing O's <em>power of optimization, </em>E<sub>R</sub> is expectation value in an R-universe and <strong>I</strong> is the yet unspecified intelligence metric (yep, we're going self-referential).</p>\n<p>The metatickle intelligence metric is then defined as the solution to the equation</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_{MTDT}^\\beta(Q)=E^D_{I_{MTDT}^\\beta}[U(\\lbrace \\upsilon_i \\rbrace)|q(\\upsilon_t)=Q]\" alt=\"\" /></p>\n<p>where the expectation value is taken w.r.t. the metatickle quasi-Solomonoff distribution defined by D and I<sup>&beta;</sup><sub>MTDT</sub>.</p>\n<p>It is suggestive to apply some fixed-point theorem to get results about existence and/or uniqueness of I<sup>&beta;</sup><sub>MTDT</sub>, something I haven't done yet.</p>\n<p>Metatickle EDT suffers from a problem common with CDT, namely it two-boxes on <a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a>. The same applies here. Specifically, suppose &Omega; is a superintelligence which is able to predict Q by modeling O and it places utility in the first box iff A(Q) one-boxes. Then two-boxers are assigned high intelligence for the self-referential reason that &Omega; predicts this and leaves the first box empty. However, I claim that in this context this behavior is sensible. From A(Q)'s point-of-view, it would gain nothing by one-boxing since one-boxing would only mean Q came out with a statistical fluke and &Omega; still left the first box empty (since the fluke is unpredictable). From O's point-of-view, it is doing everything right since its purpose is maximizing <em>intelligence</em>, not utility. O behaves just like the philosophy students Yudkowsky likes to describe, which prefer winning arguments over winning money. Indeed, we can consider a situation in which &Omega; would generate utility on the condition that Q is made <em>unintelligent.</em> In this case there is nothing paradoxical about the resulting negative relation between intelligence and utility. This argument seems similar to the standard defense of CDT: \"&Omega; simply discriminates in favor of irrational behavior\". However, the standard counterargument \"it isn't discrimination as long as only the final decisions are involved rather than the intrinsic process leading to the decisions\" doesn't apply here, since from O's point-of-view Q <em>is</em> a final decision.</p>\n<p>Note that MTDT-intelligent agents cope fantastically with the <em>usual</em> Newcomb's problem. That is, if &Omega; prepares the boxes <em>after</em> formation of A (moment <strong>t</strong>) then an MTDT-intelligent A will one-box (ceteris paribus i.e. ignoring possible non-decision-theoretic effects of programming A in this way).</p>\n<p>Note also that it <em>doesn't</em> mean we can use I<sub>CDT</sub> just as well. CDT-intelligent agents suffer from a severe mental disability, namely they are unable to deduce anything about the universe from the properties of their own self. They are blinded by faith in a divine intervention which created them. This problem doesn't apply to I<sub>MTDT</sub>.</p>\n<p>It seems useful to let &beta; go to infinity, which corresponds to \"perfect\" O. I suspect I<sup>&infin;</sup><sub>MTDT</sub> converges in many cases. In this limit the \"pink unicorn\" effect is likely to entirely disappear, since for highly intelligent Q any hypothesis of Q's origin that doesn't involve something that looks like an actual intelligence optimization process would be suppressed by its complexity.</p>\n<h2>Multi-Agent Systems</h2>\n<p>It is also interesting to consider a system of N agents A<sub>k</sub>(Q<sub>k</sub>), each with its own utility function U<sub>k</sub> and program Q<sub>k</sub> encoded in the universe as q<sub>k</sub>(&upsilon;<sub>t</sub>). In this case the metatickle quasi-Solomonoff distribution is defined by</p>\n<p><img src=\"http://www.codecogs.com/png.latex?p^D_{I_1,I_2...I_N}(R)=Z^{-1}p^D(R)e^{\\sum_k \\beta_k E_R[I_k(q_1(\\upsilon_t),q_2(\\upsilon_t)...q_N(\\upsilon_t))]}\" alt=\"\" /></p>\n<p>and we have the system of equations</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_k(Q_1,Q_2...Q_N)=E^D_{I_1,I_2...I_N}[U_k(\\lbrace \\upsilon_i \\rbrace)|\\forall l:q_l(\\upsilon_t)=Q_l]\" alt=\"\" /></p>\n<p>The functions I<sub>k</sub> define a game and it's interesting to study e.g. its Nash equilibria.</p>\n<p>In this case the <img src=\"http://www.codecogs.com/png.latex?\\beta \\rightarrow \\infty\" alt=\"\" /> limit is more complicated since depending on the relative speed of growth of the different &beta;'s, there might be different results.</p>\n<h2>Friendly Utility Functions</h2>\n<p>The problem of constructing a friendly utility function can be regarded as inverse to the problem of constructing strong AI. Namely the latter is creating an optimal agent given a utility function whereas the former is finding the utility function of the agent which is already known (homo sapiens).</p>\n<p>Fix a specific agent Alice, w.r.t. which the utility functions should be friendly. Our prior for Alice's unknown utility function U will be that it's computed by some uniformly distributed program T (like in the definition of the Solomonoff distribution). The information we use to update this prior is that Alice was generated by an intelligence optimization process of power &beta;, i.e. she was selected from a metatickle quasi-Solomonoff distribution corresponding to U. We then take the expectation value U*(Alice) of the resulting distribution on utility functions<sup>1</sup>.</p>\n<p>It is not so clear how to determine &beta;. Evidently <img src=\"http://www.codecogs.com/png.latex?%5Cbeta%20%5Crightarrow%20%5Cinfty\" alt=\"\" /> is not a good approach here since we don't consider humans to be <em>optimal</em> for their own terminal values. A possible solution is to postulate a Solomonoff-type prior for &beta; as well.</p>\n<p><sup>1</sup>It might fail to converge. To remedy this, we can restrict ourselves to utility functions taking values in the interval [0, 1].</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cL3ATdvGZ5kTy8AB4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 1.1737861660992567e-06, "legacy": true, "legacyId": "22359", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Related to: <a href=\"/lw/h4x/intelligence_metrics_and_decision_theories/\">Intelligence Metrics and Decision Theories </a></p>\n<p>Previously I presented a formalism for dealing with the <a href=\"http://wiki.lesswrong.com/wiki/Anvil_problem\">Duality</a> and <a href=\"/lw/cze/reply_to_holden_on_tool_ai/70rt\">Ontology</a> problems associated with attempts to define a formal metric of general intelligence. It also solves the <a href=\"/lw/h4x/intelligence_metrics_and_decision_theories/8ptd\">environment distribution problem</a>. This formalism ran into problems closely related to the problems of <a href=\"http://wiki.lesswrong.com/wiki/Decision_theory\">decision theory</a>. I tried to solve these problems using a formalization of <a href=\"http://wiki.lesswrong.com/wiki/UDT\">UDT</a> suitable for this context.</p>\n<p>Here I'm going to pursue a different approach, which I believe to be analogous to the \"metatickle\" version of <a href=\"http://wiki.lesswrong.com/wiki/Evidential_Decision_Theory\">EDT</a>. I will argue that, as opposed to decision theory, metatickling is a good approach to intelligence metrics. I will also present an analogous formalism for multi-agent systems. Finally, I will suggest an approach for constructing <a href=\"http://wiki.lesswrong.com/wiki/Friendly_Artificial_Intelligence\">friendly</a> utility functions using this formalism.</p>\n<h1 id=\"Review_of_Quasi_Solomonoff_Distributions\">Review of Quasi-Solomonoff Distributions</h1>\n<p>In this section I will remind the idea behind quasi-Solomonoff distributions, glossing over mathematical details. For more details consult the <a href=\"/lw/h4x/intelligence_metrics_and_decision_theories/\">previous article</a>.</p>\n<p>Most attempts at constructing a formal general intelligence metric are based on <a href=\"http://arxiv.org/abs/0712.3329\">Legg and Hutter</a> and involve considering an agent A interacting with an environment V through <em>actions</em> that A applies to V and <em>observations</em><strong> </strong>A makes on V (the latter being information flowing from V to A). The problem with this is that such an agent is indestructible since no process in V can force a change in the inner workings of A. Thus an AI programmed in accord with this formalism will consider it an a priori truth that its mind cannot be tampered with in any way, an obviously false assumption.</p>\n<p>In order to deal with this we can make A a part of V, as suggested by <a href=\"http://agi-conference.org/2012/wp-content/uploads/2012/12/paper_76.pdf\">Orseau and Ring</a>. This creates another problem, namely it's unclear what prior for V should we use. <a href=\"http://arxiv.org/abs/0712.3329\">Legg and Hutter</a> suggest using the Solomonoff distribution which makes sense since a perfectly rational agent is supposed to use the Solomonoff distribution as a prior. However, if A is a part of V, the Solomonoff distribution is clearly too general. For example if our A is implemented on a computing machine M, the rules according to which M works have to be part of our assumptions about V, since without making such assumptions it is impossible to program M in any sensible way.</p>\n<p>Enters the quasi-Solomonoff distribution. Suppose you are a programmer building an AI A. Then it makes sense for you to impart to A the knowledge you have about the universe, including at least the rules according to which A's hardware M works. Denoting this knowledge (the <em>tenative model</em>) D, the distribution to use is the Solomonoff distribution updated by a period <strong>t</strong> of observing D-behavior, where the time parameter <strong>t</strong> represents your own certainty about D.</p>\n<p>It is now tempting to introduce the intelligence metric</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_%7BEDT%7D%28Q%29%20=%20E%5BU%28%5Clbrace%20%5Cupsilon_i%20%5Crbrace%29%7Cq%28%5Cupsilon_t%29=Q%5D\" alt=\"\" width=\"255\" height=\"19\"></p>\n<p>where {<strong>\u03c5<sub>i</sub></strong>} is a sequence of natural numbers representing the universe Y, U is the utility function, Q is the data (\"program\") representing A and the expectation value is taken w.r.t. the quasi-Solomonoff distribution.</p>\n<p>I<sub>EDT</sub> suffers from problems analogous to its associated decision theory EDT. Namely, suppose a certain Q is very likely to exist in a universe containing pink unicorns (maybe because pink unicorns have a fetish for this Q). Suppose further that pink unicorns yield very high utility, even though Q itself yields little utility directly. Then I<sub>EDT</sub>(Q) might be high even though Q has few of the attributes we associate with intelligence.</p>\n<p>Alternatively we can introduce the intelligence metric</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_%7BCDT%7D%28Q%29%20=%20E_%7Bq%28%5Cupsilon_t%29%20%5Crightarrow%20Q%7D%5BU%28%5Clbrace%20%5Cupsilon_i%20%5Crbrace%29%5D\" alt=\"\" width=\"226\" height=\"20\"></p>\n<p>This time the expectation value is unconditional however we postulated a \"divine intervention\" which brings Q into existence at time <strong>t</strong> regardless of the physics selected from the quasi-Solomonoff distribution for Y. This unphysical assumption is an artifact analogous to the use of counterfactuals in CDT.</p>\n<h1 id=\"Metatickling\">Metatickling<br></h1>\n<p>To make my way out of this conundrum I observe that the increase of probability of pink unicorns in the EDT example is \"unjustified\", since if you are a programmer building an AI then you know the AI came out the way it is because of <em>you,</em> not because of pink unicorns. One way to interpret this is that D isn't a sufficiently detailed model. However including a model of the AI programmer into D seems impractical. Therefore I suggest instead including a <em>generic</em> intelligence optimization process O.</p>\n<p>Denote <img src=\"http://www.codecogs.com/png.latex?p^D(R)\" alt=\"\" width=\"48\" height=\"19\"> the probability assigned by the quasi-Solomonoff distribution to program R as the physics of Y. Then, the <em>metatickle quasi-Solomonoff distribution</em> assigns to R the probability</p>\n<p><img src=\"http://www.codecogs.com/png.latex?p^D_I(R)=Z^{-1}p^D(R)e^{\\beta E_R[I(q(\\upsilon_t))]}\" alt=\"\"></p>\n<p>Here Z is a normalization factor, \u03b2 is a constant representing O's <em>power of optimization, </em>E<sub>R</sub> is expectation value in an R-universe and <strong>I</strong> is the yet unspecified intelligence metric (yep, we're going self-referential).</p>\n<p>The metatickle intelligence metric is then defined as the solution to the equation</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_{MTDT}^\\beta(Q)=E^D_{I_{MTDT}^\\beta}[U(\\lbrace \\upsilon_i \\rbrace)|q(\\upsilon_t)=Q]\" alt=\"\"></p>\n<p>where the expectation value is taken w.r.t. the metatickle quasi-Solomonoff distribution defined by D and I<sup>\u03b2</sup><sub>MTDT</sub>.</p>\n<p>It is suggestive to apply some fixed-point theorem to get results about existence and/or uniqueness of I<sup>\u03b2</sup><sub>MTDT</sub>, something I haven't done yet.</p>\n<p>Metatickle EDT suffers from a problem common with CDT, namely it two-boxes on <a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a>. The same applies here. Specifically, suppose \u03a9 is a superintelligence which is able to predict Q by modeling O and it places utility in the first box iff A(Q) one-boxes. Then two-boxers are assigned high intelligence for the self-referential reason that \u03a9 predicts this and leaves the first box empty. However, I claim that in this context this behavior is sensible. From A(Q)'s point-of-view, it would gain nothing by one-boxing since one-boxing would only mean Q came out with a statistical fluke and \u03a9 still left the first box empty (since the fluke is unpredictable). From O's point-of-view, it is doing everything right since its purpose is maximizing <em>intelligence</em>, not utility. O behaves just like the philosophy students Yudkowsky likes to describe, which prefer winning arguments over winning money. Indeed, we can consider a situation in which \u03a9 would generate utility on the condition that Q is made <em>unintelligent.</em> In this case there is nothing paradoxical about the resulting negative relation between intelligence and utility. This argument seems similar to the standard defense of CDT: \"\u03a9 simply discriminates in favor of irrational behavior\". However, the standard counterargument \"it isn't discrimination as long as only the final decisions are involved rather than the intrinsic process leading to the decisions\" doesn't apply here, since from O's point-of-view Q <em>is</em> a final decision.</p>\n<p>Note that MTDT-intelligent agents cope fantastically with the <em>usual</em> Newcomb's problem. That is, if \u03a9 prepares the boxes <em>after</em> formation of A (moment <strong>t</strong>) then an MTDT-intelligent A will one-box (ceteris paribus i.e. ignoring possible non-decision-theoretic effects of programming A in this way).</p>\n<p>Note also that it <em>doesn't</em> mean we can use I<sub>CDT</sub> just as well. CDT-intelligent agents suffer from a severe mental disability, namely they are unable to deduce anything about the universe from the properties of their own self. They are blinded by faith in a divine intervention which created them. This problem doesn't apply to I<sub>MTDT</sub>.</p>\n<p>It seems useful to let \u03b2 go to infinity, which corresponds to \"perfect\" O. I suspect I<sup>\u221e</sup><sub>MTDT</sub> converges in many cases. In this limit the \"pink unicorn\" effect is likely to entirely disappear, since for highly intelligent Q any hypothesis of Q's origin that doesn't involve something that looks like an actual intelligence optimization process would be suppressed by its complexity.</p>\n<h2 id=\"Multi_Agent_Systems\">Multi-Agent Systems</h2>\n<p>It is also interesting to consider a system of N agents A<sub>k</sub>(Q<sub>k</sub>), each with its own utility function U<sub>k</sub> and program Q<sub>k</sub> encoded in the universe as q<sub>k</sub>(\u03c5<sub>t</sub>). In this case the metatickle quasi-Solomonoff distribution is defined by</p>\n<p><img src=\"http://www.codecogs.com/png.latex?p^D_{I_1,I_2...I_N}(R)=Z^{-1}p^D(R)e^{\\sum_k \\beta_k E_R[I_k(q_1(\\upsilon_t),q_2(\\upsilon_t)...q_N(\\upsilon_t))]}\" alt=\"\"></p>\n<p>and we have the system of equations</p>\n<p><img src=\"http://www.codecogs.com/png.latex?I_k(Q_1,Q_2...Q_N)=E^D_{I_1,I_2...I_N}[U_k(\\lbrace \\upsilon_i \\rbrace)|\\forall l:q_l(\\upsilon_t)=Q_l]\" alt=\"\"></p>\n<p>The functions I<sub>k</sub> define a game and it's interesting to study e.g. its Nash equilibria.</p>\n<p>In this case the <img src=\"http://www.codecogs.com/png.latex?\\beta \\rightarrow \\infty\" alt=\"\"> limit is more complicated since depending on the relative speed of growth of the different \u03b2's, there might be different results.</p>\n<h2 id=\"Friendly_Utility_Functions\">Friendly Utility Functions</h2>\n<p>The problem of constructing a friendly utility function can be regarded as inverse to the problem of constructing strong AI. Namely the latter is creating an optimal agent given a utility function whereas the former is finding the utility function of the agent which is already known (homo sapiens).</p>\n<p>Fix a specific agent Alice, w.r.t. which the utility functions should be friendly. Our prior for Alice's unknown utility function U will be that it's computed by some uniformly distributed program T (like in the definition of the Solomonoff distribution). The information we use to update this prior is that Alice was generated by an intelligence optimization process of power \u03b2, i.e. she was selected from a metatickle quasi-Solomonoff distribution corresponding to U. We then take the expectation value U*(Alice) of the resulting distribution on utility functions<sup>1</sup>.</p>\n<p>It is not so clear how to determine \u03b2. Evidently <img src=\"http://www.codecogs.com/png.latex?%5Cbeta%20%5Crightarrow%20%5Cinfty\" alt=\"\"> is not a good approach here since we don't consider humans to be <em>optimal</em> for their own terminal values. A possible solution is to postulate a Solomonoff-type prior for \u03b2 as well.</p>\n<p><sup>1</sup>It might fail to converge. To remedy this, we can restrict ourselves to utility functions taking values in the interval [0, 1].</p>", "sections": [{"title": "Review of Quasi-Solomonoff Distributions", "anchor": "Review_of_Quasi_Solomonoff_Distributions", "level": 1}, {"title": "Metatickling", "anchor": "Metatickling", "level": 1}, {"title": "Multi-Agent Systems", "anchor": "Multi_Agent_Systems", "level": 2}, {"title": "Friendly Utility Functions", "anchor": "Friendly_Utility_Functions", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vPtMSvnF8B5hM5LdL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-20T07:04:08.521Z", "modifiedAt": null, "url": null, "title": "Want to have a CFAR instructor visit your LW group?", "slug": "want-to-have-a-cfar-instructor-visit-your-lw-group", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:03.776Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Yh6hrJmFZ7FpbDGK8/want-to-have-a-cfar-instructor-visit-your-lw-group", "pageUrlRelative": "/posts/Yh6hrJmFZ7FpbDGK8/want-to-have-a-cfar-instructor-visit-your-lw-group", "linkUrl": "https://www.lesswrong.com/posts/Yh6hrJmFZ7FpbDGK8/want-to-have-a-cfar-instructor-visit-your-lw-group", "postedAtFormatted": "Saturday, April 20th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Want%20to%20have%20a%20CFAR%20instructor%20visit%20your%20LW%20group%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWant%20to%20have%20a%20CFAR%20instructor%20visit%20your%20LW%20group%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYh6hrJmFZ7FpbDGK8%2Fwant-to-have-a-cfar-instructor-visit-your-lw-group%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Want%20to%20have%20a%20CFAR%20instructor%20visit%20your%20LW%20group%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYh6hrJmFZ7FpbDGK8%2Fwant-to-have-a-cfar-instructor-visit-your-lw-group", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYh6hrJmFZ7FpbDGK8%2Fwant-to-have-a-cfar-instructor-visit-your-lw-group", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 120, "htmlBody": "<p>Cat, who has volunteered extensively at CFAR (and taught at CFAR), will be visiting many cities in Europe over the coming months.</p>\n<p>She is awesome. &nbsp;</p>\n<p>Also, the list of cities that she is visiting will probably be determined in the next few days.</p>\n<p>If you'd like to have her visit your LW meetup group, share some of our classes with your meetup, and generally bring connections back and forth... comment below, or PM her (or me)! &nbsp;I suspect this can be a lot of fun, and useful as well. &nbsp;Offers of couch space and similar are also appreciated.</p>\n<p>For now this is just for Europe, probably, but no harm in touching base from other cities as well; it's possible she'll visit elsewhere later.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"X7v7Fyp9cgBYaMe2e": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Yh6hrJmFZ7FpbDGK8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 30, "extendedScore": null, "score": 1.1742189295379632e-06, "legacy": true, "legacyId": "22361", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-20T16:52:54.397Z", "modifiedAt": null, "url": null, "title": "LW Women Entries- LW Meetups", "slug": "lw-women-entries-lw-meetups", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.848Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eeuembbW7g4LLw2jt/lw-women-entries-lw-meetups", "pageUrlRelative": "/posts/eeuembbW7g4LLw2jt/lw-women-entries-lw-meetups", "linkUrl": "https://www.lesswrong.com/posts/eeuembbW7g4LLw2jt/lw-women-entries-lw-meetups", "postedAtFormatted": "Saturday, April 20th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20Women%20Entries-%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20Women%20Entries-%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeeuembbW7g4LLw2jt%2Flw-women-entries-lw-meetups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20Women%20Entries-%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeeuembbW7g4LLw2jt%2Flw-women-entries-lw-meetups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeeuembbW7g4LLw2jt%2Flw-women-entries-lw-meetups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 741, "htmlBody": "<p><strong id=\"internal-source-marker_0.11153432168066502\" style=\"font-family: 'Times New Roman'; font-size: medium; font-weight: normal;\"> </strong></p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif;\">Standard Intro</h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong>The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Seven women replied, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong>Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<hr style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\" />\n<h2>Notes from Daenerys:</h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">1. I'm not on this site very much anymore, so I'm going to try to remember to post these about once a week to get them off my to-do list. So the next couple weeks might have a lot of gender discussion, but I only have 2 left, so it will be done soon.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">2. This post ended up being less anonymous. Please do NOT link to any identifying information.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">3. There were some questions recently about the purpose of this series, which makes sense because the purpose was discussed 8 months ago, which is a pretty long time, by LW standard. Shortly, by virtue of the gender ratio here (90% male), the men's voices tend to drown out the women's voices, and many women may just not post on certain issues due to the feeling of swimming upstream, so this was a way to compile a bunch of LW women's opinions and thoughts. Note that, going by the latest LW survey there are less than 100 women on here, so each submitter is over 1% of the total female readership of LW. Here is the <a href=\"/r/discussion/lw/efs/call_for_anonymous_narratives_by_lw_women_and/\">original call for responses</a>, and the <a href=\"/lw/e5h/how_to_deal_with_someone_in_a_lesswrong_meeting/7dou\">original discussion of the LW Women series idea</a>.</p>\n<hr />\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h2>Submitter C</h2>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">I wasn't going to write, but something happened at today's meetup that really irked me.</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">A man turned to a young woman near him and asked, \"So, do you actually read Less Wrong, or did someone drag you here?\" I asked, \"Are you saying that because she's wearing heels and lipstick?\" \"No, no,\" he answered, flustered. \"It's not because of how she's dressed. It's just that most of the women who come here are dragged by someone else.\" I asked, \"Do you think that any woman, no matter why she came here, would feel welcomed by being asked that question?\" At that point he began apologizing, and the other woman assured him she wasn't offended.</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">It really bothered me, though. It seemed like a basic failure to think about the consequences of his words. Apparently his hypothesis was \"Most female meetup attenders do not read Less Wrong.\" It's fine to have that hypothesis (although I think it's incorrect), but it's different to test it in a way that's likely to offend. If you really want to find out if she reads the site, ask how long she's been reading Less wrong or what her favorite posts are. Don't start by saying, essentially, \"I assume you are an outsider.\" (For the record, he was wrong - she's an avid LW reader.)</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">If someone doesn't fit the usual Less Wrong demographic, they're probably far more aware of that than you are. If you notice someone doesn't fit your mental model of a Less Wronger, please don't demand that they explain their presence. There are probably other ways to satisfy your curiosity, and if not, your curiosity does not justify making someone else feel they don't belong.</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<h2>UPDATE from Submitter C</h2>\n<p>This happened last year, and since that time we've talked about it more. I think it was a genuine mistake/misunderstanding and not a deliberate attempt to alienate anyone. I don't know how the other woman took the whole situation. I know it pushed my you-don't-belong-here button, and I responded based on that. The whole thing would have gone better if I had responded more charitably.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eeuembbW7g4LLw2jt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 14, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "20260", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong id=\"internal-source-marker_0.11153432168066502\" style=\"font-family: 'Times New Roman'; font-size: medium; font-weight: normal;\"> </strong></p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif;\" id=\"Standard_Intro\">Standard Intro</h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong id=\"The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_\">The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Seven women replied, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong id=\"Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_\">Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<hr style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">\n<h2 id=\"Notes_from_Daenerys_\">Notes from Daenerys:</h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">1. I'm not on this site very much anymore, so I'm going to try to remember to post these about once a week to get them off my to-do list. So the next couple weeks might have a lot of gender discussion, but I only have 2 left, so it will be done soon.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">2. This post ended up being less anonymous. Please do NOT link to any identifying information.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">3. There were some questions recently about the purpose of this series, which makes sense because the purpose was discussed 8 months ago, which is a pretty long time, by LW standard. Shortly, by virtue of the gender ratio here (90% male), the men's voices tend to drown out the women's voices, and many women may just not post on certain issues due to the feeling of swimming upstream, so this was a way to compile a bunch of LW women's opinions and thoughts. Note that, going by the latest LW survey there are less than 100 women on here, so each submitter is over 1% of the total female readership of LW. Here is the <a href=\"/r/discussion/lw/efs/call_for_anonymous_narratives_by_lw_women_and/\">original call for responses</a>, and the <a href=\"/lw/e5h/how_to_deal_with_someone_in_a_lesswrong_meeting/7dou\">original discussion of the LW Women series idea</a>.</p>\n<hr>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h2 id=\"Submitter_C\">Submitter C</h2>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">I wasn't going to write, but something happened at today's meetup that really irked me.</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">A man turned to a young woman near him and asked, \"So, do you actually read Less Wrong, or did someone drag you here?\" I asked, \"Are you saying that because she's wearing heels and lipstick?\" \"No, no,\" he answered, flustered. \"It's not because of how she's dressed. It's just that most of the women who come here are dragged by someone else.\" I asked, \"Do you think that any woman, no matter why she came here, would feel welcomed by being asked that question?\" At that point he began apologizing, and the other woman assured him she wasn't offended.</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">It really bothered me, though. It seemed like a basic failure to think about the consequences of his words. Apparently his hypothesis was \"Most female meetup attenders do not read Less Wrong.\" It's fine to have that hypothesis (although I think it's incorrect), but it's different to test it in a way that's likely to offend. If you really want to find out if she reads the site, ask how long she's been reading Less wrong or what her favorite posts are. Don't start by saying, essentially, \"I assume you are an outsider.\" (For the record, he was wrong - she's an avid LW reader.)</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">If someone doesn't fit the usual Less Wrong demographic, they're probably far more aware of that than you are. If you notice someone doesn't fit your mental model of a Less Wronger, please don't demand that they explain their presence. There are probably other ways to satisfy your curiosity, and if not, your curiosity does not justify making someone else feel they don't belong.</p>\n<p style=\"text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<h2 id=\"UPDATE_from_Submitter_C\">UPDATE from Submitter C</h2>\n<p>This happened last year, and since that time we've talked about it more. I think it was a genuine mistake/misunderstanding and not a deliberate attempt to alienate anyone. I don't know how the other woman took the whole situation. I know it pushed my you-don't-belong-here button, and I responded based on that. The whole thing would have gone better if I had responded more charitably.</p>", "sections": [{"title": "Standard Intro", "anchor": "Standard_Intro", "level": 1}, {"title": "The following section will be at the top of all posts in the LW Women series.", "anchor": "The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_", "level": 2}, {"title": "Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.", "anchor": "Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_", "level": 2}, {"title": "Notes from Daenerys:", "anchor": "Notes_from_Daenerys_", "level": 1}, {"title": "Submitter C", "anchor": "Submitter_C", "level": 1}, {"title": "UPDATE from Submitter C", "anchor": "UPDATE_from_Submitter_C", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "131 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 132, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tBraZAHvj2zacSxxu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-20T23:57:34.160Z", "modifiedAt": null, "url": null, "title": "[LINK] Causal Entropic Forces", "slug": "link-causal-entropic-forces", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:06.413Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jQ6NQp8tG2qAJmRTA/link-causal-entropic-forces", "pageUrlRelative": "/posts/jQ6NQp8tG2qAJmRTA/link-causal-entropic-forces", "linkUrl": "https://www.lesswrong.com/posts/jQ6NQp8tG2qAJmRTA/link-causal-entropic-forces", "postedAtFormatted": "Saturday, April 20th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Causal%20Entropic%20Forces&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Causal%20Entropic%20Forces%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjQ6NQp8tG2qAJmRTA%2Flink-causal-entropic-forces%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Causal%20Entropic%20Forces%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjQ6NQp8tG2qAJmRTA%2Flink-causal-entropic-forces", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjQ6NQp8tG2qAJmRTA%2Flink-causal-entropic-forces", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 130, "htmlBody": "<p><a href=\"http://prl.aps.org/abstract/PRL/v110/i16/e168702\">This paper</a> seems relevant to various LW interests. <span style=\"text-decoration: line-through;\">It smells like <a href=\"/lw/o5/the_second_law_of_thermodynamics_and_engines_of/\">The Second Law of Thermodynamics, and Engines of Cognition</a>, but I haven't wrapped my head enough around either to say more than that.</span> Abstract:</p>\n<blockquote>\n<p>Recent advances in fields ranging from cosmology to computer science have hinted at a possible deep connection between intelligence and entropy maximization, but no formal physical relationship between them has yet been established. Here, we explicitly propose a first step toward such a relationship in the form of a causal generalization of entropic forces that we find can cause two defining behaviors of the human &ldquo;cognitive niche&rdquo;&mdash;tool use and social cooperation&mdash;to spontaneously emerge in simple physical systems. Our results suggest a potentially general thermodynamic model of adaptive behavior as a nonequilibrium process in open systems.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jQ6NQp8tG2qAJmRTA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 9, "extendedScore": null, "score": 1.1749266043570707e-06, "legacy": true, "legacyId": "22362", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QkX2bAkwG2EpGvNug"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-21T05:15:24.075Z", "modifiedAt": null, "url": null, "title": "Meetup : Emotional Awareness ", "slug": "meetup-emotional-awareness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.621Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mt8Ks9oBDrLdLsTxD/meetup-emotional-awareness", "pageUrlRelative": "/posts/Mt8Ks9oBDrLdLsTxD/meetup-emotional-awareness", "linkUrl": "https://www.lesswrong.com/posts/Mt8Ks9oBDrLdLsTxD/meetup-emotional-awareness", "postedAtFormatted": "Sunday, April 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Emotional%20Awareness%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Emotional%20Awareness%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMt8Ks9oBDrLdLsTxD%2Fmeetup-emotional-awareness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Emotional%20Awareness%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMt8Ks9oBDrLdLsTxD%2Fmeetup-emotional-awareness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMt8Ks9oBDrLdLsTxD%2Fmeetup-emotional-awareness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 151, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lx'>Emotional Awareness </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">27 April 2013 03:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2505 w broadway, vancouver, bc</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Vancouver meetup is going to spend the next many weeks working through the CFAR core materials that are taught at the CFAR camps. Each week is another \"chapter\". The exercises should take around 2 hours, with plenty of time left over for hanging out and having fun.</p>\n\n<p>The Bayes stuff on Saturday went well. We worked through some of the Bayes theorem practice problems. I think everyone learned something (at least I did.)</p>\n\n<p>Next up is something completely different; some exercises about Emotional Awareness. It looks like it should be fun, and hopefully It will be better organized than the first one was.</p>\n\n<p>As usual, Benny's Bagels on Saturday afternoon (15:30 this week). Join us on our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a> if you are not on already.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lx'>Emotional Awareness </a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mt8Ks9oBDrLdLsTxD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.1751487013688057e-06, "legacy": true, "legacyId": "22363", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Emotional_Awareness_\">Discussion article for the meetup : <a href=\"/meetups/lx\">Emotional Awareness </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">27 April 2013 03:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2505 w broadway, vancouver, bc</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Vancouver meetup is going to spend the next many weeks working through the CFAR core materials that are taught at the CFAR camps. Each week is another \"chapter\". The exercises should take around 2 hours, with plenty of time left over for hanging out and having fun.</p>\n\n<p>The Bayes stuff on Saturday went well. We worked through some of the Bayes theorem practice problems. I think everyone learned something (at least I did.)</p>\n\n<p>Next up is something completely different; some exercises about Emotional Awareness. It looks like it should be fun, and hopefully It will be better organized than the first one was.</p>\n\n<p>As usual, Benny's Bagels on Saturday afternoon (15:30 this week). Join us on our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a> if you are not on already.</p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Emotional_Awareness_1\">Discussion article for the meetup : <a href=\"/meetups/lx\">Emotional Awareness </a></h2>", "sections": [{"title": "Discussion article for the meetup : Emotional Awareness ", "anchor": "Discussion_article_for_the_meetup___Emotional_Awareness_", "level": 1}, {"title": "Discussion article for the meetup : Emotional Awareness ", "anchor": "Discussion_article_for_the_meetup___Emotional_Awareness_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-21T15:03:23.356Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta Lesswrong: Cryonics FAQ & Signing up Party!", "slug": "meetup-atlanta-lesswrong-cryonics-faq-and-signing-up-party", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:03.803Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nova_Division", "createdAt": "2011-03-14T15:21:15.124Z", "isAdmin": false, "displayName": "Nova_Division"}, "userId": "eFXLR4aNaxDBCDatT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8s3geLNp98vbfZJaE/meetup-atlanta-lesswrong-cryonics-faq-and-signing-up-party", "pageUrlRelative": "/posts/8s3geLNp98vbfZJaE/meetup-atlanta-lesswrong-cryonics-faq-and-signing-up-party", "linkUrl": "https://www.lesswrong.com/posts/8s3geLNp98vbfZJaE/meetup-atlanta-lesswrong-cryonics-faq-and-signing-up-party", "postedAtFormatted": "Sunday, April 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta%20Lesswrong%3A%20Cryonics%20FAQ%20%26%20Signing%20up%20Party!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%20Lesswrong%3A%20Cryonics%20FAQ%20%26%20Signing%20up%20Party!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8s3geLNp98vbfZJaE%2Fmeetup-atlanta-lesswrong-cryonics-faq-and-signing-up-party%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%20Lesswrong%3A%20Cryonics%20FAQ%20%26%20Signing%20up%20Party!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8s3geLNp98vbfZJaE%2Fmeetup-atlanta-lesswrong-cryonics-faq-and-signing-up-party", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8s3geLNp98vbfZJaE%2Fmeetup-atlanta-lesswrong-cryonics-faq-and-signing-up-party", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 338, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ly'>Atlanta Lesswrong: Cryonics FAQ &amp; Signing up Party!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Transhumanism, radical life extension, and cryonics are areas that typically have a large interest intersection with rationality.\nOur ATLesswrong Meetup has several people who expressed a desire for a more focused session to discuss cryonics and perhaps start the paperwork process in the company of supportive friends. So this is that session!\nHave you been cryo-crastinating? Do you have questions that you keep meaning to research, but haven't got around to yet? Do you want hear what the process is like from people who have gone through with it? Then come to this session!\nPlease note that no one is going to pressured to sign up! Pros and Cons will be discussed (though obviously several of us have come to the conclusion that there are net pros). This is only informational, and help with paperwork IF YOU WANT IT. If you want to come fill out paperwork \"just in case\" you can do so, and make the decision whether to put it in the mail later. Issues of death and finances are deeply personal, and ALL feelings will be respected. (Anyone who is not respectful to the feelings of others will be asked to leave.)\nAgenda:\n(1) Provide information about cryonics, including the organizations you can sign up with, life insurance options, and feasibility discussions. Questions and Answers with people who have already signed up.\n(2) Put some signatures on some papers! For those who are at that stage of the process.\n(3) Celebrate! There will probably be libations.\nI will also send out an email when I get a chance about what to do to prepare for this session, if you'd like to get the paperwork ready. Check back for the text of the email here if you are not signed up for various mailing lists.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ly'>Atlanta Lesswrong: Cryonics FAQ &amp; Signing up Party!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8s3geLNp98vbfZJaE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.1755597760106214e-06, "legacy": true, "legacyId": "22364", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta_Lesswrong__Cryonics_FAQ___Signing_up_Party_\">Discussion article for the meetup : <a href=\"/meetups/ly\">Atlanta Lesswrong: Cryonics FAQ &amp; Signing up Party!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Transhumanism, radical life extension, and cryonics are areas that typically have a large interest intersection with rationality.\nOur ATLesswrong Meetup has several people who expressed a desire for a more focused session to discuss cryonics and perhaps start the paperwork process in the company of supportive friends. So this is that session!\nHave you been cryo-crastinating? Do you have questions that you keep meaning to research, but haven't got around to yet? Do you want hear what the process is like from people who have gone through with it? Then come to this session!\nPlease note that no one is going to pressured to sign up! Pros and Cons will be discussed (though obviously several of us have come to the conclusion that there are net pros). This is only informational, and help with paperwork IF YOU WANT IT. If you want to come fill out paperwork \"just in case\" you can do so, and make the decision whether to put it in the mail later. Issues of death and finances are deeply personal, and ALL feelings will be respected. (Anyone who is not respectful to the feelings of others will be asked to leave.)\nAgenda:\n(1) Provide information about cryonics, including the organizations you can sign up with, life insurance options, and feasibility discussions. Questions and Answers with people who have already signed up.\n(2) Put some signatures on some papers! For those who are at that stage of the process.\n(3) Celebrate! There will probably be libations.\nI will also send out an email when I get a chance about what to do to prepare for this session, if you'd like to get the paperwork ready. Check back for the text of the email here if you are not signed up for various mailing lists.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Atlanta_Lesswrong__Cryonics_FAQ___Signing_up_Party_1\">Discussion article for the meetup : <a href=\"/meetups/ly\">Atlanta Lesswrong: Cryonics FAQ &amp; Signing up Party!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta Lesswrong: Cryonics FAQ & Signing up Party!", "anchor": "Discussion_article_for_the_meetup___Atlanta_Lesswrong__Cryonics_FAQ___Signing_up_Party_", "level": 1}, {"title": "Discussion article for the meetup : Atlanta Lesswrong: Cryonics FAQ & Signing up Party!", "anchor": "Discussion_article_for_the_meetup___Atlanta_Lesswrong__Cryonics_FAQ___Signing_up_Party_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-21T18:38:06.144Z", "modifiedAt": null, "url": null, "title": "Produce / Consume Ratios", "slug": "produce-consume-ratios", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:04.451Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2xrm9PmgjD33v37Az/produce-consume-ratios", "pageUrlRelative": "/posts/2xrm9PmgjD33v37Az/produce-consume-ratios", "linkUrl": "https://www.lesswrong.com/posts/2xrm9PmgjD33v37Az/produce-consume-ratios", "postedAtFormatted": "Sunday, April 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Produce%20%2F%20Consume%20Ratios&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProduce%20%2F%20Consume%20Ratios%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2xrm9PmgjD33v37Az%2Fproduce-consume-ratios%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Produce%20%2F%20Consume%20Ratios%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2xrm9PmgjD33v37Az%2Fproduce-consume-ratios", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2xrm9PmgjD33v37Az%2Fproduce-consume-ratios", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2119, "htmlBody": "<p>I've been thinking about this a bit recently, and thought I'd do a dump of evidence and conjecture, and see what Less Wrong had to say.</p>\n<p>There are lots of areas of life where activities can be partitioned into either producing products or consuming products. For those areas, it may be worthwhile to calculate one's Produce / Consume Ratio (PCR) and also contemplate what the optimal PCR is for that area.<a id=\"more\"></a></p>\n<p>There's often some ambiguity with units- I spend minutes preparing food, but I eat meals, not minutes. Even if you have the units aligned (producing and consuming meals, say), I'm not certain if \"ratios\" are the right measurement, rather than 'fractions.' The benefit of ratios is that it's a single number, but the trouble is that there are many instances where one only produces <a href=\"http://en.wikipedia.org/wiki/Xor\">xor</a> consumes, which implies a ratio of either 0 or infinity; since it's more common to consume and not produce, I've arranged it so those ratios will be 0, and ratios of infinity will be unlikely. (One could talk about produce fraction minus consume fraction, which would go from -1 to 1 and be a unique mapping, but I don't find it as intuitive.)</p>\n<p>It's also worthwhile to remember the fifth of <a href=\"http://en.wikipedia.org/wiki/W._Edwards_Deming\">Deming's Seven Deadly Diseases</a>: running a company on visible figures alone. This ratio is just a measure of what's going on underneath, not a goal in its own right; it's also a dial you can turn only by adding or subtracting activities. Much of the value I've gotten from thinking about it so far is just that it gives me another perspective from which to view a situation, and I sometimes see something I missed before.</p>\n<h3>Food</h3>\n<p>Comparative advantage seems large here; for many meals, prep time is mostly fixed, rather than variable, and a relative preference for cooking over cleaning suggests domestic gains from trade, not to mention massive benefits from skill specialization.</p>\n<p>This also seems like an area where the range of PCRs is fairly well developed- everyone eats, but some people never cook (0) and chefs cook many meals that they don't eat (10-1000), and many people living alone cook most of their own meals (my ratio, eating out about one and a half times a week and eating once a day, is about .8).</p>\n<p>It seems like there may be some missed opportunities at PCRs that are only slightly above one, which I suspect is related to friction associated with family / household size. Generally, each household will have a dedicated chef who cooks most of the meals for most household members, but there's no guarantee that the household size that's optimal overall is optimal for food production. With shifting residential patterns and stricter food safety laws, we don't seem to have <a href=\"http://en.wikipedia.org/wiki/Boarding_house\">boardinghouses</a> anymore- airbnb is making the paying guest a thing, but I don't know of many areas where twenty people will eat dinner together; it seems to be either a handful or hundreds (counting all customers at a restaurant, including delivery customers, rather than just the ones there at once).</p>\n<p>On that topic- is there a missed opportunity for boardinghouses for college students? Most of the lodging options I'm familiar with are dorms (with attached cafeterias) and apartments, but the twelve-bedroom home run by someone who will cook and clean and be a friendly face seems like something that some college students would prefer.</p>\n<h3>Science</h3>\n<p>There are a couple of PCRs here; the important ones that come to mind are concepts and papers. A relevant section from Hamming's <a href=\"http://www.cs.virginia.edu/~robins/YouAndYourResearch.html\">You and Your Research</a>:</p>\n<blockquote>\n<p><em>Question:</em> How much effort should go into library work?</p>\n<p><em>Hamming:</em> It depends upon the field. I will say this about it. There was a fellow at Bell Labs, a very, very, smart guy. He was always in the library; he read everything. If you wanted references, you went to him and he gave you all kinds of references. But in the middle of forming these theories, I formed a proposition: there would be no effect named after him in the long run. He is now retired from Bell Labs and is an Adjunct Professor. He was very valuable; I'm not questioning that. He wrote some very good Physical Review articles; but there's no effect named after him because he read too much. If you read all the time what other people have done you will think the way they thought. If you want to think new thoughts that are different, then do what a lot of creative people do - get the problem reasonably clear and then refuse to look at any answers until you've thought the problem through carefully how you would do it, how you could slightly change the problem to be the correct one. So yes, you need to keep up. You need to keep up more to find out what the problems are than to read to find the solutions. The reading is necessary to know what is going on and what is possible. But reading to get the solutions does not seem to be the way to do great research. So I'll give you two answers. You read; but it is not the amount, it is the way you read that counts.</p>\n</blockquote>\n<h3>Academics</h3>\n<p>I'm tempted to say time spent learning, and time spent teaching, but I don't think those are clearly delineated. There's something called the <a href=\"http://chilab.asu.edu/papers/roscoe%20chi%20tutor%20learning%202008.pdf\">tutor learning effect</a>- students who tutor their peers learn from the experience as well, and many teachers remark on how much they learn about a subject by teaching a class on it.</p>\n<p>Time spent preparing notes and time spent rereading notes seems like it might be cleaner- in particular, looking back at classes and saying \"How would I present this material? What is the takeaway that I would try to emphasize and <a href=\"http://ankisrs.net/\">remember</a>?\"</p>\n<p>Some Confucius:</p>\n<blockquote>\n<p>To study and not think is a waste. To think and not study is dangerous.</p>\n</blockquote>\n<p>(Actually, it seems like the difficulty of measuring PCR here may be a sign that it's valuable to think about here- with food there was just economics and social interactions to think of, but here there's a complicated underlying model which you learn about by trying to tease apart the consumption and production of knowledge.)</p>\n<h3>Programming</h3>\n<p>Again, there seem to be multiple dimensions. One is time use, another is code use. Using a library that does what you want, rather than writing your own version, is generally the right decision, but shifts the code PCR heavily towards 0 while barely adjusting the time PCR (if you measure it by days, and have enough projects to fill your time, rather than measuring it by time spent on a particular project).</p>\n<p>A common claim in programming is that code is harder to read than write, and yet it seems like there are significant gains to learning from how other people write code, not just using what their code outputs. This <a href=\"http://programmingisterrible.com/post/41880113409/a-bad-programmer-talks-about-bad-programming\">talk</a>, \"Programming is Terrible\" by Thomas Figg (script <a href=\"https://github.com/tef/emfcamp2012/blob/master/programming_is_terrible.rst\">here</a>, differs a bit from the talk) is worthwhile for programmers, but here's the relevant section:</p>\n<blockquote>\n<p>Read code every day. Read other peoples code, in order to learn from someone elses mistakes.</p>\n<p>To start with a terrible metaphor - if you met a professional writer you would expect them to be well read &mdash; the few I have encountered have a intimidating collection of books. Before you are expected to write a novel, you should have read some novels. Same goes for code bases.</p>\n<p>Yet with programming, much of the education and resources goes into the practice of writing code for the first time, and little towards analysis, debugging or maintenance.</p>\n<p>Programmers often complain that &lsquo;we have to estimate things we&rsquo;ve never done before&rsquo;, I cannot help what part of this is due to our institutionalised ignorance of other peoples code and projects.</p>\n</blockquote>\n<p><a href=\"http://en.wikipedia.org/wiki/Not_invented_here\">Not Invented Here</a> seems relevant.</p>\n<h3>Fiction</h3>\n<p>Many authors have personal libraries in the tens of thousands of books; an author who just writes is unlikely to write well, but an author who only reads will find that most of what they have learned has floated away because they did not nail it down with practice. I thought Steven King had given advice on this, but he adds the two and focuses on total activity level: \"Read and write four to six hours a day. If you cannot find the time for that, you can't expect to become a good writer.\"</p>\n<p>But that's professional fiction writers; what sort of PCRs should one pursue when interested solely in entertainment? I suspect this varies heavily from individual to individual, but I don't think people do much testing to try to find the right balance. As well, this suggests the opportunity of writing for pure entertainment's sake: putting down just the scenes you want to write, when you want to write them, ignoring any steps you don't like (editing, sections critical to communicating the plot you don't want to write, etc.).</p>\n<h3>Go</h3>\n<p>(This should generalize to other competitive skill-based games.) Watching other people play games, and playing your own games are different experiences that you learn different things from. There's also deliberate practice problems, where you focus on some limited situation to work out that precise concept. While many people talk about the benefits of watching others games, or doing Go problems, this makes me wonder about the value of <em>writing</em> Go problems- when I learn something new, can I construct an example that would teach that to someone else? Attempting that will refine my understanding, but it's not clear it will do so more than reading an expert's problems (though perhaps it will make me better at the art of reading problems).</p>\n<h3>Internet</h3>\n<p>There are many lurkers, and few producers, and different sites encourage different PCRs. There seems to be both a personal PCR and a site-wide PCR; we could compare the number of submissions per reader on memegenerator and LW, and we can also compare how much I consume and produce on each site.</p>\n<p>Most of my thoughts here are muddied by the importance of quality. The amount of time I spend reading and posting on forums seems relatively constant across the years (though the ratio of reading to posting might change, I imagine it stays within a relatively small window) but the content of what I read and post has changed significantly, and for the better.</p>\n<h3>Time Use<br /></h3>\n<p>Looking at optimal PCRs for lots of different activities seems useful, but we can go a level higher- what is your global amount of time spent producing or consuming? Where can you push that ratio, and where should you? Basically every aspect of your life could be improved by devoting more time to it, but ensuring that your marginal value from additional effort is roughly equal along facets of your life is important. (If it isn't, you should shift effort from low-value activities to high-value activities.) PCR can help with that if there's costs for production or consumption are shared across areas; perhaps, for example, reading fiction is less entertaining than watching movies, and so you could increase your PCR by swapping out books for movies. (Or, perhaps, you chose movies over books for that reason, but now realize that you should take combine your entertainment and fiction-writing time and devote some of it to reading, if that gives you a better combination of fiction production quality and entertainment.)</p>\n<p>Optimal ratios seem highly dependent on personal energy levels, tastes, and efficiency. Time use gives a natural unit of measurement, but it measures inputs, and what you want from both production and consumption time is <em>outputs</em>: a meal is about as sustaining if you eat it in ten minutes and an hour, and its taste is only indirectly related to the amount of time you spent working on it.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Blog posts I found searching this topic: <a href=\"http://jsohlander.com/producingvscreating/\">JS Ohlander</a>, <a href=\"http://kevinespiritu.com/what-s-your-consumptionproduction-ratio\">Kevin Espiritu</a>. Both are short and have some insight; both focus on quality of consumption, and ramping up production.</p>\n<p>Also, it seems worthwhile to explicitly point out: while thinking about this, I considered both just thinking about it, preparing a Main post about it, and preparing a Discussion post about it while it was unfinished. The first seems like it has a PCR of infinity, the second a high PCR, and the last a moderate PCR. The first option has a deceptive ratio, because the total amount of activity varies across the options. The last seemed like the best way to learn, in part because it <em>alternated</em> produce and consume activities. My speculations would be developed by putting them in writing, I would do some research in writing the post, and then I would get feedback after publishing to discussion, which would then be useful if I decide to polish it and create something for Main.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2xrm9PmgjD33v37Az", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 22, "extendedScore": null, "score": 5.8e-05, "legacy": true, "legacyId": "22365", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I've been thinking about this a bit recently, and thought I'd do a dump of evidence and conjecture, and see what Less Wrong had to say.</p>\n<p>There are lots of areas of life where activities can be partitioned into either producing products or consuming products. For those areas, it may be worthwhile to calculate one's Produce / Consume Ratio (PCR) and also contemplate what the optimal PCR is for that area.<a id=\"more\"></a></p>\n<p>There's often some ambiguity with units- I spend minutes preparing food, but I eat meals, not minutes. Even if you have the units aligned (producing and consuming meals, say), I'm not certain if \"ratios\" are the right measurement, rather than 'fractions.' The benefit of ratios is that it's a single number, but the trouble is that there are many instances where one only produces <a href=\"http://en.wikipedia.org/wiki/Xor\">xor</a> consumes, which implies a ratio of either 0 or infinity; since it's more common to consume and not produce, I've arranged it so those ratios will be 0, and ratios of infinity will be unlikely. (One could talk about produce fraction minus consume fraction, which would go from -1 to 1 and be a unique mapping, but I don't find it as intuitive.)</p>\n<p>It's also worthwhile to remember the fifth of <a href=\"http://en.wikipedia.org/wiki/W._Edwards_Deming\">Deming's Seven Deadly Diseases</a>: running a company on visible figures alone. This ratio is just a measure of what's going on underneath, not a goal in its own right; it's also a dial you can turn only by adding or subtracting activities. Much of the value I've gotten from thinking about it so far is just that it gives me another perspective from which to view a situation, and I sometimes see something I missed before.</p>\n<h3 id=\"Food\">Food</h3>\n<p>Comparative advantage seems large here; for many meals, prep time is mostly fixed, rather than variable, and a relative preference for cooking over cleaning suggests domestic gains from trade, not to mention massive benefits from skill specialization.</p>\n<p>This also seems like an area where the range of PCRs is fairly well developed- everyone eats, but some people never cook (0) and chefs cook many meals that they don't eat (10-1000), and many people living alone cook most of their own meals (my ratio, eating out about one and a half times a week and eating once a day, is about .8).</p>\n<p>It seems like there may be some missed opportunities at PCRs that are only slightly above one, which I suspect is related to friction associated with family / household size. Generally, each household will have a dedicated chef who cooks most of the meals for most household members, but there's no guarantee that the household size that's optimal overall is optimal for food production. With shifting residential patterns and stricter food safety laws, we don't seem to have <a href=\"http://en.wikipedia.org/wiki/Boarding_house\">boardinghouses</a> anymore- airbnb is making the paying guest a thing, but I don't know of many areas where twenty people will eat dinner together; it seems to be either a handful or hundreds (counting all customers at a restaurant, including delivery customers, rather than just the ones there at once).</p>\n<p>On that topic- is there a missed opportunity for boardinghouses for college students? Most of the lodging options I'm familiar with are dorms (with attached cafeterias) and apartments, but the twelve-bedroom home run by someone who will cook and clean and be a friendly face seems like something that some college students would prefer.</p>\n<h3 id=\"Science\">Science</h3>\n<p>There are a couple of PCRs here; the important ones that come to mind are concepts and papers. A relevant section from Hamming's <a href=\"http://www.cs.virginia.edu/~robins/YouAndYourResearch.html\">You and Your Research</a>:</p>\n<blockquote>\n<p><em>Question:</em> How much effort should go into library work?</p>\n<p><em>Hamming:</em> It depends upon the field. I will say this about it. There was a fellow at Bell Labs, a very, very, smart guy. He was always in the library; he read everything. If you wanted references, you went to him and he gave you all kinds of references. But in the middle of forming these theories, I formed a proposition: there would be no effect named after him in the long run. He is now retired from Bell Labs and is an Adjunct Professor. He was very valuable; I'm not questioning that. He wrote some very good Physical Review articles; but there's no effect named after him because he read too much. If you read all the time what other people have done you will think the way they thought. If you want to think new thoughts that are different, then do what a lot of creative people do - get the problem reasonably clear and then refuse to look at any answers until you've thought the problem through carefully how you would do it, how you could slightly change the problem to be the correct one. So yes, you need to keep up. You need to keep up more to find out what the problems are than to read to find the solutions. The reading is necessary to know what is going on and what is possible. But reading to get the solutions does not seem to be the way to do great research. So I'll give you two answers. You read; but it is not the amount, it is the way you read that counts.</p>\n</blockquote>\n<h3 id=\"Academics\">Academics</h3>\n<p>I'm tempted to say time spent learning, and time spent teaching, but I don't think those are clearly delineated. There's something called the <a href=\"http://chilab.asu.edu/papers/roscoe%20chi%20tutor%20learning%202008.pdf\">tutor learning effect</a>- students who tutor their peers learn from the experience as well, and many teachers remark on how much they learn about a subject by teaching a class on it.</p>\n<p>Time spent preparing notes and time spent rereading notes seems like it might be cleaner- in particular, looking back at classes and saying \"How would I present this material? What is the takeaway that I would try to emphasize and <a href=\"http://ankisrs.net/\">remember</a>?\"</p>\n<p>Some Confucius:</p>\n<blockquote>\n<p>To study and not think is a waste. To think and not study is dangerous.</p>\n</blockquote>\n<p>(Actually, it seems like the difficulty of measuring PCR here may be a sign that it's valuable to think about here- with food there was just economics and social interactions to think of, but here there's a complicated underlying model which you learn about by trying to tease apart the consumption and production of knowledge.)</p>\n<h3 id=\"Programming\">Programming</h3>\n<p>Again, there seem to be multiple dimensions. One is time use, another is code use. Using a library that does what you want, rather than writing your own version, is generally the right decision, but shifts the code PCR heavily towards 0 while barely adjusting the time PCR (if you measure it by days, and have enough projects to fill your time, rather than measuring it by time spent on a particular project).</p>\n<p>A common claim in programming is that code is harder to read than write, and yet it seems like there are significant gains to learning from how other people write code, not just using what their code outputs. This <a href=\"http://programmingisterrible.com/post/41880113409/a-bad-programmer-talks-about-bad-programming\">talk</a>, \"Programming is Terrible\" by Thomas Figg (script <a href=\"https://github.com/tef/emfcamp2012/blob/master/programming_is_terrible.rst\">here</a>, differs a bit from the talk) is worthwhile for programmers, but here's the relevant section:</p>\n<blockquote>\n<p>Read code every day. Read other peoples code, in order to learn from someone elses mistakes.</p>\n<p>To start with a terrible metaphor - if you met a professional writer you would expect them to be well read \u2014 the few I have encountered have a intimidating collection of books. Before you are expected to write a novel, you should have read some novels. Same goes for code bases.</p>\n<p>Yet with programming, much of the education and resources goes into the practice of writing code for the first time, and little towards analysis, debugging or maintenance.</p>\n<p>Programmers often complain that \u2018we have to estimate things we\u2019ve never done before\u2019, I cannot help what part of this is due to our institutionalised ignorance of other peoples code and projects.</p>\n</blockquote>\n<p><a href=\"http://en.wikipedia.org/wiki/Not_invented_here\">Not Invented Here</a> seems relevant.</p>\n<h3 id=\"Fiction\">Fiction</h3>\n<p>Many authors have personal libraries in the tens of thousands of books; an author who just writes is unlikely to write well, but an author who only reads will find that most of what they have learned has floated away because they did not nail it down with practice. I thought Steven King had given advice on this, but he adds the two and focuses on total activity level: \"Read and write four to six hours a day. If you cannot find the time for that, you can't expect to become a good writer.\"</p>\n<p>But that's professional fiction writers; what sort of PCRs should one pursue when interested solely in entertainment? I suspect this varies heavily from individual to individual, but I don't think people do much testing to try to find the right balance. As well, this suggests the opportunity of writing for pure entertainment's sake: putting down just the scenes you want to write, when you want to write them, ignoring any steps you don't like (editing, sections critical to communicating the plot you don't want to write, etc.).</p>\n<h3 id=\"Go\">Go</h3>\n<p>(This should generalize to other competitive skill-based games.) Watching other people play games, and playing your own games are different experiences that you learn different things from. There's also deliberate practice problems, where you focus on some limited situation to work out that precise concept. While many people talk about the benefits of watching others games, or doing Go problems, this makes me wonder about the value of <em>writing</em> Go problems- when I learn something new, can I construct an example that would teach that to someone else? Attempting that will refine my understanding, but it's not clear it will do so more than reading an expert's problems (though perhaps it will make me better at the art of reading problems).</p>\n<h3 id=\"Internet\">Internet</h3>\n<p>There are many lurkers, and few producers, and different sites encourage different PCRs. There seems to be both a personal PCR and a site-wide PCR; we could compare the number of submissions per reader on memegenerator and LW, and we can also compare how much I consume and produce on each site.</p>\n<p>Most of my thoughts here are muddied by the importance of quality. The amount of time I spend reading and posting on forums seems relatively constant across the years (though the ratio of reading to posting might change, I imagine it stays within a relatively small window) but the content of what I read and post has changed significantly, and for the better.</p>\n<h3 id=\"Time_Use\">Time Use<br></h3>\n<p>Looking at optimal PCRs for lots of different activities seems useful, but we can go a level higher- what is your global amount of time spent producing or consuming? Where can you push that ratio, and where should you? Basically every aspect of your life could be improved by devoting more time to it, but ensuring that your marginal value from additional effort is roughly equal along facets of your life is important. (If it isn't, you should shift effort from low-value activities to high-value activities.) PCR can help with that if there's costs for production or consumption are shared across areas; perhaps, for example, reading fiction is less entertaining than watching movies, and so you could increase your PCR by swapping out books for movies. (Or, perhaps, you chose movies over books for that reason, but now realize that you should take combine your entertainment and fiction-writing time and devote some of it to reading, if that gives you a better combination of fiction production quality and entertainment.)</p>\n<p>Optimal ratios seem highly dependent on personal energy levels, tastes, and efficiency. Time use gives a natural unit of measurement, but it measures inputs, and what you want from both production and consumption time is <em>outputs</em>: a meal is about as sustaining if you eat it in ten minutes and an hour, and its taste is only indirectly related to the amount of time you spent working on it.</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<p>Blog posts I found searching this topic: <a href=\"http://jsohlander.com/producingvscreating/\">JS Ohlander</a>, <a href=\"http://kevinespiritu.com/what-s-your-consumptionproduction-ratio\">Kevin Espiritu</a>. Both are short and have some insight; both focus on quality of consumption, and ramping up production.</p>\n<p>Also, it seems worthwhile to explicitly point out: while thinking about this, I considered both just thinking about it, preparing a Main post about it, and preparing a Discussion post about it while it was unfinished. The first seems like it has a PCR of infinity, the second a high PCR, and the last a moderate PCR. The first option has a deceptive ratio, because the total amount of activity varies across the options. The last seemed like the best way to learn, in part because it <em>alternated</em> produce and consume activities. My speculations would be developed by putting them in writing, I would do some research in writing the post, and then I would get feedback after publishing to discussion, which would then be useful if I decide to polish it and create something for Main.</p>", "sections": [{"title": "Food", "anchor": "Food", "level": 1}, {"title": "Science", "anchor": "Science", "level": 1}, {"title": "Academics", "anchor": "Academics", "level": 1}, {"title": "Programming", "anchor": "Programming", "level": 1}, {"title": "Fiction", "anchor": "Fiction", "level": 1}, {"title": "Go", "anchor": "Go", "level": 1}, {"title": "Internet", "anchor": "Internet", "level": 1}, {"title": "Time Use", "anchor": "Time_Use", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-21T20:30:56.004Z", "modifiedAt": null, "url": null, "title": "Help Me Name My Blog", "slug": "help-me-name-my-blog", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:01.486Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8edv23eyB6CM4ppqq/help-me-name-my-blog", "pageUrlRelative": "/posts/8edv23eyB6CM4ppqq/help-me-name-my-blog", "linkUrl": "https://www.lesswrong.com/posts/8edv23eyB6CM4ppqq/help-me-name-my-blog", "postedAtFormatted": "Sunday, April 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Help%20Me%20Name%20My%20Blog&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelp%20Me%20Name%20My%20Blog%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8edv23eyB6CM4ppqq%2Fhelp-me-name-my-blog%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Help%20Me%20Name%20My%20Blog%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8edv23eyB6CM4ppqq%2Fhelp-me-name-my-blog", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8edv23eyB6CM4ppqq%2Fhelp-me-name-my-blog", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 562, "htmlBody": "<p>\n<p>A few of you may know I have a blog called Greatplay.net, located at... surprise... <a href=\"http://www.greatplay.net\">http://www.greatplay.net</a>. I&rsquo;ve heard some people that discovered my site much later than they otherwise would because the name of the site didn&rsquo;t communicate what it was about well and sounded unprofessional.</p>\n<p>Why Greatplay.net in the first place? &nbsp;I picked it when I was 12, because it was (1) short, (2) pronounceable, (3) communicable without any risk of the other person misspelling it, and (4) did not communicate any information about what the site would be about, so I could mold the site as I grew.</p>\n<p>Now after &gt;2 years of blogging about basically the same thing, I think my blog will always be about utilitarianism (both practical and philosophical), lifestyle design (my quest to make myself more productive and frugal, mainly so I can be a better utilitarian), political commentary (from a utilitarian perspective), and psychology (of morality and community and that which basically underlies practical utilitarianism).</p>\n<p>I probably would want to talk about religion/atheism from time to time, which used to be my biggest interest, but I can already tell it's moderately unpopular with my current readership (yawnnn... we really have to go over why the Bible has errors <em>again</em>?) and I'm already personally getting increasingly bored with it, so I can do away with discussing atheism if I needed to keep to a \"topic\"-focused blog.</p>\n<p>Basically, at this point, I think I stand to gain more by making my blog and domain name more descriptive than I stand to lose by risking my interests shifting away from utilitarianism (or at least the public discussion thereof). &nbsp;<strong>But the big question... what should I name my blog?</strong></p>\n<p><strong>Option #1: Keep with Greatplay.net:</strong> There will be costs with shifting to a new domain name. &nbsp;The monetary cost is mostly insignificant (&lt;$20/yr for a new domain name), but it will take a moderate amount of time to move all the archives over and make sure all the new hyperlinks on the site work. &nbsp;Also, there will be confusion among the readership, and everyone who was linking to my site externally would now be linking to dead stuff. &nbsp;So, if I've misestimated the benefits of moving, I might want to stick with the current name and not incur the costs.</p>\n<p><strong>Option #2: Go to PeterHurford.com:</strong> I already use this site as an online r&eacute;sum&eacute; of sorts, so I wouldn't need to get the domain. &nbsp;This also seems the most descriptive of what the site would be about (a personal blog, about me) and fits in with what the cool kids are doing. &nbsp;However, some of my opinions are controversial relative to the mainstream and I don't know what I'll be doing in my future. &nbsp;Keeping my real name hidden from my website might be an asset (so I don't lose opportunities because of association with unpopular mainstream opinions), though it might also be a drawback (I think I have gotten some recognition and opportunity from those who share my unpopular mainstream opinions).</p>\n<p><strong>Option #3: A new name:</strong> If Option #1 and #2 don't work, I'd want to just rename the blog to something descriptive of a blog about utilitarianism. &nbsp;Some ideas I've come up with:</p>\n<p>\n<ul>\n<li>A Shallow Pond</li>\n<li>The Everyday Utilitarian</li>\n<li>Everyday Utilitarianism</li>\n<li>Commonsense Utilitarianism</li>\n<li>Atheist Altruist</li>\n<li>Living Laudibly</li>\n</ul>\n</p>\n<p>Though feel free to suggest your own!</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8edv23eyB6CM4ppqq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -3, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "22366", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-21T21:22:48.208Z", "modifiedAt": null, "url": null, "title": "Can somebody explain this to me?: The computability of the laws of physics and hypercomputation", "slug": "can-somebody-explain-this-to-me-the-computability-of-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.983Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ChrisHallquist", "createdAt": "2011-05-25T19:16:15.462Z", "isAdmin": false, "displayName": "ChrisHallquist"}, "userId": "wvT2xWQqHKxkp9NWN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Rc2Ymaj8sfaG4Crt8/can-somebody-explain-this-to-me-the-computability-of-the", "pageUrlRelative": "/posts/Rc2Ymaj8sfaG4Crt8/can-somebody-explain-this-to-me-the-computability-of-the", "linkUrl": "https://www.lesswrong.com/posts/Rc2Ymaj8sfaG4Crt8/can-somebody-explain-this-to-me-the-computability-of-the", "postedAtFormatted": "Sunday, April 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Can%20somebody%20explain%20this%20to%20me%3F%3A%20The%20computability%20of%20the%20laws%20of%20physics%20and%20hypercomputation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACan%20somebody%20explain%20this%20to%20me%3F%3A%20The%20computability%20of%20the%20laws%20of%20physics%20and%20hypercomputation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRc2Ymaj8sfaG4Crt8%2Fcan-somebody-explain-this-to-me-the-computability-of-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Can%20somebody%20explain%20this%20to%20me%3F%3A%20The%20computability%20of%20the%20laws%20of%20physics%20and%20hypercomputation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRc2Ymaj8sfaG4Crt8%2Fcan-somebody-explain-this-to-me-the-computability-of-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRc2Ymaj8sfaG4Crt8%2Fcan-somebody-explain-this-to-me-the-computability-of-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 351, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Hypercomputation\">\"Hypercomputation\"</a> is a term coined by two philosophers, Jack Copeland and Dianne Proudfoot, to refer to allegedly computational processes that do things Turing machines are in principle incapable of doing. I'm somewhat dubious of whether any of the proposals for \"hypercomputation\" are really accurately described as computation, but here, I'm more interested in another question: is there any chance it's possible to build a physical device that answers questions a Turing machine cannot answer?</p>\n<p>I've read a number of Copeland and Proudfoot's articles promoting hypercomputation, and they claim this is an open question. I have, however, seen some indications that they're wrong about this, but my knowledge of physics and computability theory isn't enough to answer this question with confidence.&nbsp;</p>\n<p>Some of the ways to convince yourself that \"hypercomputation\" might be physically possible seem like obvious confusions, for example if you convince yourself that some physical quality is allowed to be any real number, and then notice that because some reals are non-computable, you say to yourself that if only we could measure such a non-computable quantity then we could answer questions no Turing machine could answer. Of course, the idea of doing such a measurement is physically implausible even if you could find a non-computable physical quantity in the first place. And that mistake can be sexed up in various ways, for example by talking about \"analog computers\" and assuming \"analog\" means it has components that can take any real-numbered value.</p>\n<p>Points similar to the one I've just made exist in the literature on hypercomputation (see <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.4467&amp;rep=rep1&amp;type=pdf\">here</a> and <a href=\"http://www1.maths.leeds.ac.uk/~pmt6sbc/docs/davis.myth.pdf\">here</a>, for example). But the critiques of hypercomputation I've found tend to focus on specific proposals. It's less clear whether there are any good <em>general</em> arguments in the literature that hypercomputation is physically impossible, because it would require infinite-precision measurements or something equally unlikely. It seems like it might be possible to make such an argument; I've read that the laws of physics are consiered to be computable, but I don't have a good enough understanding of what that means to tell if it entails that hypercomputation is physically impossible.</p>\n<p>Can anyone help me out here?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Rc2Ymaj8sfaG4Crt8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 23, "extendedScore": null, "score": 6.9e-05, "legacy": true, "legacyId": "22368", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-22T01:34:19.534Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne, practical rationality", "slug": "meetup-melbourne-practical-rationality-15", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:03.935Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ymxK7sMLAQApN5Yhn/meetup-melbourne-practical-rationality-15", "pageUrlRelative": "/posts/ymxK7sMLAQApN5Yhn/meetup-melbourne-practical-rationality-15", "linkUrl": "https://www.lesswrong.com/posts/ymxK7sMLAQApN5Yhn/meetup-melbourne-practical-rationality-15", "postedAtFormatted": "Monday, April 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%2C%20practical%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%2C%20practical%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FymxK7sMLAQApN5Yhn%2Fmeetup-melbourne-practical-rationality-15%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%2C%20practical%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FymxK7sMLAQApN5Yhn%2Fmeetup-melbourne-practical-rationality-15", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FymxK7sMLAQApN5Yhn%2Fmeetup-melbourne-practical-rationality-15", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/lz'>Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">03 May 2013 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">491 King Street, West Melbourne VIC 3003, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>NOTE: We've moved a stone's throw from our old office. Note the new address.</p>\n\n<p>Practical rationality. This meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Topic for May: Rationality therapy - bring questions or decisions for the group to help solve\n<a href=\"http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3876671-small-groups-rationality-therapy\" rel=\"nofollow\">http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3876671-small-groups-rationality-therapy</a></p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/lz'>Melbourne, practical rationality</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ymxK7sMLAQApN5Yhn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 1.1760011597126572e-06, "legacy": true, "legacyId": "22370", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality\">Discussion article for the meetup : <a href=\"/meetups/lz\">Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">03 May 2013 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">491 King Street, West Melbourne VIC 3003, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>NOTE: We've moved a stone's throw from our old office. Note the new address.</p>\n\n<p>Practical rationality. This meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Topic for May: Rationality therapy - bring questions or decisions for the group to help solve\n<a href=\"http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3876671-small-groups-rationality-therapy\" rel=\"nofollow\">http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3876671-small-groups-rationality-therapy</a></p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality1\">Discussion article for the meetup : <a href=\"/meetups/lz\">Melbourne, practical rationality</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality", "level": 1}, {"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-22T02:55:27.470Z", "modifiedAt": null, "url": null, "title": "Potential Meetup: Ann Arbor, MI, USA", "slug": "potential-meetup-ann-arbor-mi-usa", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:28.768Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "blumsha", "createdAt": "2010-11-16T06:54:19.399Z", "isAdmin": false, "displayName": "blumsha"}, "userId": "GDCfYwZX8NaDExjtK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dvJdEkjWE9WMzwX7u/potential-meetup-ann-arbor-mi-usa", "pageUrlRelative": "/posts/dvJdEkjWE9WMzwX7u/potential-meetup-ann-arbor-mi-usa", "linkUrl": "https://www.lesswrong.com/posts/dvJdEkjWE9WMzwX7u/potential-meetup-ann-arbor-mi-usa", "postedAtFormatted": "Monday, April 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Potential%20Meetup%3A%20Ann%20Arbor%2C%20MI%2C%20USA&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APotential%20Meetup%3A%20Ann%20Arbor%2C%20MI%2C%20USA%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdvJdEkjWE9WMzwX7u%2Fpotential-meetup-ann-arbor-mi-usa%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Potential%20Meetup%3A%20Ann%20Arbor%2C%20MI%2C%20USA%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdvJdEkjWE9WMzwX7u%2Fpotential-meetup-ann-arbor-mi-usa", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdvJdEkjWE9WMzwX7u%2Fpotential-meetup-ann-arbor-mi-usa", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 14, "htmlBody": "<p>Tentative date: either Saturday, May 11 or Sunday, May 12 (2013).&nbsp; Is anyone interested?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dvJdEkjWE9WMzwX7u", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.1760579386074276e-06, "legacy": true, "legacyId": "22371", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-22T03:18:09.010Z", "modifiedAt": null, "url": null, "title": "Meetup : Mountain View: More on Reinforcement", "slug": "meetup-mountain-view-more-on-reinforcement", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.064Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GyS7FAnozqnzJ2bmZ/meetup-mountain-view-more-on-reinforcement", "pageUrlRelative": "/posts/GyS7FAnozqnzJ2bmZ/meetup-mountain-view-more-on-reinforcement", "linkUrl": "https://www.lesswrong.com/posts/GyS7FAnozqnzJ2bmZ/meetup-mountain-view-more-on-reinforcement", "postedAtFormatted": "Monday, April 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Mountain%20View%3A%20More%20on%20Reinforcement&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Mountain%20View%3A%20More%20on%20Reinforcement%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGyS7FAnozqnzJ2bmZ%2Fmeetup-mountain-view-more-on-reinforcement%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Mountain%20View%3A%20More%20on%20Reinforcement%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGyS7FAnozqnzJ2bmZ%2Fmeetup-mountain-view-more-on-reinforcement", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGyS7FAnozqnzJ2bmZ%2Fmeetup-mountain-view-more-on-reinforcement", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 220, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m0'>Mountain View: More on Reinforcement</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 April 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">167 Jasmine Ct, Mountain View, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>More from Karen Pryor's <em>Don't Shoot the Dog</em>, as we only got through about half of it last time. Including:</p>\n\n<ul>\n<li>A (fast!) review of last week's stuff</li>\n<li>How to train responses to specific cues</li>\n<li>Methods for training away an unwanted behavior</li>\n</ul>\n\n<p>Though they sound straightforward, that the ability to do the last two tasks are the primary atoms that let you <em>program your brain</em> -- to institute appropriate, perhaps-unintuitive behaviors at the right time, and to get rid of such behavior. If we can do this -- practice doing it, make a habit of this practice -- then we can make ourselves more awesome in <a href=\"http://lesswrong.com/lw/5kz/the_5second_level/\">fine detail</a>.</p>\n\n<p>I'd love to have a conversation about what it'd look like to take these ideas <em>seriously</em>. And, since we only did one round last time, let's play a bit more of the Training Game. Maybe with a little more structure. :j</p>\n\n<p>See you there!</p>\n\n<hr />\n\n<p>If you're in the San Francisco Bay area, consider joining the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/bayarealesswrong\">Bay Area Less Wrong mailing list</a>.\nRegular meetups in Mountain View and Berkeley, and other events, are announced and discussed there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m0'>Mountain View: More on Reinforcement</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GyS7FAnozqnzJ2bmZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 1.1760738202539851e-06, "legacy": true, "legacyId": "22372", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Mountain_View__More_on_Reinforcement\">Discussion article for the meetup : <a href=\"/meetups/m0\">Mountain View: More on Reinforcement</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 April 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">167 Jasmine Ct, Mountain View, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>More from Karen Pryor's <em>Don't Shoot the Dog</em>, as we only got through about half of it last time. Including:</p>\n\n<ul>\n<li>A (fast!) review of last week's stuff</li>\n<li>How to train responses to specific cues</li>\n<li>Methods for training away an unwanted behavior</li>\n</ul>\n\n<p>Though they sound straightforward, that the ability to do the last two tasks are the primary atoms that let you <em>program your brain</em> -- to institute appropriate, perhaps-unintuitive behaviors at the right time, and to get rid of such behavior. If we can do this -- practice doing it, make a habit of this practice -- then we can make ourselves more awesome in <a href=\"http://lesswrong.com/lw/5kz/the_5second_level/\">fine detail</a>.</p>\n\n<p>I'd love to have a conversation about what it'd look like to take these ideas <em>seriously</em>. And, since we only did one round last time, let's play a bit more of the Training Game. Maybe with a little more structure. :j</p>\n\n<p>See you there!</p>\n\n<hr>\n\n<p>If you're in the San Francisco Bay area, consider joining the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/bayarealesswrong\">Bay Area Less Wrong mailing list</a>.\nRegular meetups in Mountain View and Berkeley, and other events, are announced and discussed there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Mountain_View__More_on_Reinforcement1\">Discussion article for the meetup : <a href=\"/meetups/m0\">Mountain View: More on Reinforcement</a></h2>", "sections": [{"title": "Discussion article for the meetup : Mountain View: More on Reinforcement", "anchor": "Discussion_article_for_the_meetup___Mountain_View__More_on_Reinforcement", "level": 1}, {"title": "Discussion article for the meetup : Mountain View: More on Reinforcement", "anchor": "Discussion_article_for_the_meetup___Mountain_View__More_on_Reinforcement1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JcpzFpPBSmzuksmWM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-22T04:41:19.766Z", "modifiedAt": null, "url": null, "title": "Pascal's wager", "slug": "pascal-s-wager", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.896Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "duckduckMOO", "createdAt": "2011-11-06T17:29:28.080Z", "isAdmin": false, "displayName": "duckduckMOO"}, "userId": "R8orY4w8kni4HydST", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J6eLhAxc4PgJFf4uJ/pascal-s-wager", "pageUrlRelative": "/posts/J6eLhAxc4PgJFf4uJ/pascal-s-wager", "linkUrl": "https://www.lesswrong.com/posts/J6eLhAxc4PgJFf4uJ/pascal-s-wager", "postedAtFormatted": "Monday, April 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pascal's%20wager&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APascal's%20wager%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ6eLhAxc4PgJFf4uJ%2Fpascal-s-wager%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pascal's%20wager%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ6eLhAxc4PgJFf4uJ%2Fpascal-s-wager", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ6eLhAxc4PgJFf4uJ%2Fpascal-s-wager", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1760, "htmlBody": "<h2 style=\"margin: 0px 0px 0.75em 35px; color: #333333; font-size: 1.3333em; z-index: 1; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><br /></h2>\n<p>I started this as a comment on \"Being half wrong about pascal's wager is even worse\" but its really long, so I'm posting it in discussion instead.</p>\n<p>&nbsp;</p>\n<p>Also I illustrate here using negative examples (hell and equivalents) for the sake of&nbsp;followability&nbsp;and am a little worried about inciting some paranoia so am reminding you here that every negative example has an equal and opposite positive partner. For example pascal's wager has the opposite where accepting sends you to hell, it also has the opposite where refusing sends you to heaven. I haven't mentioned any positive equivalents or opposites below. Also all of these possibilities are literally effectively 0 so don't be worrying.</p>\n<p>&nbsp;</p>\n<p>\"For so long as I can remember, I have rejected Pascal's Wager in all its forms on sheerly practical grounds: anyone who tries to plan out their life by chasing a 1 in 10,000 chance of a huge&nbsp;pay-off&nbsp;is almost certainly doomed in practice. &nbsp;This kind of clever reasoning never pays off in real life...\"</p>\n<p>&nbsp;</p>\n<p>Pascal's wager shouldn't be in in the reference class of real life. It is a unique situation that would never crop up in real life as you're using it. In the world in which pascal's wager is correct you would still see people who plan out their lives on a 1 in 10000 chance of a huge&nbsp;pay-off&nbsp;fail 9999 times out of 10000. Also, this doesn't work for actually excluding pascal's wager. If pascal's wager starts off excluded from the category real life you've already made up your mind so this cannot quite be the actual order of events.</p>\n<p>&nbsp;</p>\n<p>In this case 9999 times you waste your&nbsp;Christianity&nbsp;and 1/10000 you don't go to hell for eternity, which is, at a vast understatement, much worse than 10000 times as bad as&nbsp;worshipping&nbsp;god even at the expense of the sanity it costs to force a change in belief, the damage it does to your psyche to live as a victim of self inflicted&nbsp;Stockholm&nbsp;syndrome, and any other non obvious cost: With these premises choosing to&nbsp;believe&nbsp;in God produces infinitely better consequences on average.</p>\n<p>&nbsp;</p>\n<p>Luckily the premises are wrong. 1/10000 is about 1/10000 too high for the relevant probability. Which is:</p>\n<p>the probability that the wager or equivalent, (anything whose acceptance would prevent you going to hell is equivalent) is true</p>\n<p>MINUS</p>\n<p>the probability that its opposite or equivalent, (anything which would send you to hell for accepting is equivalent), is true&nbsp;</p>\n<p>&nbsp;</p>\n<p>1/10000 is also way too high even if you're not accounting for opposite possibilities.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>Equivalence here refers to what behaviours it punishes or rewards. I used hell because it is in the most popular wager but it applies to all wagers. To illustrate: If its true that there is one god: ANTIPASCAL GOD, and he sends you to hell for accepting any pascal's wager, then that's equivalent to any pascal's wager you hear having an opposite (no more \"or equivalent\"s will be typed but they still apply) which is true because if you accept any pascal's wager you go to hell. Conversely, If PASCAL GOD is the only god and he sends you to hell unless you accept any pascal's wager, that's equivalent to any pascal's wager you hear being true.</p>\n<p>&nbsp;</p>\n<p>The real trick of pascals wager is the idea that they're generally no more likely than their opposite. For example, there are lots of good, fun, reasons to assign the Christian pascal's wager a lower probability than its opposite even engaging on a Christian level:</p>\n<p>&nbsp;</p>\n<p>Hell is a medieval invention/translation error: the eternal torture thing isn't even in the modern bibles.</p>\n<p>The belief or hell rule is hella evil and gains credibility from the same source (Christians, not the bible) who also claim that god is good as a more fundamental belief, which directly contradicts the hell or belief rule.</p>\n<p>The bible claims that God hates people eating shellfish, taking his name in vain, and jealousy. Apparently taking his name in vain is the only unforgivable sin. So if they're right about the evil stuff, you're probably going to hell anyway.</p>\n<p>It makes no sense that god would care enough about your belief and worship to consign people to eternal torture but not enough to show up once in a while.</p>\n<p>it makes no sense to reward people for dishonesty.</p>\n<p>The evilness really can't be overstated. eternal torture as a response to a mistake which is at its worst due to stupidity (but actually not even that: just a stacked deck scenario), outdoes pretty much everyone in terms of evilness. worse than pretty much every fucked up thing every other god is reputed to have done put together. The psychopath in the bible doesn't come close to coming close.</p>\n<p>&nbsp;</p>\n<p>The problem with the general case of religious pascal's wagers is that people make stuff up (usually unintentionally) and what made up stuff gains traction has nothing to do with what is true. When both&nbsp;Christianity&nbsp;and&nbsp;Hinduism&nbsp;are taken seriously by millions (as were the&nbsp;Roman/Greek&nbsp;gods, and&nbsp;Viking&nbsp;gods, and&nbsp;Aztec&nbsp;gods, and&nbsp;Greek&nbsp;gods, and all sorts of other gods at different times, by large percentages of people) mass religious belief is 0 evidence. At most one religion set (e.g.&nbsp;Greek/Roman, Christian/Muslim/Jewish,&nbsp;etc) is even close to right so at least the rest are popular independently of truth.</p>\n<p>&nbsp;</p>\n<p>The existence of a religion does not&nbsp;elevate the possibility that the god they describe exists above the possibility that the opposite exists because there is no evidence that religion has any accuracy in determining the features of a god, should one exist.</p>\n<p>&nbsp;</p>\n<p>You might intuitively lean towards religions having better than 0 accuracy if a god exists but remember there's a lot of fictional evidence out there to generalise from. It <em>is</em> a matter of judgement here. there's no logical proof for 0 or worse accuracy (other than it being default and the lack of evidence) but negative accuracy is a possibility and you've probably played priest classes in video games or just seen how respected religions are and been primed to overestimate religion's accuracy in that hypothetical. Also if there is a god it has not shown itself&nbsp;publicly&nbsp;in a very long time, or ever. So it seems to have a preference for not being revealed. &nbsp;Also humans tend to be somewhat evil and read into others what they see in themselves. and I assume any high tier god (one that had the power to create and maintain a hell, detect disbelief, preserve immortal souls and put people in hell) would not be evil. Being evil or totally unscrupled has benefits among humans which a god would not get. I think without bad peers or parents there's no reason to be evil. I think people are mostly evil in relation to other people. &nbsp;So I religions a slight positive accuracy in the scenario where there is a god but it does not exceed priors against pascal's wager (another one is that they're pettily human) or perhaps even the god's desire to stay hidden.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Even if God itself whispered pascal's wager in your ear there is no incentive for it to actually carry out the threat:&nbsp;</p>\n<div>\n<p>&nbsp;</p>\n<p>There is only one iteration.</p>\n</div>\n<div>AND</div>\n<p>These threats aren't being made in person by the deity. They are either second hand or independently discovered so:</p>\n<p>The deity has no use for making the threat true, to claim it more believably, as it might if it was an imperfect liar (at a level detectable by humans) that made the threats in person.</p>\n<p>The deity has total plausible deniability.</p>\n<p>Which adds up to all of the benefits of the threat having already being extracted by the time the punishment is due and no possibility of a rep hit (which wouldn't matter anyway.)</p>\n<p>&nbsp;</p>\n<p>So, All else being equal. i.e. unless the god is the god of threats or pascal's wagers (whose opposites are equally likely):</p>\n<p>&nbsp;</p>\n<p>If God is good (+ev on human happiness -ev on human sadness that sort of thing), actually carrying out the threats has negative value.</p>\n<p>If god is scarily-doesn't-give-a-shit-neutral to humans, it still has no incentive to actually carry out the threat and a non zero energy cost.</p>\n<p>if god gives the tiniest most&nbsp;infinitesimal&nbsp;shit about humans its incentive to actually carry out the threat is negative.</p>\n<p>&nbsp;</p>\n<p>If God is evil you're fucked anyway:</p>\n<p>The threat gains no power by being true, so the only incentive a God can have for following through is that it values human suffering. If it does, why would it not send you to hell if you believed in it? (remember that the god of commitments is as likely as the god of breaking commitments)</p>\n<p>&nbsp;</p>\n<p>Despite the increased complexity of a human mind I think the most (not saying its at all likely just that all others are obviously wrong) likely motivational system for a god which would make it honour the wager is that that God thinks like a human and therefore would keep its commitment out of spite or gratitude or some other human reason. So here's why I think that one is wrong. It's generalizing from fictional evidence: humans aren't that&nbsp;homogeneous&nbsp;(and one without peers would be less so), and if a god gains&nbsp;likelihood&nbsp;to keep a commitment from humanness it also gains not -designed-to-be-evil-ness that would make it less likely to make evil wagers. &nbsp;It also has no source for spite or gratitude, having no peers. Finally could you ever feel spite towards a bug? Or gratitude? We are not just ants compared to a god, we're ant-ant-ant-etc-ants.</p>\n<p>&nbsp;</p>\n<p>Also there's the reasons that refusing can actually get you in trouble: &nbsp;bullies don't get nicer when their demands are met. It's often not the suffering they're after but the dominance, at which point the suffering becomes an enjoyable illustration of that dominance. &nbsp;As we are ant-ant-etc-ants this probability is lower but The fact that we aren't all already in hell suggests that if god is evil it is not raw suffering that it values. Hostages are often executed even when the ransom is paid. Even if it is evil, it could be any kind of evil: its preferences cannot have been homogenised by memes and consensus.</p>\n<p>&nbsp;</p>\n<p>There's also the rather cool possibility that if human-god is sending people to hell, maybe its for lack of understanding. If it wants belief it can take it more effectively than this. If it wants to hurt you it will hurt you anyway. Perhaps peerless, it was never prompted to think through the consequences of making others suffer. Maybe god, in the&nbsp;absence&nbsp;of peers just needs someone to explain that its not nice to let people burn in hell for eternity. I for one remember suddenly realising that those other fleshbags hosted people. I figured it out for myself but if I grew up alone as the master of the universe maybe I would have needed someone to explain it to me.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J6eLhAxc4PgJFf4uJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": -22, "extendedScore": null, "score": -5.8e-05, "legacy": true, "legacyId": "22373", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-22T18:33:31.572Z", "modifiedAt": null, "url": null, "title": "Meetup : Durham NC meetup: Living Luminously, Part 2", "slug": "meetup-durham-nc-meetup-living-luminously-part-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GFxefoDj6tLa7K8XR/meetup-durham-nc-meetup-living-luminously-part-2", "pageUrlRelative": "/posts/GFxefoDj6tLa7K8XR/meetup-durham-nc-meetup-living-luminously-part-2", "linkUrl": "https://www.lesswrong.com/posts/GFxefoDj6tLa7K8XR/meetup-durham-nc-meetup-living-luminously-part-2", "postedAtFormatted": "Monday, April 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Durham%20NC%20meetup%3A%20Living%20Luminously%2C%20Part%202&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Durham%20NC%20meetup%3A%20Living%20Luminously%2C%20Part%202%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGFxefoDj6tLa7K8XR%2Fmeetup-durham-nc-meetup-living-luminously-part-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Durham%20NC%20meetup%3A%20Living%20Luminously%2C%20Part%202%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGFxefoDj6tLa7K8XR%2Fmeetup-durham-nc-meetup-living-luminously-part-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGFxefoDj6tLa7K8XR%2Fmeetup-durham-nc-meetup-living-luminously-part-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 160, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m1'>Durham NC meetup: Living Luminously, Part 2</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">25 April 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">420 E Geer St, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Continuing in the Living Luminously sequence, we'll cover:</p>\n\n<p>The ABCs of Luminosity <br />\n(<a href=\"http://lesswrong.com/lw/1y0/the_abcs_of_luminosity/\" rel=\"nofollow\">http://lesswrong.com/lw/1y0/the_abcs_of_luminosity/</a>) <br />\n\"Affect, behavior, and circumstance interact with each other. These interactions constitute informative patterns that you should identify and use in your luminosity project.\"</p>\n\n<p>Lights, Camera, Action <br />\n(<a href=\"http://lesswrong.com/lw/1yb/lights_camera_action/\" rel=\"nofollow\">http://lesswrong.com/lw/1yb/lights_camera_action/</a>) <br />\n\"You should pay attention to key mental events, on a regular and frequent basis, because important thoughts can happen very briefly or very occasionally and you need to catch them.\"</p>\n\n<p>The Spotlight <br />\n(<a href=\"http://lesswrong.com/lw/1za/the_spotlight/\" rel=\"nofollow\">http://lesswrong.com/lw/1za/the_spotlight/</a>) <br />\n\"Inspecting thoughts is easier and more accurate if they aren't in your head. Look at them in another form from the outside, like they belonged to someone else.\"</p>\n\n<p>Use social pressure to increase the likelihood of your attendance -- RSVP here or via the RTLW group! (<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m1'>Durham NC meetup: Living Luminously, Part 2</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GFxefoDj6tLa7K8XR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.176714780874906e-06, "legacy": true, "legacyId": "22379", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_2\">Discussion article for the meetup : <a href=\"/meetups/m1\">Durham NC meetup: Living Luminously, Part 2</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">25 April 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">420 E Geer St, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Continuing in the Living Luminously sequence, we'll cover:</p>\n\n<p>The ABCs of Luminosity <br>\n(<a href=\"http://lesswrong.com/lw/1y0/the_abcs_of_luminosity/\" rel=\"nofollow\">http://lesswrong.com/lw/1y0/the_abcs_of_luminosity/</a>) <br>\n\"Affect, behavior, and circumstance interact with each other. These interactions constitute informative patterns that you should identify and use in your luminosity project.\"</p>\n\n<p>Lights, Camera, Action <br>\n(<a href=\"http://lesswrong.com/lw/1yb/lights_camera_action/\" rel=\"nofollow\">http://lesswrong.com/lw/1yb/lights_camera_action/</a>) <br>\n\"You should pay attention to key mental events, on a regular and frequent basis, because important thoughts can happen very briefly or very occasionally and you need to catch them.\"</p>\n\n<p>The Spotlight <br>\n(<a href=\"http://lesswrong.com/lw/1za/the_spotlight/\" rel=\"nofollow\">http://lesswrong.com/lw/1za/the_spotlight/</a>) <br>\n\"Inspecting thoughts is easier and more accurate if they aren't in your head. Look at them in another form from the outside, like they belonged to someone else.\"</p>\n\n<p>Use social pressure to increase the likelihood of your attendance -- RSVP here or via the RTLW group! (<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_21\">Discussion article for the meetup : <a href=\"/meetups/m1\">Durham NC meetup: Living Luminously, Part 2</a></h2>", "sections": [{"title": "Discussion article for the meetup : Durham NC meetup: Living Luminously, Part 2", "anchor": "Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_2", "level": 1}, {"title": "Discussion article for the meetup : Durham NC meetup: Living Luminously, Part 2", "anchor": "Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_21", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rLuZ6XrGpgjk9BNpX", "v4ngP587MDZ5rC48Y", "Zstm38omrpeu7iWeS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-22T19:01:38.279Z", "modifiedAt": null, "url": null, "title": "Minor, perspective changing facts", "slug": "minor-perspective-changing-facts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:04.768Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Nm6zNZmBh55pvoSBS/minor-perspective-changing-facts", "pageUrlRelative": "/posts/Nm6zNZmBh55pvoSBS/minor-perspective-changing-facts", "linkUrl": "https://www.lesswrong.com/posts/Nm6zNZmBh55pvoSBS/minor-perspective-changing-facts", "postedAtFormatted": "Monday, April 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Minor%2C%20perspective%20changing%20facts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMinor%2C%20perspective%20changing%20facts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNm6zNZmBh55pvoSBS%2Fminor-perspective-changing-facts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Minor%2C%20perspective%20changing%20facts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNm6zNZmBh55pvoSBS%2Fminor-perspective-changing-facts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNm6zNZmBh55pvoSBS%2Fminor-perspective-changing-facts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 322, "htmlBody": "<p>There's a lot of background mess in our mental pictures of the world. We try and be accurate on important issues, but a whole lot of the less important stuff we pick up from the media, the movies, and random impressions. And once these impressions are in our mental pictures, they just don't go away - until we find a fact that causes us to say \"huh\", and reassess.</p>\n<p>Here are three facts that have caused that \"huh\" in me, recently, and&nbsp;completely&nbsp;rearranged&nbsp;minor parts of my mental map. I'm sharing them here, because that experience is a valuable one.</p>\n<ol>\n<li>Think terrorist attack on Israel - did the phrase \"suicide bombing\" spring to mind? If so, you're so out of fashion: the last suicide bombing in Israel was in <a href=\"http://en.wikipedia.org/wiki/List_of_Palestinian_suicide_attacks\">2008</a>&nbsp;- a year where dedicated suicide bombers managed the feat of killing a grand total of 1 victim. Suicide bombings haven't happened in Israel for over half a decade.</li>\n<li>Large scale plane crashes seem to happen all the time, all over the world. They must happen at least a few times a year, in every major country, right? Well, if I'm reading this <a href=\"http://en.wikipedia.org/wiki/List_of_accidents_and_incidents_involving_commercial_aircraft\">page</a> right, the last time there was an airline crash in the USA that killed more that 50 people was... in <a href=\"http://en.wikipedia.org/wiki/American_Airlines_Flight_587\">2001</a>&nbsp;(2 months after 9/11). Nothing on that scale since then. And though there has been crashes on route to/from Spain and France since then, it seems that major air crashes in western countries is something that essentially never happens.</li>\n<li>The major cost of a rocket isn't the fuel, as I'd always thought. <a href=\"http://en.wikipedia.org/wiki/Falcon_9#Launch_prices\">It seems</a> that the Falcon 9 rocket costs $54 million per launch, of which fuel is only $0.2 million (or, as I prefer to think of it - I could sell my house to get enough fuel to fly to space). In the difference between those two prices, lies the potential for private spaceflight to low-Earth orbit.</li>\n</ol>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Nm6zNZmBh55pvoSBS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 58, "extendedScore": null, "score": 0.0005743363696095945, "legacy": true, "legacyId": "22378", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 158, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-22T19:51:09.164Z", "modifiedAt": null, "url": null, "title": "A thought-process testing opportunity", "slug": "a-thought-process-testing-opportunity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:03.464Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "PbyH3bFJCZjPX5DTp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YEczWSoYLiGkGG2eu/a-thought-process-testing-opportunity", "pageUrlRelative": "/posts/YEczWSoYLiGkGG2eu/a-thought-process-testing-opportunity", "linkUrl": "https://www.lesswrong.com/posts/YEczWSoYLiGkGG2eu/a-thought-process-testing-opportunity", "postedAtFormatted": "Monday, April 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20thought-process%20testing%20opportunity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20thought-process%20testing%20opportunity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYEczWSoYLiGkGG2eu%2Fa-thought-process-testing-opportunity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20thought-process%20testing%20opportunity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYEczWSoYLiGkGG2eu%2Fa-thought-process-testing-opportunity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYEczWSoYLiGkGG2eu%2Fa-thought-process-testing-opportunity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 161, "htmlBody": "<p>If you haven't seen the video of a wet towel being wrung out in space yet, it provides a great opportunity to test some basic rationality skills.</p>\n<p>Skill #1: Notice the opportunity. (I failed this test. I had a fuzzy, wrong idea about what would happen. I didn't notice the fuzziness of my own thinking until after I watched the video, when it was too late to apply basic rationality skills. I'll never know if I could have made a correct prediction.)</p>\n<p>Skill #2: Enumerate possibilities.</p>\n<p>Skill #3: Incorporate prior information.&nbsp;</p>\n<p>Skill #4: Making clear predictions.</p>\n<p>Skill #5: Understanding why/how your prediction failed/succeeded.</p>\n<p>Skill #6: There may be some things you predicted and some you didn't. Don't forget to notice the partial failures along with the partial success.</p>\n<p>&nbsp;</p>\n<p>Experiment:</p>\n<p>You are on the International Space Station. You get a towel soaking wet, then you wring it out. What happens?</p>\n<p><a href=\"http://www.youtube.com/watch?feature=player_embedded&amp;v=o8TssbmY-GM\">Video of the experiment</a></p>\n<p>&nbsp;</p>\n<p>If you haven't seen it, don't scroll into the comments.</p>\n<p>Don't click the link until you've thought about it!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DWWZwkxTJs4d5WrcX": 1, "8daMDi9NEShyLqxth": 1, "csMv9MvvjYJyeHqoo": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YEczWSoYLiGkGG2eu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 46, "extendedScore": null, "score": 1.1767691645965073e-06, "legacy": true, "legacyId": "22380", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-23T01:37:31.762Z", "modifiedAt": null, "url": null, "title": "Compromise: Send Meta Discussions to the Unofficial LessWrong Subreddit", "slug": "compromise-send-meta-discussions-to-the-unofficial-lesswrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:03.258Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "orthonormal", "createdAt": "2009-03-22T16:06:51.665Z", "isAdmin": false, "displayName": "orthonormal"}, "userId": "4fh2AAe3n7oBviyxx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N8EsWx6fEkw7sv87P/compromise-send-meta-discussions-to-the-unofficial-lesswrong", "pageUrlRelative": "/posts/N8EsWx6fEkw7sv87P/compromise-send-meta-discussions-to-the-unofficial-lesswrong", "linkUrl": "https://www.lesswrong.com/posts/N8EsWx6fEkw7sv87P/compromise-send-meta-discussions-to-the-unofficial-lesswrong", "postedAtFormatted": "Tuesday, April 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Compromise%3A%20Send%20Meta%20Discussions%20to%20the%20Unofficial%20LessWrong%20Subreddit&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACompromise%3A%20Send%20Meta%20Discussions%20to%20the%20Unofficial%20LessWrong%20Subreddit%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8EsWx6fEkw7sv87P%2Fcompromise-send-meta-discussions-to-the-unofficial-lesswrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Compromise%3A%20Send%20Meta%20Discussions%20to%20the%20Unofficial%20LessWrong%20Subreddit%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8EsWx6fEkw7sv87P%2Fcompromise-send-meta-discussions-to-the-unofficial-lesswrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8EsWx6fEkw7sv87P%2Fcompromise-send-meta-discussions-to-the-unofficial-lesswrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 372, "htmlBody": "<p>After a recent comment thread degenerated into an argument about trolling, moderation, and meta discussions, I came to the following conclusions:</p>\n<ol>\n<li>Meta conversations are annoying to stumble across, I'd rather not see them unless I think it's important, and I think other people mostly feel the same way. Moreover, moderators can't easily ignore those conversations when they encounter them, because they're usually attacks on the moderators themselves; and people can't simply avoid encountering them on a regular basis without avoiding LW altogether. This is a perfect recipe for a flamewar taking over Top Comments even when most people don't care that much.</li>\n<li>Officially banning all meta conversations, however, is a bad precedent, and I don't want LW to do that.</li>\n</ol>\n<p>Ideally, Less Wrong would implement a separate \"META\" area (so that people can read the regular area for all the object-level discussions, and then sally into the meta area only when they're ready). After talking to Luke (who also wants this), though, it seems clear that nobody is able to implement it very soon. So as a stopgap measure, I'm personally going to start doing the following, and I hope you join me:</p>\n<p><strong>Whenever a conversation starts getting bitterly meta in a thread that's not originally about a LW site meta issue, I'm going to tell people to start a thread on the&nbsp;<a href=\"http://www.reddit.com/r/LessWrong/comments/17y819/lw_uncensored_thread/\">LW Uncensored Reddit Thread</a>&nbsp;instead. Then I'm going to downvote anyone who continues the meta war on the original thread.</strong></p>\n<p><strong></strong>I know it's annoying to send people somewhere that has a different login system, but it's as far as I can tell the best fix we currently have. Since some meta conversations are important, I'm not going to punish people for linking to meta thread discussions that they think are significant, and the relevant place for those links is usually the Open Thread. I don't want LessWrong to be a community devoted to arguing about the mechanics of LessWrong, so that's my suggestion.</p>\n<p>Thoughts? (And yes, this thread is obviously open to meta discussion. I'm hopefully&nbsp;<em>doing something constructive</em> about the problem, instead of just complaining about it, though.)</p>\n<p><strong>EDIT:</strong> Changed the link to the uncensored thread more specifically, at Luke's request; originally I linked to the <a href=\"http://www.reddit.com/r/LessWrong/\">general LW subreddit</a>, which is more heavily moderated.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N8EsWx6fEkw7sv87P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": -2, "extendedScore": null, "score": -9e-06, "legacy": true, "legacyId": "22381", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-23T04:56:26.643Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Unfinished Mystery of the Shangri-La Diet", "slug": "seq-rerun-the-unfinished-mystery-of-the-shangri-la-diet", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.317Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r9Yf66vqShBkEasLw/seq-rerun-the-unfinished-mystery-of-the-shangri-la-diet", "pageUrlRelative": "/posts/r9Yf66vqShBkEasLw/seq-rerun-the-unfinished-mystery-of-the-shangri-la-diet", "linkUrl": "https://www.lesswrong.com/posts/r9Yf66vqShBkEasLw/seq-rerun-the-unfinished-mystery-of-the-shangri-la-diet", "postedAtFormatted": "Tuesday, April 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Unfinished%20Mystery%20of%20the%20Shangri-La%20Diet&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Unfinished%20Mystery%20of%20the%20Shangri-La%20Diet%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr9Yf66vqShBkEasLw%2Fseq-rerun-the-unfinished-mystery-of-the-shangri-la-diet%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Unfinished%20Mystery%20of%20the%20Shangri-La%20Diet%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr9Yf66vqShBkEasLw%2Fseq-rerun-the-unfinished-mystery-of-the-shangri-la-diet", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr9Yf66vqShBkEasLw%2Fseq-rerun-the-unfinished-mystery-of-the-shangri-la-diet", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 171, "htmlBody": "<p>Today's post, <a href=\"/lw/a6/the_unfinished_mystery_of_the_shangrila_diet/\">The Unfinished Mystery of the Shangri-La Diet</a> was originally published on 10 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries#The_Unfinished_Mystery_of_the_Shangri-La_Diet\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>An intriguing dietary theory which appears to allow some people to lose substantial amounts of weight, but doesn't appear to work at all for others.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/h7z/seq_rerun_beware_of_otheroptimizing/\">Beware of Other-Optimizing</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r9Yf66vqShBkEasLw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 1.1771513110654327e-06, "legacy": true, "legacyId": "22386", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BD4oExxQguTgpESdm", "kHsExYq6opRaNRzu7", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-23T13:18:30.995Z", "modifiedAt": null, "url": null, "title": "[LINK] Possible Unrepresentative Subjects in Studies of Medical Interventions", "slug": "link-possible-unrepresentative-subjects-in-studies-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.862Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TimS", "createdAt": "2011-10-11T12:16:35.235Z", "isAdmin": false, "displayName": "TimS"}, "userId": "pewD8vNSS3LGCvE4t", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gHT28ZzHvMhDjRNGb/link-possible-unrepresentative-subjects-in-studies-of", "pageUrlRelative": "/posts/gHT28ZzHvMhDjRNGb/link-possible-unrepresentative-subjects-in-studies-of", "linkUrl": "https://www.lesswrong.com/posts/gHT28ZzHvMhDjRNGb/link-possible-unrepresentative-subjects-in-studies-of", "postedAtFormatted": "Tuesday, April 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Possible%20Unrepresentative%20Subjects%20in%20Studies%20of%20Medical%20Interventions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Possible%20Unrepresentative%20Subjects%20in%20Studies%20of%20Medical%20Interventions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgHT28ZzHvMhDjRNGb%2Flink-possible-unrepresentative-subjects-in-studies-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Possible%20Unrepresentative%20Subjects%20in%20Studies%20of%20Medical%20Interventions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgHT28ZzHvMhDjRNGb%2Flink-possible-unrepresentative-subjects-in-studies-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgHT28ZzHvMhDjRNGb%2Flink-possible-unrepresentative-subjects-in-studies-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 309, "htmlBody": "<p>This <a href=\"http://www.samefacts.com/2013/04/health-and-medicine/the-subjects-in-the-studies-that-guide-your-medical-care-may-not-be-like-you-at-all/\">blog post</a> on subject selection in study design seems like it might be interesting to folks.</p>\n<p>From the post:</p>\n<blockquote>\n<p>[C]linical trials often forbid enrollment by many patients who are treated in our health care system, including for example anyone who is over the age of 60, or has multiple medical conditions, or is on medications etc. This makes the clinical trial easier to conduct but it can also result in a research sample that is completely unlike real-world health care recipients. If for example a new medication has been FDA-approved based on a clinical trial that excluded anyone who was already taking another medication, any adverse medication interactions won&rsquo;t come to light until patients start experiencing them in the health care system.</p>\n</blockquote>\n<p>The post links to the article, published in JAMA Internal Medicine. Abstract for the publication:</p>\n<blockquote>\n<p><span id=\"scm6MainContent_lblExtract\">Because they assign patients to treatment conditions, randomized clinical trials (RCTs) offer unparalleled internal validity for drawing inferences about the efficacy of a medical treatment. Whether such inferences can be generalized is not always clear because many RCTs enroll a low and unrepresentative proportion of all patients.<sup> </sup>The challenges of judging the clinical utility of clinical trial results are increased by poor reporting. The study by Gross et al of trials published in leading medical journals from 1999 through 2000 found that only 28% reported the proportion of screened patients who were enrolled. These deficiencies may have been ameliorated in the past decade because the CONSORT statement was revised in 2001 to require more complete information on the enrollment process in reports of clinical trials, and because many treatment research fields have been showing greater concern about generating knowledge that better informs clinical practice. Accordingly, the present study assessed the extent to which low enrollment rates are still characteristic of widely cited clinical trials, and whether reporting of enrollment information has improved.</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gHT28ZzHvMhDjRNGb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "22388", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-23T15:45:18.400Z", "modifiedAt": null, "url": null, "title": "[LINK] SMBC on AI and altruism", "slug": "link-smbc-on-ai-and-altruism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:02.771Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "feanor1600", "createdAt": "2009-07-22T18:12:08.907Z", "isAdmin": false, "displayName": "feanor1600"}, "userId": "zwyrE6j2q36cXEuAH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BQ88mLCmafD77Q3qK/link-smbc-on-ai-and-altruism", "pageUrlRelative": "/posts/BQ88mLCmafD77Q3qK/link-smbc-on-ai-and-altruism", "linkUrl": "https://www.lesswrong.com/posts/BQ88mLCmafD77Q3qK/link-smbc-on-ai-and-altruism", "postedAtFormatted": "Tuesday, April 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20SMBC%20on%20AI%20and%20altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20SMBC%20on%20AI%20and%20altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBQ88mLCmafD77Q3qK%2Flink-smbc-on-ai-and-altruism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20SMBC%20on%20AI%20and%20altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBQ88mLCmafD77Q3qK%2Flink-smbc-on-ai-and-altruism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBQ88mLCmafD77Q3qK%2Flink-smbc-on-ai-and-altruism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.smbc-comics.com/index.php?db=comics&amp;id=2956#comic\">http://www.smbc-comics.com/index.php?db=comics&amp;id=2956#comic</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BQ88mLCmafD77Q3qK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -10, "extendedScore": null, "score": -6e-06, "legacy": true, "legacyId": "22389", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-23T20:35:16.319Z", "modifiedAt": null, "url": null, "title": "Normativity and Meta-Philosophy", "slug": "normativity-and-meta-philosophy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:04.602Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wei_Dai", "createdAt": "2009-03-06T19:59:52.096Z", "isAdmin": false, "displayName": "Wei_Dai"}, "userId": "4SHky5j2PNcRwBiZt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LPRuP6vdDBTeGnXmC/normativity-and-meta-philosophy", "pageUrlRelative": "/posts/LPRuP6vdDBTeGnXmC/normativity-and-meta-philosophy", "linkUrl": "https://www.lesswrong.com/posts/LPRuP6vdDBTeGnXmC/normativity-and-meta-philosophy", "postedAtFormatted": "Tuesday, April 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Normativity%20and%20Meta-Philosophy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANormativity%20and%20Meta-Philosophy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLPRuP6vdDBTeGnXmC%2Fnormativity-and-meta-philosophy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Normativity%20and%20Meta-Philosophy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLPRuP6vdDBTeGnXmC%2Fnormativity-and-meta-philosophy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLPRuP6vdDBTeGnXmC%2Fnormativity-and-meta-philosophy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 390, "htmlBody": "<p>I find Eliezer's&nbsp;explanation&nbsp;of what \"should\" means to be <a href=\"/lw/1fz/a_less_wrong_singularity_article/19pv\">unsatisfactory</a>, and here's an attempt to do better. Consider the following usages of the word:</p>\n<ol>\n<li>You should stop building piles of X pebbles because X = Y*Z.</li>\n<li>We should kill that police informer and dump his body in the river.</li>\n<li>You should one-box in Newcomb's problem.</li>\n</ol>\n<p>All of these seem to be sensible sentences, depending on the speaker and intended audience. #1, for example, seems a reasonable translation of what a <a href=\"/lw/sy/sorting_pebbles_into_correct_heaps/\">pebblesorter</a> would say after discovering that X = Y*Z. Some might argue for \"pebblesorter::should\" instead of plain \"should\", but it's hard to deny that we need \"should\" in some form to fill the blank there for a translation, and I think few people besides Eliezer would object to plain \"should\".</p>\n<p>Normativity, or the idea that there's something in common about how \"should\" and similar words are used in different contexts, is an active area in academic philosophy. I won't try to <a href=\"http://analysis.oxfordjournals.org/content/70/2/331.full.pdf?keytype=ref&amp;ijkey=Q50DmwsULURmO5j\">survey</a> the current theories, but my current thinking is that \"should\" usually means \"better according to some shared, motivating standard or procedure of evaluation\", but occasionally it can also be used to <em>instill </em>such a standard or procedure of evaluation in someone (such as a child) who is open to being instilled by the speaker/writer.</p>\n<p>It seems to me that different people (including different humans) can have different motivating standards and procedures of evaluation, and apparent disagreements about \"should' sentences can arise from having different standards/procedures or from disagreement about whether something is better according to a shared standard/procedure. In most areas my personal procedure of evaluation is something that might be called \"doing philosophy\" but many people apparently do not share this. For example a religious extremist may have been taught by their parents, teachers, or peers to follow some rigid moral code given in their holy books, and not be open to any philosophical arguments that I can offer.</p>\n<p>Of course this isn't a fully satisfactory theory of normativity since I don't know <a href=\"/lw/2id/metaphilosophical_mysteries/\">what \"philosophy\" really is</a> (and I'm not even sure it really is a thing). But it does help explain how \"should\" in morality might relate to \"should\" in other areas such as decision theory, does not require assuming that all humans ultimately share the same morality, and avoids the need for linguistic contortions such as \"pebblesorter::should\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Z8wZZLeLMJ3NSK7kR": 2, "k6igEkzKYY2EpY7Su": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LPRuP6vdDBTeGnXmC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 29, "extendedScore": null, "score": 6e-05, "legacy": true, "legacyId": "22390", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mMBTPTjRbsrqbSkZE", "MAhueZtNz5SnDPhsy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-24T05:37:03.768Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Akrasia and Shangri-La", "slug": "seq-rerun-akrasia-and-shangri-la", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:03.183Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LiNzGXW576G8iSz9N/seq-rerun-akrasia-and-shangri-la", "pageUrlRelative": "/posts/LiNzGXW576G8iSz9N/seq-rerun-akrasia-and-shangri-la", "linkUrl": "https://www.lesswrong.com/posts/LiNzGXW576G8iSz9N/seq-rerun-akrasia-and-shangri-la", "postedAtFormatted": "Wednesday, April 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Akrasia%20and%20Shangri-La&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Akrasia%20and%20Shangri-La%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLiNzGXW576G8iSz9N%2Fseq-rerun-akrasia-and-shangri-la%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Akrasia%20and%20Shangri-La%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLiNzGXW576G8iSz9N%2Fseq-rerun-akrasia-and-shangri-la", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLiNzGXW576G8iSz9N%2Fseq-rerun-akrasia-and-shangri-la", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 247, "htmlBody": "<p>Today's post, <a href=\"/lw/ab/akrasia_and_shangrila/\">Akrasia and Shangri-La</a> was originally published on 10 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The Shangri-La diet works amazingly well for some people, but completely fails for others, for no known reason. Since the diet has a metabolic rationale and is not supposed to require willpower, its failure in my and other cases is unambigiously mysterious. If it required a component of willpower, then I and others might be tempted to blame myself for not having willpower. The art of combating akrasia (willpower failure) has the same sort of mysteries and is in the same primitive state; we don't know the deeper rule that explains why a trick works for one person but not another.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/h9u/seq_rerun_the_unfinished_mystery_of_the_shangrila/\">The Unfinished Mystery of the Shangri-La Diet</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LiNzGXW576G8iSz9N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 1.178190054207744e-06, "legacy": true, "legacyId": "22398", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["geqg9mk73NQh6uieE", "r9Yf66vqShBkEasLw", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-24T15:11:01.920Z", "modifiedAt": null, "url": null, "title": "Rocket science and big money - a cautionary tale of math gone wrong", "slug": "rocket-science-and-big-money-a-cautionary-tale-of-math-gone", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:28.624Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Morendil", "createdAt": "2009-09-21T16:34:39.505Z", "isAdmin": false, "displayName": "Morendil"}, "userId": "aDcxmpDTkqN6vWmRZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tggnLEXxrTDWQwDL3/rocket-science-and-big-money-a-cautionary-tale-of-math-gone", "pageUrlRelative": "/posts/tggnLEXxrTDWQwDL3/rocket-science-and-big-money-a-cautionary-tale-of-math-gone", "linkUrl": "https://www.lesswrong.com/posts/tggnLEXxrTDWQwDL3/rocket-science-and-big-money-a-cautionary-tale-of-math-gone", "postedAtFormatted": "Wednesday, April 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rocket%20science%20and%20big%20money%20-%20a%20cautionary%20tale%20of%20math%20gone%20wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARocket%20science%20and%20big%20money%20-%20a%20cautionary%20tale%20of%20math%20gone%20wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtggnLEXxrTDWQwDL3%2Frocket-science-and-big-money-a-cautionary-tale-of-math-gone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rocket%20science%20and%20big%20money%20-%20a%20cautionary%20tale%20of%20math%20gone%20wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtggnLEXxrTDWQwDL3%2Frocket-science-and-big-money-a-cautionary-tale-of-math-gone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtggnLEXxrTDWQwDL3%2Frocket-science-and-big-money-a-cautionary-tale-of-math-gone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1446, "htmlBody": "<p>&nbsp;</p>\n<p>The <a href=\"http://www.nasa.gov/centers/ivv/pdf/174321main_Annual_Report_06_Final.pdf\">2006 report</a> from NASA's \"Independent Verification and Validation Facility\" makes some interesting claims. Turning to page 6, we learn that thanks to IV&amp;V, \"NASA realized a software rework risk reduction benefit of $1.6 Billion in Fiscal Year 2006 alone\". This is close to 10% of NASA's overall annual budget, roughly equal to the entire annual budget of the International Space Station!</p>\n<p>If the numbers check out, this is an impressive feat for IV&amp;V (the more formal big brother of \"testing\" or \"quality assurance\" departments that most software development efforts include). Do they?</p>\n<p>&nbsp;</p>\n<h2>Flaubert and the math of ROI</h2>\n<p>Back in 1841, to <a href=\"http://en.wikipedia.org/wiki/Age_of_the_captain\">tease his sister</a>, Gustave Flaubert invented the \"age of the captain problem\", which ran like this:</p>\n<blockquote>\n<p>A ship sails the ocean. It left Boston with a cargo of wool. It grosses 200 tons. [...] There are 12 passengers aboard, the wind is blowing East-North-East, the clock points to a quarter past three in the afternoon. It is the month of May. <strong>How old is the captain?</strong></p>\n</blockquote>\n<p>Flaubert was pointing out one common way people fail at math: you can only get sensible results from a calculation if the numbers you put in are related in the right ways. (Unfortunately, math education tends to be excessively heavy on the \"manipulate numbers\" part and to skimp on the \"make sense of the question\" part, a trend dissected by French mathematician <a href=\"http://fr.wikipedia.org/wiki/Stella_Baruk\">Stella Baruk</a> who titled one of her books after Flaubert's little joke on his sister.)</p>\n<p>Unfortunately, NASA's math turns out on inspection to be \"age-of-the-captain\" math. (This strikes me as a big embarrassment to an organization literally composed mainly of rocket scientists.)<a id=\"more\"></a></p>\n<p>The $1.6 billion claimed by NASA's document is derived by applying a ROI calculation: NASA spent $19 million on IV&amp;V services in 2006, and the Report further claims that IV&amp;V can be shown to have a 83:1 ROI (Return on Investment) ratio. Thus, $19M times 83 gives us the original $1.6 billion. (The $19M is pure personnel cost, and does not include e.g. the costs of the building where IV&amp;V is housed.)</p>\n<p>What is Return on Investment? Economics defines it as the gain from an investment, minus the cost of investment, divided by (again) the cost of investment. An investment is something you spend so as to obtain a gain, and a gain is something caused by the investment. This isn't rocket science but basic economics.</p>\n<p>But how does NASA arrive at this 83:1 figure?</p>\n<p>&nbsp;</p>\n<h2>NASA IV&amp;V's math</h2>\n<p>NASA relies on the widespread claim that in software efforts, \"fixing a bug later costs more\". Specifically, it focuses on the costs of fixing software defects (as they're more formally known) at the various \"phases\" often said to compose a project: requirements, design, coding, unit test, system test, or \"in the field\". For instance, it supposedly costs on average 200 times as much to fix a defect in the field than it does at the Requirements stage. (I have <a href=\"/lw/9sv/diseased_disciplines_the_strange_case_of_the/\">debunked that claim elsewhere</a>, but it does yet enjoy a relatively robust status within academic software engineering, so we can't fault NASA for relying on it back in 2006.)</p>\n<p>NASA counted 490 \"issues\" that IV&amp;V discovered at the requirements stage of the Space Shuttle missions, during some unspecified period between 1993 (the founding of the IV&amp;V Facility) and 2006. (An \"issue\" is not the same as a defect, but for the time being we will ignore this distinction.) To this, NASA adds 304 issues found between 2004 and 2006 in other (\"Science\") missions. (We are also told that this analysis includes only the most \"severe\" issues, i.e. ones for which a work-around cannot be found and which impair a mission objective.)</p>\n<p>We can verify that <strong>(490+304)*200 = 158,000</strong>, which NASA counts as the \"weighed sub-total\" for Requirements; adding up the somewhat smaller totals from other phases, NASA finds a total of 186,505.</p>\n<p>NASA also adds up the number of issues found during all phases, which is 2,239. We can again verify that <strong>186,505 / 2,239 = 83</strong> and some change.</p>\n<p>&nbsp;</p>\n<h2>How old is the captain?</h2>\n<p>Now, the immediate objection to this procedure is that an ROI calculation involves <em>dollars</em>, not numbers of \"issues\".&nbsp;ROI is a ratio of money gained (or saved) over money invested, and while you can reasonably say you've \"saved\" some number of issues it's silly to talk about \"investing\" some number of issues.</p>\n<p>We will want to \"<a href=\"http://wiki.lesswrong.com/wiki/Steel_man\">steel-man</a>\" NASA's argument. (This is the opposite of a \"straw man\", an easily knocked down argument that your interlocutor is not actually advancing, but that you make up to score easy points.) We will be as generous with this math as we can and see if it has even a small chance of holding up.</p>\n<p>To rescue the claim, we need to turn issues into dollars. Let us list the assumptions that need to hold for NASA's calculations to be valid:</p>\n<ul>\n<li>there is some determinate average cost to detecting an issue</li>\n<li>there is some&nbsp;determinate&nbsp;average cost to fixing an issue</li>\n<li>if an issue is not detected at the earliest opportunity, it always ends up being detected \"in the field\" and its repair cost is the maximum</li>\n</ul>\n<p>The first two assumptions give our steelman attempt some leeway; not all issues need to cost the same to detect, but it has to make sense to talk about the \"average cost of detecting an issue\". Mathematically, this implies that the cost of fixing an issue obeys some well-behaved function such as the famous \"bell curve\". (However, there are some functions for which it makes no sense, mathematically, to speak of an average: for instance some \"power law\" curves. These are distributions often found to describe, for instance, the size of catastrophes such as avalanches or forest fires; no one would be very surprised to find that defect costs in fact follow a power law.)</p>\n<p>The third assumption makes things even more problematic. NASA's calculations are based on hypotheticals: what if we used different assumptions, for instance that an \"issue\" in Requirements has a good likelihood of being found by NASA's diligent software engineers in the design phase? If all issues detected by IV&amp;V in Requirements had been fixed in Design, then the ratio would only be about 5:1 (that is, the ratio between 200:1 and 40:1). Using a similar procedure for the other phases, we would find a \"ROI\" of less than 3:1. This isn't to say that my assumption is better than NASA's, but merely to observe that the final result is very sensitive to this kind of assumption.</p>\n<p>However, we may grant that it is in NASA's culture to always assume the worst case. And anyway \"up to $1.6 billion\" is almost as impressive as \"$1.6 billion\", isn't it?</p>\n<p>&nbsp;</p>\n<h2>Eighy-three! For some value of eighty-three.</h2>\n<p>If we do accept all of NASA's claim, then an \"issue\" costs on average about $9K to detect. (As a common-sense check, note that this on the order of one person-month, assuming a yearly loaded salary in the $100K range. That seems a bit excessive; not a slur on NASA's competence, but definitely a bad knock for the notion that \"averages\" make sense at all in this context.)</p>\n<p>However, note that NASA's data is <em>absolutely silent</em> on how much the same issues cost <strong>to fix</strong>. Detecting is IV&amp;V's job, but fixing is the job of the software engineers working on the project.<sup><a href=\"#note1\">1</a><a name=\"call1\"></a></sup></p>\n<p>NASA is therefore reporting on the results of the following calculation...</p>\n<p style=\"padding-left: 30px;\"><strong>ROI = (Savings from IV&amp;V - Actual cost of IV&amp;V) / Actual cost of IV&amp;V</strong></p>\n<p>where</p>\n<p style=\"padding-left: 30px;\"><strong>Savings from IV&amp;V = Hypothetical cost of fixing defects without IV&amp;V - Actual cost of fixing defects</strong></p>\n<p>...and the above <strong>cannot be derived from the numbers used in the calculation</strong> - which are 1) counts of issues and 2) actual IV&amp;V budget. Even if we do grant an 83:1 ratio between the hypothetical cost of fixing defects (had IV&amp;V not been present to find them early) and the actual cost of fixing, we are left with an unknown variable - an unbound <strong>x</strong> in the equation - which is the average cost of fixing a defect.</p>\n<p>This, then, is the fatal flaw in the argument, the one that cannot be steel-manned and that exposes NASA's math for what it is - Flaubert-style, \"age of the captain\" math, not rocket science.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p><a name=\"note1\"></a><sup><a href=\"#call1\">1</a></sup> - Relatedly, an \"issue\" is just an observation that something is wrong, whereas a \"defect\" the thing software developers fix; it's entirely possible for several \"issues\" related to one \"defect\" to be corrected simultaneously by the same fix; NASA's conceptual model grossly oversimplifies the work relationship between those who \"validate and verify\" and those who actually write the software.</p>\n<p>&nbsp;</p>\n<h3>Acknowledgements</h3>\n<p>Thanks to Aleksis Tulonen, a reader of <a href=\"http://leanpub.com/leprechauns\">my book</a>, for finding the NASA document in the first place, and spotting the absurdity of the ROI calculation.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HFou6RHqFagkyrKkW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tggnLEXxrTDWQwDL3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 26, "extendedScore": null, "score": 1.178593164363973e-06, "legacy": true, "legacyId": "22403", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>&nbsp;</p>\n<p>The <a href=\"http://www.nasa.gov/centers/ivv/pdf/174321main_Annual_Report_06_Final.pdf\">2006 report</a> from NASA's \"Independent Verification and Validation Facility\" makes some interesting claims. Turning to page 6, we learn that thanks to IV&amp;V, \"NASA realized a software rework risk reduction benefit of $1.6 Billion in Fiscal Year 2006 alone\". This is close to 10% of NASA's overall annual budget, roughly equal to the entire annual budget of the International Space Station!</p>\n<p>If the numbers check out, this is an impressive feat for IV&amp;V (the more formal big brother of \"testing\" or \"quality assurance\" departments that most software development efforts include). Do they?</p>\n<p>&nbsp;</p>\n<h2 id=\"Flaubert_and_the_math_of_ROI\">Flaubert and the math of ROI</h2>\n<p>Back in 1841, to <a href=\"http://en.wikipedia.org/wiki/Age_of_the_captain\">tease his sister</a>, Gustave Flaubert invented the \"age of the captain problem\", which ran like this:</p>\n<blockquote>\n<p>A ship sails the ocean. It left Boston with a cargo of wool. It grosses 200 tons. [...] There are 12 passengers aboard, the wind is blowing East-North-East, the clock points to a quarter past three in the afternoon. It is the month of May. <strong>How old is the captain?</strong></p>\n</blockquote>\n<p>Flaubert was pointing out one common way people fail at math: you can only get sensible results from a calculation if the numbers you put in are related in the right ways. (Unfortunately, math education tends to be excessively heavy on the \"manipulate numbers\" part and to skimp on the \"make sense of the question\" part, a trend dissected by French mathematician <a href=\"http://fr.wikipedia.org/wiki/Stella_Baruk\">Stella Baruk</a> who titled one of her books after Flaubert's little joke on his sister.)</p>\n<p>Unfortunately, NASA's math turns out on inspection to be \"age-of-the-captain\" math. (This strikes me as a big embarrassment to an organization literally composed mainly of rocket scientists.)<a id=\"more\"></a></p>\n<p>The $1.6 billion claimed by NASA's document is derived by applying a ROI calculation: NASA spent $19 million on IV&amp;V services in 2006, and the Report further claims that IV&amp;V can be shown to have a 83:1 ROI (Return on Investment) ratio. Thus, $19M times 83 gives us the original $1.6 billion. (The $19M is pure personnel cost, and does not include e.g. the costs of the building where IV&amp;V is housed.)</p>\n<p>What is Return on Investment? Economics defines it as the gain from an investment, minus the cost of investment, divided by (again) the cost of investment. An investment is something you spend so as to obtain a gain, and a gain is something caused by the investment. This isn't rocket science but basic economics.</p>\n<p>But how does NASA arrive at this 83:1 figure?</p>\n<p>&nbsp;</p>\n<h2 id=\"NASA_IV_V_s_math\">NASA IV&amp;V's math</h2>\n<p>NASA relies on the widespread claim that in software efforts, \"fixing a bug later costs more\". Specifically, it focuses on the costs of fixing software defects (as they're more formally known) at the various \"phases\" often said to compose a project: requirements, design, coding, unit test, system test, or \"in the field\". For instance, it supposedly costs on average 200 times as much to fix a defect in the field than it does at the Requirements stage. (I have <a href=\"/lw/9sv/diseased_disciplines_the_strange_case_of_the/\">debunked that claim elsewhere</a>, but it does yet enjoy a relatively robust status within academic software engineering, so we can't fault NASA for relying on it back in 2006.)</p>\n<p>NASA counted 490 \"issues\" that IV&amp;V discovered at the requirements stage of the Space Shuttle missions, during some unspecified period between 1993 (the founding of the IV&amp;V Facility) and 2006. (An \"issue\" is not the same as a defect, but for the time being we will ignore this distinction.) To this, NASA adds 304 issues found between 2004 and 2006 in other (\"Science\") missions. (We are also told that this analysis includes only the most \"severe\" issues, i.e. ones for which a work-around cannot be found and which impair a mission objective.)</p>\n<p>We can verify that <strong>(490+304)*200 = 158,000</strong>, which NASA counts as the \"weighed sub-total\" for Requirements; adding up the somewhat smaller totals from other phases, NASA finds a total of 186,505.</p>\n<p>NASA also adds up the number of issues found during all phases, which is 2,239. We can again verify that <strong>186,505 / 2,239 = 83</strong> and some change.</p>\n<p>&nbsp;</p>\n<h2 id=\"How_old_is_the_captain_\">How old is the captain?</h2>\n<p>Now, the immediate objection to this procedure is that an ROI calculation involves <em>dollars</em>, not numbers of \"issues\".&nbsp;ROI is a ratio of money gained (or saved) over money invested, and while you can reasonably say you've \"saved\" some number of issues it's silly to talk about \"investing\" some number of issues.</p>\n<p>We will want to \"<a href=\"http://wiki.lesswrong.com/wiki/Steel_man\">steel-man</a>\" NASA's argument. (This is the opposite of a \"straw man\", an easily knocked down argument that your interlocutor is not actually advancing, but that you make up to score easy points.) We will be as generous with this math as we can and see if it has even a small chance of holding up.</p>\n<p>To rescue the claim, we need to turn issues into dollars. Let us list the assumptions that need to hold for NASA's calculations to be valid:</p>\n<ul>\n<li>there is some determinate average cost to detecting an issue</li>\n<li>there is some&nbsp;determinate&nbsp;average cost to fixing an issue</li>\n<li>if an issue is not detected at the earliest opportunity, it always ends up being detected \"in the field\" and its repair cost is the maximum</li>\n</ul>\n<p>The first two assumptions give our steelman attempt some leeway; not all issues need to cost the same to detect, but it has to make sense to talk about the \"average cost of detecting an issue\". Mathematically, this implies that the cost of fixing an issue obeys some well-behaved function such as the famous \"bell curve\". (However, there are some functions for which it makes no sense, mathematically, to speak of an average: for instance some \"power law\" curves. These are distributions often found to describe, for instance, the size of catastrophes such as avalanches or forest fires; no one would be very surprised to find that defect costs in fact follow a power law.)</p>\n<p>The third assumption makes things even more problematic. NASA's calculations are based on hypotheticals: what if we used different assumptions, for instance that an \"issue\" in Requirements has a good likelihood of being found by NASA's diligent software engineers in the design phase? If all issues detected by IV&amp;V in Requirements had been fixed in Design, then the ratio would only be about 5:1 (that is, the ratio between 200:1 and 40:1). Using a similar procedure for the other phases, we would find a \"ROI\" of less than 3:1. This isn't to say that my assumption is better than NASA's, but merely to observe that the final result is very sensitive to this kind of assumption.</p>\n<p>However, we may grant that it is in NASA's culture to always assume the worst case. And anyway \"up to $1.6 billion\" is almost as impressive as \"$1.6 billion\", isn't it?</p>\n<p>&nbsp;</p>\n<h2 id=\"Eighy_three__For_some_value_of_eighty_three_\">Eighy-three! For some value of eighty-three.</h2>\n<p>If we do accept all of NASA's claim, then an \"issue\" costs on average about $9K to detect. (As a common-sense check, note that this on the order of one person-month, assuming a yearly loaded salary in the $100K range. That seems a bit excessive; not a slur on NASA's competence, but definitely a bad knock for the notion that \"averages\" make sense at all in this context.)</p>\n<p>However, note that NASA's data is <em>absolutely silent</em> on how much the same issues cost <strong>to fix</strong>. Detecting is IV&amp;V's job, but fixing is the job of the software engineers working on the project.<sup><a href=\"#note1\">1</a><a name=\"call1\"></a></sup></p>\n<p>NASA is therefore reporting on the results of the following calculation...</p>\n<p style=\"padding-left: 30px;\"><strong id=\"ROI____Savings_from_IV_V___Actual_cost_of_IV_V____Actual_cost_of_IV_V\">ROI = (Savings from IV&amp;V - Actual cost of IV&amp;V) / Actual cost of IV&amp;V</strong></p>\n<p>where</p>\n<p style=\"padding-left: 30px;\"><strong id=\"Savings_from_IV_V___Hypothetical_cost_of_fixing_defects_without_IV_V___Actual_cost_of_fixing_defects\">Savings from IV&amp;V = Hypothetical cost of fixing defects without IV&amp;V - Actual cost of fixing defects</strong></p>\n<p>...and the above <strong>cannot be derived from the numbers used in the calculation</strong> - which are 1) counts of issues and 2) actual IV&amp;V budget. Even if we do grant an 83:1 ratio between the hypothetical cost of fixing defects (had IV&amp;V not been present to find them early) and the actual cost of fixing, we are left with an unknown variable - an unbound <strong>x</strong> in the equation - which is the average cost of fixing a defect.</p>\n<p>This, then, is the fatal flaw in the argument, the one that cannot be steel-manned and that exposes NASA's math for what it is - Flaubert-style, \"age of the captain\" math, not rocket science.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<p><a name=\"note1\"></a><sup><a href=\"#call1\">1</a></sup> - Relatedly, an \"issue\" is just an observation that something is wrong, whereas a \"defect\" the thing software developers fix; it's entirely possible for several \"issues\" related to one \"defect\" to be corrected simultaneously by the same fix; NASA's conceptual model grossly oversimplifies the work relationship between those who \"validate and verify\" and those who actually write the software.</p>\n<p>&nbsp;</p>\n<h3 id=\"Acknowledgements\">Acknowledgements</h3>\n<p>Thanks to Aleksis Tulonen, a reader of <a href=\"http://leanpub.com/leprechauns\">my book</a>, for finding the NASA document in the first place, and spotting the absurdity of the ROI calculation.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "sections": [{"title": "Flaubert and the math of ROI", "anchor": "Flaubert_and_the_math_of_ROI", "level": 1}, {"title": "NASA IV&V's math", "anchor": "NASA_IV_V_s_math", "level": 1}, {"title": "How old is the captain?", "anchor": "How_old_is_the_captain_", "level": 1}, {"title": "Eighy-three! For some value of eighty-three.", "anchor": "Eighy_three__For_some_value_of_eighty_three_", "level": 1}, {"title": "ROI = (Savings from IV&V - Actual cost of IV&V) / Actual cost of IV&V", "anchor": "ROI____Savings_from_IV_V___Actual_cost_of_IV_V____Actual_cost_of_IV_V", "level": 3}, {"title": "Savings from IV&V = Hypothetical cost of fixing defects without IV&V - Actual cost of fixing defects", "anchor": "Savings_from_IV_V___Hypothetical_cost_of_fixing_defects_without_IV_V___Actual_cost_of_fixing_defects", "level": 3}, {"title": "Acknowledgements", "anchor": "Acknowledgements", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "10 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4ACmfJkXQxkYacdLt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-24T16:35:49.720Z", "modifiedAt": null, "url": null, "title": "Sorting Comments", "slug": "sorting-comments", "viewCount": null, "lastCommentedAt": "2018-10-10T07:57:43.458Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "troll", "createdAt": "2012-04-17T19:25:22.119Z", "isAdmin": false, "displayName": "troll"}, "userId": "BRPGb424E5qTCdNwr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2XtQrTFnHAHqmfi4B/sorting-comments", "pageUrlRelative": "/posts/2XtQrTFnHAHqmfi4B/sorting-comments", "linkUrl": "https://www.lesswrong.com/posts/2XtQrTFnHAHqmfi4B/sorting-comments", "postedAtFormatted": "Wednesday, April 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sorting%20Comments&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASorting%20Comments%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2XtQrTFnHAHqmfi4B%2Fsorting-comments%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sorting%20Comments%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2XtQrTFnHAHqmfi4B%2Fsorting-comments", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2XtQrTFnHAHqmfi4B%2Fsorting-comments", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 34, "htmlBody": "<p>I'd like to be able to sort comments as a list, too.</p>\n<p>An example of this would be sorting comments by new as a list so all the comments you read will be new ones.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2XtQrTFnHAHqmfi4B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": -23, "extendedScore": null, "score": 1.1786527394488244e-06, "legacy": true, "legacyId": "22404", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-24T22:21:56.500Z", "modifiedAt": null, "url": null, "title": "Michael Vassar in Europe", "slug": "michael-vassar-in-europe", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:03.661Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ay6GBGNcCgP55dRQ7/michael-vassar-in-europe", "pageUrlRelative": "/posts/Ay6GBGNcCgP55dRQ7/michael-vassar-in-europe", "linkUrl": "https://www.lesswrong.com/posts/Ay6GBGNcCgP55dRQ7/michael-vassar-in-europe", "postedAtFormatted": "Wednesday, April 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Michael%20Vassar%20in%20Europe&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMichael%20Vassar%20in%20Europe%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAy6GBGNcCgP55dRQ7%2Fmichael-vassar-in-europe%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Michael%20Vassar%20in%20Europe%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAy6GBGNcCgP55dRQ7%2Fmichael-vassar-in-europe", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAy6GBGNcCgP55dRQ7%2Fmichael-vassar-in-europe", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 93, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Michael_Vassar\">Michael Vassar</a>, former president of the Singularity Institute and current Chief Science Officer of MetaMed, is currently visiting Europe and wants to meet up with Less Wrongers there. His schedule is:</p>\n<p>25 April: Berlin</p>\n<p>29 April: Estonia</p>\n<p>8 May: London</p>\n<p>12 May: Oslo</p>\n<p>16 May: Nice (but may be able to meet people in Paris?)</p>\n<p>26 May: Home to USA</p>\n<p>If you have a meetup group in or near one of these cities, or you can put some people together, he's interested in talking about the Singularity, optimal philanthropy, and his work with MetaMed. You can reach him at <span class=\"gI\"><span class=\"go\">michael.vassar[at]gmail.com</span></span><a href=\"/user/MichaelVassar/overview/\"></a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ay6GBGNcCgP55dRQ7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 1.1788959613527265e-06, "legacy": true, "legacyId": "22405", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-25T00:07:52.499Z", "modifiedAt": null, "url": null, "title": "Tactics against Pascal's Mugging", "slug": "tactics-against-pascal-s-mugging", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.065Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gjyvXPqvCZPEtCKLB/tactics-against-pascal-s-mugging", "pageUrlRelative": "/posts/gjyvXPqvCZPEtCKLB/tactics-against-pascal-s-mugging", "linkUrl": "https://www.lesswrong.com/posts/gjyvXPqvCZPEtCKLB/tactics-against-pascal-s-mugging", "postedAtFormatted": "Thursday, April 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tactics%20against%20Pascal's%20Mugging&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATactics%20against%20Pascal's%20Mugging%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgjyvXPqvCZPEtCKLB%2Ftactics-against-pascal-s-mugging%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tactics%20against%20Pascal's%20Mugging%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgjyvXPqvCZPEtCKLB%2Ftactics-against-pascal-s-mugging", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgjyvXPqvCZPEtCKLB%2Ftactics-against-pascal-s-mugging", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2406, "htmlBody": "<p>This is meant as a rough collection of five ideas of mine on potential anti-Pascal Mugging tactics. I don't have much hope that the first three will be any useful at all and am afraid that I'm not mathematically-inclined enough to know if the last two are any good even as a partial solution towards the core problem of Pascal's Mugging -- so I'd appreciate if people with better mathematical credentials than mine could see if any of my intuitions could be formalizable in a useful manner.</p>\n<p><strong>0. Introducing the problem </strong>(this may bore you if you're aware of both the original and the mugger-less form of Pascal's Mugging)</p>\n<p>First of all the basics: <a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging</a> in its original form is described in the following way:</p>\n<ul>\n<li>Now suppose someone comes to me and says, \"Give me five dollars, or I'll use my magic powers from outside the Matrix to run a Turing machine that simulates and kills 3^^^3 people.\"</li>\n</ul>\n<p>This is the \"shallow\" form of Pascal's mugging, which includes a person that (almost certainly) is attempting to deceive the prospective AI. However let's introduce some further statements similar to the above, to avoid particular objections that might be used in some (even shallower) attempted rebuttals:</p>\n<ul>\n<li>\"Give me five dollars, and I'll use my magic powers from outside the Matrix to increase the utility of every human being by 3^^^^3 utilons\" (a supposedly positive trade rather than a blackmailer's threat)</li>\n<li>\"I'm an alien in disguise - unless you publicly proclaim allegiance to your insect overlords, we will destroy you then torture all humanity for 3^^^^3 years\" (a prankster asks for something which might be useful to an actual alien, but on a material-level not useful to a human liar)</li>\n<li>\"My consciousness has partially time-travelled from the future into the past, and one of the few tidbits I remember is that it would be of effectively infinite utility if you asked everyone to call you Princess Tutu.\" (no trade offered at all, seemingly just a statement of epistemic belief)</li>\n<li><em><a href=\"http://squid314.livejournal.com/301735.html\">Says the Devil</a> \"It's infinitely bad to end that song and dance</em><em><br />And I won't tell you why, and I probably lie, but can you really take that chance?\"<br />Blaise fills with trepidation as his calculations all turn out the devil's way.<br />And they say in the Paris catacombs, his ghost is fiddlin' to this day.</em></li>\n</ul>\n<p>I think these are all trivial variations of this basic version of Pascal's Mugging: The utility a prankster derives from the pleasure of successfully pranking the AI wouldn't be treated differently in kind to the utility of 5 dollars -- nor is the explicit offer of a trade different than the supposedly free offer of information.</p>\n<p>The mugger-less version is on the other hand more interesting and more problematic. You don't actually need a person to make such a statement -- the AI, without any prompting, can assign prior probabilities to theories which produce outcomes of positive or negative value vastly greater than their assigned improbabilities. I've seen its best description <a href=\"/lw/gqm/strongmanning_pascals_mugging/8i40\">in the comment by Kindly and the corresponding response by Eliezer</a>:</p>\n<p style=\"padding-left: 30px;\"><em><strong>Kindly: </strong>Very many hypotheses -- arguably infinitely many -- can be formed about how the world works. In particular, some of these hypotheses imply that by doing something counter-intuitive in following those hypothesis, you get ridiculously awesome outcomes. For example, even in advance of me posting this comment, you could form the hypothesis \"if I send Kindly $5 by Paypal, he or she will refrain from torturing 3^^^3 people in the matrix and instead give them candy.\" Now, usually all such hypotheses are low-probability and that decreases the expected benefit from performing these counter-intuitive actions. But how can you show that in all cases this expected benefit is sufficiently low to justify ignoring it?</em></p>\n<p style=\"padding-left: 30px;\"><em><strong>Eliezer Yudkowsky:</strong> Right, this is the real core of Pascal's Mugging [...]. For aggregative utility functions over a model of the environment which e.g. treat all sentient beings (or all paperclips) as having equal value without diminishing marginal returns, and all epistemic models which induce simplicity-weighted explanations of sensory experience, all decisions will be dominated by tiny variances in the probability of extremely unlikely hypotheses because the \"model size\" of a hypothesis can grow Busy-Beaver faster than its Kolmogorov complexity. </em></p>\n<p>The following list five ideas of mine, ordered as least-to-most-promising in the search for a general solution. Though I considered them seriously initially, I no longer really think that (1) (2) or (3) hold any promise, being limited, overly specific or even plain false -- I nonetheless list them for completeness' sake, to get them out of my head and in case anyone sees something in them that could potentially be the seed of something better. I'm slightly more hopeful for solutions (4) or (5) -- they feel to me intuitively as if they may be leading to something good. But I'd need math that I don't really have to prove or disprove it.</p>\n<p><strong>1. The James T. Kirk solution <br /></strong></p>\n<p><strong> </strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8125/8669548549_c16bcb6971_m.jpg\" alt=\"\" width=\"200\" height=\"150\" />To cut to the punchline: the James T. Kirk solution to Pascal's Mugging is <a href=\"http://www.youtube.com/watch?v=WYW_lPlekiQ\">\"What does God need with a starship?\"<br /></a></p>\n<p>Say there's a given prior possibility P(X=Matrix Lord) that any given human being is a Matrix Lord with the power to inflict 3^^^3 points of utility/disutility. The fact that such a being with such vast power seemingly wants five dollars (or a million dollars, or to be crowned Queen of Australia), makes it actually *less* likely that such a being is a Matrix Lord.</p>\n<p>We don't actually need the vast unlikely probabilities to illustrate the truth of this. Let's consider an AI with a security backdoor -- it's known for a fact than there's one person in the world which has been given a 10-word passkey that can destroy the AI at his will. (The AI is also disallowed from attempting to avoid such penalty by e.g. killing the person in question).</p>\n<p>So let's say the prior probability for any given person being the key keeper in question is \"1 in 7 billion\"</p>\n<p>Now Person X says to the AI. \"Hey, I'm the key keeper. I refuse to give you any evidence to the same, but I'll destroy you if you don't give me 20 dollars.\"</p>\n<p>Does this make Person X more or less likely to be the key keeper? My own intuition tells me \"less likely\".</p>\n<p>Unfortunately, one fundamental problem with the above syllogism is that at best it can tell us that it's only the muggerless version that we need fear. Useless for any serious purpose.</p>\n<p><strong>2. The presumption of unfriendliness</strong></p>\n<p><strong> </strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8382/8669548515_380127dc56_m.jpg\" alt=\"Robot Devil\" width=\"200\" height=\"150\" />This is most obviously the method that, in the examples above, poor Blaise should have used to defeat the devil's claim of infinite badness. In a universe where ending 'that song and dance' can be X-bad, the statement should also be considered that it could be X-bad to NOT end it, or indeed X-good to do end it. The devil (being a known malicious entity) is much more likely to push Pascal towards doing what would <em>result</em> to the infinite badness. And indeed in the fictional evidence provided by the song, that's indeed what the devil achieves: to harm Blaise Pascal and his ghost for an arbitrarily long time - by warning against the same and using Pascal's calculations against him.</p>\n<p><strong> </strong></p>\n<p>Blaise's tactic should have been not to obey the devil's warning, nor to even do the opposite than his suggestion (since the devil could be smart enough to know how to use reverse psychology), but rather to ignore him as much as possible: Blaise should end the song and dance at the point in time he would have done if he wasn't aware of the devil's statement.</p>\n<p><strong> </strong></p>\n<p>All the above is obvious for cartoonish villains like the devil -- known malicious agents who are known to have a utility function opposed to ours -- and a Matrix Lord who is willing to torture 3^^^3 people for the purpose of getting 5 dollars is probably no better; better to just ignore them. But I wonder: Can't a similar logic be used in handling most any agents with utility functions that are merely different than one's own (which is the vast number of agents in mindspace)?</p>\n<p>Moreover a thought that occurs: Doesn't it seem likely that for any supposed impact X, the greater the promised X, the less likely two different minds are both positively inclined towards it? So for any supposed impact X, shouldn't the presumption of unfriendliness (incompatibility in utility functions) increase in like measure ?</p>\n<p><strong>3. The Xenios Zeus.</strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8381/8669548483_7267e3e8b8_m.jpg\" alt=\"Pyramus and Thisbe\" width=\"200\" height=\"150\" />This idea was inspired from the old myth about Zeus and Hermes walking around pretending to be travellers in need, to examine which people were hospitable and which were not. I think there may exist similar myths about other gods in other mythologies.</p>\n<p>Let's say that each current resident has a small chance (not necessarily the same small chance) of being a Matrix Lord willing to destroy the world and throw a temper tantrum that'll punish 3^^^3 people if you don't behave properly according to what he considers proper. Much like each traveller has a chance of being Zeus.</p>\n<p>One might think that you might have to examine the data very closely to figure out which random person has the greatest probability of being Zeus -- but that rather fails to get the moral of the myth, which isn't \"figure out who is secretly Zeus\" but rather \"treat everyone nicely, just in case\". If someone does not reveal themselves to be a god, then they don't expect to be treated like a god, but might still expect human decency.</p>\n<p>To put it in LW analogous terms one might argue that an AI could treat the value system of even Matrix Lords as roughly centered around the value system of human beings -- so that by serving the CEV of humanity, it would also have the maximum chance of pleasing (or at least not angering) any Matrix Lords in question.</p>\n<p>Unfortunately in retrospect I think this idea of mine is, frankly, crap. Not only is it overly specific and again seems to treat the surface problem rather than the core problem, but I realized it reached the same conclusion as (2) by asserting the exact opposite -- the previous idea made an assumption of unfriendliness, this one makes an assumption of minds being centered around friendliness. If I'm using two contradictory ideas to lead to the same conclusion, it probably indicates that this is a result of having written the bottom line -- not of making an actually useful argument.</p>\n<p>So not much hope remains in me for solutions 1-3. Let's go to 4.</p>\n<p><strong>4. The WWBBD Principle. (What Would a Boltzman Brain Do?)</strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8546/8679711020_12fe12546d_m.jpg\" alt=\"\" width=\"200\" height=\"150\" />If you believed with 99% certainty that you were a Boltzman Brain, what should you do? The smart thing would probably be: Whatever you would do if you weren't a Boltzman Brain. You can dismiss the hypotheses where you have no control over the future; because it's only the ones where you have control that matter on a decision-theoretic basis.</p>\n<p>Calculations of future utility have a discounting factor naturally built into them -- which is the uncertainty of being able to calculate and control such a future properly. So in a very natural (no need to program it in) manner an AI would prefer the same utility for 5 seconds in the future rather than 5 minutes in the future, and for 5 minutes in the future rather than 5 years in the future.</p>\n<p>This looks at first glance as a time-discount, but in actuality it's an uncertainty-discount. So an AI that had a very good predictive capacity would be able to discount future utility less; because the uncertainty would be less. But the uncertainty would never be quite zero.</p>\n<div>One thing that may be missed in the above is that there exists not only an uncertainty in <em>reaching</em> a certain future state of the world, but there's an uncertainty in how it would affect all consequent future states as well. And <em>the greater the impact the greater such uncertainty for the future must be</em>.</div>\n<div><br />So even as the thought of 3^^^3 lives outweighs the tiny probability; couldn't it be that a similar factor punishes it to an opposite direction, especially when dealing with hypotheses in which the AI will be able to have no further control? I don't know. Bring in the mathematicians.<br /></div>\n<div><br /></div>\n<p><strong>5. The Law of Visible Impact (a.k.a. The Generalized Hanson)</strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8399/8678046989_ebac2b351f_m.jpg\" alt=\"\" width=\"200\" height=\"200\" />Robin Hanson's suggested solution to Pascal's Mugging has been the penalization of \"the prior probability of hypotheses which argue that we are in a surprisingly unique position to affect large numbers of other people who cannot symmetrically affect us.\"</p>\n<p>I have to say that I find this argument unappealing and unconvincing. One problem I have with it is that it seems to treat the concept of \"person\" as ontologically fundamental -- it's an objection I kinda have also against the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Simulation_argument\">Simulation argument</a>&nbsp;and the <a href=\"http://en.wikipedia.org/wiki/Doomsday_argument\">Doomsday Argument</a>.&nbsp;</p>\n<p>Moreover wouldn't this argument cease to apply if I was merely <em>witnessing </em>the Pascal's mugging taking place, and that therefore if I was merely witnessing I should be hoping for the mugged entity to submit? This sounds nonsensical.&nbsp;</p>\n<p>But I think Hanson's argument can be modified so here I'd like to offer what I'll call the Generalized Hanson: <strong><em>Penalize the prior probability of hypotheses which argue for the existence of high impact events whose consequences nonetheless remain unobserved.</em></strong></p>\n<p>If life's creation is easy, why aren't we seeing alien civilizations consuming the stars? Therefore most likely life's creation isn't easy at all.</p>\n<p>If the universe allowed easy time-travel, where are all the time-travellers? Hence the world most likely doesn't allow easy time-travel.&nbsp;</p>\n<p>If Matrix Lords exist that are apt to create 3^^^3 people and torture them for their amusement, why aren't we being tortured (or witnessing such torture) right now? Therefore most likely such Matrix Lords are rare enough to nullify their impact.</p>\n<p>In short the higher the impact of a hypothetical event, the more evidence we should be expecting to see for it in the surrounding universe -- the non-visibility of such provides therefore evidence against the hypothesis analogous to the extent of such hypothetical impact.</p>\n<p>I'm probably expressing the above intuition quite badly, but again: I hope someone with actual mathematical skills can take the above and make it into something useful; or tell me that it's not useful as an anti-Pascal Mugging tactic at all.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HNJiR8Jzafsv8cHrC": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gjyvXPqvCZPEtCKLB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 26, "extendedScore": null, "score": 1.1789704209704934e-06, "legacy": true, "legacyId": "22086", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This is meant as a rough collection of five ideas of mine on potential anti-Pascal Mugging tactics. I don't have much hope that the first three will be any useful at all and am afraid that I'm not mathematically-inclined enough to know if the last two are any good even as a partial solution towards the core problem of Pascal's Mugging -- so I'd appreciate if people with better mathematical credentials than mine could see if any of my intuitions could be formalizable in a useful manner.</p>\n<p><strong>0. Introducing the problem </strong>(this may bore you if you're aware of both the original and the mugger-less form of Pascal's Mugging)</p>\n<p>First of all the basics: <a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging</a> in its original form is described in the following way:</p>\n<ul>\n<li>Now suppose someone comes to me and says, \"Give me five dollars, or I'll use my magic powers from outside the Matrix to run a Turing machine that simulates and kills 3^^^3 people.\"</li>\n</ul>\n<p>This is the \"shallow\" form of Pascal's mugging, which includes a person that (almost certainly) is attempting to deceive the prospective AI. However let's introduce some further statements similar to the above, to avoid particular objections that might be used in some (even shallower) attempted rebuttals:</p>\n<ul>\n<li>\"Give me five dollars, and I'll use my magic powers from outside the Matrix to increase the utility of every human being by 3^^^^3 utilons\" (a supposedly positive trade rather than a blackmailer's threat)</li>\n<li>\"I'm an alien in disguise - unless you publicly proclaim allegiance to your insect overlords, we will destroy you then torture all humanity for 3^^^^3 years\" (a prankster asks for something which might be useful to an actual alien, but on a material-level not useful to a human liar)</li>\n<li>\"My consciousness has partially time-travelled from the future into the past, and one of the few tidbits I remember is that it would be of effectively infinite utility if you asked everyone to call you Princess Tutu.\" (no trade offered at all, seemingly just a statement of epistemic belief)</li>\n<li><em><a href=\"http://squid314.livejournal.com/301735.html\">Says the Devil</a> \"It's infinitely bad to end that song and dance</em><em><br>And I won't tell you why, and I probably lie, but can you really take that chance?\"<br>Blaise fills with trepidation as his calculations all turn out the devil's way.<br>And they say in the Paris catacombs, his ghost is fiddlin' to this day.</em></li>\n</ul>\n<p>I think these are all trivial variations of this basic version of Pascal's Mugging: The utility a prankster derives from the pleasure of successfully pranking the AI wouldn't be treated differently in kind to the utility of 5 dollars -- nor is the explicit offer of a trade different than the supposedly free offer of information.</p>\n<p>The mugger-less version is on the other hand more interesting and more problematic. You don't actually need a person to make such a statement -- the AI, without any prompting, can assign prior probabilities to theories which produce outcomes of positive or negative value vastly greater than their assigned improbabilities. I've seen its best description <a href=\"/lw/gqm/strongmanning_pascals_mugging/8i40\">in the comment by Kindly and the corresponding response by Eliezer</a>:</p>\n<p style=\"padding-left: 30px;\"><em><strong>Kindly: </strong>Very many hypotheses -- arguably infinitely many -- can be formed about how the world works. In particular, some of these hypotheses imply that by doing something counter-intuitive in following those hypothesis, you get ridiculously awesome outcomes. For example, even in advance of me posting this comment, you could form the hypothesis \"if I send Kindly $5 by Paypal, he or she will refrain from torturing 3^^^3 people in the matrix and instead give them candy.\" Now, usually all such hypotheses are low-probability and that decreases the expected benefit from performing these counter-intuitive actions. But how can you show that in all cases this expected benefit is sufficiently low to justify ignoring it?</em></p>\n<p style=\"padding-left: 30px;\"><em><strong>Eliezer Yudkowsky:</strong> Right, this is the real core of Pascal's Mugging [...]. For aggregative utility functions over a model of the environment which e.g. treat all sentient beings (or all paperclips) as having equal value without diminishing marginal returns, and all epistemic models which induce simplicity-weighted explanations of sensory experience, all decisions will be dominated by tiny variances in the probability of extremely unlikely hypotheses because the \"model size\" of a hypothesis can grow Busy-Beaver faster than its Kolmogorov complexity. </em></p>\n<p>The following list five ideas of mine, ordered as least-to-most-promising in the search for a general solution. Though I considered them seriously initially, I no longer really think that (1) (2) or (3) hold any promise, being limited, overly specific or even plain false -- I nonetheless list them for completeness' sake, to get them out of my head and in case anyone sees something in them that could potentially be the seed of something better. I'm slightly more hopeful for solutions (4) or (5) -- they feel to me intuitively as if they may be leading to something good. But I'd need math that I don't really have to prove or disprove it.</p>\n<p><strong id=\"1__The_James_T__Kirk_solution_\">1. The James T. Kirk solution <br></strong></p>\n<p><strong> </strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8125/8669548549_c16bcb6971_m.jpg\" alt=\"\" width=\"200\" height=\"150\">To cut to the punchline: the James T. Kirk solution to Pascal's Mugging is <a href=\"http://www.youtube.com/watch?v=WYW_lPlekiQ\">\"What does God need with a starship?\"<br></a></p>\n<p>Say there's a given prior possibility P(X=Matrix Lord) that any given human being is a Matrix Lord with the power to inflict 3^^^3 points of utility/disutility. The fact that such a being with such vast power seemingly wants five dollars (or a million dollars, or to be crowned Queen of Australia), makes it actually *less* likely that such a being is a Matrix Lord.</p>\n<p>We don't actually need the vast unlikely probabilities to illustrate the truth of this. Let's consider an AI with a security backdoor -- it's known for a fact than there's one person in the world which has been given a 10-word passkey that can destroy the AI at his will. (The AI is also disallowed from attempting to avoid such penalty by e.g. killing the person in question).</p>\n<p>So let's say the prior probability for any given person being the key keeper in question is \"1 in 7 billion\"</p>\n<p>Now Person X says to the AI. \"Hey, I'm the key keeper. I refuse to give you any evidence to the same, but I'll destroy you if you don't give me 20 dollars.\"</p>\n<p>Does this make Person X more or less likely to be the key keeper? My own intuition tells me \"less likely\".</p>\n<p>Unfortunately, one fundamental problem with the above syllogism is that at best it can tell us that it's only the muggerless version that we need fear. Useless for any serious purpose.</p>\n<p><strong id=\"2__The_presumption_of_unfriendliness\">2. The presumption of unfriendliness</strong></p>\n<p><strong> </strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8382/8669548515_380127dc56_m.jpg\" alt=\"Robot Devil\" width=\"200\" height=\"150\">This is most obviously the method that, in the examples above, poor Blaise should have used to defeat the devil's claim of infinite badness. In a universe where ending 'that song and dance' can be X-bad, the statement should also be considered that it could be X-bad to NOT end it, or indeed X-good to do end it. The devil (being a known malicious entity) is much more likely to push Pascal towards doing what would <em>result</em> to the infinite badness. And indeed in the fictional evidence provided by the song, that's indeed what the devil achieves: to harm Blaise Pascal and his ghost for an arbitrarily long time - by warning against the same and using Pascal's calculations against him.</p>\n<p><strong> </strong></p>\n<p>Blaise's tactic should have been not to obey the devil's warning, nor to even do the opposite than his suggestion (since the devil could be smart enough to know how to use reverse psychology), but rather to ignore him as much as possible: Blaise should end the song and dance at the point in time he would have done if he wasn't aware of the devil's statement.</p>\n<p><strong> </strong></p>\n<p>All the above is obvious for cartoonish villains like the devil -- known malicious agents who are known to have a utility function opposed to ours -- and a Matrix Lord who is willing to torture 3^^^3 people for the purpose of getting 5 dollars is probably no better; better to just ignore them. But I wonder: Can't a similar logic be used in handling most any agents with utility functions that are merely different than one's own (which is the vast number of agents in mindspace)?</p>\n<p>Moreover a thought that occurs: Doesn't it seem likely that for any supposed impact X, the greater the promised X, the less likely two different minds are both positively inclined towards it? So for any supposed impact X, shouldn't the presumption of unfriendliness (incompatibility in utility functions) increase in like measure ?</p>\n<p><strong id=\"3__The_Xenios_Zeus_\">3. The Xenios Zeus.</strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8381/8669548483_7267e3e8b8_m.jpg\" alt=\"Pyramus and Thisbe\" width=\"200\" height=\"150\">This idea was inspired from the old myth about Zeus and Hermes walking around pretending to be travellers in need, to examine which people were hospitable and which were not. I think there may exist similar myths about other gods in other mythologies.</p>\n<p>Let's say that each current resident has a small chance (not necessarily the same small chance) of being a Matrix Lord willing to destroy the world and throw a temper tantrum that'll punish 3^^^3 people if you don't behave properly according to what he considers proper. Much like each traveller has a chance of being Zeus.</p>\n<p>One might think that you might have to examine the data very closely to figure out which random person has the greatest probability of being Zeus -- but that rather fails to get the moral of the myth, which isn't \"figure out who is secretly Zeus\" but rather \"treat everyone nicely, just in case\". If someone does not reveal themselves to be a god, then they don't expect to be treated like a god, but might still expect human decency.</p>\n<p>To put it in LW analogous terms one might argue that an AI could treat the value system of even Matrix Lords as roughly centered around the value system of human beings -- so that by serving the CEV of humanity, it would also have the maximum chance of pleasing (or at least not angering) any Matrix Lords in question.</p>\n<p>Unfortunately in retrospect I think this idea of mine is, frankly, crap. Not only is it overly specific and again seems to treat the surface problem rather than the core problem, but I realized it reached the same conclusion as (2) by asserting the exact opposite -- the previous idea made an assumption of unfriendliness, this one makes an assumption of minds being centered around friendliness. If I'm using two contradictory ideas to lead to the same conclusion, it probably indicates that this is a result of having written the bottom line -- not of making an actually useful argument.</p>\n<p>So not much hope remains in me for solutions 1-3. Let's go to 4.</p>\n<p><strong id=\"4__The_WWBBD_Principle___What_Would_a_Boltzman_Brain_Do__\">4. The WWBBD Principle. (What Would a Boltzman Brain Do?)</strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8546/8679711020_12fe12546d_m.jpg\" alt=\"\" width=\"200\" height=\"150\">If you believed with 99% certainty that you were a Boltzman Brain, what should you do? The smart thing would probably be: Whatever you would do if you weren't a Boltzman Brain. You can dismiss the hypotheses where you have no control over the future; because it's only the ones where you have control that matter on a decision-theoretic basis.</p>\n<p>Calculations of future utility have a discounting factor naturally built into them -- which is the uncertainty of being able to calculate and control such a future properly. So in a very natural (no need to program it in) manner an AI would prefer the same utility for 5 seconds in the future rather than 5 minutes in the future, and for 5 minutes in the future rather than 5 years in the future.</p>\n<p>This looks at first glance as a time-discount, but in actuality it's an uncertainty-discount. So an AI that had a very good predictive capacity would be able to discount future utility less; because the uncertainty would be less. But the uncertainty would never be quite zero.</p>\n<div>One thing that may be missed in the above is that there exists not only an uncertainty in <em>reaching</em> a certain future state of the world, but there's an uncertainty in how it would affect all consequent future states as well. And <em>the greater the impact the greater such uncertainty for the future must be</em>.</div>\n<div><br>So even as the thought of 3^^^3 lives outweighs the tiny probability; couldn't it be that a similar factor punishes it to an opposite direction, especially when dealing with hypotheses in which the AI will be able to have no further control? I don't know. Bring in the mathematicians.<br></div>\n<div><br></div>\n<p><strong id=\"5__The_Law_of_Visible_Impact__a_k_a__The_Generalized_Hanson_\">5. The Law of Visible Impact (a.k.a. The Generalized Hanson)</strong></p>\n<p><img style=\"float: right; padding-left: 10px;\" src=\"http://farm9.staticflickr.com/8399/8678046989_ebac2b351f_m.jpg\" alt=\"\" width=\"200\" height=\"200\">Robin Hanson's suggested solution to Pascal's Mugging has been the penalization of \"the prior probability of hypotheses which argue that we are in a surprisingly unique position to affect large numbers of other people who cannot symmetrically affect us.\"</p>\n<p>I have to say that I find this argument unappealing and unconvincing. One problem I have with it is that it seems to treat the concept of \"person\" as ontologically fundamental -- it's an objection I kinda have also against the&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Simulation_argument\">Simulation argument</a>&nbsp;and the <a href=\"http://en.wikipedia.org/wiki/Doomsday_argument\">Doomsday Argument</a>.&nbsp;</p>\n<p>Moreover wouldn't this argument cease to apply if I was merely <em>witnessing </em>the Pascal's mugging taking place, and that therefore if I was merely witnessing I should be hoping for the mugged entity to submit? This sounds nonsensical.&nbsp;</p>\n<p>But I think Hanson's argument can be modified so here I'd like to offer what I'll call the Generalized Hanson: <strong><em>Penalize the prior probability of hypotheses which argue for the existence of high impact events whose consequences nonetheless remain unobserved.</em></strong></p>\n<p>If life's creation is easy, why aren't we seeing alien civilizations consuming the stars? Therefore most likely life's creation isn't easy at all.</p>\n<p>If the universe allowed easy time-travel, where are all the time-travellers? Hence the world most likely doesn't allow easy time-travel.&nbsp;</p>\n<p>If Matrix Lords exist that are apt to create 3^^^3 people and torture them for their amusement, why aren't we being tortured (or witnessing such torture) right now? Therefore most likely such Matrix Lords are rare enough to nullify their impact.</p>\n<p>In short the higher the impact of a hypothetical event, the more evidence we should be expecting to see for it in the surrounding universe -- the non-visibility of such provides therefore evidence against the hypothesis analogous to the extent of such hypothetical impact.</p>\n<p>I'm probably expressing the above intuition quite badly, but again: I hope someone with actual mathematical skills can take the above and make it into something useful; or tell me that it's not useful as an anti-Pascal Mugging tactic at all.</p>", "sections": [{"title": "1. The James T. Kirk solution ", "anchor": "1__The_James_T__Kirk_solution_", "level": 1}, {"title": "2. The presumption of unfriendliness", "anchor": "2__The_presumption_of_unfriendliness", "level": 1}, {"title": "3. The Xenios Zeus.", "anchor": "3__The_Xenios_Zeus_", "level": 1}, {"title": "4. The WWBBD Principle. (What Would a Boltzman Brain Do?)", "anchor": "4__The_WWBBD_Principle___What_Would_a_Boltzman_Brain_Do__", "level": 1}, {"title": "5. The Law of Visible Impact (a.k.a. The Generalized Hanson)", "anchor": "5__The_Law_of_Visible_Impact__a_k_a__The_Generalized_Hanson_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "54 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 59, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["a5JAiTdytou3Jg749"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-25T00:36:41.935Z", "modifiedAt": null, "url": null, "title": "Google's Executive Chairman Eric Schmidt: apparently a transhumanist", "slug": "google-s-executive-chairman-eric-schmidt-apparently-a", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.567Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chaosmage", "createdAt": "2012-04-27T12:21:32.969Z", "isAdmin": false, "displayName": "chaosmage"}, "userId": "onF6sJLEXsAkjx9Ki", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CL3tzXT6g6AuJAWrQ/google-s-executive-chairman-eric-schmidt-apparently-a", "pageUrlRelative": "/posts/CL3tzXT6g6AuJAWrQ/google-s-executive-chairman-eric-schmidt-apparently-a", "linkUrl": "https://www.lesswrong.com/posts/CL3tzXT6g6AuJAWrQ/google-s-executive-chairman-eric-schmidt-apparently-a", "postedAtFormatted": "Thursday, April 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Google's%20Executive%20Chairman%20Eric%20Schmidt%3A%20apparently%20a%20transhumanist&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGoogle's%20Executive%20Chairman%20Eric%20Schmidt%3A%20apparently%20a%20transhumanist%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCL3tzXT6g6AuJAWrQ%2Fgoogle-s-executive-chairman-eric-schmidt-apparently-a%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Google's%20Executive%20Chairman%20Eric%20Schmidt%3A%20apparently%20a%20transhumanist%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCL3tzXT6g6AuJAWrQ%2Fgoogle-s-executive-chairman-eric-schmidt-apparently-a", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCL3tzXT6g6AuJAWrQ%2Fgoogle-s-executive-chairman-eric-schmidt-apparently-a", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 180, "htmlBody": "<p>It makes a lot of sense for the Google people to be transhumanist, with Sergey Brin and Larry Page working with the Singularity University, but still I was surprised to hear this on the new Colbert Report (of the 23rd of April):</p>\n<blockquote>Colbert: Can I live forever?<br />Schmidt: Yes.<br />Colbert: Really?<br />Schmidt: But not now. They need to invent some more medicine.<br />Colbert: So I can live forever, but later. So I just need to live long enough for later to become now.<br />Schmidt: But your digital identity will live forever. Because there's no delete button.<br />Colbert: On me?<br />Schmidt: That's correct.<br />Colbert: That's profound.</blockquote>\n<p>He seemed quite serious, too.</p>\n<p>I guess a lot of people would take transhumanism more seriously if they heard the top people at Google are in. To me, I actually find it makes Google seem more trustworthy. In-group psychology is weird.</p>\n<p>Here's <a href=\"http://www.charlierose.com/view/interview/11217\">another good interview</a> with Eric Schmidt. No explicit transhumanism, but some fairly intense plans entirely compatible with it.</p>\n<p>(edited: corrected title)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CL3tzXT6g6AuJAWrQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 14, "extendedScore": null, "score": 1.1789906824767226e-06, "legacy": true, "legacyId": "22406", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-25T06:26:05.454Z", "modifiedAt": null, "url": null, "title": "[LINK] How to calibrate your confidence intervals", "slug": "link-how-to-calibrate-your-confidence-intervals", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:36.368Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benjamin_Todd", "createdAt": "2012-02-27T10:33:26.778Z", "isAdmin": false, "displayName": "Benjamin_Todd"}, "userId": "moXBqwii3GoAMuRwa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5XBv2onWGRKFtAEMN/link-how-to-calibrate-your-confidence-intervals", "pageUrlRelative": "/posts/5XBv2onWGRKFtAEMN/link-how-to-calibrate-your-confidence-intervals", "linkUrl": "https://www.lesswrong.com/posts/5XBv2onWGRKFtAEMN/link-how-to-calibrate-your-confidence-intervals", "postedAtFormatted": "Thursday, April 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20How%20to%20calibrate%20your%20confidence%20intervals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20How%20to%20calibrate%20your%20confidence%20intervals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5XBv2onWGRKFtAEMN%2Flink-how-to-calibrate-your-confidence-intervals%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20How%20to%20calibrate%20your%20confidence%20intervals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5XBv2onWGRKFtAEMN%2Flink-how-to-calibrate-your-confidence-intervals", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5XBv2onWGRKFtAEMN%2Flink-how-to-calibrate-your-confidence-intervals", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 464, "htmlBody": "<p>In the book \"How to Measure Anything\" D. Hubbard presents a step-by-step method for calibrating your confidence intervals, which he has tested on hundreds of people, showing that it can make 90% of people almost perfect estimators within half a day of training.</p>\n<p>I've been told that the Less Wrong and CFAR community is mostly not aware of this work, so given the importance of making good estimates to rationality, I thought it would be of interest.</p>\n<p>(although note CFAR has developed its <a href=\"http://acritch.com/credence-game/\">own games</a> for training confidence interval calibration)</p>\n<p>The main techniques to employ are:</p>\n<p>&nbsp;</p>\n<blockquote></blockquote>\n<blockquote>\n<h3 id=\"equivalent_bet\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Equivalent bet:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">For each estimate imagine that you are betting $1000 on the answer being within your 90% CI. Now compare this to betting $1000 on a spinner where 90% of the time you win and 10% of the time you lose. Would you prefer to take a spin? If so, your range is too small and you need to increase it. If you decide to answer the question your range is too large and you need to reduce it. If you don&rsquo;t mind whether you answer the question or take a spin then it really is your 90% CI.</p>\n<h3 id=\"absurdity_test\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Absurdity Test:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Start with an absurdly large range, maybe from minus infinity to plus infinity, and then begin reducing it based upon things you know to be highly unlikely or even impossible.</p>\n<h3 id=\"avoid_anchoring\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Avoid Anchoring:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Anchoring&nbsp;occurs when you think of a single answer to the question and then add an error around this answer; this often leads to ranges which are too narrow. Using the absurdity test is a good way to counter problems brought on by anchoring; another is to change how you look at your 90% CI. For a 90% CI there is a 10% chance that the answer lies outside your estimate, and if you split this there is a 5% chance that the answer is above your upper bound and a 5% chance that the answer is below your lower bound. By treating each bound separately, rephrase the question to read&nbsp;&lsquo;is there a 95% chance that the answer is above my lower bound?&rsquo;. If the answer is no, then you need to increase or decrease the bound as required. You can then repeat this process for the other bound.</p>\n<h3 id=\"pros_and_cons\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Pros and cons:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Identify two pros and two cons for the range that you have given to help clarify your reasons for making this estimate.</p>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Once you have used these techniques you can make another equivalent bet to check whether your new estimate is your 90% CI.</p>\n<p>&nbsp;</p>\n</blockquote>\n<p>&nbsp;</p>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; background-color: #ffffff; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\"><span style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; line-height: normal;\">To train yourself, practice making estimates repeatedly while using these techniques, until you reach 100% accuracy.</span></p>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; background-color: #ffffff; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\"><span style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; line-height: normal;\">To read more and try sample questions, read the article we prepared on 80,000 Hours <a href=\"http://80000hours.org/blog/170-estimation-part-i-how-to-do-it\">here</a>.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5XBv2onWGRKFtAEMN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 19, "extendedScore": null, "score": 1.1792363334227777e-06, "legacy": true, "legacyId": "22412", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In the book \"How to Measure Anything\" D. Hubbard presents a step-by-step method for calibrating your confidence intervals, which he has tested on hundreds of people, showing that it can make 90% of people almost perfect estimators within half a day of training.</p>\n<p>I've been told that the Less Wrong and CFAR community is mostly not aware of this work, so given the importance of making good estimates to rationality, I thought it would be of interest.</p>\n<p>(although note CFAR has developed its <a href=\"http://acritch.com/credence-game/\">own games</a> for training confidence interval calibration)</p>\n<p>The main techniques to employ are:</p>\n<p>&nbsp;</p>\n<blockquote></blockquote>\n<blockquote>\n<h3 id=\"Equivalent_bet_\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Equivalent bet:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">For each estimate imagine that you are betting $1000 on the answer being within your 90% CI. Now compare this to betting $1000 on a spinner where 90% of the time you win and 10% of the time you lose. Would you prefer to take a spin? If so, your range is too small and you need to increase it. If you decide to answer the question your range is too large and you need to reduce it. If you don\u2019t mind whether you answer the question or take a spin then it really is your 90% CI.</p>\n<h3 id=\"Absurdity_Test_\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Absurdity Test:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Start with an absurdly large range, maybe from minus infinity to plus infinity, and then begin reducing it based upon things you know to be highly unlikely or even impossible.</p>\n<h3 id=\"Avoid_Anchoring_\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Avoid Anchoring:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Anchoring&nbsp;occurs when you think of a single answer to the question and then add an error around this answer; this often leads to ranges which are too narrow. Using the absurdity test is a good way to counter problems brought on by anchoring; another is to change how you look at your 90% CI. For a 90% CI there is a 10% chance that the answer lies outside your estimate, and if you split this there is a 5% chance that the answer is above your upper bound and a 5% chance that the answer is below your lower bound. By treating each bound separately, rephrase the question to read&nbsp;\u2018is there a 95% chance that the answer is above my lower bound?\u2019. If the answer is no, then you need to increase or decrease the bound as required. You can then repeat this process for the other bound.</p>\n<h3 id=\"Pros_and_cons_\" style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 17.77777862548828px; vertical-align: baseline; font-weight: normal; color: #262626; text-rendering: optimizelegibility; font-family: MuseoSlab-700, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Pros and cons:</h3>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Identify two pros and two cons for the range that you have given to help clarify your reasons for making this estimate.</p>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\">Once you have used these techniques you can make another equivalent bet to check whether your new estimate is your 90% CI.</p>\n<p>&nbsp;</p>\n</blockquote>\n<p>&nbsp;</p>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; background-color: #ffffff; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\"><span style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; line-height: normal;\">To train yourself, practice making estimates repeatedly while using these techniques, until you reach 100% accuracy.</span></p>\n<p style=\"margin: 0px 0px 1.5em; padding: 0px; border: 0px; outline: 0px; font-size: 15.555556297302246px; vertical-align: baseline; background-color: #ffffff; color: #262626; font-family: MuseoSans-500, helvetica, arial, sans-serif; line-height: 23.99305534362793px;\"><span style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; line-height: normal;\">To read more and try sample questions, read the article we prepared on 80,000 Hours <a href=\"http://80000hours.org/blog/170-estimation-part-i-how-to-do-it\">here</a>.</span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "sections": [{"title": "Equivalent bet:", "anchor": "Equivalent_bet_", "level": 1}, {"title": "Absurdity Test:", "anchor": "Absurdity_Test_", "level": 1}, {"title": "Avoid Anchoring:", "anchor": "Avoid_Anchoring_", "level": 1}, {"title": "Pros and cons:", "anchor": "Pros_and_cons_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-25T13:49:51.144Z", "modifiedAt": null, "url": null, "title": "Real-world examples of money-pumping?", "slug": "real-world-examples-of-money-pumping", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:07.547Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kHyJaixCdiZyFRo66/real-world-examples-of-money-pumping", "pageUrlRelative": "/posts/kHyJaixCdiZyFRo66/real-world-examples-of-money-pumping", "linkUrl": "https://www.lesswrong.com/posts/kHyJaixCdiZyFRo66/real-world-examples-of-money-pumping", "postedAtFormatted": "Thursday, April 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Real-world%20examples%20of%20money-pumping%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReal-world%20examples%20of%20money-pumping%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkHyJaixCdiZyFRo66%2Freal-world-examples-of-money-pumping%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Real-world%20examples%20of%20money-pumping%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkHyJaixCdiZyFRo66%2Freal-world-examples-of-money-pumping", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkHyJaixCdiZyFRo66%2Freal-world-examples-of-money-pumping", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 391, "htmlBody": "<p>Intransitive preferences are a <a href=\"http://en.wikipedia.org/wiki/Dynamic_inconsistency\">demonstrable</a>&nbsp;<a href=\"http://en.wikipedia.org/wiki/Allais_paradox\">characteristic</a> of human behaviour. &nbsp;So why am I having such trouble coming up with real-world examples of money-pumping?</p>\n<p>\"Because I'm not smart or imaginative enough\" is a perfectly plausible answer, but I've been mulling this one over on-and-off for a few months now, and I haven't come up with a single example that really captures what I consider to be the salient features of the scenario: a tangled hierarchy of preferences, and exploitation of that tangled hierarchy by an agent who cyclically trades the objects in that hierarchy, generating trade surplus on each transaction. &nbsp;</p>\n<p>It's possible that I am in fact thinking about money-pumping all wrong. &nbsp;All the nearly-but-not-quite examples I came up with (amongst which were bank overdraft fees, Weight Watchers, and exploitation of addiction) had the characteristics of looking like swindles or the result of personal failings, but from the inside, money-pumping must presumably feel like a series of gratifying transactions. &nbsp;We would <em>want</em>&nbsp;any cases of money-pumping we were vulnerable to.</p>\n<p>At the moment, I have the following hypotheses for the poverty of real-world money-pumping cases:</p>\n<ol>\n<li>Money-pumping is prohibitively difficult. &nbsp;The conditions that need to be met are too specific for an exploitative agent to find and abuse.</li>\n<li>Money-pumping is possible, but the gains on each transaction are generally so small as to not be worth it.</li>\n<li>Humans have faculties for identifying certain classes of strategy that exploit the limits of their rationality, and we tell any would-be money-pumper to piss right off, much like Pascal's Mugger. &nbsp;It may be possible to money-pump wasps or horses or something.</li>\n<li>Humans have some other rationality boundary that makes them too stupid to be money-pumped, to the same effect as #3.</li>\n<li>Money-pumping is prevalent in reality, but is not obvious because money-pumping agents generate their surplus in non-pecuniary abstract forms, such as labour, time, affection, attention, status, etc.</li>\n<li>Money-pumping is prevalent in reality, but obfuscated by cognitive dissonance. &nbsp;We rationalise equivalent objects in a tangled preference hierarchy as being different.</li>\n<li>Money-pumping is prevalent in reality, but obscured by cognitive phenomena such as time-preference and discounting, or underlying human aesthetic/moral tastes, (parochial equivalents of <a href=\"/lw/sy/sorting_pebbles_into_correct_heaps/\">pebble-sorting</a>), which humans convince themselves are Real Things that are Really Real, to the same effect as #6.&nbsp;</li>\n</ol>\n<p>Does anyone have anything to add, or any good/arguable cases of real-world money-pumping?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HAFdXkW4YW4KRe2Gx": 1, "PDJ6KqJBRzvKPfuS3": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kHyJaixCdiZyFRo66", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 28, "extendedScore": null, "score": 8.6e-05, "legacy": true, "legacyId": "22417", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 97, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mMBTPTjRbsrqbSkZE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-25T18:20:19.602Z", "modifiedAt": null, "url": null, "title": "Attempting to rescue logical positivism", "slug": "attempting-to-rescue-logical-positivism", "viewCount": null, "lastCommentedAt": "2020-08-19T04:18:19.449Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RolfAndreassen", "createdAt": "2009-04-17T19:37:23.246Z", "isAdmin": false, "displayName": "RolfAndreassen"}, "userId": "KLJmn2HYWEu4tBKcC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2KYEj8dkwDxzSfH9q/attempting-to-rescue-logical-positivism", "pageUrlRelative": "/posts/2KYEj8dkwDxzSfH9q/attempting-to-rescue-logical-positivism", "linkUrl": "https://www.lesswrong.com/posts/2KYEj8dkwDxzSfH9q/attempting-to-rescue-logical-positivism", "postedAtFormatted": "Thursday, April 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Attempting%20to%20rescue%20logical%20positivism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAttempting%20to%20rescue%20logical%20positivism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2KYEj8dkwDxzSfH9q%2Fattempting-to-rescue-logical-positivism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Attempting%20to%20rescue%20logical%20positivism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2KYEj8dkwDxzSfH9q%2Fattempting-to-rescue-logical-positivism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2KYEj8dkwDxzSfH9q%2Fattempting-to-rescue-logical-positivism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 189, "htmlBody": "<p>Very brief recap: The logical positivists said \"All truths are experimentally testable\". Their critics responded: \"If that's true, how did you experimentally test it? And if it's not true, who cares?\" Which is a fair criticism. Logical positivism pretty much collapsed as a philosophical position. But it seems to me that a very slight rephrasing might have saved it: \"All _beliefs_ are experimentally testable\". For if the critic makes the same adjustment, asking \"Is that a belief, and if so -\" you can interrupt him and say, \"No, that's not a belief, that's a definition of what it means to say 'I believe X'.\"</p>\n<p>A definition is not true or false, it is useful or not useful. Why is this definition useful? Because it allows us to distinguish between two classes of declarative statements; the ones that are actual beliefs, and the ones that have the grammatical form of beliefs but are empty of meaningful belief-content.</p>\n<p>It seems to me, then, that both the positivists and their critics fell into the trap of confusing 'belief' and 'truth', and that carefully making this distinction might have saved positivism from considerable undeserved mockery.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2KYEj8dkwDxzSfH9q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 8, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "22419", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-26T08:55:44.759Z", "modifiedAt": null, "url": null, "title": "Meetup : Bratislava lesswrong meetup III", "slug": "meetup-bratislava-lesswrong-meetup-iii", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:31.785Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BarbaraB", "createdAt": "2012-04-04T15:11:52.435Z", "isAdmin": false, "displayName": "BarbaraB"}, "userId": "aHcDnFsxTnRpMEuXD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uxcLtLnPM9rMvRYYC/meetup-bratislava-lesswrong-meetup-iii", "pageUrlRelative": "/posts/uxcLtLnPM9rMvRYYC/meetup-bratislava-lesswrong-meetup-iii", "linkUrl": "https://www.lesswrong.com/posts/uxcLtLnPM9rMvRYYC/meetup-bratislava-lesswrong-meetup-iii", "postedAtFormatted": "Friday, April 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Bratislava%20lesswrong%20meetup%20III&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Bratislava%20lesswrong%20meetup%20III%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuxcLtLnPM9rMvRYYC%2Fmeetup-bratislava-lesswrong-meetup-iii%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Bratislava%20lesswrong%20meetup%20III%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuxcLtLnPM9rMvRYYC%2Fmeetup-bratislava-lesswrong-meetup-iii", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuxcLtLnPM9rMvRYYC%2Fmeetup-bratislava-lesswrong-meetup-iii", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 74, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m2'>Bratislava lesswrong meetup III</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 May 2013 06:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Ur\u0161ul\u00ednska 9, 811 01 Bratislava</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will see each other at Malewill caf\u00e9.</p>\n\n<p>Breaking news !!! \nThe charming girl, Cat from USA, who teaches emotional stuff at CFAR rationality minicamps, will be visiting our meetup !\nOne more reason to attend this time :-)</p>\n\n<p>My phone number is, as usual, ++421-915-896911.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m2'>Bratislava lesswrong meetup III</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uxcLtLnPM9rMvRYYC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 1.1803551349784637e-06, "legacy": true, "legacyId": "22424", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Bratislava_lesswrong_meetup_III\">Discussion article for the meetup : <a href=\"/meetups/m2\">Bratislava lesswrong meetup III</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 May 2013 06:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Ur\u0161ul\u00ednska 9, 811 01 Bratislava</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will see each other at Malewill caf\u00e9.</p>\n\n<p>Breaking news !!! \nThe charming girl, Cat from USA, who teaches emotional stuff at CFAR rationality minicamps, will be visiting our meetup !\nOne more reason to attend this time :-)</p>\n\n<p>My phone number is, as usual, ++421-915-896911.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Bratislava_lesswrong_meetup_III1\">Discussion article for the meetup : <a href=\"/meetups/m2\">Bratislava lesswrong meetup III</a></h2>", "sections": [{"title": "Discussion article for the meetup : Bratislava lesswrong meetup III", "anchor": "Discussion_article_for_the_meetup___Bratislava_lesswrong_meetup_III", "level": 1}, {"title": "Discussion article for the meetup : Bratislava lesswrong meetup III", "anchor": "Discussion_article_for_the_meetup___Bratislava_lesswrong_meetup_III1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-26T18:06:56.884Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington DC books meetup", "slug": "meetup-washington-dc-books-meetup-1", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:06.189Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rBq2dJf6i4smqNfRZ/meetup-washington-dc-books-meetup-1", "pageUrlRelative": "/posts/rBq2dJf6i4smqNfRZ/meetup-washington-dc-books-meetup-1", "linkUrl": "https://www.lesswrong.com/posts/rBq2dJf6i4smqNfRZ/meetup-washington-dc-books-meetup-1", "postedAtFormatted": "Friday, April 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%20DC%20books%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%20DC%20books%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrBq2dJf6i4smqNfRZ%2Fmeetup-washington-dc-books-meetup-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%20DC%20books%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrBq2dJf6i4smqNfRZ%2Fmeetup-washington-dc-books-meetup-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrBq2dJf6i4smqNfRZ%2Fmeetup-washington-dc-books-meetup-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m3'>Washington DC books meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 April 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to talk about books we've found interesting, exchange books (so bring some!) and decide if/how we want to have a book club.</p>\n\n<p>(This was also the last meetup topic, which got cancelled at the last minute)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m3'>Washington DC books meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rBq2dJf6i4smqNfRZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.1807435104199704e-06, "legacy": true, "legacyId": "22427", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_books_meetup\">Discussion article for the meetup : <a href=\"/meetups/m3\">Washington DC books meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 April 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to talk about books we've found interesting, exchange books (so bring some!) and decide if/how we want to have a book club.</p>\n\n<p>(This was also the last meetup topic, which got cancelled at the last minute)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_books_meetup1\">Discussion article for the meetup : <a href=\"/meetups/m3\">Washington DC books meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington DC books meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_books_meetup", "level": 1}, {"title": "Discussion article for the meetup : Washington DC books meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_books_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-26T18:45:44.504Z", "modifiedAt": null, "url": null, "title": "Logic in the language of probability", "slug": "logic-in-the-language-of-probability", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:05.897Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3atutKpoGAfDe5XFo/logic-in-the-language-of-probability", "pageUrlRelative": "/posts/3atutKpoGAfDe5XFo/logic-in-the-language-of-probability", "linkUrl": "https://www.lesswrong.com/posts/3atutKpoGAfDe5XFo/logic-in-the-language-of-probability", "postedAtFormatted": "Friday, April 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Logic%20in%20the%20language%20of%20probability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALogic%20in%20the%20language%20of%20probability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3atutKpoGAfDe5XFo%2Flogic-in-the-language-of-probability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Logic%20in%20the%20language%20of%20probability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3atutKpoGAfDe5XFo%2Flogic-in-the-language-of-probability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3atutKpoGAfDe5XFo%2Flogic-in-the-language-of-probability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 487, "htmlBody": "<p>This post is a minor note, to go along with the post on the <a href=\"/r/discussion/lw/h9k/probabilistic_l%C3%B6b_theorem/\">probabilistic L&ouml;b theorem</a>. It simply seeks to justify why terms like \"having probability 1\" are used interchangeably with \"provable\" and why implications symbols \"&rarr;\" can be used in a probabilistic setting.</p>\n<p>Take a system of classical logic, with a single <a href=\"http://en.wikipedia.org/wiki/Rule_of_inference\">rule of inference</a>: <a href=\"http://en.wikipedia.org/wiki/Modus_ponens\">modus ponens</a>:</p>\n<p style=\"padding-left: 30px;\">From A and A&rarr;B, deduce B.</p>\n<p>Having a single rule of inference isn't much of a restriction, because you can replace other rules of inference (\"from A<sub>1</sub>,A<sub>2</sub>,... and A<sub>n</sub>, deduce B\") with an axiom or <a href=\"http://en.wikipedia.org/wiki/Axiom_schema\">axiom schema</a>&nbsp;(\"A<sub>1</sub>&and;A<sub>2</sub>&and;...&and;A<sub>n</sub>&nbsp;&rarr; B\") and then use modus ponens on that axiom to get the other rule of inference.</p>\n<p>In this logical system, I'm now going to make some purely syntactical changes - not changing the meaning of anything, just the way we write things. For any sentence A that doesn't contain an implication arrow &rarr;, replace</p>\n<p style=\"padding-left: 30px;\">A with P(A)=1.</p>\n<p>Similarly, replace any sentence of the type</p>\n<p style=\"padding-left: 30px;\">A &rarr; B with P(B|A)=1.</p>\n<p>This is recursive, so we replace</p>\n<p style=\"padding-left: 30px;\">(A &rarr; B) &rarr; C with P(C | P(B|A)=1 )=1.</p>\n<p>And instead of using modus ponens, we'll use a combined <a href=\"http://en.wikipedia.org/wiki/Bayesian_inference\">Bayesian inference</a> and <a href=\"http://en.wikipedia.org/wiki/Law_of_total_probability\">law of total probability</a>:</p>\n<p style=\"padding-left: 30px;\">From P(A)=1 and P(B|A)=1, deduce P(B)=1.<a id=\"more\"></a></p>\n<p>Again, these are purely syntactic changes - just&nbsp;rewriting&nbsp;the symbols of a formal system in an entirely equivalent fashion. What this demonstrates, though, is that we can do classical logic using the language and the tools of probability - and hence that the objects and laws of classical logic have probabilistic counterparts.</p>\n<p>In fact, we can do a bit better, make the similarity more pronounced. Instead of having modus ponens, allow for two \"logical\" rules of inference:</p>\n<ol>\n<li>From A &rarr; B and A, deduce A&and;B.</li>\n<li>From&nbsp;A&and;B, deduce B (<a href=\"http://en.wikipedia.org/wiki/Simplification\">simplification</a>).</li>\n</ol>\n<p>Together, these two rules give modus ponens, and if we've chosen our axioms in non-weird ways, we shouldn't be able to prove anything we couldn't before. Then when writing our logic in the language of probability, we similarly have two \"probabilistic\" rules of inference:</p>\n<ol>\n<li>From P(B|A)=s and P(A)=t, deduce P(A&and;B)=st (<a href=\"http://en.wikipedia.org/wiki/Conditional_probability\">conditional probability</a>).</li>\n<li>From P(A&and;B)=s, deduce P(B)&ge;s.</li>\n</ol>\n<p>Here, we've sneakily introduced the&nbsp;possibility&nbsp;of probabilities not equal to 1 - even though they will never appear in our syntax, the rules allow for them. In order to show complete equivalence between the two systems, we merely have to require that P(B)&ge;1 be just another way to write P(B)=1.</p>\n<p>We can extend the correspondence still further by allowing P(A)=0 to be another way of writing P(&not;A)=1 (and stating that P(B)&ge;0 is an always true but vacuous statement). If we do so, we'd need to add more \"logical\" rules of inference to maintain the strict equivalence with the \"probabilistic\" rules of inference above; but again, if our axioms are non-weird, we wouldn't actually be able to prove anything we couldn't before.</p>\n<p>I won't belabour the point any further, just reiterate that classical logic can be done in the language of probability, so I'll be somewhat sloppy about language when comparing these two worlds.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3atutKpoGAfDe5XFo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 20, "extendedScore": null, "score": 1.1807708528235586e-06, "legacy": true, "legacyId": "22377", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oBDTMnEzptBidvmw7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-26T18:45:49.944Z", "modifiedAt": null, "url": null, "title": "Probabilistic L\u00f6b theorem", "slug": "probabilistic-loeb-theorem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.660Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oBDTMnEzptBidvmw7/probabilistic-loeb-theorem", "pageUrlRelative": "/posts/oBDTMnEzptBidvmw7/probabilistic-loeb-theorem", "linkUrl": "https://www.lesswrong.com/posts/oBDTMnEzptBidvmw7/probabilistic-loeb-theorem", "postedAtFormatted": "Friday, April 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Probabilistic%20L%C3%B6b%20theorem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProbabilistic%20L%C3%B6b%20theorem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoBDTMnEzptBidvmw7%2Fprobabilistic-loeb-theorem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Probabilistic%20L%C3%B6b%20theorem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoBDTMnEzptBidvmw7%2Fprobabilistic-loeb-theorem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoBDTMnEzptBidvmw7%2Fprobabilistic-loeb-theorem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1024, "htmlBody": "<p>In this post (based on results from <a href=\"http://intelligence.org/\">MIRI</a>'s recent workshop), I'll be looking at whether reflective theories of logical uncertainty (such as Paul's <a href=\"/lw/h1k/reflection_in_probabilistic_set_theory/\">design</a>) still suffer from <a href=\"/lw/t6/the_cartoon_guide_to_l%C3%B6bs_theorem/\">L&ouml;b's theorem</a>.</p>\n<p>Theories of logical uncertainty are theories which can assign probability to logical statements. Reflective theories are theories which know something about themselves within themselves. In Paul's theory, there is an external P, in the meta language, which assigns probabilities to statements, an internal P, inside the theory, that computes probabilities of coded versions of the statements inside the language, and a reflection principle that relates these two P's to each other.</p>\n<p>And&nbsp;L&ouml;b's theorem is the result that if a (sufficiently complex, classical) system can prove that \"a proof of Q implies Q\" (often abbreviated as \u25a1Q &rarr; Q), then it can prove Q. What would be the probabilistic&nbsp;analogue? Let's use \u25a1<sub>a</sub>Q to mean P('Q')&ge;1-a (so that \u25a1<sub>0</sub>Q is the same as the old \u25a1Q; see <a href=\"/r/discussion/lw/h9l/logic_in_the_language_of_probability/\">this post</a> on why we can interchange probabilistic and provability notions). Then&nbsp;L&ouml;b's theorem in a probabilistic setting could:</p>\n<p style=\"padding-left: 30px;\">Probabilistic L&ouml;b's theorem: for all a&lt;1, if the system can prove \u25a1<sub>a</sub>Q &rarr; Q, then the system can prove Q.</p>\n<p>To understand this condition, we'll go through the proof of L&ouml;b's theorem in a probabilistic setting, and see if and when it breaks down. We'll conclude with an example to show that any decent reflective probability theory has to violate this theorem.<a id=\"more\"></a></p>\n<h2>L&ouml;b's proof fails</h2>\n<p>First, the derivation conditions. Using&nbsp;\u22a2 to designate the system can prove/the system can show with probability 1 (note that&nbsp;\u22a2 is the meta-language equivalent of \u25a1), then the classical derivation conditions are:</p>\n<ol>\n<li>If&nbsp;\u22a2 A, then&nbsp;\u22a2&nbsp;\u25a1A.</li>\n<li>\u22a2 \u25a1A&nbsp;&rarr;&nbsp;\u25a1\u25a1A.</li>\n<li>\u22a2 \u25a1(A&nbsp;&rarr; B)&nbsp;&rarr; (\u25a1A&nbsp;&rarr;&nbsp;\u25a1B).</li>\n</ol>\n<p>Informally, these state that \"if the system can prove something, it can prove it can prove it\", \"the system can prove that a proof of something implies a proof of a proof of something\" and \"the system can prove that proofs obey modus ponens\".</p>\n<p>What are the equivalent statements for probabilistic theories? According to Paul's <a href=\"/lw/h1k/reflection_in_probabilistic_set_theory/\">approach</a>, one must always add small epsilons when talking about probabilities. So the following derivation principles seem reasonable, where the latin indexes (a,b,c...) are meant to represent numbers that can be arbitrarily close to zero:</p>\n<ol>\n<li>If&nbsp;\u22a2 A, then&nbsp;\u22a2&nbsp;\u25a1<sub>a&nbsp;</sub>A.</li>\n<li>\u22a2 \u25a1<sub>a</sub>A&nbsp;&rarr;&nbsp;\u25a1<sub>c</sub>\u25a1<sub>a+<strong>b</strong>&nbsp;</sub>A.</li>\n<li>\u22a2 \u25a1<sub>a</sub>(A&nbsp;&rarr; B)&nbsp;&rarr; (\u25a1<sub>b</sub>A&nbsp;&rarr;&nbsp;\u25a1<sub>a+b</sub>B).</li>\n</ol>\n<p>The first principle is quite clear - if the system can prove A, it can prove that A's probability is arbitrarily close to 1. The second one is a bit more complex - the system can prove that if the probability of A is more than 1-a, then for any b&gt;0, the system can prove that the probability of \"the probability of A being greater than 1-a-b\" is arbitrarily close to 1. Read that sentence again once or twice. The \"b\" in that derivation principle will be crucial - if b can be set to zero, L&ouml;b's theorem is true, if not, it can't be proved in the usual way. And the third derivation principle is simply stating that \"if P(B|A)&ge;1-a\", then \"P(A)&ge;1-b\" implies that \"P(B)&ge;1-a-b\" - and that the system itself can prove this. Unlike the second derivation principle, there is no need to add another layer of uncertainty here.</p>\n<p>With these tools in hand, the proof can proceed in the usual way. Fix a, and Q be sentence such that the system can prove</p>\n<p style=\"padding-left: 30px;\">\u25a1<sub>a</sub>Q &rarr; Q.</p>\n<p>Then fix b &lt; a, and construct, by diagonalisation, the&nbsp;L&ouml;b sentence:</p>\n<p style=\"padding-left: 30px;\">(\u25a1<sub>b</sub>L&nbsp;&rarr; Q)&nbsp;&harr; L.</p>\n<p>Then the proof steps are:</p>\n<p>\n<table style=\"color: #000000; line-height: normal; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">A)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">c</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;(</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr; (<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr; Q))</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">1st derivation, def of L</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">B)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr;&nbsp;<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+c</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">(</span><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr; Q)</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">3rd derivation, A)</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">C)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr; (<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">e</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr;&nbsp;<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+c+e</sub>Q)</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">3rd derivation, B)</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">D)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr; (<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">e</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+f&nbsp;</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L)</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">2rd derivation</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">E)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr; <span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+c+e</sub>Q</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">C), D), setting d+f=b</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">F)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;&rarr; <span style=\"font-size: small; line-height: normal; text-align: start;\">Q</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">E), def of Q, setting d+c+e=a</span></td>\n</tr>\n</tbody>\n</table>\n</p>\n<p>What we would want to deduce at this point is that the system can prove that L is true. This is only possible if we can set d=b. But we've shown that d+f=b, where f comes from the second derivation principle. If we can set that f to zero, we can proceed; if f&gt;0, the proof stops here. So now imagine that we can indeed set f=0; then the rest of the proof is standard:</p>\n<table style=\"color: #000000; line-height: normal; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">G)</span></td>\n<td style=\"text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 L</span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">F), def of L, with d=b</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">H)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L</span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">1st derivation, G)</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">I)</span></td>\n<td style=\"text-align: start;\"><span style=\"font-size: small;\">\u22a2 Q</span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">3rd derivation, B)</span></td>\n</tr>\n</tbody>\n</table>\n<p>Hence for any probabilistic logic to avoid L&ouml;b's theorem, we need the second derivation principle to have a little bit of extra uncertainty, that can be made arbitrarily tiny - but never zero.</p>\n<h2>L&ouml;b's theorem fails</h2>\n<p>But we can do better than that. With a little bit more conditions on the probability function P, we can construct counter-examples to the probabilistic L&ouml;b theorem. What we need is that the system knows that probabilities of opposites sum to one; that for all Q,</p>\n<p style=\"padding-left: 30px;\">\u22a2 P('&not;Q')+P('Q')=1.</p>\n<p>Then let F be any contradiction. Thus the system can prove the tautology that is its opposite:</p>\n<p style=\"padding-left: 30px;\">\u22a2 &not;F</p>\n<p>By the derivation principle, the system can also prove, for any a&lt;1,</p>\n<p style=\"padding-left: 30px;\">\u22a2 \u25a1<sub>1-a</sub>&nbsp;&not;F.</p>\n<p>This is just another way of writing that P('&not;F') &ge; a. Since probabilities sum to one, the system can prove that P('F') &le;&nbsp;1-a. Hence that \u25a1<sub>b</sub>&nbsp;F (which claims P('F') &ge; 1-b) is actually false for any b&lt;a. Since a false statement implies every statement, the system demonstrates:</p>\n<p style=\"padding-left: 30px;\">\u22a2 \u25a1<sub>b</sub>&nbsp;F &rarr; F.</p>\n<p>Now, we can choose any a&lt;1 and any b&lt;a - hence we can choose any b&lt;1. This is the condition for the probabilistic L&ouml;b theorem. And yet F is not only false, the system can disprove it!</p>\n<p>Note that the result also holds if the system know that the probabilities sum to something&nbsp;arbitrarily&nbsp;close to 1. As a corollary to these results, we can show that no coherent system of probabilistic logic can have the second derivation principle without the extra uncertainty, while&nbsp;simultaneously&nbsp;knowing that probabilities sum to 1.</p>\n<h2>The last echoes of L&ouml;b's theorem</h2>\n<p>There is one last possibility for a probabilistic L&ouml;b theorem, not ruled out by the counterexample above. It might be that all statements A are true if</p>\n<p style=\"padding-left: 30px;\">\u22a2 P('A')&gt;0 &nbsp;&rarr; A.</p>\n<p>However, this doesn't seem a critical flaw - P('A')&gt;0 is something that is 'almost always' true, if we see P('A') as being an&nbsp;arbitrarily&nbsp;close <em>approximation</em> of the meta probability P(A). And if the system shows that something 'almost always true' implies A, then A being true seems unsurprising.</p>\n<p>And this result poses no real problems for identical probabilistic systems trusting each other (to within an arbitrarily small bound).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JHYaBGQuuKHdwnrAK": 1, "6nS8oYmSMuFMaiowF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oBDTMnEzptBidvmw7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 39, "extendedScore": null, "score": 9.6e-05, "legacy": true, "legacyId": "22376", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In this post (based on results from <a href=\"http://intelligence.org/\">MIRI</a>'s recent workshop), I'll be looking at whether reflective theories of logical uncertainty (such as Paul's <a href=\"/lw/h1k/reflection_in_probabilistic_set_theory/\">design</a>) still suffer from <a href=\"/lw/t6/the_cartoon_guide_to_l%C3%B6bs_theorem/\">L\u00f6b's theorem</a>.</p>\n<p>Theories of logical uncertainty are theories which can assign probability to logical statements. Reflective theories are theories which know something about themselves within themselves. In Paul's theory, there is an external P, in the meta language, which assigns probabilities to statements, an internal P, inside the theory, that computes probabilities of coded versions of the statements inside the language, and a reflection principle that relates these two P's to each other.</p>\n<p>And&nbsp;L\u00f6b's theorem is the result that if a (sufficiently complex, classical) system can prove that \"a proof of Q implies Q\" (often abbreviated as \u25a1Q \u2192 Q), then it can prove Q. What would be the probabilistic&nbsp;analogue? Let's use \u25a1<sub>a</sub>Q to mean P('Q')\u22651-a (so that \u25a1<sub>0</sub>Q is the same as the old \u25a1Q; see <a href=\"/r/discussion/lw/h9l/logic_in_the_language_of_probability/\">this post</a> on why we can interchange probabilistic and provability notions). Then&nbsp;L\u00f6b's theorem in a probabilistic setting could:</p>\n<p style=\"padding-left: 30px;\">Probabilistic L\u00f6b's theorem: for all a&lt;1, if the system can prove \u25a1<sub>a</sub>Q \u2192 Q, then the system can prove Q.</p>\n<p>To understand this condition, we'll go through the proof of L\u00f6b's theorem in a probabilistic setting, and see if and when it breaks down. We'll conclude with an example to show that any decent reflective probability theory has to violate this theorem.<a id=\"more\"></a></p>\n<h2 id=\"L_b_s_proof_fails\">L\u00f6b's proof fails</h2>\n<p>First, the derivation conditions. Using&nbsp;\u22a2 to designate the system can prove/the system can show with probability 1 (note that&nbsp;\u22a2 is the meta-language equivalent of \u25a1), then the classical derivation conditions are:</p>\n<ol>\n<li>If&nbsp;\u22a2 A, then&nbsp;\u22a2&nbsp;\u25a1A.</li>\n<li>\u22a2 \u25a1A&nbsp;\u2192&nbsp;\u25a1\u25a1A.</li>\n<li>\u22a2 \u25a1(A&nbsp;\u2192 B)&nbsp;\u2192 (\u25a1A&nbsp;\u2192&nbsp;\u25a1B).</li>\n</ol>\n<p>Informally, these state that \"if the system can prove something, it can prove it can prove it\", \"the system can prove that a proof of something implies a proof of a proof of something\" and \"the system can prove that proofs obey modus ponens\".</p>\n<p>What are the equivalent statements for probabilistic theories? According to Paul's <a href=\"/lw/h1k/reflection_in_probabilistic_set_theory/\">approach</a>, one must always add small epsilons when talking about probabilities. So the following derivation principles seem reasonable, where the latin indexes (a,b,c...) are meant to represent numbers that can be arbitrarily close to zero:</p>\n<ol>\n<li>If&nbsp;\u22a2 A, then&nbsp;\u22a2&nbsp;\u25a1<sub>a&nbsp;</sub>A.</li>\n<li>\u22a2 \u25a1<sub>a</sub>A&nbsp;\u2192&nbsp;\u25a1<sub>c</sub>\u25a1<sub>a+<strong>b</strong>&nbsp;</sub>A.</li>\n<li>\u22a2 \u25a1<sub>a</sub>(A&nbsp;\u2192 B)&nbsp;\u2192 (\u25a1<sub>b</sub>A&nbsp;\u2192&nbsp;\u25a1<sub>a+b</sub>B).</li>\n</ol>\n<p>The first principle is quite clear - if the system can prove A, it can prove that A's probability is arbitrarily close to 1. The second one is a bit more complex - the system can prove that if the probability of A is more than 1-a, then for any b&gt;0, the system can prove that the probability of \"the probability of A being greater than 1-a-b\" is arbitrarily close to 1. Read that sentence again once or twice. The \"b\" in that derivation principle will be crucial - if b can be set to zero, L\u00f6b's theorem is true, if not, it can't be proved in the usual way. And the third derivation principle is simply stating that \"if P(B|A)\u22651-a\", then \"P(A)\u22651-b\" implies that \"P(B)\u22651-a-b\" - and that the system itself can prove this. Unlike the second derivation principle, there is no need to add another layer of uncertainty here.</p>\n<p>With these tools in hand, the proof can proceed in the usual way. Fix a, and Q be sentence such that the system can prove</p>\n<p style=\"padding-left: 30px;\">\u25a1<sub>a</sub>Q \u2192 Q.</p>\n<p>Then fix b &lt; a, and construct, by diagonalisation, the&nbsp;L\u00f6b sentence:</p>\n<p style=\"padding-left: 30px;\">(\u25a1<sub>b</sub>L&nbsp;\u2192 Q)&nbsp;\u2194 L.</p>\n<p>Then the proof steps are:</p>\n<p>\n</p><table style=\"color: #000000; line-height: normal; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">A)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">c</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;(</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192 (<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192 Q))</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">1st derivation, def of L</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">B)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192&nbsp;<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+c</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">(</span><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192 Q)</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">3rd derivation, A)</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">C)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192 (<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">e</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192&nbsp;<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+c+e</sub>Q)</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">3rd derivation, B)</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">D)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192 (<span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">e</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+f&nbsp;</sub><span style=\"font-size: small; line-height: normal; text-align: start;\">L)</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">2rd derivation</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">E)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192 <span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u25a1</span><sub style=\"line-height: normal; text-align: start;\">d+c+e</sub>Q</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">C), D), setting d+f=b</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">F)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">d</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L&nbsp;\u2192 <span style=\"font-size: small; line-height: normal; text-align: start;\">Q</span></span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">E), def of Q, setting d+c+e=a</span></td>\n</tr>\n</tbody>\n</table>\n<p></p>\n<p>What we would want to deduce at this point is that the system can prove that L is true. This is only possible if we can set d=b. But we've shown that d+f=b, where f comes from the second derivation principle. If we can set that f to zero, we can proceed; if f&gt;0, the proof stops here. So now imagine that we can indeed set f=0; then the rest of the proof is standard:</p>\n<table style=\"color: #000000; line-height: normal; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">G)</span></td>\n<td style=\"text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 L</span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">F), def of L, with d=b</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">H)</span></td>\n<td><span style=\"font-size: small; line-height: normal; text-align: start;\"><span style=\"font-size: small; line-height: normal; text-align: start;\">\u22a2 \u25a1</span><sub style=\"line-height: normal; text-align: start;\">b</sub></span><span style=\"line-height: normal; text-align: start;\">&nbsp;</span><span style=\"font-size: small; line-height: normal; text-align: start;\">L</span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">1st derivation, G)</span></td>\n</tr>\n<tr>\n<td><span style=\"font-size: small; text-align: start;\">I)</span></td>\n<td style=\"text-align: start;\"><span style=\"font-size: small;\">\u22a2 Q</span></td>\n<td align=\"right\"><span style=\"font-size: small; text-align: start;\">3rd derivation, B)</span></td>\n</tr>\n</tbody>\n</table>\n<p>Hence for any probabilistic logic to avoid L\u00f6b's theorem, we need the second derivation principle to have a little bit of extra uncertainty, that can be made arbitrarily tiny - but never zero.</p>\n<h2 id=\"L_b_s_theorem_fails\">L\u00f6b's theorem fails</h2>\n<p>But we can do better than that. With a little bit more conditions on the probability function P, we can construct counter-examples to the probabilistic L\u00f6b theorem. What we need is that the system knows that probabilities of opposites sum to one; that for all Q,</p>\n<p style=\"padding-left: 30px;\">\u22a2 P('\u00acQ')+P('Q')=1.</p>\n<p>Then let F be any contradiction. Thus the system can prove the tautology that is its opposite:</p>\n<p style=\"padding-left: 30px;\">\u22a2 \u00acF</p>\n<p>By the derivation principle, the system can also prove, for any a&lt;1,</p>\n<p style=\"padding-left: 30px;\">\u22a2 \u25a1<sub>1-a</sub>&nbsp;\u00acF.</p>\n<p>This is just another way of writing that P('\u00acF') \u2265 a. Since probabilities sum to one, the system can prove that P('F') \u2264&nbsp;1-a. Hence that \u25a1<sub>b</sub>&nbsp;F (which claims P('F') \u2265 1-b) is actually false for any b&lt;a. Since a false statement implies every statement, the system demonstrates:</p>\n<p style=\"padding-left: 30px;\">\u22a2 \u25a1<sub>b</sub>&nbsp;F \u2192 F.</p>\n<p>Now, we can choose any a&lt;1 and any b&lt;a - hence we can choose any b&lt;1. This is the condition for the probabilistic L\u00f6b theorem. And yet F is not only false, the system can disprove it!</p>\n<p>Note that the result also holds if the system know that the probabilities sum to something&nbsp;arbitrarily&nbsp;close to 1. As a corollary to these results, we can show that no coherent system of probabilistic logic can have the second derivation principle without the extra uncertainty, while&nbsp;simultaneously&nbsp;knowing that probabilities sum to 1.</p>\n<h2 id=\"The_last_echoes_of_L_b_s_theorem\">The last echoes of L\u00f6b's theorem</h2>\n<p>There is one last possibility for a probabilistic L\u00f6b theorem, not ruled out by the counterexample above. It might be that all statements A are true if</p>\n<p style=\"padding-left: 30px;\">\u22a2 P('A')&gt;0 &nbsp;\u2192 A.</p>\n<p>However, this doesn't seem a critical flaw - P('A')&gt;0 is something that is 'almost always' true, if we see P('A') as being an&nbsp;arbitrarily&nbsp;close <em>approximation</em> of the meta probability P(A). And if the system shows that something 'almost always true' implies A, then A being true seems unsurprising.</p>\n<p>And this result poses no real problems for identical probabilistic systems trusting each other (to within an arbitrarily small bound).</p>", "sections": [{"title": "L\u00f6b's proof fails", "anchor": "L_b_s_proof_fails", "level": 1}, {"title": "L\u00f6b's theorem fails", "anchor": "L_b_s_theorem_fails", "level": 1}, {"title": "The last echoes of L\u00f6b's theorem", "anchor": "The_last_echoes_of_L_b_s_theorem", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "40 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["duAkuSqJhGDcfMaTA", "ALCnqX6Xx8bpFMZq3", "3atutKpoGAfDe5XFo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-26T19:11:13.339Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Atlanta, Austin, Berlin, Brussels, Cambridge MA, Cincinnati, Durham, Vancouver, Washington DC", "slug": "weekly-lw-meetups-atlanta-austin-berlin-brussels-cambridge", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wvDERsYwz2rhKgKKA/weekly-lw-meetups-atlanta-austin-berlin-brussels-cambridge", "pageUrlRelative": "/posts/wvDERsYwz2rhKgKKA/weekly-lw-meetups-atlanta-austin-berlin-brussels-cambridge", "linkUrl": "https://www.lesswrong.com/posts/wvDERsYwz2rhKgKKA/weekly-lw-meetups-atlanta-austin-berlin-brussels-cambridge", "postedAtFormatted": "Friday, April 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Atlanta%2C%20Austin%2C%20Berlin%2C%20Brussels%2C%20Cambridge%20MA%2C%20Cincinnati%2C%20Durham%2C%20Vancouver%2C%20Washington%20DC&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Atlanta%2C%20Austin%2C%20Berlin%2C%20Brussels%2C%20Cambridge%20MA%2C%20Cincinnati%2C%20Durham%2C%20Vancouver%2C%20Washington%20DC%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwvDERsYwz2rhKgKKA%2Fweekly-lw-meetups-atlanta-austin-berlin-brussels-cambridge%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Atlanta%2C%20Austin%2C%20Berlin%2C%20Brussels%2C%20Cambridge%20MA%2C%20Cincinnati%2C%20Durham%2C%20Vancouver%2C%20Washington%20DC%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwvDERsYwz2rhKgKKA%2Fweekly-lw-meetups-atlanta-austin-berlin-brussels-cambridge", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwvDERsYwz2rhKgKKA%2Fweekly-lw-meetups-atlanta-austin-berlin-brussels-cambridge", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 541, "htmlBody": "<p><strong>This summary was posted to LW Main on April 19th. The following week's summary is <a href=\"/lw/hb0/weekly_lw_meetups_austin_london_melbourne_moscow/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/le\">April Atlanta Meetup! Friday, April 19th:&nbsp;<span class=\"date\">19 April 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/lu\">Durham/RTLW HPMoR discussion, ch. 56-60:&nbsp;<span class=\"date\">20 April 2013 12:30PM</span></a></li>\n<li><a href=\"/meetups/lg\">Brussels meetup:&nbsp;<span class=\"date\">20 April 2013 01:00PM</span></a></li>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">20 April 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/lu\"></a><a href=\"/meetups/lm\">Vancouver CFAR Materials: Bayes practice!:&nbsp;<span class=\"date\">20 April 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/ln\">Berlin Social Meetup:&nbsp;<span class=\"date\">20 April 2013 07:30PM</span></a></li>\n<li><a href=\"/meetups/lp\">Washington DC books meetup:&nbsp;<span class=\"date\">21 April 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/lf\">Cincinnati near-Schelling day:&nbsp;<span class=\"date\">21 April 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/lw\">London Meetup, 28th April:&nbsp;<span class=\"date\">28 April 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/lr\">Moscow, Measurements:&nbsp;<span class=\"date\">28 April 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/lh\">Munich Meetup:&nbsp;<span class=\"date\">04 May 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/lt\">Vienna meetup #3:&nbsp;<span class=\"date\">18 May 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/lv\">Cambridge (MA): The Meaning Of Life For Beginners:&nbsp;<span class=\"date\">21 April 2013 02:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://tinychat.com/lesswrong\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wvDERsYwz2rhKgKKA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.1807888125169659e-06, "legacy": true, "legacyId": "22360", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FaDojbECCqSFApgk7", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-27T12:39:02.727Z", "modifiedAt": null, "url": null, "title": "Links passing through api.viglink.com?", "slug": "links-passing-through-api-viglink-com", "viewCount": null, "lastCommentedAt": "2017-06-17T04:23:32.978Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Document", "createdAt": "2010-02-08T04:14:47.949Z", "isAdmin": false, "displayName": "Document"}, "userId": "vaMNHjzaCGqF8yTMS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/joDRvhGMBeAWAv4Hr/links-passing-through-api-viglink-com", "pageUrlRelative": "/posts/joDRvhGMBeAWAv4Hr/links-passing-through-api-viglink-com", "linkUrl": "https://www.lesswrong.com/posts/joDRvhGMBeAWAv4Hr/links-passing-through-api-viglink-com", "postedAtFormatted": "Saturday, April 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Links%20passing%20through%20api.viglink.com%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALinks%20passing%20through%20api.viglink.com%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoDRvhGMBeAWAv4Hr%2Flinks-passing-through-api-viglink-com%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Links%20passing%20through%20api.viglink.com%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoDRvhGMBeAWAv4Hr%2Flinks-passing-through-api-viglink-com", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoDRvhGMBeAWAv4Hr%2Flinks-passing-through-api-viglink-com", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<p>Visiting Less Wrong after being absent for a while can be a major <a href=\"/lw/2po/selfimprovement_or_shiny_distraction_why_less/\">time sink</a>. The sidebar recent-posts and recent-comments links (which I usually have <a href=\"/lw/3p1/open_thread_january_2011/46qo?context=2\">blocked</a>, but not always; I haven't installed the relevant extensions on the system I'm on yet) draw me into interesting discussions, which frequently link back to other discussions, and so on.</p>\n<p>To limit how deep I get drawn in, I try to hold back from reflexively clicking links in comments and posts. Instead I just hover over them (or press and hold on a touchscreen) to view the address, hoping to get a general idea of what they're about and whether I'm familiar with them (and occasionally saving them to a <a href=\"/lw/332/mental_focus/2ymz\">folder</a> if I think I might want them later).</p>\n<p>Recently, though, I've noticed that LW is replacing off-site links with indirect links, passed through the domain api.viglink.com. This means I can't just glance at the URL to see where it points; I have to either open it or paste it into the address bar and scroll through it looking for the embedded URL of the actual link. Is it important for it to do that? Is there a way to turn that function off, or a browser extension (preferrably Android-compatible) to reverse it?</p>\n<p>(Initially posted about <a href=\"/lw/h7r/open_thread_april_1530_2013/8uis\">here</a> in the current open thread, but I decided I wanted it to be more visible.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "joDRvhGMBeAWAv4Hr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 9, "extendedScore": null, "score": 1.1815277795567936e-06, "legacy": true, "legacyId": "22434", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uFYQaGCRwt3wKtyZP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-27T15:34:57.764Z", "modifiedAt": null, "url": null, "title": "Are there good reasons to get into a PHD (i.e. in Philosophy)? And what to optimize for in such case?", "slug": "are-there-good-reasons-to-get-into-a-phd-i-e-in-philosophy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.332Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wJsrosiuHGdDxWEht/are-there-good-reasons-to-get-into-a-phd-i-e-in-philosophy", "pageUrlRelative": "/posts/wJsrosiuHGdDxWEht/are-there-good-reasons-to-get-into-a-phd-i-e-in-philosophy", "linkUrl": "https://www.lesswrong.com/posts/wJsrosiuHGdDxWEht/are-there-good-reasons-to-get-into-a-phd-i-e-in-philosophy", "postedAtFormatted": "Saturday, April 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Are%20there%20good%20reasons%20to%20get%20into%20a%20PHD%20(i.e.%20in%20Philosophy)%3F%20And%20what%20to%20optimize%20for%20in%20such%20case%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAre%20there%20good%20reasons%20to%20get%20into%20a%20PHD%20(i.e.%20in%20Philosophy)%3F%20And%20what%20to%20optimize%20for%20in%20such%20case%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJsrosiuHGdDxWEht%2Fare-there-good-reasons-to-get-into-a-phd-i-e-in-philosophy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Are%20there%20good%20reasons%20to%20get%20into%20a%20PHD%20(i.e.%20in%20Philosophy)%3F%20And%20what%20to%20optimize%20for%20in%20such%20case%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJsrosiuHGdDxWEht%2Fare-there-good-reasons-to-get-into-a-phd-i-e-in-philosophy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJsrosiuHGdDxWEht%2Fare-there-good-reasons-to-get-into-a-phd-i-e-in-philosophy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 268, "htmlBody": "<p>There are pretty strong reasons to <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">be wary</a> of academic philosophy. And the question here is whether there are good things to optimize for which come alongside a PHD generally, and also in particular in philosophy.&nbsp; So what to optimize for when pursuing a PHD?</p>\n<p>Some alternatives include:</p>\n<p>1) Smart students</p>\n<p>2) Excellent advisor (with the cost of very little time and attention for you)</p>\n<p>3) Young but still good advisor (no time-cost)</p>\n<p>4) Level of similarity between what you want to research, and what your prospective advisor researchers</p>\n<p>5) Freedom to do what you want in terms of directing your research</p>\n<p>6) Confortable physical environment (Campus with sports area, good weather, and comfy social areas, nice caf&eacute;'s to study)</p>\n<p>7) Good contacts - Whatever that means within philosophy PHD's</p>\n<p>8) Whatever works - meaning apply to all you can and think later, which implies that it is worth applying <em>because it gets you a phd</em>, not because of what it offers to you in other ways.</p>\n<p>9) Nothing to do with academia - in this case, once you guarantee you'll get your phd, you optimize for something else, like social environment, being New York, hot students, having a beach and hiking area, etc...</p>\n<p>&nbsp;</p>\n<p>Maybe some of these can be extended to pursuers of a PHD in other areas. Also, I'm assuming price is not a consideration (either all give you scholarships, or are free)</p>\n<p>It seems to me that education is one of the things that people are most irrational about, with a lot of people going the 8 route by default, not decision, for instance. And paying the cost (in motivation, success and happiness) later down the road.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wJsrosiuHGdDxWEht", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 3, "extendedScore": null, "score": 1.1816519237361458e-06, "legacy": true, "legacyId": "22436", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FwiPfF8Woe5JrzqEu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-27T18:30:02.865Z", "modifiedAt": null, "url": null, "title": "The Upward Scaling Importance of Rationality", "slug": "the-upward-scaling-importance-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:08.801Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alfredmacdonald", "createdAt": "2012-12-15T06:51:20.080Z", "isAdmin": false, "displayName": "alfredmacdonald"}, "userId": "5LFCG3XEhArezJGXE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7QFAH9mCsEENRDLzp/the-upward-scaling-importance-of-rationality", "pageUrlRelative": "/posts/7QFAH9mCsEENRDLzp/the-upward-scaling-importance-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/7QFAH9mCsEENRDLzp/the-upward-scaling-importance-of-rationality", "postedAtFormatted": "Saturday, April 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Upward%20Scaling%20Importance%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Upward%20Scaling%20Importance%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7QFAH9mCsEENRDLzp%2Fthe-upward-scaling-importance-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Upward%20Scaling%20Importance%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7QFAH9mCsEENRDLzp%2Fthe-upward-scaling-importance-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7QFAH9mCsEENRDLzp%2Fthe-upward-scaling-importance-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<p>I've read about a quarter of the sequences, but I'm not sure if this topic has been addressed on LessWrong before. If it has, let me know.</p>\n<p>The Upward Scaling Importance of Rationality goes like this:</p>\n<p>The more influence your thought process and decisions have, the more important it is that you're rationalist. In the grand scheme of things, it is relatively unimportant that a barback at a restaurant is a rationalist, and I say this having done that. It is <em>extremely</em>&nbsp;important that a leader of a highly influential company, or a president of a university or country is a rationalist. Their decisions affect thousands if not millions of people.</p>\n<p>The more influential you are, the more your decisions have potential to screw over other people. Influence doesn't necessarily have to be in a management position: elementary school teachers and police officers are highly influential, even though they aren't in control of an organization. Influence can even be by virtue of the people you reach out to. A famous person with a large fanbase or a parent of a child prodigy, both have the capacity to influence the world with their decisions.</p>\n<p>Though arguably, this can &nbsp;be extended to anyone who votes.</p>\n<p>So rationality scales upward: the more influential someone is, the more important is it they're rationalists. Neglecting this can have bad consequences.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7QFAH9mCsEENRDLzp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 11, "extendedScore": null, "score": 1.1817755035039876e-06, "legacy": true, "legacyId": "22437", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-28T02:53:18.335Z", "modifiedAt": null, "url": null, "title": "Three more ways identity can be a curse", "slug": "three-more-ways-identity-can-be-a-curse", "viewCount": null, "lastCommentedAt": "2021-09-14T11:06:04.629Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gothgirl420666", "createdAt": "2013-01-06T19:35:18.030Z", "isAdmin": false, "displayName": "gothgirl420666"}, "userId": "P7J37T964Pxizzp9g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eZTTtCSCw9ixEEYw2/three-more-ways-identity-can-be-a-curse", "pageUrlRelative": "/posts/eZTTtCSCw9ixEEYw2/three-more-ways-identity-can-be-a-curse", "linkUrl": "https://www.lesswrong.com/posts/eZTTtCSCw9ixEEYw2/three-more-ways-identity-can-be-a-curse", "postedAtFormatted": "Sunday, April 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Three%20more%20ways%20identity%20can%20be%20a%20curse&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThree%20more%20ways%20identity%20can%20be%20a%20curse%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeZTTtCSCw9ixEEYw2%2Fthree-more-ways-identity-can-be-a-curse%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Three%20more%20ways%20identity%20can%20be%20a%20curse%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeZTTtCSCw9ixEEYw2%2Fthree-more-ways-identity-can-be-a-curse", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeZTTtCSCw9ixEEYw2%2Fthree-more-ways-identity-can-be-a-curse", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3391, "htmlBody": "<p>The Buddhists believe that one of the three keys to attaining true happiness is dissolving the illusion of the self. (The other two are dissolving the illusion of permanence, and ceasing the desire that leads to suffering.) I'm not really sure exactly what it means to say \"the self is an illusion\", and I'm not exactly sure how that will lead to enlightenment, but I do think one can easily take the first step on this long journey to happiness by beginning to dissolve the sense of one's <em>identity.&nbsp;</em></p>\n<p>Previously, in <a href=\"http://www.paulgraham.com/identity.html\">\"Keep Your Identity Small\"</a>, Paul Graham showed how a strong sense of identity can lead to epistemic irrationally, when someone refuses to accept evidence against x because \"someone who believes x\" is part of his or her identity. And in Kaj Sotala's <a href=\"/lw/8gv/the_curse_of_identity/\">\"The Curse of Identity\"</a>, he illustrated a human tendency to reinterpret a goal of \"do x\" as \"give the impression of being someone who does x\". These are both fantastic posts, and you should read them if you haven't already.&nbsp;</p>\n<p>Here are three more ways in which identity can be a curse.</p>\n<p><strong>1. Don't be afraid to change</strong></p>\n<p>James March, professor of political science at Stanford University, says that when people make choices, they tend to use one of two basic models of decision making: the consequences model, or the identity model. In the consequences model, we weigh the costs and benefits of our options and make the choice that maximizes our satisfaction. In the identity model, we ask ourselves \"What would a person like me do in this situation?\"<sup>1</sup></p>\n<p>The author of the book I read this in didn't seem to take the obvious next step and acknowledge that the consequences model is clearly The Correct Way to Make Decisions and basically by definition, if you're using the identity model and it's giving you a different result then the consequences model would, you're being led astray. A heuristic I like to use is to limit my identity to the \"observer\" part of my brain, and make my only goal maximizing the amount of happiness and pleasure the observer experiences, and minimizing the amount of misfortune and pain. It sounds obvious when you lay it out in these terms, but let me give an example.&nbsp;</p>\n<p>Alice is a incoming freshman in college trying to choose her major. In Hypothetical University, there are only two majors: English, and business. Alice absolutely adores literature, and thinks business is dreadfully boring. Becoming an English major would allow her to have a career working with something she's passionate about, which is worth 2 megautilons to her, but it would also make her poor (0 mu). Becoming a business major would mean working in a field she is not passionate about (0 mu), but it would also make her rich, which is worth 1 megautilon. So English, with 2 mu, wins out over business, with 1 mu.</p>\n<p>However, Alice is very bright, and is the type of person who can adapt herself to many situations and learn skills quickly. If Alice were to spend the first six months of college deeply immersing herself in studying business, she would probably start developing a passion for business. If she purposefully exposed herself to certain pro-business memeplexes (e.g. watched a movie glamorizing the life of Wall Street bankers), then she could speed up this process even further. After a few years of taking business classes, she would probably begin to forget what about English literature was so appealing to her, and be extremely grateful that she made the decision she did. Therefore she would gain the same 2 mu from having a job she is passionate about, along with an additional 1 mu from being rich, meaning that the 3 mu choice of business wins out over the 2 mu choice of English.</p>\n<p>However, the possibility of self-modifying to becoming someone who finds English literature boring and business interesting is very disturbing to Alice. She sees it as a betrayal of everything that she is, even though she's actually only been interested in English literature for a few years. Perhaps she thinks of choosing business as \"selling out\" or \"giving in\". Therefore she decides to major in English, and takes the 2 mu choice instead of the superior 3 mu.</p>\n<p>(Obviously this is a hypothetical example/oversimplification and there are a lot of reasons why it might be rational to pursue a career path that doesn't make very much money.)</p>\n<p>It seems to me like human beings have a bizarre tendency to want to keep certain attributes and character traits stagnant, even when doing so provides no advantage, or is actively harmful. In a world where business-passionate people systematically do better than English-passionate people, it makes sense to self-modify to become business-passionate. Yet this is often distasteful.</p>\n<p>For example, until a few weeks ago when I started solidifying this thinking pattern, I had an extremely adverse reaction to the idea of ceasing to be a hip-hop fan and becoming a fan of more \"sophisticated\" musical genres like jazz and classical, eventually coming to look down on the music I currently listen to as primitive or silly. This doesn't really make sense - I'm sure if I were to become a jazz and classical fan I would enjoy those genres at least as much as I currently enjoy hip hop. And yet I had a very strong preference to remain the same, even in the trivial realm of music taste.&nbsp;</p>\n<p>Probably the most extreme example is the common tendency for depressed people to not actually want to get better, because depression has become such a core part of their identity that the idea of becoming a healthy, happy person is disturbing to them. (I used to struggle with this myself, in fact.) Being depressed is probably the most obviously harmful characteristic that someone can have, and yet many people resist self-modification.</p>\n<p>Of course, the obvious objection is there's no way to rationally object to people's preferences - if someone truly prioritizes keeping their identity stagnant over not being depressed then there's no way to tell them they're wrong, just like if someone prioritizes paperclips over happiness there's no way to tell them they're wrong. But if you're like me, and you <em>are </em>interested in being happy, then I recommend looking out for this cognitive bias.&nbsp;</p>\n<p>The other objection is that this philosophy leads to extremely unsavory wireheading-esque scenarios if you take it to its logical conclusion. But holding the opposite belief - that it's always more important to keep your characteristics stagnant than to be happy - clearly leads to even more absurd conclusions. So there is probably some point on the spectrum where change is so distasteful that it's not worth a boost in happiness (e.g. a lobotomy or something similar). However, I think that in actual practical pre-Singularity life, most people set this point far, far too low.&nbsp;</p>\n<p><strong>2. The hidden meaning of \"be yourself\"</strong></p>\n<p>(This section is entirely my own speculation, so take it as you will.)</p>\n<p>\"Be yourself\" is probably the most widely-repeated piece of social skills advice despite being pretty clearly useless - if it worked then no one would be socially awkward, because everyone has heard this advice.&nbsp;</p>\n<p>However, there must be some sort of core grain of truth in this statement, or else it wouldn't be so widely repeated. I think that core grain is basically the point I just made, applied to social interaction. I.e, optimize always for social success and positive relationships (particularly in the moment), and not for signalling a certain identity.&nbsp;</p>\n<p>The ostensible purpose of identity/signalling is to appear to be a certain type of person, so that people will like and respect you, which is in turn so that people will want to be around you and be more likely to do stuff for you. However, oftentimes this goes horribly wrong, and people become very devoted to cultivating certain identities that are actively harmful for this purpose, e.g. goth, juggalo, \"cool reserved aloof loner\", guy that won't shut up about politics, etc. A more subtle example is Fred, who holds the wall and refuses to dance at a nightclub because he is a serious, dignified sort of guy, and doesn't want to look silly. However, the reason why \"looking silly\" is generally a bad thing is because it makes people lose respect for you, and therefore make them less likely to associate with you. In the situation Fred is in, holding the wall and looking serious will cause no one to associate with him, but if he dances and mingles with strangers and looks silly, people will be likely to associate with him. So unless he's afraid of looking silly in the eyes of God, this seems to be irrational.</p>\n<p>Probably more common is the tendency to go to great care to cultivate identities that are neither harmful nor beneficial. E.g. \"deep philosophical thinker\", \"Grateful Dead fan\", \"tough guy\", \"nature lover\", \"rationalist\", etc. Boring Bob is a guy who wears a blue polo shirt and khakis every day, works as hard as expected but no harder in his job as an accountant, holds no political views, and when he goes home he relaxes by watching whatever's on TV and reading the paper. Boring Bob would probably improve his chances of social success by cultivating a more interesting identity, perhaps by changing his wardrobe, hobbies, and viewpoints, and then liberally signalling this new identity. However, most of us are not Boring Bob, and a much better social success strategy for most of us is probably to smile more, improve our posture and body language, be more open and accepting of other people, learn how to make better small talk, etc. But most people fail to realize this and instead play elaborate signalling games in order to improve their status, sometimes even at the expense of lots of time and money.</p>\n<p>Some ways by which people can fail to \"be themselves\" in individual social interactions: liberally sprinkle references to certain attributes that they want to emphasize, say nonsensical and surreal things in order to seem quirky, be afraid to give obvious responses to questions in order to seem more interesting, insert forced \"cool\" actions into their mannerisms, act underwhelmed by what the other person is saying in order to seem jaded and superior, etc. Whereas someone who is \"being herself\" is more interested in creating rapport with the other person than giving off a certain impression of herself. &nbsp;</p>\n<p>Additionally, optimizing for a particular identity might not only be counterproductive - it might actually be a quick way to get people to <em>despise </em>you.&nbsp;</p>\n<p>I used to not understand why certain \"types\" of people, such as \"hipsters\"<sup>2</sup> or Ed Hardy and Affliction-wearing \"douchebags\" are so universally loathed (especially on the internet). Yes, these people are adopting certain styles in order to be cool and interesting, but isn't everyone doing the same? No one looks through their wardrobe and says \"hmm, I'll wear this sweater because it makes me uncool, and it'll make people not like me\". Perhaps hipsters and Ed Hardy Guys fail in their mission to be cool, but should we really hate them for this? If being a hipster was cool two years ago, and being someone who wears normal clothes, acts normal, and doesn't do anything \"ironically\" is cool today, then we're really just hating people for failing to keep up with the trends. And if being a hipster actually <em>is </em>cool, then, well, who can fault them for choosing to be one?</p>\n<p>That was my old thought process. Now it is clear to me that what makes hipsters and Ed Hardy Guys hated is that they aren't \"being themselves\" - they are much more interested in cultivating an identity of interestingness and masculinity, respectively, than connecting with other people. The same thing goes for pretty much every other collectively hated stereotype I can think of<sup>3</sup> - people who loudly express political opinions, stoners who won't stop talking about smoking weed, attention seeking teenage girls on facebook, extremely flamboyantly gay guys, \"weeaboos\", hippies and new age types, 2005 \"emo kids\", overly politically correct people, tumblr SJA weirdos who identify as otherkin and whatnot, overly patriotic \"rednecks\", the list goes on and on.&nbsp;</p>\n<p>This also clears up a confusion that occurred to me when reading How to Win Friends and Influence People. I know people who have a Dale Carnegie mindset of being optimistic and nice to everyone they meet and are adored for it, but I also know people who have the same attitude and yet are considered irritatingly saccharine and would probably do better to \"keep it real\" a little. So what's the difference? I think the difference is that the former group are genuinely interested in being nice to people and building rapport, while members of the second group have made an error like the one described in Kaj Sotala's post and are merely trying to give off the <em>impression </em>of being a nice and friendly person. The distinction is obviously very subtle, but it's one that humans are apparently very good at perceiving.&nbsp;</p>\n<p>I'm not exactly sure what it is that causes humans to have this tendency of hating people who are clearly optimizing for identity - it's not as if they harm anyone. It probably has to do with tribal status. But what is clear is that you should definitely not be one of them.&nbsp;</p>\n<p><strong>3. The worst mistake you can possibly make in combating akrasia</strong></p>\n<p>The main thesis of <a href=\"http://thinkingthingsdone.com/\">PJ Eby's Thinking Things Done</a> is that the primary reason why people are incapable of being productive is that they use negative motivation (\"if I don't do x, some negative y will happen\") as opposed to positive motivation (\"if i do x, some positive y will happen\"). He has the following evo-psych explanation for this: in the ancestral environment, personal failure meant that you could possibly be kicked out of your tribe, which would be fatal. A lot of depressed people make statements like \"I'm worthless\", or \"I'm scum\" or \"No one could ever love me\", which are illogically dramatic and overly black and white, until you realize that these statements are merely interpretations of a feeling of \"I'm about to get kicked out of the tribe, and therefore die.\" Animals have a freezing response to imminent death, so if you are fearing failure you will go into do-nothing mode and not be able to work at all.<sup>4</sup></p>\n<p>In Succeed: How We Can Reach Our Goals, Phd psychologist Heidi Halvorson takes a different view and describes positive motivation and negative motivation as having pros and cons. However, she has her own dichotomy of Good Motivation and Bad Motivation: \"Be good\" goals are performance goals, and are directed at achieving a particular outcome, like getting an A on a test, reaching a sales target, getting your attractive neighbor to go out with you, or getting into law school. They are very often tied closely to a sense of self-worth. \"Get better\" goals are mastery goals, and people who pick these goals judge themselves instead in terms of the progress they are making, asking questions like \"Am I improving? Am I learning? Am I moving forward at a good pace?\" Halvorson argues that \"get better\" goals are almost always drastically better than \"be good\" goals<sup>5</sup>. An example quote (from page 60) is:</p>\n<blockquote>\n<p>When my goal is to get an A in a class and prove that I'm smart, and I take the first exam and I <em>don't</em>&nbsp;get an A... well, then I really can't help but think that maybe I'm not so smart, right? Concluding \"maybe I'm not smart\" has several consequences and none of them are good. First, I'm going to feel terrible - probably anxious and depressed, possibly embarrassed or ashamed. My sense of self-worth and self-esteem are going to suffer. My confidence will be shaken, if not completely shattered. And if I'm not smart enough, there's really no point in continuing to try to do well, so I'll probably just give up and not bother working so hard on the remaining exams.&nbsp;</p>\n</blockquote>\n<p>And finally, in Feeling Good: The New Mood Therapy, David Burns describes a destructive side effect of depression he calls \"do-nothingism\":</p>\n<blockquote>\n<p>One of the most destructive aspects of depression is the way it paralyzes your willpower. In its mildest form you may simply procrastinate about doing a few odious chores. As your lack of motivation increases, virtually any activity appears so difficult that you become overwhelmed by the urge to do nothing. Because you accomplish very little, you feel worse and worse. Not only do you cut yourself off from your normal sources of stimulation and pleasure, but your lack of productivity aggravates your self-hatred, resulting in further isolation and incapacitation.</p>\n</blockquote>\n<p>Synthesizing these three pieces of information leads me to believe that the <em>worst thing you can possibly do for your akrasia</em> is to tie your success and productivity to your sense of identity/self-worth, especially if you're using negative motivation to do so, and <em>especially </em>if you suffer or have recently suffered from depression or low-self esteem. The thought of having a negative self-image is scary and unpleasant, perhaps for the evo-psych reasons PJ Eby outlines. If you tie your productivity to your fear of a negative self-image, working will become scary and unpleasant as well, and you won't want to do it.</p>\n<p>I feel like this might be the single number one reason why people are akratic. It might be a little premature to say that, and I might be biased by how large of a factor this mistake was in my own akrasia. But unfortunately, this trap seems like a very easy one to fall into. If you're someone who is lazy and isn't accomplishing much in life, perhaps depressed, then it makes intuitive sense to motivate yourself by saying \"Come on, self! Do you want to be a useless failure in life? No? Well get going then!\" But doing so will accomplish the exact opposite and make you feel miserable.&nbsp;</p>\n<p>So there you have it. In addition to making you a bad rationalist and causing you to lose sight of your goals, a strong sense of identity will cause you to make poor decisions that lead to unhappiness, be unpopular, and be unsuccessful. I think the Buddhists were onto something with this one, personally, and I try to limit my sense of identity as much as possible. A trick you can use in addition to the \"be the observer\" trick I mentioned, is to whenever you find yourself thinking in identity terms, swap out that identity for the identity of \"person who takes over the world by transcending the need for a sense of identity\".&nbsp;</p>\n<hr />\n<p><em>This is my first LessWrong discussion post, so constructive criticism is greatly appreciated. Was this informative? Or was what I said obvious, and I'm retreading old ground? Was this well written? Should this have been posted to Main? Should this not have been posted at all? Thank you.&nbsp;</em></p>\n<hr />\n<p>1. Paraphrased from page 153 of Switch: How to Change When Change is Hard</p>\n<p>2. Actually, while it works for this example, I think the stereotypical \"hipster\" is a bizarre caricature that doesn't match anyone who actually exists in real life, and the degree to which people will rabidly espouse hatred for this stereotypical figure (or used to two or three years ago) is one of the most bizarre tendencies people have.&nbsp;</p>\n<p>3. Other than groups that arguably hurt people (religious fundamentalists, PUAs), the only exception I can think of is frat boy/jock types. They talk about drinking and partying a lot, sure, but not really any more than people who drink and party a lot would be expected to. Possibilities for their hated status include that they do in fact engage in obnoxious signalling and I'm not aware of it, jealousy, or stigmatization as hazers and date rapists. Also, a lot of people hate stereotypical \"ghetto\" black people who sag their jeans and notoriously type in a broken, difficult-to-read form of English. This could either be a weak example of the trend (I'm not really sure what it is they would be signalling, maybe dangerous-ness?), or just a manifestation of racism.</p>\n<p>4. I'm not sure if this is valid science that he pulled from some other source, or if he just made this up.</p>\n<div>5. The exception is that \"be good\" goals can lead to a very high level of performance when the task is easy.&nbsp;</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"x6evH6MyPK3nxsoff": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eZTTtCSCw9ixEEYw2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 67, "extendedScore": null, "score": 0.000161, "legacy": true, "legacyId": "22435", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>The Buddhists believe that one of the three keys to attaining true happiness is dissolving the illusion of the self. (The other two are dissolving the illusion of permanence, and ceasing the desire that leads to suffering.) I'm not really sure exactly what it means to say \"the self is an illusion\", and I'm not exactly sure how that will lead to enlightenment, but I do think one can easily take the first step on this long journey to happiness by beginning to dissolve the sense of one's <em>identity.&nbsp;</em></p>\n<p>Previously, in <a href=\"http://www.paulgraham.com/identity.html\">\"Keep Your Identity Small\"</a>, Paul Graham showed how a strong sense of identity can lead to epistemic irrationally, when someone refuses to accept evidence against x because \"someone who believes x\" is part of his or her identity. And in Kaj Sotala's <a href=\"/lw/8gv/the_curse_of_identity/\">\"The Curse of Identity\"</a>, he illustrated a human tendency to reinterpret a goal of \"do x\" as \"give the impression of being someone who does x\". These are both fantastic posts, and you should read them if you haven't already.&nbsp;</p>\n<p>Here are three more ways in which identity can be a curse.</p>\n<p><strong id=\"1__Don_t_be_afraid_to_change\">1. Don't be afraid to change</strong></p>\n<p>James March, professor of political science at Stanford University, says that when people make choices, they tend to use one of two basic models of decision making: the consequences model, or the identity model. In the consequences model, we weigh the costs and benefits of our options and make the choice that maximizes our satisfaction. In the identity model, we ask ourselves \"What would a person like me do in this situation?\"<sup>1</sup></p>\n<p>The author of the book I read this in didn't seem to take the obvious next step and acknowledge that the consequences model is clearly The Correct Way to Make Decisions and basically by definition, if you're using the identity model and it's giving you a different result then the consequences model would, you're being led astray. A heuristic I like to use is to limit my identity to the \"observer\" part of my brain, and make my only goal maximizing the amount of happiness and pleasure the observer experiences, and minimizing the amount of misfortune and pain. It sounds obvious when you lay it out in these terms, but let me give an example.&nbsp;</p>\n<p>Alice is a incoming freshman in college trying to choose her major. In Hypothetical University, there are only two majors: English, and business. Alice absolutely adores literature, and thinks business is dreadfully boring. Becoming an English major would allow her to have a career working with something she's passionate about, which is worth 2 megautilons to her, but it would also make her poor (0 mu). Becoming a business major would mean working in a field she is not passionate about (0 mu), but it would also make her rich, which is worth 1 megautilon. So English, with 2 mu, wins out over business, with 1 mu.</p>\n<p>However, Alice is very bright, and is the type of person who can adapt herself to many situations and learn skills quickly. If Alice were to spend the first six months of college deeply immersing herself in studying business, she would probably start developing a passion for business. If she purposefully exposed herself to certain pro-business memeplexes (e.g. watched a movie glamorizing the life of Wall Street bankers), then she could speed up this process even further. After a few years of taking business classes, she would probably begin to forget what about English literature was so appealing to her, and be extremely grateful that she made the decision she did. Therefore she would gain the same 2 mu from having a job she is passionate about, along with an additional 1 mu from being rich, meaning that the 3 mu choice of business wins out over the 2 mu choice of English.</p>\n<p>However, the possibility of self-modifying to becoming someone who finds English literature boring and business interesting is very disturbing to Alice. She sees it as a betrayal of everything that she is, even though she's actually only been interested in English literature for a few years. Perhaps she thinks of choosing business as \"selling out\" or \"giving in\". Therefore she decides to major in English, and takes the 2 mu choice instead of the superior 3 mu.</p>\n<p>(Obviously this is a hypothetical example/oversimplification and there are a lot of reasons why it might be rational to pursue a career path that doesn't make very much money.)</p>\n<p>It seems to me like human beings have a bizarre tendency to want to keep certain attributes and character traits stagnant, even when doing so provides no advantage, or is actively harmful. In a world where business-passionate people systematically do better than English-passionate people, it makes sense to self-modify to become business-passionate. Yet this is often distasteful.</p>\n<p>For example, until a few weeks ago when I started solidifying this thinking pattern, I had an extremely adverse reaction to the idea of ceasing to be a hip-hop fan and becoming a fan of more \"sophisticated\" musical genres like jazz and classical, eventually coming to look down on the music I currently listen to as primitive or silly. This doesn't really make sense - I'm sure if I were to become a jazz and classical fan I would enjoy those genres at least as much as I currently enjoy hip hop. And yet I had a very strong preference to remain the same, even in the trivial realm of music taste.&nbsp;</p>\n<p>Probably the most extreme example is the common tendency for depressed people to not actually want to get better, because depression has become such a core part of their identity that the idea of becoming a healthy, happy person is disturbing to them. (I used to struggle with this myself, in fact.) Being depressed is probably the most obviously harmful characteristic that someone can have, and yet many people resist self-modification.</p>\n<p>Of course, the obvious objection is there's no way to rationally object to people's preferences - if someone truly prioritizes keeping their identity stagnant over not being depressed then there's no way to tell them they're wrong, just like if someone prioritizes paperclips over happiness there's no way to tell them they're wrong. But if you're like me, and you <em>are </em>interested in being happy, then I recommend looking out for this cognitive bias.&nbsp;</p>\n<p>The other objection is that this philosophy leads to extremely unsavory wireheading-esque scenarios if you take it to its logical conclusion. But holding the opposite belief - that it's always more important to keep your characteristics stagnant than to be happy - clearly leads to even more absurd conclusions. So there is probably some point on the spectrum where change is so distasteful that it's not worth a boost in happiness (e.g. a lobotomy or something similar). However, I think that in actual practical pre-Singularity life, most people set this point far, far too low.&nbsp;</p>\n<p><strong id=\"2__The_hidden_meaning_of__be_yourself_\">2. The hidden meaning of \"be yourself\"</strong></p>\n<p>(This section is entirely my own speculation, so take it as you will.)</p>\n<p>\"Be yourself\" is probably the most widely-repeated piece of social skills advice despite being pretty clearly useless - if it worked then no one would be socially awkward, because everyone has heard this advice.&nbsp;</p>\n<p>However, there must be some sort of core grain of truth in this statement, or else it wouldn't be so widely repeated. I think that core grain is basically the point I just made, applied to social interaction. I.e, optimize always for social success and positive relationships (particularly in the moment), and not for signalling a certain identity.&nbsp;</p>\n<p>The ostensible purpose of identity/signalling is to appear to be a certain type of person, so that people will like and respect you, which is in turn so that people will want to be around you and be more likely to do stuff for you. However, oftentimes this goes horribly wrong, and people become very devoted to cultivating certain identities that are actively harmful for this purpose, e.g. goth, juggalo, \"cool reserved aloof loner\", guy that won't shut up about politics, etc. A more subtle example is Fred, who holds the wall and refuses to dance at a nightclub because he is a serious, dignified sort of guy, and doesn't want to look silly. However, the reason why \"looking silly\" is generally a bad thing is because it makes people lose respect for you, and therefore make them less likely to associate with you. In the situation Fred is in, holding the wall and looking serious will cause no one to associate with him, but if he dances and mingles with strangers and looks silly, people will be likely to associate with him. So unless he's afraid of looking silly in the eyes of God, this seems to be irrational.</p>\n<p>Probably more common is the tendency to go to great care to cultivate identities that are neither harmful nor beneficial. E.g. \"deep philosophical thinker\", \"Grateful Dead fan\", \"tough guy\", \"nature lover\", \"rationalist\", etc. Boring Bob is a guy who wears a blue polo shirt and khakis every day, works as hard as expected but no harder in his job as an accountant, holds no political views, and when he goes home he relaxes by watching whatever's on TV and reading the paper. Boring Bob would probably improve his chances of social success by cultivating a more interesting identity, perhaps by changing his wardrobe, hobbies, and viewpoints, and then liberally signalling this new identity. However, most of us are not Boring Bob, and a much better social success strategy for most of us is probably to smile more, improve our posture and body language, be more open and accepting of other people, learn how to make better small talk, etc. But most people fail to realize this and instead play elaborate signalling games in order to improve their status, sometimes even at the expense of lots of time and money.</p>\n<p>Some ways by which people can fail to \"be themselves\" in individual social interactions: liberally sprinkle references to certain attributes that they want to emphasize, say nonsensical and surreal things in order to seem quirky, be afraid to give obvious responses to questions in order to seem more interesting, insert forced \"cool\" actions into their mannerisms, act underwhelmed by what the other person is saying in order to seem jaded and superior, etc. Whereas someone who is \"being herself\" is more interested in creating rapport with the other person than giving off a certain impression of herself. &nbsp;</p>\n<p>Additionally, optimizing for a particular identity might not only be counterproductive - it might actually be a quick way to get people to <em>despise </em>you.&nbsp;</p>\n<p>I used to not understand why certain \"types\" of people, such as \"hipsters\"<sup>2</sup> or Ed Hardy and Affliction-wearing \"douchebags\" are so universally loathed (especially on the internet). Yes, these people are adopting certain styles in order to be cool and interesting, but isn't everyone doing the same? No one looks through their wardrobe and says \"hmm, I'll wear this sweater because it makes me uncool, and it'll make people not like me\". Perhaps hipsters and Ed Hardy Guys fail in their mission to be cool, but should we really hate them for this? If being a hipster was cool two years ago, and being someone who wears normal clothes, acts normal, and doesn't do anything \"ironically\" is cool today, then we're really just hating people for failing to keep up with the trends. And if being a hipster actually <em>is </em>cool, then, well, who can fault them for choosing to be one?</p>\n<p>That was my old thought process. Now it is clear to me that what makes hipsters and Ed Hardy Guys hated is that they aren't \"being themselves\" - they are much more interested in cultivating an identity of interestingness and masculinity, respectively, than connecting with other people. The same thing goes for pretty much every other collectively hated stereotype I can think of<sup>3</sup> - people who loudly express political opinions, stoners who won't stop talking about smoking weed, attention seeking teenage girls on facebook, extremely flamboyantly gay guys, \"weeaboos\", hippies and new age types, 2005 \"emo kids\", overly politically correct people, tumblr SJA weirdos who identify as otherkin and whatnot, overly patriotic \"rednecks\", the list goes on and on.&nbsp;</p>\n<p>This also clears up a confusion that occurred to me when reading How to Win Friends and Influence People. I know people who have a Dale Carnegie mindset of being optimistic and nice to everyone they meet and are adored for it, but I also know people who have the same attitude and yet are considered irritatingly saccharine and would probably do better to \"keep it real\" a little. So what's the difference? I think the difference is that the former group are genuinely interested in being nice to people and building rapport, while members of the second group have made an error like the one described in Kaj Sotala's post and are merely trying to give off the <em>impression </em>of being a nice and friendly person. The distinction is obviously very subtle, but it's one that humans are apparently very good at perceiving.&nbsp;</p>\n<p>I'm not exactly sure what it is that causes humans to have this tendency of hating people who are clearly optimizing for identity - it's not as if they harm anyone. It probably has to do with tribal status. But what is clear is that you should definitely not be one of them.&nbsp;</p>\n<p><strong id=\"3__The_worst_mistake_you_can_possibly_make_in_combating_akrasia\">3. The worst mistake you can possibly make in combating akrasia</strong></p>\n<p>The main thesis of <a href=\"http://thinkingthingsdone.com/\">PJ Eby's Thinking Things Done</a> is that the primary reason why people are incapable of being productive is that they use negative motivation (\"if I don't do x, some negative y will happen\") as opposed to positive motivation (\"if i do x, some positive y will happen\"). He has the following evo-psych explanation for this: in the ancestral environment, personal failure meant that you could possibly be kicked out of your tribe, which would be fatal. A lot of depressed people make statements like \"I'm worthless\", or \"I'm scum\" or \"No one could ever love me\", which are illogically dramatic and overly black and white, until you realize that these statements are merely interpretations of a feeling of \"I'm about to get kicked out of the tribe, and therefore die.\" Animals have a freezing response to imminent death, so if you are fearing failure you will go into do-nothing mode and not be able to work at all.<sup>4</sup></p>\n<p>In Succeed: How We Can Reach Our Goals, Phd psychologist Heidi Halvorson takes a different view and describes positive motivation and negative motivation as having pros and cons. However, she has her own dichotomy of Good Motivation and Bad Motivation: \"Be good\" goals are performance goals, and are directed at achieving a particular outcome, like getting an A on a test, reaching a sales target, getting your attractive neighbor to go out with you, or getting into law school. They are very often tied closely to a sense of self-worth. \"Get better\" goals are mastery goals, and people who pick these goals judge themselves instead in terms of the progress they are making, asking questions like \"Am I improving? Am I learning? Am I moving forward at a good pace?\" Halvorson argues that \"get better\" goals are almost always drastically better than \"be good\" goals<sup>5</sup>. An example quote (from page 60) is:</p>\n<blockquote>\n<p>When my goal is to get an A in a class and prove that I'm smart, and I take the first exam and I <em>don't</em>&nbsp;get an A... well, then I really can't help but think that maybe I'm not so smart, right? Concluding \"maybe I'm not smart\" has several consequences and none of them are good. First, I'm going to feel terrible - probably anxious and depressed, possibly embarrassed or ashamed. My sense of self-worth and self-esteem are going to suffer. My confidence will be shaken, if not completely shattered. And if I'm not smart enough, there's really no point in continuing to try to do well, so I'll probably just give up and not bother working so hard on the remaining exams.&nbsp;</p>\n</blockquote>\n<p>And finally, in Feeling Good: The New Mood Therapy, David Burns describes a destructive side effect of depression he calls \"do-nothingism\":</p>\n<blockquote>\n<p>One of the most destructive aspects of depression is the way it paralyzes your willpower. In its mildest form you may simply procrastinate about doing a few odious chores. As your lack of motivation increases, virtually any activity appears so difficult that you become overwhelmed by the urge to do nothing. Because you accomplish very little, you feel worse and worse. Not only do you cut yourself off from your normal sources of stimulation and pleasure, but your lack of productivity aggravates your self-hatred, resulting in further isolation and incapacitation.</p>\n</blockquote>\n<p>Synthesizing these three pieces of information leads me to believe that the <em>worst thing you can possibly do for your akrasia</em> is to tie your success and productivity to your sense of identity/self-worth, especially if you're using negative motivation to do so, and <em>especially </em>if you suffer or have recently suffered from depression or low-self esteem. The thought of having a negative self-image is scary and unpleasant, perhaps for the evo-psych reasons PJ Eby outlines. If you tie your productivity to your fear of a negative self-image, working will become scary and unpleasant as well, and you won't want to do it.</p>\n<p>I feel like this might be the single number one reason why people are akratic. It might be a little premature to say that, and I might be biased by how large of a factor this mistake was in my own akrasia. But unfortunately, this trap seems like a very easy one to fall into. If you're someone who is lazy and isn't accomplishing much in life, perhaps depressed, then it makes intuitive sense to motivate yourself by saying \"Come on, self! Do you want to be a useless failure in life? No? Well get going then!\" But doing so will accomplish the exact opposite and make you feel miserable.&nbsp;</p>\n<p>So there you have it. In addition to making you a bad rationalist and causing you to lose sight of your goals, a strong sense of identity will cause you to make poor decisions that lead to unhappiness, be unpopular, and be unsuccessful. I think the Buddhists were onto something with this one, personally, and I try to limit my sense of identity as much as possible. A trick you can use in addition to the \"be the observer\" trick I mentioned, is to whenever you find yourself thinking in identity terms, swap out that identity for the identity of \"person who takes over the world by transcending the need for a sense of identity\".&nbsp;</p>\n<hr>\n<p><em>This is my first LessWrong discussion post, so constructive criticism is greatly appreciated. Was this informative? Or was what I said obvious, and I'm retreading old ground? Was this well written? Should this have been posted to Main? Should this not have been posted at all? Thank you.&nbsp;</em></p>\n<hr>\n<p>1. Paraphrased from page 153 of Switch: How to Change When Change is Hard</p>\n<p>2. Actually, while it works for this example, I think the stereotypical \"hipster\" is a bizarre caricature that doesn't match anyone who actually exists in real life, and the degree to which people will rabidly espouse hatred for this stereotypical figure (or used to two or three years ago) is one of the most bizarre tendencies people have.&nbsp;</p>\n<p>3. Other than groups that arguably hurt people (religious fundamentalists, PUAs), the only exception I can think of is frat boy/jock types. They talk about drinking and partying a lot, sure, but not really any more than people who drink and party a lot would be expected to. Possibilities for their hated status include that they do in fact engage in obnoxious signalling and I'm not aware of it, jealousy, or stigmatization as hazers and date rapists. Also, a lot of people hate stereotypical \"ghetto\" black people who sag their jeans and notoriously type in a broken, difficult-to-read form of English. This could either be a weak example of the trend (I'm not really sure what it is they would be signalling, maybe dangerous-ness?), or just a manifestation of racism.</p>\n<p>4. I'm not sure if this is valid science that he pulled from some other source, or if he just made this up.</p>\n<div>5. The exception is that \"be good\" goals can lead to a very high level of performance when the task is easy.&nbsp;</div>\n<p>&nbsp;</p>", "sections": [{"title": "1. Don't be afraid to change", "anchor": "1__Don_t_be_afraid_to_change", "level": 1}, {"title": "2. The hidden meaning of \"be yourself\"", "anchor": "2__The_hidden_meaning_of__be_yourself_", "level": 1}, {"title": "3. The worst mistake you can possibly make in combating akrasia", "anchor": "3__The_worst_mistake_you_can_possibly_make_in_combating_akrasia", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "105 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 105, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tAXrD8Y6hcJ8dt6Nt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-28T05:28:25.755Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.", "slug": "meetup-atlanta-lesswrong-s-may-meetup-the-rationality-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:30.263Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nova_Division", "createdAt": "2011-03-14T15:21:15.124Z", "isAdmin": false, "displayName": "Nova_Division"}, "userId": "eFXLR4aNaxDBCDatT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/r46gPJif9gcEy7Nm5/meetup-atlanta-lesswrong-s-may-meetup-the-rationality-of", "pageUrlRelative": "/posts/r46gPJif9gcEy7Nm5/meetup-atlanta-lesswrong-s-may-meetup-the-rationality-of", "linkUrl": "https://www.lesswrong.com/posts/r46gPJif9gcEy7Nm5/meetup-atlanta-lesswrong-s-may-meetup-the-rationality-of", "postedAtFormatted": "Sunday, April 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta%20Lesswrong's%20May%20Meetup%3A%20The%20Rationality%20of%20Social%20Relationships%2C%20Friendship%2C%20Love%2C%20and%20Family.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%20Lesswrong's%20May%20Meetup%3A%20The%20Rationality%20of%20Social%20Relationships%2C%20Friendship%2C%20Love%2C%20and%20Family.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr46gPJif9gcEy7Nm5%2Fmeetup-atlanta-lesswrong-s-may-meetup-the-rationality-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%20Lesswrong's%20May%20Meetup%3A%20The%20Rationality%20of%20Social%20Relationships%2C%20Friendship%2C%20Love%2C%20and%20Family.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr46gPJif9gcEy7Nm5%2Fmeetup-atlanta-lesswrong-s-may-meetup-the-rationality-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fr46gPJif9gcEy7Nm5%2Fmeetup-atlanta-lesswrong-s-may-meetup-the-rationality-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 208, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m4'>Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We\u2019ve been chipping away at the rationality of happiness, so let\u2019s narrow in on one of the most influential components of happiness: social relationships, both platonic and romantic. Agenda:</p>\n\n<ul>\n<li><p>Introductions, and meet and greet for new members.</p></li>\n<li><p>Mini-presentations. Anyone is invited to present on a topic of their choice related to this month\u2019s theme.</p></li>\n<li><p>Discussions. We\u2019ll start with a large group discussion and break into smaller groups as needed.</p></li>\n<li><p>Games! Because games are fun, and build good social relationships. :-)</p></li>\n</ul>\n\n<p>Recommended (but not required) reading: <a href=\"http://lesswrong.com/lw/70u/rationality_lessons_learned_from_irrational/\" rel=\"nofollow\">http://lesswrong.com/lw/70u/rationality_lessons_learned_from_irrational/</a>\n<a href=\"http://lesswrong.com/lw/63i/rational_romantic_relationships_part_1/\" rel=\"nofollow\">http://lesswrong.com/lw/63i/rational_romantic_relationships_part_1/</a></p>\n\n<p>If you don\u2019t get a chance to read these, don\u2019t worry! We will set aside 10 minutes at the meeting to read the articles before discussion.</p>\n\n<p>(Please contact me if you have allergies to cats, as our meeting space has two of the most adorable cats you\u2019ve ever seen.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m4'>Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "r46gPJif9gcEy7Nm5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1822404117986164e-06, "legacy": true, "legacyId": "22440", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta_Lesswrong_s_May_Meetup__The_Rationality_of_Social_Relationships__Friendship__Love__and_Family_\">Discussion article for the meetup : <a href=\"/meetups/m4\">Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We\u2019ve been chipping away at the rationality of happiness, so let\u2019s narrow in on one of the most influential components of happiness: social relationships, both platonic and romantic. Agenda:</p>\n\n<ul>\n<li><p>Introductions, and meet and greet for new members.</p></li>\n<li><p>Mini-presentations. Anyone is invited to present on a topic of their choice related to this month\u2019s theme.</p></li>\n<li><p>Discussions. We\u2019ll start with a large group discussion and break into smaller groups as needed.</p></li>\n<li><p>Games! Because games are fun, and build good social relationships. :-)</p></li>\n</ul>\n\n<p>Recommended (but not required) reading: <a href=\"http://lesswrong.com/lw/70u/rationality_lessons_learned_from_irrational/\" rel=\"nofollow\">http://lesswrong.com/lw/70u/rationality_lessons_learned_from_irrational/</a>\n<a href=\"http://lesswrong.com/lw/63i/rational_romantic_relationships_part_1/\" rel=\"nofollow\">http://lesswrong.com/lw/63i/rational_romantic_relationships_part_1/</a></p>\n\n<p>If you don\u2019t get a chance to read these, don\u2019t worry! We will set aside 10 minutes at the meeting to read the articles before discussion.</p>\n\n<p>(Please contact me if you have allergies to cats, as our meeting space has two of the most adorable cats you\u2019ve ever seen.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Atlanta_Lesswrong_s_May_Meetup__The_Rationality_of_Social_Relationships__Friendship__Love__and_Family_1\">Discussion article for the meetup : <a href=\"/meetups/m4\">Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.", "anchor": "Discussion_article_for_the_meetup___Atlanta_Lesswrong_s_May_Meetup__The_Rationality_of_Social_Relationships__Friendship__Love__and_Family_", "level": 1}, {"title": "Discussion article for the meetup : Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.", "anchor": "Discussion_article_for_the_meetup___Atlanta_Lesswrong_s_May_Meetup__The_Rationality_of_Social_Relationships__Friendship__Love__and_Family_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["x8Fp9NMgDWbuMpizA", "JYckkCqhZPrdScjBx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-28T15:43:49.722Z", "modifiedAt": null, "url": null, "title": "LW Women Entries- Creepiness", "slug": "lw-women-entries-creepiness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:09.186Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aRHLNr62JCbBBkQXD/lw-women-entries-creepiness", "pageUrlRelative": "/posts/aRHLNr62JCbBBkQXD/lw-women-entries-creepiness", "linkUrl": "https://www.lesswrong.com/posts/aRHLNr62JCbBBkQXD/lw-women-entries-creepiness", "postedAtFormatted": "Sunday, April 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20Women%20Entries-%20Creepiness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20Women%20Entries-%20Creepiness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaRHLNr62JCbBBkQXD%2Flw-women-entries-creepiness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20Women%20Entries-%20Creepiness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaRHLNr62JCbBBkQXD%2Flw-women-entries-creepiness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaRHLNr62JCbBBkQXD%2Flw-women-entries-creepiness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 812, "htmlBody": "<h2><span style=\"font-size: 16px; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">Standard Intro</span></h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Seven women replied, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<div>\n<hr />\n</div>\n<div><br /><br /></div>\n<h2>Submitter D</h2>\n<p>The class that a lot of creepiness falls into for me is not respecting my no. &nbsp;Someone who doesn't respect a small no can't be trusted to respect a big one, when we're alone and I have fewer options to enforce it beside physical strength. &nbsp;Sometimes not respecting a no can be a matter of omission or carelessness, but I can't tell which. &nbsp;</p>\n<p>While I'm in doubt, I'm not assuming the worst of you, but I'm on edge and alertly looking for new data in a way that's stressful for me and makes it hard for either of us to enjoy the encounter. &nbsp;And I'm sure as heck not going anywhere alone with you.</p>\n<p>I've written up some short anecdotes that involved someone not respecting or constraining a no. &nbsp;They're at a range of intensities.</p>\n<p>Joining someone for the first time and sitting down in a spot that blocks their exit from the conversation. &nbsp;Sometimes unavoidable (imagine joining people at a booth) but limits my options to exit and enforce a no.</p>\n<p>Blocking an exit less literally by coming across as the kind of person who can't end a conversation (follows you between circles at a party, limits your ability to talk to other people, etc).</p>\n<p>Asking for a number instead of offering yours. &nbsp;If I want to call you, I will, but when you ask for my number, I can't stop you calling or harassing me in the future.</p>\n<p>Asking for a number while blocking my exit. &nbsp;This has happened to me in cabs when I take them late at night. &nbsp;It's bad to start with because I can't exit a moving car and I can't control the direction it's going in. &nbsp;One driver waited to the end of the ride, asked for my number, and then handed my reciept back and demanded it when I didn't comply. &nbsp;I had to write down a fake one to get out without escalating. &nbsp;This is why I'm torn between walking through a deserted part of town or taking a cab alone at night.</p>\n<p>Talking about other girls who gave you \"invalid\" nos. &nbsp;Anything on the order of \"She was flirting with me all night and then she wouldn't put out/call me back/meet for coffee.\" &nbsp;Responding positively to you is not a promise to do anything else, and it's not leading you on. &nbsp;This kind of assumption is why I'm a little hesitant to be warm to a strange guy if I'm in a place where it would be hard to enforce a no.</p>\n<p>Withholding information to constrain my no. &nbsp;The culprit here was a girl and the target was a friend of mine. &nbsp;The two of them had gone on a date and set a time to meet again and possibly have sex. &nbsp;The girl had a boyfriend, but was in some kind of open relationship and had informed my friend of this fact. &nbsp;What she didn't disclose was that the boyfriend was back in town the night of their second date. &nbsp;She waited to reveal that until my friend had turned up. &nbsp;My friend still had the power to say no, and did, but there was nothing preventing the girl from disclosing that data earlier, when my friend could have postponed or demurred by text. &nbsp;Waiting til she'd already shlepped to the apartment put more pressure on her. &nbsp;It suggested the girl would rather rig the game than respect a no.</p>\n<p>Overstepping physical boundaries and then assigning the blame to me. &nbsp;You might go for a kiss in error or touch me in a way I'm not comfortable with. &nbsp;Say sorry and move on. &nbsp;Don't say, \"You looked like you wanted to be kissed.\" &nbsp;That implies my no is less valid if you're confused. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aRHLNr62JCbBBkQXD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 49, "baseScore": 11, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "20264", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Standard_Intro\"><span style=\"font-size: 16px; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">Standard Intro</span></h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong id=\"The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_\">The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Seven women replied, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong id=\"Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_\">Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<div>\n<hr>\n</div>\n<div><br><br></div>\n<h2 id=\"Submitter_D\">Submitter D</h2>\n<p>The class that a lot of creepiness falls into for me is not respecting my no. &nbsp;Someone who doesn't respect a small no can't be trusted to respect a big one, when we're alone and I have fewer options to enforce it beside physical strength. &nbsp;Sometimes not respecting a no can be a matter of omission or carelessness, but I can't tell which. &nbsp;</p>\n<p>While I'm in doubt, I'm not assuming the worst of you, but I'm on edge and alertly looking for new data in a way that's stressful for me and makes it hard for either of us to enjoy the encounter. &nbsp;And I'm sure as heck not going anywhere alone with you.</p>\n<p>I've written up some short anecdotes that involved someone not respecting or constraining a no. &nbsp;They're at a range of intensities.</p>\n<p>Joining someone for the first time and sitting down in a spot that blocks their exit from the conversation. &nbsp;Sometimes unavoidable (imagine joining people at a booth) but limits my options to exit and enforce a no.</p>\n<p>Blocking an exit less literally by coming across as the kind of person who can't end a conversation (follows you between circles at a party, limits your ability to talk to other people, etc).</p>\n<p>Asking for a number instead of offering yours. &nbsp;If I want to call you, I will, but when you ask for my number, I can't stop you calling or harassing me in the future.</p>\n<p>Asking for a number while blocking my exit. &nbsp;This has happened to me in cabs when I take them late at night. &nbsp;It's bad to start with because I can't exit a moving car and I can't control the direction it's going in. &nbsp;One driver waited to the end of the ride, asked for my number, and then handed my reciept back and demanded it when I didn't comply. &nbsp;I had to write down a fake one to get out without escalating. &nbsp;This is why I'm torn between walking through a deserted part of town or taking a cab alone at night.</p>\n<p>Talking about other girls who gave you \"invalid\" nos. &nbsp;Anything on the order of \"She was flirting with me all night and then she wouldn't put out/call me back/meet for coffee.\" &nbsp;Responding positively to you is not a promise to do anything else, and it's not leading you on. &nbsp;This kind of assumption is why I'm a little hesitant to be warm to a strange guy if I'm in a place where it would be hard to enforce a no.</p>\n<p>Withholding information to constrain my no. &nbsp;The culprit here was a girl and the target was a friend of mine. &nbsp;The two of them had gone on a date and set a time to meet again and possibly have sex. &nbsp;The girl had a boyfriend, but was in some kind of open relationship and had informed my friend of this fact. &nbsp;What she didn't disclose was that the boyfriend was back in town the night of their second date. &nbsp;She waited to reveal that until my friend had turned up. &nbsp;My friend still had the power to say no, and did, but there was nothing preventing the girl from disclosing that data earlier, when my friend could have postponed or demurred by text. &nbsp;Waiting til she'd already shlepped to the apartment put more pressure on her. &nbsp;It suggested the girl would rather rig the game than respect a no.</p>\n<p>Overstepping physical boundaries and then assigning the blame to me. &nbsp;You might go for a kiss in error or touch me in a way I'm not comfortable with. &nbsp;Say sorry and move on. &nbsp;Don't say, \"You looked like you wanted to be kissed.\" &nbsp;That implies my no is less valid if you're confused. &nbsp;</p>", "sections": [{"title": "Standard Intro", "anchor": "Standard_Intro", "level": 1}, {"title": "The following section will be at the top of all posts in the LW Women series.", "anchor": "The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_", "level": 2}, {"title": "Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.", "anchor": "Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_", "level": 2}, {"title": "Submitter D", "anchor": "Submitter_D", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "477 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 478, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T08:47:33.126Z", "modifiedAt": null, "url": null, "title": "Meet up in St. Petersburg, Russia", "slug": "meet-up-in-st-petersburg-russia", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8cLtrFXzWxuDqoPjM/meet-up-in-st-petersburg-russia", "pageUrlRelative": "/posts/8cLtrFXzWxuDqoPjM/meet-up-in-st-petersburg-russia", "linkUrl": "https://www.lesswrong.com/posts/8cLtrFXzWxuDqoPjM/meet-up-in-st-petersburg-russia", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meet%20up%20in%20St.%20Petersburg%2C%20Russia&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeet%20up%20in%20St.%20Petersburg%2C%20Russia%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8cLtrFXzWxuDqoPjM%2Fmeet-up-in-st-petersburg-russia%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meet%20up%20in%20St.%20Petersburg%2C%20Russia%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8cLtrFXzWxuDqoPjM%2Fmeet-up-in-st-petersburg-russia", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8cLtrFXzWxuDqoPjM%2Fmeet-up-in-st-petersburg-russia", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<p>Andrey who participate in Moscow meet-up organization will visit St. Petersburg on 8th-12th of May. He can tell you about Moscow gatherings and applied rationality, show some exercises and useful methods.</p>\n<p>We only need someone from St. Petersburg, who can find suitable venue and meet Andrey and other people there. Please write at lw@lesswrong.ru to coordinate efforts.</p>\n<p>You can also write to me after 12th of May, and we will help you to organize a meet up.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8cLtrFXzWxuDqoPjM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1833992657148595e-06, "legacy": true, "legacyId": "22442", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T12:22:19.543Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels meetup", "slug": "meetup-brussels-meetup-8", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Axel", "createdAt": "2010-11-03T17:32:46.091Z", "isAdmin": false, "displayName": "Axel"}, "userId": "vi498nAvek8eWuMWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/h65j8YjBqMzuFJxHX/meetup-brussels-meetup-8", "pageUrlRelative": "/posts/h65j8YjBqMzuFJxHX/meetup-brussels-meetup-8", "linkUrl": "https://www.lesswrong.com/posts/h65j8YjBqMzuFJxHX/meetup-brussels-meetup-8", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh65j8YjBqMzuFJxHX%2Fmeetup-brussels-meetup-8%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh65j8YjBqMzuFJxHX%2Fmeetup-brussels-meetup-8", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh65j8YjBqMzuFJxHX%2Fmeetup-brussels-meetup-8", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m5'>Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 May 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are once again meeting at 'la fleur en papier dor\u0102\u0160e' close to the Brussels Central station. If you feel like an intelligent discussion and are in the neighborhood, consider dropping by. As always, I'll have a sign. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform?pli=1\" rel=\"nofollow\">this</a> one minute form, to share your contact information.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m5'>Brussels meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "h65j8YjBqMzuFJxHX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1835512587992988e-06, "legacy": true, "legacyId": "22443", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup\">Discussion article for the meetup : <a href=\"/meetups/m5\">Brussels meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 May 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are once again meeting at 'la fleur en papier dor\u0102\u0160e' close to the Brussels Central station. If you feel like an intelligent discussion and are in the neighborhood, consider dropping by. As always, I'll have a sign. The meeting will be in English to facilitate both French and Dutch speaking members.</p>\n\n<p>If you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform?pli=1\" rel=\"nofollow\">this</a> one minute form, to share your contact information.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup1\">Discussion article for the meetup : <a href=\"/meetups/m5\">Brussels meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup", "level": 1}, {"title": "Discussion article for the meetup : Brussels meetup", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T12:37:21.264Z", "modifiedAt": null, "url": null, "title": "[LINK] Is it worth the time?", "slug": "link-is-it-worth-the-time", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:08.285Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexvermeer", "createdAt": "2010-08-13T16:28:34.576Z", "isAdmin": false, "displayName": "alexvermeer"}, "userId": "3bK6aDQviGG3ovuDJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eYQKZ5iYGvgFzrGDh/link-is-it-worth-the-time", "pageUrlRelative": "/posts/eYQKZ5iYGvgFzrGDh/link-is-it-worth-the-time", "linkUrl": "https://www.lesswrong.com/posts/eYQKZ5iYGvgFzrGDh/link-is-it-worth-the-time", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Is%20it%20worth%20the%20time%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Is%20it%20worth%20the%20time%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYQKZ5iYGvgFzrGDh%2Flink-is-it-worth-the-time%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Is%20it%20worth%20the%20time%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYQKZ5iYGvgFzrGDh%2Flink-is-it-worth-the-time", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeYQKZ5iYGvgFzrGDh%2Flink-is-it-worth-the-time", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<p>Another gem from <a href=\"http://xkcd.com\">xkcd</a>: <a href=\"http://xkcd.com/1205/\">Is It Worth the Time?</a> It visually answers the question:</p>\n<blockquote>\n<p>How long can you work on making a routine task more efficient before you're spending more time than you save?&nbsp;</p>\n</blockquote>\n<p>Of course, he's not the first person to ask this question, but the visual is handy. Note that the times are calculated assuming you'll save the time over five years.</p>\n<p>For example, I've been pondering how to shorten my showers. If I can shave off 1 minute daily, I should be willing to invest up to (but no more than) an entire day to do it. If I think I can shave off five minutes preparing my breakfast, I should be willing to spend up to <em>six days</em> attempting to do so.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eYQKZ5iYGvgFzrGDh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 14, "extendedScore": null, "score": 1.1835618957270737e-06, "legacy": true, "legacyId": "22444", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T15:57:13.164Z", "modifiedAt": null, "url": null, "title": "Meetup : NewYork - Humanist Culture Open Mic", "slug": "meetup-newyork-humanist-culture-open-mic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:07.526Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eQL3cPWRiQax84is5/meetup-newyork-humanist-culture-open-mic", "pageUrlRelative": "/posts/eQL3cPWRiQax84is5/meetup-newyork-humanist-culture-open-mic", "linkUrl": "https://www.lesswrong.com/posts/eQL3cPWRiQax84is5/meetup-newyork-humanist-culture-open-mic", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20NewYork%20-%20Humanist%20Culture%20Open%20Mic&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20NewYork%20-%20Humanist%20Culture%20Open%20Mic%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeQL3cPWRiQax84is5%2Fmeetup-newyork-humanist-culture-open-mic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20NewYork%20-%20Humanist%20Culture%20Open%20Mic%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeQL3cPWRiQax84is5%2Fmeetup-newyork-humanist-culture-open-mic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeQL3cPWRiQax84is5%2Fmeetup-newyork-humanist-culture-open-mic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 268, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m6'>NewYork - Humanist Culture Open Mic</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">01 May 2013 07:15:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2 West 64th Street (At Central Park West) New York, NY</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>God probably doesn't exist, but that's not the point.</p>\n\n<p>The point is that we live in a ridiculously amazing world, full of ridiculously amazing people who started with sticks and stones and rudimentary social structure and somehow built skyscrapers, went to the moon, destroyed smallpox, invented new crops that could feed billions of people, connected the entire planet into a global internet hive-mind and we're not even <em>done</em> yet.</p>\n\n<p>This is more awesome than you are currently thinking. Nope, more awesome than that. Keep going. More. More!</p>\n\n<p>Fortunately we also invented stories and songs, to tell our children and each other how awesome we are, and to inspire people to go even further.</p>\n\n<p>I started a open mic last year, to help create a musical and creative culture that promotes science, rationality, ethics and human progress. After a few months of hiatus we're relaunching, co-sponsored now by Center for Inquiry - NYC and the NY Society for Ethical Culture. Among my goals is to start steering the more mainstream skeptic/atheist/humanist movements towards harder, unanswered questions. This year, we're building towards a larger end of the year concert event.</p>\n\n<p>The open mic is at the Ethical Culture building, on the 5th floor in room 514. Whether you do performance art (songs, stories, comedy or otherwise) or just want to listen, you are welcome to attend!</p>\n\n<p>Meetup.com announcement is here, if you'd like to RSVP there:</p>\n\n<p><a href=\"http://cfinewyork.net/events/112756672/\" rel=\"nofollow\">http://cfinewyork.net/events/112756672/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m6'>NewYork - Humanist Culture Open Mic</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eQL3cPWRiQax84is5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "22445", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___NewYork___Humanist_Culture_Open_Mic\">Discussion article for the meetup : <a href=\"/meetups/m6\">NewYork - Humanist Culture Open Mic</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">01 May 2013 07:15:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2 West 64th Street (At Central Park West) New York, NY</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>God probably doesn't exist, but that's not the point.</p>\n\n<p>The point is that we live in a ridiculously amazing world, full of ridiculously amazing people who started with sticks and stones and rudimentary social structure and somehow built skyscrapers, went to the moon, destroyed smallpox, invented new crops that could feed billions of people, connected the entire planet into a global internet hive-mind and we're not even <em>done</em> yet.</p>\n\n<p>This is more awesome than you are currently thinking. Nope, more awesome than that. Keep going. More. More!</p>\n\n<p>Fortunately we also invented stories and songs, to tell our children and each other how awesome we are, and to inspire people to go even further.</p>\n\n<p>I started a open mic last year, to help create a musical and creative culture that promotes science, rationality, ethics and human progress. After a few months of hiatus we're relaunching, co-sponsored now by Center for Inquiry - NYC and the NY Society for Ethical Culture. Among my goals is to start steering the more mainstream skeptic/atheist/humanist movements towards harder, unanswered questions. This year, we're building towards a larger end of the year concert event.</p>\n\n<p>The open mic is at the Ethical Culture building, on the 5th floor in room 514. Whether you do performance art (songs, stories, comedy or otherwise) or just want to listen, you are welcome to attend!</p>\n\n<p>Meetup.com announcement is here, if you'd like to RSVP there:</p>\n\n<p><a href=\"http://cfinewyork.net/events/112756672/\" rel=\"nofollow\">http://cfinewyork.net/events/112756672/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___NewYork___Humanist_Culture_Open_Mic1\">Discussion article for the meetup : <a href=\"/meetups/m6\">NewYork - Humanist Culture Open Mic</a></h2>", "sections": [{"title": "Discussion article for the meetup : NewYork - Humanist Culture Open Mic", "anchor": "Discussion_article_for_the_meetup___NewYork___Humanist_Culture_Open_Mic", "level": 1}, {"title": "Discussion article for the meetup : NewYork - Humanist Culture Open Mic", "anchor": "Discussion_article_for_the_meetup___NewYork___Humanist_Culture_Open_Mic1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T18:30:35.545Z", "modifiedAt": "2020-12-18T02:48:38.828Z", "url": null, "title": "Privileging the Question", "slug": "privileging-the-question", "viewCount": null, "lastCommentedAt": "2020-12-05T15:43:35.796Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6vcxuRHzeM99jYcYd/privileging-the-question", "pageUrlRelative": "/posts/6vcxuRHzeM99jYcYd/privileging-the-question", "linkUrl": "https://www.lesswrong.com/posts/6vcxuRHzeM99jYcYd/privileging-the-question", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Privileging%20the%20Question&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APrivileging%20the%20Question%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vcxuRHzeM99jYcYd%2Fprivileging-the-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Privileging%20the%20Question%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vcxuRHzeM99jYcYd%2Fprivileging-the-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6vcxuRHzeM99jYcYd%2Fprivileging-the-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 722, "htmlBody": "<p><strong>Related to:</strong> <a href=\"/lw/19m/privileging_the_hypothesis/\">Privileging the Hypothesis</a></p>\n<blockquote>\n<p>Remember the exercises in critical reading you did in school, where you had to look at a piece of writing and step back and ask whether the author was telling the whole truth? If you really want to be a critical reader, it turns out you have to step back one step further, and ask not just whether the author is telling the truth, but <em>why he's writing about this subject at all.</em></p>\n</blockquote>\n<p>-- <a href=\"http://www.paulgraham.com/submarine.html\">Paul Graham</a></p>\n<blockquote>\n<p>There's an old saying in the public opinion business: we can't tell people what to think, but we can tell them what to think about.</p>\n</blockquote>\n<p>-- Doug Henwood</p>\n<blockquote>\n<p>Many philosophers&mdash;particularly amateur philosophers, and ancient philosophers&mdash;share a dangerous instinct: If you give them a question, they try to answer it.</p>\n</blockquote>\n<p>-- <a href=\"/lw/of/dissolving_the_question/\">Eliezer Yudkowsky</a></p>\n<p>Here are some political questions that seem to commonly get discussed in US media: should gay marriage be legal? Should Congress pass stricter gun control laws? Should immigration policy be tightened or relaxed?&nbsp;</p>\n<p>These are all examples of what I'll call <strong>privileged questions</strong>&nbsp;(if there's an existing term for this, let me know):<strong>&nbsp;</strong>questions that someone has unjustifiably brought to your attention in the same way that a privileged hypothesis unjustifiably gets brought to your attention. The questions above are probably not the most important questions we could be answering right now, even in politics (I'd guess that the economy is more important). Outside of politics, many LWers probably think \"what can we do about <a href=\"http://wiki.lesswrong.com/wiki/Existential_risk\">existential risks</a>?\" is one of the most important questions to answer, or possibly \"how do we <a href=\"/lw/3gj/efficient_charity_do_unto_others/\">optimize charity</a>?\"&nbsp;</p>\n<p>Why has the media privileged these questions? I'd guess that the media is incentivized to ask whatever questions will get them the most views. That's a very different goal from asking the most important questions, and is one reason to stop paying attention to the media.&nbsp;</p>\n<p>The problem with privileged questions is that you only have so much attention to spare. Attention paid to a question that has been privileged <a href=\"http://en.wikipedia.org/wiki/Fungibility\">funges against</a> attention you could be paying to better questions. Even worse, it may not feel from the inside like anything is wrong: you can apply all of the epistemic rationality in the world to answering a question like \"should Congress pass stricter gun control laws?\" and never once ask yourself where that question came from and whether there are better questions you could be answering instead.</p>\n<p>I suspect this is a problem in academia too. <a href=\"http://www.cs.virginia.edu/~robins/YouAndYourResearch.html\">Richard Hamming</a> once gave a talk in which he related the following story:</p>\n<blockquote>\n<p>Over on the other side of the dining hall was a chemistry table. I had worked with one of the fellows, Dave McCall; furthermore he was courting our secretary at the time. I went over and said, \"Do you mind if I join you?\" They can't say no, so I started eating with them for a while. And I started asking, \"What are the important problems of your field?\" And after a week or so, \"What important problems are you working on?\" And after some more time I came in one day and said, \"If what you are doing is not important, and if you don't think it is going to lead to something important, why are you at Bell Labs working on it?\" I wasn't welcomed after that; I had to find somebody else to eat with!</p>\n</blockquote>\n<p>Academics answer questions that have been privileged in various ways: perhaps the questions their advisor was interested in, or the questions they'll most easily be able to publish papers on. Neither of these are necessarily well-correlated with the most important questions.&nbsp;</p>\n<p>So far I've found one tool that helps combat the worst privileged questions, which is to ask the following counter-question:</p>\n<p><em>What do I plan on doing with an answer to this question?</em></p>\n<p>With the worst privileged questions I frequently find that the answer is \"nothing,\" sometimes with the follow-up answer \"signaling?\" That's a bad sign. (<strong>Edit:</strong>&nbsp;but \"nothing\" is different from \"I'm just curious,\" say in the context of an interesting mathematical or scientific question that isn't motivated by a practical concern. Intellectual curiosity can be a useful heuristic.)</p>\n<p>(I've also found the above counter-question generally useful for dealing with questions. For example, it's one way to notice when a question should be <a href=\"/lw/of/dissolving_the_question/\">dissolved</a>, and asked of someone else it's one way to help both of you clarify what they actually want to know.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"BhrpjXqGuke5GnF6g": 1, "4R8JYu4QF2FqzJxE5": 1, "DbMQGrxbhLxtNkmca": 5}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6vcxuRHzeM99jYcYd", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 134, "baseScore": 196, "extendedScore": null, "score": 0.000463, "legacy": true, "legacyId": "22438", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 196, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 312, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["X2AD2LgtKgkRNPj2a", "Mc6QcrsbH5NRXbCRX", "pC47ZTsPNAkjavkXs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 22, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2013-04-29T18:30:35.545Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T18:44:06.652Z", "modifiedAt": null, "url": null, "title": "Good luck, Mr. Rationalist", "slug": "good-luck-mr-rationalist", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:32.434Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/guWyDKzwxv9Q6pGQm/good-luck-mr-rationalist", "pageUrlRelative": "/posts/guWyDKzwxv9Q6pGQm/good-luck-mr-rationalist", "linkUrl": "https://www.lesswrong.com/posts/guWyDKzwxv9Q6pGQm/good-luck-mr-rationalist", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Good%20luck%2C%20Mr.%20Rationalist&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGood%20luck%2C%20Mr.%20Rationalist%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FguWyDKzwxv9Q6pGQm%2Fgood-luck-mr-rationalist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Good%20luck%2C%20Mr.%20Rationalist%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FguWyDKzwxv9Q6pGQm%2Fgood-luck-mr-rationalist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FguWyDKzwxv9Q6pGQm%2Fgood-luck-mr-rationalist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<p>Is there any rationalist equivalent of \"good luck\"? I've tried a few variants, such as \"work well\", \"knock them dead\", \"we're with you\" and certain situation-specific phrasings, but haven't found anything that worked generally - though a hearty \"may all the gods of Olympus be with you!\" can serve. Not a vitally important point, but it would be nice to have something similarly supportive and yet accurate to say.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "guWyDKzwxv9Q6pGQm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 9, "extendedScore": null, "score": 1.1838215295093898e-06, "legacy": true, "legacyId": "22446", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 76, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T20:01:45.806Z", "modifiedAt": null, "url": null, "title": "[Link] 2012 Winter Intelligence Conference videos available", "slug": "link-2012-winter-intelligence-conference-videos-available", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:18.711Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pablo_Stafforini", "createdAt": "2009-03-24T12:56:00.130Z", "isAdmin": false, "displayName": "Pablo"}, "userId": "W7ETRtvRMqYetyQE9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2AwJT4vdwwScmF26v/link-2012-winter-intelligence-conference-videos-available", "pageUrlRelative": "/posts/2AwJT4vdwwScmF26v/link-2012-winter-intelligence-conference-videos-available", "linkUrl": "https://www.lesswrong.com/posts/2AwJT4vdwwScmF26v/link-2012-winter-intelligence-conference-videos-available", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%202012%20Winter%20Intelligence%20Conference%20videos%20available&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%202012%20Winter%20Intelligence%20Conference%20videos%20available%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2AwJT4vdwwScmF26v%2Flink-2012-winter-intelligence-conference-videos-available%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%202012%20Winter%20Intelligence%20Conference%20videos%20available%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2AwJT4vdwwScmF26v%2Flink-2012-winter-intelligence-conference-videos-available", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2AwJT4vdwwScmF26v%2Flink-2012-winter-intelligence-conference-videos-available", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p>The Future of Humanity Institute has released video footage of the 2012 Winter Intelligence Conference. &nbsp;The videos currently available are:</p>\n<ul>\n<li>Stuart Armstrong -&nbsp;<a href=\"http://www.youtube.com/watch?v=oyZyQuROYlA\">Predicting AI... or Failing to</a></li>\n<li>Miles Brundage -&nbsp;<a href=\"http://www.youtube.com/watch?v=1KX_DFM-DRY\">Limitations and Risks of Machine Ethics</a></li>\n<li>Steve Omohundro - <a href=\"http://www.youtube.com/watch?v=zvRVs1jV6R0\">Autonomous Technology and the Greater Human Good</a></li>\n<li>Anders Sandberg -&nbsp;<a href=\"http://www.youtube.com/watch?v=4pq0cCgVgDY\">Ethics and Impact of Brain Emulations</a></li>\n<li>Carl Shulman - <a href=\"http://www.youtube.com/watch?v=ljHFmznqkYM\">Could We Use Untrustworthy Human Brain Emulations to Make Trustworthy Ones</a></li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2AwJT4vdwwScmF26v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 1.183876514116454e-06, "legacy": true, "legacyId": "22447", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T21:00:15.768Z", "modifiedAt": null, "url": null, "title": "Problems in Education", "slug": "problems-in-education-0", "viewCount": null, "lastCommentedAt": "2013-05-07T19:09:33.903Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ThinkOfTheChildren", "createdAt": "2013-04-08T19:31:47.779Z", "isAdmin": false, "displayName": "ThinkOfTheChildren"}, "userId": "nwz7jbhybAPKzt2gJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DxFFeJoczRp2rPS2K/problems-in-education-0", "pageUrlRelative": "/posts/DxFFeJoczRp2rPS2K/problems-in-education-0", "linkUrl": "https://www.lesswrong.com/posts/DxFFeJoczRp2rPS2K/problems-in-education-0", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Problems%20in%20Education&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProblems%20in%20Education%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxFFeJoczRp2rPS2K%2Fproblems-in-education-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Problems%20in%20Education%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxFFeJoczRp2rPS2K%2Fproblems-in-education-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDxFFeJoczRp2rPS2K%2Fproblems-in-education-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3532, "htmlBody": "<p>Alright guys. The main complaint of the discussion article was simply \"hoax\", yelled as loudly or as quietly as the user felt about it. Hopefully this won't get the same treatment.<br /><br />We have been evaluating educational,&nbsp; grant-funded programs for 20 years. Throughout these years, we have witnessed a slow change in how students are selected for academic services.&nbsp; Traditionally, students were targeted for academic services and opportunities based on demographic characteristics&mdash;usually race and, until recently, family income status (based on free or reduced priced lunch). Wealthier, white students are given challenging lessons and tracked into the advanced courses, while their non-white and poorer peers are tracked low and given remediation services. The latter students are often referred to as &ldquo;at-risk,&rdquo; though we are finding more and more that the greatest risk these students face is being placed into inappropriate remedial courses which eventually bar them from access to advanced courses.&nbsp; After students have been labeled &ldquo;at-risk,&rdquo; and then tracked inappropriately and provided unnecessary (and often harmful) remediation, their downward trajectory continues throughout their education. The demographic gap this creates continues to expand, despite the lip service and excessive tax and grant funds paid to eliminate&mdash;or at least lessen&mdash;this very gap. This &ldquo;at-risk&rdquo; model of assigning services is slowly being replaced by a &ldquo;pro-equity&rdquo; model. The driving force behind this change is the availability and use of data. <br /><br />The literature is full of documentation that certain demographic groups have traditionally had less access to advanced math and science courses than equally scoring students belonging to demographic groups thought to be &ldquo;not at risk.&rdquo; Some examples from research follow.<br />&bull;&nbsp;&nbsp; &nbsp;Sixth grade course placement is the main predictor of eighth grade course placement, and social factors--mainly race---are key predictors of sixth grade course placement (O&rsquo;Connor, Lewis, &amp; Mueller, 2007). <br />&bull;&nbsp;&nbsp; &nbsp;Among low-income students, little is done to assess which are high achievers. Few programs are aimed at them, and their numbers are lumped in with &ldquo;adequate&rdquo; achievers in No Child Left Behind reporting. As a result, little is known about effective practices for low-income students (Wyner, Bridgeland, &amp; DiIulio&nbsp; Jr., 2007). <br />&bull;&nbsp;&nbsp; &nbsp;In a California school district, researchers found that of students who demonstrated the ability to be admitted to algebra, 100% of the Asians, 88% of the whites, 51% of the Blacks, and 42% of the Latinos were admitted (Stone &amp; Turba, 1999).<br />&bull;&nbsp;&nbsp; &nbsp;Tracking has been described as &ldquo;a backdoor device for sorting students by race and class.&rdquo; Many researchers agree (Abu El-Haj &amp; Rubin, 2009).<br />&bull;&nbsp;&nbsp; &nbsp;When course grades are used to determine placement, studies show that some students&rsquo; grades &ldquo;matter&rdquo; more than others. Perceptions of race and social class are often used to determine placement (Mayer, 2008).<br />&bull;&nbsp;&nbsp; &nbsp;Studies show that when schools allow students the freedom to choose which track they&rsquo;ll take, teachers and counselors discourage many previously lower tracked students from choosing the higher track&nbsp; (Yonezawa, Wells, &amp; Serna, 2002).<br />&bull;&nbsp;&nbsp; &nbsp;The sequence of math students take in middle school essentially determines their math track for high school. In North Carolina, this is true because of math prerequisites for higher level math (North Carolina Department of Public Instruction, 2009).<br /><br />We are seeing a move toward using objective data for placement into gateway courses, such as 8th grade algebra. Many school districts are beginning to use Education Value Added Assessment (EVAAS) and other data system scores that predict success in 8th grade algebra for criteria to enroll. This pro-equity model is replacing the traditional, at-risk model that relied on professional judgment.&nbsp; One example of this is in Wake County, North Carolina. Superintendent Tony Tata attributed a 44% increase in the number of students enrolled in algebra to the use of the predictive software, EVAAS, to identify students likely to be successful. The success rate in the course increased with the addition of these students (KeungHu, 2012). <br /><br />Although the pro-equity model of using objective data to assign students to more rigorous courses has proven successful, many people resist it. These people cling to the at-risk model, dismissing the objective data as inconclusive. Many of the overlooked students who were predicted to succeed, yet were placed in lower tracks (disproportionately minorities), are &ldquo;weaker,&rdquo; according to the old-school staff, and allowing these students into the gateway 8th-grade algebra course would be a disservice to them. (Not allowing them into this course ensures their bleak academic future.)&nbsp; Review of the data had shown that strong students were being overlooked, and this objective use of data helps identify them (Sanders, Rivers, Enck, Leandro, &amp; White, 2009). <br /><br />The changes in education began with concern for aligning academic services with academic need. Aligning opportunities for rigor and enrichment is only just beginning. In the past, a large proportion of federal grant funds were for raising proficiency rates. In the at-risk model, grant funds were provided for services to the minority and poor demographic groups with the goals of raising academic proficiency rates. When we first started evaluating grant-funded programs, most federal grants were entirely in the at-risk model. The students were targeted for services based on demographic characteristics. The goals were to deliver the services to this group. Staff development was often designed to help staff understand children in poverty and what their lives are like, rather than helping them learn how to deliver an effective reading or math intervention. The accountability reports we were hired to write consisted of documentation that the correct demographic group was served, the program was delivered, and staff received their professional development. Proficiency rates were rarely a concern. <br /><br />In 2004, the federal government developed the Program Assessment Rating Tool (PART) to provide accountability to grant-funded programs by rating their effectiveness.&nbsp; The PART system assigned scores to programs based on services being related to goals, showing that the goals were appropriate for the individuals served, and student success measured against quality standards and assessments. PART rated programs that could not demonstrate whether they have been effective or not because of lack of data or clear performance goals with the rating &ldquo;Results Not Demonstrated&rdquo;&nbsp; (U.S. Office of Management and Budget and Federal Agencies, n.d. \"The Program Assessment Rating Tool\") . In 2009, nearly half (47%) of U.S. Department of Education grant programs rated by the government are given this rating, thus illustrating the difficulties of making this transition to outcome based accountability (U.S. Office of Management and Budget and Federal agencies, n.d. \"Department of Education programs\"). The earliest changes were in accountability, not in program services or how to target students. Accountability reports began asking for pre- and post-comparisons of academic scores. For example, if funds were for raising the proficiency rates in reading, then evaluation reports were required to compare pre- and post-reading scores. This was a confusing period, because programs still targeted students based on demographic information and provided services that often had no research basis linking them to academic achievement; professional development often remained focused on empathizing with children in poverty, although the goals and objectives would now be written in terms of the participants raising their academic achievement to proficiency. We evaluators were often called in at the conclusion of programs to compare pre- and post-academic scores, and determine whether participants improved their scores to grade-level proficiency. We often saw the results of capable students treated like low-achievers, thought to have no self-esteem, and provided remedial work. Such treatment damaged the participants who had previously scored at or above proficient prior to services. <br /><br />&nbsp;A typical narrative of an evaluation might read: <br /><br />&nbsp;The goal of the program was to raise the percentage of students scoring proficient in reading. The program targeted and served low-income and minority students. Staff received professional development on understanding poor children. Services offered to students included remedial tutorials and esteem-building activities. When the program ended, pre-reading scores were obtained and compared with post-scores to measure progress toward the program objective.&nbsp; At that time, it was discovered that a large percentage of participants were proficient prior to receiving services. <br /><br />Rather than cite our own evaluations, we found many examples from the school districts reporting on themselves.</p>\n<p>Accelerated Learning Program.</p>\n<p>The following is a direct quote from a school system in North Carolina:<br /><br />. . . Although ALP [Accelerated Learning Program] was designed primarily to help students reach proficiency as measured by End-of-Grade (EOG) tests, only 41.1% of those served showed below-grade-level scores on standard tests before service in literacy. In mathematics, 73.3% of students served had below-grade-level scores. ALP served about 40% of students who scored below grade level within literacy and within mathematics, with other services supporting many others. . . . Compared to those not served, results for Level I-II students were similar, but results for Level III-IV students were less positive. One third of non- proficient ALP mathematics students reached proficiency in 2008, compared to 42.1% of other students. (Lougee &amp; Baenen, 2009).<br /><br />Foundations of Algebra<br /><br />This program was designed for students who fit specific criteria, yet it served many students who did not. Students who were below proficient or almost proficient were to be placed in courses to eventually prepare them for Algebra I. When criteria for placement are not met, determining program effectiveness is difficult, if not impossible. Students were likely entered into the program based on teacher recommendations, which were subsequently based on demographic factors such as race. The teachers &ldquo;mistook&rdquo; these students for below-proficient students when they were not. Had objective data, such as actual proficiency scores, been consulted, the proper students could have been served. The report indicates a success, as a higher percentage of these students than similar students who were not served enrolled in Algebra I. However, it is not known if this comparison group includes only students who actually meet the criteria, or if they are a heterogeneous mix of students of varying abilities. Missing data also makes program effectiveness evaluation difficult (Paeplow, 2010).<br /><br />Partnership for Educational Success (PES)<br /><br />This program was purportedly for students who are &ldquo;at risk,&rdquo; which is defined as students who scored below grade level on EOG (below proficiency)&nbsp; and have been &ldquo;identified by the PES team as having family issues that interfere with school success.&rdquo; What is meant by &ldquo;family issues&rdquo; is unclear. The majority of students served are Economically Disadvantaged (ED) (91.3%) and Black (71.5%). More than half the students served, according to the evaluation, were at or above grade level on their EOGs when they began the program, thus making program effectiveness difficult to judge. The family component is an integral part of the program, and outside agencies visit families. Many community organizations are involved. But if the staff could miss so easy a datum as EOG scores for so many students, one has to wonder about such a subjective criterion as &ldquo;family issues.&rdquo; The program appears to have targeted ED students, with little regard to prior performance data. Data for many students (43.5%) was missing. Teachers indicate that parents of the targeted families have become more involved in the school, but little else has changed (Harlow &amp; Baenen, 2004).<br /><br />Helping Hands<br /><br />Helping Hands was initiated based on data indicating that Black males lag behind other groups in academic achievement. The program is supposed to serve Black males, and most of the participants fit these criteria. The program is also designed to improve academics, and to curtail absenteeism and suspensions. Although the percentage of selected participants who needed improvement in these areas was higher than it was for the overall population of the students served, not all students served demonstrated a need for intervention. Many students were at grade level, were not chronically absent, and had not been suspended. Yet they were served because they were Black and male (Paeplow, 2009).<br /><br />At Hodge Road Elementary School, students were tutored with remedial work in an after-school program. The only criterion the students had to meet to be allowed into the program was the inability to pay full price for their lunch. Their academic performance was irrelevant. (To be fair, these criteria were instituted by No Child Left Behind, and not the school system.) Most students were already reading and doing math at or above grade level (the two subjects for which tutoring was provided). The evaluation shows that giving remedial coursework to students who are at or above grade level, as if they were below grade level, can actually harm them. In the final statistics, 11.1% of Level III &amp; IV 3rd through 5th graders scored below grade level after being served, compared with only 2% of a comparable group who were not served. An astonishing 23% of students in kindergarten through 2nd grade served who were at or above grade level prior to the tutoring scored below grade level afterward, compared with 8% of comparable students who were not served (Paeplow &amp; Baenen, 2006).<br /><br />AVID<br /><br />AVID is a program designed for students who may be the first in their families to attend college, and who are average academic performers. The program, developed in the 1980s, maintains that by providing support while holding students to high academic standards, the achievement gap will narrow as students succeed academically and go on to successfully complete higher level education. Fidelity of implementation is often violated, which, as proponents admit on AVID&rsquo;s own website (www.AVID.org) may compromise the entire program. Student participants must have a GPA of 2.0-3.5. We were asked to evaluate Wake County Public School Systems AVID program. Many students chosen for the program, however, did not fit the criteria (Lougee &amp; Baenen, 2008). Because AVID requirements were not met, a meaningful evaluation was not possible. <br /><br />This AVID program was implemented with the goal of increasing the number of under-represented students in 8th grade algebra. This was at a time when no criteria for enrollment in 8th grade algebra existed (i.e., a target to help the students reach didn&rsquo;t exist), and high scoring students in this very group were not being referred for enrollment in algebra. Under these conditions, the program makes no sense. In summary, the goal of this program is to enroll in 8th grade algebra more low-income, minority, and students whose parents didn&rsquo;t go to college. Only students recommended by teachers can enroll in 8th grade algebra. The data showed that very high-scoring, low-income and minority students were not being recommended for 8th grade algebra. Why do we think that students whose parents didn&rsquo;t go to college can&rsquo;t enroll in 8th grade algebra without being in an intervention program first? (Also, how it is determined that the students&rsquo; parents did not attend college is not addressed.) The program is for low-average students. They served high-average students. Then they still didn&rsquo;t recommend them to be in 8th grade algebra. This program is very expensive. We have evaluated this program in many school districts and we find the same results, typically, as this report.<br /><br />During this era, the interventions typically have not been related to the desired outcomes by research. For example, self-esteem-building activities were often provided to increase the odds of passing a math class, or to improve reading scores. Sometimes programs would be academic, but claims for success were not research-based, nor was the relationship between the activities and the desired outcomes. Although many interventions were at least related to the academic subject area the program&nbsp; was trying to impact, it was not unheard of to see relaxation courses alone for increasing math test scores, or make-overs and glamor shots for raising self-esteem, which in turn would allegedly raise reading scores.<br /><br />During the last decade, education has slowly moved toward requiring accountability in terms of comparing pre- and post-scores. We saw this causing confusion and fear, rather than clarity. More than once, when we reported to school districts that they had served significant numbers of students who were already at or above proficiency levels, they thought we were saying they had served high-income students instead of their target population of low-income students. We have seen many school systems assess their own programs, write evaluation reports like the examples above, and then continue to implement the programs without any changes. We have worked with some educators whose eyes were opened to the misalignment of services and needs, and they learned to use data, to identify appropriate interventions, and keep records to make accountability possible. We&rsquo;ve seen these innovators close their achievement gaps while raising achievement of the top. But, those around them didn&rsquo;t see this as replicable.<br /><br />Race to the Top will impact the rate of change from the at-risk to the pro-equity model. Teacher and principal evaluations are going to include measures of growth in student learning (White House Office of the Press Secretary, 2009).&nbsp; EVAAS will be used to measure predicted scores with observed scores. If high-achieving students who are predicted to succeed in 8th grade algebra are tracked into the less rigorous 9th grade algebra, they are not likely to make their predicted growth .<br /><br />We are moving out of this era, and the pace of change toward identifying student needs using appropriate data is picking up. North Carolina&rsquo;s newly legislated program, Read to Achieve, mandates that reading interventions for students in K-3 be aligned to the literacy skills the students struggle with, and that data be used to determine whether students are struggling with literacy skills. Schools must also keep records for accountability. Although this approach seems logical, it is quite innovative compared with the past reading interventions that targeted the wrong students (North Carolina State Board of Education; Department of Public Instruction, n.d.). <br /><br />Education Grant programs are now requiring that applicants specify what data they will use to identify their target population, and how the intervention relates to helping the participants achieve the program goals. Staff development must relate to delivering the services well, and accountability must show that these things all happened correctly, while documenting progress toward the program objectives. It is a new era. We are not there yet, but it is coming.<br /><br />&nbsp;References<br />Harlow, K., &amp; Baenen, N. (2004). E &amp; R Report No. 04.09: Partnership for Educational Success 2002-03: Implementation and outcomes. Raleigh, NC: Wake County Public School System. Retrieved from http://www.wcpss.net/evaluation-research/reports/2004/0409partnership_edu.pdf<br />KeungHu. (2012). Wake County Superintendent Tony Tata on gains in Algebra I enrollment and proficiency. Retrieved from http://blogs.newsobserver.com/wakeed/wake-county-superintendent-tony-tata-on-gains-in-algebra-i-enrollment-and-proficiency<br />Lougee, A., &amp; Baenen, N. (2008). E &amp; R Report No. 08.07: Advancement Via Individual Determination (AVID): WCPSS Program Evaluation. Retrieved from http://www.wcpss.net/evaluation-research/reports/2008/0807avid.pdf<br />Lougee, A., &amp; Baenen, N. (2009). E&amp;R Report No. 09.27: Accelerated Learning Program (ALP) grades 3-5: Evaluation 2007-08. Retrieved from http://www.wcpss.net/evaluation-research/reports/2009/0927alp3-5_2008.pdf<br />Mayer, A. (2008). Understanding how U.S. secondary schools sort students for instructional purposes: Are all students being served equally? . American Secondary Education , 36(2), 7&ndash;25.<br />North Carolina Department of Public Instruction. (2009). Course and credit requirements. Retrieved from http://www.ncpublicschools.org/curriculum/graduation<br />North Carolina State Board of Education; Department of Public Instruction. (n.d.). North Carolina Read to Achieve: A guide to implementing House Bill 950/S.L. 2012-142 Section 7A. Retrieved from https://eboard.eboardsolutions.com/Meetings/Attachment.aspx?S=10399&amp;AID=11774&amp;MID=783<br />O&rsquo;Connor, C., Lewis, A., &amp; Mueller, J. (2007). Researching &ldquo;Black&rdquo; educational experiences and outcomes: Theoretical and methodological considerations. Educational Researcher. Retrieved from http://www.sociology.emory.edu/downloads/O%5c&rsquo;Connor_Lewis_Mueller_2007_Researching_black_educational_experiences_and_outcomes_theoretical_and_methodological_considerations.pdf<br />Paeplow, C. (2009). E &amp; R Report No. 09.30: Intervention months grades 6-8: Elective results 2008-09. Raleigh, NC: Wake County Public School System. Retrieved from http://www.wcpss.net/evaluation-research/reports/2009/0930imonths6-8.pdf<br />Paeplow, C. (2010). E &amp; R Report No. 10.28: Foundations of Algebra: 2009-10. Raleigh, NC: Wake County Public School System. Retrieved from http://assignment.wcpss.net/results/reports/2011/1028foa2010.pdf<br />Paeplow, C., &amp; Baenen, N. (2006). E &amp; R Report No. 06.09: Evaluation of Supplemental Educational Services at Hodge Road Elementary School 2005-06. Raleigh. Retrieved from http://www.wcpss.net/evaluation-research/reports/2006/0609ses_hodge.pdf<br />Sanders, W. L., Rivers, J. C., Enck, S., Leandro, J. G., &amp; White, J. (2009). Educational Policy Brief: SAS&reg; Response to the &ldquo;WCPSS E &amp; R Comparison of SAS &copy; EVAAS &copy; Results and WCPSS Effectiveness Index Results,&rdquo; Research Watch, E&amp;R Report No. 09.11, March 2009. Cary, NC: SAS. Retrieved from http://content.news14.com/pdf/sas_report.pdf<br />Stone, C. B., &amp; Turba, R. (1999). School counselors using technology for advocacy. Journal of Technology in Counseling. Retrieved from http://jtc.colstate.edu/vol1_1/advocacy.htm<br />U.S. Office of Management and Budget and Federal Agencies. (n.d.). The Program Assessment Rating Tool (PART). Retrieved from http://www.whitehouse.gov/omb/expectmore/part.html<br />U.S. Office of Management and Budget and Federal agencies. (n.d.). Department of Education programs. Retrieved from http://www.whitehouse.gov/omb/expectmore/agency/018.html<br />White House Office of the Press Secretary. (2009). Fact Sheet: The Race to the Top. Washington D.C. Retrieved from http://www.whitehouse.gov/the-press-office/fact-sheet-race-top<br />Wyner, J. S., Bridgeland, J. M., &amp; DiIulio&nbsp; Jr., J. J. (2007). Achievement trap: How America is failing millions of high-achieving students from low-income families. Jack Kent Cooke Foundation, Civic Enterprises, LLC. Retrieved from www.jkcf.org/assets/files/0000/0084/Achievement_Trap.pdf<br />Yonezawa, S., Wells, A. S., &amp; Serna, I. (2002). Choosing tracks:&ldquo;Freedom of choice&rdquo; in detracking schools. American Educational Research Journal , 39(1), 37&ndash;67.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DxFFeJoczRp2rPS2K", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": 49, "extendedScore": null, "score": 0.000177, "legacy": true, "legacyId": "22448", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-04-29T21:00:15.768Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-29T23:14:58.463Z", "modifiedAt": null, "url": null, "title": "New report: Intelligence Explosion Microeconomics", "slug": "new-report-intelligence-explosion-microeconomics", "viewCount": null, "lastCommentedAt": "2018-12-14T14:03:02.495Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CZQuFoqgPXQawH9aL/new-report-intelligence-explosion-microeconomics", "pageUrlRelative": "/posts/CZQuFoqgPXQawH9aL/new-report-intelligence-explosion-microeconomics", "linkUrl": "https://www.lesswrong.com/posts/CZQuFoqgPXQawH9aL/new-report-intelligence-explosion-microeconomics", "postedAtFormatted": "Monday, April 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20report%3A%20Intelligence%20Explosion%20Microeconomics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20report%3A%20Intelligence%20Explosion%20Microeconomics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZQuFoqgPXQawH9aL%2Fnew-report-intelligence-explosion-microeconomics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20report%3A%20Intelligence%20Explosion%20Microeconomics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZQuFoqgPXQawH9aL%2Fnew-report-intelligence-explosion-microeconomics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZQuFoqgPXQawH9aL%2Fnew-report-intelligence-explosion-microeconomics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 984, "htmlBody": "<p><strong>Summary</strong>:&nbsp;<a href=\"http://intelligence.org/files/IEM.pdf\">Intelligence Explosion Microeconomics</a>&nbsp;(pdf) is 40,000 words&nbsp;taking some initial steps toward tackling the key quantitative issue in the intelligence explosion, \"reinvestable returns on cognitive investments\": what kind of returns can you get from an investment in cognition, can you reinvest it to make yourself even smarter, and does this process die out or blow up? This can be thought of as the compact and hopefully more coherent successor to the <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">AI Foom Debate</a> of a few years back.</p>\n<p>(Sample idea you haven't heard before: &nbsp;The increase in hominid brain size over evolutionary time should be interpreted as evidence about increasing marginal fitness returns on brain size, presumably due to improved brain wiring algorithms; not as direct evidence about an intelligence scaling factor from brain size.)</p>\n<p>I hope that the open problems posed therein inspire further work by economists or economically literate modelers, interested specifically in the intelligence explosion <em>qua</em>&nbsp;cognitive intelligence rather than non-cognitive&nbsp;'technological acceleration'. &nbsp;MIRI has an intended-to-be-small-and-technical mailing list for such discussion. &nbsp;In case it's not clear from context, I (Yudkowsky) am the author of the paper.</p>\n<p><strong>Abstract:</strong></p>\n<blockquote>\n<p style=\"padding-left: 30px;\">I. J. Good's thesis of the 'intelligence explosion' is that a sufficiently advanced machine intelligence could build a smarter version of itself, which could in turn build an even smarter version of itself, and that this process could continue enough to vastly exceed human intelligence. &nbsp;As Sandberg (2010) correctly notes, there are several attempts to lay down return-on-investment formulas intended to represent sharp speedups in economic or technological growth, but very little attempt has been made to deal formally with I. J. Good's intelligence explosion thesis as such.</p>\n<p style=\"padding-left: 30px;\">I identify the key issue as <em>returns on cognitive reinvestment</em> - the ability to invest more computing power, faster computers, or improved cognitive algorithms to yield cognitive labor which produces larger brains, faster brains, or better mind designs. &nbsp;There are many phenomena in the world which have been argued as evidentially relevant to this question, from the observed course of hominid evolution, to Moore's Law, to the competence over time of machine chess-playing systems, and many more. &nbsp;I go into some depth on the sort of debates which then arise on how to interpret such evidence. &nbsp;I propose that the next step forward in analyzing positions on the intelligence explosion would be to formalize return-on-investment curves, so that each stance can say formally which possible microfoundations they hold to be falsified by historical observations already made. &nbsp;More generally, I pose multiple open questions of 'returns on cognitive reinvestment' or 'intelligence explosion microeconomics'. &nbsp;Although such questions have received little attention thus far, they seem highly relevant to policy choices affecting the outcomes for Earth-originating intelligent life.</p>\n</blockquote>\n<p>The <a href=\"https://docs.google.com/forms/d/1KElE2Zt_XQRqj8vWrc_rG89nrO4JtHWxIFldJ3IY_FQ/viewform\"><strong>dedicated mailing list</strong></a>&nbsp;will be small and restricted to technical discussants.<a id=\"more\"></a></p>\n<p>This topic was originally intended to be a sequence in&nbsp;<em>Open Problems in Friendly AI,</em>&nbsp;but further work produced something compacted beyond where it could be easily broken up into subposts.</p>\n<p><strong>Outline of contents:</strong></p>\n<p><strong>1</strong>: &nbsp;Introduces the basic questions and the key quantitative issue of sustained reinvestable returns on cognitive investments.</p>\n<p><strong>2</strong>: &nbsp;Discusses the basic language for talking about the intelligence explosion, and argues that we should pursue this project by looking for underlying microfoundations, not by pursuing analogies to allegedly similar historical events.</p>\n<p><strong>3</strong>: &nbsp;Goes into detail on what I see as the main arguments for a fast intelligence explosion, constituting the bulk of the paper with the following subsections:</p>\n<ul>\n<li><strong>3.1</strong>:<span style=\"white-space: pre;\"> </span>What the fossil record actually tells us about returns on brain size, given that most of the difference between Homo sapiens and Australopithecus was probably improved software.</li>\n<li><strong>3.2</strong>:<span style=\"white-space: pre;\"> </span>How to divide credit for the human-chimpanzee performance gap between \"humans are individually smarter than chimpanzees\" and \"the hominid transition involved a one-time qualitative gain from being able to accumulate knowledge\".</li>\n<li><strong>3.3</strong>:<span style=\"white-space: pre;\"> </span>How returns on speed (serial causal depth) contrast with returns from parallelism; how faster thought seems to contrast with more thought. &nbsp;Whether sensing and manipulating technologies are likely to present a bottleneck for faster thinkers, or how large of a bottleneck.</li>\n<li><strong>3.4</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>How human populations seem to scale in problem-solving power; some reasons to believe that we scale inefficiently enough for it to be puzzling. &nbsp;Garry Kasparov's chess match vs. The World, which Kasparov won.</li>\n<li><strong>3.5</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>Some inefficiencies that might cumulate in an estimate of humanity's net computational efficiency on a cognitive problem.</li>\n<li><strong>3.6</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>What the anthropological record actually tells us about cognitive returns on cumulative selection pressure, given that selection pressures were probably increasing over the course of hominid history. &nbsp;How the observed history would be expected to look different, if there were in fact diminishing returns on cognition.</li>\n<li><strong>3.7</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>How to relate the curves for evolutionary difficulty, human-engineering difficulty, and AI-engineering difficulty, considering that they are almost certainly different.</li>\n<li><strong>3.8</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>Correcting for anthropic bias in trying to estimate the intrinsic 'difficulty 'of hominid-level intelligence just from observing that intelligence evolved here on Earth.</li>\n<li><strong>3.9</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>The question of whether to expect a 'local' (one-project) FOOM or 'global' (whole economy) FOOM and how returns on cognitive reinvestment interact with that.</li>\n<li><strong>3.10</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>The great open uncertainty about the minimal conditions for starting a FOOM; why I. J. Good's postulate of starting from 'ultraintelligence' is probably much too strong (sufficient, but very far above what is necessary).</li>\n<li><strong>3.11</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>The enhanced probability of unknown unknowns in the scenario, since a smarter-than-human intelligence will selectively seek out and exploit flaws or gaps in our current knowledge.</li>\n</ul>\n<p><strong>4</strong>: &nbsp;A tentative methodology for formalizing theories of the intelligence explosion - a project of formalizing possible microfoundations and explicitly stating their alleged relation to historical experience, such that some possibilities can allegedly be falsified.</p>\n<p><strong>5</strong>: &nbsp;Which open sub-questions seem both high-value and possibly answerable.</p>\n<p><strong>6</strong>: &nbsp;Formally poses the Open Problem and mentions what it would take for MIRI itself to directly fund further work in this field.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 2, "oiRp4T6u5poc8r9Tj": 13, "ksdiAMKfgSyEeKMo6": 2, "5f5c37ee1b5cdee568cfb1be": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CZQuFoqgPXQawH9aL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 49, "baseScore": 72, "extendedScore": null, "score": 0.000164, "legacy": true, "legacyId": "22441", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 47, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Summary</strong>:&nbsp;<a href=\"http://intelligence.org/files/IEM.pdf\">Intelligence Explosion Microeconomics</a>&nbsp;(pdf) is 40,000 words&nbsp;taking some initial steps toward tackling the key quantitative issue in the intelligence explosion, \"reinvestable returns on cognitive investments\": what kind of returns can you get from an investment in cognition, can you reinvest it to make yourself even smarter, and does this process die out or blow up? This can be thought of as the compact and hopefully more coherent successor to the <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">AI Foom Debate</a> of a few years back.</p>\n<p>(Sample idea you haven't heard before: &nbsp;The increase in hominid brain size over evolutionary time should be interpreted as evidence about increasing marginal fitness returns on brain size, presumably due to improved brain wiring algorithms; not as direct evidence about an intelligence scaling factor from brain size.)</p>\n<p>I hope that the open problems posed therein inspire further work by economists or economically literate modelers, interested specifically in the intelligence explosion <em>qua</em>&nbsp;cognitive intelligence rather than non-cognitive&nbsp;'technological acceleration'. &nbsp;MIRI has an intended-to-be-small-and-technical mailing list for such discussion. &nbsp;In case it's not clear from context, I (Yudkowsky) am the author of the paper.</p>\n<p><strong id=\"Abstract_\">Abstract:</strong></p>\n<blockquote>\n<p style=\"padding-left: 30px;\">I. J. Good's thesis of the 'intelligence explosion' is that a sufficiently advanced machine intelligence could build a smarter version of itself, which could in turn build an even smarter version of itself, and that this process could continue enough to vastly exceed human intelligence. &nbsp;As Sandberg (2010) correctly notes, there are several attempts to lay down return-on-investment formulas intended to represent sharp speedups in economic or technological growth, but very little attempt has been made to deal formally with I. J. Good's intelligence explosion thesis as such.</p>\n<p style=\"padding-left: 30px;\">I identify the key issue as <em>returns on cognitive reinvestment</em> - the ability to invest more computing power, faster computers, or improved cognitive algorithms to yield cognitive labor which produces larger brains, faster brains, or better mind designs. &nbsp;There are many phenomena in the world which have been argued as evidentially relevant to this question, from the observed course of hominid evolution, to Moore's Law, to the competence over time of machine chess-playing systems, and many more. &nbsp;I go into some depth on the sort of debates which then arise on how to interpret such evidence. &nbsp;I propose that the next step forward in analyzing positions on the intelligence explosion would be to formalize return-on-investment curves, so that each stance can say formally which possible microfoundations they hold to be falsified by historical observations already made. &nbsp;More generally, I pose multiple open questions of 'returns on cognitive reinvestment' or 'intelligence explosion microeconomics'. &nbsp;Although such questions have received little attention thus far, they seem highly relevant to policy choices affecting the outcomes for Earth-originating intelligent life.</p>\n</blockquote>\n<p>The <a href=\"https://docs.google.com/forms/d/1KElE2Zt_XQRqj8vWrc_rG89nrO4JtHWxIFldJ3IY_FQ/viewform\"><strong>dedicated mailing list</strong></a>&nbsp;will be small and restricted to technical discussants.<a id=\"more\"></a></p>\n<p>This topic was originally intended to be a sequence in&nbsp;<em>Open Problems in Friendly AI,</em>&nbsp;but further work produced something compacted beyond where it could be easily broken up into subposts.</p>\n<p><strong id=\"Outline_of_contents_\">Outline of contents:</strong></p>\n<p><strong>1</strong>: &nbsp;Introduces the basic questions and the key quantitative issue of sustained reinvestable returns on cognitive investments.</p>\n<p><strong>2</strong>: &nbsp;Discusses the basic language for talking about the intelligence explosion, and argues that we should pursue this project by looking for underlying microfoundations, not by pursuing analogies to allegedly similar historical events.</p>\n<p><strong>3</strong>: &nbsp;Goes into detail on what I see as the main arguments for a fast intelligence explosion, constituting the bulk of the paper with the following subsections:</p>\n<ul>\n<li><strong>3.1</strong>:<span style=\"white-space: pre;\"> </span>What the fossil record actually tells us about returns on brain size, given that most of the difference between Homo sapiens and Australopithecus was probably improved software.</li>\n<li><strong>3.2</strong>:<span style=\"white-space: pre;\"> </span>How to divide credit for the human-chimpanzee performance gap between \"humans are individually smarter than chimpanzees\" and \"the hominid transition involved a one-time qualitative gain from being able to accumulate knowledge\".</li>\n<li><strong>3.3</strong>:<span style=\"white-space: pre;\"> </span>How returns on speed (serial causal depth) contrast with returns from parallelism; how faster thought seems to contrast with more thought. &nbsp;Whether sensing and manipulating technologies are likely to present a bottleneck for faster thinkers, or how large of a bottleneck.</li>\n<li><strong>3.4</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>How human populations seem to scale in problem-solving power; some reasons to believe that we scale inefficiently enough for it to be puzzling. &nbsp;Garry Kasparov's chess match vs. The World, which Kasparov won.</li>\n<li><strong>3.5</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>Some inefficiencies that might cumulate in an estimate of humanity's net computational efficiency on a cognitive problem.</li>\n<li><strong>3.6</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>What the anthropological record actually tells us about cognitive returns on cumulative selection pressure, given that selection pressures were probably increasing over the course of hominid history. &nbsp;How the observed history would be expected to look different, if there were in fact diminishing returns on cognition.</li>\n<li><strong>3.7</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>How to relate the curves for evolutionary difficulty, human-engineering difficulty, and AI-engineering difficulty, considering that they are almost certainly different.</li>\n<li><strong>3.8</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>Correcting for anthropic bias in trying to estimate the intrinsic 'difficulty 'of hominid-level intelligence just from observing that intelligence evolved here on Earth.</li>\n<li><strong>3.9</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>The question of whether to expect a 'local' (one-project) FOOM or 'global' (whole economy) FOOM and how returns on cognitive reinvestment interact with that.</li>\n<li><strong>3.10</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>The great open uncertainty about the minimal conditions for starting a FOOM; why I. J. Good's postulate of starting from 'ultraintelligence' is probably much too strong (sufficient, but very far above what is necessary).</li>\n<li><strong>3.11</strong>:&nbsp;<span style=\"white-space: pre;\"> </span>The enhanced probability of unknown unknowns in the scenario, since a smarter-than-human intelligence will selectively seek out and exploit flaws or gaps in our current knowledge.</li>\n</ul>\n<p><strong>4</strong>: &nbsp;A tentative methodology for formalizing theories of the intelligence explosion - a project of formalizing possible microfoundations and explicitly stating their alleged relation to historical experience, such that some possibilities can allegedly be falsified.</p>\n<p><strong>5</strong>: &nbsp;Which open sub-questions seem both high-value and possibly answerable.</p>\n<p><strong>6</strong>: &nbsp;Formally poses the Open Problem and mentions what it would take for MIRI itself to directly fund further work in this field.</p>", "sections": [{"title": "Abstract:", "anchor": "Abstract_", "level": 1}, {"title": "Outline of contents:", "anchor": "Outline_of_contents_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "246 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 251, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-30T02:12:51.663Z", "modifiedAt": null, "url": null, "title": "[Link] Caplan asks for help optimizing his will.", "slug": "link-caplan-asks-for-help-optimizing-his-will", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:09.261Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jayson_Virissimo", "createdAt": "2009-03-13T06:51:41.976Z", "isAdmin": false, "displayName": "Jayson_Virissimo"}, "userId": "zwzw5ALJYG47kDek8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cabyTE5KLEGSxZSqT/link-caplan-asks-for-help-optimizing-his-will", "pageUrlRelative": "/posts/cabyTE5KLEGSxZSqT/link-caplan-asks-for-help-optimizing-his-will", "linkUrl": "https://www.lesswrong.com/posts/cabyTE5KLEGSxZSqT/link-caplan-asks-for-help-optimizing-his-will", "postedAtFormatted": "Tuesday, April 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Caplan%20asks%20for%20help%20optimizing%20his%20will.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Caplan%20asks%20for%20help%20optimizing%20his%20will.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcabyTE5KLEGSxZSqT%2Flink-caplan-asks-for-help-optimizing-his-will%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Caplan%20asks%20for%20help%20optimizing%20his%20will.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcabyTE5KLEGSxZSqT%2Flink-caplan-asks-for-help-optimizing-his-will", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcabyTE5KLEGSxZSqT%2Flink-caplan-asks-for-help-optimizing-his-will", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Bryan_Caplan\">Bryan Caplan</a> of <a href=\"http://econlog.econlib.org/\">Econlog</a> asks his readers how to improve his will (given a few constraints) in light of the principles of <a href=\"http://wiki.lesswrong.com/wiki/Optimal_philanthropy\">optimal philanthropy</a>. His current draft reads:</p>\n<blockquote>\n<p>I give and bequeath to whatever charity is currently ranked #1 by GiveWell, the sum of $100,000 adjusted for inflation since 2013 using the U.S. Consumer Price Index, or 10% of the total value of my estate excluding our primary residence, whichever is smaller.<span style=\"mso-spacerun: yes;\">&nbsp; </span>If GiveWell no longer exists, I give and bequeath the same sum to another charity, selected by my wife and children, dedicated to helping the deserving poor in the Third World in a maximally cost-effective manner.<span style=\"mso-spacerun: yes;\">&nbsp; </span>I request that my wife and children consult my friends Robin Hanson, Alexander Tabarrok, Fabio Rojas, James Schneider, Michael Huemer, William Dickens, and Jason Brennan to help them select the most cost-effective charity with this mission.<span style=\"mso-spacerun: yes;\">&nbsp; </span>If possible, funding for this bequest should come from my tax-deferred 403(b) retirement accounts.</p>\n</blockquote>\n<p>The full blog post can be found <a href=\"http://econlog.econlib.org/archives/2013/04/a_supererogator.html\">here</a>.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Robin_Hanson\">Robin Hanson</a> responds:</p>\n<blockquote>\n<p>I fear \"the Third World\" might not be a robust reference, and that GiveWell will no longer exist. You might pick some \"ex ante % chance that I'd have died by now\", such as 25%, and give the money away when you are at an age where you've suffered that % chance. This could ensure at 75% chance that you'll give the money away yourself.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cabyTE5KLEGSxZSqT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 6, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "22449", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-30T05:00:52.033Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Bystander Apathy", "slug": "seq-rerun-bystander-apathy", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rPWgyidXPhKokjsCx/seq-rerun-bystander-apathy", "pageUrlRelative": "/posts/rPWgyidXPhKokjsCx/seq-rerun-bystander-apathy", "linkUrl": "https://www.lesswrong.com/posts/rPWgyidXPhKokjsCx/seq-rerun-bystander-apathy", "postedAtFormatted": "Tuesday, April 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Bystander%20Apathy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Bystander%20Apathy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPWgyidXPhKokjsCx%2Fseq-rerun-bystander-apathy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Bystander%20Apathy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPWgyidXPhKokjsCx%2Fseq-rerun-bystander-apathy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPWgyidXPhKokjsCx%2Fseq-rerun-bystander-apathy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 170, "htmlBody": "<p>Today's post, <a href=\"/lw/9j/bystander_apathy/\">Bystander Apathy</a> was originally published on 13 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries#Bystander_Apathy\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The bystander effect is when groups of people are less likely to take action than an individual. There are a few explanations for why this might be the case.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/ha6/seq_rerun_akrasia_and_shangrila/\">Akrasia and Shangri-La</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb150": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rPWgyidXPhKokjsCx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 1.184258370127183e-06, "legacy": true, "legacyId": "22450", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K5nq3KcDXaGm7QQWR", "LiNzGXW576G8iSz9N", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-30T13:02:27.212Z", "modifiedAt": null, "url": null, "title": "Meetup : Big Gaming Fun 6: A New Beginning!", "slug": "meetup-big-gaming-fun-6-a-new-beginning", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:09.118Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kenoubi", "createdAt": "2011-03-12T04:07:00.560Z", "isAdmin": false, "displayName": "Kenoubi"}, "userId": "DgrXt6eQMpunHRDXh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QYSFkoCEChEJhooH4/meetup-big-gaming-fun-6-a-new-beginning", "pageUrlRelative": "/posts/QYSFkoCEChEJhooH4/meetup-big-gaming-fun-6-a-new-beginning", "linkUrl": "https://www.lesswrong.com/posts/QYSFkoCEChEJhooH4/meetup-big-gaming-fun-6-a-new-beginning", "postedAtFormatted": "Tuesday, April 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Big%20Gaming%20Fun%206%3A%20A%20New%20Beginning!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Big%20Gaming%20Fun%206%3A%20A%20New%20Beginning!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQYSFkoCEChEJhooH4%2Fmeetup-big-gaming-fun-6-a-new-beginning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Big%20Gaming%20Fun%206%3A%20A%20New%20Beginning!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQYSFkoCEChEJhooH4%2Fmeetup-big-gaming-fun-6-a-new-beginning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQYSFkoCEChEJhooH4%2Fmeetup-big-gaming-fun-6-a-new-beginning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 213, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m7'>Big Gaming Fun 6: A New Beginning!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 May 2013 01:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">100 East End Ave., Pittsburgh, PA 15221</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Come match wits against others who value believing the truth and acting effectively to achieve their goals! Now revived after I spent 2.5 months in Switzerland and 4 months being super busy moving into my new house.</p>\n\n<p>You can see my game collection <a href=\"http://boardgamegeek.com/collection/user/Kenoubi?own=1\" rel=\"nofollow\">here</a>; please bring anything else you'd like to play.</p>\n\n<p>I have a cat. Please let me know if you're allergic and need me to put her upstairs.</p>\n\n<p>RSVP here or by sending me a private message (but don't not show up because you didn't RSVP, I just want a rough idea of the number of attendees). The door should be unlocked and there should be a sign up when you arrive; if not, call or text (412) 657-1395 when you get here. I intend to hold these every 2-3 weeks, so watch this space!</p>\n\n<p>Also, if transportation is an issue, please post a comment or send me a PM. I'm on the bus line, I might be able to pick a small number of people up, or maybe a fellow attendee can give you a ride.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m7'>Big Gaming Fun 6: A New Beginning!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QYSFkoCEChEJhooH4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1845996699223166e-06, "legacy": true, "legacyId": "22451", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Big_Gaming_Fun_6__A_New_Beginning_\">Discussion article for the meetup : <a href=\"/meetups/m7\">Big Gaming Fun 6: A New Beginning!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 May 2013 01:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">100 East End Ave., Pittsburgh, PA 15221</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Come match wits against others who value believing the truth and acting effectively to achieve their goals! Now revived after I spent 2.5 months in Switzerland and 4 months being super busy moving into my new house.</p>\n\n<p>You can see my game collection <a href=\"http://boardgamegeek.com/collection/user/Kenoubi?own=1\" rel=\"nofollow\">here</a>; please bring anything else you'd like to play.</p>\n\n<p>I have a cat. Please let me know if you're allergic and need me to put her upstairs.</p>\n\n<p>RSVP here or by sending me a private message (but don't not show up because you didn't RSVP, I just want a rough idea of the number of attendees). The door should be unlocked and there should be a sign up when you arrive; if not, call or text (412) 657-1395 when you get here. I intend to hold these every 2-3 weeks, so watch this space!</p>\n\n<p>Also, if transportation is an issue, please post a comment or send me a PM. I'm on the bus line, I might be able to pick a small number of people up, or maybe a fellow attendee can give you a ride.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Big_Gaming_Fun_6__A_New_Beginning_1\">Discussion article for the meetup : <a href=\"/meetups/m7\">Big Gaming Fun 6: A New Beginning!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Big Gaming Fun 6: A New Beginning!", "anchor": "Discussion_article_for_the_meetup___Big_Gaming_Fun_6__A_New_Beginning_", "level": 1}, {"title": "Discussion article for the meetup : Big Gaming Fun 6: A New Beginning!", "anchor": "Discussion_article_for_the_meetup___Big_Gaming_Fun_6__A_New_Beginning_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-30T13:06:54.723Z", "modifiedAt": null, "url": null, "title": "Meetup : Buffalo LW Sunday Meetup", "slug": "meetup-buffalo-lw-sunday-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "StonesOnCanvas", "createdAt": "2012-06-28T17:32:49.237Z", "isAdmin": false, "displayName": "StonesOnCanvas"}, "userId": "FAfkKGH6E8BLmXW4M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5jbLqcbpEHEsiX3o5/meetup-buffalo-lw-sunday-meetup", "pageUrlRelative": "/posts/5jbLqcbpEHEsiX3o5/meetup-buffalo-lw-sunday-meetup", "linkUrl": "https://www.lesswrong.com/posts/5jbLqcbpEHEsiX3o5/meetup-buffalo-lw-sunday-meetup", "postedAtFormatted": "Tuesday, April 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Buffalo%20LW%20Sunday%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Buffalo%20LW%20Sunday%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jbLqcbpEHEsiX3o5%2Fmeetup-buffalo-lw-sunday-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Buffalo%20LW%20Sunday%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jbLqcbpEHEsiX3o5%2Fmeetup-buffalo-lw-sunday-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5jbLqcbpEHEsiX3o5%2Fmeetup-buffalo-lw-sunday-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 127, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m8'>Buffalo LW Sunday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 May 2013 04:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">University at Buffalo - North Campus 31 Capen Hall, Buffalo, NY</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Buffalo-area Less Wrong meetups on the first Sunday and Third Thursday of every month, in 31 Capen Hall at the University at Buffalo - North Campus.</p>\n\n<p>Hey Guys, \nToday we'll try some practice with Fermi Estimates. Primary Purpose: Sometimes you will have to make decisions without perfect data and having a way to get a decent ballpark approximation can be good enough to help you decide. Secondary Goal: Keep track of how confident we are in our predictions so that we can make our confidence match more closely with our true accuracy.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m8'>Buffalo LW Sunday Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5jbLqcbpEHEsiX3o5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1846028304588178e-06, "legacy": true, "legacyId": "22452", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Buffalo_LW_Sunday_Meetup\">Discussion article for the meetup : <a href=\"/meetups/m8\">Buffalo LW Sunday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 May 2013 04:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">University at Buffalo - North Campus 31 Capen Hall, Buffalo, NY</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Buffalo-area Less Wrong meetups on the first Sunday and Third Thursday of every month, in 31 Capen Hall at the University at Buffalo - North Campus.</p>\n\n<p>Hey Guys, \nToday we'll try some practice with Fermi Estimates. Primary Purpose: Sometimes you will have to make decisions without perfect data and having a way to get a decent ballpark approximation can be good enough to help you decide. Secondary Goal: Keep track of how confident we are in our predictions so that we can make our confidence match more closely with our true accuracy.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Buffalo_LW_Sunday_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/m8\">Buffalo LW Sunday Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Buffalo LW Sunday Meetup", "anchor": "Discussion_article_for_the_meetup___Buffalo_LW_Sunday_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Buffalo LW Sunday Meetup", "anchor": "Discussion_article_for_the_meetup___Buffalo_LW_Sunday_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-30T16:18:04.955Z", "modifiedAt": null, "url": null, "title": "Meetup :  Group Decision Making (the good, the bad, and the confusion of welfare economics)", "slug": "meetup-group-decision-making-the-good-the-bad-and-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:20.819Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Davidmanheim", "createdAt": "2011-01-18T15:14:54.315Z", "isAdmin": false, "displayName": "Davidmanheim"}, "userId": "DiHrY9qMta2m6MvxJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pCHScZFWgNcMLJdaS/meetup-group-decision-making-the-good-the-bad-and-the", "pageUrlRelative": "/posts/pCHScZFWgNcMLJdaS/meetup-group-decision-making-the-good-the-bad-and-the", "linkUrl": "https://www.lesswrong.com/posts/pCHScZFWgNcMLJdaS/meetup-group-decision-making-the-good-the-bad-and-the", "postedAtFormatted": "Tuesday, April 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%20Group%20Decision%20Making%20(the%20good%2C%20the%20bad%2C%20and%20the%20confusion%20of%20welfare%20economics)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%20Group%20Decision%20Making%20(the%20good%2C%20the%20bad%2C%20and%20the%20confusion%20of%20welfare%20economics)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCHScZFWgNcMLJdaS%2Fmeetup-group-decision-making-the-good-the-bad-and-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%20Group%20Decision%20Making%20(the%20good%2C%20the%20bad%2C%20and%20the%20confusion%20of%20welfare%20economics)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCHScZFWgNcMLJdaS%2Fmeetup-group-decision-making-the-good-the-bad-and-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpCHScZFWgNcMLJdaS%2Fmeetup-group-decision-making-the-good-the-bad-and-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 275, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/m9'> Group Decision Making (the good, the bad, and the confusion of welfare economics)</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">08 May 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">West Los Angeles (At the Westside Tavern Upstair Wine Bar)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Where: The Westside Tavern in the upstairs Wine Bar (all ages welcome), located inside the Westside Pavillion on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p>Parking is free for 3 hours</p>\n\n<p>Or you can take a Public Transit! A Trip Planner can be found here: <a href=\"http://socaltransport.org/tm_pub_start.php\" rel=\"nofollow\">http://socaltransport.org/tm_pub_start.php</a> &lt;- So you can try to avoid multiple hour trips! (We appreciate your attendance despite length of commute!)</p>\n\n<p>We will hang out for 30 minutes or so, then I'll spend 10-15 minutes presenting:\nGroup decision making.\nAKA\nWhy voting can be a stupid way to make utility decisions,\nAKA\nAdding utility between people is stupid, this is an ordinal scale\nAKA\nDidn't Arrow win a Nobel prize for telling you people to stop?</p>\n\n<p>Then we'll talk about what math and economics can say about making collective decisions in a way that isn't ill defined, and continue a hopefully interesting discussion. (Bonus points if it leads to a publishable idea for me!)</p>\n\n<p>This will be a great break for me from... writing papers and taking tests about the same subject.</p>\n\n<p>No foreknowledge or exposure to Less Wrong is necessary; this will be generally accessible and useful to anyone who values thinking for themselves. That said, it might help to read <a href=\"http://lesswrong.com/lw/ggm/pinpointing_utility/\" rel=\"nofollow\">http://lesswrong.com/lw/ggm/pinpointing_utility/</a> so we can avoid type errors and radiation poisoning while we talk. (Not real radiation poisoning!)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/m9'> Group Decision Making (the good, the bad, and the confusion of welfare economics)</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pCHScZFWgNcMLJdaS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.1847383617196055e-06, "legacy": true, "legacyId": "22454", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Group_Decision_Making__the_good__the_bad__and_the_confusion_of_welfare_economics_\">Discussion article for the meetup : <a href=\"/meetups/m9\"> Group Decision Making (the good, the bad, and the confusion of welfare economics)</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">08 May 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">West Los Angeles (At the Westside Tavern Upstair Wine Bar)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Where: The Westside Tavern in the upstairs Wine Bar (all ages welcome), located inside the Westside Pavillion on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p>Parking is free for 3 hours</p>\n\n<p>Or you can take a Public Transit! A Trip Planner can be found here: <a href=\"http://socaltransport.org/tm_pub_start.php\" rel=\"nofollow\">http://socaltransport.org/tm_pub_start.php</a> &lt;- So you can try to avoid multiple hour trips! (We appreciate your attendance despite length of commute!)</p>\n\n<p>We will hang out for 30 minutes or so, then I'll spend 10-15 minutes presenting:\nGroup decision making.\nAKA\nWhy voting can be a stupid way to make utility decisions,\nAKA\nAdding utility between people is stupid, this is an ordinal scale\nAKA\nDidn't Arrow win a Nobel prize for telling you people to stop?</p>\n\n<p>Then we'll talk about what math and economics can say about making collective decisions in a way that isn't ill defined, and continue a hopefully interesting discussion. (Bonus points if it leads to a publishable idea for me!)</p>\n\n<p>This will be a great break for me from... writing papers and taking tests about the same subject.</p>\n\n<p>No foreknowledge or exposure to Less Wrong is necessary; this will be generally accessible and useful to anyone who values thinking for themselves. That said, it might help to read <a href=\"http://lesswrong.com/lw/ggm/pinpointing_utility/\" rel=\"nofollow\">http://lesswrong.com/lw/ggm/pinpointing_utility/</a> so we can avoid type errors and radiation poisoning while we talk. (Not real radiation poisoning!)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Group_Decision_Making__the_good__the_bad__and_the_confusion_of_welfare_economics_1\">Discussion article for the meetup : <a href=\"/meetups/m9\"> Group Decision Making (the good, the bad, and the confusion of welfare economics)</a></h2>", "sections": [{"title": "Discussion article for the meetup :  Group Decision Making (the good, the bad, and the confusion of welfare economics)", "anchor": "Discussion_article_for_the_meetup____Group_Decision_Making__the_good__the_bad__and_the_confusion_of_welfare_economics_", "level": 1}, {"title": "Discussion article for the meetup :  Group Decision Making (the good, the bad, and the confusion of welfare economics)", "anchor": "Discussion_article_for_the_meetup____Group_Decision_Making__the_good__the_bad__and_the_confusion_of_welfare_economics_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CQkGJ2t5Rw8GcZKJm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-04-30T18:11:13.901Z", "modifiedAt": null, "url": null, "title": "[LINK] The Unbelievers: Lawrence Krauss and Richard Dawkins Team Up Against Religion", "slug": "link-the-unbelievers-lawrence-krauss-and-richard-dawkins", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:32.328Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RszjQZFw42gqrNchA/link-the-unbelievers-lawrence-krauss-and-richard-dawkins", "pageUrlRelative": "/posts/RszjQZFw42gqrNchA/link-the-unbelievers-lawrence-krauss-and-richard-dawkins", "linkUrl": "https://www.lesswrong.com/posts/RszjQZFw42gqrNchA/link-the-unbelievers-lawrence-krauss-and-richard-dawkins", "postedAtFormatted": "Tuesday, April 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20The%20Unbelievers%3A%20Lawrence%20Krauss%20and%20Richard%20Dawkins%20Team%20Up%20Against%20Religion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20The%20Unbelievers%3A%20Lawrence%20Krauss%20and%20Richard%20Dawkins%20Team%20Up%20Against%20Religion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRszjQZFw42gqrNchA%2Flink-the-unbelievers-lawrence-krauss-and-richard-dawkins%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20The%20Unbelievers%3A%20Lawrence%20Krauss%20and%20Richard%20Dawkins%20Team%20Up%20Against%20Religion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRszjQZFw42gqrNchA%2Flink-the-unbelievers-lawrence-krauss-and-richard-dawkins", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRszjQZFw42gqrNchA%2Flink-the-unbelievers-lawrence-krauss-and-richard-dawkins", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 834, "htmlBody": "<p><span style=\"font-family: Garuda, Verdana, Geneva, sans-serif; font-size: 12px; line-height: 1.5;\">I am looking forward to watching </span><a style=\"font-family: Garuda, Verdana, Geneva, sans-serif; font-size: 12px; line-height: 1.5;\" href=\"http://unbelieversmovie.com/\">this documentary</a><span style=\"font-family: Garuda, Verdana, Geneva, sans-serif; font-size: 12px; line-height: 1.5;\"> for entertainment purposes, but I don't expect it to affect people's opinions about religion much.</span></p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; font-size: 12px; vertical-align: baseline; line-height: 1.5; font-family: Garuda, Verdana, Geneva, sans-serif;\">I have no doubt that both <a href=\"http://en.wikipedia.org/wiki/Lawrence_M._Krauss\">Krauss</a> and Dawkins are very bright and insightful people. However, here is a piece of an <a href=\"http://www.theglobeandmail.com/news/national/richard-dawkins-and-lawrence-krauss-double-down-on-disbelief/article11624891/\">interview</a> I found somewhat naive:</p>\n<p style=\"margin: 0px 0px 20px; padding: 0px 0px 0px 30px; border: 0px; outline: 0px; font-size: 12px; vertical-align: baseline; line-height: 1.5; font-family: Garuda, Verdana, Geneva, sans-serif;\">\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; line-height: 1.5;\"><strong style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">Do you foresee a time when the conversation will be over?</strong></p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; line-height: 1.5;\"><strong style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">LK:</strong>&nbsp;I think it&rsquo;s frustrating. When I was a kid in the &rsquo;60s, I was sure that by now there would be no religion. In a way it&rsquo;s very surprising that there are these momentary resurgences. I think it&rsquo;s going to be a long road.</p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; line-height: 1.5;\"><strong style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">RD:</strong>&nbsp;If you look at the broad sweep of history, then clearly we&rsquo;re on the winning side. I think things are moving in the right direction, probably not as fast as I would like to see.</p>\n</p>\n<p style=\"margin: 0px 0px 20px; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; border: 0px; outline: 0px; font-size: 12px; vertical-align: baseline; line-height: 1.5; font-family: Garuda, Verdana, Geneva, sans-serif;\">Both of them seem to tacitly assume that religion ought to eventually yield to scientific progress and such.&nbsp;<span style=\"line-height: 1.5;\">While this may be the overall trend in the West, or at least in the US, it has not necessarily been so elsewhere. I am somewhat surprised that the two rather bright guys seem to have these rose-colored glasses on.</span></p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; font-size: 12px; vertical-align: baseline; line-height: 1.5; font-family: Garuda, Verdana, Geneva, sans-serif;\"><span style=\"line-height: 1.5;\">The current and ex-Communist states are the most stark example. In the Soviet Union religion was marginalized for some 70 years, two generations grew up in the environment of state atheism, yet soon after the restrictions were relaxed, the Church has regained almost all of the lost ground. The situation was similar in the rest of the ex-Warsaw bloc (with less time under mandated atheism), and even in China, where the equilibrium was restored after the Cultural Revolution. The standard argument for this happening is \"but Communism was basically a religion by another name\", what with the various Cults of Personality and the beliefs in the One True Path.</span></p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; font-size: 12px; vertical-align: baseline; line-height: 1.5; font-family: Garuda, Verdana, Geneva, sans-serif;\">This argument seems convincing on the surface, but consider a similar situation transplanted into a US setting. Suppose that, for whatever reason, after the Civil war religion was abolished all across the country together with slavery. Overtly religious activities are frowned upon and marginalized by the authorities. The community organizations like the Y, the Salvation Army, the Scouts and others do all the same work, only without mentioning God, or maybe replacing it with some secular symbol, like the Motherland/Fatherland/Abe Lincoln/Capitalism/Free Enterprise, whichever. The movie <a href=\"http://en.wikipedia.org/wiki/The_Invention_of_Lying\">The Invention of Lying</a> alluded to a similar setup.</p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline;\"><span style=\"font-family: Garuda, Verdana, Geneva, sans-serif;\"><span style=\"font-size: 12px; line-height: 1.5;\">Furthermore, imagine your parents and grandparents not attending any church, not taking you to the Sunday school to learn about Christ dying for your sins. They are still fervently patriotic and proud of the great achievements of your country, they wave the Flag and they are distrustful of the world outside it, but none of it has religious overtones. No one bothered to add \"under God\" to the Pledge of&nbsp;</span><span style=\"font-size: 12px; line-height: 18px;\">Allegiance.</span><span style=\"font-size: 12px; line-height: 1.5;\">&nbsp;All the regular prejudices are still in place, like racism, homophobia (only without any religious references), misogyny etc. Sex education is in the same awful state. Again, this is how things were or still are in the former Eastern Bloc countries, so it's not much of a stretch. People still have their superstitions, like Friday 13, black cats, umbrellas and what not. </span></span></p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline;\"><span style=\"font-family: Garuda, Verdana, Geneva, sans-serif;\"><span style=\"font-size: 12px; line-height: 1.5;\">Science is respected, the Darwin's theory of evolution is accepted as much as the Newton's theory of gravitation and taught at school without any controversy. No Creationism. No one pays much attention to promoting atheism, because it's the obvious default position. No explicit training in Rationality beyond the usual lousy Critical Thinking courses. There are still churches, mosques, synagogues and temples, but they are mostly cultural objects, though some are active, enough to satisfy the needs of the tiny minority of believers.&nbsp;</span></span></p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline;\">A setup like that would be a dream come true for Dawkins and Co., wouldn't it? Then something bad happens. Say, the Great Depression all over again, or worse. The federal government loses all credibility and collapses, and the state governments follow suit (maybe there was some big conspiracy uncovered, or something). No social safety net, no Medicare, no jobs. Ordinary people barely scrape by to survive. What would you expect to happen religion-wise? Someone like Dawkins would probably anticipate a surge in observance, since \"there are no atheists in foxholes\", followed by a relaxation to the default state once things improve again, as they usually do.&nbsp;</p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline;\">Instead, what is likely to happen, if the experience of other countries is any indication, is the proliferation of religious beliefs and institutions, maybe institutionalizing of one dominant religion, as the leaders look for something to unite the people. And this elevated status of religion becomes the new <em>status quo.</em>&nbsp;It is not clear which way it goes from there, but there is certainly no guarantee that Atheism ought to win out, no more than there is a guarantee that Free Enterprise wins out, or that the Dictatorship of the Proletariat is the future.</p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline;\">This view might be overly pessimistic, if you are an atheist, and there might be some historical examples to the contrary, but I am certainly not convinced that religion will eventually fade away.</p>\n<p style=\"margin: 0px 0px 20px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline;\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RszjQZFw42gqrNchA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 2, "extendedScore": null, "score": 4e-06, "legacy": true, "legacyId": "22455", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-01T01:23:36.464Z", "modifiedAt": null, "url": null, "title": "Mortal: A Transponyist Fanfiction", "slug": "mortal-a-transponyist-fanfiction", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:38.974Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dLtmtghPeLbpmsFJC/mortal-a-transponyist-fanfiction", "pageUrlRelative": "/posts/dLtmtghPeLbpmsFJC/mortal-a-transponyist-fanfiction", "linkUrl": "https://www.lesswrong.com/posts/dLtmtghPeLbpmsFJC/mortal-a-transponyist-fanfiction", "postedAtFormatted": "Wednesday, May 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mortal%3A%20A%20Transponyist%20Fanfiction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMortal%3A%20A%20Transponyist%20Fanfiction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdLtmtghPeLbpmsFJC%2Fmortal-a-transponyist-fanfiction%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mortal%3A%20A%20Transponyist%20Fanfiction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdLtmtghPeLbpmsFJC%2Fmortal-a-transponyist-fanfiction", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdLtmtghPeLbpmsFJC%2Fmortal-a-transponyist-fanfiction", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 319, "htmlBody": "<p>I recently published <a href=\"http://www.fimfiction.net/story/95424/mortal\">Mortal</a>, a novella-length My Little Pony fanfiction meant to introduce anti-death concepts to an unfamiliar audience. Short description:</p>\n<blockquote>\n<p style=\"margin-bottom: 0in\">Twilight Sparkle's friends have lived long and happy lives. Now their time is coming to an end, but Rainbow Dash, at least, will not go gently. Twilight has the power to save her friend's life. Is it worth violating the natural order?</p>\n</blockquote>\n<p style=\"margin-bottom: 0in\">This is a character-driven melodrama. It's not particularly rationalist, but it's very, very transhumanist. Unlike, say,&nbsp;<a href=\"/lw/fi8/launched_friendship_is_optimal/\">Friendship is Optimal</a>, I wouldn't necessarily recommend this one to people who don't already know the source. It assumes familiarity with the characters and the world.</p>\n<p>I am going to talk about how I put together the story and how people reacted to it. This will contain spoilers.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>This line exists so you can break out of the automatic \"read everything on the page\" mode if you want to avoid the spoilers.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>This story was structured as something of a bait-and-switch. I watched the <a href=\"/lw/efo/a_my_little_pony_fanfic_allegedly_but_not_mainly/\">reaction</a>&nbsp;to a previous transhumanist horsefic (yes, there's more than one), and I was struck by how easily readers matched the <em>explicitly anti-death </em>narrative to the \"immortality is a curse\" trope. Rather than fight against this trend, I decided to work with it. The first act is meant to look like a story about learning to accept the inevitability of death. Starting in chapter 3, I break further and further away from that mold until the protagonists finally rebel against the status quo.</p>\n<p>The first chapters got a lot of people invested who I suspect would've been turned off by a less familiar opening. Once I was into the third act, I stopped being subtle and used every trick in the book to make the pro-death characters look like the unreasonable ones. Judging by the comments, there's no shortage of readers who were angry at having their expectations flouted, but quite a few&nbsp;seem thoughtful, and some explicitly changed their mind on the subject.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dLtmtghPeLbpmsFJC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 21, "extendedScore": null, "score": 1.1851252653109193e-06, "legacy": true, "legacyId": "22456", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hHCBGXkQCbEqBEADE", "uPGZBGcBi7nRFwrZY"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-01T04:33:10.392Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Collective Apathy and the Internet", "slug": "seq-rerun-collective-apathy-and-the-internet", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s79zogXPgSpGkNGms/seq-rerun-collective-apathy-and-the-internet", "pageUrlRelative": "/posts/s79zogXPgSpGkNGms/seq-rerun-collective-apathy-and-the-internet", "linkUrl": "https://www.lesswrong.com/posts/s79zogXPgSpGkNGms/seq-rerun-collective-apathy-and-the-internet", "postedAtFormatted": "Wednesday, May 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Collective%20Apathy%20and%20the%20Internet&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Collective%20Apathy%20and%20the%20Internet%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs79zogXPgSpGkNGms%2Fseq-rerun-collective-apathy-and-the-internet%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Collective%20Apathy%20and%20the%20Internet%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs79zogXPgSpGkNGms%2Fseq-rerun-collective-apathy-and-the-internet", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs79zogXPgSpGkNGms%2Fseq-rerun-collective-apathy-and-the-internet", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 174, "htmlBody": "<p>Today's post, <a href=\"/lw/9m/collective_apathy_and_the_internet/\">Collective Apathy and the Internet</a> was originally published on 14 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The causes of bystander apathy are even worse on the Internet. There may be an opportunity here for a startup to deliberately try to avert bystander apathy in online group coordination.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/hbm/seq_rerun_bystander_apathy/\">Bystander Apathy</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb150": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s79zogXPgSpGkNGms", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.185259763446313e-06, "legacy": true, "legacyId": "22457", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NnQbfLo868wgnHF4n", "rPWgyidXPhKokjsCx", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-01T11:09:50.456Z", "modifiedAt": null, "url": null, "title": "May 2013 Media Thread", "slug": "may-2013-media-thread", "viewCount": null, "lastCommentedAt": "2015-02-19T22:54:18.989Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yjFM9LfpXdJWRSnof/may-2013-media-thread", "pageUrlRelative": "/posts/yjFM9LfpXdJWRSnof/may-2013-media-thread", "linkUrl": "https://www.lesswrong.com/posts/yjFM9LfpXdJWRSnof/may-2013-media-thread", "postedAtFormatted": "Wednesday, May 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20May%202013%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMay%202013%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyjFM9LfpXdJWRSnof%2Fmay-2013-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=May%202013%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyjFM9LfpXdJWRSnof%2Fmay-2013-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyjFM9LfpXdJWRSnof%2Fmay-2013-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 185, "htmlBody": "<p>This is the monthly thread for posting media of various types that you've found that you enjoy. Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing! To see previous recommendations, check out the <a href=\"/r/discussion/tag/media_thread/\">older threads</a>.</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a <a href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please use the comment trees for genres. There is a meta thread for comments about future threads.</li>\n<li>If you think there should be a thread for a particular genre of media, please post it to the Other Media thread for now, and add a poll to the Meta thread asking if it should be a thread every month.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yjFM9LfpXdJWRSnof", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 5, "extendedScore": null, "score": 1.1855412895935785e-06, "legacy": true, "legacyId": "22459", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2013-05-01T11:09:50.456Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-01T14:40:47.028Z", "modifiedAt": null, "url": null, "title": "What do professional philosophers believe, and why?", "slug": "what-do-professional-philosophers-believe-and-why", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:03.375Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobbBB", "createdAt": "2012-08-10T00:50:11.669Z", "isAdmin": true, "displayName": "Rob Bensinger"}, "userId": "2aoRX3ookcCozcb3m", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Nm8W6FShTJEMoczix/what-do-professional-philosophers-believe-and-why", "pageUrlRelative": "/posts/Nm8W6FShTJEMoczix/what-do-professional-philosophers-believe-and-why", "linkUrl": "https://www.lesswrong.com/posts/Nm8W6FShTJEMoczix/what-do-professional-philosophers-believe-and-why", "postedAtFormatted": "Wednesday, May 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20do%20professional%20philosophers%20believe%2C%20and%20why%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20do%20professional%20philosophers%20believe%2C%20and%20why%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNm8W6FShTJEMoczix%2Fwhat-do-professional-philosophers-believe-and-why%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20do%20professional%20philosophers%20believe%2C%20and%20why%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNm8W6FShTJEMoczix%2Fwhat-do-professional-philosophers-believe-and-why", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNm8W6FShTJEMoczix%2Fwhat-do-professional-philosophers-believe-and-why", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1613, "htmlBody": "<p>LessWrong has twice discussed the <strong><a href=\"http://philpapers.org/surveys/\">PhilPapers Survey</a></strong> of professional philosophers' views on thirty controversies in their fields &mdash;&nbsp;in <a style=\"font-weight: bold;\" href=\"/lw/56q/how_would_you_respond_to_the_philpapers_what_are/\">early 2011</a>&nbsp;and, more intensively, in <strong><a href=\"/lw/emj/poll_less_wrong_and_mainstream_philosophy_how/\">late 2012</a></strong>. We've also been having some lively debates, <strong><a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">prompted by LukeProg</a></strong>, about the general value of contemporary philosophical assumptions and methods. It would be swell to test some of our intuitions about how philosophers go wrong (and right) by looking closely at the aggregate output and conduct of philosophers, but relevant data is hard to come by.</p>\n<p>Fortunately, Davids Chalmers and Bourget have done a lot of the work for us. They released a <a href=\"http://philpapers.org/archive/BOUWDP.4.pdf\"><strong>paper summarizing the PhilPapers Survey results</strong></a>&nbsp;two days ago, identifying, by factor analysis, seven major components consolidating correlations between philosophical positions, influences, areas of expertise, etc.</p>\n<p>&nbsp;</p>\n<p><img style=\"float: right; border: 3px solid black; margin: 15px;\" src=\"https://dl.dropboxusercontent.com/u/12787472/philosophy/phil-antinat.png\" alt=\"Anti-Naturalist\" width=\"151\" height=\"150\" />1. <strong>Anti-Naturalists</strong>: Philosophers of this stripe tend (more strongly than most) to assert libertarian free will (correlation with factor .66), theism (.63), the metaphysical possibility of zombies (.47), and A theories of time (.28), and to reject physicalism (.63), naturalism (.57), personal identity reductionism (.48), and liberal egalitarianism (.32).</p>\n<p>Anti-Naturalists tend to work in philosophy of religion (.3) or Greek philosophy (.11). They avoid philosophy of mind (-.17) and cognitive science (-.18) like the plague. They hate Hume (-.14), Lewis (-.13), Quine (-.12), analytic philosophy (-.14), and being from Australasia (-.11). They love Plato (.13), Aristotle (.12), and Leibniz (.1).</p>\n<p>&nbsp;</p>\n<p><img style=\"float: right; border: 3px solid black; margin: 15px;\" src=\"https://dl.dropboxusercontent.com/u/12787472/philosophy/phil-object.png\" alt=\"Objectivist\" width=\"151\" height=\"150\" />2. <strong>Objectivists</strong>: They tend to accept 'objective' moral values (.72), aesthetic values (.66), abstract objects (.38), laws of nature (.28), and scientific posits (.28). Note 'Objectivism' is being used here to pick out a tendency to treat value as objectively binding and metaphysical posits as objectively real; it isn't connected to Ayn Rand.</p>\n<p>A disproportionate number of objectivists work in normative ethics (.12), Greek philosophy (.1), or philosophy of religion (.1). They don't work in philosophy of science (-.13) or biology (-.13), and aren't continentalists (-.12) or Europeans (-.14). Their favorite philosopher is Plato (.1), least favorites Hume (-.2) and Carnap (-.12).</p>\n<p>&nbsp;</p>\n<p><img style=\"float: right; border: 3px solid black; margin: 15px;\" src=\"https://dl.dropboxusercontent.com/u/12787472/philosophy/phil-ratio.png\" alt=\"Rationalist\" width=\"150\" height=\"150\" />3. <strong>Rationalists</strong>: They tend to self-identify as 'rationalists' (.57) and 'non-naturalists' (.33), to accept that some knowledge is <em>a priori</em> (.79), and to assert that some truths are analytic, i.e., 'true by definition' or 'true in virtue of 'meaning' (.72). Also tend to posit metaphysical laws of nature (.34) and abstracta (.28). 'Rationalist' here clearly isn't being used in the LW or freethought sense; philosophical rationalists as a whole in fact tend to be theists.</p>\n<p>Rationalists are wont to work in metaphysics (.14), and to avoid thinking about the sciences of life (-.14) or cognition (-.1). They are extremely male (.15), inordinately British (.12), and prize Frege (.18) and Kant (.12). They absolutely despise Quine (-.28, the largest correlation for a philosopher), and aren't fond of Hume (-.12) or Mill (-.11) either.</p>\n<p>&nbsp;</p>\n<p><img style=\"float: right; border: 3px solid black; margin: 15px;\" src=\"https://dl.dropboxusercontent.com/u/12787472/philosophy/phil-antireal.png\" alt=\"Anti-Realist\" width=\"150\" height=\"150\" />4. <strong>Anti-Realists</strong>: They tend to define truth in terms of our cognitive and epistemic faculties (.65) and to reject scientific realism (.6), a mind-independent and knowable external world (.53), metaphysical laws of nature (.43), and the notion that proper names have no meaning beyond their referent (.35).</p>\n<p>They are extremely female (.17) and young (.15 correlation coefficient for year of birth). They work in ethics (.16), social/political philosophy (.16), and 17th-19th century philosophy (.11), avoiding metaphysics (-.2) and the philosophies of mind (-.15) and language (-.14). Their heroes are Kant (.23), Rawls (.14), and, interestingly, Hume (.11). They avoid analytic philosophy even more than the anti-naturalists do (-.17), and aren't fond of Russell (-.11).</p>\n<p>&nbsp;</p>\n<p><img style=\"float: right; border: 3px solid black; margin: 15px;\" src=\"https://dl.dropboxusercontent.com/u/12787472/philosophy/phil-extern.png\" alt=\"Externalists\" width=\"150\" height=\"150\" /></p>\n<p>5. <strong>Externalists</strong>: Really, they just like everything that anyone calls 'externalism'. They think the content of our mental lives in general (.66) and perception in particular (.55), and the justification for our beliefs (.64), all depend significantly on the world outside our heads. They also think that you can fully understand a moral imperative without being at all motivated to obey it (.5).</p>\n<div>Beyond externalism, they really have very little in common. They avoid 17th-18th century philosophy (-.13), and tend to be young (.1) and work in the UK (.1), but don't converge upon a common philosophical tradition or area of expertise, as far as the survey questions indicated.</div>\n<p>&nbsp;</p>\n<p><img style=\"float: right; border: 3px solid black; margin: 15px;\" src=\"https://dl.dropboxusercontent.com/u/12787472/philosophy/phil-antitrek.png\" alt=\"Trekophobe\" width=\"150\" height=\"150\" />6. <strong><em>Star Trek</em> Haters</strong>: This group is less clearly defined than the above ones. The main thing uniting them is that they're thoroughly convinced that teleportation would mean death (.69). Beyond that, Trekophobes tend to be deontologists (.52) who don't switch on trolley dilemmas (.47) and like A theories of time (.41).</p>\n<p>Trekophobes are relatively old (-.1) and American (.13 affiliation). They are quite rare in Australia and Asia (-.18 affiliation). They're fairly evenly distributed across philosophical fields, and tend to avoid weirdo intuitions-violating naturalists &mdash;&nbsp;Lewis (-.13), Hume (-.12), analytic philosophers generally (-.11).</p>\n<p>&nbsp;</p>\n<p><img style=\"float: right; border: 3px solid black; margin: 15px;\" src=\"https://dl.dropboxusercontent.com/u/12787472/philosophy/phil-convention.png\" alt=\"Logical Conventionalists\" width=\"150\" height=\"150\" />7. <strong>Logical Conventionalists</strong>: They two-box on Newcomb's Problem (.58), reject nonclassical logics (.48), and reject epistemic relativism and contextualism (.48). So they love causal decision theory, think all propositions/facts are generally well-behaved (always either true or false and never both or neither), and think there are always facts about which things you know, independent of who's evaluating you. Suspiciously normal.</p>\n<p>They're also fond of a wide variety of relatively uncontroversial, middle-of-the-road views most philosophers agree about or treat as 'the default' &mdash;&nbsp;political egalitarianism (.33), abstract object realism (.3), and atheism (.27). They tend to think zombies are metaphysically possible (.26) and to reject personal identity reductionism (.26) &mdash;&nbsp;which aren't metaphysically innocent or uncontroversial positions, but, again, do seem to be remarkably straightforward and banal approaches to all these problems. Notice that a lot of these positions are intuitive and 'obvious' in isolation, but that they don't converge upon any coherent world-view or consistent methodology. They clearly aren't hard-nosed philosophical conservatives like the Anti-Naturalists, Objectivists, Rationalists, and Trekophobes, but they also clearly aren't upstart radicals like the Externalists (on the analytic side) or the Anti-Realists (on the continental side). They're just kind of, well... obvious.</p>\n<p>Conventionalists are the only identified group that are strongly analytic in orientation (.19). They tend to work in epistemology (.16) or philosophy of language (.12), and are rarely found in 17th-19th century (-.12) or continental (-.11) philosophy. They're influenced by notorious two-boxer and modal realist David Lewis (.1), and show an aversion to Hegel (-.12), Aristotle (-.11), and and Wittgenstein (-.1).</p>\n<p>&nbsp;</p>\n<p>An observation: Different philosophers rely on &mdash;&nbsp;and fall victim to &mdash;&nbsp;substantially different groups of methods and intuitions. A few simple heuristics, like 'don't believe weird things until someone conclusively demonstrates them' and 'believe things that seem to be important metaphysical correlates for basic human institutions' and 'fall in love with any views starting with \"ext\"', explain a surprising amount of diversity. And there are clear common tendencies to either <strong><a href=\"/r/lesswrong/lw/fpe/philosophy_needs_to_trust_your_rationality_even/\">trust one's own rationality</a></strong> or to distrust it in partial (Externalism) or pathological (Anti-Realism, Anti-Naturalism) ways. But the heuristics don't hang together in a single Philosophical World-View or Way Of Doing Things, or even in two or three such world-views.</p>\n<p>There is no large, coherent, consolidated group that's particularly attractive to LWers across the board, but philosophers seem to fall short of LW expectations for some quite distinct reasons. So attempting to criticize, persuade, shame, praise, or even <em>speak of or address&nbsp;</em>philosophers as a whole may be a bad idea. I'd expect it to be more productive to target specific 'load-bearing' doctrines on dimensions like the above than to treat the group as a monolith, for many of the same reasons we don't want to treat 'scientists' or 'mathematicians' as monoliths.</p>\n<p>&nbsp;</p>\n<p>Another important result: Something is going seriously wrong with the&nbsp;<em>high-level</em>&nbsp;<strong><a href=\"/lw/frp/train_philosophers_with_pearl_and_kahneman_not/\">training</a> </strong>and <a href=\"/lw/1e/raising_the_sanity_waterline/\"><strong>enculturation</strong></a> of professional philosophers. Or fields are just attracting thinkers who are disproportionately bad at critically assessing a number of the basic claims their field is predicated on or exists to assess.</p>\n<p>Philosophers working in decision theory are drastically&nbsp;<em>worse&nbsp;</em>at Newcomb than are other philosophers, two-boxing 70.38% of the time where non-specialists two-box 59.07% of the time (normalized after getting rid of 'Other' answers). Philosophers of religion are the most likely to get questions about religion wrong &mdash;&nbsp;79.13% are theists (compared to 13.22% of non-specialists), and they tend strongly toward the Anti-Naturalism dimension. Non-aestheticians think aesthetic value is objective 53.64% of the time; aestheticians think it's objective 73.88% of the time.&nbsp;Working in epistemology tends to make you an internalist, philosophy of science tends to make you a Humean, metaphysics a Platonist, ethics a deontologist. This isn't always the case; but it's genuinely troubling to see non-expertise emerge as a predictor of getting&nbsp;<em>any&nbsp;</em>important&nbsp;question in an academic field right.</p>\n<p>&nbsp;</p>\n<p><strong>EDIT</strong>: I've replaced \"cluster\" talk above with \"dimension\" talk. I had in mind <a href=\"/lw/hbw/what_do_professional_philosophers_believe_and_why/8w63\">gjm</a>'s \"<em>clusters in philosophical idea-space</em>\", not distinct groups of <em>philosophers</em>. gjm makes this especially clear:</p>\n<blockquote>\n<p>The claim about these positions being made by the authors of the paper is not, not even a little bit, \"most philosophers fall into one of these seven categories\". It is \"you can generally tell most of what there is to know about a philosopher's opinions if you know how well they fit or don't fit each of these seven categories\". Not \"philosopher-space is mostly made up of these seven pieces\" but \"philosopher-space is approximately seven-dimensional\".</p>\n</blockquote>\n<p>I'm particularly guilty of promoting this misunderstanding (including in portions of my own brain) by not noting that the dimensions can be flipped to speak of (anti-anti-)naturalists, anti-rationalists, etc. My apologies. As <a href=\"/r/discussion/lw/hbw/what_do_professional_philosophers_believe_and_why/8w5e\">Douglas_Knight</a> notes below, \"If there are clusters [of philosophers], PCA might find them, but PCA might tell you something interesting even if there are no clusters. But if there are clusters, the factors that PCA finds won't be the clusters, but the differences between them. [...]&nbsp;Actually, factor analysis pretty much assumes that there aren't clusters. If factor 1 put you in a cluster, that would tell pretty much all there is to say and would pin down your factor 2, but the idea in factor analysis is that your factor 2 is designed to be as free as possible, despite knowing factor 1.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GLykb6NukBeBQtDvQ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Nm8W6FShTJEMoczix", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 44, "baseScore": 49, "extendedScore": null, "score": 1.1856910497989608e-06, "legacy": true, "legacyId": "22460", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 249, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EwSaRk7FyvJkiQ2A5", "mPBuTuqShRotscGSP", "2pdyL8bSGBfYsnkyS", "LcEzxX2FNTKbB6KXS", "XqmjdBKa4ZaXJtNmf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-01T15:37:16.911Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, May 1-15", "slug": "group-rationality-diary-may-1-15", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:09.588Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wdCpjFTirD6JRiZXc/group-rationality-diary-may-1-15", "pageUrlRelative": "/posts/wdCpjFTirD6JRiZXc/group-rationality-diary-may-1-15", "linkUrl": "https://www.lesswrong.com/posts/wdCpjFTirD6JRiZXc/group-rationality-diary-may-1-15", "postedAtFormatted": "Wednesday, May 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20May%201-15&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20May%201-15%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwdCpjFTirD6JRiZXc%2Fgroup-rationality-diary-may-1-15%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20May%201-15%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwdCpjFTirD6JRiZXc%2Fgroup-rationality-diary-may-1-15", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwdCpjFTirD6JRiZXc%2Fgroup-rationality-diary-may-1-15", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 220, "htmlBody": "<p>T<span style=\"color: #333333;\">his is the public group instrumental rationality diary for May 1-15. <br /></span></p>\n<div id=\"entry_t3_h7s\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<blockquote style=\"font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\"><span style=\"color: #333333;\">It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating!</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/r/discussion/lw/hg0/group_rationality_diary_may_1631/\">Next diary:</a>&nbsp; May 16-31<a href=\"/r/discussion/lw/hg0/group_rationality_diary_may_1631/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/r/discussion/lw/h7s/group_rationality_diary_april_1529/\">Immediate past diary</a>:&nbsp; April 15-30<a href=\"/r/discussion/lw/h7s/group_rationality_diary_april_1529/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality Diaries archive</a></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wdCpjFTirD6JRiZXc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 1.1857311666110956e-06, "legacy": true, "legacyId": "22461", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["nMP2mcg58k9zsZjv9", "Rb7KN7bQKJ8WetbLF"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-01T20:44:17.183Z", "modifiedAt": null, "url": null, "title": "Meetup : Durham/RTLW HPMoR discussion, ch. 61-63", "slug": "meetup-durham-rtlw-hpmor-discussion-ch-61-63", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wMLEnshzukMinSTrT/meetup-durham-rtlw-hpmor-discussion-ch-61-63", "pageUrlRelative": "/posts/wMLEnshzukMinSTrT/meetup-durham-rtlw-hpmor-discussion-ch-61-63", "linkUrl": "https://www.lesswrong.com/posts/wMLEnshzukMinSTrT/meetup-durham-rtlw-hpmor-discussion-ch-61-63", "postedAtFormatted": "Wednesday, May 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2061-63&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2061-63%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwMLEnshzukMinSTrT%2Fmeetup-durham-rtlw-hpmor-discussion-ch-61-63%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2061-63%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwMLEnshzukMinSTrT%2Fmeetup-durham-rtlw-hpmor-discussion-ch-61-63", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwMLEnshzukMinSTrT%2Fmeetup-durham-rtlw-hpmor-discussion-ch-61-63", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 105, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ma'>Durham/RTLW HPMoR discussion, ch. 61-63</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 May 2013 12:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">726 Rigsbee Avenue, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet up at Fullsteam to discuss HPMoR chapters 61-63! (Warning: this is only 3 chapters, but 63 is pretty substantial. Beware the planning fallacy, hyperbolic discounting, etc.) ;)</p>\n\n<p>If you feel like reading ch. 64, this is probably the week to do it -- we probably won't include it in the Official Reading.</p>\n\n<p>Bring food and coffee as you feel moved.</p>\n\n<p>Sign up for the mailing list (<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>) and let us know you'll join us!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ma'>Durham/RTLW HPMoR discussion, ch. 61-63</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wMLEnshzukMinSTrT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.185949199277452e-06, "legacy": true, "legacyId": "22463", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__61_63\">Discussion article for the meetup : <a href=\"/meetups/ma\">Durham/RTLW HPMoR discussion, ch. 61-63</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 May 2013 12:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">726 Rigsbee Avenue, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet up at Fullsteam to discuss HPMoR chapters 61-63! (Warning: this is only 3 chapters, but 63 is pretty substantial. Beware the planning fallacy, hyperbolic discounting, etc.) ;)</p>\n\n<p>If you feel like reading ch. 64, this is probably the week to do it -- we probably won't include it in the Official Reading.</p>\n\n<p>Bring food and coffee as you feel moved.</p>\n\n<p>Sign up for the mailing list (<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>) and let us know you'll join us!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__61_631\">Discussion article for the meetup : <a href=\"/meetups/ma\">Durham/RTLW HPMoR discussion, ch. 61-63</a></h2>", "sections": [{"title": "Discussion article for the meetup : Durham/RTLW HPMoR discussion, ch. 61-63", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__61_63", "level": 1}, {"title": "Discussion article for the meetup : Durham/RTLW HPMoR discussion, ch. 61-63", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__61_631", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-01T22:28:06.136Z", "modifiedAt": null, "url": null, "title": "Open Thread, May 1-14, 2013 ", "slug": "open-thread-may-1-14-2013", "viewCount": null, "lastCommentedAt": "2015-02-15T13:45:04.698Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "whpearson", "createdAt": "2009-02-28T00:34:00.976Z", "isAdmin": false, "displayName": "whpearson"}, "userId": "bq8qsRbPNvFihHxgi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jnCWdZgJgsh9NJPdS/open-thread-may-1-14-2013", "pageUrlRelative": "/posts/jnCWdZgJgsh9NJPdS/open-thread-may-1-14-2013", "linkUrl": "https://www.lesswrong.com/posts/jnCWdZgJgsh9NJPdS/open-thread-may-1-14-2013", "postedAtFormatted": "Wednesday, May 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20May%201-14%2C%202013%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20May%201-14%2C%202013%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjnCWdZgJgsh9NJPdS%2Fopen-thread-may-1-14-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20May%201-14%2C%202013%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjnCWdZgJgsh9NJPdS%2Fopen-thread-may-1-14-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjnCWdZgJgsh9NJPdS%2Fopen-thread-may-1-14-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jnCWdZgJgsh9NJPdS", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 1.186022944694867e-06, "legacy": true, "legacyId": "22464", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 649, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2013-05-01T22:28:06.136Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-02T17:34:38.818Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington DC fun and games meetup", "slug": "meetup-washington-dc-fun-and-games-meetup-4", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:19.790Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6eQSgPr5JCBL6EP7X/meetup-washington-dc-fun-and-games-meetup-4", "pageUrlRelative": "/posts/6eQSgPr5JCBL6EP7X/meetup-washington-dc-fun-and-games-meetup-4", "linkUrl": "https://www.lesswrong.com/posts/6eQSgPr5JCBL6EP7X/meetup-washington-dc-fun-and-games-meetup-4", "postedAtFormatted": "Thursday, May 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%20DC%20fun%20and%20games%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%20DC%20fun%20and%20games%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6eQSgPr5JCBL6EP7X%2Fmeetup-washington-dc-fun-and-games-meetup-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%20DC%20fun%20and%20games%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6eQSgPr5JCBL6EP7X%2Fmeetup-washington-dc-fun-and-games-meetup-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6eQSgPr5JCBL6EP7X%2Fmeetup-washington-dc-fun-and-games-meetup-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 46, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mb'>Washington DC fun and games meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 May 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to hang out and play games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mb'>Washington DC fun and games meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6eQSgPr5JCBL6EP7X", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.1868379305896814e-06, "legacy": true, "legacyId": "22471", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup\">Discussion article for the meetup : <a href=\"/meetups/mb\">Washington DC fun and games meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 May 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to hang out and play games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup1\">Discussion article for the meetup : <a href=\"/meetups/mb\">Washington DC fun and games meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington DC fun and games meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup", "level": 1}, {"title": "Discussion article for the meetup : Washington DC fun and games meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-02T20:51:30.154Z", "modifiedAt": "2021-04-29T02:35:58.091Z", "url": null, "title": "Social intelligence, education, & the workplace", "slug": "social-intelligence-education-and-the-workplace", "viewCount": null, "lastCommentedAt": "2018-03-22T12:39:28.213Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bBe2MKC26qRdtkakN/social-intelligence-education-and-the-workplace", "pageUrlRelative": "/posts/bBe2MKC26qRdtkakN/social-intelligence-education-and-the-workplace", "linkUrl": "https://www.lesswrong.com/posts/bBe2MKC26qRdtkakN/social-intelligence-education-and-the-workplace", "postedAtFormatted": "Thursday, May 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Social%20intelligence%2C%20education%2C%20%26%20the%20workplace&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASocial%20intelligence%2C%20education%2C%20%26%20the%20workplace%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbBe2MKC26qRdtkakN%2Fsocial-intelligence-education-and-the-workplace%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Social%20intelligence%2C%20education%2C%20%26%20the%20workplace%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbBe2MKC26qRdtkakN%2Fsocial-intelligence-education-and-the-workplace", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbBe2MKC26qRdtkakN%2Fsocial-intelligence-education-and-the-workplace", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 816, "htmlBody": "<p>David McClelland published an influential article (1973) claiming that IQ tests have no value, because they do not correlate with success and it is not clear that they measure anything other than social status. McClelland opened up a new discussion of whether tests predict career success, and whether the purpose of education is social investment or social reformation (why would we even want to single out children with high IQs if those are the children we want <em>not </em>to educate, in order to level the playing field?)<br /><br />This work is controversial, maybe even more so today than in the 1980s. (Barrett &amp; Depinet 1991) accused McClelland of simply lying, by not mentioning most studies that disagreed with his conclusions and misrepresenting the results of those he did quote.<br /><br />But in all this time, no one has asked the most-important question: <em>Should </em>we try to make (other people's) children more successful? And should we deliberately promote children because they're likely to be successful?<br /><br />(If the answer is yes, perhaps we should focus on giving more opportunities to children of the wealthy, since parental wealth is the strongest correlate with career success.)<br /><br />A close look at (Barrett &amp; Depinet 1991) suggests that, when social class is factored out, IQ correlates well with objective measures of <em>performance</em>, such as employee evaluations, ratings of work samples, and production quantity, but poorly with measures of career <em>success</em> such as job title and salary. Social intelligence is thus the stuff that improves your career but not your performance. That sounds suspiciously like it's skills that help you put one over on your co-workers.<br /><br />Success is a zero-sum game. It's measured by your position and wealth relative to other people. It makes sense for a prep school or college to advertise that they will make you more successful. It doesn't make sense for a taxpayer-funded school system to do so. Public school is funded by the public in order to benefit the public. The public wants performance, not career success, from you.<br /><br />It's no paradox that IQ correlates more with performance than with success. Social intelligence does wonders for your career success. People with high social intelligence are able to drive their (often stupid) ideas through committees by using coalition-building and hate-mongering, as well as sarcasm, dismissive humor, emotionally-laden jargon (\"death tax\"), distraction, and a fine sense of when they can use argument by assumption. They are the people who get grants by schmoozing, playing off the prejudices of the review panel, and snappy data-free PowerPoint presentations. They are the artists who paint a canvas black and then publish a three-page explanation of how that is a criticism of art consumerism. They are good at getting raises, bonuses, and promotions, and at taking credit for other people's work. They are the people who are ruining science and art.<br /><br />Think that a boss with high social intelligence will make your work more pleasant and resolve conflicts with your co-workers? Maybe. Or maybe that boss will strategically create conflicts to foster competition, and use their superior social intelligence to make you work harder and longer for less pay.<br /><br />(There is an underlying assumption behind how all this testing is applied that the same skills make a person a good worker and a good manager. I'm not even going to touch that question, especially since behind it lies the even harder question, \"A manager good for whom, the company or the worker?\")<br /><br />It can make sense to teach social skills to people who lack them, but it doesn't make a lot of sense to fast-track people for having competitive skills at zero-sum contests. Teaching everyone skills that would maximize their individual competitiveness if no one else has those skills may have no net effect. Putting people into gifted programs or admitting them into more-elite colleges because they have high social skills might mean that people with higher intelligence (and better ideas) will have a harder time getting their views heard. Give me a workplace full of stuttering nerds with pocket protectors, not conniving manipulators.</p>\n<p>Social skills may be an important and overlooked part of education. But we shouldn't uncritically overhaul our educational system without looking carefully at what we're maximizing for.<br /><br /><br /><strong>References</strong><br /><br />Gerald Barrett, Robert Depinet (1991). A reconsideration of testing for competence rather than for intelligence. American Psychologist 46(10), Oct 1991, 1012-1024.<br /><br />David C. McClelland (1973). Testing for competence rather than for \"intelligence\". American Psychologist 28(1), Jan 1973, 1-14. doi: 10.1037/h0034092.<br /><br />David Payne, Patrick Kyllonen (2012). The role of noncognitive skills in academic success. Presented at 21st Century knowledge and skills: the new curriculum and the future of assessment. Los Angeles, California, January 11-13, 2012.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4cKQgA4S7xfNeeWXg": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bBe2MKC26qRdtkakN", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 4, "extendedScore": null, "score": 1.1e-05, "legacy": true, "legacyId": "22473", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2013-05-02T20:51:30.154Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-02T23:45:30.441Z", "modifiedAt": null, "url": null, "title": "Meetup : [New York] Effective Altruism (Outdoor!) Dinner Discussion", "slug": "meetup-new-york-effective-altruism-outdoor-dinner-discussion", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3NqkppqdYZY3CYoAR/meetup-new-york-effective-altruism-outdoor-dinner-discussion", "pageUrlRelative": "/posts/3NqkppqdYZY3CYoAR/meetup-new-york-effective-altruism-outdoor-dinner-discussion", "linkUrl": "https://www.lesswrong.com/posts/3NqkppqdYZY3CYoAR/meetup-new-york-effective-altruism-outdoor-dinner-discussion", "postedAtFormatted": "Thursday, May 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BNew%20York%5D%20Effective%20Altruism%20(Outdoor!)%20Dinner%20Discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BNew%20York%5D%20Effective%20Altruism%20(Outdoor!)%20Dinner%20Discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3NqkppqdYZY3CYoAR%2Fmeetup-new-york-effective-altruism-outdoor-dinner-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BNew%20York%5D%20Effective%20Altruism%20(Outdoor!)%20Dinner%20Discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3NqkppqdYZY3CYoAR%2Fmeetup-new-york-effective-altruism-outdoor-dinner-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3NqkppqdYZY3CYoAR%2Fmeetup-new-york-effective-altruism-outdoor-dinner-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 186, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/mc\">[New York] Effective Altruism (Outdoor!) Dinner Discussion</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">04 May 2013 05:00:40PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Winterfell House, 316 West 138 Street New York NY 10030</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>Do you want to save the world? Do you want to mildly contribute to improving the world with your spare time or other resources and just want that mild contribution to be as effective as possible? Do you enjoy cookouts and potluck dinner discussions?</p>\n<p>If any of the above are true (and you also happen to be living in or passing through NYC) you should come down to the Effective Altruism dinner party this Saturday.</p>\n<p>The evening will be an informal potluck barbecue, where people can share past success stories and lessons learned, and talk about projects to collaborate on. Newcomers who are interested in the idea and trying to figure out how to go about having an impact can get familiar with some of the ideas behind the Effective Altruism community.</p>\n<p>Discussion will be open-ended, but with some emphasis on startups, political action and other non-charity avenues for world-improvement.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/mc\">[New York] Effective Altruism (Outdoor!) Dinner Discussion</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3NqkppqdYZY3CYoAR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "22474", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____New_York__Effective_Altruism__Outdoor___Dinner_Discussion\">Discussion article for the meetup : <a href=\"/meetups/mc\">[New York] Effective Altruism (Outdoor!) Dinner Discussion</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">04 May 2013 05:00:40PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Winterfell House, 316 West 138 Street New York NY 10030</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>Do you want to save the world? Do you want to mildly contribute to improving the world with your spare time or other resources and just want that mild contribution to be as effective as possible? Do you enjoy cookouts and potluck dinner discussions?</p>\n<p>If any of the above are true (and you also happen to be living in or passing through NYC) you should come down to the Effective Altruism dinner party this Saturday.</p>\n<p>The evening will be an informal potluck barbecue, where people can share past success stories and lessons learned, and talk about projects to collaborate on. Newcomers who are interested in the idea and trying to figure out how to go about having an impact can get familiar with some of the ideas behind the Effective Altruism community.</p>\n<p>Discussion will be open-ended, but with some emphasis on startups, political action and other non-charity avenues for world-improvement.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup____New_York__Effective_Altruism__Outdoor___Dinner_Discussion1\">Discussion article for the meetup : <a href=\"/meetups/mc\">[New York] Effective Altruism (Outdoor!) Dinner Discussion</a></h2>", "sections": [{"title": "Discussion article for the meetup : [New York] Effective Altruism (Outdoor!) Dinner Discussion", "anchor": "Discussion_article_for_the_meetup____New_York__Effective_Altruism__Outdoor___Dinner_Discussion", "level": 1}, {"title": "Discussion article for the meetup : [New York] Effective Altruism (Outdoor!) Dinner Discussion", "anchor": "Discussion_article_for_the_meetup____New_York__Effective_Altruism__Outdoor___Dinner_Discussion1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-03T00:19:01.587Z", "modifiedAt": null, "url": null, "title": "Book Suggestion: \"Diaminds\" is worth reading (CFAR-esque)", "slug": "book-suggestion-diaminds-is-worth-reading-cfar-esque", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:10.823Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MarkL", "createdAt": "2012-05-31T16:30:38.379Z", "isAdmin": false, "displayName": "MarkL"}, "userId": "QfuP3eXpC4iGfQWg5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JzXktHFFjYCDwvCqP/book-suggestion-diaminds-is-worth-reading-cfar-esque", "pageUrlRelative": "/posts/JzXktHFFjYCDwvCqP/book-suggestion-diaminds-is-worth-reading-cfar-esque", "linkUrl": "https://www.lesswrong.com/posts/JzXktHFFjYCDwvCqP/book-suggestion-diaminds-is-worth-reading-cfar-esque", "postedAtFormatted": "Friday, May 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Book%20Suggestion%3A%20%22Diaminds%22%20is%20worth%20reading%20(CFAR-esque)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABook%20Suggestion%3A%20%22Diaminds%22%20is%20worth%20reading%20(CFAR-esque)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJzXktHFFjYCDwvCqP%2Fbook-suggestion-diaminds-is-worth-reading-cfar-esque%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Book%20Suggestion%3A%20%22Diaminds%22%20is%20worth%20reading%20(CFAR-esque)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJzXktHFFjYCDwvCqP%2Fbook-suggestion-diaminds-is-worth-reading-cfar-esque", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJzXktHFFjYCDwvCqP%2Fbook-suggestion-diaminds-is-worth-reading-cfar-esque", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 851, "htmlBody": "<p>\n<p>The reason for this submission is that I don't think anyone who visits this website will ever read the book described below, otherwise. And that's a shame.</p>\n<p>Simply stated, I think CFAR curriculum designers and people who like CFAR's approach should check out this book:</p>\n<p><a href=\"http://www.amazon.com/Diaminds-Decoding-Successful-Rotman-UTP-Publishing/dp/0802099912/\">Diaminds: Decoding the Mental Habits of Successful Thinkers</a>&nbsp;by&nbsp;Mihnea Moldoveanu</p>\n<p>I claim that you will find illustrations of high-utility thinking styles and potentially useful exercises within. Yes, I am attempting to promote some random, highly questionable book to your attention.</p>\n<p>You contemptuously&nbsp;object:</p>\n<ul>\n<li><a href=\"/lw/9v/beware_of_otheroptimizing/\">beware of other optimizing</a>,</li>\n<li>does Moldeveanu even have a&nbsp;<a href=\"/lw/9c/mandatory_secret_identities/\">secret identity</a>?,</li>\n<li>\"decoding mental habits\"?!&nbsp;<a href=\"/lw/6p6/the_limits_of_introspection/\">People can't introspect</a>,</li>\n<li>anyone who entitles their book \"Diaminds\" can't be that smart,</li>\n<li>and, what are you selling?</li>\n</ul>\n<div>Stay with me.</div>\n<div><br /></div>\n<div>Moldeveanu has a \"secret identity\" as a successful serial&nbsp;<a href=\"http://www.mihneamoldoveanu.com/Companies%20Built/companies.html\">entrepreneur</a>&nbsp;(first company sold for $21 million). And, he explicitly discusses the disadvantages of his book, his lack of experimental design, selection bias, explanation versus prediction, etc. The only grounds for his claim of having decoded the mental habits of successful thinkers is that he's done a lot of reading, thinking, and doing, and he has a bunch of interview transcripts of successful people. (\"<em>Interview transcripts?!</em>\")</div>\n<div><br /></div>\n<div>You might have more objections:</div>\n<div>\n<ul>\n<li>If you dig around a little bit online you'll see that the second author writes&nbsp;<em>highly rated popular business books</em>.</li>\n<li>If you read a little bit of the book, you'll hear a lot about Nicholas Nassim Taleb, black swans, poorly justified claims about how the mind uses branching tree searches, and other assorted suspicious physical, mathematical, and computational analogies for how the mind works.</li>\n<li>He even asserts that \"death is inevitable\" (or something like that) in the introduction. *Gasp!*</li>\n</ul>\n<div>Finally, you're thinking:</div>\n<div>\n<ul>\n<li>\"There are 65 million titles out there. What are the chances that&nbsp;<em>this</em>&nbsp;particular crackpot book will be useful to me or CFAR?\"</li>\n</ul>\n</div>\n<div>Stay with me.</div>\n<div><br /></div>\n<div>Ok, still here? I think if you read this book you will continuously oscillate between swiftly-rising-annoyed-skepticism and hey-that's-uncommonly-smart-and-concisely-useful-and-I-could-try-that.</div>\n</div>\n<div><br /></div>\n<div>The exercises are not the sole value of the book, but here are some quickly assembled examples:</div>\n<div><br /></div>\n<div>\"Pick a past event that has been precisely recorded (for good example, a significant rise or fall in the price of the stock you know something about). Write down what you believe to be the best <em>explanation</em> for the event. How much would you bet on the explanation being <em>valid</em>, and why? Next, make a prediction based on your explanation (another movement in the stock's value within a certain time window). How much would you <em>bet</em> on the prediction being true, and why? Are the two sums equal? <em>Why</em> or <em>why not?</em>\"</div>\n<div><br /></div>\n<div>\"Pick a difficult personal situation[....] In written sentences, describe the situation the way you typically would when talking about it with a friend or family member. Next, figure out -- and write down -- the basic <em>causal structure</em>&nbsp;of the narrative you've written up. [...E]xpand the range of causal chains you believe were at work. [...]\"</div>\n<div><br /></div>\n<div>\"[... G]etting an associate to give you feedback, especially cutting, negative feedback, is not easy [...]. So <em>arm </em>her with a deck of file cards, on each of which is written one of the following in capital letters: WHY?, FOR WHAT PURPOSE?, BY WHAT MECHANISM?, SO WHAT?, I DISAGREE! I AGREE! [...]\"</div>\n<div><br /></div>\n<div>\"Keep a record of your thinking process as you go through the steps of trying to solve [these problems]. [...] When you've finished, go through the transcript you've produced and 'encode it' using the coding language (mentalese) we have developed in this chapter. Your coding system should include the following simplified typology: The problem complexity class (easy/hard); The solution search process you used (deterministic/probabilistic); The type of solution your mind is searching for (global/local/adaptive); Your perceived <em>distance</em> from the answer to the problem at several different points in the problem-solving process. [...]\"</div>\n<div><br /></div>\n<div>Those were just some snippets that were easy to type up. Most of the exercises are meatier, and he doesn't just say \"write down causal structure\" without any context. There is buildup if not hand-holding. There's plenty of cognitive bias-flavored stuff, debiasing stuff, mental-model-switching stuff,&nbsp;<a href=\"http://en.wikipedia.org/wiki/OODA_loop\">OODA loop</a>-type stuff, and much more.</div>\n<div><br /></div>\n<div>\n<div>Anyway, Moldoveanu tries to describe tools to change how people think. I think he succeeds, in concreteness and concision, at least, more than anything I've ever read on the subject, so far. I'm not saying this is a masterpiece; it's turgid and a little poisonous, like some PUA stuff. And it's uneven. And, I personally am not making any of the exercises a priority in my life, nor am I saying you should. But you might find helpful ideas in here for your personal experiments, and I think CFAR curriculum designers would probably benefit from reading this book.</div>\n<div><br /></div>\n<div>You can burn through a first pass of the book in a long evening. It's short enough to do so. Chapter 1 (as opposed to the Preface, Praeludium, and Chapter 6) is probably the best thing to read for deciding whether to keep reading. But go back and read the Preface and Praeludium.</div>\n</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JzXktHFFjYCDwvCqP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 3, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "22475", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6NvbSwuSAooQxxf7f", "gBewgmzcEiks2XdoQ", "K2JBqDeETX2yEgyyZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-03T01:46:56.866Z", "modifiedAt": null, "url": null, "title": "Developmental Thinking Shout-out to CFAR", "slug": "developmental-thinking-shout-out-to-cfar", "viewCount": null, "lastCommentedAt": "2018-06-03T09:32:53.755Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MarkL", "createdAt": "2012-05-31T16:30:38.379Z", "isAdmin": false, "displayName": "MarkL"}, "userId": "QfuP3eXpC4iGfQWg5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GEkojdqPg2rmMtE3z/developmental-thinking-shout-out-to-cfar", "pageUrlRelative": "/posts/GEkojdqPg2rmMtE3z/developmental-thinking-shout-out-to-cfar", "linkUrl": "https://www.lesswrong.com/posts/GEkojdqPg2rmMtE3z/developmental-thinking-shout-out-to-cfar", "postedAtFormatted": "Friday, May 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Developmental%20Thinking%20Shout-out%20to%20CFAR&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADevelopmental%20Thinking%20Shout-out%20to%20CFAR%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGEkojdqPg2rmMtE3z%2Fdevelopmental-thinking-shout-out-to-cfar%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Developmental%20Thinking%20Shout-out%20to%20CFAR%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGEkojdqPg2rmMtE3z%2Fdevelopmental-thinking-shout-out-to-cfar", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGEkojdqPg2rmMtE3z%2Fdevelopmental-thinking-shout-out-to-cfar", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1569, "htmlBody": "<p><strong>Preamble</strong></p>\n<p>Before I make my main point, I want to acknowledge that <em>curriculum development is hard</em>. It's even harder when you're trying to <a href=\"/lw/l/teaching_the_unteachable/\">teach the unteachable</a>. And it's even <em>harder</em> when you're in the process of bootstrapping. I am aware of the Kahneman inside/outside <a href=\"/lw/jh/kahnemans_planning_anecdote/\">curriculum design story</a>. And, I myself have taught 200+ hours of my own computer science curricula to middle-school students. So this \"open letter,\" is not some sort of criticism of CFAR's curriculum; It's a \"Hey, check out this cool stuff eventually when you have time,\" letter.&nbsp;I just wanted to put all this out there, to possibly influence the next five years of CFAR.</p>\n<p>Curriculum development is hard.</p>\n<p>So, anyway, I don't personally know any of the people involved in CFAR, but I do know you're all great.&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>A case for developmental thinking</strong></p>\n<div>The point of this post is to make a case for CFAR to become \"<a href=\"http://en.wikipedia.org/wiki/Positive_Adult_Development\">developmentally aware</a>.\" Massive amounts of quality research has gone into describing the differences between 1) children, 2) adults, and 3) expert or developmentally advanced adults. I haven't (yet?) seen any evidence of awareness of this research in CFAR's materials. (I haven't attended a CFAR workshop, but I've flipped through some of the more recent stuff.)</div>\n<div><br /></div>\n<div>Developmental thinking is a different approach than, e.g., cataloguing biases, promoting real-time awareness of them, and having a toolbox of de-biasing strategies and algorithms. Developmental literature gives clues to the precise cognitive operations that are painstakingly acquired over an entire lifetime, in a more fine-grained way than is possible when studying, say, already-expert performers or cognitive bias literature. I think developmental thinking goes deeper than \"toolbox thinking\" (straw!) and is an angle of approach for&nbsp;<a href=\"/lw/l/teaching_the_unteachable/\">teaching the unteachable</a>.&nbsp;</div>\n<p>Below is an annotated bibliography of some of my personal touchstones in the development literature, books that are foundational or books that synthesize decades of research about the developmental aspects of entrepreneurial, executive, educational, and scientific thinking, as well as the developmental aspects of emotion and cognition. Note that this is personal, idiosyncratic, non-exhaustive list.</p>\n<p>And, to qualify, I have epistemological and ontological issues with plenty of the stuff below. But some of these authors are brilliant, and the rest are smart, meticulous, and values-driven. Lots of these authors deeply care about empirically identifying, targeting, accelerating, and stabilizing skills ahead of schedule or helping skills manifest when they wouldn't have otherwise appeared at all. Quibbles and double-takes aside, there is lots of signal, here, even if it's not seated in a modern framework (which would of course increase the value and accessibility of what's below).</p>\n<p>There are clues or even neon signs, here, for <em>isolating fine-grained, trainable stuff to be incorporated into curricula.</em>&nbsp;Even if an intervention was designed for kids, a lot of adults still won't perform consistently prior to said intervention. And these researchers have spent thousands of collective hours thinking about how to structure assessments, interventions, and validations which may be extendable to more advanced scenarios.</p>\n<p>So all the material below is not only useful for thinking about remedial or grade-school situations, and is not just for adding more tools to a cognitive toolbox, but could be useful for radically transforming a person's thinking style at a deep level.</p>\n<p>Consider:</p>\n<p>child:adult :: adult: ?&nbsp;</p>\n<p>This has everything to do with the <a href=\"/lw/k6/the_outside_the_box_box/\">\"Outside the Box\" Box</a>. Really. One author below has been collecting data for decades to attempt to describe individuals that may represent far less than one percent of the population.</p>\n<p>&nbsp;</p>\n<p><strong>0. Protocol analysis</strong></p>\n<p>Everyone knows that people are poor reporters of what goes on in their heads. But this is a straw. A tremendous amount of research has gone into understanding what conditions, tasks, types of cognitive routines, and types of cognitive objects foster reliable introspective reporting. Introspective reporting can be reliable and useful. Grandaddy Herbert Simon (who coined the term \"bounded rationality\") devotes an entire book to it. The preface (I think) is a great overview. I wanted to mention this, first, because lots of the researchers below use verbal reports in their work.</p>\n<p><a href=\"http://www.amazon.com/Protocol-Analysis-Edition-Verbal-Reports/dp/0262550237/\">http://www.amazon.com/Protocol-Analysis-Edition-Verbal-Reports/dp/0262550237/</a></p>\n<p>&nbsp;</p>\n<p><strong>1. Developmental aspects of scientific thinking</strong></p>\n<p>Deanna Kuhn and colleagues develop and test fine-grained interventions to promote transfer of various aspects of causal inquiry and reasoning in middle school students. In her words, she wants to \"[develop] students' meta-level awareness and management of their intellectual processes.\" Kuhn believes that inquiry and argumentation skills, carefully defined and empirically backed, should be emphasized over specific content in public education. That sounds like vague and fluffy marketing-speak, but if you drill down to the specifics of what she's doing, her work is anything but. (<em>That goes for all of these 50,000 foot summaries. These people are awesome.</em>)</p>\n<p><a href=\"http://www.amazon.com/Education-Thinking-Deanna-Kuhn/dp/0674027450/\">http://www.amazon.com/Education-Thinking-Deanna-Kuhn/dp/0674027450/</a></p>\n<p><a href=\"http://www.tc.columbia.edu/academics/index.htm?facid=dk100\">http://www.tc.columbia.edu/academics/index.htm?facid=dk100</a></p>\n<p><a href=\"http://www.educationforthinking.org/\">http://www.educationforthinking.org/</a></p>\n<p>&nbsp;</p>\n<p>David Klahr and colleagues emphasize how children and adults compare in coordinated searches of a hypothesis space and experiment space. He believes that scientific thinking is not different in kind than everyday thinking. Klahr gives an integrated account of all the current approaches to studying scientific thinking. Herbert Simon was Klahr's dissertation advisor.</p>\n<p><a href=\"http://www.amazon.com/Exploring-Science-Cognition-Development-Discovery/dp/0262611767\">http://www.amazon.com/Exploring-Science-Cognition-Development-Discovery/dp/0262611767</a></p>\n<p><a href=\"http://www.psy.cmu.edu/~klahr/\">http://www.psy.cmu.edu/~klahr/</a></p>\n<p>&nbsp;</p>\n<p><strong>2. Developmental aspects of executive or instrumental thinking</strong></p>\n<p>Ok, I'll say it: Elliot Jacques was a psychoanalyst, among other things. And the guy makes weird analogies between thinking styles and truth tables. But his methods are rigorous. He has found possible discontinuities in how adults process information in order to achieve goals and how these differences relate to an individuals \"time horizon,\" or maximum time length over which an individual can comfortably execute a goal. Additionally, he has explored how these factors predictably change over a lifespan.</p>\n<p><a href=\"http://www.amazon.com/Human-Capability-Individual-Potential-Application/dp/0962107077/\">http://www.amazon.com/Human-Capability-Individual-Potential-Application/dp/0962107077/</a></p>\n<p>&nbsp;</p>\n<p><strong>3. Developmental aspects of entrepreneurial thinking</strong></p>\n<p>Saras Sarasvathy and colleagues study the difference between novice entrepreneurs and expert entrepreneurs. Sarasvathy wants to know how people function under conditions of <em>goal ambiguity</em> (\"We don't know the exact form of what we want\"), <em>environmental isotropy</em> (\"The levers to affect the world, in our concrete situation, are non-obvious\"), and <em>enaction</em> (\"When we act we change the world\"). Herbert Simon was her advisor. Her thinking predates and goes beyond the lean startup movement.</p>\n<p><a href=\"http://www.amazon.com/Effectuation-Elements-Entrepreneurial-Expertise-Entrepreneurship/dp/1848445725/\">http://www.amazon.com/Effectuation-Elements-Entrepreneurial-Expertise-Entrepreneurship/dp/1848445725/</a></p>\n<p>\"What effectuation is not\" <a href=\"http://www.effectuation.org/sites/default/files/research_papers/not-effectuation.pdf\">http://www.effectuation.org/sites/default/files/research_papers/not-effectuation.pdf</a></p>\n<p>Related:&nbsp;<a href=\"/r/discussion/lw/hcb/book_suggestion_diaminds_is_worth_reading/\">http://lesswrong.com/r/discussion/lw/hcb/book_suggestion_diaminds_is_worth_reading/</a></p>\n<p><strong>4. General Cognitive Development</strong></p>\n<p>Jane Loevinger and colleagues' work have inspired scores of studies. Loevinger discovered potentially stepwise changes in \"ego level\" over a lifespan. Ego level is an archaic-sounding term that might be defined as one's ontological, epistemological, and metacognitive stance towards self and world. Loevinger's methods are rigorous, with good inter-rater reliability, bayesian scoring rules incorporating base rates, and so forth.</p>\n<p><a href=\"http://www.amazon.com/Measuring-Ego-Development-Volume-Construction/dp/0875890598/\">http://www.amazon.com/Measuring-Ego-Development-Volume-Construction/dp/0875890598/</a></p>\n<p><a href=\"http://www.amazon.com/Measuring-Development-Scoring-Manual-Women/dp/0875890695/\">http://www.amazon.com/Measuring-Development-Scoring-Manual-Women/dp/0875890695/</a></p>\n<p>Here is a woo-woo description of the ego levels, but note that these descriptions are based on decades of experience and have a repeatedly validated empirical core. The author of this document, Susanne Cook-Greuter, received her doctorate from Harvard by extending Loevinger's model, and it's well worth reading all the way through:&nbsp;</p>\n<p><a href=\"http://www.cook-greuter.com/9%20levels%20of%20increasing%20embrace%20update%201%2007.pdf\">http://www.cook-greuter.com/9%20levels%20of%20increasing%20embrace%20update%201%2007.pdf</a></p>\n<p>Here is a recent look at the field:</p>\n<p><a href=\"http://www.amazon.com/The-Postconventional-Personality-Researching-Transpersonal/dp/1438434642/\">http://www.amazon.com/The-Postconventional-Personality-Researching-Transpersonal/dp/1438434642/</a></p>\n<p>By the way, having explicit&nbsp;<em>cognitive</em> goals predicts an increase in ego level, three years later, but <em>not</em>&nbsp;an increase in subjective well-being. (Only the highest ego levels are discontinuously associated with increased wellbeing.) Socio-emotional goals <em>do</em> predict an increase in subjective well-being, three years later. Great study:</p>\n<p>Bauer, Jack J., and Dan P. McAdams. \"Eudaimonic growth: Narrative growth goals predict increases in ego development and subjective well-being 3 years later.\" Developmental Psychology 46.4 (2010): 761.</p>\n<p>&nbsp;</p>\n<p><strong>5. Bridging symbolic and non-symbolic cognition</strong></p>\n<p>[Related:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words\">http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words</a>]</p>\n<p>Eugene Gendlin and colleagues developed a \"[...] theory of personality change [...] which involved a fundamental shift from looking at content [to] process [...]. From examining hundreds of transcripts and hours of taped psychotherapy interviews, Gendlin and Zimring formulated the Experiencing Level variable. [...]\"</p>\n<p>The \"focusing\" technique was designed as a trainable intervention to influence an individual's Experiencing Level.</p>\n<p>Marion N. Hendricks reviews 89 studies, concluding that [I quote]:</p>\n<ul>\n<li>Clients who process in a High Experiencing manner or focus do better in therapy according to client, therapist and objective outcome measures.</li>\n<li>Clients and therapists judge sessions in which focusing takes place as more successful.</li>\n<li>Successful short term therapy clients focus in every session.</li>\n<li>Some clients focus immediately in therapy; Others require training.</li>\n<li>Clients who process in a Low Experiencing manner can be taught to focus and increase in Experiencing manner, either in therapy or in a separate training.</li>\n<li>Therapist responses deepen or flatten client Experiencing. Therapists who focus effectively help their clients do so.</li>\n<li>Successful training in focusing is best maintained by those clients who are the strongest focusers during training.</li>\n</ul>\n<p><a href=\"http://www.focusing.org/research_basis.html\">http://www.focusing.org/research_basis.html</a></p>\n<p><a href=\"http://www.amazon.com/Focusing-Eugene-T-Gendlin/dp/0553278339/\">http://www.amazon.com/Focusing-Eugene-T-Gendlin/dp/0553278339/</a></p>\n<p><a href=\"http://www.amazon.com/Focusing-Oriented-Psychotherapy-Manual-Experiential-Method/dp/157230376X/\">http://www.amazon.com/Focusing-Oriented-Psychotherapy-Manual-Experiential-Method/dp/157230376X/</a></p>\n<p><a href=\"http://www.amazon.com/Self-Therapy-Step-By-Step-Wholeness-Cutting-Edge-Psychotherapy/dp/0984392777/\">http://www.amazon.com/Self-Therapy-Step-By-Step-Wholeness-Cutting-Edge-Psychotherapy/dp/0984392777/</a> [IFS is very similar to focusing]</p>\n<p><a href=\"http://www.amazon.com/Emotion-Focused-Therapy-Coaching-Clients-Feelings/dp/1557988811/\">http://www.amazon.com/Emotion-Focused-Therapy-Coaching-Clients-Feelings/dp/1557988811/</a> [more references, similar to focusing]</p>\n<p><a href=\"http://www.amazon.com/Experiencing-Creation-Meaning-Philosophical-Psychological/dp/0810114275/\">http://www.amazon.com/Experiencing-Creation-Meaning-Philosophical-Psychological/dp/0810114275/</a> [favorite book of all time, by the way]</p>\n<p>&nbsp;</p>\n<p><strong>6. Rigorous Instructional Design</strong></p>\n<p>Siegfried Engelmann (<a href=\"http://www.zigsite.com/\">http://www.zigsite.com/</a>) and colleagues are dedicated to dramatically accelerating cognitive skill acquisition in disadvantaged children. In addition to his peer-reviewed research, he specializes in unambiguously decomposing cognitive learning tasks and designing curricula. Engelmann's methods were validated as part of Project Follow Through, the \"largest and most expensive experiment in education funded by the U.S. federal government that has ever been conducted,\" according to Wikipedia. Engelmann contends that the data show that Direct Instruction outperformed all other methods:</p>\n<p><a href=\"http://www.zigsite.com/prologue_NeedyKids_chapter_5.html\">http://www.zigsite.com/prologue_NeedyKids_chapter_5.html</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Project_Follow_Through\">http://en.wikipedia.org/wiki/Project_Follow_Through</a></p>\n<p>Here, he systematically eviscerates an example of educational material that doesn't meet his standards:</p>\n<p><a href=\"http://www.zigsite.com/RubricPro.htm\">http://www.zigsite.com/RubricPro.htm</a></p>\n<p>And this is his instructional design philosophy:</p>\n<p><a href=\"http://www.amazon.com/Theory-Instruction-Applications-Siegfried-Engelmann/dp/1880183803/\">http://www.amazon.com/Theory-Instruction-Applications-Siegfried-Engelmann/dp/1880183803/</a></p>\n<p>&nbsp;</p>\n<p><strong>Conclusion</strong></p>\n<p>In conclusion, lots of scientists have cared for decades about describing the cognitive differences between children, adults, and expert or developmentally advanced adults. And lots of scientists care about making those differences happen ahead of schedule or happen when they wouldn't have otherwise happened at all. This is a valuable and complementary perspective to what seems to be CFAR's current approach. I hope CFAR will eventually consider digging into this line of thinking, though maybe they're already on top of it or up to something even better.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"X7v7Fyp9cgBYaMe2e": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GEkojdqPg2rmMtE3z", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 24, "extendedScore": null, "score": 1.187188171496213e-06, "legacy": true, "legacyId": "22472", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong id=\"Preamble\">Preamble</strong></p>\n<p>Before I make my main point, I want to acknowledge that <em>curriculum development is hard</em>. It's even harder when you're trying to <a href=\"/lw/l/teaching_the_unteachable/\">teach the unteachable</a>. And it's even <em>harder</em> when you're in the process of bootstrapping. I am aware of the Kahneman inside/outside <a href=\"/lw/jh/kahnemans_planning_anecdote/\">curriculum design story</a>. And, I myself have taught 200+ hours of my own computer science curricula to middle-school students. So this \"open letter,\" is not some sort of criticism of CFAR's curriculum; It's a \"Hey, check out this cool stuff eventually when you have time,\" letter.&nbsp;I just wanted to put all this out there, to possibly influence the next five years of CFAR.</p>\n<p>Curriculum development is hard.</p>\n<p>So, anyway, I don't personally know any of the people involved in CFAR, but I do know you're all great.&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"A_case_for_developmental_thinking\">A case for developmental thinking</strong></p>\n<div>The point of this post is to make a case for CFAR to become \"<a href=\"http://en.wikipedia.org/wiki/Positive_Adult_Development\">developmentally aware</a>.\" Massive amounts of quality research has gone into describing the differences between 1) children, 2) adults, and 3) expert or developmentally advanced adults. I haven't (yet?) seen any evidence of awareness of this research in CFAR's materials. (I haven't attended a CFAR workshop, but I've flipped through some of the more recent stuff.)</div>\n<div><br></div>\n<div>Developmental thinking is a different approach than, e.g., cataloguing biases, promoting real-time awareness of them, and having a toolbox of de-biasing strategies and algorithms. Developmental literature gives clues to the precise cognitive operations that are painstakingly acquired over an entire lifetime, in a more fine-grained way than is possible when studying, say, already-expert performers or cognitive bias literature. I think developmental thinking goes deeper than \"toolbox thinking\" (straw!) and is an angle of approach for&nbsp;<a href=\"/lw/l/teaching_the_unteachable/\">teaching the unteachable</a>.&nbsp;</div>\n<p>Below is an annotated bibliography of some of my personal touchstones in the development literature, books that are foundational or books that synthesize decades of research about the developmental aspects of entrepreneurial, executive, educational, and scientific thinking, as well as the developmental aspects of emotion and cognition. Note that this is personal, idiosyncratic, non-exhaustive list.</p>\n<p>And, to qualify, I have epistemological and ontological issues with plenty of the stuff below. But some of these authors are brilliant, and the rest are smart, meticulous, and values-driven. Lots of these authors deeply care about empirically identifying, targeting, accelerating, and stabilizing skills ahead of schedule or helping skills manifest when they wouldn't have otherwise appeared at all. Quibbles and double-takes aside, there is lots of signal, here, even if it's not seated in a modern framework (which would of course increase the value and accessibility of what's below).</p>\n<p>There are clues or even neon signs, here, for <em>isolating fine-grained, trainable stuff to be incorporated into curricula.</em>&nbsp;Even if an intervention was designed for kids, a lot of adults still won't perform consistently prior to said intervention. And these researchers have spent thousands of collective hours thinking about how to structure assessments, interventions, and validations which may be extendable to more advanced scenarios.</p>\n<p>So all the material below is not only useful for thinking about remedial or grade-school situations, and is not just for adding more tools to a cognitive toolbox, but could be useful for radically transforming a person's thinking style at a deep level.</p>\n<p>Consider:</p>\n<p>child:adult :: adult: ?&nbsp;</p>\n<p>This has everything to do with the <a href=\"/lw/k6/the_outside_the_box_box/\">\"Outside the Box\" Box</a>. Really. One author below has been collecting data for decades to attempt to describe individuals that may represent far less than one percent of the population.</p>\n<p>&nbsp;</p>\n<p><strong id=\"0__Protocol_analysis\">0. Protocol analysis</strong></p>\n<p>Everyone knows that people are poor reporters of what goes on in their heads. But this is a straw. A tremendous amount of research has gone into understanding what conditions, tasks, types of cognitive routines, and types of cognitive objects foster reliable introspective reporting. Introspective reporting can be reliable and useful. Grandaddy Herbert Simon (who coined the term \"bounded rationality\") devotes an entire book to it. The preface (I think) is a great overview. I wanted to mention this, first, because lots of the researchers below use verbal reports in their work.</p>\n<p><a href=\"http://www.amazon.com/Protocol-Analysis-Edition-Verbal-Reports/dp/0262550237/\">http://www.amazon.com/Protocol-Analysis-Edition-Verbal-Reports/dp/0262550237/</a></p>\n<p>&nbsp;</p>\n<p><strong id=\"1__Developmental_aspects_of_scientific_thinking\">1. Developmental aspects of scientific thinking</strong></p>\n<p>Deanna Kuhn and colleagues develop and test fine-grained interventions to promote transfer of various aspects of causal inquiry and reasoning in middle school students. In her words, she wants to \"[develop] students' meta-level awareness and management of their intellectual processes.\" Kuhn believes that inquiry and argumentation skills, carefully defined and empirically backed, should be emphasized over specific content in public education. That sounds like vague and fluffy marketing-speak, but if you drill down to the specifics of what she's doing, her work is anything but. (<em>That goes for all of these 50,000 foot summaries. These people are awesome.</em>)</p>\n<p><a href=\"http://www.amazon.com/Education-Thinking-Deanna-Kuhn/dp/0674027450/\">http://www.amazon.com/Education-Thinking-Deanna-Kuhn/dp/0674027450/</a></p>\n<p><a href=\"http://www.tc.columbia.edu/academics/index.htm?facid=dk100\">http://www.tc.columbia.edu/academics/index.htm?facid=dk100</a></p>\n<p><a href=\"http://www.educationforthinking.org/\">http://www.educationforthinking.org/</a></p>\n<p>&nbsp;</p>\n<p>David Klahr and colleagues emphasize how children and adults compare in coordinated searches of a hypothesis space and experiment space. He believes that scientific thinking is not different in kind than everyday thinking. Klahr gives an integrated account of all the current approaches to studying scientific thinking. Herbert Simon was Klahr's dissertation advisor.</p>\n<p><a href=\"http://www.amazon.com/Exploring-Science-Cognition-Development-Discovery/dp/0262611767\">http://www.amazon.com/Exploring-Science-Cognition-Development-Discovery/dp/0262611767</a></p>\n<p><a href=\"http://www.psy.cmu.edu/~klahr/\">http://www.psy.cmu.edu/~klahr/</a></p>\n<p>&nbsp;</p>\n<p><strong id=\"2__Developmental_aspects_of_executive_or_instrumental_thinking\">2. Developmental aspects of executive or instrumental thinking</strong></p>\n<p>Ok, I'll say it: Elliot Jacques was a psychoanalyst, among other things. And the guy makes weird analogies between thinking styles and truth tables. But his methods are rigorous. He has found possible discontinuities in how adults process information in order to achieve goals and how these differences relate to an individuals \"time horizon,\" or maximum time length over which an individual can comfortably execute a goal. Additionally, he has explored how these factors predictably change over a lifespan.</p>\n<p><a href=\"http://www.amazon.com/Human-Capability-Individual-Potential-Application/dp/0962107077/\">http://www.amazon.com/Human-Capability-Individual-Potential-Application/dp/0962107077/</a></p>\n<p>&nbsp;</p>\n<p><strong id=\"3__Developmental_aspects_of_entrepreneurial_thinking\">3. Developmental aspects of entrepreneurial thinking</strong></p>\n<p>Saras Sarasvathy and colleagues study the difference between novice entrepreneurs and expert entrepreneurs. Sarasvathy wants to know how people function under conditions of <em>goal ambiguity</em> (\"We don't know the exact form of what we want\"), <em>environmental isotropy</em> (\"The levers to affect the world, in our concrete situation, are non-obvious\"), and <em>enaction</em> (\"When we act we change the world\"). Herbert Simon was her advisor. Her thinking predates and goes beyond the lean startup movement.</p>\n<p><a href=\"http://www.amazon.com/Effectuation-Elements-Entrepreneurial-Expertise-Entrepreneurship/dp/1848445725/\">http://www.amazon.com/Effectuation-Elements-Entrepreneurial-Expertise-Entrepreneurship/dp/1848445725/</a></p>\n<p>\"What effectuation is not\" <a href=\"http://www.effectuation.org/sites/default/files/research_papers/not-effectuation.pdf\">http://www.effectuation.org/sites/default/files/research_papers/not-effectuation.pdf</a></p>\n<p>Related:&nbsp;<a href=\"/r/discussion/lw/hcb/book_suggestion_diaminds_is_worth_reading/\">http://lesswrong.com/r/discussion/lw/hcb/book_suggestion_diaminds_is_worth_reading/</a></p>\n<p><strong id=\"4__General_Cognitive_Development\">4. General Cognitive Development</strong></p>\n<p>Jane Loevinger and colleagues' work have inspired scores of studies. Loevinger discovered potentially stepwise changes in \"ego level\" over a lifespan. Ego level is an archaic-sounding term that might be defined as one's ontological, epistemological, and metacognitive stance towards self and world. Loevinger's methods are rigorous, with good inter-rater reliability, bayesian scoring rules incorporating base rates, and so forth.</p>\n<p><a href=\"http://www.amazon.com/Measuring-Ego-Development-Volume-Construction/dp/0875890598/\">http://www.amazon.com/Measuring-Ego-Development-Volume-Construction/dp/0875890598/</a></p>\n<p><a href=\"http://www.amazon.com/Measuring-Development-Scoring-Manual-Women/dp/0875890695/\">http://www.amazon.com/Measuring-Development-Scoring-Manual-Women/dp/0875890695/</a></p>\n<p>Here is a woo-woo description of the ego levels, but note that these descriptions are based on decades of experience and have a repeatedly validated empirical core. The author of this document, Susanne Cook-Greuter, received her doctorate from Harvard by extending Loevinger's model, and it's well worth reading all the way through:&nbsp;</p>\n<p><a href=\"http://www.cook-greuter.com/9%20levels%20of%20increasing%20embrace%20update%201%2007.pdf\">http://www.cook-greuter.com/9%20levels%20of%20increasing%20embrace%20update%201%2007.pdf</a></p>\n<p>Here is a recent look at the field:</p>\n<p><a href=\"http://www.amazon.com/The-Postconventional-Personality-Researching-Transpersonal/dp/1438434642/\">http://www.amazon.com/The-Postconventional-Personality-Researching-Transpersonal/dp/1438434642/</a></p>\n<p>By the way, having explicit&nbsp;<em>cognitive</em> goals predicts an increase in ego level, three years later, but <em>not</em>&nbsp;an increase in subjective well-being. (Only the highest ego levels are discontinuously associated with increased wellbeing.) Socio-emotional goals <em>do</em> predict an increase in subjective well-being, three years later. Great study:</p>\n<p>Bauer, Jack J., and Dan P. McAdams. \"Eudaimonic growth: Narrative growth goals predict increases in ego development and subjective well-being 3 years later.\" Developmental Psychology 46.4 (2010): 761.</p>\n<p>&nbsp;</p>\n<p><strong id=\"5__Bridging_symbolic_and_non_symbolic_cognition\">5. Bridging symbolic and non-symbolic cognition</strong></p>\n<p>[Related:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words\">http://wiki.lesswrong.com/wiki/A_Human's_Guide_to_Words</a>]</p>\n<p>Eugene Gendlin and colleagues developed a \"[...] theory of personality change [...] which involved a fundamental shift from looking at content [to] process [...]. From examining hundreds of transcripts and hours of taped psychotherapy interviews, Gendlin and Zimring formulated the Experiencing Level variable. [...]\"</p>\n<p>The \"focusing\" technique was designed as a trainable intervention to influence an individual's Experiencing Level.</p>\n<p>Marion N. Hendricks reviews 89 studies, concluding that [I quote]:</p>\n<ul>\n<li>Clients who process in a High Experiencing manner or focus do better in therapy according to client, therapist and objective outcome measures.</li>\n<li>Clients and therapists judge sessions in which focusing takes place as more successful.</li>\n<li>Successful short term therapy clients focus in every session.</li>\n<li>Some clients focus immediately in therapy; Others require training.</li>\n<li>Clients who process in a Low Experiencing manner can be taught to focus and increase in Experiencing manner, either in therapy or in a separate training.</li>\n<li>Therapist responses deepen or flatten client Experiencing. Therapists who focus effectively help their clients do so.</li>\n<li>Successful training in focusing is best maintained by those clients who are the strongest focusers during training.</li>\n</ul>\n<p><a href=\"http://www.focusing.org/research_basis.html\">http://www.focusing.org/research_basis.html</a></p>\n<p><a href=\"http://www.amazon.com/Focusing-Eugene-T-Gendlin/dp/0553278339/\">http://www.amazon.com/Focusing-Eugene-T-Gendlin/dp/0553278339/</a></p>\n<p><a href=\"http://www.amazon.com/Focusing-Oriented-Psychotherapy-Manual-Experiential-Method/dp/157230376X/\">http://www.amazon.com/Focusing-Oriented-Psychotherapy-Manual-Experiential-Method/dp/157230376X/</a></p>\n<p><a href=\"http://www.amazon.com/Self-Therapy-Step-By-Step-Wholeness-Cutting-Edge-Psychotherapy/dp/0984392777/\">http://www.amazon.com/Self-Therapy-Step-By-Step-Wholeness-Cutting-Edge-Psychotherapy/dp/0984392777/</a> [IFS is very similar to focusing]</p>\n<p><a href=\"http://www.amazon.com/Emotion-Focused-Therapy-Coaching-Clients-Feelings/dp/1557988811/\">http://www.amazon.com/Emotion-Focused-Therapy-Coaching-Clients-Feelings/dp/1557988811/</a> [more references, similar to focusing]</p>\n<p><a href=\"http://www.amazon.com/Experiencing-Creation-Meaning-Philosophical-Psychological/dp/0810114275/\">http://www.amazon.com/Experiencing-Creation-Meaning-Philosophical-Psychological/dp/0810114275/</a> [favorite book of all time, by the way]</p>\n<p>&nbsp;</p>\n<p><strong id=\"6__Rigorous_Instructional_Design\">6. Rigorous Instructional Design</strong></p>\n<p>Siegfried Engelmann (<a href=\"http://www.zigsite.com/\">http://www.zigsite.com/</a>) and colleagues are dedicated to dramatically accelerating cognitive skill acquisition in disadvantaged children. In addition to his peer-reviewed research, he specializes in unambiguously decomposing cognitive learning tasks and designing curricula. Engelmann's methods were validated as part of Project Follow Through, the \"largest and most expensive experiment in education funded by the U.S. federal government that has ever been conducted,\" according to Wikipedia. Engelmann contends that the data show that Direct Instruction outperformed all other methods:</p>\n<p><a href=\"http://www.zigsite.com/prologue_NeedyKids_chapter_5.html\">http://www.zigsite.com/prologue_NeedyKids_chapter_5.html</a></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Project_Follow_Through\">http://en.wikipedia.org/wiki/Project_Follow_Through</a></p>\n<p>Here, he systematically eviscerates an example of educational material that doesn't meet his standards:</p>\n<p><a href=\"http://www.zigsite.com/RubricPro.htm\">http://www.zigsite.com/RubricPro.htm</a></p>\n<p>And this is his instructional design philosophy:</p>\n<p><a href=\"http://www.amazon.com/Theory-Instruction-Applications-Siegfried-Engelmann/dp/1880183803/\">http://www.amazon.com/Theory-Instruction-Applications-Siegfried-Engelmann/dp/1880183803/</a></p>\n<p>&nbsp;</p>\n<p><strong id=\"Conclusion\">Conclusion</strong></p>\n<p>In conclusion, lots of scientists have cared for decades about describing the cognitive differences between children, adults, and expert or developmentally advanced adults. And lots of scientists care about making those differences happen ahead of schedule or happen when they wouldn't have otherwise happened at all. This is a valuable and complementary perspective to what seems to be CFAR's current approach. I hope CFAR will eventually consider digging into this line of thinking, though maybe they're already on top of it or up to something even better.</p>", "sections": [{"title": "Preamble", "anchor": "Preamble", "level": 1}, {"title": "A case for developmental thinking", "anchor": "A_case_for_developmental_thinking", "level": 1}, {"title": "0. Protocol analysis", "anchor": "0__Protocol_analysis", "level": 1}, {"title": "1. Developmental aspects of scientific thinking", "anchor": "1__Developmental_aspects_of_scientific_thinking", "level": 1}, {"title": "2. Developmental aspects of executive or instrumental thinking", "anchor": "2__Developmental_aspects_of_executive_or_instrumental_thinking", "level": 1}, {"title": "3. Developmental aspects of entrepreneurial thinking", "anchor": "3__Developmental_aspects_of_entrepreneurial_thinking", "level": 1}, {"title": "4. General Cognitive Development", "anchor": "4__General_Cognitive_Development", "level": 1}, {"title": "5. Bridging symbolic and non-symbolic cognition", "anchor": "5__Bridging_symbolic_and_non_symbolic_cognition", "level": 1}, {"title": "6. Rigorous Instructional Design", "anchor": "6__Rigorous_Instructional_Design", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9SaAyq7F7MAuzAWNN", "B9SF3v5vNzhJZFveH", "qu95AwSrKqQSo4fCY", "JzXktHFFjYCDwvCqP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-03T05:39:42.024Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Bayesians vs. Barbarians", "slug": "seq-rerun-bayesians-vs-barbarians", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:27.385Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5ccPkxjhNwfCS4BGM/seq-rerun-bayesians-vs-barbarians", "pageUrlRelative": "/posts/5ccPkxjhNwfCS4BGM/seq-rerun-bayesians-vs-barbarians", "linkUrl": "https://www.lesswrong.com/posts/5ccPkxjhNwfCS4BGM/seq-rerun-bayesians-vs-barbarians", "postedAtFormatted": "Friday, May 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Bayesians%20vs.%20Barbarians&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Bayesians%20vs.%20Barbarians%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5ccPkxjhNwfCS4BGM%2Fseq-rerun-bayesians-vs-barbarians%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Bayesians%20vs.%20Barbarians%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5ccPkxjhNwfCS4BGM%2Fseq-rerun-bayesians-vs-barbarians", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5ccPkxjhNwfCS4BGM%2Fseq-rerun-bayesians-vs-barbarians", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 249, "htmlBody": "<p>Today's post, <a href=\"/lw/5f/bayesians_vs_barbarians/\">Bayesians vs. Barbarians</a> was originally published on 14 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Suppose that a country of rationalists is attacked by a country of Evil Barbarians who know nothing of probability theory or decision theory. There's a certain concept of \"rationality\" which says that the rationalists inevitably lose, because the Barbarians believe in a heavenly afterlife if they die in battle, while the rationalists would all individually prefer to stay out of harm's way. So the rationalist civilization is doomed; it is too elegant and civilized to fight the savage Barbarians... And then there's the idea that rationalists should be able to (a) solve group coordination problems, (b) care a lot about other people and (c) win...</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/hbt/seq_rerun_collective_apathy_and_the_internet/\">Collective Apathy and the Internet</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5ccPkxjhNwfCS4BGM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.1873538238887186e-06, "legacy": true, "legacyId": "22482", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KsHmn6iJAEr9bACQW", "s79zogXPgSpGkNGms", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-03T06:17:52.462Z", "modifiedAt": null, "url": null, "title": "Meetup : [Moscow] Rationality and Media", "slug": "meetup-moscow-rationality-and-media", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4Tw8iHr2iRhAqMCno/meetup-moscow-rationality-and-media", "pageUrlRelative": "/posts/4Tw8iHr2iRhAqMCno/meetup-moscow-rationality-and-media", "linkUrl": "https://www.lesswrong.com/posts/4Tw8iHr2iRhAqMCno/meetup-moscow-rationality-and-media", "postedAtFormatted": "Friday, May 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BMoscow%5D%20Rationality%20and%20Media&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BMoscow%5D%20Rationality%20and%20Media%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Tw8iHr2iRhAqMCno%2Fmeetup-moscow-rationality-and-media%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BMoscow%5D%20Rationality%20and%20Media%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Tw8iHr2iRhAqMCno%2Fmeetup-moscow-rationality-and-media", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Tw8iHr2iRhAqMCno%2Fmeetup-moscow-rationality-and-media", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 156, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/md'>[Moscow] Rationality and Media</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 May 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Prediction markets.</p></li>\n<li><p>Practical rationality. We will train useful skills.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/md'>[Moscow] Rationality and Media</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4Tw8iHr2iRhAqMCno", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.1873809965825032e-06, "legacy": true, "legacyId": "22483", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Moscow__Rationality_and_Media\">Discussion article for the meetup : <a href=\"/meetups/md\">[Moscow] Rationality and Media</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 May 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Prediction markets.</p></li>\n<li><p>Practical rationality. We will train useful skills.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Moscow__Rationality_and_Media1\">Discussion article for the meetup : <a href=\"/meetups/md\">[Moscow] Rationality and Media</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Moscow] Rationality and Media", "anchor": "Discussion_article_for_the_meetup____Moscow__Rationality_and_Media", "level": 1}, {"title": "Discussion article for the meetup : [Moscow] Rationality and Media", "anchor": "Discussion_article_for_the_meetup____Moscow__Rationality_and_Media1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-03T14:56:22.079Z", "modifiedAt": null, "url": null, "title": "Meetup : [Cambridge] How To Do Everything", "slug": "meetup-cambridge-how-to-do-everything", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8Y3T6q6fyxA7ET2iX/meetup-cambridge-how-to-do-everything", "pageUrlRelative": "/posts/8Y3T6q6fyxA7ET2iX/meetup-cambridge-how-to-do-everything", "linkUrl": "https://www.lesswrong.com/posts/8Y3T6q6fyxA7ET2iX/meetup-cambridge-how-to-do-everything", "postedAtFormatted": "Friday, May 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BCambridge%5D%20How%20To%20Do%20Everything&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BCambridge%5D%20How%20To%20Do%20Everything%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Y3T6q6fyxA7ET2iX%2Fmeetup-cambridge-how-to-do-everything%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BCambridge%5D%20How%20To%20Do%20Everything%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Y3T6q6fyxA7ET2iX%2Fmeetup-cambridge-how-to-do-everything", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Y3T6q6fyxA7ET2iX%2Fmeetup-cambridge-how-to-do-everything", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 161, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/me'>[Cambridge] How To Do Everything</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 May 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">21 Ames St, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This meetup will focus on practical skills for organizing and motivating yourself to accomplish short-term goals. We\u2019ll have a handful of speakers give brief (maybe 3-10 minute) talks on individual techniques, which we'll use as topics for short, focused group discussions. I expect this to last 45-60 minutes before we break up for general discussion until dinner.</p>\n\n<p>Topics so far:</p>\n\n<p>\u2014The Getting Things Done method</p>\n\n<p>\u2014Beeminder</p>\n\n<p>\u2014Team productivity sessions</p>\n\n<p>If you have a useful technique to share, please do! Let me know and I'll add you to the roster.\nCambridge/Boston-area Less Wrong meetups are on the first and third Sunday of every month at 2pm in the MIT Whitaker Building (21 Ames St, Bldg 56), room 180. Room number subject to change based on availability. Signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/me'>[Cambridge] How To Do Everything</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8Y3T6q6fyxA7ET2iX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 1.1877501759030787e-06, "legacy": true, "legacyId": "22485", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Cambridge__How_To_Do_Everything\">Discussion article for the meetup : <a href=\"/meetups/me\">[Cambridge] How To Do Everything</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 May 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">21 Ames St, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This meetup will focus on practical skills for organizing and motivating yourself to accomplish short-term goals. We\u2019ll have a handful of speakers give brief (maybe 3-10 minute) talks on individual techniques, which we'll use as topics for short, focused group discussions. I expect this to last 45-60 minutes before we break up for general discussion until dinner.</p>\n\n<p>Topics so far:</p>\n\n<p>\u2014The Getting Things Done method</p>\n\n<p>\u2014Beeminder</p>\n\n<p>\u2014Team productivity sessions</p>\n\n<p>If you have a useful technique to share, please do! Let me know and I'll add you to the roster.\nCambridge/Boston-area Less Wrong meetups are on the first and third Sunday of every month at 2pm in the MIT Whitaker Building (21 Ames St, Bldg 56), room 180. Room number subject to change based on availability. Signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Cambridge__How_To_Do_Everything1\">Discussion article for the meetup : <a href=\"/meetups/me\">[Cambridge] How To Do Everything</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Cambridge] How To Do Everything", "anchor": "Discussion_article_for_the_meetup____Cambridge__How_To_Do_Everything", "level": 1}, {"title": "Discussion article for the meetup : [Cambridge] How To Do Everything", "anchor": "Discussion_article_for_the_meetup____Cambridge__How_To_Do_Everything1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-03T18:44:24.806Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, London, Melbourne, Moscow, Vancouver, Washington DC", "slug": "weekly-lw-meetups-austin-london-melbourne-moscow-vancouver", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FaDojbECCqSFApgk7/weekly-lw-meetups-austin-london-melbourne-moscow-vancouver", "pageUrlRelative": "/posts/FaDojbECCqSFApgk7/weekly-lw-meetups-austin-london-melbourne-moscow-vancouver", "linkUrl": "https://www.lesswrong.com/posts/FaDojbECCqSFApgk7/weekly-lw-meetups-austin-london-melbourne-moscow-vancouver", "postedAtFormatted": "Friday, May 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20London%2C%20Melbourne%2C%20Moscow%2C%20Vancouver%2C%20Washington%20DC&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20London%2C%20Melbourne%2C%20Moscow%2C%20Vancouver%2C%20Washington%20DC%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFaDojbECCqSFApgk7%2Fweekly-lw-meetups-austin-london-melbourne-moscow-vancouver%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20London%2C%20Melbourne%2C%20Moscow%2C%20Vancouver%2C%20Washington%20DC%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFaDojbECCqSFApgk7%2Fweekly-lw-meetups-austin-london-melbourne-moscow-vancouver", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFaDojbECCqSFApgk7%2Fweekly-lw-meetups-austin-london-melbourne-moscow-vancouver", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 513, "htmlBody": "<p><strong>This summary was posted to LW main on April 26th. The following week's summary is posted <a href=\"/lw/hcm/weekly_lw_meetups_austin_atlanta_buffalo/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/lx\">(Vancouver) Emotional Awareness :&nbsp;<span class=\"date\">27 April 2013 03:30PM</span></a></li>\n<li><a href=\"/meetups/lw\">London Meetup, 28th April:&nbsp;<span class=\"date\">28 April 2013 02:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m3\">Washington DC books meetup:&nbsp;<span class=\"date\">28 April 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/lr\">Moscow, Measurements:&nbsp;<span class=\"date\">28 April 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/lh\">Munich Meetup:&nbsp;<span class=\"date\">04 May 2013 03:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/ly\">Atlanta Lesswrong: Cryonics FAQ &amp; Signing up Party!:&nbsp;<span class=\"date\">10 May 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/lt\">Vienna meetup #3:&nbsp;<span class=\"date\">18 May 2013 04:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m2\">Bratislava lesswrong meetup III:&nbsp;<span class=\"date\">20 May 2013 06:30PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/bx\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Austin, TX:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">27 April 2019 01:30PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/lz\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Melbourne, practical rationality:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">03 May 2013 07:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FaDojbECCqSFApgk7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.18791261378751e-06, "legacy": true, "legacyId": "22428", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ERnYHhETMoxa4cs25", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-03T20:02:50.312Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes May 2013", "slug": "rationality-quotes-may-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:36.250Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "katydee", "createdAt": "2010-07-09T10:33:52.237Z", "isAdmin": false, "displayName": "katydee"}, "userId": "uHpk5J2f7BPBoiJFX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7SiYQWs69DW5tQJbN/rationality-quotes-may-2013", "pageUrlRelative": "/posts/7SiYQWs69DW5tQJbN/rationality-quotes-may-2013", "linkUrl": "https://www.lesswrong.com/posts/7SiYQWs69DW5tQJbN/rationality-quotes-may-2013", "postedAtFormatted": "Friday, May 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20May%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20May%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7SiYQWs69DW5tQJbN%2Frationality-quotes-may-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20May%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7SiYQWs69DW5tQJbN%2Frationality-quotes-may-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7SiYQWs69DW5tQJbN%2Frationality-quotes-may-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 78, "htmlBody": "<p>Here's another installment of rationality quotes. The usual rules apply:</p>\n<div>\n<div class=\"md\">\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial; padding: 0px;\">\n<li>Please post all quotes separately, so that they can be upvoted or downvoted separately. (If they are strongly related, reply to your own comments. If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote from Less Wrong itself, Overcoming Bias, or HPMoR.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>\n<p>&nbsp;</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7SiYQWs69DW5tQJbN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 1.1879678635019696e-06, "legacy": true, "legacyId": "22458", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 390, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-04T00:10:02.075Z", "modifiedAt": null, "url": null, "title": "Meetup : Visiting Sweden and Switzerland! Let's get together", "slug": "meetup-visiting-sweden-and-switzerland-let-s-get-together", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:26.971Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CatM", "createdAt": "2013-04-20T03:52:31.406Z", "isAdmin": false, "displayName": "CatM"}, "userId": "ihizZG5eAPwkDRjPH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WDrEoJuD4Lgxroji7/meetup-visiting-sweden-and-switzerland-let-s-get-together", "pageUrlRelative": "/posts/WDrEoJuD4Lgxroji7/meetup-visiting-sweden-and-switzerland-let-s-get-together", "linkUrl": "https://www.lesswrong.com/posts/WDrEoJuD4Lgxroji7/meetup-visiting-sweden-and-switzerland-let-s-get-together", "postedAtFormatted": "Saturday, May 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Visiting%20Sweden%20and%20Switzerland!%20Let's%20get%20together&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Visiting%20Sweden%20and%20Switzerland!%20Let's%20get%20together%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWDrEoJuD4Lgxroji7%2Fmeetup-visiting-sweden-and-switzerland-let-s-get-together%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Visiting%20Sweden%20and%20Switzerland!%20Let's%20get%20together%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWDrEoJuD4Lgxroji7%2Fmeetup-visiting-sweden-and-switzerland-let-s-get-together", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWDrEoJuD4Lgxroji7%2Fmeetup-visiting-sweden-and-switzerland-let-s-get-together", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 257, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mf'>Visiting Sweden and Switzerland! Let's get together</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 May 2013 02:09:26AM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Switzerland (St. Galen, Basel, Bern) Sweden (Stockholm and Gothenburg)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hello Europe!\nI will be visiting Switzerland and Sweden in the next few days and I'd love\nto get together with any and all interested LWers in the area.</p>\n\n<p>Switzerland:\nSt. Gallen- May 5\nBasel- May 6\nBern-May 7</p>\n\n<p>Sweden:\nGothenburg-May 8\nStockholm -May 9 and 10</p>\n\n<p>I'd love to do a CfAR class, join a meet up, get together socially or organize a comfort zone expansion outing (CoZE)!</p>\n\n<p>Please email me if you are in any of those places and you'd like to\nconnect! (if you are in a place nearby and you'd like me to try and\nvisit, please let me know. I'm sure we can work something out.)</p>\n\n<p>Also, if you have a meetup group/mailing list of people in those areas who\nmay want to connect, please pass the message along.</p>\n\n<p>I had an amazing time getting to know the group in Berlin and I'm feeling\nvery inspired by the incredible people in the greater LW community!</p>\n\n<p>original thread: <a href=\"http://lesswrong.com/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/\" rel=\"nofollow\">http://lesswrong.com/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/</a></p>\n\n<p>Warmly,\nCat</p>\n\n<p>PS if anyone knows of good places to meet in those cities (or better yet is willing to host a gathering) please do let me know. Having a local person propose a meeting place is far more likely to be successful than my internet guess.</p>\n\n<p>PPS If anyone has a couch to offer for the night it'd be greatly appreciated\nemail: cat@appliedrationality.org</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mf'>Visiting Sweden and Switzerland! Let's get together</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WDrEoJuD4Lgxroji7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 1.188144623466323e-06, "legacy": true, "legacyId": "22488", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Visiting_Sweden_and_Switzerland__Let_s_get_together\">Discussion article for the meetup : <a href=\"/meetups/mf\">Visiting Sweden and Switzerland! Let's get together</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 May 2013 02:09:26AM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Switzerland (St. Galen, Basel, Bern) Sweden (Stockholm and Gothenburg)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Hello Europe!\nI will be visiting Switzerland and Sweden in the next few days and I'd love\nto get together with any and all interested LWers in the area.</p>\n\n<p>Switzerland:\nSt. Gallen- May 5\nBasel- May 6\nBern-May 7</p>\n\n<p>Sweden:\nGothenburg-May 8\nStockholm -May 9 and 10</p>\n\n<p>I'd love to do a CfAR class, join a meet up, get together socially or organize a comfort zone expansion outing (CoZE)!</p>\n\n<p>Please email me if you are in any of those places and you'd like to\nconnect! (if you are in a place nearby and you'd like me to try and\nvisit, please let me know. I'm sure we can work something out.)</p>\n\n<p>Also, if you have a meetup group/mailing list of people in those areas who\nmay want to connect, please pass the message along.</p>\n\n<p>I had an amazing time getting to know the group in Berlin and I'm feeling\nvery inspired by the incredible people in the greater LW community!</p>\n\n<p>original thread: <a href=\"http://lesswrong.com/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/\" rel=\"nofollow\">http://lesswrong.com/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/</a></p>\n\n<p>Warmly,\nCat</p>\n\n<p>PS if anyone knows of good places to meet in those cities (or better yet is willing to host a gathering) please do let me know. Having a local person propose a meeting place is far more likely to be successful than my internet guess.</p>\n\n<p>PPS If anyone has a couch to offer for the night it'd be greatly appreciated\nemail: cat@appliedrationality.org</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Visiting_Sweden_and_Switzerland__Let_s_get_together1\">Discussion article for the meetup : <a href=\"/meetups/mf\">Visiting Sweden and Switzerland! Let's get together</a></h2>", "sections": [{"title": "Discussion article for the meetup : Visiting Sweden and Switzerland! Let's get together", "anchor": "Discussion_article_for_the_meetup___Visiting_Sweden_and_Switzerland__Let_s_get_together", "level": 1}, {"title": "Discussion article for the meetup : Visiting Sweden and Switzerland! Let's get together", "anchor": "Discussion_article_for_the_meetup___Visiting_Sweden_and_Switzerland__Let_s_get_together1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Yh6hrJmFZ7FpbDGK8"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-04T02:51:15.363Z", "modifiedAt": null, "url": null, "title": "Seeking reliable evidence - claim that closing sweatshops leads to child prostitution", "slug": "seeking-reliable-evidence-claim-that-closing-sweatshops", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:31.946Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/o5bpfnT3KkiSKtjB4/seeking-reliable-evidence-claim-that-closing-sweatshops", "pageUrlRelative": "/posts/o5bpfnT3KkiSKtjB4/seeking-reliable-evidence-claim-that-closing-sweatshops", "linkUrl": "https://www.lesswrong.com/posts/o5bpfnT3KkiSKtjB4/seeking-reliable-evidence-claim-that-closing-sweatshops", "postedAtFormatted": "Saturday, May 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seeking%20reliable%20evidence%20-%20claim%20that%20closing%20sweatshops%20leads%20to%20child%20prostitution&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeeking%20reliable%20evidence%20-%20claim%20that%20closing%20sweatshops%20leads%20to%20child%20prostitution%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo5bpfnT3KkiSKtjB4%2Fseeking-reliable-evidence-claim-that-closing-sweatshops%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seeking%20reliable%20evidence%20-%20claim%20that%20closing%20sweatshops%20leads%20to%20child%20prostitution%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo5bpfnT3KkiSKtjB4%2Fseeking-reliable-evidence-claim-that-closing-sweatshops", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo5bpfnT3KkiSKtjB4%2Fseeking-reliable-evidence-claim-that-closing-sweatshops", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 366, "htmlBody": "<p>I've been looking for reliable evidence of a claim I've heard a few times. The claim is that the closing of sweatshops (by anti-globalization activists) has resulted in many of the child workers becoming prostitutes. The idea is frequently proffered as an example of do-gooder foolishness ignoring basic economics and screwing people over.</p>\n<p>However, despite searching for a while, I can't find anything to indicate that this actually happened.</p>\n<p>Some guy at the Library of Economics and Liberty mentions it <a href=\"http://www.econlib.org/library/Columns/y2008/Powellsweatshops.html\">here</a>:</p>\n<blockquote>\n<p>In one famous 1993 case U.S. senator Tom Harkin proposed banning imports from countries that employed children in sweatshops. In response a factory in Bangladesh laid off 50,000 children. What was their next best alternative? According to the British charity Oxfam a large number of them became prostitutes.</p>\n</blockquote>\n<p>But in&nbsp;<a href=\"http://www.nytimes.com/2001/04/22/opinion/reckonings-hearts-and-heads.html\">the article</a>, Paul Krugman mentions the Oxfam study without citation:</p>\n<blockquote>\n<p>In 1993, child workers in Bangladesh were found to be producing clothing for Wal-Mart, and Senator Tom Harkin proposed legislation banning imports from countries employing underage workers. The direct result was that Bangladeshi textile factories stopped employing children. But did the children go back to school? Did they return to happy homes? Not according to Oxfam, which found that the displaced child workers ended up in even worse jobs, or on the streets -- and that a significant number were forced into prostitution.</p>\n</blockquote>\n<p>I looked at some Oxfam stuff, but couldn't find the study.</p>\n<p>A similar claim is made in&nbsp;<em>The Race to the Top: The Real Story of Globalization</em> by Tomas Larsson (go <a href=\"http://store.cato.org/books/race-top-real-story-globalization-hardback\">here</a> and use the search tool for the word 'prostitution'), but doesn't mention the Oxfam study:</p>\n<blockquote>\n<p>Keith E. Maskus, an economist at the University of Colorado, has studied the issue... He concludes that... \"The celebrated French ban of soccer balls sewn in Pakistan for the World Cup in 1998 resulted in significant dislocation of children from employment. Those who tracked them found that a large proportion ended up begging and/or in prostitution,\"</p>\n</blockquote>\n<p>I looked for a paper or something by Maskus but came up empty.</p>\n<p>I was taught this fact at a Poli Sci class in college, but I'm starting to think it's more likely to be an information cascade. Can anyone do a better job than me?</p>\n<p>Thanks in advance.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "o5bpfnT3KkiSKtjB4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 19, "extendedScore": null, "score": 1.188259525718891e-06, "legacy": true, "legacyId": "22489", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-04T06:45:37.520Z", "modifiedAt": null, "url": null, "title": "Estimates vs. head-to-head comparisons", "slug": "estimates-vs-head-to-head-comparisons", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:30.731Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hF5BykTKazCvy55em/estimates-vs-head-to-head-comparisons", "pageUrlRelative": "/posts/hF5BykTKazCvy55em/estimates-vs-head-to-head-comparisons", "linkUrl": "https://www.lesswrong.com/posts/hF5BykTKazCvy55em/estimates-vs-head-to-head-comparisons", "postedAtFormatted": "Saturday, May 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Estimates%20vs.%20head-to-head%20comparisons&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEstimates%20vs.%20head-to-head%20comparisons%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhF5BykTKazCvy55em%2Festimates-vs-head-to-head-comparisons%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Estimates%20vs.%20head-to-head%20comparisons%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhF5BykTKazCvy55em%2Festimates-vs-head-to-head-comparisons", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhF5BykTKazCvy55em%2Festimates-vs-head-to-head-comparisons", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1787, "htmlBody": "<p>(Cross-posted from <a href=\"http://www.rationalaltruist.com\">my blog</a>.)</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">Summary: when choosing between two options, it&rsquo;s not always optimal to estimate the value of each option and then pick the better one.</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Suppose I am choosing between two actions, X and Y. One way to make my decision is to predict what will happen if I do X and predict what will happen if I do Y, and then pick the option which leads to the outcome that I prefer.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">My predictions may be both vague and error-prone, and my value judgments might be very hard or nearly arbitrary. But it seems like I ultimately&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">must</em>&nbsp;make some predictions, and&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">must</em>&nbsp;decide how valuable the different outcomes are.&nbsp;So if I have to evaluate N options, I could do it by evaluating the goodness of each option, and then simply picking the option with the highest value. Right?<a id=\"more\"></a></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">There are other possible procedures for evaluating which of two options is better. For example, I have often encountered advice of the form \"if your error bars are too big, you should just ignore the estimate\". To be most extreme,&nbsp;<span style=\"background-color: transparent; line-height: 1.5em;\">I could choose some particular axis on which options can be better or worse, and then pick the option which is best on that axis, ignoring all others. (E.g., I could choose the option which is cheapest, or the charity which is most competently administered, or whatever.)</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">If you have an optimistic quantitative outlook like mine, this probably looks pretty silly&mdash;if one option is cheaper, that just gets figured into my estimate for how good it is. If my error bars are big, as long as I keep track of the error bars in my calculation it is still better than nothing. So why would I ever want to do anything other than estimate the value of each option?</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">In fact I don&rsquo;t think my intuition is quite right. To see why, let&rsquo;s start with a very simple case.</p>\n<h3 style=\"margin: 30px 0px 5px; padding: 0px; border: none; outline: 0px; font-size: 1.6em; vertical-align: baseline; background-color: transparent; color: #333333; font-family: Constantia, Palatino, 'Times New Roman', serif; position: static;\">A simple model</h3>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Alice and Bob are picking between two interventions X and Y. They only have a year to make their decision, so they split up: Alice will produce an estimate of the value of X and Bob will produce an estimate of the value of Y, and they will both do whichever one looks better. Let&rsquo;s suppose that Alice and Bob are perfectly calibrated and trust each other completely, so that each of them believes the other&rsquo;s estimate to be unbiased.&nbsp;</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Suppose that intervention X is good because it reduces carbon emissions. First Alice dutifully estimates the reductions in emissions that result from intervention X, call that number A1.&nbsp;Of course Alice doesn&rsquo;t care about carbon emissions&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">per se</em>, she cares about the improvements in human quality of life that result from decreased emissions--and she couldn&rsquo;t compare her estimate with Bob&rsquo;s unless she converts it into units of goodness. &nbsp;So she next estimates the gain in quality of life per unit of reduced emissions, call that number A2. She then reports that the value of X is A1 * A2. Because she is unbiased, as long as her estimates of A1 and A2 are independent she obtains an unbiased estimate of the value of X.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Meanwhile, it happens to be the case that intervention Y is also good because it reduces carbon emissions. So Bob similarly estimates the reduction in carbon emissions from intervention Y, B1, and then the goodness of reduced emissions, B2, and reports B1 * B2. His estimate is also an unbiased estimate of the value of Y.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">The pair decides to do intervention X iff it appears to have a higher value than Y, i.e. iff A1 * A2 &gt; B1 * B2. This is not crazy but it&rsquo;s also not a very good idea. It is easy to see that intervention X is better than intervention Y iff A1 &gt; B1. But if estimates A2 and B2 are relatively noisy&mdash;especially if the noise in those estimates is larger than the actual gap between A1 and B1&mdash;then Alice and Bob will make an unnecessarily random decision.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">What went wrong? Alice and Bob aren&rsquo;t making a systematically bad decision, but they could have made a better decision by using a different technique for comparison. I think that a similar situation arises very often, in much less simple and slightly less severe situations. This may mean that the best way to compare X and Y is not always to compute the value for each. When making a comparison between X and Y, we can minimize uncertainty by making the analysis of X as similar to the analysis of Y as possible.</p>\n<h3 style=\"margin: 30px 0px 5px; padding: 0px; border: none; outline: 0px; font-size: 1.6em; vertical-align: baseline; background-color: transparent; color: #333333; font-family: Constantia, Palatino, 'Times New Roman', serif; position: static;\">Objections</h3>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Of course this example was very simple, and there are lots of reasons you might expect more realistic estimates to be safe from these problems. I think that, despite all of these divergences, this simple model captures a common failure in estimation. The basic problem is that the argument above shows that there is no&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">general</em>&nbsp;reason to expect independent estimates of value to yield optimal results. Without a general reason to think that this procedure is optimal, it seems to be on much shakier ground. But to make the point, here are responses to some of the most obvious objections:</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">1. The reason we can say that Alice and Bob did badly is because we know something they didn't---that A2 and B2 were estimates of the same quantity. Couldn't they just have done one extra step of work---updating each of their estimates after looking at the other's work---and avoided the problem?</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">In this case, that would have solved Alice and Bob's problem. But in practice, different estimates rarely involve estimating&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">exactly</em><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">&nbsp;the same intermediates. If I want to compare the goodness of health interventions and education interventions in the developing world, the most natural estimates might not have even a single step in common. Nevertheless, each of those estimates would involve many uncertainties about social dynamics in the developing world, long-term global outcomes, and so on. I&nbsp;</span><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">could&nbsp;</em><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">do my analysis in a way that introduced analogies between the two estimates, and this could help me eliminate some of this uncertainty (even if the resulting estimates were noisier, or involved ignoring some apparently useful information).</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">If Alice and Bob's estimates were related in a more complicated way, then it's still the case that there is some extra update Alice and Bob could have done, which would have eliminated the problem (i.e. updating on each other's estimates, using that relationship). But such an update could be quite complicated, and after making it Alice and Bob would need to make further updates still. In general, it's not clear I can fix the problem without being logically omniscient. I don't know the extent of this issue in practice, and I'm not familiar with a literature on this or related problems. It seems pretty messy in general, but I expect it would be possible to make meaningful headway on it.</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">The point is: in order to prove that comparing independent value estimates is optimal, it is&nbsp;</span><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">not&nbsp;</em><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">enough to assume that my beliefs are well-calibrated. I also need to assume that my beliefs make use of all available information (including having considered every alternative estimation strategy that sheds light on the question), which is unrealistic even for an idealized agent unless it is logically omniscient. When my beliefs don&rsquo;t make use of all available information, other techniques for comparison might do better, including using different estimates which have more elements in common. (In some cases, even very simple approaches like &ldquo;do the cheapest thing&rdquo; will be predictably better than comparing independent value estimates.)</span></span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">2. Alice and Bob had trouble because they are two different people. I agree that I shouldn&rsquo;t compare estimates from different people, but if I do all of the estimates myself it seems like this isn&rsquo;t a problem.</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">When I try to estimate the same thing several times, without remembering my earlier estimates, I tend to get different results. I strongly suspect this is universal, though I haven&rsquo;t seen research on that question.</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Moreover, when I try to estimate different things, my estimates tend not to obey the logical relationships that I know the estimated quantities must, unless I go back through with those particular relationship in mind and enforce them. For example, if I estimate A and B separately, the sum is rarely the same as if I estimated A+B. When the relationships amongst items are complicated, such consistency is unrealistically difficult to enforce. (Of course, the prospects for making comparisons also suffer.) It may be that there is some principled way to get around these problems, but I don't know it.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Alice and Bob's estimates don&rsquo;t have to be very far from each other before they could have done better. I agree that estimates from a single person will have a higher degree of consistency than estimates from different people, but they won't be consistent enough to remove the problem (or opportunity for improvement, if you want to look at it from a different angle).</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">3. The weird behavior in the example came from the artificial structure of the problem. How often could you do such factoring out for realistic estimates, even when they are similar?</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">If I&rsquo;m trying to estimate the effect of different health interventions, the first step would be to separate the question &ldquo;How much does this improve people&rsquo;s health?&rdquo; from &ldquo;How much does improving people&rsquo;s health matter?&rdquo; That already factors out a big piece of the uncertainty. I think most people get that far, though, and so the question is: can you go farther?</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">I think it is still easier to estimate \"Which of these interventions improve health more?\" than to estimate the absolute improvement from either. We can break this comparison down into still smaller comparisons: &ldquo;How many more or fewer people does X reach than Y?&rdquo; and &ldquo;Per person affected, what is the relative impact of X and Y?&rdquo; etc. By focusing on the most important comparisons, and writing the others off as a wash, we might be able to reduce the total error in our comparison.</span></p>\n<h3 style=\"margin: 30px 0px 5px; padding: 0px; border: none; outline: 0px; font-size: 1.6em; vertical-align: baseline; background-color: transparent; color: #333333; font-family: Constantia, Palatino, 'Times New Roman', serif; position: static;\">Conclusion</h3>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">Trying to explicitly estimate the goodness of outcomes tends to draw a lot of criticism from pretty much every side. I think most of this criticism is unjustified (and often rooted in an aversion to making reasoning or motivations explicit, a desire to avoid offense or culpability, etc.). Nevertheless, there are problems with many straightforward approaches to quantitative estimation, and some qualitative processes improve on quantitative estimation in important ways. Many of these improvements are often dismissed by optimistic quantitative types (myself included), and I think that is an error. For example, I mentioned that I've often dismissed arguments of the form \"If your error bars are too big, you are sometimes better off ignoring the data.\" This looks obviously wrong on the Bayesian account, but as far as I can tell it may actually be the optimal behavior---even for idealized, bias-free humans.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hF5BykTKazCvy55em", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 23, "extendedScore": null, "score": 1.1884265953621463e-06, "legacy": true, "legacyId": "22490", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>(Cross-posted from <a href=\"http://www.rationalaltruist.com\">my blog</a>.)</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">Summary: when choosing between two options, it\u2019s not always optimal to estimate the value of each option and then pick the better one.</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Suppose I am choosing between two actions, X and Y. One way to make my decision is to predict what will happen if I do X and predict what will happen if I do Y, and then pick the option which leads to the outcome that I prefer.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">My predictions may be both vague and error-prone, and my value judgments might be very hard or nearly arbitrary. But it seems like I ultimately&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">must</em>&nbsp;make some predictions, and&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">must</em>&nbsp;decide how valuable the different outcomes are.&nbsp;So if I have to evaluate N options, I could do it by evaluating the goodness of each option, and then simply picking the option with the highest value. Right?<a id=\"more\"></a></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">There are other possible procedures for evaluating which of two options is better. For example, I have often encountered advice of the form \"if your error bars are too big, you should just ignore the estimate\". To be most extreme,&nbsp;<span style=\"background-color: transparent; line-height: 1.5em;\">I could choose some particular axis on which options can be better or worse, and then pick the option which is best on that axis, ignoring all others. (E.g., I could choose the option which is cheapest, or the charity which is most competently administered, or whatever.)</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">If you have an optimistic quantitative outlook like mine, this probably looks pretty silly\u2014if one option is cheaper, that just gets figured into my estimate for how good it is. If my error bars are big, as long as I keep track of the error bars in my calculation it is still better than nothing. So why would I ever want to do anything other than estimate the value of each option?</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">In fact I don\u2019t think my intuition is quite right. To see why, let\u2019s start with a very simple case.</p>\n<h3 style=\"margin: 30px 0px 5px; padding: 0px; border: none; outline: 0px; font-size: 1.6em; vertical-align: baseline; background-color: transparent; color: #333333; font-family: Constantia, Palatino, 'Times New Roman', serif; position: static;\" id=\"A_simple_model\">A simple model</h3>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Alice and Bob are picking between two interventions X and Y. They only have a year to make their decision, so they split up: Alice will produce an estimate of the value of X and Bob will produce an estimate of the value of Y, and they will both do whichever one looks better. Let\u2019s suppose that Alice and Bob are perfectly calibrated and trust each other completely, so that each of them believes the other\u2019s estimate to be unbiased.&nbsp;</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Suppose that intervention X is good because it reduces carbon emissions. First Alice dutifully estimates the reductions in emissions that result from intervention X, call that number A1.&nbsp;Of course Alice doesn\u2019t care about carbon emissions&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">per se</em>, she cares about the improvements in human quality of life that result from decreased emissions--and she couldn\u2019t compare her estimate with Bob\u2019s unless she converts it into units of goodness. &nbsp;So she next estimates the gain in quality of life per unit of reduced emissions, call that number A2. She then reports that the value of X is A1 * A2. Because she is unbiased, as long as her estimates of A1 and A2 are independent she obtains an unbiased estimate of the value of X.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Meanwhile, it happens to be the case that intervention Y is also good because it reduces carbon emissions. So Bob similarly estimates the reduction in carbon emissions from intervention Y, B1, and then the goodness of reduced emissions, B2, and reports B1 * B2. His estimate is also an unbiased estimate of the value of Y.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">The pair decides to do intervention X iff it appears to have a higher value than Y, i.e. iff A1 * A2 &gt; B1 * B2. This is not crazy but it\u2019s also not a very good idea. It is easy to see that intervention X is better than intervention Y iff A1 &gt; B1. But if estimates A2 and B2 are relatively noisy\u2014especially if the noise in those estimates is larger than the actual gap between A1 and B1\u2014then Alice and Bob will make an unnecessarily random decision.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">What went wrong? Alice and Bob aren\u2019t making a systematically bad decision, but they could have made a better decision by using a different technique for comparison. I think that a similar situation arises very often, in much less simple and slightly less severe situations. This may mean that the best way to compare X and Y is not always to compute the value for each. When making a comparison between X and Y, we can minimize uncertainty by making the analysis of X as similar to the analysis of Y as possible.</p>\n<h3 style=\"margin: 30px 0px 5px; padding: 0px; border: none; outline: 0px; font-size: 1.6em; vertical-align: baseline; background-color: transparent; color: #333333; font-family: Constantia, Palatino, 'Times New Roman', serif; position: static;\" id=\"Objections\">Objections</h3>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Of course this example was very simple, and there are lots of reasons you might expect more realistic estimates to be safe from these problems. I think that, despite all of these divergences, this simple model captures a common failure in estimation. The basic problem is that the argument above shows that there is no&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background-color: transparent;\">general</em>&nbsp;reason to expect independent estimates of value to yield optimal results. Without a general reason to think that this procedure is optimal, it seems to be on much shakier ground. But to make the point, here are responses to some of the most obvious objections:</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">1. The reason we can say that Alice and Bob did badly is because we know something they didn't---that A2 and B2 were estimates of the same quantity. Couldn't they just have done one extra step of work---updating each of their estimates after looking at the other's work---and avoided the problem?</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">In this case, that would have solved Alice and Bob's problem. But in practice, different estimates rarely involve estimating&nbsp;<em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">exactly</em><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">&nbsp;the same intermediates. If I want to compare the goodness of health interventions and education interventions in the developing world, the most natural estimates might not have even a single step in common. Nevertheless, each of those estimates would involve many uncertainties about social dynamics in the developing world, long-term global outcomes, and so on. I&nbsp;</span><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">could&nbsp;</em><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">do my analysis in a way that introduced analogies between the two estimates, and this could help me eliminate some of this uncertainty (even if the resulting estimates were noisier, or involved ignoring some apparently useful information).</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">If Alice and Bob's estimates were related in a more complicated way, then it's still the case that there is some extra update Alice and Bob could have done, which would have eliminated the problem (i.e. updating on each other's estimates, using that relationship). But such an update could be quite complicated, and after making it Alice and Bob would need to make further updates still. In general, it's not clear I can fix the problem without being logically omniscient. I don't know the extent of this issue in practice, and I'm not familiar with a literature on this or related problems. It seems pretty messy in general, but I expect it would be possible to make meaningful headway on it.</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">The point is: in order to prove that comparing independent value estimates is optimal, it is&nbsp;</span><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">not&nbsp;</em><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">enough to assume that my beliefs are well-calibrated. I also need to assume that my beliefs make use of all available information (including having considered every alternative estimation strategy that sheds light on the question), which is unrealistic even for an idealized agent unless it is logically omniscient. When my beliefs don\u2019t make use of all available information, other techniques for comparison might do better, including using different estimates which have more elements in common. (In some cases, even very simple approaches like \u201cdo the cheapest thing\u201d will be predictably better than comparing independent value estimates.)</span></span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">2. Alice and Bob had trouble because they are two different people. I agree that I shouldn\u2019t compare estimates from different people, but if I do all of the estimates myself it seems like this isn\u2019t a problem.</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">When I try to estimate the same thing several times, without remembering my earlier estimates, I tend to get different results. I strongly suspect this is universal, though I haven\u2019t seen research on that question.</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Moreover, when I try to estimate different things, my estimates tend not to obey the logical relationships that I know the estimated quantities must, unless I go back through with those particular relationship in mind and enforce them. For example, if I estimate A and B separately, the sum is rarely the same as if I estimated A+B. When the relationships amongst items are complicated, such consistency is unrealistically difficult to enforce. (Of course, the prospects for making comparisons also suffer.) It may be that there is some principled way to get around these problems, but I don't know it.</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\">Alice and Bob's estimates don\u2019t have to be very far from each other before they could have done better. I agree that estimates from a single person will have a higher degree of consistency than estimates from different people, but they won't be consistent enough to remove the problem (or opportunity for improvement, if you want to look at it from a different angle).</p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><em style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">3. The weird behavior in the example came from the artificial structure of the problem. How often could you do such factoring out for realistic estimates, even when they are similar?</em></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">If I\u2019m trying to estimate the effect of different health interventions, the first step would be to separate the question \u201cHow much does this improve people\u2019s health?\u201d from \u201cHow much does improving people\u2019s health matter?\u201d That already factors out a big piece of the uncertainty. I think most people get that far, though, and so the question is: can you go farther?</span></p>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">I think it is still easier to estimate \"Which of these interventions improve health more?\" than to estimate the absolute improvement from either. We can break this comparison down into still smaller comparisons: \u201cHow many more or fewer people does X reach than Y?\u201d and \u201cPer person affected, what is the relative impact of X and Y?\u201d etc. By focusing on the most important comparisons, and writing the others off as a wash, we might be able to reduce the total error in our comparison.</span></p>\n<h3 style=\"margin: 30px 0px 5px; padding: 0px; border: none; outline: 0px; font-size: 1.6em; vertical-align: baseline; background-color: transparent; color: #333333; font-family: Constantia, Palatino, 'Times New Roman', serif; position: static;\" id=\"Conclusion\">Conclusion</h3>\n<p style=\"margin: 0px 0px 1.7em; padding: 0px; border: 0px; outline: 0px; font-size: 14px; vertical-align: baseline; background-color: transparent; line-height: 1.5em; color: #333333; text-align: justify; background-position: initial initial; background-repeat: initial initial;\"><span style=\"margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 13px; vertical-align: baseline; background-color: transparent; line-height: 19px; background-position: initial initial; background-repeat: initial initial;\">Trying to explicitly estimate the goodness of outcomes tends to draw a lot of criticism from pretty much every side. I think most of this criticism is unjustified (and often rooted in an aversion to making reasoning or motivations explicit, a desire to avoid offense or culpability, etc.). Nevertheless, there are problems with many straightforward approaches to quantitative estimation, and some qualitative processes improve on quantitative estimation in important ways. Many of these improvements are often dismissed by optimistic quantitative types (myself included), and I think that is an error. For example, I mentioned that I've often dismissed arguments of the form \"If your error bars are too big, you are sometimes better off ignoring the data.\" This looks obviously wrong on the Bayesian account, but as far as I can tell it may actually be the optimal behavior---even for idealized, bias-free humans.</span></p>", "sections": [{"title": "A simple model", "anchor": "A_simple_model", "level": 1}, {"title": "Objections", "anchor": "Objections", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "30 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-04T17:34:31.864Z", "modifiedAt": null, "url": null, "title": "Meetup : Padeborn Meetup May 8th", "slug": "meetup-padeborn-meetup-may-8th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:27.306Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Just_existing", "createdAt": "2012-01-16T18:40:07.392Z", "isAdmin": false, "displayName": "Just_existing"}, "userId": "o89m5G8Hk2tbpKTxg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eNqyyP3aMgiHcevfJ/meetup-padeborn-meetup-may-8th", "pageUrlRelative": "/posts/eNqyyP3aMgiHcevfJ/meetup-padeborn-meetup-may-8th", "linkUrl": "https://www.lesswrong.com/posts/eNqyyP3aMgiHcevfJ/meetup-padeborn-meetup-may-8th", "postedAtFormatted": "Saturday, May 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Padeborn%20Meetup%20May%208th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Padeborn%20Meetup%20May%208th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeNqyyP3aMgiHcevfJ%2Fmeetup-padeborn-meetup-may-8th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Padeborn%20Meetup%20May%208th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeNqyyP3aMgiHcevfJ%2Fmeetup-padeborn-meetup-may-8th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeNqyyP3aMgiHcevfJ%2Fmeetup-padeborn-meetup-may-8th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mg'>Padeborn Meetup May 8th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">08 May 2013 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Gownsmen's Pub, Uni Paderborn, Warburger Stra\u00dfe 100, Paderborn</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are meeting once again in Paderborn.</p>\n\n<p>The topics of this evening will probably include some thinking on how to introduce rationality to someone who doesn't know what you are talking about. Further topics will develop during the meetup or over the next days.</p>\n\n<p>If you live in the area consider dropping by :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mg'>Padeborn Meetup May 8th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eNqyyP3aMgiHcevfJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.188889383263205e-06, "legacy": true, "legacyId": "22493", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Padeborn_Meetup_May_8th\">Discussion article for the meetup : <a href=\"/meetups/mg\">Padeborn Meetup May 8th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">08 May 2013 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Gownsmen's Pub, Uni Paderborn, Warburger Stra\u00dfe 100, Paderborn</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are meeting once again in Paderborn.</p>\n\n<p>The topics of this evening will probably include some thinking on how to introduce rationality to someone who doesn't know what you are talking about. Further topics will develop during the meetup or over the next days.</p>\n\n<p>If you live in the area consider dropping by :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Padeborn_Meetup_May_8th1\">Discussion article for the meetup : <a href=\"/meetups/mg\">Padeborn Meetup May 8th</a></h2>", "sections": [{"title": "Discussion article for the meetup : Padeborn Meetup May 8th", "anchor": "Discussion_article_for_the_meetup___Padeborn_Meetup_May_8th", "level": 1}, {"title": "Discussion article for the meetup : Padeborn Meetup May 8th", "anchor": "Discussion_article_for_the_meetup___Padeborn_Meetup_May_8th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-04T20:23:05.694Z", "modifiedAt": null, "url": null, "title": "[LINK] Fixed-action patterns: Stop FAPing!", "slug": "link-fixed-action-patterns-stop-faping", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:24.947Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/td4Qx2bHgahFDm2Mr/link-fixed-action-patterns-stop-faping", "pageUrlRelative": "/posts/td4Qx2bHgahFDm2Mr/link-fixed-action-patterns-stop-faping", "linkUrl": "https://www.lesswrong.com/posts/td4Qx2bHgahFDm2Mr/link-fixed-action-patterns-stop-faping", "postedAtFormatted": "Saturday, May 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Fixed-action%20patterns%3A%20Stop%20FAPing!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Fixed-action%20patterns%3A%20Stop%20FAPing!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftd4Qx2bHgahFDm2Mr%2Flink-fixed-action-patterns-stop-faping%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Fixed-action%20patterns%3A%20Stop%20FAPing!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftd4Qx2bHgahFDm2Mr%2Flink-fixed-action-patterns-stop-faping", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftd4Qx2bHgahFDm2Mr%2Flink-fixed-action-patterns-stop-faping", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 45, "htmlBody": "<p>A worse pun than \"JAQing off\" for a <a href=\"https://themerelyreal.wordpress.com/2013/04/23/stop-faping/\">title</a>, but a nice reminder of a small way not to be stupid.</p>\n<p style=\"padding-left: 30px;\">If you notice yourself making the same arguments over and over, or being  accused of saying things irrelevant to the argument, try to stop  yourself.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "td4Qx2bHgahFDm2Mr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 4, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "22494", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T01:58:29.631Z", "modifiedAt": null, "url": null, "title": "LW Women- Female privilege", "slug": "lw-women-female-privilege", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:34.222Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WdQJAfc5DFRtSyBCJ/lw-women-female-privilege", "pageUrlRelative": "/posts/WdQJAfc5DFRtSyBCJ/lw-women-female-privilege", "linkUrl": "https://www.lesswrong.com/posts/WdQJAfc5DFRtSyBCJ/lw-women-female-privilege", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20Women-%20Female%20privilege&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20Women-%20Female%20privilege%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWdQJAfc5DFRtSyBCJ%2Flw-women-female-privilege%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20Women-%20Female%20privilege%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWdQJAfc5DFRtSyBCJ%2Flw-women-female-privilege", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWdQJAfc5DFRtSyBCJ%2Flw-women-female-privilege", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1069, "htmlBody": "<p><strong id=\"internal-source-marker_0.11153432168066502\"> </strong></p>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">Daenerys' Note: This is the last item in the LW Women series. Thanks to all who participated. :)</h2>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">\n<hr />\n</h2>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">Standard Intro</h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Seven women replied, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<div style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<hr />\n</div>\n<div style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><br /><br /></div>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">Submitter E</h2>\n<p>&nbsp;</p>\n<p><a href=\"http://youtu.be/QjWn-ueeeLw\" target=\"_blank\">I'm a girl, and by me that's only great</a>.</p>\n<p>No seriously. I've grown up and lived in the social circles where female privilege way outweigh male privilege. I've never been sexually assaulted, nor been denied anything because of my gender. I study a male-dominated subject, and most of my friends are polite, deferential feminism-controlled men. I have, however, been able to flirt and sympathise and generally girl-game my way into getting what I want. (Charming guys is fun!) Sure, there will eventually come a point where I'll be disadvantaged in the job market because of my ability to bear children; but I've gotta balance that against the fact that I have the ability to bear children.</p>\n<p>In fact, most of the gender problems I personally face stem from biology, so there's not much I can do about them. It sucks that I have to be the one responsible for contraception, and that my attractiveness to men depends largely on my looks but the inverse is not true. But there's not much society can do to change biological facts, so I live with them.</p>\n<p>&nbsp;I don't think it's a very disputed fact that women, in general, tend to be more emotional than men. I'm an INFJ, most of my (male) friends are INTJ. With the help of Less Wrong's epistemology and a large pinch of Game, I've achieved a fair degree of luminosity over my inner workings. I'm complicated. I don't think my INTJ friends are this complicated, and the complicatedness is part of the reason why I'm an \"F\": my intuitions system is useful. It makes me really quite good at people, especially when I can introspect and then apply my conscious to my instincts as well. I don't know how many of the people here are F instead of T, but for anyone who uses intuition a lot, applying proper rationality to introspection (a.k.a. luminosity) is essential. It is so so so easy to rationalise, and it takes effort to just know my instinct without rationalising false reasons for it. I'm not sure the luminosity sequence helps everyone, because everyone works differently, but just being aware of the concept and being on the lookout for ways that work is good.</p>\n<p>There's a problem with strong intuition though, and that's that I have less conscious control over my opinions - it's hard enough being aware of them and not rationalising additional reasons for them. I judge ugly women and unsuccessful men. I try to consciously adjust for the effect, but it's hard.</p>\n<p>Onto the topic of gender discussions on Less Wrong - it annoys me how quickly things gets irrational. The whole <a href=\"/lw/134/sayeth_the_girl/\" target=\"_blank\">objectification debacle of July 2009</a> proved that even the best can get caught up in it (though maybe things have got better since 2009?). I was confused <a href=\"/lw/4vj/a_rationalists_account_of_objectification/\" target=\"_blank\">in the same way Luke was</a>: I didn't see anything wrong with objectification. I objectify people all the time, but I still treat them as agents when I need to. Porn is great, but it doesn't mean I'm going to find it harder to befriend a porn star. I objectify Eliezer Yukowsky because he's a phenomenon on the internet more than a flesh-and-blood person to me, but that doesn't mean I'd have difficulty interacting with a flesh-and-blood Eliezer. On the whole, Less Wrong doesn't do well at talking about controversial topics, even though we know how to. Maybe we just need to work harder. Maybe we need more luminosity. I would love for Less Wrong to be a place where all things could just be discussed rationally.</p>\n<p>There's another reason that I come out on a different side to most women in feminism and gender discussions though, and this is the bit I'm only saying because it's anonymous. I'm not a typical woman. I act, dress and style feminine because I enjoy feeling like a princess. I am most fulfilled when I'm in a M-dom f-sub relationship. My favourite activity is cooking and my honest-to-god favourite place in the house is the kitchen. I take pride in making awesome sandwiches. I just can't alieve it's offensive when I hear \"get in the kitchen\", because I'd just be like \"ok! :D\". I love sex, and I value getting better at it. I want to be able to have sex like a porn star. Suppressing my gag reflex is one of the most useful things I learned all year. I love being hit on and seduced by men. When I dress sexy, it is because male attention turns me on. I love getting wolf whistles. Because of luminosity and self-awareness, I'm ever-conscious of the vagina tingle. I'm aware of when I'm turned on, and I don't rationalise it away. And the same testosterone that makes me good at a male-dominated subject, makes sure I'm really easily turned on.</p>\n<p>I understand that all these things are different when I'm consenting and I'm viewed as an agent and all that. But it's just hard to understand other girls being offended when I'm not, because it's much harder to empathise with someone you don't agree with. Not generalising from one example is hard.</p>\n<p>Understanding other girls is hard.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W9aNkPwtPhMrcfgj7": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WdQJAfc5DFRtSyBCJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 44, "extendedScore": null, "score": 0.000111, "legacy": true, "legacyId": "20262", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 44, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong id=\"internal-source-marker_0.11153432168066502\"> </strong></p>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\" id=\"Daenerys__Note__This_is_the_last_item_in_the_LW_Women_series__Thanks_to_all_who_participated____\">Daenerys' Note: This is the last item in the LW Women series. Thanks to all who participated. :)</h2>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">\n<hr>\n</h2>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\" id=\"Standard_Intro\">Standard Intro</h2>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong id=\"The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_\">The following section will be at the top of all posts in the LW Women series.</strong></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Several months ago, I put out a call for anonymous submissions by the women on LW, with the idea that I would compile them into some kind of post. &nbsp;There is a LOT of material, so I am breaking them down into more manageable-sized themed posts.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Seven women replied, totaling about 18 pages.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Standard Disclaimer</strong>- Women have many different viewpoints, and just because I am acting as an intermediary to allow for anonymous communication does NOT mean that I agree with everything that will be posted in this series. (It would be rather impossible to, since there are some posts arguing opposite sides!)</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>To the submitters</strong>- If you would like to respond anonymously to a comment (for example if there is a comment questioning something in your post, and you want to clarify), you can PM your message and I will post it for you. If this happens a lot, I might create a LW_Women sockpuppet account for the submitters to share.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong id=\"Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_\">Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.</strong></p>\n<div style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<hr>\n</div>\n<div style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><br><br></div>\n<h2 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\" id=\"Submitter_E\">Submitter E</h2>\n<p>&nbsp;</p>\n<p><a href=\"http://youtu.be/QjWn-ueeeLw\" target=\"_blank\">I'm a girl, and by me that's only great</a>.</p>\n<p>No seriously. I've grown up and lived in the social circles where female privilege way outweigh male privilege. I've never been sexually assaulted, nor been denied anything because of my gender. I study a male-dominated subject, and most of my friends are polite, deferential feminism-controlled men. I have, however, been able to flirt and sympathise and generally girl-game my way into getting what I want. (Charming guys is fun!) Sure, there will eventually come a point where I'll be disadvantaged in the job market because of my ability to bear children; but I've gotta balance that against the fact that I have the ability to bear children.</p>\n<p>In fact, most of the gender problems I personally face stem from biology, so there's not much I can do about them. It sucks that I have to be the one responsible for contraception, and that my attractiveness to men depends largely on my looks but the inverse is not true. But there's not much society can do to change biological facts, so I live with them.</p>\n<p>&nbsp;I don't think it's a very disputed fact that women, in general, tend to be more emotional than men. I'm an INFJ, most of my (male) friends are INTJ. With the help of Less Wrong's epistemology and a large pinch of Game, I've achieved a fair degree of luminosity over my inner workings. I'm complicated. I don't think my INTJ friends are this complicated, and the complicatedness is part of the reason why I'm an \"F\": my intuitions system is useful. It makes me really quite good at people, especially when I can introspect and then apply my conscious to my instincts as well. I don't know how many of the people here are F instead of T, but for anyone who uses intuition a lot, applying proper rationality to introspection (a.k.a. luminosity) is essential. It is so so so easy to rationalise, and it takes effort to just know my instinct without rationalising false reasons for it. I'm not sure the luminosity sequence helps everyone, because everyone works differently, but just being aware of the concept and being on the lookout for ways that work is good.</p>\n<p>There's a problem with strong intuition though, and that's that I have less conscious control over my opinions - it's hard enough being aware of them and not rationalising additional reasons for them. I judge ugly women and unsuccessful men. I try to consciously adjust for the effect, but it's hard.</p>\n<p>Onto the topic of gender discussions on Less Wrong - it annoys me how quickly things gets irrational. The whole <a href=\"/lw/134/sayeth_the_girl/\" target=\"_blank\">objectification debacle of July 2009</a> proved that even the best can get caught up in it (though maybe things have got better since 2009?). I was confused <a href=\"/lw/4vj/a_rationalists_account_of_objectification/\" target=\"_blank\">in the same way Luke was</a>: I didn't see anything wrong with objectification. I objectify people all the time, but I still treat them as agents when I need to. Porn is great, but it doesn't mean I'm going to find it harder to befriend a porn star. I objectify Eliezer Yukowsky because he's a phenomenon on the internet more than a flesh-and-blood person to me, but that doesn't mean I'd have difficulty interacting with a flesh-and-blood Eliezer. On the whole, Less Wrong doesn't do well at talking about controversial topics, even though we know how to. Maybe we just need to work harder. Maybe we need more luminosity. I would love for Less Wrong to be a place where all things could just be discussed rationally.</p>\n<p>There's another reason that I come out on a different side to most women in feminism and gender discussions though, and this is the bit I'm only saying because it's anonymous. I'm not a typical woman. I act, dress and style feminine because I enjoy feeling like a princess. I am most fulfilled when I'm in a M-dom f-sub relationship. My favourite activity is cooking and my honest-to-god favourite place in the house is the kitchen. I take pride in making awesome sandwiches. I just can't alieve it's offensive when I hear \"get in the kitchen\", because I'd just be like \"ok! :D\". I love sex, and I value getting better at it. I want to be able to have sex like a porn star. Suppressing my gag reflex is one of the most useful things I learned all year. I love being hit on and seduced by men. When I dress sexy, it is because male attention turns me on. I love getting wolf whistles. Because of luminosity and self-awareness, I'm ever-conscious of the vagina tingle. I'm aware of when I'm turned on, and I don't rationalise it away. And the same testosterone that makes me good at a male-dominated subject, makes sure I'm really easily turned on.</p>\n<p>I understand that all these things are different when I'm consenting and I'm viewed as an agent and all that. But it's just hard to understand other girls being offended when I'm not, because it's much harder to empathise with someone you don't agree with. Not generalising from one example is hard.</p>\n<p>Understanding other girls is hard.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Daenerys' Note: This is the last item in the LW Women series. Thanks to all who participated. :)", "anchor": "Daenerys__Note__This_is_the_last_item_in_the_LW_Women_series__Thanks_to_all_who_participated____", "level": 1}, {"title": "Standard Intro", "anchor": "Standard_Intro", "level": 1}, {"title": "The following section will be at the top of all posts in the LW Women series.", "anchor": "The_following_section_will_be_at_the_top_of_all_posts_in_the_LW_Women_series_", "level": 2}, {"title": "Please do NOT break anonymity, because it lowers the anonymity of the rest of the submitters.", "anchor": "Please_do_NOT_break_anonymity__because_it_lowers_the_anonymity_of_the_rest_of_the_submitters_", "level": 2}, {"title": "Submitter E", "anchor": "Submitter_E", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "236 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 236, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gsL6CLqjujPNSLL2o", "NP8yar5gqNLsnjzZv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T03:17:30.281Z", "modifiedAt": null, "url": null, "title": "Health/Longevity Link List", "slug": "health-longevity-link-list", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:37.377Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KFwzqsogGfj3ericH/health-longevity-link-list", "pageUrlRelative": "/posts/KFwzqsogGfj3ericH/health-longevity-link-list", "linkUrl": "https://www.lesswrong.com/posts/KFwzqsogGfj3ericH/health-longevity-link-list", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Health%2FLongevity%20Link%20List&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHealth%2FLongevity%20Link%20List%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKFwzqsogGfj3ericH%2Fhealth-longevity-link-list%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Health%2FLongevity%20Link%20List%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKFwzqsogGfj3ericH%2Fhealth-longevity-link-list", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKFwzqsogGfj3ericH%2Fhealth-longevity-link-list", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p>Dying or becoming severely physically/mentally ill is very likely going to significantly lower the output of your utility function, so it would probably be a very bad idea to ignore the low-hanging resources which can significantly extend the time for which you are alive and well. I have attempted to search LessWrong for a list of such resources, and haven't been able to find one.</p>\n<p>Are there any books, websites, or posts that contain significantly low-hanging fruit in this area? If so, please list them in the comments below.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KFwzqsogGfj3ericH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 5, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "22495", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T05:59:21.860Z", "modifiedAt": null, "url": null, "title": "Ray Kurzweil joins Google to work on AI (link)", "slug": "ray-kurzweil-joins-google-to-work-on-ai-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:24.445Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "D_Alex", "createdAt": "2009-07-17T08:21:38.505Z", "isAdmin": false, "displayName": "D_Alex"}, "userId": "Sriopfkdwx2qJBx4G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oFPing35oenmkSXHx/ray-kurzweil-joins-google-to-work-on-ai-link", "pageUrlRelative": "/posts/oFPing35oenmkSXHx/ray-kurzweil-joins-google-to-work-on-ai-link", "linkUrl": "https://www.lesswrong.com/posts/oFPing35oenmkSXHx/ray-kurzweil-joins-google-to-work-on-ai-link", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ray%20Kurzweil%20joins%20Google%20to%20work%20on%20AI%20(link)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARay%20Kurzweil%20joins%20Google%20to%20work%20on%20AI%20(link)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFPing35oenmkSXHx%2Fray-kurzweil-joins-google-to-work-on-ai-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ray%20Kurzweil%20joins%20Google%20to%20work%20on%20AI%20(link)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFPing35oenmkSXHx%2Fray-kurzweil-joins-google-to-work-on-ai-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFPing35oenmkSXHx%2Fray-kurzweil-joins-google-to-work-on-ai-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 62, "htmlBody": "<p>I am very curious what will come out of this. Does Kurzweil really have some insightful ideas that will help advance AI? He used to be quite the technocrat, but I have the feeling that he is more a philosopher these days than a technical person. But maybe progress toward a new philosophical approach is exactly what the AI needs... comments sought!</p>\n<p>&nbsp;</p>\n<p><a href=\"http://www.forbes.com/sites/roberthof/2013/04/29/interview-how-ray-kurzweil-plans-to-revolutionize-search-at-google/\">http://www.forbes.com/sites/roberthof/2013/04/29/interview-how-ray-kurzweil-plans-to-revolutionize-search-at-google/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oFPing35oenmkSXHx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 0, "extendedScore": null, "score": 1.1894209781588914e-06, "legacy": true, "legacyId": "22496", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T08:33:01.758Z", "modifiedAt": null, "url": null, "title": "Use Search Engines Early and Often", "slug": "use-search-engines-early-and-often", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.584Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "katydee", "createdAt": "2010-07-09T10:33:52.237Z", "isAdmin": false, "displayName": "katydee"}, "userId": "uHpk5J2f7BPBoiJFX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hdRzQ8TGJYDacmdZ9/use-search-engines-early-and-often", "pageUrlRelative": "/posts/hdRzQ8TGJYDacmdZ9/use-search-engines-early-and-often", "linkUrl": "https://www.lesswrong.com/posts/hdRzQ8TGJYDacmdZ9/use-search-engines-early-and-often", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Use%20Search%20Engines%20Early%20and%20Often&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUse%20Search%20Engines%20Early%20and%20Often%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhdRzQ8TGJYDacmdZ9%2Fuse-search-engines-early-and-often%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Use%20Search%20Engines%20Early%20and%20Often%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhdRzQ8TGJYDacmdZ9%2Fuse-search-engines-early-and-often", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhdRzQ8TGJYDacmdZ9%2Fuse-search-engines-early-and-often", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 612, "htmlBody": "<p>The Internet contains vast amounts of useful content. Unfortunately, it also contains vast amounts of garbage, <a href=\"/lw/h3/superstimuli_and_the_collapse_of_western/\">superstimulus hazards</a>, and false, meaningless, or outright harmful information. One skill that is hence quite useful in the modern day is using search engines correctly, allowing you to separate the wheat from the chaff. When doing so, one can often uncover preexisting work that solves your problem for you, the answers to relevant factual questions, and so on. It is rare to find a situation where search engines are outright <em>useless--</em> at the very least they tend to point you in the direction of useful information.</p>\n<p>Further, the time cost of setting up and refining a search is extremely low, meaning that most of the time \"just Google it\" should in fact be your default response to a situation where you don't have very much information.<sup>[1]</sup> Overall, I consider one's ability to use search engines-- and, just as importantly, one's ability to recognize what types of situations can benefit from using them-- a basic but fairly significant instrumental rationality skill.</p>\n<p>Much of the above sounds extremely obvious, and in point of fact it should be-- but the fact remains that people don't use search engines anywhere near as often as they seemingly should. I've frequently found myself in situations where someone in the same room as me asks me a trivially searchable factual question while we are both using computers. Worse still, I've been in situations where people do the same over IRC! The existence of <a href=\"http://lmgtfy.com/?q=lmgtfy\">lmgtfy</a> indicates that others have noticed this issue before, and yet it remains a problem.</p>\n<p>So, how can we do better?</p>\n<p>One easy trick that I've found very helpful is to use <a href=\"http://www.goodsearch.com/faq\">Goodsearch</a> instead of Google. Goodsearch is a service that automatically donates a cent to a charity of your choice whenever you search.<sup>[2] </sup>Further, it can be installed into your search toolbar in Firefox, making the activation cost of using Goodsearch rather than Google essentially zero if, like me, you tend to search in the search bar instead of the URL field. Goodsearch has had profound effects on my tendency to perform searches because it gives me a little hit of \"doing good\" every time I perform a search, thus encouraging me to do so in more situations, thus causing me to accrue more money via Goodsearch, etc.</p>\n<p>This has not only made me more productive by causing me to search more but added positive externalities to every search I conduct. Earlier, I would say that I frequently used search engines to find out information about a new topic or project-- now I would say that I nearly automatically do this as the first step in most situations where I need some information before proceeding. The potential information gained from a search is very high, the costs of performing a search are very low, and with Goodsearch you can donate a little bit to charity while you do so.</p>\n<p>If you're reading this in Firefox and haven't already spent large amounts of time getting used to advanced search methods in other engines (and maybe even if you have), I strongly suggest navigating over to <a href=\"http://www.goodsearch.com/\">Goodsearch</a>, signing up for an account, and installing the <a href=\"http://www.goodsearch.com/toolbar/mode/plugin\">Goodsearch App</a> to make it your default toolbar search. For me, this proved to be a big win-- opportunities to increase instrumental rationality for only a minimal time expenditure while also earning free money for charity are not exactly common!</p>\n<p>&nbsp;</p>\n<p>[1] Note that there are some things you might not want to Google. I would, for instance, be very careful about what terms I used if I were looking into the history of political assassinations.</p>\n<p>[2] Before anyone gets <em>too</em> clever, <a href=\"http://www.goodsearch.com/faq\">there are restrictions</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hdRzQ8TGJYDacmdZ9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -2, "extendedScore": null, "score": 1.189530702693848e-06, "legacy": true, "legacyId": "22497", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Jq73GozjsuhdwMLEG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T15:51:40.077Z", "modifiedAt": null, "url": null, "title": "[Link] More Right launched", "slug": "link-more-right-launched", "viewCount": null, "lastCommentedAt": "2017-06-17T04:36:39.412Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "mstevens", "createdAt": "2009-05-07T14:46:38.489Z", "isAdmin": false, "displayName": "mstevens"}, "userId": "wgKFztEMLyjFRm4ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2X6zJwWTrMbf73q5R/link-more-right-launched", "pageUrlRelative": "/posts/2X6zJwWTrMbf73q5R/link-more-right-launched", "linkUrl": "https://www.lesswrong.com/posts/2X6zJwWTrMbf73q5R/link-more-right-launched", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20More%20Right%20launched&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20More%20Right%20launched%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2X6zJwWTrMbf73q5R%2Flink-more-right-launched%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20More%20Right%20launched%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2X6zJwWTrMbf73q5R%2Flink-more-right-launched", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2X6zJwWTrMbf73q5R%2Flink-more-right-launched", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 141, "htmlBody": "<p>Various people (including <a href=\"/user/Konkvistador/overview/\">Konkvistador</a> who has been talking about it the most) have launched their blog <a href=\"http://www.moreright.net/\">More Right</a></p>\n<p>\"A group blog, More Right is a place to discuss the many things that are touched by politics that we prefer wouldn&rsquo;t be, as well as right wing ideas in general. It grew out of the correspondences among like minded people in late 2012, who first began their journey studying the findings of modern cognitive science on the failings of human reasoning and ended it reading serious 19th century gentlemen denouncing democracy. Surveying modernity, we found cracks in its fa&ccedil;ade. Findings and seemingly correct ideas, carefully bolted down and hidden, met with disapproving stares and inarticulate denunciation when unearthed. This only whetted our appetites. Proceeding from the surface to the foundations, we found them lacking. This is reflected in the spirit of the site.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2X6zJwWTrMbf73q5R", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 22, "extendedScore": null, "score": 1.1898440113950995e-06, "legacy": true, "legacyId": "22498", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 106, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T17:26:33.879Z", "modifiedAt": null, "url": null, "title": "Antijargon Project", "slug": "antijargon-project", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.606Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R6coM4SgNTu5uwHLD/antijargon-project", "pageUrlRelative": "/posts/R6coM4SgNTu5uwHLD/antijargon-project", "linkUrl": "https://www.lesswrong.com/posts/R6coM4SgNTu5uwHLD/antijargon-project", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Antijargon%20Project&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAntijargon%20Project%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6coM4SgNTu5uwHLD%2Fantijargon-project%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Antijargon%20Project%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6coM4SgNTu5uwHLD%2Fantijargon-project", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6coM4SgNTu5uwHLD%2Fantijargon-project", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 199, "htmlBody": "<p>When a group of people talk to each other a lot they develop terms that they can use in place of larger concepts.  This makes it easier to talk to people inside the group, but then it's harder to talk about the same ideas with people outside the group.  If we were smart enough to keep up fully independent vocabularies where we would always use the right words for the people we were talking to, this wouldn't be an issue.  But instead we get in the habit of saying weird words, and then when we want to talk to people who don't know those words we either struggle to find words they know or waste a lot of time introducing words.  Especially when the group jargon term offers only a minor advantage over the non-jargon phrasing I think this is a bad tradeoff if you also want to speak to people outside the group.</p>\n<p>Recently I've been working on using as little jargon as possible.  Pushing myself to speak conventionally, even when among people who would understand weird terms a little faster, can be frustrating, but I think I'm also getting better at it.</p>\n<p>&nbsp;</p>\n<p><small><em>I also posted this <a href=\"http://www.jefftk.com/news/2013-05-05\">on my blog</a></em></small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R6coM4SgNTu5uwHLD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 19, "extendedScore": null, "score": 1.1899118129444317e-06, "legacy": true, "legacyId": "22499", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T20:48:48.329Z", "modifiedAt": null, "url": null, "title": "Meetup : London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed ", "slug": "meetup-london-special-guests-jaan-tallinn-and-michael-vassar", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.751Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kerspoon", "createdAt": "2011-12-27T09:53:49.512Z", "isAdmin": false, "displayName": "kerspoon"}, "userId": "XvZ9yyyJNeDwWhECW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xokDuadRy2ndEMTr2/meetup-london-special-guests-jaan-tallinn-and-michael-vassar", "pageUrlRelative": "/posts/xokDuadRy2ndEMTr2/meetup-london-special-guests-jaan-tallinn-and-michael-vassar", "linkUrl": "https://www.lesswrong.com/posts/xokDuadRy2ndEMTr2/meetup-london-special-guests-jaan-tallinn-and-michael-vassar", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Special%20Guests%3A%20Jaan%20Tallinn%20and%20Michael%20Vassar%20of%20MetaMed%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Special%20Guests%3A%20Jaan%20Tallinn%20and%20Michael%20Vassar%20of%20MetaMed%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxokDuadRy2ndEMTr2%2Fmeetup-london-special-guests-jaan-tallinn-and-michael-vassar%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Special%20Guests%3A%20Jaan%20Tallinn%20and%20Michael%20Vassar%20of%20MetaMed%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxokDuadRy2ndEMTr2%2Fmeetup-london-special-guests-jaan-tallinn-and-michael-vassar", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxokDuadRy2ndEMTr2%2Fmeetup-london-special-guests-jaan-tallinn-and-michael-vassar", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mh'>London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 May 2013 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">London (Shakespeares Head, Holborn)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We have three specials guests! Jaan, Michael, and Cat (see below) are flying in to the UK and will be joining us for a meetup. As usual, it is simply a few people with common interests chatting for a few hours. Anyone can come along, don't feel like you need to have read the sequences. It's a fun way to spend a few hours. It's also nice to have people to bounce ideas off - we are a friendly bunch. Hope to see you there,\nFor more information see our google group (link below) or message me (kerspoon)\nGuests:\n- Jaan Tallinn, who participated in the development of Skype and Kazaa.\n- Michael Vassar, the former president of the Singularity Institute and current Chief Science Officer of MetaMed.\n- Cat Lavigne, CFAR instructor.\nSee:\nhttps://groups.google.com/forum/?fromgroups=#!topic/lesswronglondon/_h6lGBjnO9Q\n<a href=\"http://lesswrong.com/r/discussion/lw/had/michael_vassar_in_europe/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/had/michael_vassar_in_europe/</a> <a href=\"http://lesswrong.com/r/discussion/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mh'>London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed </a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xokDuadRy2ndEMTr2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 1.1900563322893164e-06, "legacy": true, "legacyId": "22500", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Special_Guests__Jaan_Tallinn_and_Michael_Vassar_of_MetaMed_\">Discussion article for the meetup : <a href=\"/meetups/mh\">London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 May 2013 01:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">London (Shakespeares Head, Holborn)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We have three specials guests! Jaan, Michael, and Cat (see below) are flying in to the UK and will be joining us for a meetup. As usual, it is simply a few people with common interests chatting for a few hours. Anyone can come along, don't feel like you need to have read the sequences. It's a fun way to spend a few hours. It's also nice to have people to bounce ideas off - we are a friendly bunch. Hope to see you there,\nFor more information see our google group (link below) or message me (kerspoon)\nGuests:\n- Jaan Tallinn, who participated in the development of Skype and Kazaa.\n- Michael Vassar, the former president of the Singularity Institute and current Chief Science Officer of MetaMed.\n- Cat Lavigne, CFAR instructor.\nSee:\nhttps://groups.google.com/forum/?fromgroups=#!topic/lesswronglondon/_h6lGBjnO9Q\n<a href=\"http://lesswrong.com/r/discussion/lw/had/michael_vassar_in_europe/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/had/michael_vassar_in_europe/</a> <a href=\"http://lesswrong.com/r/discussion/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/\" rel=\"nofollow\">http://lesswrong.com/r/discussion/lw/h95/want_to_have_a_cfar_instructor_visit_your_lw_group/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_Special_Guests__Jaan_Tallinn_and_Michael_Vassar_of_MetaMed_1\">Discussion article for the meetup : <a href=\"/meetups/mh\">London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed </a></h2>", "sections": [{"title": "Discussion article for the meetup : London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed ", "anchor": "Discussion_article_for_the_meetup___London_Special_Guests__Jaan_Tallinn_and_Michael_Vassar_of_MetaMed_", "level": 1}, {"title": "Discussion article for the meetup : London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed ", "anchor": "Discussion_article_for_the_meetup___London_Special_Guests__Jaan_Tallinn_and_Michael_Vassar_of_MetaMed_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Ay6GBGNcCgP55dRQ7", "Yh6hrJmFZ7FpbDGK8"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T22:35:00.823Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley: Information theory and the art of conversation", "slug": "meetup-berkeley-information-theory-and-the-art-of", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AAesocP83xtPLdYna/meetup-berkeley-information-theory-and-the-art-of", "pageUrlRelative": "/posts/AAesocP83xtPLdYna/meetup-berkeley-information-theory-and-the-art-of", "linkUrl": "https://www.lesswrong.com/posts/AAesocP83xtPLdYna/meetup-berkeley-information-theory-and-the-art-of", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%3A%20Information%20theory%20and%20the%20art%20of%20conversation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%3A%20Information%20theory%20and%20the%20art%20of%20conversation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAAesocP83xtPLdYna%2Fmeetup-berkeley-information-theory-and-the-art-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%3A%20Information%20theory%20and%20the%20art%20of%20conversation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAAesocP83xtPLdYna%2Fmeetup-berkeley-information-theory-and-the-art-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAAesocP83xtPLdYna%2Fmeetup-berkeley-information-theory-and-the-art-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/mi\">Berkeley: Information theory and the art of conversation</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">08 May 2013 07:30:00PM (-0700)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Berkeley, CA</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p><strong>Abstract:</strong> A Bayesian definition of surprise is as follows: Given a distribution P over models M and some observed data D, the surprise of D is the Kullback-Liebler divergence from the prior to the posterior:</p>\n<p><a rel=\"nofollow\" href=\"http://goo.gl/cKE6w\">http://goo.gl/cKE6w</a></p>\n<p>A good experiment or a good conversation is one that has a high expectation of surprise, E[S(D, M)]. In this meetup we will practice having good conversations by using the strategy \"Ask the question whose answer will surprise you most.\"</p>\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n<p><a rel=\"nofollow\" href=\"http://groups.google.com/group/bayarealesswrong\">http://groups.google.com/group/bayarealesswrong</a></p>\n<p>or call me at:</p>\n<p><a rel=\"nofollow\" href=\"http://i.imgur.com/Vcafy.png\">http://i.imgur.com/Vcafy.png</a></p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/mi\">Berkeley: Information theory and the art of conversation</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AAesocP83xtPLdYna", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.1901322400920453e-06, "legacy": true, "legacyId": "22502", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Information_theory_and_the_art_of_conversation\">Discussion article for the meetup : <a href=\"/meetups/mi\">Berkeley: Information theory and the art of conversation</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">08 May 2013 07:30:00PM (-0700)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Berkeley, CA</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p><strong>Abstract:</strong> A Bayesian definition of surprise is as follows: Given a distribution P over models M and some observed data D, the surprise of D is the Kullback-Liebler divergence from the prior to the posterior:</p>\n<p><a rel=\"nofollow\" href=\"http://goo.gl/cKE6w\">http://goo.gl/cKE6w</a></p>\n<p>A good experiment or a good conversation is one that has a high expectation of surprise, E[S(D, M)]. In this meetup we will practice having good conversations by using the strategy \"Ask the question whose answer will surprise you most.\"</p>\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n<p><a rel=\"nofollow\" href=\"http://groups.google.com/group/bayarealesswrong\">http://groups.google.com/group/bayarealesswrong</a></p>\n<p>or call me at:</p>\n<p><a rel=\"nofollow\" href=\"http://i.imgur.com/Vcafy.png\">http://i.imgur.com/Vcafy.png</a></p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Information_theory_and_the_art_of_conversation1\">Discussion article for the meetup : <a href=\"/meetups/mi\">Berkeley: Information theory and the art of conversation</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley: Information theory and the art of conversation", "anchor": "Discussion_article_for_the_meetup___Berkeley__Information_theory_and_the_art_of_conversation", "level": 1}, {"title": "Discussion article for the meetup : Berkeley: Information theory and the art of conversation", "anchor": "Discussion_article_for_the_meetup___Berkeley__Information_theory_and_the_art_of_conversation1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T23:19:05.116Z", "modifiedAt": null, "url": null, "title": "Maximizing Your Donations via a Job", "slug": "maximizing-your-donations-via-a-job", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:07.318Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexei", "createdAt": "2010-08-02T15:14:11.411Z", "isAdmin": false, "displayName": "Alexei"}, "userId": "CD3DC5D7GHtgBmxz5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z6dmoLyfBdmo6HEss/maximizing-your-donations-via-a-job", "pageUrlRelative": "/posts/Z6dmoLyfBdmo6HEss/maximizing-your-donations-via-a-job", "linkUrl": "https://www.lesswrong.com/posts/Z6dmoLyfBdmo6HEss/maximizing-your-donations-via-a-job", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Maximizing%20Your%20Donations%20via%20a%20Job&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaximizing%20Your%20Donations%20via%20a%20Job%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6dmoLyfBdmo6HEss%2Fmaximizing-your-donations-via-a-job%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Maximizing%20Your%20Donations%20via%20a%20Job%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6dmoLyfBdmo6HEss%2Fmaximizing-your-donations-via-a-job", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6dmoLyfBdmo6HEss%2Fmaximizing-your-donations-via-a-job", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 6603, "htmlBody": "<p>In November of 2012 I set a goal for myself: find the most x-risk reducing role I can fill. At first I thought it would be by working directly with <a href=\"http://intelligence.org/\">MIRI</a>, but after a while it became clear that I could contribute more by simply donating. So my goal became: find the highest paying job, so I can donate lots of money to <a href=\"http://appliedrationality.org/\">CFAR</a> and <a href=\"http://intelligence.org/\">MIRI</a>.</p>\n<p>A little bit of background on me. Started programming in 2000. Graduated in 2009 with Bachelor's in computer science. Worked for about a year and a half at a game company. Then did my own game startup for about a year. Then moved to the bay area and joined a game startup here, which was acquired 10 months later. Worked a bit at the new company and then left. So, just under four years of professional programming experience, but primarily in the game industry. Almost no leadership / managerial experience, aside from the startup I did where I hired freelancers.</p>\n<p>Below is my experience of finding a software engineering job in the Silicon Valley. If you are not an engineer or not in the Silicon Valley, I think you'll still find a lot of useful information here.</p>\n<p>&nbsp;</p>\n<h2><strong>Pre-game</strong></h2>\n<p>Before sending out my resume, I spent about a month preparing. I read <a href=\"http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/ref=sr_1_1?ie=UTF8&amp;qid=1367534120&amp;sr=8-1&amp;keywords=intro+to+algorithms\" target=\"_blank\">Intro to Algorithms</a>, which was very good overall, but not a huge help in preparing for interviews.<a href=\"/lw/hd1/maximizing_your_donations_via_a_job/#1\">[1]</a> I read <a href=\"http://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/098478280X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1367534155&amp;sr=1-1&amp;keywords=cracking+the+coding+interview\" target=\"_blank\">Cracking the Coding Interview</a>, which was extremely helpful. (If you read only one book to prepare, make it this one.) The book has a lot of questions that are similar to the ones you'll actually see during interviews. I also did TopCoder problems, which were pretty helpful as well.<a href=\"/lw/hd1/maximizing_your_donations_via_a_job/#2\">[2]</a> Looking back, I wish I spent more time finding actual interview questions online and doing more of those (that's why CCI book was so helpful).</p>\n<p>After several weeks of&nbsp;preparation, I compiled a long list of companies I was going to apply to. I checked on <a href=\"http://www.glassdoor.com/index.htm\">GlassDoor</a> to see what kind of salary I could expect at each one. I then rated all the companies. Companies with low salaries and poor personal fit received the lowest rating.</p>\n<p>I started by applying to companies with the lowest ratings. This way I could use them as practice for the companies I thought would actually make a competitive offer. This was the right move and worked very well. (Another friend of mine did the same approach with good results as well.) Remember, you are not just doing those interviews to practice the coding problems, you are practicing pitching yourself as well.</p>\n<p>&nbsp;</p>\n<h2><strong>Interviewing with a company</strong></h2>\n<p>Standard procedure for applying to a tech company:</p>\n<p>1. Send them your resume.</p>\n<ul>\n<li>Proofread your resume. Let your friends proofread it.</li>\n<li>Make sure there are only relevant things on it. When I applied to tech companies, I removed a lot of game-specific things from my resume. When I applied to companies that did 3D graphics, I made sure I had all my 3D graphics experience listed. I ended up with two version of my resume.</li>\n<li>Have your resume in DOC, PDF, and TXT formats. This way you'll always have the right one when you upload / paste it.</li>\n<li>For a few companies, I had a friend or friend of a friend who referred me. This REALLY HELPS in two ways: 1) your resume will be processed a lot faster, 2) if your friend is a great engineer/employee, you'll be taken a lot more seriously, and the company will fight for you a lot harder.</li>\n</ul>\n<div><br /></div>\n<p style=\"margin-bottom: 0in;\">2. You'll get an email from the recruiter and setup a time to speak, where you'll talk about yourself, what you've done, why you are interested in their company, and so on. You can and should ask them questions as well.</p>\n<ul>\n<li>When you start getting multiple calls each day, make sure you know who is calling. There is nothing worse than talking about the challenges of streaming music to a car sharing startup. (True story.)</li>\n<li>Read about the company on Wikipedia before the call. Know the basic stuff. Look at their website and read the About page.</li>\n<li>Find the thing that makes the company special and successful. Find the thing that you actually think is cool about the company. Those are your answers for why you want to work there.</li>\n<li>Ask non-technical questions: How is the company structured? How many teams are there? How many employees? Engineers? Think of other intelligent questions to ask.</li>\n<li>In my experience, it's not very beneficial to tell them you are interviewing with a dozen other companies. When they ask who else you are interviewing with, just name a few companies, especially the competitors / similar companies.</li>\n<li>Be SUPER NICE to your recruiter. They are your main point of contact with the company. They'll be the one fighting to get you the best offer.</li>\n</ul>\n<div><br /></div>\n<p style=\"margin-bottom: 0in;\">3. You'll have a technical phone interview with a software engineer where you'll solve a problem or two on <a href=\"http://collabedit.com/\" target=\"_blank\">collabedit</a> or some similar website. At the end, you'll get a few minutes to ask them questions too.</p>\n<ul>\n<li>All the usual interviewing tips apply here. E.g. talk out loud, your interviewer doesn't know what you are thinking.</li>\n<li>Most companies don't care what language you use, as long as it's mainstream. (I used C# for almost all my coding questions.)</li>\n<li>DO NOT start answering the question by writing code. If the questions seems vague, ask about the context. Who'll be using this solution? Definitely ask about the kind of data you are working with. If it's integers, are they random? Over some small range or over all possible integers?</li>\n<li>List out metrics for various approaches: brute-force solution, optimized for speed solution, optimized for memory solution. Here is a question I saw a few times: Write a data structure which can accept and store integers, and can check if there exist two integers that sum up to a given number. There are multiple solutions, and the best one depends on the ratio of addInteger to checkForSum calls.</li>\n<li>The previous steps should only take you a minute or two. Once you've decided what the best approach is, then you can write the solution. When you are done, check for errors, then run through several examples. Do a simple example and a slightly complicated example. When you find a bug, don't be hasty in fixing it. Understand why it happened and make sure you won't introduce new bugs by fixing it.</li>\n<li>If everything works, make sure you handle errors correctly. Can you handle invalid input? Input that violates your assumptions? (As a reminder, I leave &ldquo;\\\\Check for errors&rdquo; comments in appropriate spots as I code the solution.)</li>\n<li>When you are done, ask the interviewer questions. Ask them to tell you about what they do, if they haven't already. What have they been working on recently? What technologies/languages do they use at the company? Do they use Scrum/Agile? Pair-programming? Come up with other intelligent questions to ask.</li>\n</ul>\n<p>&nbsp;</p>\n<p>4. You'll be invited for an on-site interview which will be 3-6 hours long, at least half of which will be coding on a white-board. (Although, a friend told me he brought his laptop with him, and most people were fine with him coding on it.)</p>\n<ul>\n<li>All the previous tips apply.</li>\n<li>Be on time. Take bathroom breaks when you need them. I found that drinking water during the interview keeps me refreshed. Remember your posture, body-language, and eye-contact skills.</li>\n<li>Learn how to talk out loud as you are writing out your solution. If you are stuck, explain what you are thinking, and what your intuition is telling you.</li>\n<li>Learn how to read your interviewers. If you say, \"Here we should check for the null case or for empty array,\" and they go \"Yeah, yeah, okay,\" they are not the type of interviewer that really cares about error conditions, so you can be somewhat more lax there. By the time I was finishing my on-site interviews, I could tell if my solution was right just by the interviewer's body language.</li>\n<li>When you are done, ask them questions. What are they working on? What's the thing they like most about the company? What's their least favorite thing about the company? (Another way to phrase that: What's one thing you would change if you could change anything about the company?) Do they have to work overtime? How are the people here? Can you switch between projects? Are there company wide events? In all my interviews I've never met an interviewer that didn't try to sell their company really hard. People will always tell you their company is the best place to work.</li>\n<li>If the person is a manager or a director, ask them higher level questions. What kind of culture are they trying to create? What are the current big challenges? Where do they want the company to be in the next 5 years? How does one advance in the company? (Usually there is a managerial and a technical track.) How often are reviews done? How are they structured?</li>\n</ul>\n<p>&nbsp;</p>\n<p>5. You'll get a call from the recruiter congratulating you on an offer. They'll go over the offer details with you.</p>\n<ul>\n<li>Before they make you an offer, they'll check if you are actually seriously considering their company. If you told a startup you are also interviewing with Google, they might suspect that you are not seriously considering them. Unless you dissuade those fears, they might actually not even make you an offer. (Happened to me with Rdio.)</li>\n<li>If you didn't get an offer, try to get as much info as you can. What happened? What can you improve on? Below are the reasons why I didn't get an offer after an on-site interview: \n<ul>\n<li>Not doing well on a technical question. (Happened twice; one time because of a very obnoxious interviewer.)</li>\n<li>Not interviewing for quite the right position (that on-site interview ended early).</li>\n<li>Not having the necessary experience (a lot more important to startups than bigger companies).</li>\n<li>Not being passionate enough about the company.</li>\n</ul>\n</li>\n<li>If this is not a good timing for the offer, e.g. it's one of your first interviews, then tell them so. They will probably wait to give you the offer details until you are ready to consider it.</li>\n<li>The recruiter will likely ask what's important to you in an offer. How are you going to make your decision? What I've said is that compensation will be an important factor in my decision, but that the team/project/etc. are important considerations as well.</li>\n</ul>\n<p>&nbsp;</p>\n<p>6. You have a few days (usually around 5 business days) until the offer expires to decide if you want to accept it.</p>\n<ul>\n<li>Sometimes the offer will expire before you've received offers from other companies. This is why it's important to interview in rough order of ranking, so that you can just let those offers go, knowing you'll have much better ones soon. If you want to hold on to the offer, just ask your recruiter for an extension. It'll be much easier to get an extension at big companies, especially if you are interviewing for a generic position.</li>\n<li>If you decline the offer, let them know.</li>\n</ul>\n<p>&nbsp;</p>\n<p>Always be very nice, friendly, and polite. Walk the fine line between telling the truth and saying the right thing. Ideally, make sure those are the same. Even if you are interviewing with a company you have no intention of working at, make sure to find something you really like about them, something that makes them stand out to you. Always have a good answer to: \"Why do you want to work here?\"</p>\n<p>Before each on-site interview make sure you research the company thoroughly. Use their product. Think of ways to improve it. It's very helpful if you can meet with someone that works there and talk to them. See if they can give you any tips on the interview process. Some companies (e.g. AirBnB) want people that are <em>extremely</em> passionate about their product. Some companies focus more than usual on architectural questions. Many companies expect the engineers to have some familiarity with UI/UX and the ability to think about a feature from all angles.</p>\n<p>&nbsp;</p>\n<h2><strong>Managing your time</strong></h2>\n<p>I sent my resume to 78 companies, had at least a phone conversation with a recruiter with 27 of them, had an on-site interview with 16 companies, and received 12 offers. Out of those, I've only seriously considered 3. (Companies with lower ratings had an atrocious response rate.)</p>\n<p>My time-line ended up looking something like this:</p>\n<ul>\n<li>Week 1: Started applying to low-rated companies. About 2 phone interviews.</li>\n<li>Week 2: About 7 phone interviews. One on-site interview. Sending out more resumes.</li>\n<li>Week 3: About 3 phone interviews.</li>\n<li>Week 4: About 15 phone interviews. A few meetings with friends of friends, who ended up referring me. 1 on-site interview. Sent my resume to all the high-rated companies. (During this week interviewing became a full-time job.)</li>\n<li>Week 5: About 10 phone interviews. 4 on-site interviews.</li>\n<li>Week 6: 8 phone interviews. 4 on-site interviews.</li>\n<li>Week 7: 4 phone calls. 5 on-site interviews.</li>\n<li>Week 8: 12 phone calls. 2 on-site interviews.</li>\n<li>Week 9: About 8 calls a day for a few days, while I negotiated with my top companies.</li>\n<li>(These are strictly lower bounds for phone calls. On-site data is pretty accurate.)</li>\n</ul>\n<p>Some companies move fast, some companies move slow. Google took 2 weeks from the on-site interview to the offer call. This is very common for them, but most other companies move faster. With Amazon, I actually interviewed with two different branches. With one branch things were going well, until they dropped the ball and never got back to me, even after I pestered them. This is unusual; although, Twitter did something similar, but then ended up responding with an on-site invitation. With the other Amazon branch, when I got home from the on-site interview, I already had an email saying they were going to make an offer. This is extremely fast. (I had a very good reference for that position.) Most companies take about a week between on-site and offer. The whole process, from first call to offer, takes about three weeks.</p>\n<p>If your recruiter doesn't respond to you during 4 days or longer, shoot them an email. They might have forgotten to respond, or thought they did, or may be things are moving slowly, or may be they decided not to pursue. You want to be clear on where you stand with all the companies you are applying to.</p>\n<p>The timing is pretty important here. You want your top-rated companies to give you an offer within a span of a week. This way you'll be able to leverage all those offers against each other.</p>\n<p>If your current job position is already almost optimal for your goals, then it's possible you can do a few interviews, get a few offers and pick the best one, which will give you some marginal improvement. Or use those offers to leverage a raise at your existing company. But if you are pretty sure your current job has not been optimized for your goal, then I'd say, contrary to popular wisdom, just leave and spend a full month interviewing. (Or, even better, if you can, take a long \"vacation\".) You just can't do this kind of intense interviewing while holding another job. The one exception to this rule I can think of is if one of your highest-rated companies is a competitor with your current employer. Then you can leverage that!</p>\n<p>Value of information is extremely high during this process. Talk to all the companies you can, talk to all the people you can. Once you have the final list of companies you are considering, reduce your uncertainty on everything. Validate all your assumptions. (Example: I was <em>sure</em> Google matched donations up to $12k, but turns out it's only up to $6k.)</p>\n<p>&nbsp;</p>\n<h2><strong>How to evaluate your offer</strong></h2>\n<p>There are 4 basic components in an offer: sign-on bonus, base salary, equity, and bonus.</p>\n<p><strong>Sign-on bonus.</strong> Most companies will be okay offering something like $12k sign-on bonus. Some will offer more. Most startups probably won't offer any.</p>\n<p><strong>Base salary.</strong> This is pretty consistent across most companies. Based on your experience, you'll be given a title (e.g. Senior Software Engineer or SE 2), and that title will determine the range of the salary you can expect. If you are good, you can demand a salary at the top of that range, but it's extremely hard to go higher.</p>\n<p><strong>Equity.</strong> This is the most interesting part. A good amount of value will come from this portion. With a startup, it'll be most of it. Here are two things to pay attention to:</p>\n<ul>\n<li>Is the company public or private? If it's public, you are most likely going to be given RSUs (restricted stock units), which will basically convert to normal company shares when they vest. For private companies, see the section below.</li>\n<li>What's the vesting schedule? For almost all companies you'll get 25% of your shares right after your first year. (This is called a 'cliff'.) After that you'll be given the appropriate fraction either monthly (e.g. at Google) or quarterly (e.g. at Facebook). Amazon is an example of a company where the vesting schedule is somewhat different: 5% after year 1, 15% after year 2, and then 20% each semester for the next two years.</li>\n</ul>\n<p><strong>Bonus.</strong> This is the bonus system the company has setup. You can't negotiate it, but it's important to take it into account.</p>\n<ul>\n<li>There will usually be a cash bonus that's based on your salary. It'll have a target percent (e.g. 15%). If you can find out how many people hit their target, that will be very helpful. However, most companies don't share or simply don't have that information.</li>\n<li>Some companies also have equity bonuses. Try to get as much info on those as you can. Don't assume that you'll get the maximum bonus even if you work hard. If you have friends working at that company, ask them what kind of bonuses they've been getting.</li>\n<li>Lots of startups don't have bonus systems in place.</li>\n</ul>\n<p><strong>Other factors.</strong></p>\n<ul>\n<li>Donation matching: Google matches up to $6k (you donate $6k to any charity, they'll donate another $6k). Craigslist matches 3:1 up to 10% of your salary. Most companies don't have anything like that, and you can't negotiate it.</li>\n<li>Paid Time Off: Google offers 2 weeks, all other companies I was considering offer 3 weeks, and some even have unlimited PTO. This is not negotiable in most companies.</li>\n<li>Commute: how far will you have to travel to work? Are you okay moving closer to work? (Google and Facebook have shuttles that can pick you up almost anywhere, so you could work while you commute.)</li>\n<li>People/culture/community/team/project are all important factors as well, depending on what you want. If you are going to spend the next several years working on something, you should be building up skills that will still be valuable in the future.</li>\n</ul>\n<p>&nbsp;</p>\n<h2><strong>Thinking about private companies</strong></h2>\n<p>If the company is private, you might be given RSUs or you might be given stock options. With stock options, you'll have to pay the strike price to exercise your options. So the total value your options have is: (price of a share - strike price) * number of shares.</p>\n<p>You can't do anything with your shares until the company gets acquired or goes public. Some companies have liquidation events, but those are pretty rare. Most companies don't have them, and the ones that do only extend the opportunity to people that have been with the company for a while. There are also second-hand markets, but I don't know much about those.</p>\n<p>If you are completely risk-intolerant, then just go with a public company, and don't consider private companies. (This is actually not exactly true. Just because a company is public, doesn't mean its risk-free, and just because a company is private doesn't mean there is a lot of risk. There are other important factors like the size of the company, their market diversity, and how long they've been around.) If you are okay with some risk, then you want a company that's close to an IPO or is likely to get acquired soon. If you want to have a chance to make more than a few million dollars, either start your own company or join a very early stage startup (my top pick would be <a href=\"https://ripple.com/\">Ripple</a>). Before doing so, check out the stats on startups to make sure you understand how likely any given startup is to fail and make sure you understand the concepts of inside/outside view.</p>\n<p>&nbsp;</p>\n<h2><strong>Taxes</strong></h2>\n<p>It's crucial to understand all the tax implications of your salary, equity, and donations. I'm not going to go into all the details, there are a lot of resources out there for this, but you should definitely read them until it's crystal clear how you will be taxed. I'll highlight a few points:</p>\n<ul>\n<li>Understand the <a href=\"http://taxes.about.com/od/Federal-Income-Taxes/qt/Tax-Rates-For-The-2013-Tax-Year.htm\">tax rate schedule</a> and notice the new 39.6% tax bracket. If your income is $100k, that doesn't mean you get taxed 28% on all of it. 28% applies only to the income portion above $87,850. Also note that this is only the federal tax. Your state will have additional taxes as well. Aside from those percentages, there are a few other flat taxes, but they are considerably smaller in magnitude.</li>\n<li>The money you donate to a&nbsp;nonprofit&nbsp;(aka.&nbsp;501(c)(3)) organization can be subtracted from your taxable income. This means that you will most likely get a refund when you file your taxes. Why? Because when you fill out your W4 form, you'll basically tell your employer how much money to withhold from your paycheck for tax purposes. If you don't account for your future donations, more money will be withheld than is appropriate and the discrepancy will be paid back to you after you file your taxes. Ideally, you want to take your donations into account and fill out the W4 form such that there are no discrepancies. That means you'll get your money now rather than later. (I haven't gone through this process myself, so there is some uncertainty here.)</li>\n<li>You can claim tax deduction for up to 50% of your wages. That means if you make a lot of money in one year, even if you donate most of it, you'll be able to reduce your taxable income by a maximum of 50%. The rest goes over to the next year.</li>\n<li>When RSUs vest, their value is treated as ordinary income for tax purposes. When you sell them, the difference is taxed as a capital gain (or loss).</li>\n<li>Stock options have a more complicated set of tax rules, and you should understand them if you are considering a company that offers them.</li>\n<li>You can't have your employer donate money or stock for you to bypass the taxes. I've asked.</li>\n</ul>\n<p>&nbsp;</p>\n<h2><strong>Calculating donations</strong></h2>\n<p>To calculate exactly how much I could donate if I worked at a given company, I've created <a href=\"https://dl.dropboxusercontent.com/u/30954211/SalariesExample.xls\">this spreadsheet</a>. (This is an example with completely fictitious company offers with very low numbers, but the calculations should be correct.) Let me walk you through the spreadsheet.</p>\n<p>&nbsp;</p>\n<p><strong>Time discounting (Cell B1)</strong></p>\n<p>Money now is more valuable than money later. By how much? That's a very complicated question. If you invest your money now, you might be able to make something like 10%&nbsp;annually with some risk.<a href=\"/lw/hd1/maximizing_your_donations_via_a_job/#1\">[3]</a> If you are donating to a charity, and they are growing very rapidly, then they can do a lot with your money right now, and you should account for that as well. If you expect the charity to double in size/effectiveness/output in the next year, then you might use a discount rate as high as 50%. I chose to use 20% annual discount rate based on my own estimates. Since I'm doing monthly compounding, the spreadsheet value is slightly higher (~22%). You can look at the column K to see how the future value of a dollar is being discounted. Note, for example, that a dollar in 12 months is worth 80&cent;&nbsp;to me now. This discounting rate is especially important to keep in mind when examining startups, because almost all their compensation lies in the future. The further away it is, the more heavily you have to discount it.</p>\n<p>&nbsp;</p>\n<p><strong>Cost of living (Cell B2)</strong></p>\n<p>This is how much pre-tax money a year I'm not going to donate. See column L for the monthly expenses. We time-discount those dollars as well.</p>\n<p>&nbsp;</p>\n<p><strong>Offers (Cells A4-I15)</strong></p>\n<p>This is where you plug-in the offers you get. <em>Bonus</em> row is for cash bonus. <em>Equity</em> row is for the total equity the company offers you. I use the dollar amount, but you'll notice that for some of them I'm computing the dollar amount as: RSUs the company is giving me * current share price. For private companies, this is value I expect my equity to have when the company goes public. For Square it looks like: (percent of the company I'll own) * (my guess at valuation of the company at IPO) - (cost to exercise my options). For Twitter it looks like: (growth factor up to IPO) * (current price per share) * (RSUs I am granted). (Again, the numbers are completely made up.) In my calculations I'm not expecting public companies' share price to rise or fall. If you disagree, you should adjust for that as well.</p>\n<p>&nbsp;</p>\n<p><strong>Monthly projections (Cells A18-I66)</strong></p>\n<p>We are going to look at how much money we'll be making per month for the next four years. (Four years because our equity should be fully vested by that time.) If you are certain that you will stay at the company for less time than that, then you should consider a shorter timeline. This might affect companies differently. For example, most of the equity you get at Amazon comes during the last two years. If you are not going to be there, you are missing out on a big part of your offer.</p>\n<p>For companies that I was seriously considering, I created two columns: one for cash wages and one for equity wages. This way I can do taxes on them more precisely.</p>\n<p>Let's go through the Google's offer:</p>\n<ul>\n<li>\n<p>For the first year we'll be only making our standard salary.</p>\n</li>\n<li>\n<p>After the first year, we get our cash bonus (green font). Here we are assuming it'll be 15% of our salary. We also get 25% of our RSUs vested (salmon background).</p>\n</li>\n<li>\n<p>For the remainder of the second year, we are making our normal salary. Each month we also get 1/48<sup>th</sup> of our original equity offer.</p>\n</li>\n<li>\n<p>Google also has an equity bonus system, where each year you can get a bonus of up to 50% of your original equity offer. This bonus will be paid in RSUs, and it vests over 4 years, but with no cliff. So we count that as well, but I'm assuming I'm only going to get 15%, not the full 50%.</p>\n</li>\n<li>\n<p>In year 3 everything is basically the same, except now we got our second equity bonus, so we have two of them running simultaneously.</p>\n</li>\n<li>\n<p>In year 4, we have three of them running simultaneously.</p>\n</li>\n</ul>\n<p>For pre-IPO companies, I've estimated when they'll go IPO. Most have clauses in place that don't allow you to sell your shares until after half a year or so after the IPO. I'm assuming I will sell/donate all my shares then, and then continue selling/donating them as they continue vesting.</p>\n<p>&nbsp;</p>\n<p><strong>Sum (Cells A68-I71)</strong></p>\n<p>In row 68 we have the total sum. This is the amount of pre-tax dollars we expect to earn in the next four years (remember that this amount has been adjusted for time-discounting, so it'll seem much lower than you'd normally expect). L68 is how much money we are spending on ourselves during those four years.</p>\n<p>In row 69 we subtract our living expenses to get the amount of money we'll be able to donate. Note that I'm subtracting it from the cash column, leaving the equity column alone (for the companies where I split the two).</p>\n<p>In row 70 we account for taxes. Note that our living expenses already accounted for the taxes we pay up to $65k, so the rest of it will be taxed at around 28% or higher. You could sell your shares, or you could just donate your shares directly to your charity. (That's what we are doing with our Google offer.)</p>\n<p>In row 71 we simply sum up the donations from cash and equity.</p>\n<p>&nbsp;</p>\n<p>Disclaimer 1: while I tried as hard as I could to double check this spreadsheet, there might still be mistakes there, so use it with caution and triple check everything. The tax calculations as they are right now are wrong, and you'll have to redo them (basically the whole Row 70) based on your own numbers.</p>\n<p>Disclaimer 2: this spreadsheet is not great for evaluating an offer from a startup, since it doesn't capture the associated uncertainty and risk. Furthermore, if you expect the startup to succeed after more than 4 years, to correctly compare it to other companies you'll have to compute more than 48 months and potentially start accounting for things like promotions and raises.</p>\n<p>&nbsp;</p>\n<h2><strong>Picking the one</strong></h2>\n<p>All right, so how do you actually pick the best company? It's not as simple as picking the one with the highest EV, since you have to account for risk involved with startups and even pre-IPO companies. In fact, you should be surprised if your offers from public companies have a higher EV than offers from startups. If that's the case, I'd double check your calculations.</p>\n<p>This is where it becomes extremely crucial to narrow down your uncertainty. When is the company going to IPO? What is the likely valuation? Does the company have a lot of competitors? Does the company have the necessary talent to execute on their plan? What's the company's history? What is the employee churn rate (especially for executives)? How well is the company doing financially? Who are the investors? Etc, etc, etc... There is a ton of questions you should be asking, and you should be asking them to everyone whose opinion on this issue you can respect. Honest opinion from an informed and knowledgeable neutral party is worth a LOT here!</p>\n<p>You should also talk to the people at the company. Your recruiter will connect you to the right people if you ask. Keep in mind that nobody there will tell you that the company is going to go bankrupt or fail. But you can still get some valuable estimates, and then potentially discount them down a bit. You can even ask for their opinion on other companies you are interviewing with. Expect them to completely throw the other company under the bus though, but even so, you could get a lot of valuable criticism and bring it up when you talk to that other company. Overall, expect a lot of conflicting messages.</p>\n<p>Keep in mind the charities you'll be donating to. What kind of donors do they have already? Are most people donating a bit from their salary? In that case, a more risky venture might be reasonable. Can they really use some money right now, or would they be a lot more effective later on with a large capital? What's their time discount rate? If you care about your charity, you can help them diversify their donor pool.</p>\n<p>For me, it was a hard choice between big public companies (primary candidate: Google) and close to IPO companies (primary candidates: Twitter and Square).</p>\n<p>&nbsp;</p>\n<h2><strong>Negotiating</strong></h2>\n<p>You have to negotiate your offer. You have to <em>have to</em> <strong>have to</strong> HAVE TO. For any given company, you'll be able to get them to up their offer at least once and potentially thrice. Example: Google upped my offer three times.</p>\n<ul>\n<li>Some companies will tell you their offer is not negotiable. That's not true.</li>\n<li>It's much easier to leverage similar companies against each other. Leverage big public companies against each other; leverage pre-IPO companies against each other; etc... Leveraging between those categories is a bit more difficult, because startups know they can't compete with the raw cash value you are offered at bigger companies. The only thing they can do is up their equity offer and hope that they are a much better personal fit for you than the large companies.</li>\n<li>Recruiters will ask you very directly what the other companies are offering you. You can choose to disclose or not to disclose. If you don't disclose, the company will come back to you with their standard offer. That offer might be higher or lower than you expected. (Example: The first offer I got from Google was significantly worse than initial offers I got from Facebook and Amazon.) If you tell them what offers you have (and you should only disclose details of your very best offers), then they'll very likely match or come in a bit stronger. Usually you don't have much to gain by disclosing your other offers upfront. You can always do so later. However, you should let your recruiters know that other companies <em>did</em> make an offer, or you are expecting them to. That gives you more leveraging power.</li>\n<li>Sign-on bonus is very easy to negotiate. You can easily convince a company to match a sign-on bonus their competitor has offered.</li>\n<li>Negotiating salary is much harder, but, again, usually you can convince a company to match a salary their competitor has offered or at least come closer to it. If you are interviewing with startups, their salary offer will usually be lower than at bigger companies and even harder to negotiate. (\"Cash is king\" is the common phrase used there.)</li>\n</ul>\n<p><strong>First&nbsp;</strong><strong>negotiating&nbsp;phase:</strong> simply email / call back your recruiter (who is now your best friend, right?) and tell them that the offer is somewhat lower than you expected, you have other better offers from other companies, and you are wondering if they can increase their offer. If the company made you a clearly worse offer than another similar company, you should be very open about it.</p>\n<p><strong>Second negotiating phase:</strong> matching other companies. This is when it makes the most sense to disclose your other offers. For example, I used my Amazon and Facebook offers to convince Google to up their offer significantly. For some reason their original offer was very low, but seeing their competitors with much better offers convinced them to update pretty quickly. You can also bring up the perks one company has that the other doesn't (e.g. donation matching or unlimited PTO). The company can make up for that with salary/equity. There is some difficulty in using offers from private companies as leverage, because there is not much information you can disclose about them. You can talk about the number of shares you'll have, but it might not mean anything to the other recruiters if they are not familiar with the startup.</p>\n<p><strong>Third&nbsp;negotiating&nbsp;phase:</strong> once you picked the company you'll work for, go back to them and say something along the lines of \"I really like the offer and the company, but there are a few things that don't make it ideal for me. One of your competitors did this, and another company has that. Right now I'm inclined to go with your competitor, but it's a tough decision, and I would rather go with you. I think if you can make me an offer with the following parameters, it'll make my decision extremely easy, and I'll sign on the spot.\" Include offer letters from other companies, especially the ones that have them beat or beat on some parameters. Notice the key promise at the end: <em>you will sign with them</em>. Your recruiter will have a lot more leverage in fighting for you if you make that promise. You are not legally obligated to follow through with your promise, but I wouldn't advise breaking it or using it just to extract more value to use as leverage against other companies. Use this tactic at the very end to extract that last bit of value from the company that's already the best. This is what I did with Google. I asked for about 3% higher salary and 12% more equity than what they were offering, and they came back with the exact numbers I requested, which means I should have asked for more. My advice would be to ask for about twice or may be even three times as much (6% and 30% respectively). Even if they come back with a compromise, it'll very likely be more than 3% and 12% increase. If not, you can try to barter one more time.</p>\n<p>I'm sure some people will cringe at this kind of haggling, but, in all honesty, this is what recruiters expect, and they are very much used to it. Nobody even blinked an eye when I started negotiating, even on second and third rounds. However, some recruiters might try to make you feel guilty. They'll say that if you really want to work at their startup, then you shouldn't really care about your compensation. Most points they'll make will even be valid, but if you are trying to optimize for donations, then you have to make the compensation the most important factor in your decision. I've actually told most of my recruiters that I plan to donate most of my salary to charities. I don't think that got me higher offers, but it made me come off less like a greedy jerk.</p>\n<p>At the end of the day, the company wants you, but they want to pay you as little as possible. <em>But</em>, given the choice of having you and paying you the most you&nbsp;deserve&nbsp;VS. not having you, all companies will pick the first option. ALL OF THEM. This is one of the best perks of being a talented software engineer in the bay area.</p>\n<p>Once you accept the offer, don't forget to email everyone else and let them know. Thank everyone that helped you. Some recruiters will be surprised by your decision, and some will even fight really hard to get you to reconsider.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p><a name=\"1\"></a>[1] None of the interviews required a data structure more complicated than a heap. All the answers had a very easy to compute complexity, either polynomial, polynomial * logarithmic, or factorial. The most weird one was probably O(&radic;n) for computing prime numbers.</p>\n<p><a name=\"2\"></a>[2] Some problems I did during actual single-round match-up (SRM) competitions, which is good for training yourself how to code and think faster than you are used to. I also did a lot of old SRM problems, which have solutions and explanations posted in case I couldn't get them. I could easily do problem 1 &amp; 2 in the easy division, and could do problem 3 most of the time. I didn't really bother with the hard division, and none of the interview questions were ever as hard as problem 3 in the easy division.</p>\n<p><a name=\"3\"></a>[3] According to the comments, this number is too high. Pick your own best estimate.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JsJPrdgRGRqnci8cZ": 2, "4kQXps8dYsKJgaayN": 2, "xexCWMyds6QLWognu": 1, "qAvbtzdG2A2RBn7in": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z6dmoLyfBdmo6HEss", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 123, "baseScore": 177, "extendedScore": null, "score": 0.000414, "legacy": true, "legacyId": "22501", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 178, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In November of 2012 I set a goal for myself: find the most x-risk reducing role I can fill. At first I thought it would be by working directly with <a href=\"http://intelligence.org/\">MIRI</a>, but after a while it became clear that I could contribute more by simply donating. So my goal became: find the highest paying job, so I can donate lots of money to <a href=\"http://appliedrationality.org/\">CFAR</a> and <a href=\"http://intelligence.org/\">MIRI</a>.</p>\n<p>A little bit of background on me. Started programming in 2000. Graduated in 2009 with Bachelor's in computer science. Worked for about a year and a half at a game company. Then did my own game startup for about a year. Then moved to the bay area and joined a game startup here, which was acquired 10 months later. Worked a bit at the new company and then left. So, just under four years of professional programming experience, but primarily in the game industry. Almost no leadership / managerial experience, aside from the startup I did where I hired freelancers.</p>\n<p>Below is my experience of finding a software engineering job in the Silicon Valley. If you are not an engineer or not in the Silicon Valley, I think you'll still find a lot of useful information here.</p>\n<p>&nbsp;</p>\n<h2 id=\"Pre_game\"><strong>Pre-game</strong></h2>\n<p>Before sending out my resume, I spent about a month preparing. I read <a href=\"http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/ref=sr_1_1?ie=UTF8&amp;qid=1367534120&amp;sr=8-1&amp;keywords=intro+to+algorithms\" target=\"_blank\">Intro to Algorithms</a>, which was very good overall, but not a huge help in preparing for interviews.<a href=\"/lw/hd1/maximizing_your_donations_via_a_job/#1\">[1]</a> I read <a href=\"http://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/098478280X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1367534155&amp;sr=1-1&amp;keywords=cracking+the+coding+interview\" target=\"_blank\">Cracking the Coding Interview</a>, which was extremely helpful. (If you read only one book to prepare, make it this one.) The book has a lot of questions that are similar to the ones you'll actually see during interviews. I also did TopCoder problems, which were pretty helpful as well.<a href=\"/lw/hd1/maximizing_your_donations_via_a_job/#2\">[2]</a> Looking back, I wish I spent more time finding actual interview questions online and doing more of those (that's why CCI book was so helpful).</p>\n<p>After several weeks of&nbsp;preparation, I compiled a long list of companies I was going to apply to. I checked on <a href=\"http://www.glassdoor.com/index.htm\">GlassDoor</a> to see what kind of salary I could expect at each one. I then rated all the companies. Companies with low salaries and poor personal fit received the lowest rating.</p>\n<p>I started by applying to companies with the lowest ratings. This way I could use them as practice for the companies I thought would actually make a competitive offer. This was the right move and worked very well. (Another friend of mine did the same approach with good results as well.) Remember, you are not just doing those interviews to practice the coding problems, you are practicing pitching yourself as well.</p>\n<p>&nbsp;</p>\n<h2 id=\"Interviewing_with_a_company\"><strong>Interviewing with a company</strong></h2>\n<p>Standard procedure for applying to a tech company:</p>\n<p>1. Send them your resume.</p>\n<ul>\n<li>Proofread your resume. Let your friends proofread it.</li>\n<li>Make sure there are only relevant things on it. When I applied to tech companies, I removed a lot of game-specific things from my resume. When I applied to companies that did 3D graphics, I made sure I had all my 3D graphics experience listed. I ended up with two version of my resume.</li>\n<li>Have your resume in DOC, PDF, and TXT formats. This way you'll always have the right one when you upload / paste it.</li>\n<li>For a few companies, I had a friend or friend of a friend who referred me. This REALLY HELPS in two ways: 1) your resume will be processed a lot faster, 2) if your friend is a great engineer/employee, you'll be taken a lot more seriously, and the company will fight for you a lot harder.</li>\n</ul>\n<div><br></div>\n<p style=\"margin-bottom: 0in;\">2. You'll get an email from the recruiter and setup a time to speak, where you'll talk about yourself, what you've done, why you are interested in their company, and so on. You can and should ask them questions as well.</p>\n<ul>\n<li>When you start getting multiple calls each day, make sure you know who is calling. There is nothing worse than talking about the challenges of streaming music to a car sharing startup. (True story.)</li>\n<li>Read about the company on Wikipedia before the call. Know the basic stuff. Look at their website and read the About page.</li>\n<li>Find the thing that makes the company special and successful. Find the thing that you actually think is cool about the company. Those are your answers for why you want to work there.</li>\n<li>Ask non-technical questions: How is the company structured? How many teams are there? How many employees? Engineers? Think of other intelligent questions to ask.</li>\n<li>In my experience, it's not very beneficial to tell them you are interviewing with a dozen other companies. When they ask who else you are interviewing with, just name a few companies, especially the competitors / similar companies.</li>\n<li>Be SUPER NICE to your recruiter. They are your main point of contact with the company. They'll be the one fighting to get you the best offer.</li>\n</ul>\n<div><br></div>\n<p style=\"margin-bottom: 0in;\">3. You'll have a technical phone interview with a software engineer where you'll solve a problem or two on <a href=\"http://collabedit.com/\" target=\"_blank\">collabedit</a> or some similar website. At the end, you'll get a few minutes to ask them questions too.</p>\n<ul>\n<li>All the usual interviewing tips apply here. E.g. talk out loud, your interviewer doesn't know what you are thinking.</li>\n<li>Most companies don't care what language you use, as long as it's mainstream. (I used C# for almost all my coding questions.)</li>\n<li>DO NOT start answering the question by writing code. If the questions seems vague, ask about the context. Who'll be using this solution? Definitely ask about the kind of data you are working with. If it's integers, are they random? Over some small range or over all possible integers?</li>\n<li>List out metrics for various approaches: brute-force solution, optimized for speed solution, optimized for memory solution. Here is a question I saw a few times: Write a data structure which can accept and store integers, and can check if there exist two integers that sum up to a given number. There are multiple solutions, and the best one depends on the ratio of addInteger to checkForSum calls.</li>\n<li>The previous steps should only take you a minute or two. Once you've decided what the best approach is, then you can write the solution. When you are done, check for errors, then run through several examples. Do a simple example and a slightly complicated example. When you find a bug, don't be hasty in fixing it. Understand why it happened and make sure you won't introduce new bugs by fixing it.</li>\n<li>If everything works, make sure you handle errors correctly. Can you handle invalid input? Input that violates your assumptions? (As a reminder, I leave \u201c\\\\Check for errors\u201d comments in appropriate spots as I code the solution.)</li>\n<li>When you are done, ask the interviewer questions. Ask them to tell you about what they do, if they haven't already. What have they been working on recently? What technologies/languages do they use at the company? Do they use Scrum/Agile? Pair-programming? Come up with other intelligent questions to ask.</li>\n</ul>\n<p>&nbsp;</p>\n<p>4. You'll be invited for an on-site interview which will be 3-6 hours long, at least half of which will be coding on a white-board. (Although, a friend told me he brought his laptop with him, and most people were fine with him coding on it.)</p>\n<ul>\n<li>All the previous tips apply.</li>\n<li>Be on time. Take bathroom breaks when you need them. I found that drinking water during the interview keeps me refreshed. Remember your posture, body-language, and eye-contact skills.</li>\n<li>Learn how to talk out loud as you are writing out your solution. If you are stuck, explain what you are thinking, and what your intuition is telling you.</li>\n<li>Learn how to read your interviewers. If you say, \"Here we should check for the null case or for empty array,\" and they go \"Yeah, yeah, okay,\" they are not the type of interviewer that really cares about error conditions, so you can be somewhat more lax there. By the time I was finishing my on-site interviews, I could tell if my solution was right just by the interviewer's body language.</li>\n<li>When you are done, ask them questions. What are they working on? What's the thing they like most about the company? What's their least favorite thing about the company? (Another way to phrase that: What's one thing you would change if you could change anything about the company?) Do they have to work overtime? How are the people here? Can you switch between projects? Are there company wide events? In all my interviews I've never met an interviewer that didn't try to sell their company really hard. People will always tell you their company is the best place to work.</li>\n<li>If the person is a manager or a director, ask them higher level questions. What kind of culture are they trying to create? What are the current big challenges? Where do they want the company to be in the next 5 years? How does one advance in the company? (Usually there is a managerial and a technical track.) How often are reviews done? How are they structured?</li>\n</ul>\n<p>&nbsp;</p>\n<p>5. You'll get a call from the recruiter congratulating you on an offer. They'll go over the offer details with you.</p>\n<ul>\n<li>Before they make you an offer, they'll check if you are actually seriously considering their company. If you told a startup you are also interviewing with Google, they might suspect that you are not seriously considering them. Unless you dissuade those fears, they might actually not even make you an offer. (Happened to me with Rdio.)</li>\n<li>If you didn't get an offer, try to get as much info as you can. What happened? What can you improve on? Below are the reasons why I didn't get an offer after an on-site interview: \n<ul>\n<li>Not doing well on a technical question. (Happened twice; one time because of a very obnoxious interviewer.)</li>\n<li>Not interviewing for quite the right position (that on-site interview ended early).</li>\n<li>Not having the necessary experience (a lot more important to startups than bigger companies).</li>\n<li>Not being passionate enough about the company.</li>\n</ul>\n</li>\n<li>If this is not a good timing for the offer, e.g. it's one of your first interviews, then tell them so. They will probably wait to give you the offer details until you are ready to consider it.</li>\n<li>The recruiter will likely ask what's important to you in an offer. How are you going to make your decision? What I've said is that compensation will be an important factor in my decision, but that the team/project/etc. are important considerations as well.</li>\n</ul>\n<p>&nbsp;</p>\n<p>6. You have a few days (usually around 5 business days) until the offer expires to decide if you want to accept it.</p>\n<ul>\n<li>Sometimes the offer will expire before you've received offers from other companies. This is why it's important to interview in rough order of ranking, so that you can just let those offers go, knowing you'll have much better ones soon. If you want to hold on to the offer, just ask your recruiter for an extension. It'll be much easier to get an extension at big companies, especially if you are interviewing for a generic position.</li>\n<li>If you decline the offer, let them know.</li>\n</ul>\n<p>&nbsp;</p>\n<p>Always be very nice, friendly, and polite. Walk the fine line between telling the truth and saying the right thing. Ideally, make sure those are the same. Even if you are interviewing with a company you have no intention of working at, make sure to find something you really like about them, something that makes them stand out to you. Always have a good answer to: \"Why do you want to work here?\"</p>\n<p>Before each on-site interview make sure you research the company thoroughly. Use their product. Think of ways to improve it. It's very helpful if you can meet with someone that works there and talk to them. See if they can give you any tips on the interview process. Some companies (e.g. AirBnB) want people that are <em>extremely</em> passionate about their product. Some companies focus more than usual on architectural questions. Many companies expect the engineers to have some familiarity with UI/UX and the ability to think about a feature from all angles.</p>\n<p>&nbsp;</p>\n<h2 id=\"Managing_your_time\"><strong>Managing your time</strong></h2>\n<p>I sent my resume to 78 companies, had at least a phone conversation with a recruiter with 27 of them, had an on-site interview with 16 companies, and received 12 offers. Out of those, I've only seriously considered 3. (Companies with lower ratings had an atrocious response rate.)</p>\n<p>My time-line ended up looking something like this:</p>\n<ul>\n<li>Week 1: Started applying to low-rated companies. About 2 phone interviews.</li>\n<li>Week 2: About 7 phone interviews. One on-site interview. Sending out more resumes.</li>\n<li>Week 3: About 3 phone interviews.</li>\n<li>Week 4: About 15 phone interviews. A few meetings with friends of friends, who ended up referring me. 1 on-site interview. Sent my resume to all the high-rated companies. (During this week interviewing became a full-time job.)</li>\n<li>Week 5: About 10 phone interviews. 4 on-site interviews.</li>\n<li>Week 6: 8 phone interviews. 4 on-site interviews.</li>\n<li>Week 7: 4 phone calls. 5 on-site interviews.</li>\n<li>Week 8: 12 phone calls. 2 on-site interviews.</li>\n<li>Week 9: About 8 calls a day for a few days, while I negotiated with my top companies.</li>\n<li>(These are strictly lower bounds for phone calls. On-site data is pretty accurate.)</li>\n</ul>\n<p>Some companies move fast, some companies move slow. Google took 2 weeks from the on-site interview to the offer call. This is very common for them, but most other companies move faster. With Amazon, I actually interviewed with two different branches. With one branch things were going well, until they dropped the ball and never got back to me, even after I pestered them. This is unusual; although, Twitter did something similar, but then ended up responding with an on-site invitation. With the other Amazon branch, when I got home from the on-site interview, I already had an email saying they were going to make an offer. This is extremely fast. (I had a very good reference for that position.) Most companies take about a week between on-site and offer. The whole process, from first call to offer, takes about three weeks.</p>\n<p>If your recruiter doesn't respond to you during 4 days or longer, shoot them an email. They might have forgotten to respond, or thought they did, or may be things are moving slowly, or may be they decided not to pursue. You want to be clear on where you stand with all the companies you are applying to.</p>\n<p>The timing is pretty important here. You want your top-rated companies to give you an offer within a span of a week. This way you'll be able to leverage all those offers against each other.</p>\n<p>If your current job position is already almost optimal for your goals, then it's possible you can do a few interviews, get a few offers and pick the best one, which will give you some marginal improvement. Or use those offers to leverage a raise at your existing company. But if you are pretty sure your current job has not been optimized for your goal, then I'd say, contrary to popular wisdom, just leave and spend a full month interviewing. (Or, even better, if you can, take a long \"vacation\".) You just can't do this kind of intense interviewing while holding another job. The one exception to this rule I can think of is if one of your highest-rated companies is a competitor with your current employer. Then you can leverage that!</p>\n<p>Value of information is extremely high during this process. Talk to all the companies you can, talk to all the people you can. Once you have the final list of companies you are considering, reduce your uncertainty on everything. Validate all your assumptions. (Example: I was <em>sure</em> Google matched donations up to $12k, but turns out it's only up to $6k.)</p>\n<p>&nbsp;</p>\n<h2 id=\"How_to_evaluate_your_offer\"><strong>How to evaluate your offer</strong></h2>\n<p>There are 4 basic components in an offer: sign-on bonus, base salary, equity, and bonus.</p>\n<p><strong>Sign-on bonus.</strong> Most companies will be okay offering something like $12k sign-on bonus. Some will offer more. Most startups probably won't offer any.</p>\n<p><strong>Base salary.</strong> This is pretty consistent across most companies. Based on your experience, you'll be given a title (e.g. Senior Software Engineer or SE 2), and that title will determine the range of the salary you can expect. If you are good, you can demand a salary at the top of that range, but it's extremely hard to go higher.</p>\n<p><strong>Equity.</strong> This is the most interesting part. A good amount of value will come from this portion. With a startup, it'll be most of it. Here are two things to pay attention to:</p>\n<ul>\n<li>Is the company public or private? If it's public, you are most likely going to be given RSUs (restricted stock units), which will basically convert to normal company shares when they vest. For private companies, see the section below.</li>\n<li>What's the vesting schedule? For almost all companies you'll get 25% of your shares right after your first year. (This is called a 'cliff'.) After that you'll be given the appropriate fraction either monthly (e.g. at Google) or quarterly (e.g. at Facebook). Amazon is an example of a company where the vesting schedule is somewhat different: 5% after year 1, 15% after year 2, and then 20% each semester for the next two years.</li>\n</ul>\n<p><strong>Bonus.</strong> This is the bonus system the company has setup. You can't negotiate it, but it's important to take it into account.</p>\n<ul>\n<li>There will usually be a cash bonus that's based on your salary. It'll have a target percent (e.g. 15%). If you can find out how many people hit their target, that will be very helpful. However, most companies don't share or simply don't have that information.</li>\n<li>Some companies also have equity bonuses. Try to get as much info on those as you can. Don't assume that you'll get the maximum bonus even if you work hard. If you have friends working at that company, ask them what kind of bonuses they've been getting.</li>\n<li>Lots of startups don't have bonus systems in place.</li>\n</ul>\n<p><strong id=\"Other_factors_\">Other factors.</strong></p>\n<ul>\n<li>Donation matching: Google matches up to $6k (you donate $6k to any charity, they'll donate another $6k). Craigslist matches 3:1 up to 10% of your salary. Most companies don't have anything like that, and you can't negotiate it.</li>\n<li>Paid Time Off: Google offers 2 weeks, all other companies I was considering offer 3 weeks, and some even have unlimited PTO. This is not negotiable in most companies.</li>\n<li>Commute: how far will you have to travel to work? Are you okay moving closer to work? (Google and Facebook have shuttles that can pick you up almost anywhere, so you could work while you commute.)</li>\n<li>People/culture/community/team/project are all important factors as well, depending on what you want. If you are going to spend the next several years working on something, you should be building up skills that will still be valuable in the future.</li>\n</ul>\n<p>&nbsp;</p>\n<h2 id=\"Thinking_about_private_companies\"><strong>Thinking about private companies</strong></h2>\n<p>If the company is private, you might be given RSUs or you might be given stock options. With stock options, you'll have to pay the strike price to exercise your options. So the total value your options have is: (price of a share - strike price) * number of shares.</p>\n<p>You can't do anything with your shares until the company gets acquired or goes public. Some companies have liquidation events, but those are pretty rare. Most companies don't have them, and the ones that do only extend the opportunity to people that have been with the company for a while. There are also second-hand markets, but I don't know much about those.</p>\n<p>If you are completely risk-intolerant, then just go with a public company, and don't consider private companies. (This is actually not exactly true. Just because a company is public, doesn't mean its risk-free, and just because a company is private doesn't mean there is a lot of risk. There are other important factors like the size of the company, their market diversity, and how long they've been around.) If you are okay with some risk, then you want a company that's close to an IPO or is likely to get acquired soon. If you want to have a chance to make more than a few million dollars, either start your own company or join a very early stage startup (my top pick would be <a href=\"https://ripple.com/\">Ripple</a>). Before doing so, check out the stats on startups to make sure you understand how likely any given startup is to fail and make sure you understand the concepts of inside/outside view.</p>\n<p>&nbsp;</p>\n<h2 id=\"Taxes\"><strong>Taxes</strong></h2>\n<p>It's crucial to understand all the tax implications of your salary, equity, and donations. I'm not going to go into all the details, there are a lot of resources out there for this, but you should definitely read them until it's crystal clear how you will be taxed. I'll highlight a few points:</p>\n<ul>\n<li>Understand the <a href=\"http://taxes.about.com/od/Federal-Income-Taxes/qt/Tax-Rates-For-The-2013-Tax-Year.htm\">tax rate schedule</a> and notice the new 39.6% tax bracket. If your income is $100k, that doesn't mean you get taxed 28% on all of it. 28% applies only to the income portion above $87,850. Also note that this is only the federal tax. Your state will have additional taxes as well. Aside from those percentages, there are a few other flat taxes, but they are considerably smaller in magnitude.</li>\n<li>The money you donate to a&nbsp;nonprofit&nbsp;(aka.&nbsp;501(c)(3)) organization can be subtracted from your taxable income. This means that you will most likely get a refund when you file your taxes. Why? Because when you fill out your W4 form, you'll basically tell your employer how much money to withhold from your paycheck for tax purposes. If you don't account for your future donations, more money will be withheld than is appropriate and the discrepancy will be paid back to you after you file your taxes. Ideally, you want to take your donations into account and fill out the W4 form such that there are no discrepancies. That means you'll get your money now rather than later. (I haven't gone through this process myself, so there is some uncertainty here.)</li>\n<li>You can claim tax deduction for up to 50% of your wages. That means if you make a lot of money in one year, even if you donate most of it, you'll be able to reduce your taxable income by a maximum of 50%. The rest goes over to the next year.</li>\n<li>When RSUs vest, their value is treated as ordinary income for tax purposes. When you sell them, the difference is taxed as a capital gain (or loss).</li>\n<li>Stock options have a more complicated set of tax rules, and you should understand them if you are considering a company that offers them.</li>\n<li>You can't have your employer donate money or stock for you to bypass the taxes. I've asked.</li>\n</ul>\n<p>&nbsp;</p>\n<h2 id=\"Calculating_donations\"><strong>Calculating donations</strong></h2>\n<p>To calculate exactly how much I could donate if I worked at a given company, I've created <a href=\"https://dl.dropboxusercontent.com/u/30954211/SalariesExample.xls\">this spreadsheet</a>. (This is an example with completely fictitious company offers with very low numbers, but the calculations should be correct.) Let me walk you through the spreadsheet.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Time_discounting__Cell_B1_\">Time discounting (Cell B1)</strong></p>\n<p>Money now is more valuable than money later. By how much? That's a very complicated question. If you invest your money now, you might be able to make something like 10%&nbsp;annually with some risk.<a href=\"/lw/hd1/maximizing_your_donations_via_a_job/#1\">[3]</a> If you are donating to a charity, and they are growing very rapidly, then they can do a lot with your money right now, and you should account for that as well. If you expect the charity to double in size/effectiveness/output in the next year, then you might use a discount rate as high as 50%. I chose to use 20% annual discount rate based on my own estimates. Since I'm doing monthly compounding, the spreadsheet value is slightly higher (~22%). You can look at the column K to see how the future value of a dollar is being discounted. Note, for example, that a dollar in 12 months is worth 80\u00a2&nbsp;to me now. This discounting rate is especially important to keep in mind when examining startups, because almost all their compensation lies in the future. The further away it is, the more heavily you have to discount it.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Cost_of_living__Cell_B2_\">Cost of living (Cell B2)</strong></p>\n<p>This is how much pre-tax money a year I'm not going to donate. See column L for the monthly expenses. We time-discount those dollars as well.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Offers__Cells_A4_I15_\">Offers (Cells A4-I15)</strong></p>\n<p>This is where you plug-in the offers you get. <em>Bonus</em> row is for cash bonus. <em>Equity</em> row is for the total equity the company offers you. I use the dollar amount, but you'll notice that for some of them I'm computing the dollar amount as: RSUs the company is giving me * current share price. For private companies, this is value I expect my equity to have when the company goes public. For Square it looks like: (percent of the company I'll own) * (my guess at valuation of the company at IPO) - (cost to exercise my options). For Twitter it looks like: (growth factor up to IPO) * (current price per share) * (RSUs I am granted). (Again, the numbers are completely made up.) In my calculations I'm not expecting public companies' share price to rise or fall. If you disagree, you should adjust for that as well.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Monthly_projections__Cells_A18_I66_\">Monthly projections (Cells A18-I66)</strong></p>\n<p>We are going to look at how much money we'll be making per month for the next four years. (Four years because our equity should be fully vested by that time.) If you are certain that you will stay at the company for less time than that, then you should consider a shorter timeline. This might affect companies differently. For example, most of the equity you get at Amazon comes during the last two years. If you are not going to be there, you are missing out on a big part of your offer.</p>\n<p>For companies that I was seriously considering, I created two columns: one for cash wages and one for equity wages. This way I can do taxes on them more precisely.</p>\n<p>Let's go through the Google's offer:</p>\n<ul>\n<li>\n<p>For the first year we'll be only making our standard salary.</p>\n</li>\n<li>\n<p>After the first year, we get our cash bonus (green font). Here we are assuming it'll be 15% of our salary. We also get 25% of our RSUs vested (salmon background).</p>\n</li>\n<li>\n<p>For the remainder of the second year, we are making our normal salary. Each month we also get 1/48<sup>th</sup> of our original equity offer.</p>\n</li>\n<li>\n<p>Google also has an equity bonus system, where each year you can get a bonus of up to 50% of your original equity offer. This bonus will be paid in RSUs, and it vests over 4 years, but with no cliff. So we count that as well, but I'm assuming I'm only going to get 15%, not the full 50%.</p>\n</li>\n<li>\n<p>In year 3 everything is basically the same, except now we got our second equity bonus, so we have two of them running simultaneously.</p>\n</li>\n<li>\n<p>In year 4, we have three of them running simultaneously.</p>\n</li>\n</ul>\n<p>For pre-IPO companies, I've estimated when they'll go IPO. Most have clauses in place that don't allow you to sell your shares until after half a year or so after the IPO. I'm assuming I will sell/donate all my shares then, and then continue selling/donating them as they continue vesting.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Sum__Cells_A68_I71_\">Sum (Cells A68-I71)</strong></p>\n<p>In row 68 we have the total sum. This is the amount of pre-tax dollars we expect to earn in the next four years (remember that this amount has been adjusted for time-discounting, so it'll seem much lower than you'd normally expect). L68 is how much money we are spending on ourselves during those four years.</p>\n<p>In row 69 we subtract our living expenses to get the amount of money we'll be able to donate. Note that I'm subtracting it from the cash column, leaving the equity column alone (for the companies where I split the two).</p>\n<p>In row 70 we account for taxes. Note that our living expenses already accounted for the taxes we pay up to $65k, so the rest of it will be taxed at around 28% or higher. You could sell your shares, or you could just donate your shares directly to your charity. (That's what we are doing with our Google offer.)</p>\n<p>In row 71 we simply sum up the donations from cash and equity.</p>\n<p>&nbsp;</p>\n<p>Disclaimer 1: while I tried as hard as I could to double check this spreadsheet, there might still be mistakes there, so use it with caution and triple check everything. The tax calculations as they are right now are wrong, and you'll have to redo them (basically the whole Row 70) based on your own numbers.</p>\n<p>Disclaimer 2: this spreadsheet is not great for evaluating an offer from a startup, since it doesn't capture the associated uncertainty and risk. Furthermore, if you expect the startup to succeed after more than 4 years, to correctly compare it to other companies you'll have to compute more than 48 months and potentially start accounting for things like promotions and raises.</p>\n<p>&nbsp;</p>\n<h2 id=\"Picking_the_one\"><strong>Picking the one</strong></h2>\n<p>All right, so how do you actually pick the best company? It's not as simple as picking the one with the highest EV, since you have to account for risk involved with startups and even pre-IPO companies. In fact, you should be surprised if your offers from public companies have a higher EV than offers from startups. If that's the case, I'd double check your calculations.</p>\n<p>This is where it becomes extremely crucial to narrow down your uncertainty. When is the company going to IPO? What is the likely valuation? Does the company have a lot of competitors? Does the company have the necessary talent to execute on their plan? What's the company's history? What is the employee churn rate (especially for executives)? How well is the company doing financially? Who are the investors? Etc, etc, etc... There is a ton of questions you should be asking, and you should be asking them to everyone whose opinion on this issue you can respect. Honest opinion from an informed and knowledgeable neutral party is worth a LOT here!</p>\n<p>You should also talk to the people at the company. Your recruiter will connect you to the right people if you ask. Keep in mind that nobody there will tell you that the company is going to go bankrupt or fail. But you can still get some valuable estimates, and then potentially discount them down a bit. You can even ask for their opinion on other companies you are interviewing with. Expect them to completely throw the other company under the bus though, but even so, you could get a lot of valuable criticism and bring it up when you talk to that other company. Overall, expect a lot of conflicting messages.</p>\n<p>Keep in mind the charities you'll be donating to. What kind of donors do they have already? Are most people donating a bit from their salary? In that case, a more risky venture might be reasonable. Can they really use some money right now, or would they be a lot more effective later on with a large capital? What's their time discount rate? If you care about your charity, you can help them diversify their donor pool.</p>\n<p>For me, it was a hard choice between big public companies (primary candidate: Google) and close to IPO companies (primary candidates: Twitter and Square).</p>\n<p>&nbsp;</p>\n<h2 id=\"Negotiating\"><strong>Negotiating</strong></h2>\n<p>You have to negotiate your offer. You have to <em>have to</em> <strong>have to</strong> HAVE TO. For any given company, you'll be able to get them to up their offer at least once and potentially thrice. Example: Google upped my offer three times.</p>\n<ul>\n<li>Some companies will tell you their offer is not negotiable. That's not true.</li>\n<li>It's much easier to leverage similar companies against each other. Leverage big public companies against each other; leverage pre-IPO companies against each other; etc... Leveraging between those categories is a bit more difficult, because startups know they can't compete with the raw cash value you are offered at bigger companies. The only thing they can do is up their equity offer and hope that they are a much better personal fit for you than the large companies.</li>\n<li>Recruiters will ask you very directly what the other companies are offering you. You can choose to disclose or not to disclose. If you don't disclose, the company will come back to you with their standard offer. That offer might be higher or lower than you expected. (Example: The first offer I got from Google was significantly worse than initial offers I got from Facebook and Amazon.) If you tell them what offers you have (and you should only disclose details of your very best offers), then they'll very likely match or come in a bit stronger. Usually you don't have much to gain by disclosing your other offers upfront. You can always do so later. However, you should let your recruiters know that other companies <em>did</em> make an offer, or you are expecting them to. That gives you more leveraging power.</li>\n<li>Sign-on bonus is very easy to negotiate. You can easily convince a company to match a sign-on bonus their competitor has offered.</li>\n<li>Negotiating salary is much harder, but, again, usually you can convince a company to match a salary their competitor has offered or at least come closer to it. If you are interviewing with startups, their salary offer will usually be lower than at bigger companies and even harder to negotiate. (\"Cash is king\" is the common phrase used there.)</li>\n</ul>\n<p><strong>First&nbsp;</strong><strong>negotiating&nbsp;phase:</strong> simply email / call back your recruiter (who is now your best friend, right?) and tell them that the offer is somewhat lower than you expected, you have other better offers from other companies, and you are wondering if they can increase their offer. If the company made you a clearly worse offer than another similar company, you should be very open about it.</p>\n<p><strong>Second negotiating phase:</strong> matching other companies. This is when it makes the most sense to disclose your other offers. For example, I used my Amazon and Facebook offers to convince Google to up their offer significantly. For some reason their original offer was very low, but seeing their competitors with much better offers convinced them to update pretty quickly. You can also bring up the perks one company has that the other doesn't (e.g. donation matching or unlimited PTO). The company can make up for that with salary/equity. There is some difficulty in using offers from private companies as leverage, because there is not much information you can disclose about them. You can talk about the number of shares you'll have, but it might not mean anything to the other recruiters if they are not familiar with the startup.</p>\n<p><strong>Third&nbsp;negotiating&nbsp;phase:</strong> once you picked the company you'll work for, go back to them and say something along the lines of \"I really like the offer and the company, but there are a few things that don't make it ideal for me. One of your competitors did this, and another company has that. Right now I'm inclined to go with your competitor, but it's a tough decision, and I would rather go with you. I think if you can make me an offer with the following parameters, it'll make my decision extremely easy, and I'll sign on the spot.\" Include offer letters from other companies, especially the ones that have them beat or beat on some parameters. Notice the key promise at the end: <em>you will sign with them</em>. Your recruiter will have a lot more leverage in fighting for you if you make that promise. You are not legally obligated to follow through with your promise, but I wouldn't advise breaking it or using it just to extract more value to use as leverage against other companies. Use this tactic at the very end to extract that last bit of value from the company that's already the best. This is what I did with Google. I asked for about 3% higher salary and 12% more equity than what they were offering, and they came back with the exact numbers I requested, which means I should have asked for more. My advice would be to ask for about twice or may be even three times as much (6% and 30% respectively). Even if they come back with a compromise, it'll very likely be more than 3% and 12% increase. If not, you can try to barter one more time.</p>\n<p>I'm sure some people will cringe at this kind of haggling, but, in all honesty, this is what recruiters expect, and they are very much used to it. Nobody even blinked an eye when I started negotiating, even on second and third rounds. However, some recruiters might try to make you feel guilty. They'll say that if you really want to work at their startup, then you shouldn't really care about your compensation. Most points they'll make will even be valid, but if you are trying to optimize for donations, then you have to make the compensation the most important factor in your decision. I've actually told most of my recruiters that I plan to donate most of my salary to charities. I don't think that got me higher offers, but it made me come off less like a greedy jerk.</p>\n<p>At the end of the day, the company wants you, but they want to pay you as little as possible. <em>But</em>, given the choice of having you and paying you the most you&nbsp;deserve&nbsp;VS. not having you, all companies will pick the first option. ALL OF THEM. This is one of the best perks of being a talented software engineer in the bay area.</p>\n<p>Once you accept the offer, don't forget to email everyone else and let them know. Thank everyone that helped you. Some recruiters will be surprised by your decision, and some will even fight really hard to get you to reconsider.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<p><a name=\"1\"></a>[1] None of the interviews required a data structure more complicated than a heap. All the answers had a very easy to compute complexity, either polynomial, polynomial * logarithmic, or factorial. The most weird one was probably O(\u221an) for computing prime numbers.</p>\n<p><a name=\"2\"></a>[2] Some problems I did during actual single-round match-up (SRM) competitions, which is good for training yourself how to code and think faster than you are used to. I also did a lot of old SRM problems, which have solutions and explanations posted in case I couldn't get them. I could easily do problem 1 &amp; 2 in the easy division, and could do problem 3 most of the time. I didn't really bother with the hard division, and none of the interview questions were ever as hard as problem 3 in the easy division.</p>\n<p><a name=\"3\"></a>[3] According to the comments, this number is too high. Pick your own best estimate.</p>", "sections": [{"title": "Pre-game", "anchor": "Pre_game", "level": 1}, {"title": "Interviewing with a company", "anchor": "Interviewing_with_a_company", "level": 1}, {"title": "Managing your time", "anchor": "Managing_your_time", "level": 1}, {"title": "How to evaluate your offer", "anchor": "How_to_evaluate_your_offer", "level": 1}, {"title": "Other factors.", "anchor": "Other_factors_", "level": 2}, {"title": "Thinking about private companies", "anchor": "Thinking_about_private_companies", "level": 1}, {"title": "Taxes", "anchor": "Taxes", "level": 1}, {"title": "Calculating donations", "anchor": "Calculating_donations", "level": 1}, {"title": "Time discounting (Cell B1)", "anchor": "Time_discounting__Cell_B1_", "level": 2}, {"title": "Cost of living (Cell B2)", "anchor": "Cost_of_living__Cell_B2_", "level": 2}, {"title": "Offers (Cells A4-I15)", "anchor": "Offers__Cells_A4_I15_", "level": 2}, {"title": "Monthly projections (Cells A18-I66)", "anchor": "Monthly_projections__Cells_A18_I66_", "level": 2}, {"title": "Sum (Cells A68-I71)", "anchor": "Sum__Cells_A68_I71_", "level": 2}, {"title": "Picking the one", "anchor": "Picking_the_one", "level": 1}, {"title": "Negotiating", "anchor": "Negotiating", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "58 comments"}], "headingsCount": 17}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 17, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-05T23:36:13.940Z", "modifiedAt": "2021-04-06T21:28:01.697Z", "url": null, "title": "Pascal's Muggle (short version)", "slug": "pascal-s-muggle-short-version", "viewCount": null, "lastCommentedAt": "2015-01-15T15:40:05.885Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KDzXTWSTg8ArwbhRR/pascal-s-muggle-short-version", "pageUrlRelative": "/posts/KDzXTWSTg8ArwbhRR/pascal-s-muggle-short-version", "linkUrl": "https://www.lesswrong.com/posts/KDzXTWSTg8ArwbhRR/pascal-s-muggle-short-version", "postedAtFormatted": "Sunday, May 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pascal's%20Muggle%20(short%20version)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APascal's%20Muggle%20(short%20version)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDzXTWSTg8ArwbhRR%2Fpascal-s-muggle-short-version%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pascal's%20Muggle%20(short%20version)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDzXTWSTg8ArwbhRR%2Fpascal-s-muggle-short-version", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDzXTWSTg8ArwbhRR%2Fpascal-s-muggle-short-version", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3173, "htmlBody": "<p><strong>Shortened version of</strong>: &nbsp;<a href=\"/lw/h8k/pascals_muggle_infinitesimal_priors_and_strong/\">Pascal's Muggle: &nbsp;Infinitesimal Priors and Strong Evidence</a></p>\n<p>One proposal which has been floated for dealing with Pascal's Mugger is to penalize hypotheses that let you affect a large number of people, in proportion to the number of people affected - what we could call perhaps a \"leverage penalty\" instead of a \"complexity penalty\". &nbsp;This isn't just for Pascal's Mugger in particularly, it seems required to have expected utilities in general converge when the 'size' of scenarios can grow much faster than their algorithmic complexity.</p>\n<p>Unfortunately this potentially leads us into a different problem, that of&nbsp;<em>Pascal's Muggle.</em></p>\n<p>Suppose a poorly-dressed street person asks you for five dollars in exchange for doing a googolplex's worth of good using his Matrix Lord powers - say, saving the lives of a googolplex other people inside computer simulations they're running.</p>\n<p>\"Well,\" you reply, \"I think that it would be very improbable that I would be able to affect so many people through my own, personal actions - who am I to have such a great impact upon events? &nbsp;Indeed, I think the probability is somewhere around one over googolplex, maybe a bit less. &nbsp;So no, I won't pay five dollars - it is unthinkably improbable that I could do so much good!\"</p>\n<p>\"I see,\" says the Mugger.</p>\n<p>A wind begins to blow about the alley, whipping the Mugger's loose clothes about him as they shift from ill-fitting shirt and jeans into robes of infinite blackness, within whose depths tiny galaxies and stranger things seem to twinkle. &nbsp;In the sky above, a gap edged by blue fire opens with a horrendous tearing sound - you can hear people on the nearby street yelling in sudden shock and terror, implying that they can see it too - and displays the image of the Mugger himself, wearing the same robes that now adorn his body, seated before a keyboard and a monitor.</p>\n<p>\"That's not actually me,\" the Mugger says, \"just a conceptual representation, but I don't want to drive you insane. &nbsp;Now give me those five dollars, and I'll save a googolplex lives, just as promised. &nbsp;It's easy enough for me, given the computing power my home universe offers. &nbsp;As for why I'm doing this, there's an ancient debate in philosophy among my people - something about how we ought to sum our expected utilities - and I mean to use the video of this event to make a point at the next decision theory conference I attend. &nbsp; Now will you give me the five dollars, or not?\"</p>\n<p>\"Mm... no,\" you reply.</p>\n<p>\"<em>No?</em>\" says the Mugger. &nbsp;\"I understood earlier when you didn't want to give a random street person five dollars based on a wild story with no evidence behind it whatsoever. &nbsp;But surely I've offered you evidence now.\"</p>\n<p>\"Unfortunately, you haven't offered me&nbsp;<em>enough</em>&nbsp;evidence,\" you explain.</p>\n<p>\"Seriously?\" says the Mugger. &nbsp;\"I've opened up a fiery portal in the sky, and that's not enough to persuade you? &nbsp;What do I have to do, then? &nbsp;Rearrange the planets in your solar system, and wait for the observatories to confirm the fact? &nbsp;I suppose I could also explain the true laws of physics in the higher universe in more detail, and let you play around a bit with the computer program that encodes all the universes containing the googolplex people I would save if you just gave me the damn five dollars -\"</p>\n<p>\"Sorry,\" you say, shaking your head firmly, \"there's just no&nbsp;<em>way</em>&nbsp;you can convince me that I'm in a position to affect a googolplex people, because the prior probability of that is one over googolplex. &nbsp;If you wanted to convince me of some fact of merely 2<sup>-100&nbsp;</sup>prior probability, a mere decillion to one - like that a coin would come up heads and tails in some particular pattern of a hundred coinflips - then you could just show me 100 bits of evidence, which is within easy reach of my brain's sensory bandwidth. &nbsp;I mean, you could just flip the coin a hundred times, and my eyes, which send my brain a hundred megabits a second or so - though that gets processed down to one megabit or so by the time it goes through the lateral geniculate nucleus - would easily give me enough data to conclude that this decillion-to-one possibility was true. &nbsp;But to conclude something whose prior probability is on the order of one over googolplex, I need on the order of a googol bits of evidence, and you can't present me with a sensory experience containing a googol bits. &nbsp;Indeed, you can't&nbsp;<em>ever</em>&nbsp;present a mortal like me with evidence that has a likelihood ratio of a googolplex to one - evidence I'm a googolplex times more likely to encounter if the hypothesis is true, than if it's false - because the chance of all my neurons spontaneously rearranging themselves to fake the same evidence would always be higher than one over googolplex. &nbsp;You know the old saying about how once you assign something probability one, or probability zero, you can't update that probability regardless of what evidence you see? &nbsp;Well, odds of a googolplex to one, or one to a googolplex, work pretty much the same way.\"</p>\n<p>\"So no matter what evidence I show you,\" the Mugger says - as the blue fire goes on crackling in the torn sky above, and screams and desperate prayers continue from the street beyond - \"you can't&nbsp;ever notice that you're in a position to help a googolplex people.\"</p>\n<p>\"Right!\" you say. &nbsp;\"I can believe that you're a Matrix Lord. &nbsp;I mean, I'm not a&nbsp;<em>total</em>&nbsp;Muggle, I'm psychologically capable of responding in&nbsp;<em>some</em>&nbsp;fashion to that giant hole in the sky. &nbsp;But it's just completely forbidden for me to assign any significant probability whatsoever that you will actually save a googolplex people after I give you five dollars. &nbsp;You're lying, and I am absolutely, absolutely, absolutely confident of that.\"</p>\n<p>\"So you weren't&nbsp;<em>just</em>&nbsp;invoking the leverage penalty as a plausible-sounding way of getting out of paying me the five dollars earlier,\" the Mugger says thoughtfully. &nbsp;\"I mean, I'd understand if that was just a rationalization of your discomfort at forking over five dollars for what seemed like a tiny probability, when I hadn't done my duty to present you with a corresponding amount of evidence before demanding payment. &nbsp;But you... you're acting like an AI would if it was actually programmed with a leverage penalty on hypotheses!\"</p>\n<p>\"Exactly,\" you say. &nbsp;\"I'm forbidden&nbsp;<em>a priori</em>&nbsp;to believe I can&nbsp;ever do that much good.\"</p>\n<p>\"Why?\" the Mugger says curiously. &nbsp;\"I mean, all I have to do is press this button here and a googolplex lives will be saved.\" &nbsp;The figure within the blazing portal above points to a green button on the console before it.</p>\n<p>\"Like I said,\" you explain again, \"the prior probability is just too infinitesimal for the massive evidence you're showing me to overcome it -\"</p>\n<p>The Mugger shrugs, and vanishes in a puff of purple mist.</p>\n<p>The portal in the sky above closes, taking with the console and the green button.</p>\n<p>(The screams go on from the street outside.)</p>\n<p>A few days later, you're sitting in your office at the physics institute where you work, when one of your colleagues bursts in through your door, seeming highly excited. &nbsp;\"I've got it!\" she cries. &nbsp;\"I've figured out that whole dark energy thing! &nbsp;Look, these simple equations retrodict it exactly, there's no way that could be a coincidence!\"</p>\n<p>At first you're also excited, but as you pore over the equations, your face configures itself into a frown. &nbsp;\"No...\" you say slowly. &nbsp;\"These equations may look extremely simple so far as computational complexity goes - and they do exactly fit the petabytes of evidence our telescopes have gathered so far - but I'm afraid they're far too improbable to ever believe.\"</p>\n<p>\"What?\" she says. &nbsp;\"Why?\"</p>\n<p>\"Well,\" you say reasonably, \"if these equations are actually true, then our descendants will be able to exploit dark energy to do computations, and according to my back-of-the-envelope calculations here, we'd be able to create around a googolplex people that way. &nbsp;But that would mean that we, here on Earth, are in a position to affect a googolplex people - since, if we blow ourselves up via a nanotechnological war or&nbsp;<em>(cough)&nbsp;</em>make certain&nbsp;other errors, those googolplex people will never come into existence. &nbsp;The prior probability of us being in a position to impact a googolplex people is on the order of one over googolplex, so your equations must be wrong.\"</p>\n<p>\"Hmm...\" she says. &nbsp;\"I hadn't thought of that. &nbsp;But what if these equations are right, and yet somehow, everything I do is exactly balanced, down to the googolth decimal point or so, with respect to how it impacts the chance of modern-day Earth participating in a chain of events that leads to creating an intergalactic civilization?\"</p>\n<p>\"How would&nbsp;<em>that</em>&nbsp;work?\" you say. &nbsp;\"There's only seven billion people on today's Earth - there's probably been only a hundred billion people who ever existed total, or will exist before we go through the intelligence explosion or whatever - so even before analyzing your exact position, it seems like your leverage on future affairs couldn't reasonably be less than one in a ten trillion part of the future or so.\"</p>\n<p>\"But then given this physical theory which seems obviously true, my acts might imply expected utility differentials on the order of 10<sup>10<sup>100</sup></sup><sup>-13</sup>,\" she explains, \"and I'm not allowed to believe that no matter how much evidence you show me.\"</p>\n<hr />\n<p>This problem may not be as bad as it looks; a leverage penalty may lead to more reasonable behavior than depicted above, after taking into account Bayesian updating:</p>\n<hr />\n<p>Mugger: &nbsp;\"Give me five dollars, and I'll save&nbsp;<a href=\"http://en.wikipedia.org/wiki/Knuth's_up-arrow_notation\">3&uarr;&uarr;&uarr;3</a>&nbsp;lives using my Matrix Powers.\"</p>\n<p>You: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"Why not? &nbsp;It's a really large impact.\"</p>\n<p>You: &nbsp;\"Yes, and I assign a probability on the order of 1 in 3&uarr;&uarr;&uarr;3 that I would be in a unique position to affect 3&uarr;&uarr;&uarr;3 people.\"</p>\n<p>Mugger: &nbsp;\"Oh, is that really the probability that you assign? &nbsp;Behold!\"</p>\n<p><em>(A gap opens in the sky, edged with blue fire.)</em></p>\n<p>Mugger: &nbsp;\"Now what do you think, eh?\"</p>\n<p>You: &nbsp;\"Well... I can't actually say this has a likelihood ratio of 3&uarr;&uarr;&uarr;3 to 1. &nbsp;No stream of evidence that can enter a human brain over the course of a century is ever going to have a likelihood ratio larger than, say, 10<sup>10<sup>26</sup></sup>&nbsp;to 1 at the&nbsp;<em>absurdly most,&nbsp;</em>assuming one megabit per second of sensory data, for a century, each bit of which has at least a 1-in-a-trillion error probability. &nbsp;You'd probably start to be dominated by Boltzmann brains or other exotic minds well before then.\"</p>\n<p>Mugger: &nbsp;\"So you're not convinced.\"</p>\n<p>You: &nbsp;\"Indeed not. &nbsp;The probability that you're telling the truth is so tiny that God couldn't find it with an electron microscope. &nbsp;Here's the five dollars.\"</p>\n<p>Mugger: &nbsp;\"Done! &nbsp;You've saved 3&uarr;&uarr;&uarr;3 lives! &nbsp;Congratulations, you're never going to top that, your peak life accomplishment will now always lie in your past. &nbsp;But why'd you give me the five dollars if you think I'm lying?\"</p>\n<p>You: &nbsp;\"Well, because the evidence you&nbsp;<em>did</em>&nbsp;present me with had a likelihood ratio of at least a billion to one - I would've assigned less than 10<sup>-9</sup>&nbsp;prior probability of seeing this when I woke up this morning - so in accordance with Bayes's Theorem I promoted the probability from 1/3&uarr;&uarr;&uarr;3 to at least 10<sup>9</sup>/3&uarr;&uarr;&uarr;3, which when multiplied by an impact of&nbsp;3&uarr;&uarr;&uarr;3, yields an expected value of at least a billion lives saved for giving you five dollars.\"</p>\n<hr />\n<p>I confess that I find this line of reasoning a bit suspicious - it seems overly clever - but at least on the level of intuitive-virtues-of-rationality it doesn't seem completely stupid in the same way as Pascal's Muggle. &nbsp;This muggee is at least <em>behaviorally </em>reacting to the evidence. &nbsp;In fact, they're reacting in a way&nbsp;<em>exactly</em>&nbsp;proportional to the evidence - they would've assigned the same net importance to handing over the five dollars if the Mugger had offered 3&uarr;&uarr;&uarr;4 lives, so long as the strength of the evidence seemed the same.</p>\n<p>But I still feel a bit nervous about the idea that Pascal's Muggee, after the sky splits open, is handing over five dollars while claiming to assign probability on the order of 10<sup>9</sup>/3&uarr;&uarr;&uarr;3 that it's doing any good. &nbsp;My own reaction would probably be more like this:</p>\n<hr />\n<p>Mugger: &nbsp;\"Give me five dollars, and I'll save&nbsp;3&uarr;&uarr;&uarr;3&nbsp;lives using my Matrix Powers.\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"So then, you think the probability I'm telling the truth is on the order of 1/3&uarr;&uarr;&uarr;3?\"</p>\n<p>Me: &nbsp;\"Yeah... that probably has to follow. &nbsp;I don't see any way around that revealed belief, given that I'm not actually giving you the five dollars. &nbsp;I've heard some people try to claim silly things like, the probability that you're telling the truth is counterbalanced by the probability that you'll kill 3&uarr;&uarr;&uarr;3 people instead, or something else with a conveniently exactly equal and opposite utility. &nbsp;But there's no way that things would balance out that neatly in practice, if there was no&nbsp;<em>a priori</em>&nbsp;mathematical requirement that they balance. &nbsp;Even if the prior probability of your saving 3&uarr;&uarr;&uarr;3 people and killing 3&uarr;&uarr;&uarr;3 people, conditional on my giving you five dollars,&nbsp;<em>exactly&nbsp;</em>balanced down to the log(3&uarr;&uarr;&uarr;3) decimal place, the likelihood ratio for your telling me&nbsp;that you would \"save\" 3&uarr;&uarr;&uarr;3 people would not be exactly 1:1 for the two hypotheses down to the log(3&uarr;&uarr;&uarr;3) decimal place. &nbsp;So if I assigned probabilities much greater than 1/3&uarr;&uarr;&uarr;3 to your doing something that affected 3&uarr;&uarr;&uarr;3 people, my actions would be overwhelmingly dominated by even a tiny difference in likelihood ratio elevating the probability that you saved 3&uarr;&uarr;&uarr;3 people over the probability that you did something equally and oppositely bad to them. &nbsp;The only way this hypothesis can't dominate my actions - really, the only way my expected utility sums can converge at all - is if I assign probability on the order of 1/3&uarr;&uarr;&uarr;3 or less. &nbsp;I don't see any way of escaping that part.\"</p>\n<p>Mugger: &nbsp;\"But can you, in your mortal uncertainty, truly assign a probability as low as 1 in 3&uarr;&uarr;&uarr;3 to any proposition whatever? &nbsp;Can you truly believe, with your error-prone neural brain, that you could make 3&uarr;&uarr;&uarr;3 statements&nbsp;<em>of any kind&nbsp;</em>one after another, and be wrong, on average, about once?\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"So give me five dollars!\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"Why not?\"</p>\n<p>Me: &nbsp;\"Because even though I, in my mortal uncertainty, will eventually be wrong about all sorts of things if I make enough statements one after another, this fact can't be used to increase the probability of arbitrary statements beyond what my prior says they should be, because then my prior would sum to more than 1. &nbsp;There must be some kind of required condition for taking a hypothesis seriously enough to worry that I might be overconfident about it -\"</p>\n<p>Mugger: &nbsp;\"Then behold!\"</p>\n<p><em>(A gap opens in the sky, edged with blue fire.)</em></p>\n<p>Mugger: &nbsp;\"Now what do you think, eh?\"</p>\n<p>Me&nbsp;<em>(staring up at the sky):</em>&nbsp; \"...whoa.\" &nbsp;<em>(Pause.)</em>&nbsp; \"You turned into a cat.\"</p>\n<p>Mugger: &nbsp;\"What?\"</p>\n<p>Me: &nbsp;\"Private joke. &nbsp;Okay, I think I'm going to have to rethink a&nbsp;<em>lot&nbsp;</em>of things. &nbsp;But if you want to tell me about how I was wrong to assign a prior probability on the order of 1/3&uarr;&uarr;&uarr;3 to your scenario, I will shut up and listen very carefully to what you have to say about it. &nbsp;Oh, and here's the five dollars, can I pay an extra twenty and make some other requests?\"</p>\n<p><em>(The thought bubble pops, and we return to two people standing in an alley, the sky above perfectly normal.)</em></p>\n<p>Mugger: &nbsp;\"Now, in this scenario we've just imagined, you were taking my case seriously, right? &nbsp;But the evidence there couldn't have had a likelihood ratio of more than 10<sup>10<sup>26</sup></sup>&nbsp;to 1, and probably much less. &nbsp;So by the method of imaginary updates, you must assign probability at least 10<sup>-10<sup>26</sup></sup>&nbsp;to my scenario, which when multiplied by a benefit on the order of 3&uarr;&uarr;&uarr;3, yields an unimaginable bonanza in exchange for just five dollars -\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"How can you possibly say that? &nbsp;You're not being logically coherent!\"</p>\n<p>Me: &nbsp;\"I agree that I'm being incoherent in a sense, but I think that's acceptable in this case, since I don't have infinite computing power. &nbsp;In the scenario you're asking me to imagine, you're presenting me with evidence which I currently think Can't Happen. &nbsp;And if that actually&nbsp;<em>does</em>&nbsp;happen,&nbsp;the sensible way for me to react is by questioning my prior assumptions and reasoning which led me to believe I shouldn't see it happen. &nbsp;One way that I handle my lack of logical omniscience - my finite, error-prone reasoning capabilities - is by being willing to assign infinitesimal probabilities to non-privileged hypotheses so that my prior over all possibilities can sum to 1. &nbsp;But if I actually see strong evidence for something I previously thought was super-improbable, I don't just do a Bayesian update, I should also question whether I was right to assign such a tiny probability in the first place - whether the scenario was really as complex, or unnatural, as I thought. &nbsp;In real life, you are not ever supposed to have a prior improbability of 10<sup>-100</sup>&nbsp;for some fact distinguished enough to be written down, and yet encounter strong evidence, say 10<sup>10</sup>&nbsp;to 1, that the thing has actually happened. &nbsp;If something like that happens, you don't do a Bayesian update to a posterior of 10<sup>-90</sup>. &nbsp;Instead you question both whether the evidence might be weaker than it seems,&nbsp;<em>and</em>&nbsp;whether your estimate of prior improbability might have been poorly calibrated, because rational agents who actually have well-calibrated priors should not encounter situations like that until they are ten billion days old. &nbsp;Now, this may mean that I end up doing some non-Bayesian updates: &nbsp;I say some hypothesis has a prior probability of a quadrillion to one, you show me evidence with a likelihood ratio of a billion to one, and I say 'Guess I was wrong about that quadrillion to one thing' rather than being a Muggle about it. &nbsp;And then I shut up and listen to what&nbsp;<em>you</em>&nbsp;have to say about how to estimate probabilities, because on my worldview, I wasn't&nbsp;<em>expecting</em>&nbsp;to see you turn into a cat.&nbsp; But for me to make a super-update like that - reflecting a posterior belief that I was logically incorrect about the prior probability - you have to really actually show me the evidence, you can't just ask me to imagine it. &nbsp;This is something that only logically incoherent agents ever say, but that's all right because I'm not logically omniscient.\"</p>\n<hr />\n<p>When I add up a complexity penalty, a leverage penalty, and the \"You turned into a cat!\" logical non-omniscience clause, I get the best candidate I have so far for the correct decision-theoretic way to handle these sorts of possibilities while still having expected utilities converge.</p>\n<p>As mentioned in the longer version, this has very little in the way of relevance for optimal philanthropy, because we don't really need to consider these sorts of rules for handling small large numbers on the order of a universe containing 10<sup>80</sup>&nbsp;atoms, and because most of the improbable leverage associated with x-risk charities is associated with discovering yourself to be an Ancient Earthling from before the intelligence explosion, which improbability (for universes the size of 10<sup>80</sup> atoms) is easily overcome by the sensory experiences which tell you you're an Earthling. &nbsp;For more on this see <a href=\"/lw/h8k/pascals_muggle_infinitesimal_priors_and_strong/\">the original long-form post</a>. &nbsp;The main FAI issue at stake is what sort of prior to program into an AI.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HNJiR8Jzafsv8cHrC": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KDzXTWSTg8ArwbhRR", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 45, "extendedScore": null, "score": 0.00011, "legacy": true, "legacyId": "22503", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 45, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Ap4KfkHyxjYPDiqh2"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-05-05T23:36:13.940Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-06T03:49:02.329Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Of Gender and Rationality", "slug": "seq-rerun-of-gender-and-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:32.945Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CLXEPDqguiYEpXgLY/seq-rerun-of-gender-and-rationality", "pageUrlRelative": "/posts/CLXEPDqguiYEpXgLY/seq-rerun-of-gender-and-rationality", "linkUrl": "https://www.lesswrong.com/posts/CLXEPDqguiYEpXgLY/seq-rerun-of-gender-and-rationality", "postedAtFormatted": "Monday, May 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Of%20Gender%20and%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Of%20Gender%20and%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCLXEPDqguiYEpXgLY%2Fseq-rerun-of-gender-and-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Of%20Gender%20and%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCLXEPDqguiYEpXgLY%2Fseq-rerun-of-gender-and-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCLXEPDqguiYEpXgLY%2Fseq-rerun-of-gender-and-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 164, "htmlBody": "<p>Today's post, <a href=\"/lw/ap/of_gender_and_rationality/\">Of Gender and Rationality</a> was originally published on 16 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Analysis of the gender imbalance that appears in \"rationalist\" communities, suggesting nine possible causes of the effect, and possible corresponding solutions.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/hci/seq_rerun_bayesians_vs_barbarians/\">Bayesians vs. Barbarians</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CLXEPDqguiYEpXgLY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 1.1903567261507786e-06, "legacy": true, "legacyId": "22508", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xsyG7PkMekHud2DMK", "5ccPkxjhNwfCS4BGM", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-06T05:34:57.443Z", "modifiedAt": null, "url": null, "title": "Using Evolution for Marriage or Sex ", "slug": "using-evolution-for-marriage-or-sex", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:07.417Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oFMywHmJffsCSDNB7/using-evolution-for-marriage-or-sex", "pageUrlRelative": "/posts/oFMywHmJffsCSDNB7/using-evolution-for-marriage-or-sex", "linkUrl": "https://www.lesswrong.com/posts/oFMywHmJffsCSDNB7/using-evolution-for-marriage-or-sex", "postedAtFormatted": "Monday, May 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Using%20Evolution%20for%20Marriage%20or%20Sex%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUsing%20Evolution%20for%20Marriage%20or%20Sex%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFMywHmJffsCSDNB7%2Fusing-evolution-for-marriage-or-sex%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Using%20Evolution%20for%20Marriage%20or%20Sex%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFMywHmJffsCSDNB7%2Fusing-evolution-for-marriage-or-sex", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFMywHmJffsCSDNB7%2Fusing-evolution-for-marriage-or-sex", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3852, "htmlBody": "<p>Returned to original title, for the good reasons <a href=\"/lw/con/the_rational_rationalists_guide_to_rationally/\">given here</a></p>\n<p>There was a <a href=\"/lw/fmw/lw_women_entries_creepiness/\">recent post</a> in Discussion which at time of this writing held staggering 454 commentaries, which inclined me to write an evolutionary psychology and social endocrinology derived post on courtship, and Mating Intelligence, to share some readings on recent discussions and evidence coming from those areas. I've been meaning to do this for a while, and a much longer version could have been written, with more specific case studies and citations and an academic outlook, yet I find this abridged personal version more adequate for Lesswrong. In no area more disclaimers are desirable than when speaking about evolutionary drives for mating. It touches emotions, gender issues, morality, societal standards, and it speaks of topics that make people shy, embarrassed, angry and happy on a weekly basis, so I'll begin with a few paragraphs of disclaimers.</p>\n<p>I'll try to avoid saying anything that I can remember having read in a Pick Up Artist book, and focus on using less known mating biases to help straight women and men find what they look for in different contexts. This post won't work well for same-gender seduction. If you object irrevocably to evolutionary psychology, just so stories, etc... I suggest you refrain from commenting, and also reading, why bother?</p>\n<p>Words of caution on reading people (me included) talking about evolutionary psychology, specially when applied to current people: Suspicious about whether there is <a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">good </a><a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">evidence</a> for it? <a href=\"/lw/fry/how_to_avoid_the_conflict_between_feminism_and/8131\">Read this first</a>, then if you want <a href=\"/lw/yi/the_evolutionarycognitive_boundary/\">Eliezer</a> on the evolutionary-cognitive difference, and <a href=\"/lw/fry/how_to_avoid_the_conflict_between_feminism_and/\">this </a>if your feminist taste buds activate negatively. If you never heard of Evolutionary Psychology (which includes <a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">8 different bodies of data to draw from</a>), check <a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">a</a><a href=\"http://www.youtube.com/watch?v=QZw3lxyuhEU\">lso an Introduction with Dawkins and Buss</a>.</p>\n<p>When I say \"A guy does D when G happens\" <strong>please read: </strong>\"There are statistically significant, or theoretically significant reasons from social endocrinology, or social and evolutionary psychology to believe that under circumstances broadly similar to G, human males, on average, will be inclined towards behaving in manners broadly similar to the D way. Also, most tests are made with western human males, tests are less than 40 years old,&nbsp; subject to publication bias, and sometimes done by people who don't understand math well enough to do their statistics homework, they have not been replicated several times, and they are less homogenous than physics, because psychology is more complex than physics.\"</p>\n<p>If you couldn't care less for theory, and just want the advice, go to the Advice Session.</p>\n<h1><strong>Misconceptions</strong><br /></h1>\n<p>Thusfar in Evolutionary Psychology it seems that our genes come equipped with two designs that become activated through environmental cues to think about mating.</p>\n<p>Short-term mating</p>\n<p>Long-term mating</p>\n<p>Knowing this is becoming mainstream. The <a href=\"http://libgen.info/view.php?id=877190\">state of the art</a> term is <a href=\"http://libgen.info/view.php?id=343870\">Mating Intelligence</a>, and it has these two canonical modes that can be activated, depending on factors as diverse as being informed that X is leaving town in two days, and detecting X's level of testosterone, accounting for his height and status, and calculating whether his genes are worth more or less than his future company. If you choose to read the linked books, then you'll delve in this much deeper than I have, so stop reading this, and write a post of your own afterwards.</p>\n<p>I'll list some main misconceptions, then suggest how to use either the misconceptions, or the theory mentioned while explaining them to optimize for whatever you want from the opposite gender individuals at a particular moment.</p>\n<p><strong> </strong></p>\n<p><strong><em>Misconception 1:</em> Guys do Short-term, Girls do Long-term, unless they don't have this option.</strong></p>\n<p>This is false. Guys are very frequently pair bonded, most times even before women are, both have oxytocin levels going up after sex, and both have high levels of oxytocin during relationships. Girls only have less frequent causal intercourse <em>because</em> it is hard to find males worthy of the 2 year raising a baby period, or in the case in which they are pair-bonded already, <em>because </em>of the risk of the cuckolded \"father\" leaving, fighting her, or recognizing the baby ain't his. Obviously, no one's brain has managed to completely catch up with condoms and open relationships yet.</p>\n<p><strong><em>Misconception 2:</em> Women go for the bad guys (if I remember my American Pie's correctly, also called jocks in US) and good guys, nerds, and conventionals are left last.&nbsp;</strong></p>\n<p>'Bad guys' is a popular name for high testosterone, risk taking, little routine individuals. And indeed when a woman's short-term mating intelligence program is activated, which happens particularly when she is ovulating and young (even when she's close married/relationshiped) she does exhibit a preference for such types. When optimizing for long-term partners, the reverse is true.</p>\n<p><strong><em>Misconception 3: </em>Guys just go for looks, Girls just go for status.&nbsp;</strong></p>\n<p>Toned down reality: Guys in short-term mating mode go for looks, Girls in long-term mating mode care substantially for the difference between lower than average status and average status, then marginal utility decreases and more status is defeated by other desirable traits.</p>\n<p>Women in short-term mode <em>do not</em> optimize for status, they'll take a bus-boy who shows through size, melanin, symmetry and chin that he survived local pathogens despite his high testoterone, she's after resistant genes, not resources. Men in long term mode still optimize for looks, but not that much, kindness and emotional stability take over when marginal returns for more beauty start subsiziding.</p>\n<p><strong><em>Misconception 4:</em> When genders optimize for Status, Status=Money.</strong></p>\n<p>Unlike all known primate and cetacean species, Humans daily deal with being high, low, and medium status in different hierarchical situations. This should be as obvious as not to be worth mentioning, but sadly there are strong media incentives, and for some reason I don't understand well strong reasons within English and American culture to <em>pretend</em> that women go for status, status=money, therefore women go for money, and men should make more money. It may be a selection effect, the societies that financially took over the world believed that being financially powerful was the best way to get laid, or marry. It may just be that marketing these things together (using sexy women to sell cars) created a long-term pavlovian association. Fact is that it unfortunately happened, and people <em>believe it</em>, despite it being false. Women who begin believing it sometimes force themselves into doing it even more.&nbsp;</p>\n<p>Status has no universal measure. If you met someone in Basketball team, status will be how good that person is plus their game attitude. If in a class at university, maybe it will be how well spoken the person is in the relevant topic. Status can be how much food the person usually shares with groups, or how much they can ask for others without being very apologetic. It can be how many women sleep with a man, or how many he can afford to reject. It can be how many purses a woman has, or how she can show thrift and a sense of belonging to a community that identifies as anti-consumerist. Some minds assign status based on location of birth, race, hair color etc...&nbsp;&nbsp; (In my city, Japanese women, all the 400.000, are commonly assumed to be high status). Finally, men do optimize for the trait people think as status, explained below, in long-term mates.&nbsp;</p>\n<p>Even in the case where status plays the largest role, women when activating long-term reasoning, status is only one factor out of four multiplicants that are important for the same reason, and detected, in a prospective male mate:&nbsp;&nbsp;</p>\n<p>Kindness*Dependability*(Ambition-Age)*Status = How many resources a man is expected to share with you and your hypothetical kids.</p>\n<p>And this does not even begin to account for any physical trait, nor intelligence, humour, energy levels etc... If you take one thing out of this text, take this: <em>Make your beliefs about what status is pay rent</em>. Test if status is what people think it is, or something that only roughly correlates with that. Sophisticate your status modules, they may have been corrupted.</p>\n<p><em><strong>Misconception 5:</strong></em> <strong>Once you learn what your mind is doing when it selects mates, you should make it get better at that.</strong></p>\n<p>Let's begin by reaffirming the obvious: We live in a world that has nothing to do with savannahs where our minds spent a long time. We can access thousands, if not millions of people, during a lifetime.<strong> We have condoms and contraceptives</strong>. We live in an era of abundance compared to any other time in history, and in societies so large, that the moral norms constraining what \"everyone will know\" do not apply anymore.</p>\n<p>So the last thing you want to do is to make your mind really sharp and accurate when judging a potential mate through its natural algorithms. What you want to do, to the extent that it is possible, is to override your algorithms with something that is better, and better is one of these two things:</p>\n<p>1) Increasing your likelihood of mating with the individual (or class of individuals) you want to mate with <em>in a matched time-horizon (long if you want long, for instance).</em></p>\n<p>2) Enlarging the scope of individuals you want to mate with to include more people you actually do, will or can get to know.&nbsp;</p>\n<p>&nbsp;</p>\n<h1>Advice<br /></h1>\n<p>To give better advice, I'll first mention general advice anyone can use, and then specific advice for the four quadrants. For those who will say this is the Dark Arts, I say it would be if we lived in a Savannah without condoms, heating, medicine, houses or internets. Now it looks to me more like causing one-self, and one's beloved, to be more epistemically rational.</p>\n<p>&nbsp;</p>\n<p><strong>General Advice</strong></p>\n<p><strong>Women, be confident</strong>: If you are a woman, be more confident, way more confident, when approaching a guy, don't be aggressive, just safe, you mind is tuned with who knows how many trigger devices that may make you afraid of a no, of being thought of as slutty, of losing face, and of the guy not raising your kids. Discount for all that, twice. Don't do it if everyone <em>really will</em> know, or if you actually want kids from that guy.</p>\n<p><strong>Use your best horizon features:</strong> If you have a trait that the other gender optimizes for more in short-term, lure them by acting short-term, even if later you'll attempt to raise their oxytocin to the long-term point. If you have goods and ills on both time horizons, switch back and forth until you grasp what they want.&nbsp;</p>\n<p><strong>Discount for population size: </strong>There are two ways of doing that, one is to reason to yourself \"I may not be as attractive as Natalie Portman or Brad Pitt, but our minds are tuned to trying to get the best few achievable mates out of a group of 100-1000, not of hundreds of millions, so I do stand a very good chance\" The other is nearly opposite: \"I may think that I should only marry a prince, or sleep with Iron Man, but in fact my world is much smaller than this, and my mind will be totally okay to mate with Adam, that cool guy.\"</p>\n<p><strong>Be hedonistic: </strong>For men and women alike, the main way evolution got us into intercourse was by making it <em>fun</em>. The reasons it got us out are related to <em>unlikelihood of leaving great-grandchildren, energy waste, disease, and lowered status</em>. Of those, only a subset of lowered status is still significant in a world full of condoms. Other than women when aiming at long-term only, everyone is completely under-calibrated for sex, since we substantially reduced the risks without reducing the hedonic benefits nearly as much.</p>\n<p><strong>Use fetishes and peculiarities</strong>: There are things each particular person is attracted to more than everyone else (for me that's freckles, red/orange/blue/purple hair, upper back, and short women). Use that in your favour, <em>less competition</em>, as simple as that.</p>\n<p><strong>Go places</strong>: There are better and worse places to find mates. Short-terming males (a temporary condition in which any male may find himself, <em>not</em> a kind of male) abound in dancing clubs, military facilities and sports areas, not to mention OkCupid. Long-terming females (same) abound on courses and classes of yoga, dancing, cooking, languages, etc...&nbsp; Long-terming males usually have more of a routine, so are more frequent on saturdays and fridays than on a tuesday late evening, they'll be more frequent wherever no one naturally would go to find a one night stand, or in groups that are preselected for strong emotions (low thresholds for falling in love) Short-terming females may exist in dancing clubs, bars and other related areas, but are very high value due to comparative scarcity when in these areas, someone looking for them is better off in groups with a small majority of women, where social tension and hierarchies don't scale up in either gender.</p>\n<p>&nbsp;</p>\n<p><strong>Specific Advice</strong></p>\n<p>Note: The advice is about things you should do <em>in addition</em> to what you naturally tend to do in those situations, you already have the algorithms, and should just improve calibration, unless when explicited, the suggestion is not to substitute what you naturally tend to do, or this would be a book all by itself explaining 4 kinds of human courtship.</p>\n<p><strong>For Long-terming Men: </strong>Stop freaking out about financial status. Find a place where you are among the great ones in something, specially kindness, dependability, physical constitution, and symmetry which guys think of less frequently than Successful startups or Tennis worldchampions. If you are hot, use short-term, women are particularly more prone to switching from short to long-term. Get a dog, show you are able and willing to take care of something unspeakably cute and adorable. Be ambitious in your projects, show passion. While ambitious and passionate, also make sure she realizes (truly) that you notice things about her no one else does, find out her values, talk about shared ones, and be non aggressively curious about all of them.&nbsp; Show her kindness in small gestures that need not cost a lot, such as time consuming hand-made presents. Test OkCupid and see if it works for you. Memorize details about her personality, assure her you can be loving specifically to her. Postpone sex <em>a little bit</em>. May sound hard, but is a reliable indicator that you won't change her for the next that quickly. Rationally override any emotion you may have regarding her sexual behavior, show you are not agressive and jealous, thus making her \"(be) (a)lieve unconsciously\" that you will not kill her in an assault of hatred when she sleeps with hypothetical another man whose child will never exist and get some years of schooling from you. If you think you can tell the wheat from the chaff, separate the PUA stuff that works for long-term, if not, read softer confidence/influence/seduction material. Use oxytocin inducing media (TV series and romantic movies). Rest assured, there are more women looking for long-term men than the opposite, aid the odds by going places. Show sympathy, kindness (to others as well) and dependability whenever you can.</p>\n<p><strong>For Long-terming Women:<em> </em></strong>If you've been convinced by financial status gospel, stop freaking out about it. If you just account for the 4 factors in the equation above, you'll be way ahead of everyone within the gospel trance, then there are still all the other things you look for in a guy, which by themselves are very important. Sure, a classic indicator is how much other women in your social group like him, and, good as it is, it is defined in terms of competition, try to discount this one, after all, it is partially just made of a conformity bias, a bad bias to have when looking for a long-term mate. Be very nice and kind, and almost silly near the guy. The kinds of guys who are Long-terming most of the time are those who won't approach you that frequently. Also, older guys obviously have less chaos on in their minds and lives, so are more likely to want to settle down for a few years. <em>Postpone sex</em> in proportion to how much you suspect the guy is Short-terming. The importance of this cannot be overstated. By postponing sex (and sex alone) you make sure Short-termers still have a good reason to be around you until suddenly there is a hormonal overload and they fall in love with you (not that romantic, but mildly accurate), love's trigger is activated by many factors, when they sum above a threshold. The most malleable of these factors is time investment, give a guy mixed short long signals, and you'll increase likelihood of surpassing the threshold. Also, give known guys a second chance, many times your algorithms friendzoned (sorry for the term) them for reasons as silly as \"he didn't touch me the first time we met, and I didn't feel his smell, because the table was wide\" or \"That day I was in Short-term mode and this other guy had more easily detectable attractive features, leaving John on the omega mental slot\". Forget romantic comedies and princess tales where your role is passive. A man's love is actively conquered by a woman, you are the one who will fight dragons - frequently RPG dragons - for the guy in the beggining, not the opposite, the opposite comes later as a prize.&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>For Short-terming Guys: </strong>Read Pick Up Artist books, actually do the exercises, as in don't find excuses for why you can't, do them. Don't do anything that disgusts you morally, which may be nearly all of it, but do all the rest. Other than that?... Some few things, very few indeed, were left out of those books. Optimize more than anything for your fetishes and specific desires to avoid competition. Use mildly tense situations which can be confounded with arousal (narrow bridges get you more dates than wide bridges). Woman's attractiveness peaks at approximately 1,73cm 5 feet 8 inches, shorter women are more likely to have had less home stability and developmental stability when young, which triggers more frequent short-terming, looking for testosterone indicators (square chin, prominent forehead, and specially having a ring-finger longer than index-finger) also helps, and it is fun because you can claim to read hands and actually make good predictions out of it.</p>\n<p><strong>For Short-terming Girls: </strong>I'll start with easy stuff, and escalate quickly to extremely high probability even in tough cases, such as he's not on the mood, tired, really shy, or (you think) not excited. Quite likely the main obstacle is inside your mind, not your clothes, either fear of rejection, or fear of reputational cost or something else. Be confident. Few guys will reject a subtle, feminine, <em>discrete</em> and firm sex \"offer\" (notice how language itself puts it). Look at him, smile, touch him while you speak, look intensely at his mouth while slowly approaching, <em>make sure</em> to try do this where he is unlikely to be paying some reputational cost (not on his aunt's marriage). If feeling clumsy, mention you do. When short-terming, men really do optimize for looks, so decrease light levels, and avoid available-female company, like asking him out to check a bookstore, or to see a movie. Sit near him while touching him, cut the conversation at some point, kiss him (remember to do that where neither of you may get embarrassed with anyone else). Before, talk about sexuality naturally and <em>imagetically</em>, say how it is important to you to be embraced, desired, enticed, penetrated, transformed inside, and arise re-energized the next day to go back to your life. If you are sure he is short-terming, make yourself scarce by mentioning time constraints. Carry condoms and pick them up while making up if he is still hesitant whether you want sex or not. But be cozy and reassure him \"It's okay\" if it feels like he nervous. If you are confortable with that, use the web, there are tons of Short-terming guys, and if you feel embarassed to meet a man who would reject you, you are safeguarded by being filtered beforehand through your pictures and description or by the<em> bang with friends</em> app. On the web, be upfront about your intentions, and assure them you are not a scam/bot/adv. When almost there, if he is not excited, <em>it is not because you are not attractive to him</em>, don't be passive, slowly touch and rub his genital, quite likely he's just nervous and you are disputing against his sympathetic system, when you and the parasympathetic win, he'll be excited and relaxed, and the party is on. If you live in a large urban area, go to swing places alone or with acquaintances, not friends - nowhere else there will be that many guys willing to have sex right there, right now, and the necessary infrastructure for it, <em>in a safe environment</em> with security guards, other high-class women etc... to make sure you are not getting into trouble - In short, guarantee situations in which neither him nor you pay reputational costs, be active yet reassuring, lower light levels, avoid competition and make sure there is infrastructure for the act.</p>\n<p>&nbsp;</p>\n<p>The saying goes that you can't achieve happiness by trying to be happy (thought you can if you <em>optimize</em> for happiness, i.e. by reading positive psychology and acting on it). To some extent, it is also true that a lot of what goes on during courtship does not take place while actively and consciously focusing on courtship. It is one thing to keep those misconceptions and advices in mind, and a whole different thing to be obsessed about them and use them as cognitive canonical maxims for behaving, the point of writing this is to help, if it stops being helpful, stop using it.</p>\n<p>&nbsp;</p>\n<p>Edit: Scrambled sources:</p>\n<div id=\"body_t1_8x55\" class=\"comment-content \">\n<div class=\"md\">\n<p>Buss Handbook of Evolutionary Psychology 2004</p>\n<p>Pinker - Family Values and Love chapters on How The Mind Works</p>\n<p>Mating Intelligence, the one from 2007 and the 2011 ones, many authors (including Helen Fisher) both linked above.</p>\n<p>Robert Trivers theory of parental investment, conflict etc... - 197x</p>\n<p>Lots of conversations with dozens to a hundred friends about their current sex lives.</p>\n<p>PUA - Mistery Method - Rules of The Game - The Layguide (assumption: the older ones had less economic incentive to create vocabulary and new complexity out of the blue, therefore are more accurate and less Bullshitty)</p>\n<p>Helen Fisher (presentations, vidoes, some articles)</p>\n<p>Lots of conversations with a friend who read lots of evopsych and would spend the pomodoro intervals explaining the article he just read to me.</p>\n<p>Personal experience.</p>\n<p>The Eternal Child, Clive Broomhall</p>\n<p>The Mind in the Cave - forgot author</p>\n<p>MIT The Cognitive Neurosciences III (2004)</p>\n<p>Primate sexuality (1999)</p>\n<p>This video is also great, Why do Women Have Sex? <a rel=\"nofollow\" href=\"http://www.youtube.com/watch?v=KA0sqg3EHm8\">http://www.youtube.com/watch?v=KA0sqg3EHm8</a></p>\n<h6>Edit: This was originally posted to main and downgraded to Discussion by Eliezer claiming that it didn't have many upvotes. It did have lots of downvotes (37%), as I'd expect from any controversial topic, but also had more than 50 upvotes at the time. I submit a proposal that controversial topics should not be downgraded, and that total number of votes be a relevant factor, not only difference between ups and downs, to avoid death spirals, and conformity bias. If policy changes, notice this DOES NOT benefit me in any way, since I don't plan on writing for about a semester, and this text will be long gone. <br /></h6>\n<p>It is hard to unscramble it all to give specific citations, but that is a list of stuff I've read that deals with related issues that come to mind.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oFMywHmJffsCSDNB7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 73, "baseScore": 17, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "22453", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Returned to original title, for the good reasons <a href=\"/lw/con/the_rational_rationalists_guide_to_rationally/\">given here</a></p>\n<p>There was a <a href=\"/lw/fmw/lw_women_entries_creepiness/\">recent post</a> in Discussion which at time of this writing held staggering 454 commentaries, which inclined me to write an evolutionary psychology and social endocrinology derived post on courtship, and Mating Intelligence, to share some readings on recent discussions and evidence coming from those areas. I've been meaning to do this for a while, and a much longer version could have been written, with more specific case studies and citations and an academic outlook, yet I find this abridged personal version more adequate for Lesswrong. In no area more disclaimers are desirable than when speaking about evolutionary drives for mating. It touches emotions, gender issues, morality, societal standards, and it speaks of topics that make people shy, embarrassed, angry and happy on a weekly basis, so I'll begin with a few paragraphs of disclaimers.</p>\n<p>I'll try to avoid saying anything that I can remember having read in a Pick Up Artist book, and focus on using less known mating biases to help straight women and men find what they look for in different contexts. This post won't work well for same-gender seduction. If you object irrevocably to evolutionary psychology, just so stories, etc... I suggest you refrain from commenting, and also reading, why bother?</p>\n<p>Words of caution on reading people (me included) talking about evolutionary psychology, specially when applied to current people: Suspicious about whether there is <a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">good </a><a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">evidence</a> for it? <a href=\"/lw/fry/how_to_avoid_the_conflict_between_feminism_and/8131\">Read this first</a>, then if you want <a href=\"/lw/yi/the_evolutionarycognitive_boundary/\">Eliezer</a> on the evolutionary-cognitive difference, and <a href=\"/lw/fry/how_to_avoid_the_conflict_between_feminism_and/\">this </a>if your feminist taste buds activate negatively. If you never heard of Evolutionary Psychology (which includes <a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">8 different bodies of data to draw from</a>), check <a href=\"http://www.bradley.edu/dotAsset/165869.pdf\">a</a><a href=\"http://www.youtube.com/watch?v=QZw3lxyuhEU\">lso an Introduction with Dawkins and Buss</a>.</p>\n<p>When I say \"A guy does D when G happens\" <strong>please read: </strong>\"There are statistically significant, or theoretically significant reasons from social endocrinology, or social and evolutionary psychology to believe that under circumstances broadly similar to G, human males, on average, will be inclined towards behaving in manners broadly similar to the D way. Also, most tests are made with western human males, tests are less than 40 years old,&nbsp; subject to publication bias, and sometimes done by people who don't understand math well enough to do their statistics homework, they have not been replicated several times, and they are less homogenous than physics, because psychology is more complex than physics.\"</p>\n<p>If you couldn't care less for theory, and just want the advice, go to the Advice Session.</p>\n<h1 id=\"Misconceptions\"><strong>Misconceptions</strong><br></h1>\n<p>Thusfar in Evolutionary Psychology it seems that our genes come equipped with two designs that become activated through environmental cues to think about mating.</p>\n<p>Short-term mating</p>\n<p>Long-term mating</p>\n<p>Knowing this is becoming mainstream. The <a href=\"http://libgen.info/view.php?id=877190\">state of the art</a> term is <a href=\"http://libgen.info/view.php?id=343870\">Mating Intelligence</a>, and it has these two canonical modes that can be activated, depending on factors as diverse as being informed that X is leaving town in two days, and detecting X's level of testosterone, accounting for his height and status, and calculating whether his genes are worth more or less than his future company. If you choose to read the linked books, then you'll delve in this much deeper than I have, so stop reading this, and write a post of your own afterwards.</p>\n<p>I'll list some main misconceptions, then suggest how to use either the misconceptions, or the theory mentioned while explaining them to optimize for whatever you want from the opposite gender individuals at a particular moment.</p>\n<p><strong> </strong></p>\n<p><strong id=\"Misconception_1__Guys_do_Short_term__Girls_do_Long_term__unless_they_don_t_have_this_option_\"><em>Misconception 1:</em> Guys do Short-term, Girls do Long-term, unless they don't have this option.</strong></p>\n<p>This is false. Guys are very frequently pair bonded, most times even before women are, both have oxytocin levels going up after sex, and both have high levels of oxytocin during relationships. Girls only have less frequent causal intercourse <em>because</em> it is hard to find males worthy of the 2 year raising a baby period, or in the case in which they are pair-bonded already, <em>because </em>of the risk of the cuckolded \"father\" leaving, fighting her, or recognizing the baby ain't his. Obviously, no one's brain has managed to completely catch up with condoms and open relationships yet.</p>\n<p><strong id=\"Misconception_2__Women_go_for_the_bad_guys__if_I_remember_my_American_Pie_s_correctly__also_called_jocks_in_US__and_good_guys__nerds__and_conventionals_are_left_last__\"><em>Misconception 2:</em> Women go for the bad guys (if I remember my American Pie's correctly, also called jocks in US) and good guys, nerds, and conventionals are left last.&nbsp;</strong></p>\n<p>'Bad guys' is a popular name for high testosterone, risk taking, little routine individuals. And indeed when a woman's short-term mating intelligence program is activated, which happens particularly when she is ovulating and young (even when she's close married/relationshiped) she does exhibit a preference for such types. When optimizing for long-term partners, the reverse is true.</p>\n<p><strong id=\"Misconception_3__Guys_just_go_for_looks__Girls_just_go_for_status__\"><em>Misconception 3: </em>Guys just go for looks, Girls just go for status.&nbsp;</strong></p>\n<p>Toned down reality: Guys in short-term mating mode go for looks, Girls in long-term mating mode care substantially for the difference between lower than average status and average status, then marginal utility decreases and more status is defeated by other desirable traits.</p>\n<p>Women in short-term mode <em>do not</em> optimize for status, they'll take a bus-boy who shows through size, melanin, symmetry and chin that he survived local pathogens despite his high testoterone, she's after resistant genes, not resources. Men in long term mode still optimize for looks, but not that much, kindness and emotional stability take over when marginal returns for more beauty start subsiziding.</p>\n<p><strong id=\"Misconception_4__When_genders_optimize_for_Status__Status_Money_\"><em>Misconception 4:</em> When genders optimize for Status, Status=Money.</strong></p>\n<p>Unlike all known primate and cetacean species, Humans daily deal with being high, low, and medium status in different hierarchical situations. This should be as obvious as not to be worth mentioning, but sadly there are strong media incentives, and for some reason I don't understand well strong reasons within English and American culture to <em>pretend</em> that women go for status, status=money, therefore women go for money, and men should make more money. It may be a selection effect, the societies that financially took over the world believed that being financially powerful was the best way to get laid, or marry. It may just be that marketing these things together (using sexy women to sell cars) created a long-term pavlovian association. Fact is that it unfortunately happened, and people <em>believe it</em>, despite it being false. Women who begin believing it sometimes force themselves into doing it even more.&nbsp;</p>\n<p>Status has no universal measure. If you met someone in Basketball team, status will be how good that person is plus their game attitude. If in a class at university, maybe it will be how well spoken the person is in the relevant topic. Status can be how much food the person usually shares with groups, or how much they can ask for others without being very apologetic. It can be how many women sleep with a man, or how many he can afford to reject. It can be how many purses a woman has, or how she can show thrift and a sense of belonging to a community that identifies as anti-consumerist. Some minds assign status based on location of birth, race, hair color etc...&nbsp;&nbsp; (In my city, Japanese women, all the 400.000, are commonly assumed to be high status). Finally, men do optimize for the trait people think as status, explained below, in long-term mates.&nbsp;</p>\n<p>Even in the case where status plays the largest role, women when activating long-term reasoning, status is only one factor out of four multiplicants that are important for the same reason, and detected, in a prospective male mate:&nbsp;&nbsp;</p>\n<p>Kindness*Dependability*(Ambition-Age)*Status = How many resources a man is expected to share with you and your hypothetical kids.</p>\n<p>And this does not even begin to account for any physical trait, nor intelligence, humour, energy levels etc... If you take one thing out of this text, take this: <em>Make your beliefs about what status is pay rent</em>. Test if status is what people think it is, or something that only roughly correlates with that. Sophisticate your status modules, they may have been corrupted.</p>\n<p><em><strong>Misconception 5:</strong></em> <strong>Once you learn what your mind is doing when it selects mates, you should make it get better at that.</strong></p>\n<p>Let's begin by reaffirming the obvious: We live in a world that has nothing to do with savannahs where our minds spent a long time. We can access thousands, if not millions of people, during a lifetime.<strong> We have condoms and contraceptives</strong>. We live in an era of abundance compared to any other time in history, and in societies so large, that the moral norms constraining what \"everyone will know\" do not apply anymore.</p>\n<p>So the last thing you want to do is to make your mind really sharp and accurate when judging a potential mate through its natural algorithms. What you want to do, to the extent that it is possible, is to override your algorithms with something that is better, and better is one of these two things:</p>\n<p>1) Increasing your likelihood of mating with the individual (or class of individuals) you want to mate with <em>in a matched time-horizon (long if you want long, for instance).</em></p>\n<p>2) Enlarging the scope of individuals you want to mate with to include more people you actually do, will or can get to know.&nbsp;</p>\n<p>&nbsp;</p>\n<h1 id=\"Advice\">Advice<br></h1>\n<p>To give better advice, I'll first mention general advice anyone can use, and then specific advice for the four quadrants. For those who will say this is the Dark Arts, I say it would be if we lived in a Savannah without condoms, heating, medicine, houses or internets. Now it looks to me more like causing one-self, and one's beloved, to be more epistemically rational.</p>\n<p>&nbsp;</p>\n<p><strong id=\"General_Advice\">General Advice</strong></p>\n<p><strong>Women, be confident</strong>: If you are a woman, be more confident, way more confident, when approaching a guy, don't be aggressive, just safe, you mind is tuned with who knows how many trigger devices that may make you afraid of a no, of being thought of as slutty, of losing face, and of the guy not raising your kids. Discount for all that, twice. Don't do it if everyone <em>really will</em> know, or if you actually want kids from that guy.</p>\n<p><strong>Use your best horizon features:</strong> If you have a trait that the other gender optimizes for more in short-term, lure them by acting short-term, even if later you'll attempt to raise their oxytocin to the long-term point. If you have goods and ills on both time horizons, switch back and forth until you grasp what they want.&nbsp;</p>\n<p><strong>Discount for population size: </strong>There are two ways of doing that, one is to reason to yourself \"I may not be as attractive as Natalie Portman or Brad Pitt, but our minds are tuned to trying to get the best few achievable mates out of a group of 100-1000, not of hundreds of millions, so I do stand a very good chance\" The other is nearly opposite: \"I may think that I should only marry a prince, or sleep with Iron Man, but in fact my world is much smaller than this, and my mind will be totally okay to mate with Adam, that cool guy.\"</p>\n<p><strong>Be hedonistic: </strong>For men and women alike, the main way evolution got us into intercourse was by making it <em>fun</em>. The reasons it got us out are related to <em>unlikelihood of leaving great-grandchildren, energy waste, disease, and lowered status</em>. Of those, only a subset of lowered status is still significant in a world full of condoms. Other than women when aiming at long-term only, everyone is completely under-calibrated for sex, since we substantially reduced the risks without reducing the hedonic benefits nearly as much.</p>\n<p><strong>Use fetishes and peculiarities</strong>: There are things each particular person is attracted to more than everyone else (for me that's freckles, red/orange/blue/purple hair, upper back, and short women). Use that in your favour, <em>less competition</em>, as simple as that.</p>\n<p><strong>Go places</strong>: There are better and worse places to find mates. Short-terming males (a temporary condition in which any male may find himself, <em>not</em> a kind of male) abound in dancing clubs, military facilities and sports areas, not to mention OkCupid. Long-terming females (same) abound on courses and classes of yoga, dancing, cooking, languages, etc...&nbsp; Long-terming males usually have more of a routine, so are more frequent on saturdays and fridays than on a tuesday late evening, they'll be more frequent wherever no one naturally would go to find a one night stand, or in groups that are preselected for strong emotions (low thresholds for falling in love) Short-terming females may exist in dancing clubs, bars and other related areas, but are very high value due to comparative scarcity when in these areas, someone looking for them is better off in groups with a small majority of women, where social tension and hierarchies don't scale up in either gender.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Specific_Advice\">Specific Advice</strong></p>\n<p>Note: The advice is about things you should do <em>in addition</em> to what you naturally tend to do in those situations, you already have the algorithms, and should just improve calibration, unless when explicited, the suggestion is not to substitute what you naturally tend to do, or this would be a book all by itself explaining 4 kinds of human courtship.</p>\n<p><strong>For Long-terming Men: </strong>Stop freaking out about financial status. Find a place where you are among the great ones in something, specially kindness, dependability, physical constitution, and symmetry which guys think of less frequently than Successful startups or Tennis worldchampions. If you are hot, use short-term, women are particularly more prone to switching from short to long-term. Get a dog, show you are able and willing to take care of something unspeakably cute and adorable. Be ambitious in your projects, show passion. While ambitious and passionate, also make sure she realizes (truly) that you notice things about her no one else does, find out her values, talk about shared ones, and be non aggressively curious about all of them.&nbsp; Show her kindness in small gestures that need not cost a lot, such as time consuming hand-made presents. Test OkCupid and see if it works for you. Memorize details about her personality, assure her you can be loving specifically to her. Postpone sex <em>a little bit</em>. May sound hard, but is a reliable indicator that you won't change her for the next that quickly. Rationally override any emotion you may have regarding her sexual behavior, show you are not agressive and jealous, thus making her \"(be) (a)lieve unconsciously\" that you will not kill her in an assault of hatred when she sleeps with hypothetical another man whose child will never exist and get some years of schooling from you. If you think you can tell the wheat from the chaff, separate the PUA stuff that works for long-term, if not, read softer confidence/influence/seduction material. Use oxytocin inducing media (TV series and romantic movies). Rest assured, there are more women looking for long-term men than the opposite, aid the odds by going places. Show sympathy, kindness (to others as well) and dependability whenever you can.</p>\n<p><strong>For Long-terming Women:<em> </em></strong>If you've been convinced by financial status gospel, stop freaking out about it. If you just account for the 4 factors in the equation above, you'll be way ahead of everyone within the gospel trance, then there are still all the other things you look for in a guy, which by themselves are very important. Sure, a classic indicator is how much other women in your social group like him, and, good as it is, it is defined in terms of competition, try to discount this one, after all, it is partially just made of a conformity bias, a bad bias to have when looking for a long-term mate. Be very nice and kind, and almost silly near the guy. The kinds of guys who are Long-terming most of the time are those who won't approach you that frequently. Also, older guys obviously have less chaos on in their minds and lives, so are more likely to want to settle down for a few years. <em>Postpone sex</em> in proportion to how much you suspect the guy is Short-terming. The importance of this cannot be overstated. By postponing sex (and sex alone) you make sure Short-termers still have a good reason to be around you until suddenly there is a hormonal overload and they fall in love with you (not that romantic, but mildly accurate), love's trigger is activated by many factors, when they sum above a threshold. The most malleable of these factors is time investment, give a guy mixed short long signals, and you'll increase likelihood of surpassing the threshold. Also, give known guys a second chance, many times your algorithms friendzoned (sorry for the term) them for reasons as silly as \"he didn't touch me the first time we met, and I didn't feel his smell, because the table was wide\" or \"That day I was in Short-term mode and this other guy had more easily detectable attractive features, leaving John on the omega mental slot\". Forget romantic comedies and princess tales where your role is passive. A man's love is actively conquered by a woman, you are the one who will fight dragons - frequently RPG dragons - for the guy in the beggining, not the opposite, the opposite comes later as a prize.&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>For Short-terming Guys: </strong>Read Pick Up Artist books, actually do the exercises, as in don't find excuses for why you can't, do them. Don't do anything that disgusts you morally, which may be nearly all of it, but do all the rest. Other than that?... Some few things, very few indeed, were left out of those books. Optimize more than anything for your fetishes and specific desires to avoid competition. Use mildly tense situations which can be confounded with arousal (narrow bridges get you more dates than wide bridges). Woman's attractiveness peaks at approximately 1,73cm 5 feet 8 inches, shorter women are more likely to have had less home stability and developmental stability when young, which triggers more frequent short-terming, looking for testosterone indicators (square chin, prominent forehead, and specially having a ring-finger longer than index-finger) also helps, and it is fun because you can claim to read hands and actually make good predictions out of it.</p>\n<p><strong>For Short-terming Girls: </strong>I'll start with easy stuff, and escalate quickly to extremely high probability even in tough cases, such as he's not on the mood, tired, really shy, or (you think) not excited. Quite likely the main obstacle is inside your mind, not your clothes, either fear of rejection, or fear of reputational cost or something else. Be confident. Few guys will reject a subtle, feminine, <em>discrete</em> and firm sex \"offer\" (notice how language itself puts it). Look at him, smile, touch him while you speak, look intensely at his mouth while slowly approaching, <em>make sure</em> to try do this where he is unlikely to be paying some reputational cost (not on his aunt's marriage). If feeling clumsy, mention you do. When short-terming, men really do optimize for looks, so decrease light levels, and avoid available-female company, like asking him out to check a bookstore, or to see a movie. Sit near him while touching him, cut the conversation at some point, kiss him (remember to do that where neither of you may get embarrassed with anyone else). Before, talk about sexuality naturally and <em>imagetically</em>, say how it is important to you to be embraced, desired, enticed, penetrated, transformed inside, and arise re-energized the next day to go back to your life. If you are sure he is short-terming, make yourself scarce by mentioning time constraints. Carry condoms and pick them up while making up if he is still hesitant whether you want sex or not. But be cozy and reassure him \"It's okay\" if it feels like he nervous. If you are confortable with that, use the web, there are tons of Short-terming guys, and if you feel embarassed to meet a man who would reject you, you are safeguarded by being filtered beforehand through your pictures and description or by the<em> bang with friends</em> app. On the web, be upfront about your intentions, and assure them you are not a scam/bot/adv. When almost there, if he is not excited, <em>it is not because you are not attractive to him</em>, don't be passive, slowly touch and rub his genital, quite likely he's just nervous and you are disputing against his sympathetic system, when you and the parasympathetic win, he'll be excited and relaxed, and the party is on. If you live in a large urban area, go to swing places alone or with acquaintances, not friends - nowhere else there will be that many guys willing to have sex right there, right now, and the necessary infrastructure for it, <em>in a safe environment</em> with security guards, other high-class women etc... to make sure you are not getting into trouble - In short, guarantee situations in which neither him nor you pay reputational costs, be active yet reassuring, lower light levels, avoid competition and make sure there is infrastructure for the act.</p>\n<p>&nbsp;</p>\n<p>The saying goes that you can't achieve happiness by trying to be happy (thought you can if you <em>optimize</em> for happiness, i.e. by reading positive psychology and acting on it). To some extent, it is also true that a lot of what goes on during courtship does not take place while actively and consciously focusing on courtship. It is one thing to keep those misconceptions and advices in mind, and a whole different thing to be obsessed about them and use them as cognitive canonical maxims for behaving, the point of writing this is to help, if it stops being helpful, stop using it.</p>\n<p>&nbsp;</p>\n<p>Edit: Scrambled sources:</p>\n<div id=\"body_t1_8x55\" class=\"comment-content \">\n<div class=\"md\">\n<p>Buss Handbook of Evolutionary Psychology 2004</p>\n<p>Pinker - Family Values and Love chapters on How The Mind Works</p>\n<p>Mating Intelligence, the one from 2007 and the 2011 ones, many authors (including Helen Fisher) both linked above.</p>\n<p>Robert Trivers theory of parental investment, conflict etc... - 197x</p>\n<p>Lots of conversations with dozens to a hundred friends about their current sex lives.</p>\n<p>PUA - Mistery Method - Rules of The Game - The Layguide (assumption: the older ones had less economic incentive to create vocabulary and new complexity out of the blue, therefore are more accurate and less Bullshitty)</p>\n<p>Helen Fisher (presentations, vidoes, some articles)</p>\n<p>Lots of conversations with a friend who read lots of evopsych and would spend the pomodoro intervals explaining the article he just read to me.</p>\n<p>Personal experience.</p>\n<p>The Eternal Child, Clive Broomhall</p>\n<p>The Mind in the Cave - forgot author</p>\n<p>MIT The Cognitive Neurosciences III (2004)</p>\n<p>Primate sexuality (1999)</p>\n<p>This video is also great, Why do Women Have Sex? <a rel=\"nofollow\" href=\"http://www.youtube.com/watch?v=KA0sqg3EHm8\">http://www.youtube.com/watch?v=KA0sqg3EHm8</a></p>\n<h6>Edit: This was originally posted to main and downgraded to Discussion by Eliezer claiming that it didn't have many upvotes. It did have lots of downvotes (37%), as I'd expect from any controversial topic, but also had more than 50 upvotes at the time. I submit a proposal that controversial topics should not be downgraded, and that total number of votes be a relevant factor, not only difference between ups and downs, to avoid death spirals, and conformity bias. If policy changes, notice this DOES NOT benefit me in any way, since I don't plan on writing for about a semester, and this text will be long gone. <br></h6>\n<p>It is hard to unscramble it all to give specific citations, but that is a list of stuff I've read that deals with related issues that come to mind.</p>\n</div>\n</div>", "sections": [{"title": "Misconceptions", "anchor": "Misconceptions", "level": 1}, {"title": "Misconception 1: Guys do Short-term, Girls do Long-term, unless they don't have this option.", "anchor": "Misconception_1__Guys_do_Short_term__Girls_do_Long_term__unless_they_don_t_have_this_option_", "level": 2}, {"title": "Misconception 2: Women go for the bad guys (if I remember my American Pie's correctly, also called jocks in US) and good guys, nerds, and conventionals are left last.\u00a0", "anchor": "Misconception_2__Women_go_for_the_bad_guys__if_I_remember_my_American_Pie_s_correctly__also_called_jocks_in_US__and_good_guys__nerds__and_conventionals_are_left_last__", "level": 2}, {"title": "Misconception 3: Guys just go for looks, Girls just go for status.\u00a0", "anchor": "Misconception_3__Guys_just_go_for_looks__Girls_just_go_for_status__", "level": 2}, {"title": "Misconception 4: When genders optimize for Status, Status=Money.", "anchor": "Misconception_4__When_genders_optimize_for_Status__Status_Money_", "level": 2}, {"title": "Advice", "anchor": "Advice", "level": 1}, {"title": "General Advice", "anchor": "General_Advice", "level": 2}, {"title": "Specific Advice", "anchor": "Specific_Advice", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "149 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 149, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DFHhuAMexXAi8T6AY", "aRHLNr62JCbBBkQXD", "o8Bh82hKGpRNA2q36", "x6WkBHYEiqDYCpsnX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-06T06:51:31.722Z", "modifiedAt": null, "url": null, "title": "Meetup :  ", "slug": "meetup-1", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "A4YWnHwTjSbdqiGhj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LXhvK7guD4Agu3Wrc/meetup-1", "pageUrlRelative": "/posts/LXhvK7guD4Agu3Wrc/meetup-1", "linkUrl": "https://www.lesswrong.com/posts/LXhvK7guD4Agu3Wrc/meetup-1", "postedAtFormatted": "Monday, May 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXhvK7guD4Agu3Wrc%2Fmeetup-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXhvK7guD4Agu3Wrc%2Fmeetup-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXhvK7guD4Agu3Wrc%2Fmeetup-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mj'> </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 May 2013 06:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mj'> </a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LXhvK7guD4Agu3Wrc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "22511", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____\">Discussion article for the meetup : <a href=\"/meetups/mj\"> </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 May 2013 06:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____1\">Discussion article for the meetup : <a href=\"/meetups/mj\"> </a></h2>", "sections": [{"title": "Discussion article for the meetup :  ", "anchor": "Discussion_article_for_the_meetup____", "level": 1}, {"title": "Discussion article for the meetup :  ", "anchor": "Discussion_article_for_the_meetup____1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T02:27:31.590Z", "modifiedAt": null, "url": null, "title": "Be Nice to Non-Rationalists", "slug": "be-nice-to-non-rationalists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.317Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wobster109", "createdAt": "2011-03-23T00:20:05.950Z", "isAdmin": false, "displayName": "wobster109"}, "userId": "ACBZi6NBz3rarqbY9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xsZgGjW4ARQLrA2Q8/be-nice-to-non-rationalists", "pageUrlRelative": "/posts/xsZgGjW4ARQLrA2Q8/be-nice-to-non-rationalists", "linkUrl": "https://www.lesswrong.com/posts/xsZgGjW4ARQLrA2Q8/be-nice-to-non-rationalists", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Be%20Nice%20to%20Non-Rationalists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABe%20Nice%20to%20Non-Rationalists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxsZgGjW4ARQLrA2Q8%2Fbe-nice-to-non-rationalists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Be%20Nice%20to%20Non-Rationalists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxsZgGjW4ARQLrA2Q8%2Fbe-nice-to-non-rationalists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxsZgGjW4ARQLrA2Q8%2Fbe-nice-to-non-rationalists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 685, "htmlBody": "<p><span style=\"color: #808080;\">Note: I have no intention of criticizing the person involved. I admire that (s)he made the \"right\" decision in the end (in my opinion), and I mention it only as an example we could all learn from. I did request permission to use his/her anecdote here. I'll also use the pronoun \"he\" when really I mean he/she.</span></p>\n<p>---</p>\n<p><em>Once Pat says &ldquo;no,&rdquo; it&rsquo;s harder to get to &ldquo;yes&rdquo; than if you had never asked.</em></p>\n<p>---</p>\n<p>Crocker's rules has this very clear clause, and we should keep it well in mind:</p>\n<p><em>Note that Crocker's Rules does not mean you can insult people; it means that other people don't have to worry about whether they are insulting you. Crocker's Rules are a discipline, not a privilege. Furthermore, taking advantage of Crocker's Rules does not imply reciprocity. How could it? Crocker's Rules are something you do for yourself, to maximize information received - not something you grit your teeth over and do as a favor.</em></p>\n<p>Recently, a rationalist heard over social media that an acquaintance - a friend-of-a-friend - had found their lost pet. They said it was better than winning a lottery. The rationalist responded that unless they'd spent thousands of dollars searching, or posted a large reward, then they're saying something they don't really mean. Then, feeling like a party-pooper and a downer, he deleted his comment.</p>\n<p>I believe this was absolutely the correct things to do. As Miss Manners says (<a href=\"http://www.washingtonpost.com/wp-dyn/content/article/2007/02/06/AR2007020601518.html\">http://www.washingtonpost.com/wp-dyn/content/article/2007/02/06/AR2007020601518.html</a>), people will associate unpleasant emotions with the source and the cause. They're not going to say, oh, that's correct; I was mistaken about the value of my pet; thank you for correcting my flawed value system.</p>\n<p>Instead they'll say, those rationalists are so heartless, attaching dollar signs to everything. They think they know better. They're rude and stuck up. I don't want to have anything to do with them. And then they'll think walk away with a bad impression of us. (Yes, all of us, for we are a minority now, and each of us reflects upon all of us, the same way a Muslim bomber would reflect poorly on public opinion of all Muslims, while a Christian bomber would not.) In the future they'll be less likely to listen to any one of us.</p>\n<p>The only appropriate thing to say in this case is \"I'm so happy for you.\" But that doesn't mean we can't promote ourselves ever. Here are some alternatives.</p>\n<ul>\n<li>At another time, ask for \"help\" with your own decisions. Go through the process of calculating out all the value and expected values. This is completely non-confrontational, and your friends/acquaintances will not need to defend anything. Whenever they give a suggestion, praise it as being a good idea, and then make a show of weighing the expected value out loud.</li>\n<li>Say \"wow, I don't know many people who'd spend that much! Your pet is lucky to have someone like you!\" But it must be done without any sarcasm. They might feel a bit uncomfortable taking that much praise. They might go home and mull it over.</li>\n<li>Invite them to \"try something you saw online\" with you. This thing could be mindcharting, the estimation game, learning quantum physics, meditation, goal refactoring, anything. Emphasize the curiosity/exploring aspect. See if it leads into a conversation about rationality. Don't mention the incident with the pet - it could come off as criticism.</li>\n<li>At a later date, introduce them to Methods or Rationality. Say it's because \"it's funny,\" or \"you have a lot of interesting ideas,\" or even just \"I think you'll like it.\" That's generally a good starting point. :)</li>\n<li>Let it be. First do no harm.</li>\n</ul>\n<p>I was told long ago (in regards to LGBT rights) that minds are not changed by logic or reasoning or facts. They are changed over a long period of time by emotions. For us, that means showing what we believe without pressing it on others, while at the same time being the kind of person you want to be like. If we are successful and happy, if we carry ourselves with kindness and dignity, we'll win over hearts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xsZgGjW4ARQLrA2Q8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 42, "extendedScore": null, "score": 1.1913287278581075e-06, "legacy": true, "legacyId": "22513", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T05:35:31.400Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] My Way", "slug": "seq-rerun-my-way", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:37.541Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fGeHrNPwdd63jmeeE/seq-rerun-my-way", "pageUrlRelative": "/posts/fGeHrNPwdd63jmeeE/seq-rerun-my-way", "linkUrl": "https://www.lesswrong.com/posts/fGeHrNPwdd63jmeeE/seq-rerun-my-way", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20My%20Way&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20My%20Way%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfGeHrNPwdd63jmeeE%2Fseq-rerun-my-way%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20My%20Way%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfGeHrNPwdd63jmeeE%2Fseq-rerun-my-way", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfGeHrNPwdd63jmeeE%2Fseq-rerun-my-way", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 270, "htmlBody": "<p>Today's post, <a href=\"/lw/bd/my_way/\">My Way</a> was originally published on 17 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>I sometimes think of myself as being like the protagonist in a classic SF labyrinth story, wandering further and further into some alien artifact, trying to radio back a description of what I'm seeing, so that I can be followed. But what I'm finding is not just the Way, the thing that lies at the center of the labyrinth; it is also my Way, the path that I would take to come closer to the center, from whatever place I started out. And yet there is still a common thing we are all trying to find. We should be aware that others' shortest paths may not be the same as our own, but this is not the same as giving up the ability to judge or to share.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/hd8/seq_rerun_of_gender_and_rationality/\">Of Gender and Rationality</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fGeHrNPwdd63jmeeE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.1914633506150041e-06, "legacy": true, "legacyId": "22518", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FBgozHEv7J72NCEPB", "CLXEPDqguiYEpXgLY", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T12:59:06.778Z", "modifiedAt": null, "url": null, "title": "Catching Up With the Present From the Developing World", "slug": "catching-up-with-the-present-from-the-developing-world", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:27.459Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qg7pMzgeTPpG2MSsa/catching-up-with-the-present-from-the-developing-world", "pageUrlRelative": "/posts/qg7pMzgeTPpG2MSsa/catching-up-with-the-present-from-the-developing-world", "linkUrl": "https://www.lesswrong.com/posts/qg7pMzgeTPpG2MSsa/catching-up-with-the-present-from-the-developing-world", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Catching%20Up%20With%20the%20Present%20From%20the%20Developing%20World&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACatching%20Up%20With%20the%20Present%20From%20the%20Developing%20World%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqg7pMzgeTPpG2MSsa%2Fcatching-up-with-the-present-from-the-developing-world%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Catching%20Up%20With%20the%20Present%20From%20the%20Developing%20World%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqg7pMzgeTPpG2MSsa%2Fcatching-up-with-the-present-from-the-developing-world", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqg7pMzgeTPpG2MSsa%2Fcatching-up-with-the-present-from-the-developing-world", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 968, "htmlBody": "<p>Hi all, I'm leaving Lesswrong for a few months to pursue a Masters, and this Text below will never be finished. It is just a story of what is it like to grow up outside where everything is going on, a country where humanities are sad and terrible, and people are fun, but not quite <a href=\"http://www.davemckay.co.uk/philosophy/russell/russell.php?name=knowledge.and.wisdom\">wise</a>.&nbsp;</p>\n<p>Original Summary: Two things <em>(Note: Were going to)</em> permeate this text, an autobiographical short account of what is it like to grow up far from where things are happening, and an outside view account of some of the people and institutions (MIRI,LW,Leverage Research, FHI,80k,GWWC) whom presently carry, as far as I can see, the highest expected value gamble of our time. I have visited all those institutions, and my account here should be considered just a biased, one subjective perspective data point, not a proper evaluation of those places. Other people who come from developing world countries might have interesting stories to tell, and I'd encourage them to do so (Pablo in Argentina, many in India, China and elsewhere)</p>\n<p><em>(NOTE: There is </em>nothing<em> about the institutions here, only the growing up part was written by the time I decided to halt this writing)</em></p>\n<p><strong>Far away, across the sea</strong></p>\n<p>As is the case with most outliers, outcasts, and outsiders in general, a large amount of sociological facts were determinant of me being the first person in Brazil acquainted with the cluster of ideas to which the institutions mentioned belong. Jonatas, the other&nbsp;Brazilian who entered this world early on (2004), has a very similar story to tell. The prerequisites seem to have been: young, middle class, children of early adopters, inclined towards philosophy, living in a cosmopolitan area, with a particular disregard for authority (uncommon in Brazil), high IQ (aprox 4 SDs above Brazilian average) beginning to get stuck in a nonsense university system in the humanities. Due to expected income considerations and a large variance in income among Brazilians, most of the high IQ people go for Medicine, Engineering, Law and sometimes physical sciences. Thus many of the humanities become just signalling that you praise the right authorities (right here meaning whomever your advisor or professor was compelled to praise by his professor) and the cycle rolls on and on.&nbsp;</p>\n<p>So I was left with good resources (time, curiosity, intellectual eagerness) and internet access. The web changed it all. It was hard to capture the signal among the noise in the intellectual world there, and my path was reading an interview in a magazine with this guy who thought so differently that he seemed amazing, a biogeographist is what the magazine called him (I had to invent a meaning for that), that was Jared Diamond. Then Guns Germs and Steel, and, buying books, waiting two months for them to come, I slowly built a foundational knowledge of the Third Culture people, those whom John Brockman currently gathers on <em>The Edge</em>&nbsp;website.&nbsp;</p>\n<p>It seemed they were sensible and smart people, Dawkins, Dennett, Pinker, and many others. Yet in our closed country in the humanities, no one had any idea of what that was all about. Understandably, I frequently thought I was wrong, or crazy, since that is what others thought about me. The neodarwinians were a huge problem in the moral punishing intellectual world I was living, they were enough to make you an outcast, an untouchable perhaps. But they were not the worse, the worse was yet to come.</p>\n<p>&nbsp;The worse was when I found Aubrey de Grey and Nick Bostrom. I should call those early years the schizophrenic ones, because only focusing all my brainpower in being schizophrenic could I possibly survive among my peers while considering the opinions and thoughts of those two individuals sensible and worthy. It has recently been pointed out in one the best posts here that:</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;Any idiot can tell you why death is bad, but it takes a very particular sort of idiot to believe that death might be good.</span></p>\n</blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">- Yvain&nbsp;</span></p>\n<p>That very particular sort of idiot composes 98% of our humanities academy, the intelligence that is valued is the subtle and sophisticated one that makes small benefits salient while concealing obviously enormous costs, or the one that signals capacity while making the world a worse place.&nbsp;</p>\n<p>At the young age of eighteen I was learning Freudian babble during the day, reading Russell at late afternoon, since he was both sensible and acceptable among my peers, being a 100 years old Lord, and subscribed to the Shock Level 4 email group controlled by Eliezer at night, noticing that something really big was going on and not having anyone around to talk about it. I'd be thinking about the Simulation Argument, and my friends would be thinking about what the teacher's password was for that particular behaviorist explanation that was discredited 70 years ago, and how they hated it <em>because </em>the Freudian alternative obviously felt right. It takes schizophrenia to survive in the wild.&nbsp;</p>\n<p><strong>The Path Became Smooth</strong></p>\n<p>Time went by, memes were spread and slowly but steadily it was possible to come out of the closet about a lot of my beliefs and thoughts. The classes on how to write ambiguous commentaries on Hegel didn't stop, but the sanity waterline was being raised, specially among my colleagues who were pursuing exact science degrees. 2008 was the shifting point, suddenly I met one other Transhumanist, and eventually a rationalist, and near the end an utilitarian. Schizophrenia was no longer that necessary. Fast forward to now 2013 and you have many of those ideas, such as Singularity, ending ageing, considering cognitive science a part of psychology, brain machine interface, etc... all on the cover page of major magazines and being topic of conversation on TV shows. &nbsp;</p>\n<p>Some few people started actually caring about that. Meanwhile something else was growing, the Effective Altruist movement.</p>\n<p>(here this abruptly finishes, and won't be continued)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qg7pMzgeTPpG2MSsa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 27, "extendedScore": null, "score": 1.191781107901124e-06, "legacy": true, "legacyId": "22120", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Hi all, I'm leaving Lesswrong for a few months to pursue a Masters, and this Text below will never be finished. It is just a story of what is it like to grow up outside where everything is going on, a country where humanities are sad and terrible, and people are fun, but not quite <a href=\"http://www.davemckay.co.uk/philosophy/russell/russell.php?name=knowledge.and.wisdom\">wise</a>.&nbsp;</p>\n<p>Original Summary: Two things <em>(Note: Were going to)</em> permeate this text, an autobiographical short account of what is it like to grow up far from where things are happening, and an outside view account of some of the people and institutions (MIRI,LW,Leverage Research, FHI,80k,GWWC) whom presently carry, as far as I can see, the highest expected value gamble of our time. I have visited all those institutions, and my account here should be considered just a biased, one subjective perspective data point, not a proper evaluation of those places. Other people who come from developing world countries might have interesting stories to tell, and I'd encourage them to do so (Pablo in Argentina, many in India, China and elsewhere)</p>\n<p><em>(NOTE: There is </em>nothing<em> about the institutions here, only the growing up part was written by the time I decided to halt this writing)</em></p>\n<p><strong id=\"Far_away__across_the_sea\">Far away, across the sea</strong></p>\n<p>As is the case with most outliers, outcasts, and outsiders in general, a large amount of sociological facts were determinant of me being the first person in Brazil acquainted with the cluster of ideas to which the institutions mentioned belong. Jonatas, the other&nbsp;Brazilian who entered this world early on (2004), has a very similar story to tell. The prerequisites seem to have been: young, middle class, children of early adopters, inclined towards philosophy, living in a cosmopolitan area, with a particular disregard for authority (uncommon in Brazil), high IQ (aprox 4 SDs above Brazilian average) beginning to get stuck in a nonsense university system in the humanities. Due to expected income considerations and a large variance in income among Brazilians, most of the high IQ people go for Medicine, Engineering, Law and sometimes physical sciences. Thus many of the humanities become just signalling that you praise the right authorities (right here meaning whomever your advisor or professor was compelled to praise by his professor) and the cycle rolls on and on.&nbsp;</p>\n<p>So I was left with good resources (time, curiosity, intellectual eagerness) and internet access. The web changed it all. It was hard to capture the signal among the noise in the intellectual world there, and my path was reading an interview in a magazine with this guy who thought so differently that he seemed amazing, a biogeographist is what the magazine called him (I had to invent a meaning for that), that was Jared Diamond. Then Guns Germs and Steel, and, buying books, waiting two months for them to come, I slowly built a foundational knowledge of the Third Culture people, those whom John Brockman currently gathers on <em>The Edge</em>&nbsp;website.&nbsp;</p>\n<p>It seemed they were sensible and smart people, Dawkins, Dennett, Pinker, and many others. Yet in our closed country in the humanities, no one had any idea of what that was all about. Understandably, I frequently thought I was wrong, or crazy, since that is what others thought about me. The neodarwinians were a huge problem in the moral punishing intellectual world I was living, they were enough to make you an outcast, an untouchable perhaps. But they were not the worse, the worse was yet to come.</p>\n<p>&nbsp;The worse was when I found Aubrey de Grey and Nick Bostrom. I should call those early years the schizophrenic ones, because only focusing all my brainpower in being schizophrenic could I possibly survive among my peers while considering the opinions and thoughts of those two individuals sensible and worthy. It has recently been pointed out in one the best posts here that:</p>\n<blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;Any idiot can tell you why death is bad, but it takes a very particular sort of idiot to believe that death might be good.</span></p>\n</blockquote>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">- Yvain&nbsp;</span></p>\n<p>That very particular sort of idiot composes 98% of our humanities academy, the intelligence that is valued is the subtle and sophisticated one that makes small benefits salient while concealing obviously enormous costs, or the one that signals capacity while making the world a worse place.&nbsp;</p>\n<p>At the young age of eighteen I was learning Freudian babble during the day, reading Russell at late afternoon, since he was both sensible and acceptable among my peers, being a 100 years old Lord, and subscribed to the Shock Level 4 email group controlled by Eliezer at night, noticing that something really big was going on and not having anyone around to talk about it. I'd be thinking about the Simulation Argument, and my friends would be thinking about what the teacher's password was for that particular behaviorist explanation that was discredited 70 years ago, and how they hated it <em>because </em>the Freudian alternative obviously felt right. It takes schizophrenia to survive in the wild.&nbsp;</p>\n<p><strong id=\"The_Path_Became_Smooth\">The Path Became Smooth</strong></p>\n<p>Time went by, memes were spread and slowly but steadily it was possible to come out of the closet about a lot of my beliefs and thoughts. The classes on how to write ambiguous commentaries on Hegel didn't stop, but the sanity waterline was being raised, specially among my colleagues who were pursuing exact science degrees. 2008 was the shifting point, suddenly I met one other Transhumanist, and eventually a rationalist, and near the end an utilitarian. Schizophrenia was no longer that necessary. Fast forward to now 2013 and you have many of those ideas, such as Singularity, ending ageing, considering cognitive science a part of psychology, brain machine interface, etc... all on the cover page of major magazines and being topic of conversation on TV shows. &nbsp;</p>\n<p>Some few people started actually caring about that. Meanwhile something else was growing, the Effective Altruist movement.</p>\n<p>(here this abruptly finishes, and won't be continued)</p>", "sections": [{"title": "Far away, across the sea", "anchor": "Far_away__across_the_sea", "level": 1}, {"title": "The Path Became Smooth", "anchor": "The_Path_Became_Smooth", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T13:30:38.019Z", "modifiedAt": null, "url": null, "title": "Googling is the first step. Consider adding scholarly searches to your arsenal.", "slug": "googling-is-the-first-step-consider-adding-scholarly", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:14.417Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tenoke", "createdAt": "2012-04-10T21:37:29.739Z", "isAdmin": false, "displayName": "Tenoke"}, "userId": "CRSZPEg9dHyMspTzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AkkGf7KSBQ7ZZxYk9/googling-is-the-first-step-consider-adding-scholarly", "pageUrlRelative": "/posts/AkkGf7KSBQ7ZZxYk9/googling-is-the-first-step-consider-adding-scholarly", "linkUrl": "https://www.lesswrong.com/posts/AkkGf7KSBQ7ZZxYk9/googling-is-the-first-step-consider-adding-scholarly", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Googling%20is%20the%20first%20step.%20Consider%20adding%20scholarly%20searches%20to%20your%20arsenal.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGoogling%20is%20the%20first%20step.%20Consider%20adding%20scholarly%20searches%20to%20your%20arsenal.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAkkGf7KSBQ7ZZxYk9%2Fgoogling-is-the-first-step-consider-adding-scholarly%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Googling%20is%20the%20first%20step.%20Consider%20adding%20scholarly%20searches%20to%20your%20arsenal.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAkkGf7KSBQ7ZZxYk9%2Fgoogling-is-the-first-step-consider-adding-scholarly", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAkkGf7KSBQ7ZZxYk9%2Fgoogling-is-the-first-step-consider-adding-scholarly", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1122, "htmlBody": "<p><span style=\"color: #999999;\"><a href=\"/r/discussion/lw/hcx/use_search_engines_early_and_often/\"></a></span></p>\n<p><strong>Related to:&nbsp;</strong><a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">Scholarship: How to Do It Efficiently</a></p>\n<p><a href=\"/r/discussion/lw/hcx/use_search_engines_early_and_often/\">There</a> <a href=\"/r/discussion/lw/h3w/open_thread_april_115_2013/8p3q\">has </a>been a slightly increased focus on the use of search engines lately. I agree that using Google is an important skill - in fact I believe that for years I have came across as significantly more&nbsp;knowledgeable&nbsp;than I actually am just by quickly looking for information when I am asked something.</p>\n<p>However, There are obviously some types of information which are more accessible by Google and some which are less accessible. For example distinct characteristics, specific dates of events etc. are easily googleable<sup>1</sup> and you can expect to quickly find&nbsp;accurate&nbsp;information on the topic. On the other hand, if you want to find out more&nbsp;ambiguous&nbsp;things such as the effects of having more friends on weight or even something like the negative and positive effects of a substance - then googling might leave you with some contradicting results,&nbsp;inaccurate&nbsp;information or at the very least it will likely take you longer to get to the truth.</p>\n<p>I have observed that in the latter case (when the topic is less 'googleable') most people, even those knowledgeable of search engines and 'science' will just stop searching for information after not finding anything on Google or even before<sup>2</sup> unless they are actually willing to devote a lot of time to find it. This is where my recommendation comes - consider doing a&nbsp;scholarly&nbsp;search like the one provided by <a href=\"http://scholar.google.co.uk/\">Google Scholar</a>.</p>\n<p>And, no, I am not suggesting that people should read a bunch of papers on every topic that they discuss. By using some simple heuristics we can easily gain a pretty good picture of the relevant information on a large variety of topics in a few minutes (or less in some cases). The heuristics are as follows:</p>\n<p>1. Read only or mainly the abstracts. This is what saves you time but gives you a lot of information in return and this is the key to the most cost-effective way to quickly find information from a scholary search. Often you wouldn't have immediate access to the paper anyway, however you can almost always read the abstract. And if you follow the other heuristics you will still be looking at relatively 'accurate' information most of the time. On the other hand, if you are looking for more information and have access to the full paper then the discussion+conclusion section are usually the second best thing to look at; and if you are unsure about the quality of the study, then you should also look at the method section to identify its limitations.<sup>3</sup></p>\n<p>2. Look at the number of citations for an article. The higher the better. Less than 10 citations in most cases means that you can find a better paper.</p>\n<p>3. Look at the date of the paper. Often more recent = better. However, you can expect less citations for more recent articles and you need to adjust accordingly. For example if the article came out in 2013 but it has already been cited 5 times this is probably a good sign. For new articles the subheuristic that I use is to evaluate the 'accuracy' of the article by judging the author's general credibilty instead - argument from authority.</p>\n<p>4. Meta-analyses/Systematic Reviews are your friend. This is where you can get the most information in the least amount of time!</p>\n<p>5. If you cannot find anything relevant fiddle with your search terms in whatever ways you can think of (you usually get better at this over time by learning what search terms give better results).</p>\n<p>That's the gist of it. By reading a few abstracts in a minute or two you can effectively search for information regarding our scientific knowledge on a subject with almost the same speed as searching for specific information on topics that I dubbed googleable. In my experience&nbsp;scholarly&nbsp;searches on pretty much anything can be really beneficial. Do you believe that drinking beer is bad but drinking wine is good? Search on&nbsp;Google Scholar! Do you think that it is a fact that social interaction is correlated with happiness?&nbsp;Google Scholar it! Sure, some things might seem obvious to you that X but it doesn't hurt to search on google scholar for a minute just to be able to cite a decent study on the topic to those X disbelievers.</p>\n<p>&nbsp;</p>\n<p>This post might not be useful to some people but it is my belief that scholarly searches are the next step of&nbsp;efficient&nbsp;information seeking after googling and that most LessWrongers are not utilizing this enough. Hell, I only recently started doing this actively and I still do not do it enough. Furthermore I fully agree with <a href=\"/r/discussion/lw/h3w/open_thread_april_115_2013/8p4z\">this </a>comment by gwern:</p>\n<blockquote>\n<p>My belief is that the more familiar and skilled you are with a tool, the more willing you are to reach for it. Someone who has been programming for decades will be far more willing to write a short one-off program to solve a problem than someone who is unfamiliar and unsure about programs (even if they suspect that they could get a canned script copied from StackExchange running in a few minutes). So the unwillingness to try googling at all is at least partially a lack of googling skill and familiarity.</p>\n</blockquote>\n<p>A lot of people will be reluctant to start doing scholarly searches because they have barely done any or because they have never done it. I want to tell those people to still give it a try. Start by searching for something easy, maybe something that you already know from lesswrong or from somewhere else. Read a few abstracts, if you do not understand a given abstract try finding other papers on the topic - some authors adopt a more technical style of writing, others focus mainly on statistics, etc. but you should still be able to find some good information if you read multiple abstracts and identify the main points. If you cannot find anythinr relevant then move on and try another topic.</p>\n<p>&nbsp;</p>\n<p>P.S. In my opinion, when you are&nbsp;comfortable&nbsp;enough to have scholarly searches as a part of your arsenal you will rarely have days when there is nothing to check for. If you are doing 1 scholarly search per month for example you are most probably not fully utilizing this skill.</p>\n<p>&nbsp;</p>\n<h5><br /><span style=\"font-weight: normal;\">1. By googleable I mean that the search terms are google friendly - you can relatively easily and quickly find relevant and accurate information.<br />2. If the people in question have developed a sense for what type of information is more accessible by google then they might not even try to google the less accessible-type things.<br />3. If you want to get a better and more accurate view on the topic in question you should read the full paper. The heuristic of mainly focusing on abstracts is cost-effective but it invariably results in a loss of information.</span></h5>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AkkGf7KSBQ7ZZxYk9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 30, "extendedScore": null, "score": 1.1918036928503288e-06, "legacy": true, "legacyId": "22522", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hdRzQ8TGJYDacmdZ9", "37sHjeisS9uJufi4u"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T14:26:04.604Z", "modifiedAt": null, "url": null, "title": "[LINK] Antibiotic seemingly improves decision-making in the presence of attractive women.", "slug": "link-antibiotic-seemingly-improves-decision-making-in-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:28.276Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "iconreforged", "createdAt": "2013-03-29T17:05:43.614Z", "isAdmin": false, "displayName": "iconreforged"}, "userId": "6pY4H6nEqYTBvKrvm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F3oZq8GhYbTxqMZfg/link-antibiotic-seemingly-improves-decision-making-in-the", "pageUrlRelative": "/posts/F3oZq8GhYbTxqMZfg/link-antibiotic-seemingly-improves-decision-making-in-the", "linkUrl": "https://www.lesswrong.com/posts/F3oZq8GhYbTxqMZfg/link-antibiotic-seemingly-improves-decision-making-in-the", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Antibiotic%20seemingly%20improves%20decision-making%20in%20the%20presence%20of%20attractive%20women.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Antibiotic%20seemingly%20improves%20decision-making%20in%20the%20presence%20of%20attractive%20women.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3oZq8GhYbTxqMZfg%2Flink-antibiotic-seemingly-improves-decision-making-in-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Antibiotic%20seemingly%20improves%20decision-making%20in%20the%20presence%20of%20attractive%20women.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3oZq8GhYbTxqMZfg%2Flink-antibiotic-seemingly-improves-decision-making-in-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF3oZq8GhYbTxqMZfg%2Flink-antibiotic-seemingly-improves-decision-making-in-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 165, "htmlBody": "<p><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/23595250\">This study</a>&nbsp;seems to show that <a href=\"http://en.wikipedia.org/wiki/Minocycline\">minocycline</a>&nbsp;helps to resist placing too much trust in attractive women.</p>\n<blockquote>\n<p><span style=\"font-family: arial, helvetica, clean, sans-serif; font-size: 13px; line-height: 17px;\">Recently, minocycline, a tetracycline antibiotic, has been reported to improve symptoms of psychiatric disorders and to facilitate sober decision-making in healthy human subjects. Here we show that minocycline also reduces the risk of the 'honey trap' during an economic exchange. Males tend to cooperate with physically attractive females without careful evaluation of their trustworthiness, resulting in betrayal by the female. In this experiment, healthy male participants made risky choices (whether or not to trust female partners, identified only by photograph, who had decided in advance to exploit the male participants). The results show that trusting behaviour in male participants significantly increased in relation to the perceived attractiveness of the female partner, but that attractiveness did not impact trusting behaviour in the minocycline group. Animal studies have shown that minocycline inhibits microglial activities. Therefore, this minocycline effect may shed new light on the unknown roles microglia play in human mental activities.</span></p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F3oZq8GhYbTxqMZfg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 7, "extendedScore": null, "score": 1.1918434203427474e-06, "legacy": true, "legacyId": "22523", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T14:30:37.725Z", "modifiedAt": null, "url": null, "title": "Meetup : Durham NC meetup: Living Luminously, Part 3", "slug": "meetup-durham-nc-meetup-living-luminously-part-3", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KhvxzzEdyqAsTFA7e/meetup-durham-nc-meetup-living-luminously-part-3", "pageUrlRelative": "/posts/KhvxzzEdyqAsTFA7e/meetup-durham-nc-meetup-living-luminously-part-3", "linkUrl": "https://www.lesswrong.com/posts/KhvxzzEdyqAsTFA7e/meetup-durham-nc-meetup-living-luminously-part-3", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Durham%20NC%20meetup%3A%20Living%20Luminously%2C%20Part%203&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Durham%20NC%20meetup%3A%20Living%20Luminously%2C%20Part%203%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKhvxzzEdyqAsTFA7e%2Fmeetup-durham-nc-meetup-living-luminously-part-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Durham%20NC%20meetup%3A%20Living%20Luminously%2C%20Part%203%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKhvxzzEdyqAsTFA7e%2Fmeetup-durham-nc-meetup-living-luminously-part-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKhvxzzEdyqAsTFA7e%2Fmeetup-durham-nc-meetup-living-luminously-part-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mk'>Durham NC meetup: Living Luminously, Part 3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">420 E Geer St, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be wrapping up our Living Luminously discussion with:</p>\n\n<p>Highlights and Shadows: <a href=\"http://lesswrong.com/lw/209/highlights_and_shadows/\" rel=\"nofollow\">http://lesswrong.com/lw/209/highlights_and_shadows/</a> <br />\nAs you uncover and understand new things about yourself, it's useful to endorse and repudiate your sub-components, and then encourage or interrupt them, respectively.</p>\n\n<p>City of Lights: <a href=\"http://lesswrong.com/lw/20r/city_of_lights/\" rel=\"nofollow\">http://lesswrong.com/lw/20r/city_of_lights/</a> <br />\nIt's a handy trick to represent yourself as multiple agents when dealing with tensions in yourself.</p>\n\n<p>Lampshading: <a href=\"http://lesswrong.com/lw/21l/lampshading/\" rel=\"nofollow\">http://lesswrong.com/lw/21l/lampshading/</a> <br />\nWhen you have models, test them - but rig your experiments!</p>\n\n<p>We'll have informal discussion and beverage procurement starting at 7 and official discussion from 7:30-9:00 or so.  Afterward, we often adjourn to an adjacent establishment (probably Fullsteam) for further beverages and social activity.</p>\n\n<p>RSVP on the listserv [<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>].  If you'd like transportation assistance, let us know there or here.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mk'>Durham NC meetup: Living Luminously, Part 3</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KhvxzzEdyqAsTFA7e", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.1918466821520042e-06, "legacy": true, "legacyId": "22524", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_3\">Discussion article for the meetup : <a href=\"/meetups/mk\">Durham NC meetup: Living Luminously, Part 3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">420 E Geer St, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be wrapping up our Living Luminously discussion with:</p>\n\n<p>Highlights and Shadows: <a href=\"http://lesswrong.com/lw/209/highlights_and_shadows/\" rel=\"nofollow\">http://lesswrong.com/lw/209/highlights_and_shadows/</a> <br>\nAs you uncover and understand new things about yourself, it's useful to endorse and repudiate your sub-components, and then encourage or interrupt them, respectively.</p>\n\n<p>City of Lights: <a href=\"http://lesswrong.com/lw/20r/city_of_lights/\" rel=\"nofollow\">http://lesswrong.com/lw/20r/city_of_lights/</a> <br>\nIt's a handy trick to represent yourself as multiple agents when dealing with tensions in yourself.</p>\n\n<p>Lampshading: <a href=\"http://lesswrong.com/lw/21l/lampshading/\" rel=\"nofollow\">http://lesswrong.com/lw/21l/lampshading/</a> <br>\nWhen you have models, test them - but rig your experiments!</p>\n\n<p>We'll have informal discussion and beverage procurement starting at 7 and official discussion from 7:30-9:00 or so.  Afterward, we often adjourn to an adjacent establishment (probably Fullsteam) for further beverages and social activity.</p>\n\n<p>RSVP on the listserv [<a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a>].  If you'd like transportation assistance, let us know there or here.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_31\">Discussion article for the meetup : <a href=\"/meetups/mk\">Durham NC meetup: Living Luminously, Part 3</a></h2>", "sections": [{"title": "Discussion article for the meetup : Durham NC meetup: Living Luminously, Part 3", "anchor": "Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_3", "level": 1}, {"title": "Discussion article for the meetup : Durham NC meetup: Living Luminously, Part 3", "anchor": "Discussion_article_for_the_meetup___Durham_NC_meetup__Living_Luminously__Part_31", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tCTmAmAapB37dAz9Y", "vfHRahpgbp9YFPuGQ", "goCfoiQkniQwPryki"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T17:22:52.299Z", "modifiedAt": null, "url": null, "title": "Open Thread: how do you look for information?", "slug": "open-thread-how-do-you-look-for-information", "viewCount": null, "lastCommentedAt": "2017-06-17T04:35:34.076Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9xvD68BnRfrMmAgnW/open-thread-how-do-you-look-for-information", "pageUrlRelative": "/posts/9xvD68BnRfrMmAgnW/open-thread-how-do-you-look-for-information", "linkUrl": "https://www.lesswrong.com/posts/9xvD68BnRfrMmAgnW/open-thread-how-do-you-look-for-information", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%3A%20how%20do%20you%20look%20for%20information%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%3A%20how%20do%20you%20look%20for%20information%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9xvD68BnRfrMmAgnW%2Fopen-thread-how-do-you-look-for-information%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%3A%20how%20do%20you%20look%20for%20information%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9xvD68BnRfrMmAgnW%2Fopen-thread-how-do-you-look-for-information", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9xvD68BnRfrMmAgnW%2Fopen-thread-how-do-you-look-for-information", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 58, "htmlBody": "<p>There have been a <a href=\"/r/discussion/lw/hdm/googling_is_the_first_step_consider_adding/\">couple</a>&nbsp;<a href=\"/r/discussion/lw/hcx/use_search_engines_early_and_often/\">discussion</a>&nbsp;<a href=\"/r/discussion/lw/h3w/open_thread_april_115_2013/8p3q\">posts</a>&nbsp;on this, but let's make it general and collect our tips in one place. It's also a good way to encourage each other at getting better at this - looking for info more often and more efficiently.</p>\n<p>So, if you want to find something out, where do you look, and how? Who do you ask?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9xvD68BnRfrMmAgnW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 1.1919701176235637e-06, "legacy": true, "legacyId": "22525", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AkkGf7KSBQ7ZZxYk9", "hdRzQ8TGJYDacmdZ9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-07T18:47:07.412Z", "modifiedAt": null, "url": null, "title": "Testing lords over foolish lords: gaming Pascal's mugging", "slug": "testing-lords-over-foolish-lords-gaming-pascal-s-mugging", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:28.586Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zWyBAzdp8hx7CvmhL/testing-lords-over-foolish-lords-gaming-pascal-s-mugging", "pageUrlRelative": "/posts/zWyBAzdp8hx7CvmhL/testing-lords-over-foolish-lords-gaming-pascal-s-mugging", "linkUrl": "https://www.lesswrong.com/posts/zWyBAzdp8hx7CvmhL/testing-lords-over-foolish-lords-gaming-pascal-s-mugging", "postedAtFormatted": "Tuesday, May 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Testing%20lords%20over%20foolish%20lords%3A%20gaming%20Pascal's%20mugging&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATesting%20lords%20over%20foolish%20lords%3A%20gaming%20Pascal's%20mugging%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzWyBAzdp8hx7CvmhL%2Ftesting-lords-over-foolish-lords-gaming-pascal-s-mugging%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Testing%20lords%20over%20foolish%20lords%3A%20gaming%20Pascal's%20mugging%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzWyBAzdp8hx7CvmhL%2Ftesting-lords-over-foolish-lords-gaming-pascal-s-mugging", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzWyBAzdp8hx7CvmhL%2Ftesting-lords-over-foolish-lords-gaming-pascal-s-mugging", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 403, "htmlBody": "<p>There are two&nbsp;separate&nbsp;reasons to reject <a href=\"/lw/h8k/pascals_muggle_infinitesimal_priors_and_strong/\">Pascal's mugger's demands</a>. The first one is if you have a system of priors or a method of updating that precluded you from going along with the deal. The second reason is that if it becomes known that you accept Pascal's mugger situations, people are going to seek you out and take advantage of you.</p>\n<p>I think it's useful to keep the two reasons very separate. If Pascal's mugger was a force of nature - a new theory of physics, maybe - then the case for keeping to expected utility maximisation may be quite strong. But when there are opponents, everything gets much more complicated - which is why <a href=\"http://en.wikipedia.org/wiki/Game_theory\">game theory</a>&nbsp;has thousands of published research papers, while expected utility maximisation is taught in passing in other subjects.</p>\n<p>But does this really affect the argument? It means that someone approaching you with a Pascal's mugging today is much less likely to be honest (and much more likely to have simply read about it on Less Wrong). But that's a relatively small shift in probability, in an area where the number are already so huge/tiny.</p>\n<p>Nevertheless, it seems that \"reject Pascal's muggings (and other easily exploitable gambles)\" may be a reasonable position to take, even if you agreed with the expected utility calculation. First, of course, you would gain that you reject all the human attempts to exploit you. But there's another dynamic: the \"Lords of the Matrix\" are players too. They propose certain deals to you for certain reasons, and fail to propose them to you for other reasons. We can model three kinds of lords:</p>\n<ol>\n<li>The foolish lords, who will offer a Pascal's mugging no matter what they predict your reaction will be.</li>\n<li>The sadistic lords, who will offer a deal you won't accept.</li>\n<li>The testing lords, who will offer a deal you will accept, but push you to the edge of your logic and value system.</li>\n</ol>\n<p>Precommitting to rejecting the mugging burns you only with the foolish lords. The sadistic lords won't offer an acceptable deal anyway, and the testing lords will offer you a better deal if you've made such a&nbsp;precommitment. So the gain is the loss with (some of) the foolish lords versus a gain with the testing lords. Depending on your probability distribution over the lord types, this can be a reasonable thing to do, even if you would accept the impersonal version of the&nbsp;mugging.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zWyBAzdp8hx7CvmhL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 4, "extendedScore": null, "score": 1.1920305037859426e-06, "legacy": true, "legacyId": "22526", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Ap4KfkHyxjYPDiqh2"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-08T00:43:17.403Z", "modifiedAt": null, "url": null, "title": "Pascal's Muggle: Infinitesimal Priors and Strong Evidence", "slug": "pascal-s-muggle-infinitesimal-priors-and-strong-evidence", "viewCount": null, "lastCommentedAt": "2016-03-19T20:48:25.725Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ap4KfkHyxjYPDiqh2/pascal-s-muggle-infinitesimal-priors-and-strong-evidence", "pageUrlRelative": "/posts/Ap4KfkHyxjYPDiqh2/pascal-s-muggle-infinitesimal-priors-and-strong-evidence", "linkUrl": "https://www.lesswrong.com/posts/Ap4KfkHyxjYPDiqh2/pascal-s-muggle-infinitesimal-priors-and-strong-evidence", "postedAtFormatted": "Wednesday, May 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pascal's%20Muggle%3A%20Infinitesimal%20Priors%20and%20Strong%20Evidence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APascal's%20Muggle%3A%20Infinitesimal%20Priors%20and%20Strong%20Evidence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAp4KfkHyxjYPDiqh2%2Fpascal-s-muggle-infinitesimal-priors-and-strong-evidence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pascal's%20Muggle%3A%20Infinitesimal%20Priors%20and%20Strong%20Evidence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAp4KfkHyxjYPDiqh2%2Fpascal-s-muggle-infinitesimal-priors-and-strong-evidence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAp4KfkHyxjYPDiqh2%2Fpascal-s-muggle-infinitesimal-priors-and-strong-evidence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 7771, "htmlBody": "<p><strong>Followup to:</strong>&nbsp; <a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">Pascal's Mugging: Tiny Probabilities of Vast Utilities</a>, <a href=\"/lw/z0/the_pascals_wager_fallacy_fallacy/\">The Pascal's Wager Fallacy Fallacy</a>, <a href=\"/lw/h8m/being_halfrational_about_pascals_wager_is_even/\">Being Half-Rational About Pascal's Wager Is Even Worse</a></p>\n<p><strong>Short form: &nbsp;</strong><a href=\"/r/discussion/lw/hd3/pascals_muggle_short_version/\">Pascal's Muggle</a></p>\n<p><em>tl;dr: &nbsp;If you assign superexponentially infinitesimal probability to claims of large impacts, then apparently you should ignore the possibility of a large impact even after seeing huge amounts of evidence. &nbsp;If a poorly-dressed street person offers to save 10<sup>(10^100)</sup> lives (googolplex lives) for $5 using their Matrix Lord powers, and you claim to assign this scenario less than 10<sup>-(10^100)</sup> probability, then apparently you should continue to believe absolutely that their offer is bogus even after they snap their fingers and cause a giant silhouette of themselves to appear in the sky. &nbsp;For the same reason, any evidence you encounter showing that the human species could create a sufficiently large number of descendants - no matter how normal the corresponding laws of physics appear to be, or how well-designed the experiments which told you about them - must be rejected out of hand. &nbsp;There is a possible reply to this objection using Robin Hanson's anthropic adjustment against the probability of large impacts, and in this case you will treat a Pascal's Mugger as having decision-theoretic importance exactly proportional to the Bayesian strength of evidence they present you, without quantitative dependence on the number of lives they claim to save.&nbsp; This however corresponds to an odd mental state which some, such as myself, would find unsatisfactory. &nbsp;In the end, however, I cannot see any better candidate for a prior than having a leverage penalty plus a complexity penalty on the prior probability of scenarios.</em></p>\n<p>In late 2007 I coined the term \"Pascal's Mugging\" to describe a problem which seemed to me to arise when combining conventional decision theory and conventional epistemology in the obvious way. &nbsp;On conventional epistemology, <a href=\"http://wiki.lesswrong.com/wiki/Occam's_razorhttp://lesswrong.com/lw/jp/occams_razor/\">the prior probability of hypotheses diminishes exponentially with their complexity</a>; if it would take 20 bits to specify a hypothesis, then its prior probability receives a 2<sup>-20</sup> penalty factor and it will require evidence with a likelihood ratio of&nbsp;1,048,576:1 - evidence which we are&nbsp;1048576 times more likely to see if the theory is true, than if it is false - to make us assign it around 50-50 credibility. &nbsp;(This isn't as hard as it sounds. &nbsp;Flip a coin 20 times and note down the exact sequence of heads and tails. &nbsp;You now believe in a state of affairs you would have assigned a million-to-one probability beforehand - namely, that the coin would produce the exact sequence HTHHHHTHTTH... or whatever - after experiencing sensory data which are more than a million times more probable if that fact is true than if it is false.) &nbsp;The problem is that although this kind of prior probability penalty may seem very strict at first, it's easy to construct physical scenarios that grow in size vastly faster than they grow in complexity.</p>\n<p>I originally illustrated this using Pascal's Mugger: &nbsp;A poorly dressed street person says \"I'm actually a Matrix Lord running this world as a computer simulation, along with many others - the universe above this one has laws of physics which allow me easy access to vast amounts of computing power. &nbsp;Just for fun, I'll make you an offer - you give me five dollars, and I'll use my Matrix Lord powers to save 3&uarr;&uarr;&uarr;&uarr;3 people inside my simulations from dying and let them live long and happy lives\" where &uarr; is&nbsp;<a href=\"http://en.wikipedia.org/wiki/Knuth's_up-arrow_notation\">Knuth's up-arrow notation</a>. &nbsp;This was originally posted in 2007, when I was a bit more naive about what kind of mathematical notation you can throw into a random blog post without creating a stumbling block. &nbsp;(E.g.: &nbsp;On several occasions now, I've seen someone on the Internet approximate the number of dust specks from <a href=\"/lw/kn/torture_vs_dust_specks/\">this scenario</a> as being a \"billion\", since any incomprehensibly large number equals a billion.) &nbsp;Let's try an easier (and <em>way </em>smaller) number instead, and suppose that Pascal's Mugger offers to save a googolplex lives, where a googol is 10<sup>100</sup> (a 1 followed by a hundred zeroes) and a googolplex is 10 to the googol power, so 10<sup>10<sup>100</sup></sup> or 10<sup>10,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000</sup> lives saved if you pay Pascal's Mugger five dollars, if the offer is honest.<a id=\"more\"></a></p>\n<p>If Pascal's Mugger had only offered to save a mere <em>googol </em>lives (10<sup>100</sup>), we could perhaps reply that although the notion of a Matrix Lord may sound simple to say in English, if we actually try to imagine all the machinery involved, it works out to a substantial amount of computational complexity. &nbsp;(Similarly, Thor is a worse explanation for lightning bolts than the laws of physics because, among other points, an anthropomorphic deity is more complex than calculus in <em>formal</em>&nbsp;terms - it would take a larger computer program to simulate Thor as a complete mind, than to simulate Maxwell's Equations - even though in mere human words Thor sounds much easier to explain.) &nbsp;To imagine this scenario in formal detail, we might have to write out the laws of the higher universe the Mugger supposedly comes from, the Matrix Lord's state of mind leading them to make that offer, and so on. &nbsp;And so (we reply) when mere verbal English has been translated into a formal hypothesis, the Kolmogorov complexity of this hypothesis is more than 332 bits - it would take more than 332 ones and zeroes to specify - where 2<sup>-332</sup> ~ 10<sup>-100</sup>. &nbsp;Therefore (we conclude) the net expected value of the Mugger's offer is still tiny, once its prior improbability is taken into account.</p>\n<p>But once Pascal's Mugger offers to save a <em>googolplex</em>&nbsp;lives - offers us a scenario whose value is constructed by twice-repeated&nbsp;exponentiation - we seem to run into some difficulty using this answer. &nbsp;Can we really claim that the complexity of this scenario is on the order of a googol bits&nbsp;- that to formally write out the hypothesis would take one hundred billion billion times more bits than there are atoms in the observable universe?</p>\n<p>And a tiny, paltry number like a googolplex is only the beginning of computationally simple numbers that are unimaginably huge. &nbsp;Exponentiation is defined as repeated multiplication: &nbsp;If you see a number like 3<sup>5</sup>, it tells you to multiply five 3s together: 3&times;3&times;3&times;3&times;3 = 243. &nbsp;Suppose we write 3<sup>5</sup>&nbsp;as 3&uarr;5, so that a single arrow &uarr; stands for exponentiation, and let the double arrow &uarr;&uarr; stand for repeated exponentation, or <em>tetration</em>. &nbsp;Thus 3&uarr;&uarr;3 would stand for 3&uarr;(3&uarr;3) or 3<sup>3<sup>3</sup></sup>&nbsp;= 3<sup>27</sup>&nbsp;= 7,625,597,484,987. &nbsp;Tetration is also written as follows:&nbsp;<sup>3</sup>3 = 3&uarr;&uarr;3. &nbsp;Thus&nbsp;<sup>4</sup>2 = 2<sup>2<sup>2<sup>2</sup></sup></sup>&nbsp;= 2<sup>2<sup>4</sup></sup> = 2<sup>16</sup> = 65,536. &nbsp;Then pentation, or repeated tetration, would be written with 3&uarr;&uarr;&uarr;3 = <sup><sup>3</sup>3</sup>3 = <sup>7,625,597,484,987</sup>3 = 3<sup>3<sup>...<sup>3</sup></sup></sup>&nbsp;where the ... summarizes an exponential tower of 3s seven trillion layers high.</p>\n<p>But 3&uarr;&uarr;&uarr;3 is still quite simple computationally - we could describe a small Turing machine which computes it - so a hypothesis involving&nbsp;3&uarr;&uarr;&uarr;3&nbsp;should not therefore get a large complexity penalty, if we're penalizing hypotheses by algorithmic complexity.</p>\n<p>I had originally intended the scenario of Pascal's Mugging to point up what seemed like a basic problem with combining conventional epistemology with conventional decision theory: &nbsp;Conventional epistemology says to penalize hypotheses by an exponential factor of computational complexity. &nbsp;This seems pretty strict in everyday life: &nbsp;\"What? for a mere 20 bits I am to be called a million times less probable?\" &nbsp;But for stranger hypotheses about things like Matrix Lords, the size of the hypothetical universe can blow up enormously faster than the exponential of its complexity. &nbsp;This would mean that all our decisions were dominated by tiny-seeming probabilities (on the order of 2<sup>-100</sup> and less) of scenarios where our lightest action affected 3&uarr;&uarr;4 people... which would <em>in turn</em>&nbsp;be dominated by even <em>more</em>&nbsp;remote probabilities of affecting 3&uarr;&uarr;5 people...</p>\n<p>This problem is worse than just giving five dollars to Pascal's Mugger - our expected utilities don't converge at all! &nbsp;Conventional epistemology tells us to sum over the predictions of all hypotheses weighted by their computational complexity and evidential fit. &nbsp;This works fine with <em>epistemic</em>&nbsp;probabilities&nbsp;and sensory&nbsp;predictions&nbsp;because no hypothesis can predict more than probability 1 or less than probability 0 for a sensory experience. &nbsp;As hypotheses get more and more complex, their contributed predictions have tinier and tinier weights, and the sum converges quickly. &nbsp;But decision theory tells us to calculate expected <em>utility</em>&nbsp;by summing the utility of each possible outcome, times the probability of that outcome conditional on our action. &nbsp;If hypothetical utilities&nbsp;can grow faster than hypothetical probability diminishes, the contribution of an average term in the series will keep increasing, and this sum will never converge - not if we try to do it the same way we got our epistemic predictions, by summing over complexity-weighted possibilities. &nbsp;(See also this similar-but-different <a href=\"http://arxiv.org/abs/0712.4318\">paper by Peter de Blanc</a>.)</p>\n<p>Unfortunately I failed to make it clear in my <a href=\"/lw/kd/pascals_mugging_tiny_probabilities_of_vast/\">original writeup</a> that this was where the problem came from, and that it was general to situations beyond the Mugger. &nbsp;<a href=\"http://www.nickbostrom.com/papers/pascal.pdf\">Nick Bostrom's writeup of Pascal's Mugging for a philosophy journal</a>&nbsp;used a Mugger offering a quintillion days of happiness, where a quintillion is merely 1,000,000,000,000,000,000 = 10<sup>18</sup>. &nbsp;It takes at least two exponentiations to outrun a singly-exponential complexity penalty. &nbsp;I would be willing to assign a probability of less than 1 in 10<sup>18</sup> to a random person being a Matrix Lord. &nbsp;You may not have to invoke 3&uarr;&uarr;&uarr;3 to cause problems, but you've got to use something like 10<sup>10<sup>100</sup></sup>&nbsp;- double exponentiation or better. &nbsp;Manipulating ordinary hypotheses about the ordinary physical universe taken at face value, which just contains 10<sup>80</sup> atoms within range of our telescopes, should not lead us into such difficulties.</p>\n<p>(And then the phrase \"Pascal's Mugging\" got&nbsp;<em>completely</em>&nbsp;bastardized to refer to an emotional feeling of being mugged that some people apparently get when a high-stakes charitable proposition is presented to them, <em>regardless of whether it's supposed to have a low probability.</em>&nbsp; This is enough to make me regret having ever invented the term \"Pascal's Mugging\" in the first place; and for further thoughts on this see&nbsp;<a href=\"/lw/z0/the_pascals_wager_fallacy_fallacy/\">The Pascal's Wager Fallacy Fallacy</a>&nbsp;(just because the stakes are high does not mean the probabilities are low, and Pascal's Wager is fallacious because of the low probability, not the high stakes!) and&nbsp;<a href=\"/lw/h8m/being_halfrational_about_pascals_wager_is_even/\">Being Half-Rational About Pascal's Wager Is Even Worse</a>. &nbsp;Again, when dealing with issues the mere size of the apparent universe, on the order of 10<sup>80</sup>&nbsp;- for <em>small</em>&nbsp;large numbers&nbsp;- we do <em>not</em>&nbsp;run into the sort of decision-theoretic problems I originally meant to single out by the concept of \"Pascal's Mugging\". &nbsp;My rough intuitive stance on x-risk charity is that if you are one of the tiny fraction of all sentient beings who happened to be born here on Earth before the intelligence explosion, when the existence of the whole vast intergalactic future depends on what we do now, you should expect to find yourself surrounded by a <em>smorgasbord&nbsp;</em>of opportunities to affect small large numbers of sentient beings. &nbsp;There is then no reason to worry about tiny probabilities of having a large impact when we can expect to find medium-sized opportunities of having a large impact, so long as we restrict ourselves to impacts no larger than the size of the known universe.)</p>\n<p>One proposal which has been floated for dealing with Pascal's Mugger in the decision-theoretic sense is to penalize hypotheses that let you affect a large number of people, in proportion to the number of people affected - what we could call perhaps a \"leverage penalty\" instead of a \"complexity penalty\".</p>\n<p>Unfortunately this potentially leads us into a different problem, that of <em>Pascal's Muggle.</em></p>\n<p>Suppose a poorly-dressed street person asks you for five dollars in exchange for doing a googolplex's worth of good using his Matrix Lord powers.</p>\n<p>\"Well,\" you reply, \"I think it very improbable that I would be able to affect so many people through my own, personal actions - who am I to have such a great impact upon events? &nbsp;Indeed, I think the probability is somewhere around one over googolplex, maybe a bit less. &nbsp;So no, I won't pay five dollars - it is unthinkably improbable that I could do so much good!\"</p>\n<p>\"I see,\" says the Mugger.</p>\n<p>A wind begins to blow about the alley, whipping the Mugger's loose clothes about him as they shift from ill-fitting shirt and jeans into robes of infinite blackness, within whose depths tiny galaxies and stranger things seem to twinkle. &nbsp;In the sky above, a gap edged by blue fire opens with a horrendous tearing sound - you can hear people on the nearby street yelling in sudden shock and terror, implying that they can see it too - and displays the image of the Mugger himself, wearing the same robes that now adorn his body, seated before a keyboard and a monitor.</p>\n<p>\"That's not actually me,\" the Mugger says, \"just a conceptual representation, but I don't want to drive you insane. &nbsp;Now give me those five dollars, and I'll save a googolplex lives, just as promised. &nbsp;It's easy enough for me, given the computing power my home universe offers. &nbsp;As for why I'm doing this, there's an ancient debate in philosophy among my people - something about how we ought to sum our expected utilities - and I mean to use the video of this event to make a point at the next decision theory conference I attend. &nbsp; Now will you give me the five dollars, or not?\"</p>\n<p>\"Mm... no,\" you reply.</p>\n<p>\"<em>No?</em>\" says the Mugger. &nbsp;\"I understood earlier when you didn't want to give a random street person five dollars based on a wild story with no evidence behind it. &nbsp;But now I've offered you evidence.\"</p>\n<p>\"Unfortunately, you haven't offered me <em>enough</em>&nbsp;evidence,\" you explain.</p>\n<p>\"Really?\" says the Mugger. &nbsp;\"I've opened up a fiery portal in the sky, and that's not enough to persuade you? &nbsp;What do I have to do, then? &nbsp;Rearrange the planets in your solar system, and wait for the observatories to confirm the fact? &nbsp;I suppose I could also explain the true laws of physics in the higher universe in more detail, and let you play around a bit with the computer program that encodes all the universes containing the googolplex people I would save if you gave me the five dollars -\"</p>\n<p>\"Sorry,\" you say, shaking your head firmly, \"there's just no <em>way</em>&nbsp;you can convince me that I'm in a position to affect a googolplex people, because the prior probability of that is one over googolplex. &nbsp;If you wanted to convince me of some fact of merely 2<sup>-100&nbsp;</sup>prior probability, a mere decillion to one - like that a coin would come up heads and tails in some particular pattern of a hundred coinflips - then you could just show me 100 bits of evidence, which is within easy reach of my brain's sensory bandwidth. &nbsp;I mean, you could just flip the coin a hundred times, and my eyes, which send my brain a hundred megabits a second or so - though that gets processed down to one megabit or so by the time it goes through the lateral geniculate nucleus - would easily give me enough data to conclude that this decillion-to-one possibility was true. &nbsp;But to conclude something whose prior probability is on the order of one over googolplex, I need on the order of a googol bits of evidence, and you can't present me with a sensory experience containing a googol bits. &nbsp;Indeed, you can't <em>ever</em>&nbsp;present a mortal like me with evidence that has a likelihood ratio of a googolplex to one - evidence I'm a googolplex times more likely to encounter if the hypothesis is true, than if it's false - because the chance of all my neurons spontaneously rearranging themselves to fake the same evidence would always be higher than one over googolplex. &nbsp;You know the old saying about how once you assign something probability one, or probability zero, you can never change your mind regardless of what evidence you see? &nbsp;Well, odds of a googolplex to one, or one to a googolplex, work pretty much the same way.\"</p>\n<p>\"So no matter what evidence I show you,\" the Mugger says - as the blue fire goes on crackling in the torn sky above, and screams and desperate prayers continue from the street beyond - \"you can't&nbsp;ever notice that you're in a position to help a googolplex people.\"</p>\n<p>\"Right!\" you say. &nbsp;\"I can believe that you're a Matrix Lord. &nbsp;I mean, I'm not a <em>total</em>&nbsp;Muggle, I'm psychologically capable of responding in <em>some</em>&nbsp;fashion to that giant hole in the sky. &nbsp;But it's just completely forbidden for me to assign any significant probability whatsoever that you will actually save a googolplex people after I give you five dollars. &nbsp;You're lying, and I am absolutely, absolutely, absolutely confident of that.\"</p>\n<p>\"So you weren't <em>just</em>&nbsp;invoking the leverage penalty as a plausible-sounding way of getting out of paying me the five dollars earlier,\" the Mugger says thoughtfully. &nbsp;\"I mean, I'd understand if that was just a rationalization of your discomfort at forking over five dollars for what seemed like a tiny probability, when I hadn't done my duty to present you with a corresponding amount of evidence before demanding payment. &nbsp;But you... you're acting like an AI would if it was actually programmed with a leverage penalty on hypotheses!\"</p>\n<p>\"Exactly,\" you say. &nbsp;\"I'm forbidden <em>a priori</em>&nbsp;to believe I can&nbsp;ever do that much good.\"</p>\n<p>\"Why?\" the Mugger says curiously. &nbsp;\"I mean, all I have to do is press this button here and a googolplex lives will be saved.\" &nbsp;The figure within the blazing portal above points to a green button on the console before it.</p>\n<p>\"Like I said,\" you explain again, \"the prior probability is just too infinitesimal for the massive evidence you're showing me to overcome it -\"</p>\n<p>The Mugger shrugs, and vanishes in a puff of purple mist.</p>\n<p>The portal in the sky above closes, taking with the console and the green button.</p>\n<p>(The screams go on from the street outside.)</p>\n<p>A few days later, you're sitting in your office at the physics institute where you work, when one of your colleagues bursts in through your door, seeming highly excited. &nbsp;\"I've got it!\" she cries. &nbsp;\"I've figured out that whole dark energy thing! &nbsp;Look, these simple equations retrodict it exactly, there's no way that could be a coincidence!\"</p>\n<p>At first you're also excited, but as you pore over the equations, your face configures itself into a frown. &nbsp;\"No...\" you say slowly. &nbsp;\"These equations may look extremely simple so far as computational complexity goes - and they do exactly fit the petabytes of evidence our telescopes have gathered so far - but I'm afraid they're far too improbable to ever believe.\"</p>\n<p>\"What?\" she says. &nbsp;\"Why?\"</p>\n<p>\"Well,\" you say reasonably, \"if these equations are actually true, then our descendants will be able to exploit dark energy to do computations, and according to my back-of-the-envelope calculations here, we'd be able to create around a googolplex people that way. &nbsp;But that would mean that we, here on Earth, are in a position to affect a googolplex people - since, if we blow ourselves up via a nanotechnological war or <em>(cough) </em>make certain&nbsp;other errors, those googolplex people will never come into existence. &nbsp;The prior probability of us being in a position to impact a googolplex people is on the order of one over googolplex, so your equations must be wrong.\"</p>\n<p>\"Hmm...\" she says. &nbsp;\"I hadn't thought of that. &nbsp;But what if these equations are right, and yet somehow, everything I do is exactly balanced, down to the googolth decimal point or so, with respect to how it impacts the chance of modern-day Earth participating in a chain of events that leads to creating an intergalactic civilization?\"</p>\n<p>\"How would <em>that</em>&nbsp;work?\" you say. &nbsp;\"There's only seven billion people on today's Earth - there's probably been only a hundred billion people who ever existed total, or will exist before we go through the intelligence explosion or whatever - so even before analyzing your exact position, it seems like your leverage on future affairs couldn't reasonably be less than a one in ten trillion part of the future or so.\"</p>\n<p>\"But then given this physical theory which seems obviously true, my acts might imply expected utility differentials on the order of 10<sup>10<sup>100</sup></sup><sup>-13</sup>,\" she explains, \"and I'm not allowed to believe that no matter how much evidence you show me.\"</p>\n<hr />\n<p>This problem may not be as bad as it looks; with some further reasoning, the leverage penalty may lead to more sensible behavior than depicted above.</p>\n<p>Robin Hanson has suggested that the logic of a leverage penalty should stem from the general improbability of individuals being in a <em>unique</em> position to affect many others (which is why I called it a leverage penalty). &nbsp;At most 10 out of 3&uarr;&uarr;&uarr;3 people can ever be in a position to be \"solely responsible\" for the fate of 3&uarr;&uarr;&uarr;3 people if \"solely responsible\" is taken to imply a causal chain that goes through no more than 10 people's decisions; i.e. at most 10 people can ever be solely<sub>10</sub>&nbsp;responsible for any given event. &nbsp;Or if \"fate\" is taken to be a sufficiently ultimate fate that there's at most 10 other decisions of similar magnitude that could cumulate to determine someone's outcome utility to within &plusmn;50%, then any given person could have their fate<sub>10</sub>&nbsp;determined on at most 10 occasions. &nbsp;We would surely agree, while assigning priors at the dawn of reasoning, that an agent randomly selected from the pool of all agents in Reality has at most a 100/X chance of being able to be solely<sub>10</sub>&nbsp;responsible for the fate<sub>10</sub>&nbsp;of X people. &nbsp;Any reasoning we do about universes, their complexity, sensory experiences, and so on, should maintain this net balance. &nbsp;You can even strip out the part about agents and carry out the reasoning on pure causal nodes; the chance of a randomly selected causal node being in a unique<sub>100</sub> position on a causal graph with respect to 3&uarr;&uarr;&uarr;3 other nodes ought to be at most 100/3&uarr;&uarr;&uarr;3 for finite causal graphs. &nbsp;(As for infinite causal graphs, well, if problems arise <em>only</em>&nbsp;when introducing infinity, maybe it's infinity that has the problem.)</p>\n<p>Suppose we apply the Hansonian leverage penalty to the face-value scenario of our own universe, in which there are apparently no aliens and the galaxies we can reach in the future contain on the order of 10<sup>80</sup> atoms; which, if the <a href=\"http://intelligence.org/files/IE-EI.pdf\">intelligence explosion</a> goes well, might be transformed into on the very loose order of... let's ignore a lot of intermediate calculations and just call it the equivalent of 10<sup>80</sup> centuries of life. &nbsp;(The neurons in your brain perform lots of operations; you don't get only one computing operation per element, because you're powered by the Sun over time. &nbsp;The universe contains a lot more negentropy than just 10<sup>80</sup> bits due to things like the gravitational potential energy that can be extracted from mass. &nbsp;Plus we should take into account reversible computing. &nbsp;But of course it also takes more than one computing operation to implement a century of life. &nbsp;So I'm just going to xerox the number 10<sup>80</sup> for use in these calculations, since it's not supposed to be the main focus.)</p>\n<p>Wouldn't it be terribly odd to find ourselves - where by 'ourselves' I mean the hundred billion humans who have ever lived on Earth, for no more than a century or so apiece - solely<sub>100,000,000,000</sub> responsible for the fate<sub>10</sub> of around 10<sup>80</sup> units of life? &nbsp;Isn't the prior probability of this somewhere around 10<sup>-68</sup>?</p>\n<p>Yes, according to the leverage penalty. &nbsp;But a prior probability of 10<sup>-68</sup>&nbsp;is not an insurmountable epistemological barrier. &nbsp;If you're <a href=\"/r/discussion/lw/h8m/being_halfrational_about_pascals_wager_is_even/\">taking things at face value</a>, 10<sup>-68</sup> is just 226 bits of evidence or thereabouts, and your eyes are sending you a megabit per second. &nbsp;Becoming convinced that <em>you,</em>&nbsp;yes <em>you</em>&nbsp;are an Earthling is epistemically doable; you just need to see a stream of sensory experiences which is 10<sup>68</sup>&nbsp;times more probable if you are an Earthling than if you are someone else. &nbsp;If we take everything at face value, then there could be around 10<sup>80</sup> centuries of life over the history of the universe, and only 10<sup>11</sup> of those centuries will be lived by creatures who discover themselves occupying organic bodies. &nbsp;Taking everything at face value, the sensory experiences of your life are unique to Earthlings and should immediately convince you that you're an Earthling - just looking around the room you occupy will provide you with sensory experiences that plausibly belong to only 10<sup>11</sup> out of 10<sup>80</sup> life-centuries.</p>\n<p>If we <em>don't</em>&nbsp;take everything at face value, then there might be such things as ancestor simulations, and it might be that your experience of looking around the room is something that happens in 10<sup>20</sup> ancestor simulations for every time that it happens in 'base level' reality. &nbsp;In this case your probable leverage on the future is diluted (though it may be large even post-dilution). &nbsp;But this is not something that the Hansonian leverage penalty <em>forces </em>you to believe - not when the putative stakes are still as small as 10<sup>80</sup>. &nbsp;Conceptually, the Hansonian leverage penalty doesn't interact much with the Simulation Hypothesis (SH) at all. &nbsp;If you don't believe SH, then you think that the experiences of creatures like yours are rare in the universe and hence present strong, convincing evidence for you occupying the leverage-privileged position of an Earthling - much stronger evidence than its prior improbability. &nbsp;(There's some separate anthropic issues here about whether or not this is <em>itself</em>&nbsp;evidence for SH,&nbsp;but I don't think that question is intrinsic to leverage penalties per se.)</p>\n<p>A key point here is that even if you accept a Hanson-style leverage penalty, it doesn't have to manifest as an inescapable commandment of modesty. &nbsp;You need not refuse to believe (in your deep and irrevocable humility) that you could be someone as special as an Ancient Earthling. &nbsp;Even if Earthlings matter in the universe - even if we occupy a unique position to affect the future of galaxies - it is still possible to encounter pretty convincing evidence that you're an Earthling. &nbsp;Universes the size of 10<sup>80</sup> do not pose problems to conventional decision-theoretic reasoning, or to conventional epistemology.</p>\n<p>Things play out similarly if - still taking everything at face value - you're wondering about the chance that you could be special even for an Earthling, because you might be one of say 10<sup>4</sup> people in the history of the universe who contribute a major amount to an x-risk reduction project which ends up actually saving the galaxies. &nbsp;The vast majority of the improbability here is just in being an Earthling in the first place! &nbsp;Thus most of the clever arguments for not taking this high-impact possibility at face value would also tell you not to take being an Earthling at face value, since Earthlings as a whole are much more unique within the total temporal history of the universe than you are supposing yourself to be unique among Earthlings. &nbsp;But given &not;SH, the prior improbability of being an Earthling can be overcome by a few megabits of sensory experience from looking around the room and querying your memories - it's not like 10<sup>80</sup> is enough future beings that the number of agents randomly hallucinating similar experiences outweighs the number of real Earthlings. &nbsp;Similarly, if you don't think lots of Earthlings are hallucinating the experience of going to a donation page and clicking on the Paypal button for an x-risk charity, that sensory experience can easily serve to distinguish you as one of 10<sup>4</sup> people donating to an x-risk philanthropy.</p>\n<p>Yes, there are various clever-sounding lines of argument which involve <em>not</em>&nbsp;taking things at face value - \"Ah, but maybe you should consider yourself as an indistinguishable part of this here large reference class of deluded people who think they're important.\" &nbsp;Which I consider to be a bad idea because it renders you a permanent Muggle by putting you into an inescapable reference class of self-deluded people and then dismissing all your further thoughts as insufficient evidence because you <em>could</em>&nbsp;just be deluding yourself further about whether these are good arguments. &nbsp;Nor do I believe the world can only be saved by good people who are incapable of distinguishing themselves from a large class of crackpots, all of whom have no choice but to continue based on the tiny probability that they are not crackpots. &nbsp;(For more on this see&nbsp;<a href=\"/lw/h8m/being_halfrational_about_pascals_wager_is_even/\">Being Half-Rational About Pascal's Wager Is Even Worse</a>.) &nbsp;In this case you are a Pascal's Muggle not because you've explicitly assigned a probability like one over googolplex, but because you took an improbability like 10<sup>-6</sup>&nbsp;at unquestioning face value and then cleverly questioned all the evidence which could've overcome that prior improbability, and so, in practice, you can never climb out of the epistemological sinkhole. &nbsp;<a href=\"http://slatestarcodex.com/2013/04/13/proving-too-much/\">By the same token</a>, you should conclude that you are just self-deluded about being an Earthling since real Earthlings are so rare and privileged in their leverage.</p>\n<p>In general, leverage penalties don't translate into&nbsp;advice about modesty or that you're just deluding yourself - they just say that to be rationally coherent, your picture of the universe has to imply that your sensory experiences are at least as rare as the corresponding magnitude of your leverage.</p>\n<p>Which brings us back to Pascal's Mugger, in the original alleyway version. &nbsp;The Hansonian leverage penalty seems to imply that to be coherent,&nbsp;<em>either</em>&nbsp;you believe that your sensory experiences are <em>really actually</em>&nbsp;1 in a googolplex - that only 1 in a googolplex beings experiences what you're experiencing - or else you really <em>can't </em>take the situation at face value.</p>\n<p>Suppose the Mugger is telling the truth, and a googolplex other people are being simulated. &nbsp;Then there are at least a googolplex people in the universe. &nbsp;Perhaps some of them are hallucinating a situation similar to this one by sheer chance? &nbsp;Rather than telling you flatly that you can't have a large impact, the Hansonian leverage penalty implies a coherence requirement on how uniquely you think your sensory experiences identify the position you believe yourself to occupy. &nbsp;When it comes to believing you're one of 10<sup>11</sup> Earthlings who can impact 10<sup>80</sup> other life-centuries, you need to think your sensory experiences are unique to Earthlings - identify Earthlings with a likelihood ratio on the order of 10<sup>69</sup>. &nbsp;This is quite achievable, if we <a href=\"/lw/h8m/being_halfrational_about_pascals_wager_is_even/\">take the evidence at face value</a>. &nbsp;But when it comes to improbability on the order of 1/3&uarr;&uarr;&uarr;3, the prior improbability <em>is </em>inescapable - your sensory experiences <em>can't </em>possibly be that unique - which is assumed to be appropriate because almost-everyone who ever believes they'll be in a position to help 3&uarr;&uarr;&uarr;3 people <em>will&nbsp;in fact</em> be hallucinating. &nbsp;Boltzmann brains should be much more common than people in a unique position to affect 3&uarr;&uarr;&uarr;3 others, at least if the causal graphs are finite.</p>\n<p>Furthermore - although I didn't realize this part until recently - applying Bayesian updates from that starting point may partially avert the Pascal's Muggle effect:</p>\n<p>Mugger: &nbsp;\"Give me five dollars, and I'll save&nbsp;3&uarr;&uarr;&uarr;3&nbsp;lives using my Matrix Powers.\"</p>\n<p>You: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"Why not? &nbsp;It's a really large impact.\"</p>\n<p>You: &nbsp;\"Yes, and I assign a probability on the order of 1 in 3&uarr;&uarr;&uarr;3 that I would be in a unique position to affect 3&uarr;&uarr;&uarr;3 people.\"</p>\n<p>Mugger: &nbsp;\"Oh, is that really the probability that you assign? &nbsp;Behold!\"</p>\n<p><em>(A gap opens in the sky, edged with blue fire.)</em></p>\n<p>Mugger: &nbsp;\"Now what do you think, eh?\"</p>\n<p>You: &nbsp;\"Well... I can't actually say this observation has a likelihood ratio of 3&uarr;&uarr;&uarr;3 to 1. &nbsp;No stream of evidence that can enter a human brain over the course of a century is ever going to have a likelihood ratio larger than, say, 10<sup>10<sup>26</sup></sup> to 1 at the <em>absurdly most, </em>assuming one megabit per second of sensory data, for a century, each bit of which has at least a 1-in-a-trillion error probability. &nbsp;I'd probably start to be dominated by Boltzmann brains or other exotic minds well before then.\"</p>\n<p>Mugger: &nbsp;\"So you're not convinced.\"</p>\n<p>You: &nbsp;\"Indeed not. &nbsp;The probability that you're telling the truth is so tiny that God couldn't find it with an electron microscope. &nbsp;Here's the five dollars.\"</p>\n<p>Mugger: &nbsp;\"Done! &nbsp;You've saved 3&uarr;&uarr;&uarr;3 lives! &nbsp;Congratulations, you're never going to top that, your peak life accomplishment will now always lie in your past. &nbsp;But why'd you give me the five dollars if you think I'm lying?\"</p>\n<p>You: &nbsp;\"Well, because the evidence you <em>did</em>&nbsp;present me with had a likelihood ratio of at least a billion to one - I would've assigned less than 10<sup>-9</sup> prior probability of seeing this when I woke up this morning - so in accordance with Bayes's Theorem I promoted the probability from 1/3&uarr;&uarr;&uarr;3 to at least 10<sup>9</sup>/3&uarr;&uarr;&uarr;3, which when multiplied by an impact of&nbsp;3&uarr;&uarr;&uarr;3, yields an expected value of at least a billion lives saved for giving you five dollars.\"</p>\n<hr />\n<p>I confess that I find this line of reasoning a bit suspicious - it seems overly clever. &nbsp;But on the level of intuitive virtues of rationality, it does seem less stupid than the original Pascal's Muggle; this muggee is at least <em>behaviorally </em>reacting to the evidence. &nbsp;In fact, they're reacting in a way exactly&nbsp;proportional to the evidence - they would've assigned the same net importance to handing over the five dollars if the Mugger had offered 3&uarr;&uarr;&uarr;4 lives, so long as the strength of the evidence seemed the same.</p>\n<p>(Anyone who tries to apply the lessons here to actual x-risk reduction charities (which I think is probably a bad idea), keep in mind that the vast majority of the improbable-position-of-leverage in any x-risk reduction effort comes from being an Earthling in a position to affect the future of a hundred billion galaxies, and that sensory evidence for being an Earthling is what gives you most of your belief that your actions can have an outsized impact.)</p>\n<p>So why not just run with this - why not just declare the decision-theoretic problem resolved, if we have a rule that seems to give reasonable behavioral answers in practice? &nbsp;Why not just go ahead and program that rule into an AI?</p>\n<p>Well... I still feel a bit nervous about the idea that Pascal's Muggee, after the sky splits open, is handing over five dollars while claiming to assign probability on the order of 10<sup>9</sup>/3&uarr;&uarr;&uarr;3 that it's doing any good.</p>\n<p>I think that my own reaction in a similar situation would be along these lines instead:</p>\n<hr />\n<p>Mugger: &nbsp;\"Give me five dollars, and I'll save&nbsp;3&uarr;&uarr;&uarr;3&nbsp;lives using my Matrix Powers.\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"So then, you think the probability I'm telling the truth is on the order of 1/3&uarr;&uarr;&uarr;3?\"</p>\n<p>Me: &nbsp;\"Yeah... that probably <em>has </em>to follow. &nbsp;I don't see any way around that revealed belief, given that I'm not actually giving you the five dollars. &nbsp;I've heard some people try to claim silly things like, the probability that you're telling the truth is counterbalanced by the probability that you'll kill 3&uarr;&uarr;&uarr;3 people instead, or something else with a conveniently equal and opposite utility. &nbsp;But there's no way that things would balance out <em>exactly</em> in practice, if there was no <em>a priori</em>&nbsp;mathematical requirement that they balance. &nbsp;Even if the prior probability of your saving 3&uarr;&uarr;&uarr;3 people and killing 3&uarr;&uarr;&uarr;3 people, conditional on my giving you five dollars, <em>exactly </em>balanced down to the log(3&uarr;&uarr;&uarr;3) decimal place, the likelihood ratio for your telling me&nbsp;that you would \"save\" 3&uarr;&uarr;&uarr;3 people would not be exactly 1:1 for the two hypotheses down to the log(3&uarr;&uarr;&uarr;3) decimal place. &nbsp;So if I assigned probabilities much greater than 1/3&uarr;&uarr;&uarr;3 to your doing something that affected 3&uarr;&uarr;&uarr;3 people, my actions would be overwhelmingly dominated by even a tiny difference in likelihood ratio elevating the probability that you saved 3&uarr;&uarr;&uarr;3 people over the probability that you did something bad to them. &nbsp;The only way this hypothesis can't dominate my actions - really, the only way my expected utility sums can converge at all - is if I assign probability on the order of 1/3&uarr;&uarr;&uarr;3 or less. &nbsp;I don't see any way of escaping that part.\"</p>\n<p>Mugger: &nbsp;\"But can you, in your mortal uncertainty, truly assign a probability as low as 1 in 3&uarr;&uarr;&uarr;3 to any proposition whatever? &nbsp;Can you truly believe, with your error-prone neural brain, that you could make 3&uarr;&uarr;&uarr;3 statements <em>of any kind&nbsp;</em>one after another, and be wrong, on average, about once?\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"So give me five dollars!\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"Why not?\"</p>\n<p>Me: &nbsp;\"Because even though I, in my mortal uncertainty, will eventually be wrong about all sorts of things if I make enough statements one after another, this fact can't be used to increase the probability of arbitrary statements beyond what my prior says they should be, because then my prior would sum to more than 1. &nbsp;There must be some kind of required condition for taking a hypothesis seriously enough to worry that I might be overconfident about it -\"</p>\n<p>Mugger: &nbsp;\"Then behold!\"</p>\n<p><em>(A gap opens in the sky, edged with blue fire.)</em></p>\n<p>Mugger: &nbsp;\"Now what do you think, eh?\"</p>\n<p>Me <em>(staring up at the sky):</em>&nbsp; \"...whoa.\" &nbsp;<em>(Pause.)</em>&nbsp; \"You turned into a cat.\"</p>\n<p>Mugger: &nbsp;\"What?\"</p>\n<p>Me: &nbsp;\"Private joke. &nbsp;Okay, I think I'm going to have to rethink a <em>lot </em>of things. &nbsp;But if you want to tell me about how I was wrong to assign a prior probability on the order of 1/3&uarr;&uarr;&uarr;3 to your scenario, I will shut up and listen very carefully to what you have to say about it. &nbsp;Oh, and here's the five dollars, can I pay an extra twenty and make some other requests?\"</p>\n<p><em>(The thought bubble pops, and we return to two people standing in an alley, the sky above perfectly normal.)</em></p>\n<p>Mugger: &nbsp;\"Now, in this scenario we've just imagined, you were taking my case seriously, right? &nbsp;But the evidence there couldn't have had a likelihood ratio of more than 10<sup>10<sup>26</sup></sup>&nbsp;to 1, and probably much less. &nbsp;So by the method of imaginary updates, you must assign probability at least 10<sup>-10<sup>26</sup></sup>&nbsp;to my scenario, which when multiplied by a benefit on the order of 3&uarr;&uarr;&uarr;3, yields an unimaginable bonanza in exchange for just five dollars -\"</p>\n<p>Me: &nbsp;\"Nope.\"</p>\n<p>Mugger: &nbsp;\"How can you possibly say that? &nbsp;You're not being logically coherent!\"</p>\n<p>Me: &nbsp;\"I agree that I'm not being logically coherent, but I think that's acceptable in this case.\"</p>\n<p>Mugger: &nbsp;\"This ought to be good. &nbsp;Since when are rationalists allowed to deliberately be logically incoherent?\"</p>\n<p>Me: &nbsp;\"Since we don't have infinite computing power -\"</p>\n<p>Mugger: &nbsp;\"That sounds like a fully general excuse if I ever heard one.\"</p>\n<p>Me: &nbsp;\"No, this is a&nbsp;<em>specific</em>&nbsp;consequence of bounded computing power. &nbsp;Let me start with a simpler example. &nbsp;Suppose I believe in a set of mathematical axioms. &nbsp;Since I don't have infinite computing power, I won't be able to know all the deductive consequences of those axioms. &nbsp;And <em>that</em>&nbsp;means I will necessarily fall prey to the conjunction fallacy, in the sense that you'll present me with a theorem X that is a deductive consequence of my axioms, but which I don't know to be a deductive consequence of my axioms, and you'll ask me to assign a probability to X, and I'll assign it 50% probability or something. &nbsp;Then you present me with a brilliant lemma Y, which clearly seems like a likely consequence of my mathematical axioms, and which also seems to imply X - once I see Y, the connection from my axioms to X, via Y, becomes obvious. &nbsp;So I assign P(X&amp;Y) = 90%, or something like that. &nbsp;Well, that's the conjunction fallacy - I assigned P(X&amp;Y) &gt; P(X). &nbsp;The thing is, if you <em>then</em>&nbsp;ask me P(X), after I've seen Y, I'll reply that P(X) is 91% or at any rate something higher than P(X&amp;Y). &nbsp;I'll have changed my mind about what my prior beliefs logically imply, because I'm not logically omniscient, even if that looks like assigning probabilities <em>over time</em> which are incoherent in the Bayesian sense.\"</p>\n<p>Mugger: &nbsp;\"And how does this work out to my not getting five dollars?\"</p>\n<p>Me: &nbsp;\"In the scenario you're asking me to imagine, you present me with evidence which I currently think Just Plain Shouldn't Happen. &nbsp;And if that actually <em>does</em>&nbsp;happen,&nbsp;the sensible way for me to react is by questioning my prior assumptions and the reasoning which led me assign such low probability. &nbsp;One way that I handle my lack of logical omniscience - my finite, error-prone reasoning capabilities - is by being willing to assign infinitesimal probabilities to non-privileged hypotheses so that my prior over all possibilities can sum to 1. &nbsp;But if I actually see strong evidence for something I previously thought was super-improbable, I don't just do a Bayesian update, I should also question whether I was right to assign such a tiny probability in the first place - whether it was really as complex, or unnatural, as I thought. &nbsp;In real life, you are not ever supposed to have a prior improbability of 10<sup>-100</sup>&nbsp;for some fact distinguished enough to be written down in advance, and yet encounter strong evidence, say 10<sup>10</sup> to 1, that the thing has actually happened. &nbsp;If something like that happens, you don't do a Bayesian update to a posterior of 10<sup>-90</sup>. &nbsp;Instead you question both whether the evidence might be weaker than it seems, <em>and</em>&nbsp;whether your estimate of prior improbability might have been poorly calibrated, because rational agents who actually have well-calibrated priors should not encounter situations like that until they are ten billion days old. &nbsp;Now, this may mean that I end up doing some non-Bayesian updates: &nbsp;I say some hypothesis has a prior probability of a quadrillion to one, you show me evidence with a likelihood ratio of a billion to one, and I say 'Guess I was wrong about that quadrillion to one thing' rather than being a Muggle about it. &nbsp;And then I shut up and listen to what <em>you</em>&nbsp;have to say about how to estimate probabilities, because on my worldview, I wasn't <em>expecting</em>&nbsp;to see you turn into a cat.&nbsp; But for me to make a super-update like that - reflecting a posterior belief that I was logically incorrect about the prior probability - you have to really actually show me the evidence, you can't just ask me to imagine it. &nbsp;This is something that only logically incoherent agents ever say, but that's all right because I'm not logically omniscient.\"</p>\n<hr />\n<p>At some point, we're going to have to build some sort of actual prior into, you know, some sort of actual self-improving AI.</p>\n<p>(Scary thought, right?)</p>\n<p>So far as I can presently see, the logic requiring some sort of leverage penalty - not just so that we don't pay $5 to Pascal's Mugger, but also so that our expected utility sums converge at all - seems clear enough that I can't yet see a good alternative to it (feel welcome to suggest one), and Robin Hanson's rationale is by far the best I've heard.</p>\n<p>In fact, what we actually need is more like a combined leverage-and-complexity penalty, to avoid scenarios like this:</p>\n<hr />\n<p>Mugger: &nbsp;\"Give me $5 and I'll save 3&uarr;&uarr;&uarr;3 people.\"</p>\n<p>You: &nbsp;\"I assign probability exactly 1/3&uarr;&uarr;&uarr;3 to that.\"</p>\n<p>Mugger: &nbsp;\"So that's one life saved for $5, on average. &nbsp;That's a pretty good bargain, right?\"</p>\n<p>You: &nbsp;\"Not by comparison with x-risk reduction charities. &nbsp;But I also like to do good on a smaller scale now and then. &nbsp;How about a penny? &nbsp;Would you be willing to save 3&uarr;&uarr;&uarr;3/500 lives for a penny?\"</p>\n<p>Mugger: &nbsp;\"Eh, fine.\"</p>\n<p>You: &nbsp;\"Well, the probability of that is 500/3&uarr;&uarr;&uarr;3, so here's a penny!\" &nbsp;<em>(Goes on way, whistling cheerfully.)</em></p>\n<hr />\n<p>Adding a complexity penalty <em>and</em>&nbsp;a leverage penalty is necessary, not just to avert this exact scenario, but so that we don't get an infinite expected utility sum over a 1/3&uarr;&uarr;&uarr;3 probability of saving 3&uarr;&uarr;&uarr;3 lives, 1/(3&uarr;&uarr;&uarr;3 + 1) probability of saving 3&uarr;&uarr;&uarr;3 + 1 lives, and so on. &nbsp;If we combine&nbsp;the standard complexity penalty with a leverage penalty, the whole thing should converge.</p>\n<p>Probability penalties are epistemic features - they affect what we believe, not just what we do. &nbsp;Maps, ideally, correspond to territories. &nbsp;Is there any territory that this complexity+leverage penalty can correspond to - any state of a single reality which would make these the true frequencies? &nbsp;Or is it only interpretable as pure uncertainty over realities, with there being no single reality that could correspond to it? &nbsp;To put it another way, the complexity penalty and the leverage penalty seem unrelated, so perhaps they're mutually inconsistent; can we show that the union of these two theories has a model?</p>\n<p>As near as I can figure, the corresponding state of affairs to a complexity+leverage prior improbability would be a Tegmark Level IV multiverse in which each reality got an amount of magical-reality-fluid corresponding to the complexity of its program (1/2 to the power of its Kolmogorov complexity) and then this magical-reality-fluid had to be <em>divided</em>&nbsp;among all the causal elements within that universe - if you contain 3&uarr;&uarr;&uarr;3 causal nodes, then each node can only get 1/3&uarr;&uarr;&uarr;3 of the total realness of that universe.&nbsp;&nbsp;(As always, the term \"magical reality fluid\" reflects an attempt to demarcate a philosophical area where I feel quite confused, and try to use correspondingly blatantly wrong terminology so that I do not mistake my reasoning about my confusion for a solution.) &nbsp;This setup is not entirely implausible because the Born probabilities in our own universe look like they might behave like this sort of magical-reality-fluid - quantum amplitude flowing between configurations in a way that preserves the total amount of realness while dividing it between worlds - and perhaps every other part of the multiverse must necessarily work the same way for some reason. &nbsp;It seems worth noting that part of what's motivating this version of the 'territory' is that our sum over all real things, weighted by reality-fluid, can then converge. &nbsp;In other words, the reason why complexity+leverage works in decision theory is that the union of the two theories has a model in which the total multiverse contains an amount of reality-fluid that can sum to 1 rather than being infinite. &nbsp;(Though we need to suppose that either (a) only programs with a finite number of causal nodes exist, or (2) programs can divide finite reality-fluid among an infinite number of nodes via some measure that gives every experience-moment a well-defined relative amount of reality-fluid. &nbsp;Again see caveats about basic philosophical confusion - perhaps our map needs this property over its uncertainty but the territory doesn't have to work the same way, etcetera.)</p>\n<p>If an AI's overall architecture is also such as to enable it to carry out the \"You turned into a cat\" effect - where if the AI actually ends up with strong evidence for a scenario it assigned super-exponential improbability, the AI reconsiders its priors and the apparent strength of evidence rather than executing a blind Bayesian update, though this part is formally a tad underspecified - then at the moment I can't think of anything else to add in.</p>\n<p>In other words: &nbsp;This is my best current idea for how a prior, e.g. as used in an AI, could yield decision-theoretic convergence over explosively large possible worlds.</p>\n<p>However, I would still call this a semi-open FAI problem (edit: <a href=\"/lw/h8k/pascals_muggle_infinitesimal_priors_and_strong/#8xrk\">wide-open</a>) because it seems quite plausible that somebody is going to kick holes in the overall view I've just presented, or come up with a better solution, possibly within an hour of my posting this - the proposal is both recent and weak even by my standards. &nbsp;I'm also worried about whether it turns out to imply anything crazy on anthropic problems. &nbsp;Over to you, readers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 1, "HAFdXkW4YW4KRe2Gx": 1, "L3NcKBNTvQaFXwv9u": 1, "HNJiR8Jzafsv8cHrC": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ap4KfkHyxjYPDiqh2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 54, "baseScore": 70, "extendedScore": null, "score": 0.000172, "legacy": true, "legacyId": "22340", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 70, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 406, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["a5JAiTdytou3Jg749", "TQSb4wd6v5C3p6HX2", "ebiCeBHr7At8Yyq9R", "KDzXTWSTg8ArwbhRR", "3wYTFWY3LKQCnAptN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 16, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-05-08T00:43:17.403Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-08T04:51:43.947Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Sin of Underconfidence", "slug": "seq-rerun-the-sin-of-underconfidence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:27.492Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Bw9EW9nQhuyATtgrv/seq-rerun-the-sin-of-underconfidence", "pageUrlRelative": "/posts/Bw9EW9nQhuyATtgrv/seq-rerun-the-sin-of-underconfidence", "linkUrl": "https://www.lesswrong.com/posts/Bw9EW9nQhuyATtgrv/seq-rerun-the-sin-of-underconfidence", "postedAtFormatted": "Wednesday, May 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Sin%20of%20Underconfidence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Sin%20of%20Underconfidence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBw9EW9nQhuyATtgrv%2Fseq-rerun-the-sin-of-underconfidence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Sin%20of%20Underconfidence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBw9EW9nQhuyATtgrv%2Fseq-rerun-the-sin-of-underconfidence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBw9EW9nQhuyATtgrv%2Fseq-rerun-the-sin-of-underconfidence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 260, "htmlBody": "<p>Today's post, <a href=\"/lw/c3/the_sin_of_underconfidence/\">The Sin of Underconfidence</a> was originally published on 20 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When subjects know about a bias or are warned about a bias, overcorrection is not unheard of as an experimental result. That's what makes a lot of cognitive subtasks so troublesome - you know you're biased but you're not sure how much, and if you keep tweaking you may overcorrect. The danger of underconfidence (overcorrecting for overconfidence) is that you pass up opportunities on which you could have been successful; not challenging difficult enough problems; losing forward momentum and adopting defensive postures; refusing to put the hypothesis of your inability to the test; losing enough hope of triumph to try hard enough to win. You should ask yourself \"Does this way of thinking make me stronger, or weaker?\"</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/hdi/seq_rerun_my_way/\">My Way</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Bw9EW9nQhuyATtgrv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.1924640062932325e-06, "legacy": true, "legacyId": "22528", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pkFazhcTErMw7TFtT", "fGeHrNPwdd63jmeeE", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-08T20:37:32.096Z", "modifiedAt": null, "url": null, "title": "Justifiable Erroneous Scientific Pessimism", "slug": "justifiable-erroneous-scientific-pessimism", "viewCount": null, "lastCommentedAt": "2013-06-25T22:52:19.555Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HCCfKCrxxHoTCincF/justifiable-erroneous-scientific-pessimism", "pageUrlRelative": "/posts/HCCfKCrxxHoTCincF/justifiable-erroneous-scientific-pessimism", "linkUrl": "https://www.lesswrong.com/posts/HCCfKCrxxHoTCincF/justifiable-erroneous-scientific-pessimism", "postedAtFormatted": "Wednesday, May 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Justifiable%20Erroneous%20Scientific%20Pessimism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJustifiable%20Erroneous%20Scientific%20Pessimism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCCfKCrxxHoTCincF%2Fjustifiable-erroneous-scientific-pessimism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Justifiable%20Erroneous%20Scientific%20Pessimism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCCfKCrxxHoTCincF%2Fjustifiable-erroneous-scientific-pessimism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCCfKCrxxHoTCincF%2Fjustifiable-erroneous-scientific-pessimism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 409, "htmlBody": "<p>In an erratum to my previous post on Pascalian wagers, it has been plausibly argued to me that <em>all</em>&nbsp;the roads to nuclear weapons, including plutonium production from U-238, may have bottlenecked through the presence of significant amounts of Earthly U235 (apparently even the giant heap of unrefined uranium bricks in Chicago Pile 1 was, functionally, empty space with a scattering of U235 dust). &nbsp;If this is the case then Fermi's estimate of a \"ten percent\" probability of nuclear weapons may have actually been justifiable because nuclear weapons were almost impossible (at least without particle accelerators) - though it's not totally clear to me why \"10%\" instead of \"2%\" or \"50%\" but then I'm not Fermi.</p>\n<p>We're all familiar with examples of <em>correct</em>&nbsp;scientific skepticism, such as about Uri Geller and hydrino theory. &nbsp;We also know many famous examples of scientists just completely making up their <a href=\"http://www.foresight.org/news/negativeComments.html\">pessimism</a>, for example about the impossibility of human heavier-than-air flight. &nbsp;Before this occasion I could only think offhand of one other famous example of <em>erroneous </em>scientific pessimism that was <em>not</em>&nbsp;in defiance of the default extrapolation of existing models, namely Lord Kelvin's careful estimate from multiple sources that the Sun was around sixty million years of age. &nbsp;This was wrong, but because of new physics - though you could make a case that new physics might well be expected in this case - and there was some degree of contrary evidence from geology, as I understand it - and that's not exactly the same as technological skepticism - but still. &nbsp;Where there are sort of two, there may be more. &nbsp;Can anyone name a third example of <em>erroneous</em>&nbsp;scientific pessimism whose error was, to the same degree, not something a smarter scientist could've seen coming?</p>\n<p>I ask this with some degree of trepidation, since by most standards of reasoning essentially anything is \"justifiable\" if you try hard enough to find excuses and then not question them further, so I'll phrase it more carefully this way: &nbsp;I am looking for a case of erroneous scientific pessimism, preferably about technological impossibility or extreme difficulty, where it seems clear that the inverse case for possibility would've been weaker if carried out strictly with contemporary knowledge, after exploring points and counterpoints. &nbsp;(So that relaxed standards for \"justifiability\" will just produce even more justifiable cases for the technological possibility.) &nbsp;We probably should also not accept as \"erroneous\" any prediction of technological impossibility where it required more than, say, seventy years to get the technology.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HCCfKCrxxHoTCincF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 26, "extendedScore": null, "score": 1.193142703150647e-06, "legacy": true, "legacyId": "22533", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-05-08T20:37:32.096Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-08T21:40:34.745Z", "modifiedAt": null, "url": null, "title": "How should negative externalities be handled?  (Warning: politics)", "slug": "how-should-negative-externalities-be-handled-warning", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:34.506Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nigerweiss", "createdAt": "2012-11-20T18:28:27.983Z", "isAdmin": false, "displayName": "nigerweiss"}, "userId": "DYPo3FWGnAX3mwp2Y", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hacisxJX7fAQhcSdu/how-should-negative-externalities-be-handled-warning", "pageUrlRelative": "/posts/hacisxJX7fAQhcSdu/how-should-negative-externalities-be-handled-warning", "linkUrl": "https://www.lesswrong.com/posts/hacisxJX7fAQhcSdu/how-should-negative-externalities-be-handled-warning", "postedAtFormatted": "Wednesday, May 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20should%20negative%20externalities%20be%20handled%3F%20%20(Warning%3A%20politics)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20should%20negative%20externalities%20be%20handled%3F%20%20(Warning%3A%20politics)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhacisxJX7fAQhcSdu%2Fhow-should-negative-externalities-be-handled-warning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20should%20negative%20externalities%20be%20handled%3F%20%20(Warning%3A%20politics)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhacisxJX7fAQhcSdu%2Fhow-should-negative-externalities-be-handled-warning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhacisxJX7fAQhcSdu%2Fhow-should-negative-externalities-be-handled-warning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 851, "htmlBody": "<p><em>Politics ahead! &nbsp;Read at your own risk, mind killers, etc. &nbsp;Let all caveats be well and thoroughly emptored.</em><br /><br />It seems reasonably clear to me that, from a computational perspective, functional central planning is not practically possible. &nbsp;Resource allocation among many agents looks an awful lot like an exponential time problem, and the world market is quite an efficient approximation. &nbsp;In the real world, markets, regulated to preclude blackmail, theft, and slavery, will tend to provide a better approximation of \"correct\" resource allocation between free agents than a central resource allocation algorithm could plausibly achieve without a tremendous, invasive amount of information about the desires of every market participant, and quite a lot of computing power (within a few orders of magnitude of the combined computational budget of the human species). &nbsp;</p>\n<p>It would be naive to say that we'd need exactly the computational power of the human species in order to achieve it: we can imagine how we might optimize the resource allocation scheme by quite a lot. &nbsp;Populations are (at least somewhat) compressible, in that there are a number of groups of individual people who optimize for similar things, allowing you to save on simulating all of them. &nbsp;Additionally, a decent chunk of human neurological and intellectual activity is not dedicated to economic&nbsp;optimization of any kind, which saves you some computing time there as well. &nbsp;And, of course, humans are not rational, and the homunculi representing them in the optimized market simulation could be, giving them substantially more bang for their cognitive buck - we can imagine, for instance, that this market simulation would not sink billions of dollars into lotteries each year! &nbsp;It may also be that the behavior of the market itself, on some level, is lawful, and a sufficiently intelligent agent could find general-case solutions that are less expensive than market simulation. &nbsp; &nbsp;</p>\n<p>Still, though, the amount of information and raw processing power needed to pull off central planning competitive with the market approximation seems to be out of our reach for the time being. &nbsp;As a result of this, and a few other factors, my own politics tend to lean Libertarian / minarchist, and I'm aware that there is some of this sentiment in circulation on this site, though generally not explicitly. &nbsp;I'm trying to refine my beliefs surrounding some of the sticky issues in Libertarian philosophy (mostly related to children and extreme policy cases), and I thought I'd ask LW what they thought about one issue in particular. &nbsp;</p>\n<p>I have been wondering whether or not there are any interventions in the economy that can have a positive expected benefit. &nbsp;I honestly don't know if this is the case: put another way, the question is really asking if there are any characteristic behaviors of markets that are undesirable in some sense, and can be corrected by the application of an external law. &nbsp;Furthermore, such things cannot be profitable to correct for any participant or plausibly-sized collection of participants in the market, but must be good for the market as a whole, or must be something that <em>requires</em>&nbsp;regulatory power to fix. &nbsp;</p>\n<p>An obvious example of this sort of thing is the tragedy of the commons and negative externalities. &nbsp;The most pressing case study would be climate change: the science suggests, fairly firmly, that human CO2 emissions are causing long-term shifts in global climate. &nbsp;How disastrous these shifts will actually be is less well settled, but there is at least a reasonable probability that it will be fairly unpleasant, in the long term. &nbsp;Personally, I feel that we are likely to run into much bigger problems much sooner than the 50-200 year timescales these disasters seem to expected on. &nbsp;However, were this not the case, I find that I'm not quite sure how my ideal government, run by a few thousand much smarter and better informed copies of me, ought to respond to the issue. &nbsp;I don't know what I think the ideal policy for dealing with these sorts of externalities is, and I thought I'd ask for LessWrong's thoughts on the matter.</p>\n<p>In my own mind, I think that as light a touch as possible is probably desirable. &nbsp;Law is a very blunt instrument, and crude legislation like a carbon tax could easily have its own serious negative implications (driving industry to countries that simply don't care about CO2 emissions, for example). &nbsp;However, actions like subsidizing and partially deregulating nuclear power plants could help a lot by making coal-fired power plants noncompetitive. &nbsp;We could also declare a policy of slowly withdrawing any government involvement in overseas oil acquisition, which would drive up the price of&nbsp;petroleum products&nbsp;and make electric cars a more appealing alternative. &nbsp;However, I don't know if there would be horrifying consequences to any of these actions: this is the underlying problem - I am not as smart as the market, and guessing its moods is not something that I, or any human is going to be very good at. &nbsp;However, it seems clear that some intervention is necessary in this sort of case. &nbsp;Rock, hard place, you are here. &nbsp;<br /><br />Thoughts? &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hacisxJX7fAQhcSdu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": -14, "extendedScore": null, "score": -3.5e-05, "legacy": true, "legacyId": "22534", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 132, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-09T05:46:24.707Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Well-Kept Gardens Die By Pacifism", "slug": "seq-rerun-well-kept-gardens-die-by-pacifism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.159Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rKbLh89tGNi7n52YM/seq-rerun-well-kept-gardens-die-by-pacifism", "pageUrlRelative": "/posts/rKbLh89tGNi7n52YM/seq-rerun-well-kept-gardens-die-by-pacifism", "linkUrl": "https://www.lesswrong.com/posts/rKbLh89tGNi7n52YM/seq-rerun-well-kept-gardens-die-by-pacifism", "postedAtFormatted": "Thursday, May 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Well-Kept%20Gardens%20Die%20By%20Pacifism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Well-Kept%20Gardens%20Die%20By%20Pacifism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKbLh89tGNi7n52YM%2Fseq-rerun-well-kept-gardens-die-by-pacifism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Well-Kept%20Gardens%20Die%20By%20Pacifism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKbLh89tGNi7n52YM%2Fseq-rerun-well-kept-gardens-die-by-pacifism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKbLh89tGNi7n52YM%2Fseq-rerun-well-kept-gardens-die-by-pacifism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 268, "htmlBody": "<p>Today's post, <a href=\"/lw/c1/wellkept_gardens_die_by_pacifism/\">Well-Kept Gardens Die By Pacifism</a> was originally published on 21 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Good online communities die primarily by refusing to defend themselves, and so it has been since the days of Eternal September. Anyone acculturated by academia knows that censorship is a very grave sin... in their walled gardens where it costs thousands and thousands of dollars to enter. A community with internal politics will treat any attempt to impose moderation as a coup attempt (since internal politics seem of far greater import than invading barbarians). In rationalist communities this is probably an instance of underconfidence - mildly competent moderators are probably quite trustworthy to wield the banhammer. On Less Wrong, the community is the moderator (via karma) and you will need to trust yourselves enough to wield the power and keep the garden clear.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/hds/seq_rerun_the_sin_of_underconfidence/\">The Sin of Underconfidence</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rKbLh89tGNi7n52YM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 1.193536883798048e-06, "legacy": true, "legacyId": "22537", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tscc3e5eujrsEeFN4", "Bw9EW9nQhuyATtgrv", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-09T18:18:34.466Z", "modifiedAt": null, "url": null, "title": "Meetup : LessWrong Ottawa", "slug": "meetup-lesswrong-ottawa", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:30.861Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hL2DK7fjNKQhC6ibR/meetup-lesswrong-ottawa", "pageUrlRelative": "/posts/hL2DK7fjNKQhC6ibR/meetup-lesswrong-ottawa", "linkUrl": "https://www.lesswrong.com/posts/hL2DK7fjNKQhC6ibR/meetup-lesswrong-ottawa", "postedAtFormatted": "Thursday, May 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20LessWrong%20Ottawa&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20LessWrong%20Ottawa%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhL2DK7fjNKQhC6ibR%2Fmeetup-lesswrong-ottawa%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20LessWrong%20Ottawa%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhL2DK7fjNKQhC6ibR%2Fmeetup-lesswrong-ottawa", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhL2DK7fjNKQhC6ibR%2Fmeetup-lesswrong-ottawa", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 44, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ml'>LessWrong Ottawa</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 May 2013 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1015 Wellington St W</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>If you're in Ottawa, read LessWrong, and want to meet others like you, come on out to AlphaSoul Caf\u00e9!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ml'>LessWrong Ottawa</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hL2DK7fjNKQhC6ibR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.1940774308576946e-06, "legacy": true, "legacyId": "22539", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___LessWrong_Ottawa\">Discussion article for the meetup : <a href=\"/meetups/ml\">LessWrong Ottawa</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 May 2013 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1015 Wellington St W</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>If you're in Ottawa, read LessWrong, and want to meet others like you, come on out to AlphaSoul Caf\u00e9!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___LessWrong_Ottawa1\">Discussion article for the meetup : <a href=\"/meetups/ml\">LessWrong Ottawa</a></h2>", "sections": [{"title": "Discussion article for the meetup : LessWrong Ottawa", "anchor": "Discussion_article_for_the_meetup___LessWrong_Ottawa", "level": 1}, {"title": "Discussion article for the meetup : LessWrong Ottawa", "anchor": "Discussion_article_for_the_meetup___LessWrong_Ottawa1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-10T05:04:04.503Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Go Forth and Create the Art", "slug": "seq-rerun-go-forth-and-create-the-art", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.433Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/f3XNFbnNPx42stozW/seq-rerun-go-forth-and-create-the-art", "pageUrlRelative": "/posts/f3XNFbnNPx42stozW/seq-rerun-go-forth-and-create-the-art", "linkUrl": "https://www.lesswrong.com/posts/f3XNFbnNPx42stozW/seq-rerun-go-forth-and-create-the-art", "postedAtFormatted": "Friday, May 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Go%20Forth%20and%20Create%20the%20Art&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Go%20Forth%20and%20Create%20the%20Art%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff3XNFbnNPx42stozW%2Fseq-rerun-go-forth-and-create-the-art%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Go%20Forth%20and%20Create%20the%20Art%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff3XNFbnNPx42stozW%2Fseq-rerun-go-forth-and-create-the-art", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ff3XNFbnNPx42stozW%2Fseq-rerun-go-forth-and-create-the-art", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 293, "htmlBody": "<p>Today's post, <a href=\"/lw/c4/go_forth_and_create_the_art/\">Go Forth and Create the Art!</a> was originally published on 23 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>I've developed primarily the art of epistemic rationality, in particular, the arts required for advanced cognitive reductionism... arts like distinguishing fake explanations from real ones and avoiding affective death spirals. There is much else that needs developing to create a craft of rationality - fighting akrasia; coordinating groups; teaching, training, verification, and becoming a proper experimental science; developing better introductory literature... And yet it seems to me that there is a beginning barrier to surpass before you can start creating high-quality craft of rationality, having to do with virtually everyone who tries to think lofty thoughts going instantly astray, or indeed even realizing that a craft of rationality exists and that you ought to be studying cognitive science literature to create it. It's my hope that my writings, as partial as they are, will serve to surpass this initial barrier. The rest I leave to you.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/he1/seq_rerun_wellkept_gardens_die_by_pacifism/\">Well-Kept Gardens Die By Pacifism</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "f3XNFbnNPx42stozW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 1.1945416698717295e-06, "legacy": true, "legacyId": "22545", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["aFEsqd6ofwnkNqaXo", "rKbLh89tGNi7n52YM", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-10T08:18:23.823Z", "modifiedAt": null, "url": null, "title": "Wikifying the blog list", "slug": "wikifying-the-blog-list", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:38.148Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PeTL97v92LxRJBsrM/wikifying-the-blog-list", "pageUrlRelative": "/posts/PeTL97v92LxRJBsrM/wikifying-the-blog-list", "linkUrl": "https://www.lesswrong.com/posts/PeTL97v92LxRJBsrM/wikifying-the-blog-list", "postedAtFormatted": "Friday, May 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wikifying%20the%20blog%20list&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWikifying%20the%20blog%20list%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPeTL97v92LxRJBsrM%2Fwikifying-the-blog-list%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wikifying%20the%20blog%20list%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPeTL97v92LxRJBsrM%2Fwikifying-the-blog-list", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPeTL97v92LxRJBsrM%2Fwikifying-the-blog-list", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<p>Konkvistador's excellent <a href=\"/lw/d8t/blogs_by_lwers/\">List of Blogs by LWers</a> led me to some of my favorite blogs, but is pretty well hidden and gradually becoming obsolete. In order to create an easily-update-able replacement, I have created the wiki page <a href=\"http://wiki.lesswrong.com/wiki/List_of_Blogs\">List of Blogs</a> and added most of the blogs from Konkvistador's list. If you have a blog, or you read blogs, please help in the following ways:</p>\n<p>-- Add your blog if it's not on there, and <em>if it has updated in the past few months </em>(no dead blogs this time, exceptions for very complete archives of excellent material like Common Sense Atheism in the last section)</p>\n<p>-- Add any other blogs you like that are written by LWers or frequently engage with LW ideas</p>\n<p>-- Remove your blog if you don't want it on there (I added some prominent critics of LW ideas who might not want to be linked to us)</p>\n<p>-- Move your blog to a different category if you don't like the one it's in right now</p>\n<p>-- Add a description of your blog, or change the one that already exists</p>\n<p>-- Change the name you're listed by (I defaulted to people's LW handles)</p>\n<p>-- Bold the name of your blog if it updates near-daily, has a large readership/commentership, and/or gets linked to on LW a lot</p>\n<p>-- Improve formatting</p>\n<p>Somebody more familiar with the Less Wrong twittersphere might want to do something similar to <a href=\"/lw/d92/less_wrong_on_twitter/\">Grognor's Less Wrong on Twitter</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GQyPQcdEQF4zXhJBq": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PeTL97v92LxRJBsrM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 50, "extendedScore": null, "score": 1.1946814871797053e-06, "legacy": true, "legacyId": "22550", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["h83ZzxEpKiPPjsRKs", "BBsCv9dSfnxCArgi7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-10T18:44:17.349Z", "modifiedAt": null, "url": null, "title": "Meetup : Vancouver Microeconomics: Fungibility", "slug": "meetup-vancouver-microeconomics-fungibility", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.868Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qgGSwunTniBS44zpF/meetup-vancouver-microeconomics-fungibility", "pageUrlRelative": "/posts/qgGSwunTniBS44zpF/meetup-vancouver-microeconomics-fungibility", "linkUrl": "https://www.lesswrong.com/posts/qgGSwunTniBS44zpF/meetup-vancouver-microeconomics-fungibility", "postedAtFormatted": "Friday, May 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Vancouver%20Microeconomics%3A%20Fungibility&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Vancouver%20Microeconomics%3A%20Fungibility%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgGSwunTniBS44zpF%2Fmeetup-vancouver-microeconomics-fungibility%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Vancouver%20Microeconomics%3A%20Fungibility%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgGSwunTniBS44zpF%2Fmeetup-vancouver-microeconomics-fungibility", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgGSwunTniBS44zpF%2Fmeetup-vancouver-microeconomics-fungibility", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mm'>Vancouver Microeconomics: Fungibility</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 May 2013 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2505 west broadway, vancouver, bc</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week, we will meet and study the CFAR microeconomics I material. I think it's using fungibility to reorganize how you achieve your goals.</p>\n\n<p>We will meet at 15:30 at Benny's Bagels on Saturday.</p>\n\n<p>As usual, join us on our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a></p>\n\n<p>Sorry for the short notice, hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mm'>Vancouver Microeconomics: Fungibility</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qgGSwunTniBS44zpF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 1.195132022302384e-06, "legacy": true, "legacyId": "22551", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Vancouver_Microeconomics__Fungibility\">Discussion article for the meetup : <a href=\"/meetups/mm\">Vancouver Microeconomics: Fungibility</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 May 2013 03:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2505 west broadway, vancouver, bc</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week, we will meet and study the CFAR microeconomics I material. I think it's using fungibility to reorganize how you achieve your goals.</p>\n\n<p>We will meet at 15:30 at Benny's Bagels on Saturday.</p>\n\n<p>As usual, join us on our <a href=\"http://groups.google.com/group/vancouver-rationalists\" rel=\"nofollow\">mailing list</a></p>\n\n<p>Sorry for the short notice, hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Vancouver_Microeconomics__Fungibility1\">Discussion article for the meetup : <a href=\"/meetups/mm\">Vancouver Microeconomics: Fungibility</a></h2>", "sections": [{"title": "Discussion article for the meetup : Vancouver Microeconomics: Fungibility", "anchor": "Discussion_article_for_the_meetup___Vancouver_Microeconomics__Fungibility", "level": 1}, {"title": "Discussion article for the meetup : Vancouver Microeconomics: Fungibility", "anchor": "Discussion_article_for_the_meetup___Vancouver_Microeconomics__Fungibility1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-10T18:55:09.335Z", "modifiedAt": null, "url": null, "title": "Meetup : Seattle-Vancouver Kilomeetup", "slug": "meetup-seattle-vancouver-kilomeetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:31.086Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FrYSg7t3ohhMswe6B/meetup-seattle-vancouver-kilomeetup", "pageUrlRelative": "/posts/FrYSg7t3ohhMswe6B/meetup-seattle-vancouver-kilomeetup", "linkUrl": "https://www.lesswrong.com/posts/FrYSg7t3ohhMswe6B/meetup-seattle-vancouver-kilomeetup", "postedAtFormatted": "Friday, May 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Seattle-Vancouver%20Kilomeetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Seattle-Vancouver%20Kilomeetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrYSg7t3ohhMswe6B%2Fmeetup-seattle-vancouver-kilomeetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Seattle-Vancouver%20Kilomeetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrYSg7t3ohhMswe6B%2Fmeetup-seattle-vancouver-kilomeetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrYSg7t3ohhMswe6B%2Fmeetup-seattle-vancouver-kilomeetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 76, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mn'>Seattle-Vancouver Kilomeetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 May 2013 11:54:51AM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1600, ne 68 st, Seattle</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>For May long weekend, I will be going to Seattle to visit jsalvatier.</p>\n\n<p>It's a kilomeetup because it's more than a meetup but not really a megameetup.</p>\n\n<p>I can bring three Vancouver folks (driving).</p>\n\n<p>Topic is still up in the air, but it looks like it will be at jsalvatier's house on saturday.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mn'>Seattle-Vancouver Kilomeetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FrYSg7t3ohhMswe6B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 1.1951398469163034e-06, "legacy": true, "legacyId": "22552", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Seattle_Vancouver_Kilomeetup\">Discussion article for the meetup : <a href=\"/meetups/mn\">Seattle-Vancouver Kilomeetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 May 2013 11:54:51AM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1600, ne 68 st, Seattle</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>For May long weekend, I will be going to Seattle to visit jsalvatier.</p>\n\n<p>It's a kilomeetup because it's more than a meetup but not really a megameetup.</p>\n\n<p>I can bring three Vancouver folks (driving).</p>\n\n<p>Topic is still up in the air, but it looks like it will be at jsalvatier's house on saturday.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Seattle_Vancouver_Kilomeetup1\">Discussion article for the meetup : <a href=\"/meetups/mn\">Seattle-Vancouver Kilomeetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Seattle-Vancouver Kilomeetup", "anchor": "Discussion_article_for_the_meetup___Seattle_Vancouver_Kilomeetup", "level": 1}, {"title": "Discussion article for the meetup : Seattle-Vancouver Kilomeetup", "anchor": "Discussion_article_for_the_meetup___Seattle_Vancouver_Kilomeetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-11T01:15:43.086Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, Atlanta, Buffalo, Cambridge MA, Durham, Los Angeles, Munich, New York, Pittsburgh, Washington DC", "slug": "weekly-lw-meetups-austin-atlanta-buffalo-cambridge-ma-durham", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:26.136Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ERnYHhETMoxa4cs25/weekly-lw-meetups-austin-atlanta-buffalo-cambridge-ma-durham", "pageUrlRelative": "/posts/ERnYHhETMoxa4cs25/weekly-lw-meetups-austin-atlanta-buffalo-cambridge-ma-durham", "linkUrl": "https://www.lesswrong.com/posts/ERnYHhETMoxa4cs25/weekly-lw-meetups-austin-atlanta-buffalo-cambridge-ma-durham", "postedAtFormatted": "Saturday, May 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20Atlanta%2C%20Buffalo%2C%20Cambridge%20MA%2C%20Durham%2C%20Los%20Angeles%2C%20Munich%2C%20New%20York%2C%20Pittsburgh%2C%20Washington%20DC&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20Atlanta%2C%20Buffalo%2C%20Cambridge%20MA%2C%20Durham%2C%20Los%20Angeles%2C%20Munich%2C%20New%20York%2C%20Pittsburgh%2C%20Washington%20DC%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FERnYHhETMoxa4cs25%2Fweekly-lw-meetups-austin-atlanta-buffalo-cambridge-ma-durham%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20Atlanta%2C%20Buffalo%2C%20Cambridge%20MA%2C%20Durham%2C%20Los%20Angeles%2C%20Munich%2C%20New%20York%2C%20Pittsburgh%2C%20Washington%20DC%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FERnYHhETMoxa4cs25%2Fweekly-lw-meetups-austin-atlanta-buffalo-cambridge-ma-durham", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FERnYHhETMoxa4cs25%2Fweekly-lw-meetups-austin-atlanta-buffalo-cambridge-ma-durham", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 591, "htmlBody": "<p><strong>This summary was posted to LW main on May 3rd. The following week's summary is <a href=\"/lw/heh/weekly_lw_meetups_atlanta_austin_moscow_ottawa/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/lh\">Munich Meetup:&nbsp;<span class=\"date\">04 May 2013 03:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/ma\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Durham/RTLW HPMoR discussion, ch. 61-63:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">04 May 2013 12:30PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m7\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">(Pittsburgh) Big Gaming Fun 6: A New Beginning!:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">05 May 2013 01:00PM</span></a></li>\n<li><a style=\"color: #3d3d3e; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/mb\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #3d3d3e;\"><span style=\"line-height: 19px; text-align: justify;\">Washington DC fun and games meetup:&nbsp;</span></span><span class=\"date\" style=\"color: #3d3d3e; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">05 May 2013 03:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m8\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Buffalo LW Sunday Meetup:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">05 May 2013 04:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m9\">(Los Angeles) Group Decision Making (the good, the bad, and the confusion of welfare economics):&nbsp;<span class=\"date\">08 May 2013 07:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/ly\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Atlanta Lesswrong: Cryonics FAQ &amp; Signing up Party!:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">10 May 2013 07:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/md\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Moscow, Rationality and Media:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">12 May 2013 04:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m4\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">17 May 2013 07:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m5\">Brussels meetup:&nbsp;<span class=\"date\">18 May 2013 01:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m2\">Bratislava lesswrong meetup III:&nbsp;<span class=\"date\">20 May 2013 06:30PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">04 May 2019 01:30PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/mc\"><span style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\"><span style=\"line-height: 19px; text-align: justify;\">[New York] Effective Altruism (Outdoor!) Dinner Discussion:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">04 May 2013 05:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/me\">[Cambridge MA] How To Do Everything:&nbsp;<span class=\"date\">05 May 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/lt\">Vienna meetup #3:&nbsp;<span class=\"date\">18 May 2013 04:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ERnYHhETMoxa4cs25", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.195413936878234e-06, "legacy": true, "legacyId": "22486", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9Zt3vjcYjpvzcWwDJ", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-11T02:46:05.869Z", "modifiedAt": null, "url": null, "title": "new meetup policy: promote posts only with first-time meetups", "slug": "new-meetup-policy-promote-posts-only-with-first-time-meetups", "viewCount": null, "lastCommentedAt": "2013-05-12T10:50:13.175Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ew7icRfAkhYfkHEvD/new-meetup-policy-promote-posts-only-with-first-time-meetups", "pageUrlRelative": "/posts/ew7icRfAkhYfkHEvD/new-meetup-policy-promote-posts-only-with-first-time-meetups", "linkUrl": "https://www.lesswrong.com/posts/ew7icRfAkhYfkHEvD/new-meetup-policy-promote-posts-only-with-first-time-meetups", "postedAtFormatted": "Saturday, May 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20new%20meetup%20policy%3A%20promote%20posts%20only%20with%20first-time%20meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Anew%20meetup%20policy%3A%20promote%20posts%20only%20with%20first-time%20meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Few7icRfAkhYfkHEvD%2Fnew-meetup-policy-promote-posts-only-with-first-time-meetups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=new%20meetup%20policy%3A%20promote%20posts%20only%20with%20first-time%20meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Few7icRfAkhYfkHEvD%2Fnew-meetup-policy-promote-posts-only-with-first-time-meetups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Few7icRfAkhYfkHEvD%2Fnew-meetup-policy-promote-posts-only-with-first-time-meetups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 157, "htmlBody": "<p>I propose for comment the following alteration of the LW meetup promotion policy:</p>\n<p>* The weekly meetup roundup will contain, in its title, only the names of cities which have not previously had an LW meetup, or which have not had an LW meetup in the last year.</p>\n<p>* On occasions where no such name appears in the title, the meetup roundup post will still appear in Main but will not be Promoted.</p>\n<p>* Cities having a first-time meetup, or where a new meetup is being started by a new organizer after a hiatus, should have additional info about that meetup and its organizer appearing in a prominent, top-of-post position in the roundup post.</p>\n<p>This is intended to make it easier for new meetups to gain attention, by requiring hopeful LWers awaiting a new meetup in their area to pay attention to a smaller number of promoted posts and a smaller number of cities appearing in the titles of Main posts.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ew7icRfAkhYfkHEvD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 9, "extendedScore": null, "score": 1.1954790467761094e-06, "legacy": true, "legacyId": "22554", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-05-11T02:46:05.869Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-11T03:38:46.104Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Practical Advice Backed By Deep Theories", "slug": "seq-rerun-practical-advice-backed-by-deep-theories", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.736Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kew43k6gvneabK4Cq/seq-rerun-practical-advice-backed-by-deep-theories", "pageUrlRelative": "/posts/kew43k6gvneabK4Cq/seq-rerun-practical-advice-backed-by-deep-theories", "linkUrl": "https://www.lesswrong.com/posts/kew43k6gvneabK4Cq/seq-rerun-practical-advice-backed-by-deep-theories", "postedAtFormatted": "Saturday, May 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Practical%20Advice%20Backed%20By%20Deep%20Theories&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Practical%20Advice%20Backed%20By%20Deep%20Theories%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkew43k6gvneabK4Cq%2Fseq-rerun-practical-advice-backed-by-deep-theories%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Practical%20Advice%20Backed%20By%20Deep%20Theories%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkew43k6gvneabK4Cq%2Fseq-rerun-practical-advice-backed-by-deep-theories", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkew43k6gvneabK4Cq%2Fseq-rerun-practical-advice-backed-by-deep-theories", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 233, "htmlBody": "<p>Today's post, <a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a> was originally published on 25 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Practical advice is genuinely much, much more useful when it's backed up by concrete experimental results, causal models that are actually true, or valid math that is validly interpreted. (Listed in increasing order of difficulty.) Stripping out the theories and giving the mere advice alone wouldn't have nearly the same impact or even the same message; and oddly enough, translating experiments and math into practical advice seems to be a rare niche activity relative to academia. If there's a distinctive LW style, this is it.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/he9/seq_rerun_go_forth_and_create_the_art/\">Go Forth and Create the Art</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kew43k6gvneabK4Cq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.1955169936559315e-06, "legacy": true, "legacyId": "22555", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LqjKP255fPRY7aMzw", "f3XNFbnNPx42stozW", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-11T12:58:07.286Z", "modifiedAt": null, "url": null, "title": "Keeping Choices Donation Neutral", "slug": "keeping-choices-donation-neutral", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:00.081Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GaS8KBTH8s7prz8bw/keeping-choices-donation-neutral", "pageUrlRelative": "/posts/GaS8KBTH8s7prz8bw/keeping-choices-donation-neutral", "linkUrl": "https://www.lesswrong.com/posts/GaS8KBTH8s7prz8bw/keeping-choices-donation-neutral", "postedAtFormatted": "Saturday, May 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Keeping%20Choices%20Donation%20Neutral&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKeeping%20Choices%20Donation%20Neutral%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGaS8KBTH8s7prz8bw%2Fkeeping-choices-donation-neutral%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Keeping%20Choices%20Donation%20Neutral%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGaS8KBTH8s7prz8bw%2Fkeeping-choices-donation-neutral", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGaS8KBTH8s7prz8bw%2Fkeeping-choices-donation-neutral", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 585, "htmlBody": "<p>Every dollar I spend on myself is a dollar that could go much farther if spent on other people.  I can give someone else a year of healthy life for about $50 [1] and there's no way $50 can do anywhere near that much to help me.  I could go through my life constantly <a href=\"http://www.raikoth.net/deadchild.html\">weighing every purchase</a> against the good it could do, but this would make me miserable.  So how do I accept that other people need my money more without giving up on being happy myself?</p>\n<p>For me the key is to make most choices donation neutral.  As money comes in I divide it into \"money to give to the most effective charity\" and \"money to spend as I wish\".  How to divide it is a hard and distressing choice, but it's one I only have to make once a year. Then when deciding to buy something (socks, rent, phone, instruments, food) I know it's money that isn't getting given away regardless, so I don't have to feel constantly guilty about making tradeoffs with people's lives.</p>\n<p><a href=\"http://www.givinggladly.com/\">Julia</a> and I have been using this system since 2009. [2] It's mostly worked well, but it's needed some additions.  The main issue is that declining to spend money on yourself isn't the only way to trade off benefits to other people against costs to yourself.  For example you could decide to be vegan, <a href=\"/lw/d4v/altruistic_kidney_donation/\">donate a kidney</a>, or cash out your vacation days and give away the money.  For ones that generate money directly (cashing out vacation) the solution is simple: that money goes into the pool that can't be given away.  For ones that don't generate money you would convert them into money via the good you think they do. Take the most effective charity you know about, figure out how much you would need to give to them in order to have the same positive effect, and then move that amount of money from donations to self-spending.  For example, I might estimate that giving $100 to the AMF does about as much good as being vegan for a year, so if I decided to go ahead with being vegan I would decrease my annual donations by $100 and allocate another $100 to spend on myself.</p>\n<p>I may or may not decide that having another $X to spend on myself is better than sacrifice Y, but whichever way I decide I'm working to make myself as happy as possible for a given amount of doing good. It's not a choice that has additional lives saved weighing on either side of it.</p>\n<p>(This doesn't deal with a potentially important category: things that only make you somewhat unhappy.  For example, working a higher paying job you like less, or pushing yourself to host more <a href=\"http://effective-altruism.meetup.com/\">effective altruism meetups</a> than you'd really like to.  I don't see how to deal with this, but I don't think it's been a problem so far.)</p>\n<p><br /> [1] Specifically, I can donate to the Against Malaria Foundation, which distributes     anti-malarial nets.  The main effect is averting deaths of children who will probably     go on to live around 30 years once you take into account other things they might die     from.  This comes to about $75 per additional year of life.  There are also many other     people protected by the nets where it doesn't make the difference between life and     death but helps them live healthier lives.  That brings the $/DALY figure down to     about $50.</p>\n<p>[2] I also wrote about this approach <a href=\"http://www.jefftk.com/news/2010-07-19\">in 2010</a> when it was much younger.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GaS8KBTH8s7prz8bw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 23, "extendedScore": null, "score": 8.9e-05, "legacy": true, "legacyId": "22557", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wzdjAmeoPRmBE8v8o"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-12T00:17:43.442Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington DC Munchinkry meetup", "slug": "meetup-washington-dc-munchinkry-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:32.824Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vHEHbcB7ekF2hwHoE/meetup-washington-dc-munchinkry-meetup", "pageUrlRelative": "/posts/vHEHbcB7ekF2hwHoE/meetup-washington-dc-munchinkry-meetup", "linkUrl": "https://www.lesswrong.com/posts/vHEHbcB7ekF2hwHoE/meetup-washington-dc-munchinkry-meetup", "postedAtFormatted": "Sunday, May 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%20DC%20Munchinkry%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%20DC%20Munchinkry%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvHEHbcB7ekF2hwHoE%2Fmeetup-washington-dc-munchinkry-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%20DC%20Munchinkry%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvHEHbcB7ekF2hwHoE%2Fmeetup-washington-dc-munchinkry-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvHEHbcB7ekF2hwHoE%2Fmeetup-washington-dc-munchinkry-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 48, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mo'>Washington DC Munchinkry meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 May 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet to talk about interesting lifehacky things!</p>\n\n<p>(Credit to Maia for the idea for this one).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mo'>Washington DC Munchinkry meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vHEHbcB7ekF2hwHoE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.196410225472083e-06, "legacy": true, "legacyId": "22558", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_Munchinkry_meetup\">Discussion article for the meetup : <a href=\"/meetups/mo\">Washington DC Munchinkry meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 May 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet to talk about interesting lifehacky things!</p>\n\n<p>(Credit to Maia for the idea for this one).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_Munchinkry_meetup1\">Discussion article for the meetup : <a href=\"/meetups/mo\">Washington DC Munchinkry meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington DC Munchinkry meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_Munchinkry_meetup", "level": 1}, {"title": "Discussion article for the meetup : Washington DC Munchinkry meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_Munchinkry_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-12T10:03:12.547Z", "modifiedAt": null, "url": null, "title": "LW Study Hall - 2 Month Update", "slug": "lw-study-hall-2-month-update", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:35.411Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Lachouette", "createdAt": "2012-11-05T19:19:25.611Z", "isAdmin": false, "displayName": "Lachouette"}, "userId": "AeqmHjYoZ4gvvvjHN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2huJTJ2Fs9qbw3xR7/lw-study-hall-2-month-update", "pageUrlRelative": "/posts/2huJTJ2Fs9qbw3xR7/lw-study-hall-2-month-update", "linkUrl": "https://www.lesswrong.com/posts/2huJTJ2Fs9qbw3xR7/lw-study-hall-2-month-update", "postedAtFormatted": "Sunday, May 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20Study%20Hall%20-%202%20Month%20Update&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20Study%20Hall%20-%202%20Month%20Update%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2huJTJ2Fs9qbw3xR7%2Flw-study-hall-2-month-update%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20Study%20Hall%20-%202%20Month%20Update%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2huJTJ2Fs9qbw3xR7%2Flw-study-hall-2-month-update", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2huJTJ2Fs9qbw3xR7%2Flw-study-hall-2-month-update", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 652, "htmlBody": "<div id=\"body_t1_8yj2\" class=\"comment-content \">\n<div class=\"md\">\n<p><em>Comment reposted from <a href=\"/lw/gwo/coworking_collaboration_to_combat_akrasia/\">(link)</a> for exposure</em></p>\n<p>&nbsp;</p>\n<p>Two months have passed and I&rsquo;m glad to say the <a href=\"http://tinychat.com/lesswrong\" target=\"_blank\"><span class=\"fullwidth\">LW Study Hall on tinychat</span></a> is still active and alive. Since judging from the comments it kind of looks like we&rsquo;ve moved on from tinychat, a review like this might be useful for anyone who hasn&rsquo;t been there yet.</p>\n<p>My first sessions on the chat were driven more by curiosity than anything else since I didn&rsquo;t believe it would be really effective for me &ndash; I&rsquo;ve felt that I procrastinate too much, but it never occurred to me that working together with other people might make me more effective. I was proven wrong.</p>\n<p>Since those first sessions I&rsquo;ve been online almost every day and got to see different people come and go, and some people stay. It didn&rsquo;t take long for me to feel like a part of the &ldquo;chat community&rdquo;, and to feel motivated to work to see the regulars more often, some of which I might even consider friends now. The atmosphere is friendly, people make an active effort to integrate newcomers in the &ldquo;community&rdquo; and I have yet to see an argument that isn&rsquo;t constructive. Though the breaks are a bit flexible, people usually don&rsquo;t overstretch it and it&rsquo;s generally good practice not to chat during a working phase. More introverted people can participate without taking part in the chat much and without broadcasting video.</p>\n<p>So, what makes this chat so effective in combating procrastination? Pomodoros are the &ldquo;flow&rdquo; of the chat. Since you&rsquo;re working with other people, you are much more likely to stick to the pomodoro cycle than if you set those constraints for yourself. That doesn&rsquo;t just mean you keep the breaks relatively short, but you also don&rsquo;t work too long. I find that if I work alone, I tend to keep at it for longer than I can keep concentrated. When I do take a break I don&rsquo;t really have anything else to do, so I might start to procrastinate, leading to a work cycle where the &ldquo;breaks&rdquo; can be as long as the working phases. This has been my main issue with structuring my working day, and I was more surprised than I probably should have been to see that problem solved by working in a group. Judging from my own experiences and those of others I believe everyone struggling with akrasia should at least try if it works for him/her. For those who struggle with akrasia more, it might be useful to combine several techniques such as precommitting to fixed working dates, showing your screen on camera or finding someone on the chat who will remind you (e.g. via skype) to show up again if you&rsquo;ve been absent for longer (or any number of other methods like beeminder).</p>\n<p>There are a few issues with the chat, especially that tinychat isn&rsquo;t always stable. The limited options have also been subject of complaints, but it&rsquo;s so far the best thing we&rsquo;ve found. I&rsquo;m optimistic that a better option will be found or created in the long term &ndash; the more people frequent the chat, the more likely it gets. Covering all time slots hasn&rsquo;t worked out perfectly, but we usually have good &ldquo;coverage&rdquo; during the UTC afternoon/evening, so that is probably a good time to try. In case the chat is empty, don&rsquo;t be discouraged, just try again later. I will try to put as many of my working hours in the precommitment schedule (link on top of the chat window) and hope others will do so more often too, so it&rsquo;s possible to sync up working time.</p>\n<p>Over these two months the lesswrong chat has become a substantial part of my life that I really want to keep, ideally for much longer. While it is no longer an experiment for me, I want to invite you to try it, if you haven&rsquo;t already. I&rsquo;d be glad to welcome you on the chat anytime. :)</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "udPbn9RthmgTtHMiG": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2huJTJ2Fs9qbw3xR7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 40, "extendedScore": null, "score": 1.196832745048688e-06, "legacy": true, "legacyId": "22559", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Zq3Dey8ZboSby6YAv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-12T13:17:40.561Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne Social Meetup", "slug": "meetup-melbourne-social-meetup-9", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:30.318Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Maelin", "createdAt": "2009-05-28T03:32:36.549Z", "isAdmin": false, "displayName": "Maelin"}, "userId": "CE5vuYfsSRTeG2KWd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mi9GkqLAJTbBA2A3E/meetup-melbourne-social-meetup-9", "pageUrlRelative": "/posts/Mi9GkqLAJTbBA2A3E/meetup-melbourne-social-meetup-9", "linkUrl": "https://www.lesswrong.com/posts/Mi9GkqLAJTbBA2A3E/meetup-melbourne-social-meetup-9", "postedAtFormatted": "Sunday, May 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20Social%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20Social%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMi9GkqLAJTbBA2A3E%2Fmeetup-melbourne-social-meetup-9%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20Social%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMi9GkqLAJTbBA2A3E%2Fmeetup-melbourne-social-meetup-9", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMi9GkqLAJTbBA2A3E%2Fmeetup-melbourne-social-meetup-9", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mp'>Melbourne Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 May 2013 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\"> 5 / 52 Leicester St, Carlton 3053</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next regular social meetup will occur on Friday 17th May 2013 at our usual location. All welcome from 6:30pm for a 7:00pm official start, but feel free to arrive later as circumstances require.</p>\n\n<p>Our social meetups are relaxed, informal events where we play card and board games, chat about topics of interest, and occasionally play parlour games like Mafia or Resistance if there's interest. The social meetup is a great first meetup to attend if you haven't come to one before - we're always happy to welcome newcomers.</p>\n\n<p>We generally organise some kind of take-away food for dinner for those that would like some. Snacks will also be provided, BYO drinks.</p>\n\n<p>Press the number 5 button at the front door, or call me (Richard) on 0421231789, and we'll buzz you in. For any questions, feel free to post on our Google Group or send me an SMS during the week.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mp'>Melbourne Social Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mi9GkqLAJTbBA2A3E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.196973141913238e-06, "legacy": true, "legacyId": "22560", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Social_Meetup\">Discussion article for the meetup : <a href=\"/meetups/mp\">Melbourne Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 May 2013 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\"> 5 / 52 Leicester St, Carlton 3053</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next regular social meetup will occur on Friday 17th May 2013 at our usual location. All welcome from 6:30pm for a 7:00pm official start, but feel free to arrive later as circumstances require.</p>\n\n<p>Our social meetups are relaxed, informal events where we play card and board games, chat about topics of interest, and occasionally play parlour games like Mafia or Resistance if there's interest. The social meetup is a great first meetup to attend if you haven't come to one before - we're always happy to welcome newcomers.</p>\n\n<p>We generally organise some kind of take-away food for dinner for those that would like some. Snacks will also be provided, BYO drinks.</p>\n\n<p>Press the number 5 button at the front door, or call me (Richard) on 0421231789, and we'll buzz you in. For any questions, feel free to post on our Google Group or send me an SMS during the week.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Social_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/mp\">Melbourne Social Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne Social Meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_Social_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne Social Meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_Social_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-12T17:01:02.724Z", "modifiedAt": null, "url": null, "title": "Computer Science and Software Engineering", "slug": "computer-science-and-software-engineering", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:35.088Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JMiller", "createdAt": "2012-11-15T16:08:50.381Z", "isAdmin": false, "displayName": "JMiller"}, "userId": "YePJv5oBk8LKnWogz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PGpN2RFWmTen4r8Bi/computer-science-and-software-engineering", "pageUrlRelative": "/posts/PGpN2RFWmTen4r8Bi/computer-science-and-software-engineering", "linkUrl": "https://www.lesswrong.com/posts/PGpN2RFWmTen4r8Bi/computer-science-and-software-engineering", "postedAtFormatted": "Sunday, May 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Computer%20Science%20and%20Software%20Engineering&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AComputer%20Science%20and%20Software%20Engineering%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPGpN2RFWmTen4r8Bi%2Fcomputer-science-and-software-engineering%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Computer%20Science%20and%20Software%20Engineering%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPGpN2RFWmTen4r8Bi%2Fcomputer-science-and-software-engineering", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPGpN2RFWmTen4r8Bi%2Fcomputer-science-and-software-engineering", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 184, "htmlBody": "<p>Hello,</p>\n<p>I'm not sure if this should be posted here. If it should go in the open thread please let me know. I figured this could be an interesting conversation, since many people on lesswrong seem to be programmers.</p>\n<p>I am currently researching the difference/ pros-cons of pursuing a computer science degree versus a software engineering degree. By \"software engineering\" I mean an accredited 4 year engineering program that allows a student to become a p.eng. My understanding is that computer science is more theoretical and mathematical and studies things like algorithms, data strictures, complexity and computability, while engineering is concerned with the practical design,development, testing, and production of software.&nbsp;</p>\n<p>I'm wondering what kind of jobs each degree can lead to, and if one is more optimal than the other in terms of:</p>\n<p>1) short term salary</p>\n<p>2) long term salary</p>\n<p>3) promotability (job ladder climbing)</p>\n<p>I'm sure there are more useful and relevent questions which I do not even know to ask. If there is anything you think might be a good question that others (or you) can answer, please let me know and I'll add it into the OP.</p>\n<p>Thanks!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PGpN2RFWmTen4r8Bi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 0, "extendedScore": null, "score": 1.197134441096266e-06, "legacy": true, "legacyId": "22561", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-12T20:09:21.466Z", "modifiedAt": null, "url": null, "title": "How to calibrate your political beliefs", "slug": "how-to-calibrate-your-political-beliefs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:32.561Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Macaulay", "createdAt": "2012-01-06T01:43:41.420Z", "isAdmin": false, "displayName": "Macaulay"}, "userId": "nnWFuK7EiB9brbWop", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HQKZvioos9vsk8sMu/how-to-calibrate-your-political-beliefs", "pageUrlRelative": "/posts/HQKZvioos9vsk8sMu/how-to-calibrate-your-political-beliefs", "linkUrl": "https://www.lesswrong.com/posts/HQKZvioos9vsk8sMu/how-to-calibrate-your-political-beliefs", "postedAtFormatted": "Sunday, May 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20calibrate%20your%20political%20beliefs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20calibrate%20your%20political%20beliefs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQKZvioos9vsk8sMu%2Fhow-to-calibrate-your-political-beliefs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20calibrate%20your%20political%20beliefs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQKZvioos9vsk8sMu%2Fhow-to-calibrate-your-political-beliefs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHQKZvioos9vsk8sMu%2Fhow-to-calibrate-your-political-beliefs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 234, "htmlBody": "<p>So you're playing the <a href=\"http://acritch.com/credence-game/\">credence game</a>, and you&rsquo;re getting a pretty good sense of which level of confidence to assign to your beliefs. Later, when you&rsquo;re discussing politics, you wonder how you can calibrate your political beliefs as well (beliefs of the form \"policy X will result in outcome Y\"). Here there's no easy way to assess whether a belief is true or false, in contrast to the trivia questions in the credence game. Moreover, it&rsquo;s very easy to become mindkilled by politics. What do you do?</p>\n<p>In the credence game, you get direct feedback that allows you to learn about your internal proxies for credence, i.e., emotional and heuristic cues about how much to trust yourself. With political beliefs, however, there is no such feedback. One workaround would be to assign high confidence only to beliefs for which you have read <em>n</em> academic papers on the subject. For example, only assign 90% confidence if you've read ten academic papers.</p>\n<p>To account for mindkilling, use a second criterion: assign high confidence only to beliefs for which you are ideologically Turing-capable (i.e., able to pass an <a href=\"http://en.wikipedia.org/wiki/Ideological_Turing_Test\">ideological Turing test</a>). As a proxy for an actual ideological Turing test, you should be able to accurately restate your opponent&rsquo;s position, or be able to state the strongest counterargument to your position.</p>\n<p>In sum, to calibrate your political beliefs, only assign high confidence to beliefs which satisfy extremely demanding epistemic standards.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HQKZvioos9vsk8sMu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 2, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "22562", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 75, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-13T00:36:14.487Z", "modifiedAt": null, "url": null, "title": "Unlimited Pomodoro Works: My Scheduling System", "slug": "unlimited-pomodoro-works-my-scheduling-system", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:05.099Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Intrism", "createdAt": "2013-03-05T16:41:08.154Z", "isAdmin": false, "displayName": "Intrism"}, "userId": "pj7GE4aJifZfjLgD9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Szwofei5zbYAmf2TW/unlimited-pomodoro-works-my-scheduling-system", "pageUrlRelative": "/posts/Szwofei5zbYAmf2TW/unlimited-pomodoro-works-my-scheduling-system", "linkUrl": "https://www.lesswrong.com/posts/Szwofei5zbYAmf2TW/unlimited-pomodoro-works-my-scheduling-system", "postedAtFormatted": "Monday, May 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Unlimited%20Pomodoro%20Works%3A%20My%20Scheduling%20System&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUnlimited%20Pomodoro%20Works%3A%20My%20Scheduling%20System%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzwofei5zbYAmf2TW%2Funlimited-pomodoro-works-my-scheduling-system%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Unlimited%20Pomodoro%20Works%3A%20My%20Scheduling%20System%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzwofei5zbYAmf2TW%2Funlimited-pomodoro-works-my-scheduling-system", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSzwofei5zbYAmf2TW%2Funlimited-pomodoro-works-my-scheduling-system", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1064, "htmlBody": "<p><strong>Related: </strong><a href=\"/lw/gp4/the_power_of_pomodoros/\">The Power of Pomodoros</a>,&nbsp;<a href=\"/lw/3kv/working_hurts_less_than_procrastinating_we_fear/\">Working Hurts Less Than Procrastinating</a>, <a href=\"/lw/d2/cached_procrastination/\">Cached Procrastination</a></p>\n<p><strong>Follow-up To: </strong><a href=\"/lw/h1w/reinforcement_and_shortterm_rewards_as_antiakratic/\">Reinforcement and Short-Term Rewards as Anti-Akratic</a></p>\n<p>I'm still working on cleaning up my scheduling system for release, like I mentioned in the comments to my last post. However, I managed to forget the end of my college semester, which is taking up a distressing amount of my time. So, although progress is being made, I'm not done quite yet and probably won't be until sometime after my final exams end on the 16th.&nbsp;In the meantime, I'm going to explain my scheduling system and some of the modifications I've made to it.</p>\n<p>My system is derived from the <a href=\"/lw/gp4/the_power_of_pomodoros/\">Pomodoro Technique</a>. In it, work is separated into individual 25-minute blocks also called \"Pomodoros.\" To ensure that blocks last for the full 25 minutes, they're timed; once the timer has started, the block should not be uninterrupted until the timer runs out. There's a short break between each Pomodoro; after several Pomodoros, there's a longer break.</p>\n<p>The biggest benefit I've noticed from using my system is in fixing my problems with task switching. When I was doing something I didn't much like, I used to think about doing something else almost constantly; it usually wasn't long before I stopped working to do something else. The original Pomodoro Method solved this problem by forcing me to wait until the timer had expired to stop working.&nbsp;However, I had another problem with task switching that the original Pomodoro System didn't touch.&nbsp;When I was slacking off, I could sit contented for hours without doing anything else; I found it hard to start working or stop slacking off.&nbsp;That's where my changes came in. These problems are both very similar; in this one, I change tasks too infrequently, where in the other, I changed tasks too often. It stands to reason, then, that they could both be solved the same way: by timing them. So, in my system, <em>everything </em>I do is treated like work is under the Pomodoro System, even slacking off.</p>\n<p>That's the biggest change my system makes: everything is a block (or a Pomodoro), and I'm in a block all the time. However, my system is more than just a few rule tweaks. My system is computerized; I use a web application for my block timer, as well as for managing my task list and the various other add-ons my system has. I've also made a number of more subtle decisions that better adapt the system for computerization.</p>\n<p>Like in the Pomodoro System, my system times each block of work I do. After the work period ends (usually 25 minutes), my system enters a 5-minute break period. During this break period, I preload my next task into the system so that I can start working as soon as the break ends, without having to futz with the timer. If I forget to preload a task, my system doesn't start anything automatically; I'm just left outside of a block, which I consider to be a failure state that I always try to avoid.</p>\n<p>My system also integrates a task list; to start a block, I must choose my task from the list. This also helps to improve my productivity. Because I choose tasks from a list of all my potential activities, it's easier to find and select tasks with higher activation energy, instead of falling back on <a href=\"/lw/d2/cached_procrastination/\">cached procrastination</a>. Forcing me to select a task from a list also makes me explicitly consider what I ought to be doing with my time.</p>\n<p>A web application is nice, but there are a lot of things about it that, on its own, make it a bit less useful than the traditional timer. It doesn't ring, for instance, and I have to open it up every time I want to check how much time I have left. So, I built an application that runs on another computer on my desk that handles all of those things. It rings a digital gong when the current timer ends. It shows me whether I'm in a break, in a task, or if my task has expired by changing the color of the screen. It displays in text the current task, some information about it, and how much time is left on the timer. Right now, this is a fairly bare-bones terminal application; one of the things I'm working on in my current revision is making it look a bit nicer.</p>\n<p>Of course, my extrinsic motivator from <a href=\"/lw/h1w/reinforcement_and_shortterm_rewards_as_antiakratic/\">my previous article</a> is tied into this system as well. Simply put, it rewards me with candy for keeping on track with my schedule. The rules it follows are more precisely explained in its own article. I'm rewriting the rules, however; expect a new article about them in a few weeks.</p>\n<p>Even the best scheduling system in the world would be of no use if I couldn't bring myself to follow it. That's what my browser plugin is for. When I don't have a block timer active, or if I'm trying to access a non-productive web site during a productive block, my browser plugin will block the site and tell me to go start a block. I can still override the plugin, but the plugin requires me to wait 10 seconds before I get the option. Since most of my procrastination time is spent on the Internet, the plugin is an effective way of reminding me to turn the system back on.</p>\n<p>Since my goal is to keep the system on at all times, it's a bit problematic that many of real-world tasks don't divide neatly into Pomodoro-sized chunks. These are things like eating dinner, walking the dog, or sleeping. In order to track them, my system has a category of \"real-world\" tasks which run for an indefinite amount of time. However, such a task would seem open to abuse; in order to prevent that, my browser plugin blocks my access to the Internet during them, just as if I weren't in a block at all.</p>\n<p>My original plans for the system included things like reports on time usage and a system to help me calibrate my expectations for the amount of time a task is likely to take. However, I've yet to implement any of these, and honestly I'm still not sure what the best way to implement these would be. Any interesting suggestions would be appreciated; I hope to write an article about building these systems sometime soon.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Qyeqh8wycbSapBNsp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Szwofei5zbYAmf2TW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 17, "extendedScore": null, "score": 1.1974632656627855e-06, "legacy": true, "legacyId": "22395", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4iLk2rxTguFqHHs3Y", "9o3QBg2xJXcRCxGjS", "5MmCYWKNnvAPWRBYL", "Gne4dR4iec3QkWiyv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-13T03:49:52.368Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Final Words", "slug": "seq-rerun-final-words", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:31.063Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XjnG9pHmFAHKggTRT/seq-rerun-final-words", "pageUrlRelative": "/posts/XjnG9pHmFAHKggTRT/seq-rerun-final-words", "linkUrl": "https://www.lesswrong.com/posts/XjnG9pHmFAHKggTRT/seq-rerun-final-words", "postedAtFormatted": "Monday, May 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Final%20Words&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Final%20Words%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXjnG9pHmFAHKggTRT%2Fseq-rerun-final-words%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Final%20Words%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXjnG9pHmFAHKggTRT%2Fseq-rerun-final-words", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXjnG9pHmFAHKggTRT%2Fseq-rerun-final-words", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<p>Today's post, <a href=\"/lw/cl/final_words/\">Final Words</a> was originally published on 27 April 2009.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries#Final_Words\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The conclusion of the Beisutsukai series.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/hej/seq_rerun_practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XjnG9pHmFAHKggTRT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1.197603189442983e-06, "legacy": true, "legacyId": "22567", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yffPyiu7hRLyc7r23", "kew43k6gvneabK4Cq", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-13T12:42:57.106Z", "modifiedAt": null, "url": null, "title": "The autopilot problem: driving without experience", "slug": "the-autopilot-problem-driving-without-experience", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:32.738Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oGpcimKtzmg4narKK/the-autopilot-problem-driving-without-experience", "pageUrlRelative": "/posts/oGpcimKtzmg4narKK/the-autopilot-problem-driving-without-experience", "linkUrl": "https://www.lesswrong.com/posts/oGpcimKtzmg4narKK/the-autopilot-problem-driving-without-experience", "postedAtFormatted": "Monday, May 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20autopilot%20problem%3A%20driving%20without%20experience&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20autopilot%20problem%3A%20driving%20without%20experience%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoGpcimKtzmg4narKK%2Fthe-autopilot-problem-driving-without-experience%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20autopilot%20problem%3A%20driving%20without%20experience%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoGpcimKtzmg4narKK%2Fthe-autopilot-problem-driving-without-experience", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoGpcimKtzmg4narKK%2Fthe-autopilot-problem-driving-without-experience", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 443, "htmlBody": "<p>Consider a mixed system, in which an automated system is paired with a human overseer. The automated system handles most of the routine tasks, while the overseer is tasked with looking out for errors and taking over in extreme or unpredictable&nbsp;circumstances. Examples of this could be autopilots, cruise control, GPS direction finding, high-frequency trading&nbsp;&ndash; in fact nearly every automated system has this feature, because they nearly all rely on humans \"keeping an eye on things\".</p>\n<p>But often the human component doesn't perform as well as it should do &ndash; doesn't perform as well as it did before part of the system was automated. Cruise control can <a href=\"http://trid.trb.org/view.aspx?id=462221\">impair driver performance</a>, leading to more&nbsp;accidents. GPS errors can take people <a href=\"http://www.telegraph.co.uk/news/worldnews/europe/belgium/9798779/GPS-failure-leaves-Belgian-woman-in-Zagreb-two-days-later.html\">far more off course</a> than following maps did. When the autopilot fails, pilots <a href=\"http://spectrum.ieee.org/riskfactor/aerospace/aviation/air-france-flight-447-crash-caused-by-a-combination-of-factors\">can crash their planes</a> in rather conventional conditions. Traders don't understand why their <a href=\"http://en.wikipedia.org/wiki/2010_Flash_Crash\">algorithms misbehave</a>, or how to stop this.</p>\n<p>There seems to be three factors at work here:</p>\n<ol>\n<li>Firstly, if the automation performs flawlessly, the overseers will become complacent, blindly trusting the instruments and failing to perform basic sanity checks. They will have far less procedural understanding of what's actually going on, since they have no opportunity to exercise their knowledge.</li>\n<li>This goes along with a general <a href=\"http://en.wikipedia.org/wiki/Deskill\">deskilling</a> of the overseer. When the autopilot controls the plane for <a href=\"http://www.gadling.com/2008/05/02/plane-answers-when-do-pilots-use-the-autopilot/\">most of its trip</a>, pilots get far less hands-on experience of actually flying the plane. Paradoxically, less efficient automation can help with both these problems: if the system fails 10% of the time, the overseer will watch and understand it closely.</li>\n<li>And when the automation does fail, the overseer will typically lack situational awareness of what's going on. All they know is that something extraordinary has happened, and they may have the (possibly flawed) readings of various instruments to guide them&nbsp;&ndash; but they won't have a good <em>feel</em> for what happened to put them in that situation.</li>\n</ol>\n<p>So, when the automation fails, the overseer is generally dumped into an emergency situation, whose nature they are going to have to deduce, and, using skills that have atrophied, they are going to have to take on the task of the automated system that has never failed before and that they have never had to truly understand.</p>\n<p>And they'll typically get blamed for getting it wrong.</p>\n<p>Similarly, if we design AI control mechanisms that rely on the presence of a human in the loop (such as <a href=\"/lw/cze/reply_to_holden_on_tool_ai/\">tools AIs</a>, <a href=\"/lw/any/a_taxonomy_of_oracle_ais/\">Oracle AIs</a>, and, to a lesser extent, <a href=\"/lw/gmx/domesticating_reduced_impact_ais/\">reduced impact AIs</a>), we'll need to take the autopilot problem into account, and design the role of the overseer so as not to deskill them, and not count on them being free of error.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Z5A4c4kjTgLSFEr3h": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oGpcimKtzmg4narKK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 37, "extendedScore": null, "score": 1.1979885579316932e-06, "legacy": true, "legacyId": "22570", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sizjfDgCgAsuLJQmm", "XddMs9kSGtm6L8522", "FdcxknHjeNH2MzrTj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-13T14:43:27.860Z", "modifiedAt": null, "url": null, "title": "Anyone live in or near Osaka?", "slug": "anyone-live-in-or-near-osaka", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Crux", "createdAt": "2011-09-15T17:49:36.096Z", "isAdmin": false, "displayName": "Crux"}, "userId": "XfQRFDS5eFdeYe6uM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HhDcmhrZ5WZpxASJb/anyone-live-in-or-near-osaka", "pageUrlRelative": "/posts/HhDcmhrZ5WZpxASJb/anyone-live-in-or-near-osaka", "linkUrl": "https://www.lesswrong.com/posts/HhDcmhrZ5WZpxASJb/anyone-live-in-or-near-osaka", "postedAtFormatted": "Monday, May 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20live%20in%20or%20near%20Osaka%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20live%20in%20or%20near%20Osaka%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHhDcmhrZ5WZpxASJb%2Fanyone-live-in-or-near-osaka%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20live%20in%20or%20near%20Osaka%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHhDcmhrZ5WZpxASJb%2Fanyone-live-in-or-near-osaka", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHhDcmhrZ5WZpxASJb%2Fanyone-live-in-or-near-osaka", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 33, "htmlBody": "<p>I'm currently located in Osaka, and will be here for the next few months. Anyone close enough to meet? Would be cool to meet some people from Less Wrong who live around here!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HhDcmhrZ5WZpxASJb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 1, "extendedScore": null, "score": 1.1980757081717537e-06, "legacy": true, "legacyId": "22572", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-13T18:27:34.226Z", "modifiedAt": null, "url": null, "title": "[LINK] Scatter, Adapt, and Remember: How Humans Will Survive a Mass Extinction", "slug": "link-scatter-adapt-and-remember-how-humans-will-survive-a", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:31.469Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "Zwqz6uaZMhJ7uqHae", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/od3AkgvZZ8Gt6hFth/link-scatter-adapt-and-remember-how-humans-will-survive-a", "pageUrlRelative": "/posts/od3AkgvZZ8Gt6hFth/link-scatter-adapt-and-remember-how-humans-will-survive-a", "linkUrl": "https://www.lesswrong.com/posts/od3AkgvZZ8Gt6hFth/link-scatter-adapt-and-remember-how-humans-will-survive-a", "postedAtFormatted": "Monday, May 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Scatter%2C%20Adapt%2C%20and%20Remember%3A%20How%20Humans%20Will%20Survive%20a%20Mass%20Extinction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Scatter%2C%20Adapt%2C%20and%20Remember%3A%20How%20Humans%20Will%20Survive%20a%20Mass%20Extinction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fod3AkgvZZ8Gt6hFth%2Flink-scatter-adapt-and-remember-how-humans-will-survive-a%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Scatter%2C%20Adapt%2C%20and%20Remember%3A%20How%20Humans%20Will%20Survive%20a%20Mass%20Extinction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fod3AkgvZZ8Gt6hFth%2Flink-scatter-adapt-and-remember-how-humans-will-survive-a", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fod3AkgvZZ8Gt6hFth%2Flink-scatter-adapt-and-remember-how-humans-will-survive-a", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 104, "htmlBody": "<p>A new popular science book on existential risks and mass extinctions from Annalee Newitz, the founding editor of io9.com</p>\n<p>It probably won't display the same rigour as <em>Global Catastrophic Risks&nbsp;</em>(Bostrom, Cirkovic et al.), but that was published five years ago and is a bit academic. A new book written in a popular, journalistic way seems pretty appealing - it might even be a good introduction for family/friends. Anyway I'm looking forward to reading it, and I expect enough other LWers will be interested in this news to warrant the post.</p>\n<p>If anyone has any other existential risk book recommendations, please comment.</p>\n<p><a title=\"Tumblr\" href=\"http://scatteradaptandremember.com/\">Tumblr</a></p>\n<p><a title=\"Amazon\" href=\"http://www.amazon.com/Scatter-Adapt-Remember-Survive-Extinction/dp/0385535910\">Amazon</a></p>\n<p><a href=\"http://www.goodreads.com/book/show/15798335-scatter-adapt-and-remember\">Some reviews on goodreads</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "od3AkgvZZ8Gt6hFth", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 1.1982378032570716e-06, "legacy": true, "legacyId": "22573", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-13T23:56:09.245Z", "modifiedAt": null, "url": null, "title": "Reminder Memes", "slug": "reminder-memes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:31.831Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mass_Driver", "createdAt": "2010-03-30T15:48:06.997Z", "isAdmin": false, "displayName": "Mass_Driver"}, "userId": "62rKjNqA2LCJ6RthR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Chr4zgCEHcZ7tBw5N/reminder-memes", "pageUrlRelative": "/posts/Chr4zgCEHcZ7tBw5N/reminder-memes", "linkUrl": "https://www.lesswrong.com/posts/Chr4zgCEHcZ7tBw5N/reminder-memes", "postedAtFormatted": "Monday, May 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reminder%20Memes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReminder%20Memes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FChr4zgCEHcZ7tBw5N%2Freminder-memes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reminder%20Memes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FChr4zgCEHcZ7tBw5N%2Freminder-memes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FChr4zgCEHcZ7tBw5N%2Freminder-memes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 41, "htmlBody": "<p>EDIT: Apologies to anyone who wasted time with this; I did not intend it to go live. I left a draft post up on a computer that had an automatic system update; it must have posted as the window was terminated.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Chr4zgCEHcZ7tBw5N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": -20, "extendedScore": null, "score": 1.1984755366792739e-06, "legacy": true, "legacyId": "22575", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-14T04:25:21.643Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley: Munchkinism", "slug": "meetup-berkeley-munchkinism", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/h88NrnyNregaSPyx2/meetup-berkeley-munchkinism", "pageUrlRelative": "/posts/h88NrnyNregaSPyx2/meetup-berkeley-munchkinism", "linkUrl": "https://www.lesswrong.com/posts/h88NrnyNregaSPyx2/meetup-berkeley-munchkinism", "postedAtFormatted": "Tuesday, May 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%3A%20Munchkinism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%3A%20Munchkinism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh88NrnyNregaSPyx2%2Fmeetup-berkeley-munchkinism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%3A%20Munchkinism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh88NrnyNregaSPyx2%2Fmeetup-berkeley-munchkinism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fh88NrnyNregaSPyx2%2Fmeetup-berkeley-munchkinism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 192, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mq'>Berkeley: Munchkinism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 May 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week's meetup is about Munchkinism:</p>\n\n<p>\"A Munchkin is the sort of person who, faced with a role-playing game, reads through the rulebooks over and over until he finds a way to combine three innocuous-seeming magical items into a cycle of infinite wish spells.  Or who, in real life, composes a surprisingly effective diet out of drinking a quarter-cup of extra-light olive oil at least one hour before and after tasting anything else.  Or combines liquid nitrogen and antifreeze and life-insurance policies into a ridiculously cheap method of defeating the invincible specter of unavoidable Death.  Or figures out how to build the real-life version of the cycle of infinite wish spells.\"</p>\n\n<p>\u2014 Eliezer Yudkowsky</p>\n\n<p>Come and bring your strange and zany ideas for exploiting the structure of reality at the expense of the Protestant work ethic. I suggest you look at this recent Less Wrong thread on Munchkinism beforehand, although it is not required:</p>\n\n<p><a href=\"http://lesswrong.com/lw/h9b/post_ridiculous_munchkin_ideas/\" rel=\"nofollow\">http://lesswrong.com/lw/h9b/post_ridiculous_munchkin_ideas/</a></p>\n\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mq'>Berkeley: Munchkinism</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "h88NrnyNregaSPyx2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.198670372446982e-06, "legacy": true, "legacyId": "22578", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Munchkinism\">Discussion article for the meetup : <a href=\"/meetups/mq\">Berkeley: Munchkinism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 May 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This week's meetup is about Munchkinism:</p>\n\n<p>\"A Munchkin is the sort of person who, faced with a role-playing game, reads through the rulebooks over and over until he finds a way to combine three innocuous-seeming magical items into a cycle of infinite wish spells.  Or who, in real life, composes a surprisingly effective diet out of drinking a quarter-cup of extra-light olive oil at least one hour before and after tasting anything else.  Or combines liquid nitrogen and antifreeze and life-insurance policies into a ridiculously cheap method of defeating the invincible specter of unavoidable Death.  Or figures out how to build the real-life version of the cycle of infinite wish spells.\"</p>\n\n<p>\u2014 Eliezer Yudkowsky</p>\n\n<p>Come and bring your strange and zany ideas for exploiting the structure of reality at the expense of the Protestant work ethic. I suggest you look at this recent Less Wrong thread on Munchkinism beforehand, although it is not required:</p>\n\n<p><a href=\"http://lesswrong.com/lw/h9b/post_ridiculous_munchkin_ideas/\" rel=\"nofollow\">http://lesswrong.com/lw/h9b/post_ridiculous_munchkin_ideas/</a></p>\n\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Munchkinism1\">Discussion article for the meetup : <a href=\"/meetups/mq\">Berkeley: Munchkinism</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley: Munchkinism", "anchor": "Discussion_article_for_the_meetup___Berkeley__Munchkinism", "level": 1}, {"title": "Discussion article for the meetup : Berkeley: Munchkinism", "anchor": "Discussion_article_for_the_meetup___Berkeley__Munchkinism1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3RJ3xFupXJKB8vE4q"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-14T10:36:25.710Z", "modifiedAt": null, "url": null, "title": "The Power of Pomodoros", "slug": "the-power-of-pomodoros", "viewCount": null, "lastCommentedAt": "2021-11-09T10:44:10.630Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "elharo", "createdAt": "2012-12-28T14:11:02.335Z", "isAdmin": false, "displayName": "elharo"}, "userId": "cgJcCeZhdRnGtwMMR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4iLk2rxTguFqHHs3Y/the-power-of-pomodoros", "pageUrlRelative": "/posts/4iLk2rxTguFqHHs3Y/the-power-of-pomodoros", "linkUrl": "https://www.lesswrong.com/posts/4iLk2rxTguFqHHs3Y/the-power-of-pomodoros", "postedAtFormatted": "Tuesday, May 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Power%20of%20Pomodoros&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Power%20of%20Pomodoros%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4iLk2rxTguFqHHs3Y%2Fthe-power-of-pomodoros%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Power%20of%20Pomodoros%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4iLk2rxTguFqHHs3Y%2Fthe-power-of-pomodoros", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4iLk2rxTguFqHHs3Y%2Fthe-power-of-pomodoros", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 897, "htmlBody": "<p>Until recently, I hadn't paid much attention to <a href=\"https://en.wikipedia.org/wiki/Pomodoro_Technique\">Pomodoro</a>, though I've heard of it for a few years now. \"Uncle Bob\" Martin seemed to like it, and he's usually worth paying attention to in such matters. However, it mostly seemed to me like a way of organizing a variety of tasks and avoiding procrastination, and I've never had much trouble with that.</p>\n<p>However after the January CFAR workshop suggested it in passing, I decided to give it a try; and I realized I had it all wrong. Pomodoros aren't (for me) a means of avoiding procrastination or dividing time among projects. They're a way of blasting through <a href=\"/lw/21b/ugh_fields/\">Ugh fields</a>.</p>\n<p>The Pomodoro technique is really simple compared to more involved systems like <a href=\"http://www.amazon.com/exec/obidos/ISBN=0142000280/ref=nosim/cafeaulaitA\">Getting Things Done (<acronym>GTD</acronym>)</a>. Here it is:</p>\n<ol>\n<li>Set a timer for 25 minutes</li>\n<li>Work on one thing for that 25 minutes, nothing else. No email, no phone calls, no snack breaks, no Twitter, no IM, etc.</li>\n<li>Take a five minute break</li>\n<li>Pick a new project, or the same project, if you prefer.</li>\n<li>Repeat</li>\n</ol>\n<p>That's pretty much it. You can buy a <a href=\"http://www.amazon.com/exec/obidos/ISBN=1934356506/ref=nosim/cafeaulaitA\">book</a> or a <a href=\"http://www.amazon.com/exec/obidos/ISBN=B006TVTER4/ref=nosim/cafeaulaitA\">special timer</a> for this; but there's really nothing else to it. It takes longer to explain the name than the technique. (When Francesco Cirillo invented this technique in the 1980s, he was using an Italian kitchen timer shaped like a tomato. <em>Pomodoro</em> is Italian for <em>tomato</em>.)</p>\n<p>I got interested in Pomodoro when I realized I could use it to clean my office/desk/apartment. David Allen's <acronym>GTD</acronym> system appealed to me, but I could never maintain it, and the 2+ days it needed to get all the way to a clean desk was always a big hurdle to vault. However, spending 25 minutes at a time, followed by a break and another project seemed a lot more manageable.</p>\n<p>I tried it, and it worked. My desk stack quickly shrunk, not to empty, but at least to a place where an accidental elbow swing no longer launched avalanches of paper onto the floor as I typed.</p>\n<p>So I decided to try Pomodoro on my upcoming book. The publisher was using a new authoring system and template that I was unfamiliar with. There were a dozen little details to figure out about the new system--how to check out files in git, how to create a section break, whether to use hard or soft wrapping, etc.--and I just worked through them one by one. 25 minutes later I'd knocked them all out, and was familiar enough with the new system to begin writing in earnest. I didn't know everything about the software, but I knew enough that it was no longer averting. Next I used 25 minutes on a chapter that was challenging me, and Pomodoro got me to the point where I was in the flow.</p>\n<p>That's when I realized that Pomodoro is not a system for organizing time or avoiding procrastination (at least not for me). What it is, is an incredibly effective way to break through tasks that look too hard: code you're not familiar with, an office that's too cluttered, a chapter you don't know how to begin.</p>\n<p>The key is that a Pomodoro forces you to focus on the unfamiliar, difficult, aversive task for 25 minutes. 25 minutes of focused attention without distractions from other, easier tasks is enough to figure out many complex situations or at least get far enough along that the next step is obvious.</p>\n<p>Here's another example. I had a task to design a <a href=\"https://developers.google.com/web-toolkit/\">GWT</a> widget and plug it into an existing application, and I have never done any work with GWT. Every time I looked at the frontend application code, it seemed like a big mess of confused, convoluted, dependency injected, late bound, spooky-action-at-a-distance spaghetti. Now doubtless there wasn't anything fundamentally more difficult about this code than the server side code I have been writing; and if my career had taken just <a href=\"http://www.elharo.com/blog/personal/2013/01/31/domains-of-knowledge-ive-never-gotten-around-to-learning/\">a slightly different path</a> over the last six years, frontend GWT code might be my bread and butter. But my career didn't take that path, and this code was a big Ugh field for me. So I set the Pomodoro timer on my smartphone and started working. Did I finish? No, but I got started, made progress, and proved to myself that GWT wasn't all that challenging after all. The widget is still difficult enough and GWT complex enough that I may need several more Pomodoros to finish the job, but I did get way further and learn more in 25 minutes of intense focus than I would have done in a day or even a week without it.</p>\n<p>I don't use the Pomodoro technique exclusively. Once I get going on a project or a chapter, I don't need the help; and five minute breaks once I'm in the flow just distract me. So some days I just do 1 or 2 or 0 Pomodoros, whatever it takes to get me rolling again and past the blocker.</p>\n<p>I also don't know if this works for genuinely difficult problems. For instance, I don't know if it will help with a difficult mathematical proof I've been struggling with for months (though I intend to find out). But for subjects that I know I can do, but can't quite figure out how to do, or where to start, the power of focusing 25 minutes of real attention on just that one problem is astonishing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"udPbn9RthmgTtHMiG": 1, "dqx5k65wjFfaiJ9sQ": 1, "Qyeqh8wycbSapBNsp": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4iLk2rxTguFqHHs3Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 56, "baseScore": 75, "extendedScore": null, "score": 0.000189, "legacy": true, "legacyId": "21640", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 75, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EFQ3F6kmt4WHXRqik"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-14T17:42:29.910Z", "modifiedAt": null, "url": null, "title": "Megameetup Announcement: Boston, July 13-14", "slug": "megameetup-announcement-boston-july-13-14", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:01.382Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/z3jmMG6kPrWyosCAz/megameetup-announcement-boston-july-13-14", "pageUrlRelative": "/posts/z3jmMG6kPrWyosCAz/megameetup-announcement-boston-july-13-14", "linkUrl": "https://www.lesswrong.com/posts/z3jmMG6kPrWyosCAz/megameetup-announcement-boston-july-13-14", "postedAtFormatted": "Tuesday, May 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Megameetup%20Announcement%3A%20Boston%2C%20July%2013-14&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMegameetup%20Announcement%3A%20Boston%2C%20July%2013-14%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz3jmMG6kPrWyosCAz%2Fmegameetup-announcement-boston-july-13-14%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Megameetup%20Announcement%3A%20Boston%2C%20July%2013-14%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz3jmMG6kPrWyosCAz%2Fmegameetup-announcement-boston-july-13-14", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz3jmMG6kPrWyosCAz%2Fmegameetup-announcement-boston-july-13-14", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 96, "htmlBody": "<p>On the weekend of July 13-14, the Boston community will be hosting a megameetup. Everyone who can make the trip is strongly encouraged to come. Details are being worked out, but I expect to have presentations, pairwise discussion, a prediction market game, and (weather permitting) running around outside.</p>\n<p>If you think you might come, please leave a comment and a confidence estimate. For example, if you would bring two guests and are 75% certain you will come, your comment might contain \"me +2, 75%.\" If you need a space to crash at night, send me a PM.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "z3jmMG6kPrWyosCAz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 1.1992476222212535e-06, "legacy": true, "legacyId": "22584", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-14T19:59:11.520Z", "modifiedAt": null, "url": null, "title": "The impact of whole brain emulation", "slug": "the-impact-of-whole-brain-emulation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:09.933Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3AXpysm7emgWQ2BKe/the-impact-of-whole-brain-emulation", "pageUrlRelative": "/posts/3AXpysm7emgWQ2BKe/the-impact-of-whole-brain-emulation", "linkUrl": "https://www.lesswrong.com/posts/3AXpysm7emgWQ2BKe/the-impact-of-whole-brain-emulation", "postedAtFormatted": "Tuesday, May 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20impact%20of%20whole%20brain%20emulation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20impact%20of%20whole%20brain%20emulation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3AXpysm7emgWQ2BKe%2Fthe-impact-of-whole-brain-emulation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20impact%20of%20whole%20brain%20emulation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3AXpysm7emgWQ2BKe%2Fthe-impact-of-whole-brain-emulation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3AXpysm7emgWQ2BKe%2Fthe-impact-of-whole-brain-emulation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 454, "htmlBody": "<p>At some point in the future we may be able to scan someone's brain at very high resolution and \"run\" them <a href=\"https://en.wikipedia.org/wiki/Mind_uploading\">on a computer</a>. [1] When I first heard this as a teenager I thought it was interesting but not hugely important.  Running people faster or slower and keeping backups came immediately to mind, and <a href=\"https://en.wikipedia.org/wiki/Mind_uploading#Theoretical_benefits\">Wikipedia adds</a> space travel, but those three by themselves don't seem like they change that much.  Thinking speed doesn't seem to be major limiting factor in coming up with good ideas, we generally only restore from backups in cases of rare failure, and while space travel would dramatically affect the ability of humans to spread [2] it doesn't sound like it changes the conditions of life.</p>\n<p>This actually undersells emulation by quite a lot.   For example \"backups\" let you repeatedly run the same copy of a person on different information.  You can find identify a person when they're at their intellectual or creative best, and give them an hour to think about a new situation.  Add in potentially increased simulation speed and parallelism, and you could run lots of these ones looking into all sorts of candidate approaches to problems.</p>\n<p>With emulations you can get around the mental overhead of keeping all your assumptions about a direction of thought in your mind at once.  I might not know if X is true, and spend a while thinking about what should happen if it's true and another while about what if it's not, but it's hard for me to get past the problem that I'm still uncertain about X.  With an emulation that you can reset to a saved state however, you could have multiple runs where you give some emulations a strong assurance that X is true and some a strong assurance that X is false</p>\n<p>You can also run randomized controlled trials where the experimental group and the control group are the same person.  This should hugely bring down experimental cost and noise, allowing us to make major and rapid progress in discovering what works in education, motivation, and productivity.</p>\n<p>(Backups stop being about error recovery and fundamentally change the way an emulation is useful.)</p>\n<p>These ideas aren't new here [3] but I don't see them often in discussions of the impact of emulating people.  I also suspect there are many more creative ways of using emulation; what else could you do with it?</p>\n<p><br /> [1] I think this is <a href=\"http://www.jefftk.com/news/2011-11-02\">a long way off</a> but don't see any reasons why it wouldn't be possible.</p>\n<p>[2] Which has a big effect on <a href=\"http://www.jefftk.com/news/2011-10-24\">estimates of the number of future people</a>.</p>\n<p>[3] I think most of these ideas fo back to Carl Schulman's 2010 <a href=\"http://intelligence.org/files/WBE-Superorgs.pdf\">Whole Brain Emulation and the Evolution of Superorganisms</a>.</p>\n<p><small><em>I also posted this <a href=\"http://www.jefftk.com/news/2013-05-14\">on my blog</a></em></small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb2ac": 2, "5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3AXpysm7emgWQ2BKe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 1.1993466586361456e-06, "legacy": true, "legacyId": "22585", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-14T20:23:54.858Z", "modifiedAt": null, "url": null, "title": "Avoiding the emergency room", "slug": "avoiding-the-emergency-room", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.103Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JkySer6nQ3zqnffSZ/avoiding-the-emergency-room", "pageUrlRelative": "/posts/JkySer6nQ3zqnffSZ/avoiding-the-emergency-room", "linkUrl": "https://www.lesswrong.com/posts/JkySer6nQ3zqnffSZ/avoiding-the-emergency-room", "postedAtFormatted": "Tuesday, May 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Avoiding%20the%20emergency%20room&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAvoiding%20the%20emergency%20room%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJkySer6nQ3zqnffSZ%2Favoiding-the-emergency-room%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Avoiding%20the%20emergency%20room%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJkySer6nQ3zqnffSZ%2Favoiding-the-emergency-room", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJkySer6nQ3zqnffSZ%2Favoiding-the-emergency-room", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 406, "htmlBody": "<p>Diana Hsieh interviews <a href=\"http://www.philosophyinaction.com/blog/?p=10769\">Dr. Doug McGuff</a> about avoidable injuries and deaths.</p>\n<p>He's an emergency room physician in South Carolina, so he's pretty much just talking about what he's seen-- different regions have different characteristic injuries.</p>\n<p>He says that you're safest in the largest car you can afford, which raises some interesting ethical issues.</p>\n<p>There's a fair amount about the risks of getting overfocused on getting something done. This adds tremendously to the hazards of using ladders.<br /><br />Also, did you know trees can go sproing? One of hazards of chainsaws is that a good bit of energy might be stored in a twisted tree trunk. Don't just know your physics, apply it!</p>\n<p>More generally, there are machines and situations (ATVs, chainsaws, airplanes, skiing, etc.) which tend to make people feel more competent than they are.&nbsp;<br /><br />On the other hand, injuries from rock climbing and horseback riding are less common than you might think. I don't know why the ancestral environment didn't give people a reflexive distaste against diving into water. Perhaps people back then had too much sense to dive much.</p>\n<p>One of the pieces of advice-- to get out of stressful relationships-- is too general. This is mostly a good idea, but from what I've read, leaving a violent relationship can lead to more risk of violence. It's still a good idea to leave, but it's important to leave cautiously.</p>\n<p>Both McGuff and Hsieh are objectivists, so some of the discussion might be in mind-killer territory.</p>\n<p><strong>Edited to add:</strong>&nbsp;It's possible that objectivism would be better discussed under a new post. It's certain that there's a bunch of interesting material in the podcast, and avoidable accidents are worth discussing.</p>\n<p>Topic list:</p>\n<p>&nbsp;</p>\n<ul style=\"font-family: Arial, sans-serif; font-size: 14px; margin: 0.5em 0px 1.5em 1.5em; padding: 0px 0px 0px 30px; line-height: 18px; color: #444444; border: 0px; outline: 0px;\">\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">&ldquo;Black swans&rdquo; of health and &ldquo;The Dirty Dozen&rdquo;</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#1: Driving a car or motorcycle</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#2: Riding an ATV</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#3: Biking or jogging on public roads</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#4: Flying a plane or helicopter yourself</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#5: Getting into a fight</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#6: Lighting a gas grill</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#7: Diving into water</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#8: Using ladders and chainsaws</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#9: Retiring and building your dream house</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#10: Allowing yourself to be forced into a car or trunk at gunpoint</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#11: Staying in stressful relationships</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">#12: Winning the lottery</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">Dr. McGuff&rsquo;s history with risky sports</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">The risks of other sports</li>\n<li style=\"margin: 0px; padding: 3px 0px; border: 0px; outline: 0px;\">How to survive the ER</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"yAmE3StuxBmzCBPWq": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JkySer6nQ3zqnffSZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 13, "extendedScore": null, "score": 1.1993645718029585e-06, "legacy": true, "legacyId": "22586", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-14T20:27:45.433Z", "modifiedAt": null, "url": null, "title": "Meetup : Paris Meetup: Sunday, May 26.", "slug": "meetup-paris-meetup-sunday-may-26", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:34.693Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EYm7WGGbuLrJvbC3K/meetup-paris-meetup-sunday-may-26", "pageUrlRelative": "/posts/EYm7WGGbuLrJvbC3K/meetup-paris-meetup-sunday-may-26", "linkUrl": "https://www.lesswrong.com/posts/EYm7WGGbuLrJvbC3K/meetup-paris-meetup-sunday-may-26", "postedAtFormatted": "Tuesday, May 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Paris%20Meetup%3A%20Sunday%2C%20May%2026.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Paris%20Meetup%3A%20Sunday%2C%20May%2026.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEYm7WGGbuLrJvbC3K%2Fmeetup-paris-meetup-sunday-may-26%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Paris%20Meetup%3A%20Sunday%2C%20May%2026.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEYm7WGGbuLrJvbC3K%2Fmeetup-paris-meetup-sunday-may-26", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEYm7WGGbuLrJvbC3K%2Fmeetup-paris-meetup-sunday-may-26", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mr'>Paris Meetup: Sunday, May 26.</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">26 May 2013 02:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Caf\u00e9 des Arts et M\u00e9tiers\u200e, 51 Rue Turbigo, Paris</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Paris Meetup will be Sunday, May 26, at the Caf\u00e9 des Arts et M\u00e9tiers opposite the Museum.\nWe have several guests of honor! Cat should be around, and loup-vaillant is coming up from the south!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mr'>Paris Meetup: Sunday, May 26.</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EYm7WGGbuLrJvbC3K", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.199367356311144e-06, "legacy": true, "legacyId": "22587", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Paris_Meetup__Sunday__May_26_\">Discussion article for the meetup : <a href=\"/meetups/mr\">Paris Meetup: Sunday, May 26.</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">26 May 2013 02:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Caf\u00e9 des Arts et M\u00e9tiers\u200e, 51 Rue Turbigo, Paris</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Paris Meetup will be Sunday, May 26, at the Caf\u00e9 des Arts et M\u00e9tiers opposite the Museum.\nWe have several guests of honor! Cat should be around, and loup-vaillant is coming up from the south!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Paris_Meetup__Sunday__May_26_1\">Discussion article for the meetup : <a href=\"/meetups/mr\">Paris Meetup: Sunday, May 26.</a></h2>", "sections": [{"title": "Discussion article for the meetup : Paris Meetup: Sunday, May 26.", "anchor": "Discussion_article_for_the_meetup___Paris_Meetup__Sunday__May_26_", "level": 1}, {"title": "Discussion article for the meetup : Paris Meetup: Sunday, May 26.", "anchor": "Discussion_article_for_the_meetup___Paris_Meetup__Sunday__May_26_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-14T21:54:48.349Z", "modifiedAt": null, "url": null, "title": "Improving Cryonics - Regulations and Ethical Considerations", "slug": "improving-cryonics-regulations-and-ethical-considerations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:35.445Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "5TGpqrcWauZ3uHf9e", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K24yrbFkaSawRziqh/improving-cryonics-regulations-and-ethical-considerations", "pageUrlRelative": "/posts/K24yrbFkaSawRziqh/improving-cryonics-regulations-and-ethical-considerations", "linkUrl": "https://www.lesswrong.com/posts/K24yrbFkaSawRziqh/improving-cryonics-regulations-and-ethical-considerations", "postedAtFormatted": "Tuesday, May 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Improving%20Cryonics%20-%20Regulations%20and%20Ethical%20Considerations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AImproving%20Cryonics%20-%20Regulations%20and%20Ethical%20Considerations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK24yrbFkaSawRziqh%2Fimproving-cryonics-regulations-and-ethical-considerations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Improving%20Cryonics%20-%20Regulations%20and%20Ethical%20Considerations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK24yrbFkaSawRziqh%2Fimproving-cryonics-regulations-and-ethical-considerations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK24yrbFkaSawRziqh%2Fimproving-cryonics-regulations-and-ethical-considerations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 379, "htmlBody": "<p>Here is my understanding - correct me if I'm wrong:</p>\r\n<p>Cryonics is only allowed once a person is determined legally dead: when the heart stops beating.</p>\r\n<p>One of the reasons why they have to be dead seems to be that the majority of the population consider cryonics to be a death-sentence, as there is no guarantee at this time that subjects can be revived - regardless of if there's a cure for whatever ailment caused a person's death.</p>\r\n<p>It is difficult at this time&nbsp;to improve the revitalizing process as the patients - or clients - are incapable of surviving as their body was already in the process of shutting down, and we do not have the technology to bring them fully back.</p>\r\n<p>&nbsp;</p>\r\n<p>Now, to some conjecturing.</p>\r\n<p>&nbsp;</p>\r\n<p>We might be able to more reasonably test the effectiveness of procedures to revive current patients&nbsp;if we had healthier people, ones not yet at death's door.</p>\r\n<p>Here's where the ethical dilemma hits home: we could use people who are in good health, here defined as 'not terminally-ill or otherwise dying from health complications in the near future,' who are already intending to end their life. Simply stated, those who are suicidal.</p>\r\n<p>For all intensive purposes they would cease to exist, which&nbsp;would be&nbsp;part of the appeal to that subgroup. At this time there is a probability of them dying from the procedure, which should be ok as they were self-destructing anyway. And if they don't die, they get the chance to reflect on their life or go at it again. In this way their death would be more beneficial to the whole.</p>\r\n<p>The benefits to this would be the additional research into the effects of cryonics on the body and how to develop a procedure to guarantee that you CAN be revived once put under.</p>\r\n<p>I am aware of a couple of problems: legal complications, how to find willing participants, etc., and am thinking of ways to resolve that.</p>\r\n<p>I've just been thinking about this for the past week or so and wanted additional insight. Thoughts?</p>\r\n<p>&nbsp;</p>\r\n<p>***On Suicide</p>\r\n<p>For those opposed to suicide: this idea does not encourage people to kill themselves. Rather, it provides those who are already intent upon ending their existence a means to do so more honorably.</p>\r\n<p>In case people have not read it, I recommend Schopenhauer's Essay on Suicide, found here: <a href=\"http://www.egs.edu/library/arthur-schopenhauer/articles/essays-of-schopenhauer/on-suicide/\">http://www.egs.edu/library/arthur-schopenhauer/articles/essays-of-schopenhauer/on-suicide/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K24yrbFkaSawRziqh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": -1, "extendedScore": null, "score": 1.1994304337333904e-06, "legacy": true, "legacyId": "22588", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-15T03:08:06.216Z", "modifiedAt": null, "url": null, "title": "Adjusting Effort to Barely Meet Standards", "slug": "adjusting-effort-to-barely-meet-standards", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:36.648Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "2b5hCBN2QcAofABRh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NzKrw5eXeJDBfgwbJ/adjusting-effort-to-barely-meet-standards", "pageUrlRelative": "/posts/NzKrw5eXeJDBfgwbJ/adjusting-effort-to-barely-meet-standards", "linkUrl": "https://www.lesswrong.com/posts/NzKrw5eXeJDBfgwbJ/adjusting-effort-to-barely-meet-standards", "postedAtFormatted": "Wednesday, May 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Adjusting%20Effort%20to%20Barely%20Meet%20Standards&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAdjusting%20Effort%20to%20Barely%20Meet%20Standards%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNzKrw5eXeJDBfgwbJ%2Fadjusting-effort-to-barely-meet-standards%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Adjusting%20Effort%20to%20Barely%20Meet%20Standards%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNzKrw5eXeJDBfgwbJ%2Fadjusting-effort-to-barely-meet-standards", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNzKrw5eXeJDBfgwbJ%2Fadjusting-effort-to-barely-meet-standards", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 676, "htmlBody": "<p>There is sometimes an observed inverse correlation between a student's inherent talent/intelligence and the amount of effort expended. The trend is one that I see everywhere in high school. Smart students just sort of shrug and coast by to get an acceptable grade. Or, on the other side, students that don't grasp material as quickly give it an extra push, knowing that it will take some work in order to get the grades they want.</p>\n<p>The similarity between the two is that both types of students are adjusting the amount of work they need to put in,&nbsp;<em>based on the given standard</em>. Given an average, or a benchmark to aim at, they just figure out how much work they need to put in. Students find the equilibrium, the balance between their intelligence and the work they have to put in, that allows them to scrape by.</p>\n<p>For students that have less inherent talent in a particular subject, this may be an incentive to improve. But for the students that are never challenged in school, who easily fly through classes that do not provide the adequate learning environment, this drills into their minds that they don't need to work hard.</p>\n<p>And this lesson is definitely not desirable to teach to bright students. Some are never exposed to anything besides the monotony and apparent irrelevance of schoolwork (When will we ever use this in the real world?) and fall into the habit of filing everything new under the \"pay attention only enough to scrape by\" category of their minds. So, when faced with something like, say, global existential risk, the weight of the subject is ignored.</p>\n<p>Of course, there are many other factors involved. It isn't that everyone has been trained to adjust to put in minimal work based on an average. If that was the case, then all smart students in public school would be slackers. On a larger scale, then there would be no deviations on either side - everyone would just fall exactly on the average line.</p>\n<p>So there is clearly something that lets some people ignore the average. Most motivated and thoughtful people probably don't pay attention to what is considered typical or the standard, anyway. But for many students, a certain test score is a signal to just stop.</p>\n<p>Back to the larger scale, now. The problem of using an external standard doesn&rsquo;t apply only to high school students. There are a multitude of other areas in life, areas in which it is easy to reach a certain point that serves as a mental stopping point.</p>\n<p>This may help to account for people that find themselves in an unsatisfying job, wondering why they&rsquo;re unhappily stuck &ndash; based on the standards of salary and stability, the job could look fine. One level further, if meeting a standard is the sole basis of effort, then the job certainly could be done &ndash; but without creativity or innovation.&nbsp;</p>\n<p>If the goal becomes to reach a certain average, then you could go checkmark, checkmark, checkmark down the row of criteria, without really getting anywhere, or doing anything meaningful. Who creates those standards in the first place? Are they actually a good measure of effectiveness, usefulness, or mastery? Basing work and effort on external stimulus will not compare to having the internal source of motivation, desire, or&nbsp;<a href=\"/lw/nb/something_to_protect/\">cause</a>.</p>\n<p>One last note: the TED talk and this post have focused on the concept of hard work, or \"grit.\" It is worth pointing out that there is a difference between just working hard, possibly ineffectively and working smarter. It doesn't help to do the same thing over and over again and wonder why the results aren't getting better. Real improvement takes some reflection - identifying weak areas, prioritizing, etc. Though this is probably commonly known, it is a vital distinction to keep in mind with the subject this discussion.</p>\n<p>Edit: The links to this&nbsp;<a href=\"http://www.ted.com/talks/angela_lee_duckworth_the_key_to_success_grit.html\">TED talk</a>&nbsp;(and an&nbsp;<a href=\"http://www.youtube.com/watch?v=qaeFnxSfSC4\">older version here</a>) were originally featured at the very beginning of the post. Since the talk wasn't relevant in any way, except for a single remark, I removed the links from the prominent focus to increase clarity.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NzKrw5eXeJDBfgwbJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "22595", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SGR4GxFK7KmW7ckCB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-15T05:43:05.131Z", "modifiedAt": null, "url": null, "title": "How to Build a Community", "slug": "how-to-build-a-community", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.979Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/87GCpuFr8ywGqqXkP/how-to-build-a-community", "pageUrlRelative": "/posts/87GCpuFr8ywGqqXkP/how-to-build-a-community", "linkUrl": "https://www.lesswrong.com/posts/87GCpuFr8ywGqqXkP/how-to-build-a-community", "postedAtFormatted": "Wednesday, May 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Build%20a%20Community&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Build%20a%20Community%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F87GCpuFr8ywGqqXkP%2Fhow-to-build-a-community%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Build%20a%20Community%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F87GCpuFr8ywGqqXkP%2Fhow-to-build-a-community", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F87GCpuFr8ywGqqXkP%2Fhow-to-build-a-community", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2463, "htmlBody": "<p>I've noticed that quite a few people are interested in fostering communities -- both creating communities and improving them to make them work together. &nbsp;But how do we go about actually doing this? &nbsp;What's there to community that we can foster and build upon? &nbsp;What makes a community thrive, and how do we take advantage of this to make and/or improve communities?</p>\n<p>To answer these questions, I turned to two books:</p>\n<p>The first is <a href=\"http://www.amazon.com/dp/0385525761\"><strong>The Penguin and The Leviathan: How Cooperation Triumphs Over Self-Interest</strong></a>&nbsp;by Yochai Benkler. &nbsp;Benkler, in writing about cooperative systems (Penguins, named after the Linux Penguin) and hierarchical systems (Leviathans, named after Thomas Hobbes's The Leviathan), studies the psychology, economics, and political science of cooperation and helps explain what makes communities stick.</p>\n<p>The second is <a href=\"http://www.amazon.com/dp/1118143302\"><strong>Liars and Outliers: Enabling the Trust that Society Needs to Thrive</strong></a>&nbsp;by Bruce Schneier. &nbsp;Schneier studies trust and cooperation from a dizzying variety of sciences (psychology, biology, economics, anthropology, computer science, and political science). &nbsp;Schneier's ultimate game is figuring out what is preventing society from falling apart, and that can be applied to building communities.</p>\n<p>Let's see what they got.</p>\n<p>&nbsp;</p>\n<h2>Communities Need Cooperation</h2>\n<p>Schneier and Benkler both paint a view of human nature that is different than what is commonly thought, but what has emerged from the sciences: People are both self-interested and other-interested, different people will have different balances of each, and within each person these two goals can often conflict. &nbsp;Additionally, the \"other-interested\" aspect can be multiple and occasionally conflicting allegiances, such as to one's family, to one's neighborhood, to one's country, to one's venture philanthropy club, etc.</p>\n<p>What's unique to all communities is that they involve people who have set aside some of their immediate self-interest to work together. &nbsp;For instance, when we work together in a group, I definitely don't beat you over the head and steal your lunch money, and I don't usually attempt to free ride and get you to do the group work for me, but we mutually work to solve communal problems and share in the benefits of community.</p>\n<h4>Public Goods and Free Riders</h4>\n<p>An example of how psychology has sought to simplify and simulate a community is through what's called \"The Public Goods Game\". &nbsp;In this game, a group of about ten participants are each sat down, and given $10 each to start with. &nbsp;The game is then played for several rounds, and in each round all participants get to put a certain secret amount of their money into a collective pot. &nbsp;The experimenters then look at the pot, double the amount of money inside it, and redistribute the result evenly to all the players. &nbsp;For added bonus, the experimenters inform all participants that they get to walk away with their winnings after the game is over.</p>\n<p>If everyone went perfectly with the community, each player would see their money double each round. &nbsp;But the wrinkle is that if people don't contribute at all to the pot, then they stand to gain even more money from the results of everyone else's contributions. &nbsp;This is called the free rider problem: there is a tension between wanting to contribute to the pot for the good of yourself and the good of the group as a whole and refraining from contributing so that you benefit even more.</p>\n<h4>The Free Rider Problem and The Collective Action Problem</h4>\n<p>But the tension can result in further disaster, for imagine everyone decides to be a free rider and defect from the group -- now, no money goes in the pot at all, and everyone ends with the $10 they start with. &nbsp;This gets worse when we imagine some other real-life scenarios -- for instance, that of fishermen in a lake.</p>\n<p>The fishermen can either choose to fish normally or overfish. &nbsp;If all the fishermen overfish, they stand to deplete the lake and all fishermen lose their jobs. &nbsp;However, if just a few fishermen overfish, they get the benefit of added fish to sell, and the lake can handle the slight increase in load. &nbsp;So this tension is to be the fisherman that wins most by personally overfishing, while not collectively depleting the entire lake. &nbsp;Such problems are called collective action problems -- people do well individually by defecting but do worse collectively if everyone defects. &nbsp;The result of a collective action problem ending in disaster is called the tragedy of the commons.</p>\n<h4>The Community Solution</h4>\n<p>So what's the solution to these problems? &nbsp;Benkler proposes two models for dealing with them -- employing the Leviathan and placing lots of regulations on overfishing and enforcing them with strict punishments, or employing the Penguin and creating a community that deals with these problems collectively and in a self-policing way.</p>\n<p>It turns out that certain problems are best dealt with differing combinations of Leviathan and Penguin models, but most problems need lots of community just because it can be difficult to figure out who is going against the community, and communities have more freedom for their participants. &nbsp;At the same time, if there are too many would-be defectors a community can never get off the ground.</p>\n<p>Communities need cooperation to work. &nbsp;So how can we get this cooperation to fly?</p>\n<p>&nbsp;</p>\n<h2>The Four Pressures of Cooperation</h2>\n<p>Bruce Schneier notes that normally we don't think through these free rider problems and try to scheme our way through them -- we just cooperate, instinctively. &nbsp;We don't assume people will rip us off, and we usually don't rip other people off -- that's just how we are. &nbsp;But why? &nbsp;Schneier suggests that cooperation can be fostered and maintained through four different pressures, though differing kinds and amounts of pressure apply to different situations, and getting the balance of pressures right is a key part of his book:</p>\n<p><strong>1.) Moral Pressures:</strong>&nbsp;Many, but not all of us, have various moral feelings that lead us to want to cooperate. &nbsp;It could be as easy as feeling incredibly guilty when we defect against our friends, or as complex as subscribing to an abstract principle of justice. &nbsp;For most of us, it's a general feeling that cooperating is the \"right thing to do\" and defecting for our own personal self-interest is \"wrong\", and we just don't want to do it. &nbsp;Schneier and Benkler both find that moral pressures compel cooperation a surprising amount of the time.</p>\n<p><strong>2.) Reputational Pressures:</strong>&nbsp;Another part about living in a community for a long time is that you have a reputation to live by. &nbsp;Defect against the community and you may win a few times, but then people start to notice and start working to stop you. &nbsp;They might refuse you friendship or other things you want, or even kick you out of the community altogether! &nbsp;Benkler finds that many communities can thrive on reputation alone, like eBay, Amazon, or Reddit.</p>\n<p><strong>3.) Institutional Pressures:</strong>&nbsp;Morals and reputation aren't the end of it though; many communities make specific, codified norms and enforce them with specific, codified punishments. &nbsp;These pressures are laws, and the fear of breaking the law, being caught, and getting the punishment can often further spur cooperation. &nbsp;Best yet, the community can often get together and agree to these norms, realizing it is in their individual benefit to force themselves and the rest of the community to play along, as to avoid tragedies of the commons.</p>\n<p><strong>4.) Security Pressures:</strong>&nbsp;Lastly, there are always going to be a few people who put morals, reputation, and laws aside and try to defect anyway. &nbsp;For these, we hope to stop them in their tracks or make their jobs more difficult, by using complex security systems. &nbsp;It can be as simple as a security camera or anti-theft radio, or as complex as Fort Knox. &nbsp;Security is a double plan: it first attempts to raise the costs of defection; by making it physically harder to defect, one is less tempted to do so. &nbsp;It then attempts to better catch and apprehend those who still try.</p>\n<p>&nbsp;</p>\n<h2>Your Reason for Joining; Your Reason for Staying</h2>\n<p>Remember these pressures don't all work for the same problems -- it may be proper to use security and institutional pressures to stop someone from overfishing, but not from intentionally cutting the cake so they get to eat the bigger slice. &nbsp;Moral and reputational pressures seem to be more encompassing, but they are also more easily defeated -- people with less of a moral compass can often wander from community to community, wrecking small amounts of havoc and never getting caught or punished.</p>\n<p>Benkler suggests another way to get people to buy into a community and not defect against it -- make it clear that being part of the community is something they really want. &nbsp;Whether your joining a community or forced into one (family, country, etc.), the community will be more likely to thrive.</p>\n<h4>Four Ways to Bond</h4>\n<p>But why might one want to join or stay in a community? &nbsp;For many, the answer is the intangibles -- they feel a sense of belonging, friendship, and group cohesion that creates an empathetic attachment and makes people want to play by the rules of the group. &nbsp;For others, the answer is the tangibles -- the group may have a stated mission statement that is important to the person, or belonging in the group might confer a specific benefit. &nbsp;People might even belong for a mix of tangibles and intangibles, plus a natural tendency to want to join groups.</p>\n<p>But how do we foster these bonds? &nbsp;Benkler has his own set of four things, suggesting that group identity can be fostered through a combination of four means:</p>\n<p><strong>1.) Fairness:</strong> The community needs to be fair -- people need to all contribute more or less equally, or at least have genuine intentions to put in equal effort, and the benefits of the group need to be spread among all participants more or less evenly, or in a fair proportion to how much the participant puts in.</p>\n<p><strong>2.) Autonomy:</strong>&nbsp;The community needs to not demand too much, and make sure to compensate quickly and generously for special sacrifices. &nbsp;There are inherent costs to joining and staying with a group, and costs for cooperating with the group -- one doesn't just give up the self-interested benefits of defection, but rather must pay additional costs to maintain their group status. &nbsp;Being aware of and addressing these costs are important. &nbsp;In short, the group must respect their members as individuals.</p>\n<p><strong>3.) Democracy:</strong>&nbsp;The community also needs to accept (with fairness and autonomy) the input of all the members. &nbsp;Group norms should be developed by a vote, with weight given on building consensus as much as possible, and with understanding the reasons why people might not like the consensus. &nbsp;Not only does having input make it more likely people's preferences will be taken into account, lowering the costs of cooperation, but having input makes people feel more group cohesion and belonging.</p>\n<p><strong>4.) Communication:</strong>&nbsp;During times when formal votes aren't taken, the community also needs to be consistently (but not constantly) talking about how the group is doing, and checking in with members who might be feeling left out. &nbsp;Just like democracy, group cohesion is built through communication, and communication lowers the costs of cooperation. &nbsp;It's best when resolving disputes is not dictatorial, like in a court of law, but rather cooperative, like in an arbitration.</p>\n<p>&nbsp;</p>\n<h2>Looking Back to the Public Goods Game</h2>\n<p>To demonstrate these four points, Benkler draws on many real-world examples, such as policies of various companies, and interactions on the internet. &nbsp;He also draws on returning back to our simple-community-in-the-lab, the Public Goods Game, for additional confirmation, and its worth seeing how these things play out.</p>\n<p>In the original Public Goods game, contributions to the pot were made anonymously and no-one was allowed to talk or communicate. &nbsp;Typically, a fair amount of people would cooperate in the beginning (generally, people contribute about 70% of their share), but starts to drop as people see that others aren't contributing. &nbsp;They start to feel like suckers, and the fairness starts to kick in.</p>\n<h4>A Different Game</h4>\n<p>However, variants of the Public Goods game offer ways out. &nbsp;When participants were allowed to talk to each other, contributions rose (communication). &nbsp;Likewise, when participants were allowed to use some of their money to punish those who didn't contribute (say, pay $3 to prevent someone from getting their share this round if they didn't cooperate last round), people would do so. &nbsp;</p>\n<p>Even the simple act of making the contributions public increased cooperation, drawing on reputation. &nbsp;Sometimes small fines were imposed on those who didn't cooperate (institutional pressures) which brought up cooperation, and these fines worked especially well when the group got to vote on how high they would be (democracy).</p>\n<p>Lastly, helping frame the game would help -- those who were told they were taking place in a \"Community Game\" were far more likely to contribute to the pot and keep contributing than those who were told they were taking place in a \"Wall Street Game\". &nbsp;By reminding people they are in a community, people thought more about their community norms, and felt more group cohesion, and were more likely to trust others.</p>\n<p>&nbsp;</p>\n<h2>Conclusions</h2>\n<p>Ultimately, creating communities is all about fostering cooperation, and you foster cooperation by ensuring that there is mutual trust and some sort of way to prevent defectors from taking advantage of the system. &nbsp;People often naturally don't want to defect, but will do so if they think others will take advantage of them first.</p>\n<h4>Social Pressures</h4>\n<p>But how do we foster this trust? &nbsp;The first step is to make use of our social pressures when and to the amount that's appropriate -- relying on empathetic and moral norms, reputation, institutionalized laws, and security systems -- and being sure to get the balance right. &nbsp;For small communities, this probably just needs to be a set of agreed norms, and ensuring that the norms are properly and responsibly enforced.</p>\n<h4>The Benefits of Joining</h4>\n<p>The second part is while implementing the first step, we should keep in mind why people are joining or staying in the first place, and make sure to provide a community where the benefits of joining -- both the tangibles and intangibles -- are present and apparent. &nbsp;We should acknowledge the costs of cooperating, and make sure the benefits are there to foster group loyalty and belonging.</p>\n<h4>An Effective Community</h4>\n<p>While implementing, it's important to keep in mind that communities should also be fair, respect the autonomy and individuality of the members, give members input through democracy, and foster lots of communication about how things are going. &nbsp;We should also keep a keen eye to how things are framed, while not going overboard on it or lying.</p>\n<h4>The End Reward</h4>\n<p>But when we accomplish communities, the rewards are pretty great -- not only do we avoid free riders and the tragedy of the commons, but we ourselves get to take advantage of communities that are more productive than the individuals alone, and secure the feelings of belonging to a group we enjoy.</p>\n<p>-</p>\n<address><span style=\"font-weight: normal;\"><span style=\"font-family: mceinline;\">Also <a href=\"http://www.everydayutilitarian.com/essays/how-to-build-a-community/\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</span></span></address>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "87GCpuFr8ywGqqXkP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 19, "extendedScore": null, "score": 1.1997698605673385e-06, "legacy": true, "legacyId": "22598", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I've noticed that quite a few people are interested in fostering communities -- both creating communities and improving them to make them work together. &nbsp;But how do we go about actually doing this? &nbsp;What's there to community that we can foster and build upon? &nbsp;What makes a community thrive, and how do we take advantage of this to make and/or improve communities?</p>\n<p>To answer these questions, I turned to two books:</p>\n<p>The first is <a href=\"http://www.amazon.com/dp/0385525761\"><strong>The Penguin and The Leviathan: How Cooperation Triumphs Over Self-Interest</strong></a>&nbsp;by Yochai Benkler. &nbsp;Benkler, in writing about cooperative systems (Penguins, named after the Linux Penguin) and hierarchical systems (Leviathans, named after Thomas Hobbes's The Leviathan), studies the psychology, economics, and political science of cooperation and helps explain what makes communities stick.</p>\n<p>The second is <a href=\"http://www.amazon.com/dp/1118143302\"><strong>Liars and Outliers: Enabling the Trust that Society Needs to Thrive</strong></a>&nbsp;by Bruce Schneier. &nbsp;Schneier studies trust and cooperation from a dizzying variety of sciences (psychology, biology, economics, anthropology, computer science, and political science). &nbsp;Schneier's ultimate game is figuring out what is preventing society from falling apart, and that can be applied to building communities.</p>\n<p>Let's see what they got.</p>\n<p>&nbsp;</p>\n<h2 id=\"Communities_Need_Cooperation\">Communities Need Cooperation</h2>\n<p>Schneier and Benkler both paint a view of human nature that is different than what is commonly thought, but what has emerged from the sciences: People are both self-interested and other-interested, different people will have different balances of each, and within each person these two goals can often conflict. &nbsp;Additionally, the \"other-interested\" aspect can be multiple and occasionally conflicting allegiances, such as to one's family, to one's neighborhood, to one's country, to one's venture philanthropy club, etc.</p>\n<p>What's unique to all communities is that they involve people who have set aside some of their immediate self-interest to work together. &nbsp;For instance, when we work together in a group, I definitely don't beat you over the head and steal your lunch money, and I don't usually attempt to free ride and get you to do the group work for me, but we mutually work to solve communal problems and share in the benefits of community.</p>\n<h4 id=\"Public_Goods_and_Free_Riders\">Public Goods and Free Riders</h4>\n<p>An example of how psychology has sought to simplify and simulate a community is through what's called \"The Public Goods Game\". &nbsp;In this game, a group of about ten participants are each sat down, and given $10 each to start with. &nbsp;The game is then played for several rounds, and in each round all participants get to put a certain secret amount of their money into a collective pot. &nbsp;The experimenters then look at the pot, double the amount of money inside it, and redistribute the result evenly to all the players. &nbsp;For added bonus, the experimenters inform all participants that they get to walk away with their winnings after the game is over.</p>\n<p>If everyone went perfectly with the community, each player would see their money double each round. &nbsp;But the wrinkle is that if people don't contribute at all to the pot, then they stand to gain even more money from the results of everyone else's contributions. &nbsp;This is called the free rider problem: there is a tension between wanting to contribute to the pot for the good of yourself and the good of the group as a whole and refraining from contributing so that you benefit even more.</p>\n<h4 id=\"The_Free_Rider_Problem_and_The_Collective_Action_Problem\">The Free Rider Problem and The Collective Action Problem</h4>\n<p>But the tension can result in further disaster, for imagine everyone decides to be a free rider and defect from the group -- now, no money goes in the pot at all, and everyone ends with the $10 they start with. &nbsp;This gets worse when we imagine some other real-life scenarios -- for instance, that of fishermen in a lake.</p>\n<p>The fishermen can either choose to fish normally or overfish. &nbsp;If all the fishermen overfish, they stand to deplete the lake and all fishermen lose their jobs. &nbsp;However, if just a few fishermen overfish, they get the benefit of added fish to sell, and the lake can handle the slight increase in load. &nbsp;So this tension is to be the fisherman that wins most by personally overfishing, while not collectively depleting the entire lake. &nbsp;Such problems are called collective action problems -- people do well individually by defecting but do worse collectively if everyone defects. &nbsp;The result of a collective action problem ending in disaster is called the tragedy of the commons.</p>\n<h4 id=\"The_Community_Solution\">The Community Solution</h4>\n<p>So what's the solution to these problems? &nbsp;Benkler proposes two models for dealing with them -- employing the Leviathan and placing lots of regulations on overfishing and enforcing them with strict punishments, or employing the Penguin and creating a community that deals with these problems collectively and in a self-policing way.</p>\n<p>It turns out that certain problems are best dealt with differing combinations of Leviathan and Penguin models, but most problems need lots of community just because it can be difficult to figure out who is going against the community, and communities have more freedom for their participants. &nbsp;At the same time, if there are too many would-be defectors a community can never get off the ground.</p>\n<p>Communities need cooperation to work. &nbsp;So how can we get this cooperation to fly?</p>\n<p>&nbsp;</p>\n<h2 id=\"The_Four_Pressures_of_Cooperation\">The Four Pressures of Cooperation</h2>\n<p>Bruce Schneier notes that normally we don't think through these free rider problems and try to scheme our way through them -- we just cooperate, instinctively. &nbsp;We don't assume people will rip us off, and we usually don't rip other people off -- that's just how we are. &nbsp;But why? &nbsp;Schneier suggests that cooperation can be fostered and maintained through four different pressures, though differing kinds and amounts of pressure apply to different situations, and getting the balance of pressures right is a key part of his book:</p>\n<p><strong>1.) Moral Pressures:</strong>&nbsp;Many, but not all of us, have various moral feelings that lead us to want to cooperate. &nbsp;It could be as easy as feeling incredibly guilty when we defect against our friends, or as complex as subscribing to an abstract principle of justice. &nbsp;For most of us, it's a general feeling that cooperating is the \"right thing to do\" and defecting for our own personal self-interest is \"wrong\", and we just don't want to do it. &nbsp;Schneier and Benkler both find that moral pressures compel cooperation a surprising amount of the time.</p>\n<p><strong>2.) Reputational Pressures:</strong>&nbsp;Another part about living in a community for a long time is that you have a reputation to live by. &nbsp;Defect against the community and you may win a few times, but then people start to notice and start working to stop you. &nbsp;They might refuse you friendship or other things you want, or even kick you out of the community altogether! &nbsp;Benkler finds that many communities can thrive on reputation alone, like eBay, Amazon, or Reddit.</p>\n<p><strong>3.) Institutional Pressures:</strong>&nbsp;Morals and reputation aren't the end of it though; many communities make specific, codified norms and enforce them with specific, codified punishments. &nbsp;These pressures are laws, and the fear of breaking the law, being caught, and getting the punishment can often further spur cooperation. &nbsp;Best yet, the community can often get together and agree to these norms, realizing it is in their individual benefit to force themselves and the rest of the community to play along, as to avoid tragedies of the commons.</p>\n<p><strong>4.) Security Pressures:</strong>&nbsp;Lastly, there are always going to be a few people who put morals, reputation, and laws aside and try to defect anyway. &nbsp;For these, we hope to stop them in their tracks or make their jobs more difficult, by using complex security systems. &nbsp;It can be as simple as a security camera or anti-theft radio, or as complex as Fort Knox. &nbsp;Security is a double plan: it first attempts to raise the costs of defection; by making it physically harder to defect, one is less tempted to do so. &nbsp;It then attempts to better catch and apprehend those who still try.</p>\n<p>&nbsp;</p>\n<h2 id=\"Your_Reason_for_Joining__Your_Reason_for_Staying\">Your Reason for Joining; Your Reason for Staying</h2>\n<p>Remember these pressures don't all work for the same problems -- it may be proper to use security and institutional pressures to stop someone from overfishing, but not from intentionally cutting the cake so they get to eat the bigger slice. &nbsp;Moral and reputational pressures seem to be more encompassing, but they are also more easily defeated -- people with less of a moral compass can often wander from community to community, wrecking small amounts of havoc and never getting caught or punished.</p>\n<p>Benkler suggests another way to get people to buy into a community and not defect against it -- make it clear that being part of the community is something they really want. &nbsp;Whether your joining a community or forced into one (family, country, etc.), the community will be more likely to thrive.</p>\n<h4 id=\"Four_Ways_to_Bond\">Four Ways to Bond</h4>\n<p>But why might one want to join or stay in a community? &nbsp;For many, the answer is the intangibles -- they feel a sense of belonging, friendship, and group cohesion that creates an empathetic attachment and makes people want to play by the rules of the group. &nbsp;For others, the answer is the tangibles -- the group may have a stated mission statement that is important to the person, or belonging in the group might confer a specific benefit. &nbsp;People might even belong for a mix of tangibles and intangibles, plus a natural tendency to want to join groups.</p>\n<p>But how do we foster these bonds? &nbsp;Benkler has his own set of four things, suggesting that group identity can be fostered through a combination of four means:</p>\n<p><strong>1.) Fairness:</strong> The community needs to be fair -- people need to all contribute more or less equally, or at least have genuine intentions to put in equal effort, and the benefits of the group need to be spread among all participants more or less evenly, or in a fair proportion to how much the participant puts in.</p>\n<p><strong>2.) Autonomy:</strong>&nbsp;The community needs to not demand too much, and make sure to compensate quickly and generously for special sacrifices. &nbsp;There are inherent costs to joining and staying with a group, and costs for cooperating with the group -- one doesn't just give up the self-interested benefits of defection, but rather must pay additional costs to maintain their group status. &nbsp;Being aware of and addressing these costs are important. &nbsp;In short, the group must respect their members as individuals.</p>\n<p><strong>3.) Democracy:</strong>&nbsp;The community also needs to accept (with fairness and autonomy) the input of all the members. &nbsp;Group norms should be developed by a vote, with weight given on building consensus as much as possible, and with understanding the reasons why people might not like the consensus. &nbsp;Not only does having input make it more likely people's preferences will be taken into account, lowering the costs of cooperation, but having input makes people feel more group cohesion and belonging.</p>\n<p><strong>4.) Communication:</strong>&nbsp;During times when formal votes aren't taken, the community also needs to be consistently (but not constantly) talking about how the group is doing, and checking in with members who might be feeling left out. &nbsp;Just like democracy, group cohesion is built through communication, and communication lowers the costs of cooperation. &nbsp;It's best when resolving disputes is not dictatorial, like in a court of law, but rather cooperative, like in an arbitration.</p>\n<p>&nbsp;</p>\n<h2 id=\"Looking_Back_to_the_Public_Goods_Game\">Looking Back to the Public Goods Game</h2>\n<p>To demonstrate these four points, Benkler draws on many real-world examples, such as policies of various companies, and interactions on the internet. &nbsp;He also draws on returning back to our simple-community-in-the-lab, the Public Goods Game, for additional confirmation, and its worth seeing how these things play out.</p>\n<p>In the original Public Goods game, contributions to the pot were made anonymously and no-one was allowed to talk or communicate. &nbsp;Typically, a fair amount of people would cooperate in the beginning (generally, people contribute about 70% of their share), but starts to drop as people see that others aren't contributing. &nbsp;They start to feel like suckers, and the fairness starts to kick in.</p>\n<h4 id=\"A_Different_Game\">A Different Game</h4>\n<p>However, variants of the Public Goods game offer ways out. &nbsp;When participants were allowed to talk to each other, contributions rose (communication). &nbsp;Likewise, when participants were allowed to use some of their money to punish those who didn't contribute (say, pay $3 to prevent someone from getting their share this round if they didn't cooperate last round), people would do so. &nbsp;</p>\n<p>Even the simple act of making the contributions public increased cooperation, drawing on reputation. &nbsp;Sometimes small fines were imposed on those who didn't cooperate (institutional pressures) which brought up cooperation, and these fines worked especially well when the group got to vote on how high they would be (democracy).</p>\n<p>Lastly, helping frame the game would help -- those who were told they were taking place in a \"Community Game\" were far more likely to contribute to the pot and keep contributing than those who were told they were taking place in a \"Wall Street Game\". &nbsp;By reminding people they are in a community, people thought more about their community norms, and felt more group cohesion, and were more likely to trust others.</p>\n<p>&nbsp;</p>\n<h2 id=\"Conclusions\">Conclusions</h2>\n<p>Ultimately, creating communities is all about fostering cooperation, and you foster cooperation by ensuring that there is mutual trust and some sort of way to prevent defectors from taking advantage of the system. &nbsp;People often naturally don't want to defect, but will do so if they think others will take advantage of them first.</p>\n<h4 id=\"Social_Pressures\">Social Pressures</h4>\n<p>But how do we foster this trust? &nbsp;The first step is to make use of our social pressures when and to the amount that's appropriate -- relying on empathetic and moral norms, reputation, institutionalized laws, and security systems -- and being sure to get the balance right. &nbsp;For small communities, this probably just needs to be a set of agreed norms, and ensuring that the norms are properly and responsibly enforced.</p>\n<h4 id=\"The_Benefits_of_Joining\">The Benefits of Joining</h4>\n<p>The second part is while implementing the first step, we should keep in mind why people are joining or staying in the first place, and make sure to provide a community where the benefits of joining -- both the tangibles and intangibles -- are present and apparent. &nbsp;We should acknowledge the costs of cooperating, and make sure the benefits are there to foster group loyalty and belonging.</p>\n<h4 id=\"An_Effective_Community\">An Effective Community</h4>\n<p>While implementing, it's important to keep in mind that communities should also be fair, respect the autonomy and individuality of the members, give members input through democracy, and foster lots of communication about how things are going. &nbsp;We should also keep a keen eye to how things are framed, while not going overboard on it or lying.</p>\n<h4 id=\"The_End_Reward\">The End Reward</h4>\n<p>But when we accomplish communities, the rewards are pretty great -- not only do we avoid free riders and the tragedy of the commons, but we ourselves get to take advantage of communities that are more productive than the individuals alone, and secure the feelings of belonging to a group we enjoy.</p>\n<p>-</p>\n<address><span style=\"font-weight: normal;\"><span style=\"font-family: mceinline;\">Also <a href=\"http://www.everydayutilitarian.com/essays/how-to-build-a-community/\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</span></span></address>\n<p>&nbsp;</p>", "sections": [{"title": "Communities Need Cooperation", "anchor": "Communities_Need_Cooperation", "level": 1}, {"title": "Public Goods and Free Riders", "anchor": "Public_Goods_and_Free_Riders", "level": 2}, {"title": "The Free Rider Problem and The Collective Action Problem", "anchor": "The_Free_Rider_Problem_and_The_Collective_Action_Problem", "level": 2}, {"title": "The Community Solution", "anchor": "The_Community_Solution", "level": 2}, {"title": "The Four Pressures of Cooperation", "anchor": "The_Four_Pressures_of_Cooperation", "level": 1}, {"title": "Your Reason for Joining; Your Reason for Staying", "anchor": "Your_Reason_for_Joining__Your_Reason_for_Staying", "level": 1}, {"title": "Four Ways to Bond", "anchor": "Four_Ways_to_Bond", "level": 2}, {"title": "Looking Back to the Public Goods Game", "anchor": "Looking_Back_to_the_Public_Goods_Game", "level": 1}, {"title": "A Different Game", "anchor": "A_Different_Game", "level": 2}, {"title": "Conclusions", "anchor": "Conclusions", "level": 1}, {"title": "Social Pressures", "anchor": "Social_Pressures", "level": 2}, {"title": "The Benefits of Joining", "anchor": "The_Benefits_of_Joining", "level": 2}, {"title": "An Effective Community", "anchor": "An_Effective_Community", "level": 2}, {"title": "The End Reward", "anchor": "The_End_Reward", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "229 comments"}], "headingsCount": 16}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 229, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-15T07:38:18.403Z", "modifiedAt": null, "url": null, "title": "Kevin Drum's Article about AI and Technology", "slug": "kevin-drum-s-article-about-ai-and-technology", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:50.417Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "knb", "createdAt": "2009-02-27T04:55:09.459Z", "isAdmin": false, "displayName": "knb"}, "userId": "YEwEAL5Mu6YxaX4rD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2t8NsSSRuNWw39TPB/kevin-drum-s-article-about-ai-and-technology", "pageUrlRelative": "/posts/2t8NsSSRuNWw39TPB/kevin-drum-s-article-about-ai-and-technology", "linkUrl": "https://www.lesswrong.com/posts/2t8NsSSRuNWw39TPB/kevin-drum-s-article-about-ai-and-technology", "postedAtFormatted": "Wednesday, May 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Kevin%20Drum's%20Article%20about%20AI%20and%20Technology&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKevin%20Drum's%20Article%20about%20AI%20and%20Technology%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2t8NsSSRuNWw39TPB%2Fkevin-drum-s-article-about-ai-and-technology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Kevin%20Drum's%20Article%20about%20AI%20and%20Technology%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2t8NsSSRuNWw39TPB%2Fkevin-drum-s-article-about-ai-and-technology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2t8NsSSRuNWw39TPB%2Fkevin-drum-s-article-about-ai-and-technology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 699, "htmlBody": "<p>Kevin Drum has an <a href=\"http://www.motherjones.com/media/2013/05/robots-artificial-intelligence-jobs-automation\">article in Mother Jones</a> about AI and Moore's Law:</p>\n<blockquote>\n<p>THIS IS A STORY ABOUT THE FUTURE. Not the unhappy future, the one where climate change turns the planet into a cinder or we all die in a global nuclear war. This is the happy version. It's the one where computers keep getting smarter and smarter, and clever engineers keep building better and better robots. By 2040, computers the size of a softball are as smart as human beings. Smarter, in fact. Plus they're computers: They never get tired, they're never ill-tempered, they never make mistakes, and they have instant access to all of human knowledge.</p>\n<p>The result is paradise. Global warming is a problem of the past because computers have figured out how to generate limitless amounts of green energy and intelligent robots have tirelessly built the infrastructure to deliver it to our homes. No one needs to work anymore. Robots can do everything humans can do, and they do it uncomplainingly, 24 hours a day. Some things remain scarce&mdash;beachfront property in Malibu, original Rembrandts&mdash;but thanks to super-efficient use of natural resources and massive recycling, scarcity of ordinary consumer goods is a thing of the past. Our days are spent however we please, perhaps in study, perhaps playing video games. It's up to us.</p>\n</blockquote>\n<p>Although he only mentions consumer goods, Drum presumably means that scarcity will end for services <em>and </em>consumer goods. If scarcity only ended for consumer goods, people would still have to work (most jobs are currently in the services economy).&nbsp;</p>\n<p>Drum explains that our linear-thinking brains don't intuitively grasp exponential systems like Moore's law.&nbsp;</p>\n<blockquote>\n<p>Suppose it's 1940 and Lake Michigan has (somehow) been emptied. Your job is to fill it up using the following rule: To start off, you can add one fluid ounce of water to the lake bed. Eighteen months later, you can add two. In another 18 months, you can add four ounces. And so on. Obviously this is going to take a while.</p>\n<p>By 1950, you have added around a gallon of water. But you keep soldiering on. By 1960, you have a bit more than 150 gallons. By 1970, you have 16,000 gallons, about as much as an average suburban swimming pool.</p>\n<p>At this point it's been 30 years, and even though 16,000 gallons is a fair amount of water, it's nothing compared to the size of Lake Michigan. To the naked eye you've made no progress at all.</p>\n<p>So let's skip all the way ahead to 2000. Still nothing. You have&mdash;maybe&mdash;a slight sheen on the lake floor. How about 2010? You have a few inches of water here and there. This is ridiculous. It's now been 70 years and you still don't have enough water to float a goldfish. Surely this task is futile?</p>\n<p>But wait. Just as you're about to give up, things suddenly change. By 2020, you have about 40 feet of water. And by 2025 you're done. After 70 years you had nothing. Fifteen years later, the job was finished.</p>\n</blockquote>\n<p>He also includes this nice animated .gif which illustrates the principle very clearly.&nbsp;</p>\n<p><img src=\"http://assets.motherjones.com/media/2013/05/LakeMichigan-Final3.gif\" alt=\"\" width=\"629\" height=\"354\" /></p>\n<p>Drum continues by talking about possible economic ramifications.</p>\n<blockquote>\n<p>Until a decade ago, the share of total national income going to workers was pretty stable at around 70 percent, while the share going to capital&mdash;mainly corporate profits and returns on financial investments&mdash;made up the other 30 percent. More recently, though, those shares have started to change. Slowly but steadily, labor's share of total national income has gone down, while the share going to capital owners has gone up. The most obvious effect of this is the skyrocketing wealth of the top 1 percent, due mostly to huge increases in capital gains and investment income.</p>\n</blockquote>\n<p>Drum says the share of (US) national income going to workers was stable until about a decade ago. I think the graph he links to shows the worker's share has been declining since approximately the late 1960s/early 1970s. This is about the time US immigration levels started increasing (which raises returns to capital and lowers native worker wages).&nbsp;</p>\n<p><img src=\"http://blogs.reuters.com/felix-salmon/files/2012/09/2012-13-1w.gif\" alt=\"\" width=\"420\" height=\"412\" /></p>\n<p>The rest of Drum's piece isn't terribly interesting, but it is good to see mainstream pundits talking about these topics.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2t8NsSSRuNWw39TPB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 29, "extendedScore": null, "score": 1.1998534032589145e-06, "legacy": true, "legacyId": "22600", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-15T10:41:59.215Z", "modifiedAt": null, "url": null, "title": "Crash problems for total futarchy", "slug": "crash-problems-for-total-futarchy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:06.144Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3MqzX86KBpRsCWMFD/crash-problems-for-total-futarchy", "pageUrlRelative": "/posts/3MqzX86KBpRsCWMFD/crash-problems-for-total-futarchy", "linkUrl": "https://www.lesswrong.com/posts/3MqzX86KBpRsCWMFD/crash-problems-for-total-futarchy", "postedAtFormatted": "Wednesday, May 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Crash%20problems%20for%20total%20futarchy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACrash%20problems%20for%20total%20futarchy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MqzX86KBpRsCWMFD%2Fcrash-problems-for-total-futarchy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Crash%20problems%20for%20total%20futarchy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MqzX86KBpRsCWMFD%2Fcrash-problems-for-total-futarchy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3MqzX86KBpRsCWMFD%2Fcrash-problems-for-total-futarchy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 225, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Futarchy\">Futarchy</a> holds great promise for dealing with all the morass of <a href=\"http://en.wikipedia.org/wiki/List_of_biases_in_judgment_and_decision_making\">poor decision making</a> in our governments and corporations. For those who haven't heard of it, the main concept is to use betting markets, where people place bets on the expected outcome of a policy, and the decision-makers choose the policy that the market decrees is most likely to achieve their desired outcomes. Robin Hanson&nbsp;summarises&nbsp;it as \"<a href=\"http://hanson.gmu.edu/futarchy.html\">Vote Values, But Bet Beliefs</a>\".</p>\n<p>The approach, however, could lead to problems in a large financial crisis. When a large financial bubble bursts, many things change: liquidity, risk aversion, volatility, the competence of the average investor. If the betting markets are integrated into the general market (which they would be), then they would be affected in the same way. So at precisely the moment when decision makers need the best results, their main tools would be going haywire.</p>\n<p>This would be even worse if they'd been <a href=\"/r/discussion/lw/hey/the_autopilot_problem_driving_without_experience/\">depending</a> on the betting markets for their decisions, operating merely as overseers. At that point, they may have lost the ability to make effective decision entirely.</p>\n<p>Since isolating the betting markets from the swings of the rest of the market is unrealistic/impossible/stupid, we should aim for a mixed governance model - one where betting markets play an integral part, but where the deciders still have experience making their own decisions and&nbsp;overriding&nbsp;the betting markets with some regularity.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RGPpwYoCHrPNB86TW": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3MqzX86KBpRsCWMFD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "22602", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oGpcimKtzmg4narKK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-15T18:23:32.791Z", "modifiedAt": null, "url": null, "title": "[LINK] Prizes and open source for drug research (proposed, and some politics)", "slug": "link-prizes-and-open-source-for-drug-research-proposed-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.163Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/joetdsMKbkQjyKe4F/link-prizes-and-open-source-for-drug-research-proposed-and", "pageUrlRelative": "/posts/joetdsMKbkQjyKe4F/link-prizes-and-open-source-for-drug-research-proposed-and", "linkUrl": "https://www.lesswrong.com/posts/joetdsMKbkQjyKe4F/link-prizes-and-open-source-for-drug-research-proposed-and", "postedAtFormatted": "Wednesday, May 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Prizes%20and%20open%20source%20for%20drug%20research%20(proposed%2C%20and%20some%20politics)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Prizes%20and%20open%20source%20for%20drug%20research%20(proposed%2C%20and%20some%20politics)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoetdsMKbkQjyKe4F%2Flink-prizes-and-open-source-for-drug-research-proposed-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Prizes%20and%20open%20source%20for%20drug%20research%20(proposed%2C%20and%20some%20politics)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoetdsMKbkQjyKe4F%2Flink-prizes-and-open-source-for-drug-research-proposed-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjoetdsMKbkQjyKe4F%2Flink-prizes-and-open-source-for-drug-research-proposed-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 680, "htmlBody": "<p><a href=\"http://www.theatlantic.com/health/archive/2013/05/how-drug-companies-keep-medicine-out-of-reach/275853/?single_page=true\">Trying to get drug research to happen in spite of the drug companies</a>:</p>\n<p>The article also has rather a lot about US government opposition to the proposed treaty, which includes a requirement that member nations spend 0.01% of GDP annually on neglected diseases, and Bill Gates' opposition as well.</p>\n<p>Is there any reason why non-profits aren't doing drug research?</p>\n<blockquote>Love's idea suggests the use of cash prizes -- rather than patents -- to incentivize research; say, $2 billion for an effective therapeutic drug for Chagas disease. A cure, once developed, proven, and awarded a prize, would then exist as open-access intellectual property, with manufacturers around the world competing to produce the drug in the most cost effective manner. Implementing the idea, Love said, \"is effectively leveraging the power of the free market twice, once to produce the thing you want and then again to manufacture it as economically as possible.\" The concept is known as delinking.</blockquote>\n<p>*****</p>\n<blockquote>To combat the problem [of isolated research groups], the R&amp;D treaty would create an observatory, an open platform for researchers in disparate corners of the globe to pool data and coordinate their work. Grants given to fund their studies would come with provisions requiring that the research exist on that public, cloud-based observatory.</blockquote>\n<p>*****</p>\n<blockquote>Love's concept of delinking is outlined in a proposal for an R&amp;D treaty, which remains in limbo at the WHO in Geneva. It will have its fate decided in late May, at the annual World Health Assembly (WHA), the democratic forum of members states that governs the WHO.</blockquote>\n<p>*****</p>\n<blockquote>\n<p>Scannell worked as a consultant in the drug industry and then as an equity analyst, but quit last year to team up with Young once more at small biotech firm Scannell described as \"heretical.\" The company is called e-Therapeutics, and its approaching drug design via the pair's background in networks. \"Go back to how the drug industry says it discovers drugs. It looks for individual targets and then it optimizes drugs for high affinity binding on that target,\" Scannell said. The strategy, to Scannell's and Young's eyes, fails to take into account the complexity of biological systems.</p>\n<p>\"If you look at the structure of protein-protein interaction networks in cells, or the metabolic networks, these have been designed by evolution to be robust. You've got feedback loops, you've got parallel pathways, you've got redundancies. And what that says is, if you start your search process looking for an individual molecular component you want to perturb to influence a disease, probably evolution has designed your cell that, if you perturb that component, nothing is going to happen.\" Given the approach, Scannell said, \"Maybe it shouldn't be surprising that 95 percent of drugs going into clinical trials fail.\"</p>\n<p>\"Historically, you can make a very strong case that the way drugs were discovered when it was cheap and easy -- you can't do all this now because of the regulators, but some of this you might be able to do -- was essentially through broad phenotypic screening, very often in man,\" Scannell said. \"Drugs were regarded as potential tools that might do something useful, and then people essentially searched for uses for the tool. And today we do the exact opposite. Which is we say, we want something that cures Alzheimer's disease, let's design something that cures Alzheimer's disease, and frankly that just doesn't work.\"</p>\n</blockquote>\n<p>*****</p>\n<blockquote>\"He [Bill Gates] slowly, as Foundation and as a philanthropist, is being drawn into more open-source policies,\" Love said. \"If you look at the licensing he does on his own government-funded research, he has experienced a little bit of frustration when he doesn't get sufficient openness in the research he's funded himself, so he's begin to put things that much very much like open-source provisions in his own licenses,\" Love said. \"That has been progress, and people have noticed that. It used to be that if you applied to the program to fund libraries -- I know somebody that did this -- she was told you had to eliminate the words 'open-source' because they couldn't fund anything that had even the words.\"</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "joetdsMKbkQjyKe4F", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 1.2003214340352349e-06, "legacy": true, "legacyId": "22603", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-15T22:27:19.072Z", "modifiedAt": null, "url": null, "title": "Post ridiculous munchkin ideas!", "slug": "post-ridiculous-munchkin-ideas", "viewCount": null, "lastCommentedAt": "2021-10-04T19:57:59.716Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "D_Malik", "createdAt": "2011-01-05T12:45:17.182Z", "isAdmin": false, "displayName": "D_Malik"}, "userId": "9dhw3PngyAWKqTymS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3RJ3xFupXJKB8vE4q/post-ridiculous-munchkin-ideas", "pageUrlRelative": "/posts/3RJ3xFupXJKB8vE4q/post-ridiculous-munchkin-ideas", "linkUrl": "https://www.lesswrong.com/posts/3RJ3xFupXJKB8vE4q/post-ridiculous-munchkin-ideas", "postedAtFormatted": "Wednesday, May 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Post%20ridiculous%20munchkin%20ideas!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APost%20ridiculous%20munchkin%20ideas!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3RJ3xFupXJKB8vE4q%2Fpost-ridiculous-munchkin-ideas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Post%20ridiculous%20munchkin%20ideas!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3RJ3xFupXJKB8vE4q%2Fpost-ridiculous-munchkin-ideas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3RJ3xFupXJKB8vE4q%2Fpost-ridiculous-munchkin-ideas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 228, "htmlBody": "<p><a href=\"/lw/5c0/epistle_to_the_new_york_less_wrongians/\">Thus spake Eliezer</a>:</p>\n<blockquote>\n<p>A Munchkin is the sort of person who, faced with a role-playing game, reads through the rulebooks over and over until he finds a way to combine three innocuous-seeming magical items into a cycle of infinite <em>wish</em> spells.<span>&nbsp; </span>Or who, in real life, composes a surprisingly effective diet out of drinking a quarter-cup of extra-light olive oil at least one hour before and after tasting anything else.<span>&nbsp; </span>Or combines liquid nitrogen and antifreeze and life-insurance policies into a ridiculously cheap method of defeating the invincible specter of unavoidable Death.<span>&nbsp; </span>Or figures out how to build the real-life version of the cycle of infinite <em>wish</em> spells.</p>\n</blockquote>\n<p>It seems that many here might have outlandish ideas for ways of improving our lives. For instance, <a href=\"/lw/gdl/my_simple_hack_for_increased_alertness_and/\">a recent post</a> advocated installing really bright lights as a way to boost alertness and productivity. We should not adopt such hacks into our dogma until we're pretty sure they work; however, one way of knowing whether a crazy idea works is to try implementing it, and you may have more ideas than you're planning to implement.</p>\n<p>So: please post all such lifehack ideas! Even if you haven't tried them, even if they seem unlikely to work. Post them separately, unless some other way would be more appropriate. If you've tried some idea and it <em>hasn't</em> worked, it would be useful to post that too.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 6, "Tg9aFPFCPBHxGABRr": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3RJ3xFupXJKB8vE4q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 75, "baseScore": 78, "extendedScore": null, "score": 0.000205, "legacy": true, "legacyId": "22367", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 78, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1251, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jP583FwKepjiWbeoQ", "Ag7oQifJQM5AnMCrR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-16T01:28:42.000Z", "modifiedAt": null, "url": null, "title": "Why is it rational to invest in retirement? I don't get it. ", "slug": "why-is-it-rational-to-invest-in-retirement-i-don-t-get-it", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:33.845Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DBajPuTRK9x26jrvh/why-is-it-rational-to-invest-in-retirement-i-don-t-get-it", "pageUrlRelative": "/posts/DBajPuTRK9x26jrvh/why-is-it-rational-to-invest-in-retirement-i-don-t-get-it", "linkUrl": "https://www.lesswrong.com/posts/DBajPuTRK9x26jrvh/why-is-it-rational-to-invest-in-retirement-i-don-t-get-it", "postedAtFormatted": "Thursday, May 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20is%20it%20rational%20to%20invest%20in%20retirement%3F%20I%20don't%20get%20it.%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20is%20it%20rational%20to%20invest%20in%20retirement%3F%20I%20don't%20get%20it.%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDBajPuTRK9x26jrvh%2Fwhy-is-it-rational-to-invest-in-retirement-i-don-t-get-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20is%20it%20rational%20to%20invest%20in%20retirement%3F%20I%20don't%20get%20it.%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDBajPuTRK9x26jrvh%2Fwhy-is-it-rational-to-invest-in-retirement-i-don-t-get-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDBajPuTRK9x26jrvh%2Fwhy-is-it-rational-to-invest-in-retirement-i-don-t-get-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 339, "htmlBody": "<p>I know I said I'd be gone... but this was just a comment originally, and I noticed it may actually be relevant.</p>\n<p>Elharo <a href=\"/lw/h9b/post_ridiculous_munchkin_ideas/8zkf\">said in Munchkin Ideas</a>:</p>\n<blockquote>\n<p>Put as much money as you can afford into tax advantaged retirement accounts. In the U.S. that means 401K, 403b, IRA, SEP, etc.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>I'm interested in the following: <br /><br />Why should people invest in retirement? Or, instead, why should someone invest as much as most do in retirement. <br /><br /><strong>Few facts that make it a boggling question for me:</strong></p>\n<p>You are 10% to 20% <a href=\"http://www.nationmaster.com/graph/hea_sur_rat_to_age_65_men-survival-rate-age-65-men\">likely to die</a> before you enjoy even your first retirement year. <br /><br />People adjust much more to harsh economical conditions than they believe they would. They remain happy, as many studies by Seligman and others show. <br /><br />People who retire are only happier as retirees if they retired by choice (I lost the paper, sorry). <br /><br />Most people here live in rich countries - darn, hate to be the exception! - , and their state would happily provide them with at least the maximal retirement plan legal in my country (aprox 2000 dollars/month). And surely would provide them with double the minimal (about 200/month) if they needed. <br /><br />If you have descendants, they may support you in case you are still alive, and if you are not rich enough to keep a house, you have a good excuse to be in company of loved ones (you have nowhere else to go).</p>\n<p>Last, but not least: That person<a href=\"http://libgen.info/view.php?id=363943\"> is not</a>&nbsp; <a href=\"http://marcsandersfoundation.com/assets/pdfs/ammoniusfinal.pdf\">even you</a> that much anyway.</p>\n<p>Given all that, I have no clue what the whole fuss about retirement plans, and being 60% of a rich old person with a crappy body is all about, specially if you are in the grave.</p>\n<p>I mean, in the cryopreservation chamber, of course.</p>\n<p>&nbsp;</p>\n<p>Edit: A related question not worth its own post, but maybe worth discussing, is Should inheritance \"jump\" a generation. Everyone inheriting from grandparents, instead of parents? Just the abstract ethical question. Regardless of implementation procedure.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jgcAJnksReZRuvgzp": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DBajPuTRK9x26jrvh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 28, "extendedScore": null, "score": 6.6e-05, "legacy": true, "legacyId": "22604", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-16T04:12:36.524Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, May 16-31", "slug": "group-rationality-diary-may-16-31", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:21.272Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nMP2mcg58k9zsZjv9/group-rationality-diary-may-16-31", "pageUrlRelative": "/posts/nMP2mcg58k9zsZjv9/group-rationality-diary-may-16-31", "linkUrl": "https://www.lesswrong.com/posts/nMP2mcg58k9zsZjv9/group-rationality-diary-may-16-31", "postedAtFormatted": "Thursday, May 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20May%2016-31&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20May%2016-31%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnMP2mcg58k9zsZjv9%2Fgroup-rationality-diary-may-16-31%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20May%2016-31%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnMP2mcg58k9zsZjv9%2Fgroup-rationality-diary-may-16-31", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnMP2mcg58k9zsZjv9%2Fgroup-rationality-diary-may-16-31", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 218, "htmlBody": "<p>T<span style=\"color: #333333;\">his is the public group instrumental rationality diary for May 16-31.<br /></span></p>\n<div id=\"entry_t3_h7s\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<blockquote style=\"font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\"><span style=\"color: #333333;\">It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating!</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/r/discussion/lw/hqf/group_rationality_diary_june_130/\">Next diary</a>: June 1-30<a href=\"/r/discussion/lw/hqf/group_rationality_diary_june_130/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/lw/hbx/group_rationality_diary_may_115\">Immediate past diary</a>: May 1-15<a href=\"/lw/hbx/group_rationality_diary_may_115\"> </a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality Diaries archive</a></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nMP2mcg58k9zsZjv9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.2007489979353232e-06, "legacy": true, "legacyId": "22608", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DTg6Y5x4MbgqEFAJr", "wdCpjFTirD6JRiZXc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-16T04:27:12.185Z", "modifiedAt": null, "url": null, "title": "Meetup : Durham/RTLW HPMoR discussion, ch. 65-68", "slug": "meetup-durham-rtlw-hpmor-discussion-ch-65-68", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yurG8CjcsygeS4tmQ/meetup-durham-rtlw-hpmor-discussion-ch-65-68", "pageUrlRelative": "/posts/yurG8CjcsygeS4tmQ/meetup-durham-rtlw-hpmor-discussion-ch-65-68", "linkUrl": "https://www.lesswrong.com/posts/yurG8CjcsygeS4tmQ/meetup-durham-rtlw-hpmor-discussion-ch-65-68", "postedAtFormatted": "Thursday, May 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2065-68&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2065-68%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyurG8CjcsygeS4tmQ%2Fmeetup-durham-rtlw-hpmor-discussion-ch-65-68%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Durham%2FRTLW%20HPMoR%20discussion%2C%20ch.%2065-68%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyurG8CjcsygeS4tmQ%2Fmeetup-durham-rtlw-hpmor-discussion-ch-65-68", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyurG8CjcsygeS4tmQ%2Fmeetup-durham-rtlw-hpmor-discussion-ch-65-68", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 84, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ms'>Durham/RTLW HPMoR discussion, ch. 65-68</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 May 2013 12:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">726 Rigsbee Avenue, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at Fullsteam (address above) for discussion of HPMoR chapters 65-68!</p>\n\n<p>We may be recognizeable by our large spiral-bound tome, but the likely absence of other groups will probably make us easy to spot.</p>\n\n<p>Bring coffee and/or food as you are inclined; tell the list if you'd like a ride:  <a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a></p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ms'>Durham/RTLW HPMoR discussion, ch. 65-68</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yurG8CjcsygeS4tmQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2007595942670508e-06, "legacy": true, "legacyId": "22609", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__65_68\">Discussion article for the meetup : <a href=\"/meetups/ms\">Durham/RTLW HPMoR discussion, ch. 65-68</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 May 2013 12:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">726 Rigsbee Avenue, Durham NC 27701</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at Fullsteam (address above) for discussion of HPMoR chapters 65-68!</p>\n\n<p>We may be recognizeable by our large spiral-bound tome, but the likely absence of other groups will probably make us easy to spot.</p>\n\n<p>Bring coffee and/or food as you are inclined; tell the list if you'd like a ride:  <a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a></p>\n\n<p>See you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__65_681\">Discussion article for the meetup : <a href=\"/meetups/ms\">Durham/RTLW HPMoR discussion, ch. 65-68</a></h2>", "sections": [{"title": "Discussion article for the meetup : Durham/RTLW HPMoR discussion, ch. 65-68", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__65_68", "level": 1}, {"title": "Discussion article for the meetup : Durham/RTLW HPMoR discussion, ch. 65-68", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_HPMoR_discussion__ch__65_681", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-16T06:09:03.401Z", "modifiedAt": null, "url": null, "title": "Meetup : [Moscow] Belief cleaning", "slug": "meetup-moscow-belief-cleaning", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZWHigCBShKuSvyDBb/meetup-moscow-belief-cleaning", "pageUrlRelative": "/posts/ZWHigCBShKuSvyDBb/meetup-moscow-belief-cleaning", "linkUrl": "https://www.lesswrong.com/posts/ZWHigCBShKuSvyDBb/meetup-moscow-belief-cleaning", "postedAtFormatted": "Thursday, May 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BMoscow%5D%20Belief%20cleaning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BMoscow%5D%20Belief%20cleaning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWHigCBShKuSvyDBb%2Fmeetup-moscow-belief-cleaning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BMoscow%5D%20Belief%20cleaning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWHigCBShKuSvyDBb%2Fmeetup-moscow-belief-cleaning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZWHigCBShKuSvyDBb%2Fmeetup-moscow-belief-cleaning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 197, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mt'>[Moscow] Belief cleaning</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">26 May 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Epistemic Spring Cleaning: we will do exercise to find and change old unnecessary beliefs.</p></li>\n<li><p>Prediction markets. We will have another round of predictions, you can find the discussion and bets table on the <a href=\"http://lesswrong.ru/forum/index.php/topic,103.0.html\">Russian forum</a>.</p></li>\n<li><p>Game session: the Resistance. You can find <a href=\"http://www.gaga.ru/gaga/files/pdf/rules/1242.pdf\" rel=\"nofollow\">rules here</a>, in Russian.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mt'>[Moscow] Belief cleaning</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZWHigCBShKuSvyDBb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.200833551913045e-06, "legacy": true, "legacyId": "22613", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Moscow__Belief_cleaning\">Discussion article for the meetup : <a href=\"/meetups/mt\">[Moscow] Belief cleaning</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">26 May 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Epistemic Spring Cleaning: we will do exercise to find and change old unnecessary beliefs.</p></li>\n<li><p>Prediction markets. We will have another round of predictions, you can find the discussion and bets table on the <a href=\"http://lesswrong.ru/forum/index.php/topic,103.0.html\">Russian forum</a>.</p></li>\n<li><p>Game session: the Resistance. You can find <a href=\"http://www.gaga.ru/gaga/files/pdf/rules/1242.pdf\" rel=\"nofollow\">rules here</a>, in Russian.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Moscow__Belief_cleaning1\">Discussion article for the meetup : <a href=\"/meetups/mt\">[Moscow] Belief cleaning</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Moscow] Belief cleaning", "anchor": "Discussion_article_for_the_meetup____Moscow__Belief_cleaning", "level": 1}, {"title": "Discussion article for the meetup : [Moscow] Belief cleaning", "anchor": "Discussion_article_for_the_meetup____Moscow__Belief_cleaning1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-16T09:50:19.214Z", "modifiedAt": null, "url": null, "title": "Meetup :  Bielefeld Meetup May 22nd", "slug": "meetup-bielefeld-meetup-may-22nd", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Just_existing", "createdAt": "2012-01-16T18:40:07.392Z", "isAdmin": false, "displayName": "Just_existing"}, "userId": "o89m5G8Hk2tbpKTxg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Nkv9z7NExZpa2beux/meetup-bielefeld-meetup-may-22nd", "pageUrlRelative": "/posts/Nkv9z7NExZpa2beux/meetup-bielefeld-meetup-may-22nd", "linkUrl": "https://www.lesswrong.com/posts/Nkv9z7NExZpa2beux/meetup-bielefeld-meetup-may-22nd", "postedAtFormatted": "Thursday, May 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%20Bielefeld%20Meetup%20May%2022nd&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%20Bielefeld%20Meetup%20May%2022nd%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNkv9z7NExZpa2beux%2Fmeetup-bielefeld-meetup-may-22nd%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%20Bielefeld%20Meetup%20May%2022nd%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNkv9z7NExZpa2beux%2Fmeetup-bielefeld-meetup-may-22nd", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNkv9z7NExZpa2beux%2Fmeetup-bielefeld-meetup-may-22nd", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mu'> Bielefeld Meetup May 22nd</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 May 2013 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Grill/Bar Verve, Klosterplatz 13, Bielefeld</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are meeting once again in Bielefeld.</p>\n\n<p>The topics of this evening are not yet determined, but will be in the next days, or develop during the meetup. Highly interesting talk can be expected.</p>\n\n<p>If you live in the area consider dropping by :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mu'> Bielefeld Meetup May 22nd</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Nkv9z7NExZpa2beux", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2009942429014528e-06, "legacy": true, "legacyId": "22616", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Bielefeld_Meetup_May_22nd\">Discussion article for the meetup : <a href=\"/meetups/mu\"> Bielefeld Meetup May 22nd</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 May 2013 07:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Grill/Bar Verve, Klosterplatz 13, Bielefeld</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are meeting once again in Bielefeld.</p>\n\n<p>The topics of this evening are not yet determined, but will be in the next days, or develop during the meetup. Highly interesting talk can be expected.</p>\n\n<p>If you live in the area consider dropping by :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Bielefeld_Meetup_May_22nd1\">Discussion article for the meetup : <a href=\"/meetups/mu\"> Bielefeld Meetup May 22nd</a></h2>", "sections": [{"title": "Discussion article for the meetup :  Bielefeld Meetup May 22nd", "anchor": "Discussion_article_for_the_meetup____Bielefeld_Meetup_May_22nd", "level": 1}, {"title": "Discussion article for the meetup :  Bielefeld Meetup May 22nd", "anchor": "Discussion_article_for_the_meetup____Bielefeld_Meetup_May_22nd1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-16T10:51:46.043Z", "modifiedAt": null, "url": null, "title": "Meetup : London Meetup - 26th May", "slug": "meetup-london-meetup-26th-may", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5vSy8kCMHnH8PY4cR/meetup-london-meetup-26th-may", "pageUrlRelative": "/posts/5vSy8kCMHnH8PY4cR/meetup-london-meetup-26th-may", "linkUrl": "https://www.lesswrong.com/posts/5vSy8kCMHnH8PY4cR/meetup-london-meetup-26th-may", "postedAtFormatted": "Thursday, May 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Meetup%20-%2026th%20May&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Meetup%20-%2026th%20May%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5vSy8kCMHnH8PY4cR%2Fmeetup-london-meetup-26th-may%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Meetup%20-%2026th%20May%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5vSy8kCMHnH8PY4cR%2Fmeetup-london-meetup-26th-may", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5vSy8kCMHnH8PY4cR%2Fmeetup-london-meetup-26th-may", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/mv\">London Meetup: 26th May</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">26 May 2013 02:00:00PM (+0100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Holborn, London, WC2B 6BG</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>One of our fortnightly meetups. This will be held in the Shakespeare's Head by Holborn tube station. Turn left out of the station exit, and it's &lt;100m on your left.</p>\n<p>We're in the process of changing the format of meetups, so they alternate between designated \"social\" and \"practical\" gatherings. This will be the last undesignated meetup.</p>\n<p>One of our number will have recently returned from the May CFAR Rationality Minicamp, and has volunteered to provide an AMA-style discussion on the experience.</p>\n<p>We have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google Group</a>. Why not join it?</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/mv\">London Meetup: 26th May</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5vSy8kCMHnH8PY4cR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 1.2010388751553237e-06, "legacy": true, "legacyId": "22617", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Meetup__26th_May\">Discussion article for the meetup : <a href=\"/meetups/mv\">London Meetup: 26th May</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">26 May 2013 02:00:00PM (+0100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Holborn, London, WC2B 6BG</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>One of our fortnightly meetups. This will be held in the Shakespeare's Head by Holborn tube station. Turn left out of the station exit, and it's &lt;100m on your left.</p>\n<p>We're in the process of changing the format of meetups, so they alternate between designated \"social\" and \"practical\" gatherings. This will be the last undesignated meetup.</p>\n<p>One of our number will have recently returned from the May CFAR Rationality Minicamp, and has volunteered to provide an AMA-style discussion on the experience.</p>\n<p>We have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google Group</a>. Why not join it?</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___London_Meetup__26th_May1\">Discussion article for the meetup : <a href=\"/meetups/mv\">London Meetup: 26th May</a></h2>", "sections": [{"title": "Discussion article for the meetup : London Meetup: 26th May", "anchor": "Discussion_article_for_the_meetup___London_Meetup__26th_May", "level": 1}, {"title": "Discussion article for the meetup : London Meetup: 26th May", "anchor": "Discussion_article_for_the_meetup___London_Meetup__26th_May1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-16T16:04:31.681Z", "modifiedAt": null, "url": null, "title": "Meetup : Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR", "slug": "meetup-tel-aviv-israel-meetup-goal-clarification-with", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:35.559Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SoftFlare", "createdAt": "2012-11-09T00:22:21.187Z", "isAdmin": false, "displayName": "SoftFlare"}, "userId": "dSdSRiHQPaFuBXhG6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DW6bpSTRzkp4Fu5qA/meetup-tel-aviv-israel-meetup-goal-clarification-with", "pageUrlRelative": "/posts/DW6bpSTRzkp4Fu5qA/meetup-tel-aviv-israel-meetup-goal-clarification-with", "linkUrl": "https://www.lesswrong.com/posts/DW6bpSTRzkp4Fu5qA/meetup-tel-aviv-israel-meetup-goal-clarification-with", "postedAtFormatted": "Thursday, May 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Tel%20Aviv%2C%20Israel%20Meetup%20-%20Goal%20Clarification%20with%20special%20guest%20Cat%20from%20CFAR&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Tel%20Aviv%2C%20Israel%20Meetup%20-%20Goal%20Clarification%20with%20special%20guest%20Cat%20from%20CFAR%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDW6bpSTRzkp4Fu5qA%2Fmeetup-tel-aviv-israel-meetup-goal-clarification-with%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Tel%20Aviv%2C%20Israel%20Meetup%20-%20Goal%20Clarification%20with%20special%20guest%20Cat%20from%20CFAR%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDW6bpSTRzkp4Fu5qA%2Fmeetup-tel-aviv-israel-meetup-goal-clarification-with", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDW6bpSTRzkp4Fu5qA%2Fmeetup-tel-aviv-israel-meetup-goal-clarification-with", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 139, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mw'>Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 May 2013 07:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">TBA, In central Tel Aviv</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>For the first time in something like forever there will be a rationality meetup in Tel Aviv, Israel. It'll be a great chance to meet your fellow LWers from Israel.</p>\n\n<p>We will be joined by very special guest Cat from CFAR who will talk about Goal Clarification - a useful technique for increasing productivity.</p>\n\n<p>Please email me @ hochbergg@gmail.com about your RSVP.</p>\n\n<p>If you are a LWer from Israel who'd would have liked to come, but can't due to scheduling constraints, please email me as well so we can stay in touch :)</p>\n\n<p>Gal Hochberg</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mw'>Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DW6bpSTRzkp4Fu5qA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 1.2012660953793759e-06, "legacy": true, "legacyId": "22618", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Tel_Aviv__Israel_Meetup___Goal_Clarification_with_special_guest_Cat_from_CFAR\">Discussion article for the meetup : <a href=\"/meetups/mw\">Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 May 2013 07:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">TBA, In central Tel Aviv</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>For the first time in something like forever there will be a rationality meetup in Tel Aviv, Israel. It'll be a great chance to meet your fellow LWers from Israel.</p>\n\n<p>We will be joined by very special guest Cat from CFAR who will talk about Goal Clarification - a useful technique for increasing productivity.</p>\n\n<p>Please email me @ hochbergg@gmail.com about your RSVP.</p>\n\n<p>If you are a LWer from Israel who'd would have liked to come, but can't due to scheduling constraints, please email me as well so we can stay in touch :)</p>\n\n<p>Gal Hochberg</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Tel_Aviv__Israel_Meetup___Goal_Clarification_with_special_guest_Cat_from_CFAR1\">Discussion article for the meetup : <a href=\"/meetups/mw\">Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR</a></h2>", "sections": [{"title": "Discussion article for the meetup : Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR", "anchor": "Discussion_article_for_the_meetup___Tel_Aviv__Israel_Meetup___Goal_Clarification_with_special_guest_Cat_from_CFAR", "level": 1}, {"title": "Discussion article for the meetup : Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR", "anchor": "Discussion_article_for_the_meetup___Tel_Aviv__Israel_Meetup___Goal_Clarification_with_special_guest_Cat_from_CFAR1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "10 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T01:59:51.360Z", "modifiedAt": null, "url": null, "title": "10-Step Anti-Procrastination Checklist", "slug": "10-step-anti-procrastination-checklist", "viewCount": null, "lastCommentedAt": "2019-11-05T03:18:00.211Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JesseGalef", "createdAt": "2011-04-02T01:36:57.286Z", "isAdmin": false, "displayName": "JesseGalef"}, "userId": "xmmzCdbLf5PBgEEC7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/585XAc2C4RfHvYKNq/10-step-anti-procrastination-checklist", "pageUrlRelative": "/posts/585XAc2C4RfHvYKNq/10-step-anti-procrastination-checklist", "linkUrl": "https://www.lesswrong.com/posts/585XAc2C4RfHvYKNq/10-step-anti-procrastination-checklist", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%2010-Step%20Anti-Procrastination%20Checklist&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A10-Step%20Anti-Procrastination%20Checklist%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F585XAc2C4RfHvYKNq%2F10-step-anti-procrastination-checklist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=10-Step%20Anti-Procrastination%20Checklist%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F585XAc2C4RfHvYKNq%2F10-step-anti-procrastination-checklist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F585XAc2C4RfHvYKNq%2F10-step-anti-procrastination-checklist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 492, "htmlBody": "<p>Despite recent strides in my productivity habits, I still catch myself procrastinating at work more often than I'd like.&nbsp; It's not that I make a conscious decision to put off a project; it just feels as though I wake up 20 minutes later and realize that nothing got accomplished. (Or, to avoid the passive voice and take much-deserved responsibility, I \"realize that I haven't accomplished anything\".)</p>\n<p>I've been looking for techniques to improve, and got a lot out of <a href=\"/user/lukeprog/\">LukeProg</a>'s articles on <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a> and <a href=\"/lw/9wr/my_algorithm_for_beating_procrastination/\">My Algorithm for Beating Procrastination</a>, based on Piers Steel's <a href=\"http://www.amazon.com/Procrastination-Equation-Putting-Things-Getting/dp/0061703613/\">The Procrastination Equation</a>.<a href=\"/lw/9wr/my_algorithm_for_beating_procrastination/\"><br /></a></p>\n<p>But I also wanted a way to put the principles to use with the lowest activation cost possible.&nbsp; I can't expect unmotivated future-me to be too cooperative; I need to provide him with an easy path to get in flow.</p>\n<p>So! I developed a 10-Step Productivity Checklist, pulling the concepts from Luke's articles and adding a couple points that are important for me.&nbsp; Now whenever I notice myself being unproductive I have a much easier time following the steps one by one until I get back in a good mindset to work.</p>\n<h3>Productivity Checklist:</h3>\n<ol>\n<li>\n<p><strong>What is the task?</strong> Make sure you're going to focus on one thing at a time.</p>\n</li>\n<li>\n<p><strong>Do you have something to drink?</strong> Get yourself some tea, coffee, or water.<strong><br /></strong></p>\n</li>\n<li>\n<p><strong>Are distractions closed?</strong> Shut the door, quit Tweetdeck, close the Facebook and Gmail tabs, and set skype to \"Do not disturb.\"</p>\n</li>\n<li>\n<p><strong>What music will you listen to inspire yourself to be productive or get in flow?</strong> Put on a good instrumental playlist! (I love video game soundtracks, further notes in comments.)</p>\n</li>\n<li>\n<p><strong>Why are you doing this task?</strong>&nbsp; Trace the value until you feel the benefit.</p>\n</li>\n<li>\n<p><strong>What are the parts to this task?</strong>&nbsp; Break things down as much as you can, until they're physical actions if possible.</p>\n</li>\n<li>\n<p><strong>What are some ways to gamify the task?</strong>&nbsp; Try to have fun with it!</p>\n</li>\n<li>\n<p><strong>What are some rewards you can offer yourself for completing sections of the task?</strong> Smiling, throwing your arms up in the air and proclaiming victory, or M&amp;M's all count.</p>\n</li>\n<li>\n<p><strong>What's an achievable goal for this sitting?</strong> Set a reasonable expectation for yourself.</p>\n</li>\n<li>\n<p><strong>How long will you work until you take a break?</strong>&nbsp; Set a timer and commit to focusing.</p>\n</li>\n</ol>\n<h3>Get into flow!</h3>\n<p>I'd love to hear from you:</p>\n<ul>\n<li>Whether these are useful</li>\n<li>Any ideas for good ways to enact these steps </li>\n<li>Steps that should be added/removed/tweaked</li>\n<li>Whether there are other posts/resources that you've found valuable</li>\n</ul>\n<p>I hope this helps you as much as it's helping me, and that together we can make it even better!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dqx5k65wjFfaiJ9sQ": 2, "2oWPnnnzMbiAxWfbs": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "585XAc2C4RfHvYKNq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 42, "extendedScore": null, "score": 0.000101, "legacy": true, "legacyId": "22621", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Despite recent strides in my productivity habits, I still catch myself procrastinating at work more often than I'd like.&nbsp; It's not that I make a conscious decision to put off a project; it just feels as though I wake up 20 minutes later and realize that nothing got accomplished. (Or, to avoid the passive voice and take much-deserved responsibility, I \"realize that I haven't accomplished anything\".)</p>\n<p>I've been looking for techniques to improve, and got a lot out of <a href=\"/user/lukeprog/\">LukeProg</a>'s articles on <a href=\"/lw/3w3/how_to_beat_procrastination/\">How to Beat Procrastination</a> and <a href=\"/lw/9wr/my_algorithm_for_beating_procrastination/\">My Algorithm for Beating Procrastination</a>, based on Piers Steel's <a href=\"http://www.amazon.com/Procrastination-Equation-Putting-Things-Getting/dp/0061703613/\">The Procrastination Equation</a>.<a href=\"/lw/9wr/my_algorithm_for_beating_procrastination/\"><br></a></p>\n<p>But I also wanted a way to put the principles to use with the lowest activation cost possible.&nbsp; I can't expect unmotivated future-me to be too cooperative; I need to provide him with an easy path to get in flow.</p>\n<p>So! I developed a 10-Step Productivity Checklist, pulling the concepts from Luke's articles and adding a couple points that are important for me.&nbsp; Now whenever I notice myself being unproductive I have a much easier time following the steps one by one until I get back in a good mindset to work.</p>\n<h3 id=\"Productivity_Checklist_\">Productivity Checklist:</h3>\n<ol>\n<li>\n<p><strong>What is the task?</strong> Make sure you're going to focus on one thing at a time.</p>\n</li>\n<li>\n<p><strong>Do you have something to drink?</strong> Get yourself some tea, coffee, or water.<strong><br></strong></p>\n</li>\n<li>\n<p><strong>Are distractions closed?</strong> Shut the door, quit Tweetdeck, close the Facebook and Gmail tabs, and set skype to \"Do not disturb.\"</p>\n</li>\n<li>\n<p><strong>What music will you listen to inspire yourself to be productive or get in flow?</strong> Put on a good instrumental playlist! (I love video game soundtracks, further notes in comments.)</p>\n</li>\n<li>\n<p><strong>Why are you doing this task?</strong>&nbsp; Trace the value until you feel the benefit.</p>\n</li>\n<li>\n<p><strong>What are the parts to this task?</strong>&nbsp; Break things down as much as you can, until they're physical actions if possible.</p>\n</li>\n<li>\n<p><strong>What are some ways to gamify the task?</strong>&nbsp; Try to have fun with it!</p>\n</li>\n<li>\n<p><strong>What are some rewards you can offer yourself for completing sections of the task?</strong> Smiling, throwing your arms up in the air and proclaiming victory, or M&amp;M's all count.</p>\n</li>\n<li>\n<p><strong>What's an achievable goal for this sitting?</strong> Set a reasonable expectation for yourself.</p>\n</li>\n<li>\n<p><strong>How long will you work until you take a break?</strong>&nbsp; Set a timer and commit to focusing.</p>\n</li>\n</ol>\n<h3 id=\"Get_into_flow_\">Get into flow!</h3>\n<p>I'd love to hear from you:</p>\n<ul>\n<li>Whether these are useful</li>\n<li>Any ideas for good ways to enact these steps </li>\n<li>Steps that should be added/removed/tweaked</li>\n<li>Whether there are other posts/resources that you've found valuable</li>\n</ul>\n<p>I hope this helps you as much as it's helping me, and that together we can make it even better!</p>", "sections": [{"title": "Productivity Checklist:", "anchor": "Productivity_Checklist_", "level": 1}, {"title": "Get into flow!", "anchor": "Get_into_flow_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "55 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RWo4LwFzpHNQCTcYt", "Ty2tjPwv8uyPK9vrz"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-05-17T01:59:51.360Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T06:58:09.711Z", "modifiedAt": null, "url": null, "title": "To Inspire People to Give, Be Public About Your Giving", "slug": "to-inspire-people-to-give-be-public-about-your-giving", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:36.532Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N6FNkxMJpraMLTPwq/to-inspire-people-to-give-be-public-about-your-giving", "pageUrlRelative": "/posts/N6FNkxMJpraMLTPwq/to-inspire-people-to-give-be-public-about-your-giving", "linkUrl": "https://www.lesswrong.com/posts/N6FNkxMJpraMLTPwq/to-inspire-people-to-give-be-public-about-your-giving", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20To%20Inspire%20People%20to%20Give%2C%20Be%20Public%20About%20Your%20Giving&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATo%20Inspire%20People%20to%20Give%2C%20Be%20Public%20About%20Your%20Giving%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6FNkxMJpraMLTPwq%2Fto-inspire-people-to-give-be-public-about-your-giving%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=To%20Inspire%20People%20to%20Give%2C%20Be%20Public%20About%20Your%20Giving%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6FNkxMJpraMLTPwq%2Fto-inspire-people-to-give-be-public-about-your-giving", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6FNkxMJpraMLTPwq%2Fto-inspire-people-to-give-be-public-about-your-giving", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1687, "htmlBody": "<p>Many people think it would be nicer if people were to give more money to non-profits, especially effective ones. &nbsp;However, for most people, it doesn't even occur to them that they giving a large share of their salary to charity is something that people actually can do, or <a href=\"http://www.givingwhatwecan.org\">that people are doing on a regular basis</a>.</p>\n<p>Being public with one's pledge to donate not only spreads information about how easy it is to fight global poverty with a serious commitment, but that such commitments are the kind of thing that people can actually take. &nbsp;By being public with these pledges, we can actually inspire people to give, where they otherwise wouldn't.</p>\n<p>But how did people get stuck in a rut? &nbsp;Why doesn't giving money come naturally? &nbsp;And how would public declarations help dig people out of this rut?</p>\n<p>&nbsp;</p>\n<h2>The Bystander Effect and The Assumption of Self-Interest</h2>\n<p>First, to understand how to get people to give we have to understand why they currently do not. &nbsp;There are <a href=\"http://www.everydayutilitarian.com/essays/why-dont-people-help-others-more/\">a number of reasons</a>, but one of the most prevalent is what's called the <a href=\"http://en.wikipedia.org/wiki/Bystander Effect\">bystander effect</a>. &nbsp;While this effect is widely known in groups failing to respond to disasters right in front of their faces, it's magnified when the disaster is global poverty a continent or two away. &nbsp;We think that because other people around us are not giving, it must also not be our responsibility, and we sure wouldn't want to be suckered into helping when no one else is doing their fair share.</p>\n<p>Ever since Thomas Hobbes's <strong>The Leviathan</strong>, seeing human nature in terms of selfishness has been common, and persists to this day[1,2] as a strong and occasionally self-reinforcing belief[3,4]. &nbsp;People think of monetary incentives as being the most effective incentive for encouraging blood donations[5], even when this turns out to not be the case[6]. &nbsp;People greatly over-estimate the amount people will support a policy that favors them over other people[5]. &nbsp;As noted by Alexis de Tocqueville in 1835, \"Americans enjoy explaining almost every act of their lives on the principle of self-interest\"[7].</p>\n<p>This leads us to a natural assumption that donating to charity is irrational... or, at least, other people aren't doing it, so neither should I. &nbsp;However, this norm of self-interest is largely a myth, and people seem to do better than most people expect.</p>\n<p>&nbsp;</p>\n<h2>Challenging the Self-Interest Norm</h2>\n<p>This means the self-interest norm has to be challenged, and if it is challenged, we can expect people to revise their selfish-based theory of human nature and turn to more selfless acts like charitable giving. &nbsp;If we're interested in getting people to donate more than what they already do, we need to open people up to the idea that charitable giving cannot only be virtuous but <em>expected</em>, and can be done not only at the typical rate of 1%, but at rates of 10% or much higher[8]. &nbsp;We also should challenge the norm that charity should be silent and not spoken about, and instead mention it openly and proudly[9].</p>\n<p>People tend to conform, both intentionally and unintentionally, adopting the actions of others[4], and end up unwilling to adopt contrary actions unless other people are also going along with them. &nbsp;If peer pressure can make high schoolers turn to drug use, alcohol drinking, cigarette smoking, or even drop out of high school[10], surely it can stop people from giving.</p>\n<p>&nbsp;</p>\n<p>For example, take the famous <a href=\"http://en.wikipedia.org/wiki/Asch_conformity_experiments\">Asch Conformity Experiments</a>. &nbsp;Here, people were in a group and asked to look at a line and compare its length to three other lines on another card, and state which line matches the height of the first line. &nbsp;The task is enormously simple, but is complicated by being in a group of several other people, all in on the experiment, all who give the identical wrong answer.</p>\n<p>Asch found that many people would conform to this wrong answer, even against their better judgement. &nbsp;However, by adding another subject to this experiment who would give the correct answer, the tendency to conform would drop dramatically, even though the correct answer is still in the minority. &nbsp;Take away the partner, even halfway through the experiment with the same subject, and conformity shoots back up.</p>\n<p>&nbsp;</p>\n<p>However, allowing people an escape from this norm can lead them to be able to increase their charitable donations. &nbsp;In one field experiment, a radio station would mention to potential donors whenever a previous donor had donated $300, and they found that this increased donations by $13 more per person over the control condition, and these donors were also more likely to renew their memberships and donate more the next year compared to those in the control condition[11].</p>\n<p>In a separate field experiment, donors gave more to a radio station when prompted with an amount that was higher than their previous contribution[12]. &nbsp;Lastly, a third field experiment found that student donors were more likely to give to funds for students when told that 64% of other students had donated than when they were told that 46% of other students had donated[13].</p>\n<p>&nbsp;</p>\n<p>Overall, people are moved by seeing what others do, and can be tilted away from self-destructive norms by seeing other people go against the flow. &nbsp;An organization like Giving What We Can making a public stand for giving can accomplish just that. &nbsp;Make your giving public, and it should multiply as you inspire others.</p>\n<p>&nbsp;</p>\n<h2>Motivations and Fights for Status</h2>\n<p>Reflecting on the need to push up the norm to accurately reflect the giving nature of society, it seems like the pushback to privatize giving is harmful. &nbsp;And I think it is. &nbsp;But why does it come about in the first place? &nbsp;<a href=\"http://www.overcomingbias.com/2012/09/covert-virtue-the-signal-that-doesnt-bark.html\">Robert Wiblin speculates</a>&nbsp;that being public about giving calls your motivations into question. &nbsp;If you're only motivated by compassion for those in need, why do you need to boast?</p>\n<p>Well, of course, there's an interest in raising the norm. &nbsp;But let's assume that giving was really just a giant fight for status... would that be so bad? &nbsp;All else being equal, I prefer pure intention to that of giving just to prove to others, but competing for status via donation oneupmanship is <em>considerably</em>&nbsp;more useful than competing for status via bigger houses, bigger cars, and bigger flatscreen TVs.</p>\n<p>Or rather, people still end up competing over their charitable contributions, but it comes in the forms of significantly less-effective (though still arguably worthwhile) charitable competition, like <a href=\"http://www.jefftk.com/news/2012-11-20\">volunteering</a>, building schools, or adopting African children. &nbsp;If, instead, we normalized people giving checks, at least more people could be helped while the status fight goes on.</p>\n<p>&nbsp;</p>\n<h2>Conclusion</h2>\n<p>Many people want to leave the world in a better place than they found it, perhaps even going as far as wanting to do the best they can. &nbsp;To these people, I hope that the idea of donation, especially to <a href=\"http://givewell.org/giving101\">effective causes</a>&nbsp;in <a href=\"http://www.utilitarian-essays.com/make-money.html\">potentially large amounts</a>&nbsp;ends up appealing. &nbsp;But if this cool idea is seen as \"boastful\", it won't catch on, and won't get the publicity (I think) it deserves.</p>\n<p>Moreover, people won't be able to network together and share information about more cost-effective charities or the latest trends in development economics, because everyone will be keeping it to themselves, ending up being collectively self-defeating.</p>\n<p>We seem forced by society to pretend to be self-interested, because we're asked to not talk about our acts of kindness. &nbsp;But this only goes to re-enforce the deadly cycle. &nbsp;The only way to push ourselves out of this cycle is to demonstrate that some people do donate and push up this norm. &nbsp;And groups like <a href=\"http://www.givingwhatwecan.org\">GivingWhatWeCan</a>, <a href=\"http://www.80000hours.org\">80000 Hours</a>, and <a href=\"http://www.boldergiving.org/\">BolderGiving</a>&nbsp;are working on doing just that.</p>\n<p>Personally, I'd have to agree that this works -- I'm inspired by these stories, and I don't think I would ever be donating 10%+ without a group that makes it seem like a completely normal and awesome thing to do.</p>\n<p>So is talking about donations too boastful? &nbsp;I think, for the sake of those the donations help, we can afford a little boasting in this one area.</p>\n<p>&nbsp;</p>\n<h2>References and Notes</h2>\n<p><em>(Note: Most of these links open to PDFs.)</em></p>\n<h6><span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">[1]: Barry Schwartz. 1986. </span><a href=\"http://www.amazon.com/The-Battle-Human-Nature-Morality/dp/0393304450\">The Battle for Human Nature: Science, Morality and Modern Life</a><span style=\"font-weight: normal;\">. Canada: Penguin Books.</span><br /><br /><span style=\"font-weight: normal;\">[2]: Alfie Kohn. 1990. </span></span><span style=\"font-weight: normal;\"><a href=\"http://www.amazon.com/Brighter-Side-Human-Nature-Altruism/dp/0465007589\">The Brighter Side of Human Nature</a></span><span style=\"font-weight: normal;\">. New York: Basic Books.<br /><br />[3]: Dale T. Miller. 1999. <a href=\"http://faculty-gsb.stanford.edu/millerd/docs/1999amerpsyc.html\">\"The Norm of Self-Interest\"</a>. <em>American Psychologist</em>&nbsp;54 (12): 1053-1060.<br /><br />[4]: John M. Darley and Russell H. Fazio. <a href=\"http://psych.princeton.edu/psychology/research/darley/pdfs/Expectancy%20Confirmation.PDF\">\"Expectancy Confirmation Processes Arising in the Social Interaction Sequence\"</a>. 1980. <em>American Psychologist</em> 35 (10): 867-881.<br /><br />[5]: Dale T. Miller and Rebecca K. Ratner. 1998. <a href=\"http://www.rhsmith.umd.edu/marketing/pdfs_docs/ratner/millerratner.pdf\">\"The Disparity Between the Actual and Assumed Power of Self-Interest\"</a>. <em>Journal of Personality and Social Psychology</em> 74 (1): 53-62.<br /><br />[6]: Nicola Lacetera, Mario Macis, and Robert Slonim. 2011. <a href=\"http://bfi.uchicago.edu/events/20111028_experiments/papers/Lacetera_LMS2_21Oct2011.pdf\">\"Rewarding Altruism? A Natural Field Experiment\"</a>. The National Bureau of Economic Research Working Paper #17636.<br /><br />[7]: Alexis de Tocqueville in J.P. Mayer ed., G. Lawrence, trans. 1969.&nbsp;</span><span style=\"font-weight: normal;\"><a href=\"http://www.amazon.com/Democracy-America-Alexis-Tocqueville/dp/0060915226\">Democracy in America</a></span><span style=\"font-weight: normal;\">. Garden City, N.Y.: Anchor, p546.<br /><br />[8]: The Giving What We Can pledge requires 10% and this is already shockingly high for most, but people on <a href=\"http://80000hours.org/members\">80000 Hours's member list</a>&nbsp;or among <a href=\"http://www.boldergiving.org/\">Bolder Giving's stories</a>&nbsp;donate up to 50% of their income or more!<br /><br />[9]: Of course, I don't think we should mention it *all* the time -- we should recognize when is the time and place, and not be unreasonable. &nbsp;On the same time, we shouldn't be completely silent. &nbsp;Places like Facebook, personal blogs, and when the topic comes up for conversation all seem like fair game.<br /><br />[10]: Alejandro Gaviria and Steven Raphael. 2001. <a href=\"http://agaviria.uniandes.edu.co/papers_pub/School_Based_Peer_Effects_and_Juvenile_Behavior.pdf\">\"School-Based Peer Effects and Juvenile Behavior\"</a>. <em>The Review of Economics and Statistics</em> 83 (2): 257-268.<br /><br />[11]: Other conditions were $180, $75, or no prompt about previous donors at all. &nbsp;Jen Shang and Rachel Croson. Forthcoming. &ldquo;Field Experiments in Charitable Contribution: The Impact of Social Influence on the Voluntary Provision of Public Goods&rdquo;. <em>The Economic Journal</em>.<br /><br />[12]: Rachel Croson and Jen Shang. 2008. <a href=\"http://www.iu.edu/~spea/pubs/faculty/Croson_Shang_2008.pdf\">\"The Impact of Downward Social Information on Contribution Decisions\"</a>.&nbsp;<em>Experimental Economics</em> 11: 221-233.<br /><br />[13]: Bruno S. Frey and Stephan Meier. 2004. <a href=\"http://www.bsfrey.ch/articles/418_04.pdf\">\"Social Comparisons and Pro-social Behavior: Testing 'Conditional Cooperation' in a Field Experiment\"</a>. <em>The American Economic Review</em> 94 (5): 1717-1722.</span></h6>\n<p>-</p>\n<address><span style=\"font-family: mceinline;\">Also <a href=\"http://www.everydayutilitarian.com/essays/to-inspire-people-to-give-be-public-about-your-giving\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</span></address><address><span style=\"font-family: mceinline;\"><br /></span></address>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb150": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N6FNkxMJpraMLTPwq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 24, "extendedScore": null, "score": 6.1e-05, "legacy": true, "legacyId": "22627", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Many people think it would be nicer if people were to give more money to non-profits, especially effective ones. &nbsp;However, for most people, it doesn't even occur to them that they giving a large share of their salary to charity is something that people actually can do, or <a href=\"http://www.givingwhatwecan.org\">that people are doing on a regular basis</a>.</p>\n<p>Being public with one's pledge to donate not only spreads information about how easy it is to fight global poverty with a serious commitment, but that such commitments are the kind of thing that people can actually take. &nbsp;By being public with these pledges, we can actually inspire people to give, where they otherwise wouldn't.</p>\n<p>But how did people get stuck in a rut? &nbsp;Why doesn't giving money come naturally? &nbsp;And how would public declarations help dig people out of this rut?</p>\n<p>&nbsp;</p>\n<h2 id=\"The_Bystander_Effect_and_The_Assumption_of_Self_Interest\">The Bystander Effect and The Assumption of Self-Interest</h2>\n<p>First, to understand how to get people to give we have to understand why they currently do not. &nbsp;There are <a href=\"http://www.everydayutilitarian.com/essays/why-dont-people-help-others-more/\">a number of reasons</a>, but one of the most prevalent is what's called the <a href=\"http://en.wikipedia.org/wiki/Bystander Effect\">bystander effect</a>. &nbsp;While this effect is widely known in groups failing to respond to disasters right in front of their faces, it's magnified when the disaster is global poverty a continent or two away. &nbsp;We think that because other people around us are not giving, it must also not be our responsibility, and we sure wouldn't want to be suckered into helping when no one else is doing their fair share.</p>\n<p>Ever since Thomas Hobbes's <strong>The Leviathan</strong>, seeing human nature in terms of selfishness has been common, and persists to this day[1,2] as a strong and occasionally self-reinforcing belief[3,4]. &nbsp;People think of monetary incentives as being the most effective incentive for encouraging blood donations[5], even when this turns out to not be the case[6]. &nbsp;People greatly over-estimate the amount people will support a policy that favors them over other people[5]. &nbsp;As noted by Alexis de Tocqueville in 1835, \"Americans enjoy explaining almost every act of their lives on the principle of self-interest\"[7].</p>\n<p>This leads us to a natural assumption that donating to charity is irrational... or, at least, other people aren't doing it, so neither should I. &nbsp;However, this norm of self-interest is largely a myth, and people seem to do better than most people expect.</p>\n<p>&nbsp;</p>\n<h2 id=\"Challenging_the_Self_Interest_Norm\">Challenging the Self-Interest Norm</h2>\n<p>This means the self-interest norm has to be challenged, and if it is challenged, we can expect people to revise their selfish-based theory of human nature and turn to more selfless acts like charitable giving. &nbsp;If we're interested in getting people to donate more than what they already do, we need to open people up to the idea that charitable giving cannot only be virtuous but <em>expected</em>, and can be done not only at the typical rate of 1%, but at rates of 10% or much higher[8]. &nbsp;We also should challenge the norm that charity should be silent and not spoken about, and instead mention it openly and proudly[9].</p>\n<p>People tend to conform, both intentionally and unintentionally, adopting the actions of others[4], and end up unwilling to adopt contrary actions unless other people are also going along with them. &nbsp;If peer pressure can make high schoolers turn to drug use, alcohol drinking, cigarette smoking, or even drop out of high school[10], surely it can stop people from giving.</p>\n<p>&nbsp;</p>\n<p>For example, take the famous <a href=\"http://en.wikipedia.org/wiki/Asch_conformity_experiments\">Asch Conformity Experiments</a>. &nbsp;Here, people were in a group and asked to look at a line and compare its length to three other lines on another card, and state which line matches the height of the first line. &nbsp;The task is enormously simple, but is complicated by being in a group of several other people, all in on the experiment, all who give the identical wrong answer.</p>\n<p>Asch found that many people would conform to this wrong answer, even against their better judgement. &nbsp;However, by adding another subject to this experiment who would give the correct answer, the tendency to conform would drop dramatically, even though the correct answer is still in the minority. &nbsp;Take away the partner, even halfway through the experiment with the same subject, and conformity shoots back up.</p>\n<p>&nbsp;</p>\n<p>However, allowing people an escape from this norm can lead them to be able to increase their charitable donations. &nbsp;In one field experiment, a radio station would mention to potential donors whenever a previous donor had donated $300, and they found that this increased donations by $13 more per person over the control condition, and these donors were also more likely to renew their memberships and donate more the next year compared to those in the control condition[11].</p>\n<p>In a separate field experiment, donors gave more to a radio station when prompted with an amount that was higher than their previous contribution[12]. &nbsp;Lastly, a third field experiment found that student donors were more likely to give to funds for students when told that 64% of other students had donated than when they were told that 46% of other students had donated[13].</p>\n<p>&nbsp;</p>\n<p>Overall, people are moved by seeing what others do, and can be tilted away from self-destructive norms by seeing other people go against the flow. &nbsp;An organization like Giving What We Can making a public stand for giving can accomplish just that. &nbsp;Make your giving public, and it should multiply as you inspire others.</p>\n<p>&nbsp;</p>\n<h2 id=\"Motivations_and_Fights_for_Status\">Motivations and Fights for Status</h2>\n<p>Reflecting on the need to push up the norm to accurately reflect the giving nature of society, it seems like the pushback to privatize giving is harmful. &nbsp;And I think it is. &nbsp;But why does it come about in the first place? &nbsp;<a href=\"http://www.overcomingbias.com/2012/09/covert-virtue-the-signal-that-doesnt-bark.html\">Robert Wiblin speculates</a>&nbsp;that being public about giving calls your motivations into question. &nbsp;If you're only motivated by compassion for those in need, why do you need to boast?</p>\n<p>Well, of course, there's an interest in raising the norm. &nbsp;But let's assume that giving was really just a giant fight for status... would that be so bad? &nbsp;All else being equal, I prefer pure intention to that of giving just to prove to others, but competing for status via donation oneupmanship is <em>considerably</em>&nbsp;more useful than competing for status via bigger houses, bigger cars, and bigger flatscreen TVs.</p>\n<p>Or rather, people still end up competing over their charitable contributions, but it comes in the forms of significantly less-effective (though still arguably worthwhile) charitable competition, like <a href=\"http://www.jefftk.com/news/2012-11-20\">volunteering</a>, building schools, or adopting African children. &nbsp;If, instead, we normalized people giving checks, at least more people could be helped while the status fight goes on.</p>\n<p>&nbsp;</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>Many people want to leave the world in a better place than they found it, perhaps even going as far as wanting to do the best they can. &nbsp;To these people, I hope that the idea of donation, especially to <a href=\"http://givewell.org/giving101\">effective causes</a>&nbsp;in <a href=\"http://www.utilitarian-essays.com/make-money.html\">potentially large amounts</a>&nbsp;ends up appealing. &nbsp;But if this cool idea is seen as \"boastful\", it won't catch on, and won't get the publicity (I think) it deserves.</p>\n<p>Moreover, people won't be able to network together and share information about more cost-effective charities or the latest trends in development economics, because everyone will be keeping it to themselves, ending up being collectively self-defeating.</p>\n<p>We seem forced by society to pretend to be self-interested, because we're asked to not talk about our acts of kindness. &nbsp;But this only goes to re-enforce the deadly cycle. &nbsp;The only way to push ourselves out of this cycle is to demonstrate that some people do donate and push up this norm. &nbsp;And groups like <a href=\"http://www.givingwhatwecan.org\">GivingWhatWeCan</a>, <a href=\"http://www.80000hours.org\">80000 Hours</a>, and <a href=\"http://www.boldergiving.org/\">BolderGiving</a>&nbsp;are working on doing just that.</p>\n<p>Personally, I'd have to agree that this works -- I'm inspired by these stories, and I don't think I would ever be donating 10%+ without a group that makes it seem like a completely normal and awesome thing to do.</p>\n<p>So is talking about donations too boastful? &nbsp;I think, for the sake of those the donations help, we can afford a little boasting in this one area.</p>\n<p>&nbsp;</p>\n<h2 id=\"References_and_Notes\">References and Notes</h2>\n<p><em>(Note: Most of these links open to PDFs.)</em></p>\n<h6><span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\">[1]: Barry Schwartz. 1986. </span><a href=\"http://www.amazon.com/The-Battle-Human-Nature-Morality/dp/0393304450\">The Battle for Human Nature: Science, Morality and Modern Life</a><span style=\"font-weight: normal;\">. Canada: Penguin Books.</span><br><br><span style=\"font-weight: normal;\">[2]: Alfie Kohn. 1990. </span></span><span style=\"font-weight: normal;\"><a href=\"http://www.amazon.com/Brighter-Side-Human-Nature-Altruism/dp/0465007589\">The Brighter Side of Human Nature</a></span><span style=\"font-weight: normal;\">. New York: Basic Books.<br><br>[3]: Dale T. Miller. 1999. <a href=\"http://faculty-gsb.stanford.edu/millerd/docs/1999amerpsyc.html\">\"The Norm of Self-Interest\"</a>. <em>American Psychologist</em>&nbsp;54 (12): 1053-1060.<br><br>[4]: John M. Darley and Russell H. Fazio. <a href=\"http://psych.princeton.edu/psychology/research/darley/pdfs/Expectancy%20Confirmation.PDF\">\"Expectancy Confirmation Processes Arising in the Social Interaction Sequence\"</a>. 1980. <em>American Psychologist</em> 35 (10): 867-881.<br><br>[5]: Dale T. Miller and Rebecca K. Ratner. 1998. <a href=\"http://www.rhsmith.umd.edu/marketing/pdfs_docs/ratner/millerratner.pdf\">\"The Disparity Between the Actual and Assumed Power of Self-Interest\"</a>. <em>Journal of Personality and Social Psychology</em> 74 (1): 53-62.<br><br>[6]: Nicola Lacetera, Mario Macis, and Robert Slonim. 2011. <a href=\"http://bfi.uchicago.edu/events/20111028_experiments/papers/Lacetera_LMS2_21Oct2011.pdf\">\"Rewarding Altruism? A Natural Field Experiment\"</a>. The National Bureau of Economic Research Working Paper #17636.<br><br>[7]: Alexis de Tocqueville in J.P. Mayer ed., G. Lawrence, trans. 1969.&nbsp;</span><span style=\"font-weight: normal;\"><a href=\"http://www.amazon.com/Democracy-America-Alexis-Tocqueville/dp/0060915226\">Democracy in America</a></span><span style=\"font-weight: normal;\">. Garden City, N.Y.: Anchor, p546.<br><br>[8]: The Giving What We Can pledge requires 10% and this is already shockingly high for most, but people on <a href=\"http://80000hours.org/members\">80000 Hours's member list</a>&nbsp;or among <a href=\"http://www.boldergiving.org/\">Bolder Giving's stories</a>&nbsp;donate up to 50% of their income or more!<br><br>[9]: Of course, I don't think we should mention it *all* the time -- we should recognize when is the time and place, and not be unreasonable. &nbsp;On the same time, we shouldn't be completely silent. &nbsp;Places like Facebook, personal blogs, and when the topic comes up for conversation all seem like fair game.<br><br>[10]: Alejandro Gaviria and Steven Raphael. 2001. <a href=\"http://agaviria.uniandes.edu.co/papers_pub/School_Based_Peer_Effects_and_Juvenile_Behavior.pdf\">\"School-Based Peer Effects and Juvenile Behavior\"</a>. <em>The Review of Economics and Statistics</em> 83 (2): 257-268.<br><br>[11]: Other conditions were $180, $75, or no prompt about previous donors at all. &nbsp;Jen Shang and Rachel Croson. Forthcoming. \u201cField Experiments in Charitable Contribution: The Impact of Social Influence on the Voluntary Provision of Public Goods\u201d. <em>The Economic Journal</em>.<br><br>[12]: Rachel Croson and Jen Shang. 2008. <a href=\"http://www.iu.edu/~spea/pubs/faculty/Croson_Shang_2008.pdf\">\"The Impact of Downward Social Information on Contribution Decisions\"</a>.&nbsp;<em>Experimental Economics</em> 11: 221-233.<br><br>[13]: Bruno S. Frey and Stephan Meier. 2004. <a href=\"http://www.bsfrey.ch/articles/418_04.pdf\">\"Social Comparisons and Pro-social Behavior: Testing 'Conditional Cooperation' in a Field Experiment\"</a>. <em>The American Economic Review</em> 94 (5): 1717-1722.</span></h6>\n<p>-</p>\n<address><span style=\"font-family: mceinline;\">Also <a href=\"http://www.everydayutilitarian.com/essays/to-inspire-people-to-give-be-public-about-your-giving\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</span></address><address><span style=\"font-family: mceinline;\"><br></span></address>", "sections": [{"title": "The Bystander Effect and The Assumption of Self-Interest", "anchor": "The_Bystander_Effect_and_The_Assumption_of_Self_Interest", "level": 1}, {"title": "Challenging the Self-Interest Norm", "anchor": "Challenging_the_Self_Interest_Norm", "level": 1}, {"title": "Motivations and Fights for Status", "anchor": "Motivations_and_Fights_for_Status", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "References and Notes", "anchor": "References_and_Notes", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "15 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T10:51:56.068Z", "modifiedAt": null, "url": null, "title": "The Unselfish Trolley Problem", "slug": "the-unselfish-trolley-problem", "viewCount": null, "lastCommentedAt": "2020-05-24T18:28:18.159Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "elharo", "createdAt": "2012-12-28T14:11:02.335Z", "isAdmin": false, "displayName": "elharo"}, "userId": "cgJcCeZhdRnGtwMMR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3xhrqxNAwHZYjNj7C/the-unselfish-trolley-problem", "pageUrlRelative": "/posts/3xhrqxNAwHZYjNj7C/the-unselfish-trolley-problem", "linkUrl": "https://www.lesswrong.com/posts/3xhrqxNAwHZYjNj7C/the-unselfish-trolley-problem", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Unselfish%20Trolley%20Problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Unselfish%20Trolley%20Problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xhrqxNAwHZYjNj7C%2Fthe-unselfish-trolley-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Unselfish%20Trolley%20Problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xhrqxNAwHZYjNj7C%2Fthe-unselfish-trolley-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xhrqxNAwHZYjNj7C%2Fthe-unselfish-trolley-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1356, "htmlBody": "<p>By now <a href=\"http://www.howstuffworks.com/trolley-problem.htm\">the Trolley Problem</a> is well known amongst <a href=\"https://en.wikipedia.org/wiki/Trolley_problem\">moral philosophers</a> and <a href=\"/lw/383/the_trolley_problem_dodging_moral_questions/\">LessWrong readers</a>. In brief, there's a trolley hurtling down the tracks. The dastardly villain <span class=\"st\">Snidely Whiplash</span> has tied five people to the tracks. You have only seconds to act. You can save the five people by throwing a switch and transferring the trolley to another track. However the evil villain has tied a sixth person to the alternate track. Should you throw the switch?</p>\n<p>When first presented with this problem, almost everyone answers yes. Sacrifice the one to save five. It's not a very hard choice.</p>\n<p>Now comes the hard question. There is no switch or alternate track. The trolley is still coming down the tracks, and there are still five people tied to it. You are instead standing on a bridge over the tracks. Next to you is a fat man. If you push the man onto the tracks, the trolley car will hit him and derail, saving the five people; but the fat man will die. Do you push him?</p>\n<p>This is a really hard problem. Most people say no, they don't push. But really what is the difference here? In both scenarios you are choosing to take one life in order to save five. It's a net gain of four lives. Especially if you call yourself a utilitarian, as many folks here do, how can you not push? If you do push, how will you feel about that choice afterwards?</p>\n<p>Try not to <span class=\"st\"><em>Kobayashi Maru</em> </span> this question, at least not yet. I know you can <a href=\"/lw/2xh/the_problem_with_trolley_problems/\">criticize the scenario and find it unrealistic</a>. For instance, you may say you won't push because the man might fight back, and you'd both fall but not till after the trolley had passed so everyone dies. So imagine the fat man in a wheelchair, so he can be lightly rolled off the bridge. And if you're too socially constrained to consider hurting a handicapped person, maybe the five people tied to the tracks are also in wheelchairs. If you think that being pushed off a bridge is more terrifying than being hit by a train, suppose the fat man is thoroughly anesthetized. Yes, this is an unrealistic thought experiment; but please play along for now.</p>\n<p>Have your answer? Good. Now comes the third, final, and hardest question; especially for anybody who said they'd push the fat man. There is still no switch or alternate track. The trolley is still coming down the tracks, and there are still five people tied to it. You are still standing on a bridge over the tracks. But this time you're alone and the only way to stop the train is by jumping in front of it yourself. Do you jump? If you said yes, you would push the fat man; but you won't jump. Why?</p>\n<p>Do you have a moral obligation to jump in front of the train? If you have a moral obligation to push someone else, don't you have a moral obligation to sacrifice yourself as well? or if you won't sacrifice yourself, how can you justify sacrificing someone else? Is it morally more right to push someone else than jump yourself? I'd argue the opposite...</p>\n<p>Realistically you may not be able to bring yourself to jump. It's not exactly a moral decision. You're just not that brave. You accept that it's right for you to jump, and accept that you're not that moral. Fine. Now imagine someone is standing next to you, a skinny athletic person who's too small to stop the train themselves but strong enough to push you over into the path of the trolley. Do you still think the correct answer to the trolley problem is to push?</p>\n<p>If we take it seriously, this is a hard problem. The best answer I know is <a href=\"https://en.wikipedia.org/wiki/John_Rawls\">Rawlsianism</a>. You pick your answer in ignorance of who you'll be in the problem. You don't know whether you're the pusher, the pushed, or one of the people tied to the tracks. In this case, the answer is easy: push! There's a 6/7 chance you'll survive so the selfish and utilitarian answers converge.</p>\n<p>We can play other variants. For instance, suppose Snidely kidnaps you and says \"Tomorrow I'm going to flip a coin. Heads I'll put you on the tracks with 4 other people (and put a different person on the bridge next to the pusher). Tails I'll put you on the bridge next to a pusher.\" Should the pusher push? Actually that's an easy one because you don't know where you'll end up so you might as well save the four extra people in both scenarios. Your expected value is the same and everyone else's is increased by pushing.</p>\n<p>Now imagine <span class=\"st\">Snidely</span> says instead he'll roll a die. If it comes up 1-5, he puts six people including you on the track. If it comes up 6, he lets you go and puts the other five people on the track. However if you agree to be tied to the track without a roll, without even a chance of escape, he'll let the other five people go. What now? Suppose he rolls two dice and they both have to come up 6 for you to go free; but he'll still let everyone else go if you agree. Will you save the other five people at the cost of a 1/36 chance of saving your own life? How about three dice? four? How many dice must Snidely roll before you think the chance of saving your own life is outweighed by the certainty of saving five others?&nbsp;</p>\n<p>Do you have your answers? Are you prepared to defend them? Good. Comment away, and you can even <span class=\"st\"><em>Kobayashi Maru</em> </span>the scenario or criticize the excessively contrived hypotheticals I've posed here. But be forewarned, in part 2 I'm going to show you an actual, non-hypothetical scenario where this problem becomes very real; indeed a situation I know many LessWrong readers are facing right now; and yes, it's a matter of life and death.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p><strong>Update</strong>: It now occurs to me that the scenario can be tightened up considerably. Forget the bridge and the fat man. They're irrelevant details. Case 1 is as before. 5 people on one track, 1 on another. Pull the switch to save the 5 and kill the 1. Still not a hard problem.</p>\n<p>Case 2: same as before, except this time you are standing next to the one person tied to the track who will be hit by the trolley if you throw the switch. And they are conscious, can talk to you, and see what you're doing. No one else will know what you did. Does this change your answer, and if so why?</p>\n<p>Case 3: same as before, except this time you are the one person tied to the track who will be hit by the trolley if you throw the switch.</p>\n<p>Folks here are being refreshingly honest. I don't think anyone has yet said they would throw the switch in case 3, and most of us (myself included) are simply admitting we're not that brave/altruistic/suicidal (assuming the five people on the other track are not our friends or family). So let's make it a little easier. Suppose in case 3 someone else, not you, is tied to the track but can reach the switch. What now?</p>\n<p>\n<hr />\n</p>\n<p><strong>Update 2</strong>: Case 4: As in case 3, you are tied to the track, five other unrelated people are tied to the opposite track, and you have access to a switch that will cause the trolley to change tracks. However now the trolley is initially aimed at you. The five people on the other track are safe unless you throw the switch. Is there a difference between throwing the switch in this case, and not throwing the switch in Case 3?</p>\n<p>This case also raises the interesting question of legality. If there are any lawyers in the room, do you think a person who throws the switch in case 4--that is, saves themselves at the cost of five other lives--could be convicted of a crime? (Of course, the answer to this one may vary with jurisdiction.) Are there any actual precedents of cases like this?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"LMFBzsJaCRADQqw3F": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3xhrqxNAwHZYjNj7C", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 4, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "22346", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 132, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5YuQAj63CkcDLewbW", "h22n4nZQd9J2MEZxq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T13:47:27.299Z", "modifiedAt": null, "url": null, "title": "Open thread, May 17-31 2013", "slug": "open-thread-may-17-31-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:38.181Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "W55i9XXdye9ETAyu5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4PBibbGSMopowtpCu/open-thread-may-17-31-2013", "pageUrlRelative": "/posts/4PBibbGSMopowtpCu/open-thread-may-17-31-2013", "linkUrl": "https://www.lesswrong.com/posts/4PBibbGSMopowtpCu/open-thread-may-17-31-2013", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20May%2017-31%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20May%2017-31%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4PBibbGSMopowtpCu%2Fopen-thread-may-17-31-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20May%2017-31%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4PBibbGSMopowtpCu%2Fopen-thread-may-17-31-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4PBibbGSMopowtpCu%2Fopen-thread-may-17-31-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"text-align: justify; line-height: 19px; font-family: Arial, Helvetica, sans-serif;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4PBibbGSMopowtpCu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 1.2022134890577632e-06, "legacy": true, "legacyId": "22630", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 312, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T14:02:48.808Z", "modifiedAt": null, "url": null, "title": "The flawed Turing test: language, understanding, and partial p-zombies", "slug": "the-flawed-turing-test-language-understanding-and-partial-p", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:09.844Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/er6G2DdzevvfdZWtg/the-flawed-turing-test-language-understanding-and-partial-p", "pageUrlRelative": "/posts/er6G2DdzevvfdZWtg/the-flawed-turing-test-language-understanding-and-partial-p", "linkUrl": "https://www.lesswrong.com/posts/er6G2DdzevvfdZWtg/the-flawed-turing-test-language-understanding-and-partial-p", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20flawed%20Turing%20test%3A%20language%2C%20understanding%2C%20and%20partial%20p-zombies&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20flawed%20Turing%20test%3A%20language%2C%20understanding%2C%20and%20partial%20p-zombies%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fer6G2DdzevvfdZWtg%2Fthe-flawed-turing-test-language-understanding-and-partial-p%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20flawed%20Turing%20test%3A%20language%2C%20understanding%2C%20and%20partial%20p-zombies%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fer6G2DdzevvfdZWtg%2Fthe-flawed-turing-test-language-understanding-and-partial-p", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fer6G2DdzevvfdZWtg%2Fthe-flawed-turing-test-language-understanding-and-partial-p", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 649, "htmlBody": "<p>There is a problem with the Turing test,&nbsp;practically&nbsp;and philosophically, and I would be willing to bet that the first entity to pass the test will not be conscious, or intelligent, or have whatever spark or quality the test is supposed to measure. And I hold this position while fully embracing materialism, and rejecting <a href=\"/lw/p7/zombies_zombies/\">p-zombies</a>&nbsp;or <a href=\"http://en.wikipedia.org/wiki/Epiphenomenalism\">epiphenomenalism</a>.</p>\n<p>The problem is <a href=\"http://en.wikipedia.org/wiki/Campbell's_law\">Campbell's law</a>&nbsp;(or <a href=\"http://en.wikipedia.org/wiki/Goodhart's_law\">Goodhart's law</a>):</p>\n<blockquote>\n<p>The more any quantitative <del>social</del> indicator is used for <del>social</del> decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the <del>social</del> processes it is intended to monitor.\"</p>\n</blockquote>\n<p>This applies to more than social indicators. To&nbsp;illustrate, imagine that you were a school inspector, tasked with&nbsp;assessing&nbsp;the all-round education of a group of 14-year old students. You engage them on the French revolution and they respond with pertinent contrasts between the Montagnards and Girondins. Your quizzes about the properties of prime numbers are answered with impressive speed, and, when asked, they can all play quite passable pieces from \"Die Zauberfl&ouml;te\".</p>\n<p>You feel tempted to give them the seal of approval... but they you learn that the principal had been expecting your questions (you don't vary them much), and that, in fact, the whole school has spent the last three years doing nothing but studying 18th century France, number theory and Mozart operas - day after day after day. Now you're less impressed. You can still conclude that the students have some technical ability, but you can't assess their all-round level of education.</p>\n<p>The Turing test functions in the same way. Imagine no-one had heard of the test, and someone created a putative AI, designing it to, say, track rats efficiently across the city. You sit this anti-rat-AI down and give it a Turing test - and, to your astonishment, it passes. You could now conclude that it was (very likely) a genuinely conscious or intelligent entity.<a id=\"more\"></a></p>\n<p>But this is not the case: nearly everyone's heard of the Turing test. So the first machines to pass will be dedicated systems, specifically designed to get through the test. Their whole setup will be constructed to maximise \"passing the test\", not to \"being intelligent\" or whatever we want the test to measure (the fact we have difficulty stating what exactly the test should be measuring shows the difficulty here).</p>\n<p>Of course, this is a matter of degree, not of kind: a machine that passed the Turing test would still be rather nifty, and as the test got longer, and more&nbsp;complicated, as the interactions between subject and judge got more intricate, our confidence that we were facing a&nbsp;truly&nbsp;intelligence machine would increase.</p>\n<p>But degree can go a long way. <a href=\"http://en.wikipedia.org/wiki/Watson_(computer)\">Watson</a> won on&nbsp;Jeopardy&nbsp;without exhibiting any of the skills of a truly intelligent being - apart from one: answering Jeopardy questions. With the rise of big data and statistical algorithms, I would certainly rate it as plausible that we could create beings that are nearly perfectly conscious from a (textual) linguistic perspective. These \"super-chatterbots\" could only be identified as such with long and tedious effort. And yet they would demonstrate none of the other attributes of intelligence: chattering is all they're any good at (if you ask them to do any planning, for instance, they'll come up with designs that sound good but fail: <a href=\"/lw/iq/guessing_the_teachers_password/\">they parrot back other people's plans with minimal modifications</a>). These would be the closest plausible analogues to p-zombies.</p>\n<p>The best way to avoid this is to create more varied analogues of the Turing test - and to keep them secret. Just as you keep the training set and the test set distinct in machine learning, you want to confront the putative AIs with quasi-Turing tests that their designers will not have encountered or planed for. Mix up the test conditions, add extra requirements, change what is being measured, do something completely different, be unfair: do things that a genuine intelligence would deal with, but an&nbsp;overtrained narrow statistical machine couldn't.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "er6G2DdzevvfdZWtg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 11, "extendedScore": null, "score": 1.2022246645025908e-06, "legacy": true, "legacyId": "22629", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 184, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fdEWWr8St59bXLbQr", "NMoLJuDJEms7Ku9XS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T14:53:14.046Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Atlanta, Austin, Moscow, Ottawa, Vancouver", "slug": "weekly-lw-meetups-atlanta-austin-moscow-ottawa-vancouver", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9Zt3vjcYjpvzcWwDJ/weekly-lw-meetups-atlanta-austin-moscow-ottawa-vancouver", "pageUrlRelative": "/posts/9Zt3vjcYjpvzcWwDJ/weekly-lw-meetups-atlanta-austin-moscow-ottawa-vancouver", "linkUrl": "https://www.lesswrong.com/posts/9Zt3vjcYjpvzcWwDJ/weekly-lw-meetups-atlanta-austin-moscow-ottawa-vancouver", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Atlanta%2C%20Austin%2C%20Moscow%2C%20Ottawa%2C%20Vancouver&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Atlanta%2C%20Austin%2C%20Moscow%2C%20Ottawa%2C%20Vancouver%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9Zt3vjcYjpvzcWwDJ%2Fweekly-lw-meetups-atlanta-austin-moscow-ottawa-vancouver%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Atlanta%2C%20Austin%2C%20Moscow%2C%20Ottawa%2C%20Vancouver%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9Zt3vjcYjpvzcWwDJ%2Fweekly-lw-meetups-atlanta-austin-moscow-ottawa-vancouver", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9Zt3vjcYjpvzcWwDJ%2Fweekly-lw-meetups-atlanta-austin-moscow-ottawa-vancouver", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 523, "htmlBody": "<p><strong>This summary was posted to LW main on May 10th. The following week's summary is <a href=\"/lw/hgn/new_lw_meetup_tel_aviv/\">here</a>.</strong></p>\n<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/mh\">London Special Guests: Jaan Tallinn and Michael Vassar of MetaMed :&nbsp;<span class=\"date\">11 May 2013 01:00PM</span></a></li>\n<li><a href=\"/meetups/mm\">Vancouver Microeconomics: Fungibility:&nbsp;<span class=\"date\">11 May 2013 03:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/md\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Moscow, Rationality and Media:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">12 May 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/ml\">LessWrong Ottawa:&nbsp;<span class=\"date\">13 May 2013 07:30PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m4\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">17 May 2013 07:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m5\">Brussels meetup:&nbsp;<span class=\"date\">18 May 2013 01:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m2\">Bratislava lesswrong meetup III:&nbsp;<span class=\"date\">20 May 2013 06:30PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly&nbsp;scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">11 May 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/lt\">Vienna meetup #3:&nbsp;<span class=\"date\">18 May 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/mn\">Seattle-Vancouver Kilomeetup:&nbsp;<span class=\"date\">18 May 2013 11:54AM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9Zt3vjcYjpvzcWwDJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2022613538855505e-06, "legacy": true, "legacyId": "22553", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ij8ZF7Bo9CSeY3rL7", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T15:26:03.583Z", "modifiedAt": null, "url": null, "title": "Morality should be Moral", "slug": "morality-should-be-moral", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:57.687Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OrphanWilde", "createdAt": "2012-06-21T18:24:36.749Z", "isAdmin": false, "displayName": "OrphanWilde"}, "userId": "cdW87AS6fdK2sywL2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wfWsimkCSo7Ma3ees/morality-should-be-moral", "pageUrlRelative": "/posts/wfWsimkCSo7Ma3ees/morality-should-be-moral", "linkUrl": "https://www.lesswrong.com/posts/wfWsimkCSo7Ma3ees/morality-should-be-moral", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Morality%20should%20be%20Moral&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMorality%20should%20be%20Moral%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwfWsimkCSo7Ma3ees%2Fmorality-should-be-moral%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Morality%20should%20be%20Moral%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwfWsimkCSo7Ma3ees%2Fmorality-should-be-moral", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwfWsimkCSo7Ma3ees%2Fmorality-should-be-moral", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 889, "htmlBody": "<p>This article is just some major questions concerning morality, then broken up into sub-questions to try to assist somebody in answering the major question; it's not a criticism of any morality in particular, but rather what I hope is a useful way to consider any moral system, and hopefully to help people challenge their own assumptions about their own moral systems. &nbsp;I don't expect responses to try to answer these questions; indeed, I'd prefer you don't. &nbsp;My preferred responses would be changes, additions, clarifications, or challenges to the questions or to the objective of this article.</p>\n<p>&nbsp;</p>\n<p>First major question: Could you morally advocate other people adopt your moral system?</p>\n<p>&nbsp;</p>\n<p>This isn't as trivial a question as it seems on its face. &nbsp;Take a strawman hedonism, for a very simple example. &nbsp;Is a hedonist's pleasure maximized by encouraging other people to pursue -their- pleasure? &nbsp;Or would it be better served by convincing them to pursue other people's (a class of people of which our strawman hedonist is a member) pleasure?</p>\n<p>&nbsp;</p>\n<p>It's not merely selfish moralities which suffer meta-moral problems. &nbsp;I've encountered a few near-Comtean altruists who will readily admit their morality makes them miserable; the idea that other people are worse off than them fills them with a deep guilt which they cannot resolve. &nbsp;If their goal is truly the happiness of others, spreading their moral system is a short-term evil. &nbsp;(It may be a long-term good, depending on how they do their accounting, but non-moral altruism isn't actually a rare quality, so I think an honest accounting would suggest their moral system doesn't add much additional altruism to the system, only a lot of guilt about the fact that not much altruistic action is taking place.)</p>\n<p>&nbsp;</p>\n<p>Note: I use the word \"altruism\" here in its modern, non-Comtean sense. &nbsp;Altruism is that which benefits others.</p>\n<p>&nbsp;</p>\n<p>Does your moral system make you unhappy, on the whole? &nbsp;Does it, like most moral systems, place a value on happiness? &nbsp;Would it make the average person less or more happy, if they and they alone adopted it? &nbsp;Are your expectations of the moral value of your moral system predicated on an unrealistic scenario of universal acceptance? &nbsp;Maybe your moral system isn't itself very moral.</p>\n<p>&nbsp;</p>\n<p>Second: Do you think your moral system makes you a more moral person?</p>\n<p>&nbsp;</p>\n<p>Does your moral system promote moral actions? &nbsp;What percentage of your actions concerning your morality are spent feeling good because you feel like you've effectively promoted your moral system, rather than promoting the values inherent in it?</p>\n<p>&nbsp;</p>\n<p>Do you behave any differently than you would if you operated under a \"common law\" morality, such as social norms and laws? &nbsp;That is, does your ethical system make you behave differently than if you didn't possess it? &nbsp;Are you evaluating the merits of your moral system solely on how it answers hypothetical situations, rather than how it addresses your day-to-day life?</p>\n<p><br />Does your moral system promote behaviors you're uncomfortable with and/or could not actually do, such as pushing people in the way of trolleys to save more people?</p>\n<p>&nbsp;</p>\n<p>Third: Does your moral system promote morality, or itself as a moral system?</p>\n<p>&nbsp;</p>\n<p>Is the primary contribution of your moral system to your life adding outrage that other people -don't- follow your moral system? &nbsp;Do you feel that people who follow other moral systems are immoral even if they end up behaving in exactly the same way you do? &nbsp;Does your moral system imply complex calculations which aren't actually taking place? &nbsp;Is the primary purpose of your moral system encouraging moral behavior, or defining what the moral behavior would have been after the fact?</p>\n<p>&nbsp;</p>\n<p>Considered as a meme or memeplex, does your moral system seem better suited to propagating itself than to encouraging morality? &nbsp;Do you think \"The primary purpose of this moral system is ensuring that these morals continue to exist\" could be an accurate description of your moral system? &nbsp;Does the moral system promote the belief that people who don't follow it are completely immoral?</p>\n<p>&nbsp;</p>\n<p>Fourth: Is the major purpose of your morality morality itself?</p>\n<p>&nbsp;</p>\n<p>This is a rather tough question to elaborate with further questions, so I suppose I should try to clarify a bit first: Take a strawman utilitarianism where \"utility\" -really is- what the morality is all about, where somebody has painstakingly gone through and assigned utility points to various things (this is kind of common in game-based moral systems, where you're just accumulating some kind of moral points, positive or negative). &nbsp;Or imagine (tough, I know) a religious morality where the sole objective of the moral system is satisfying God's will. &nbsp;That is, does your moral system define morality to be about something abstract and immeasurable, defined only in the context of your moral system? &nbsp;Is your moral system a tautology, which must be accepted to even be meaningful?</p>\n<p>&nbsp;</p>\n<p>This one can be difficult to identify from the inside, because to some extent -all- human morality is tautological; you have to identify it with respect to other moralities, to see if it's a unique island of tautology, or whether it applies to human moral concerns in the general case. &nbsp;With that in mind, when you argue with other people about your ethical system, do they -always- seem to miss the point? &nbsp;Do they keep trying to reframe moral questions in terms of other moral systems? &nbsp;Do they bring up things which have nothing to do with (your) morality?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wfWsimkCSo7Ma3ees", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 12, "extendedScore": null, "score": 3.9e-05, "legacy": true, "legacyId": "22633", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 63, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T16:32:55.717Z", "modifiedAt": null, "url": null, "title": "Education control?", "slug": "education-control", "viewCount": null, "lastCommentedAt": "2013-05-29T08:44:04.978Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yYuon4QuxKn4iDq7h/education-control", "pageUrlRelative": "/posts/yYuon4QuxKn4iDq7h/education-control", "linkUrl": "https://www.lesswrong.com/posts/yYuon4QuxKn4iDq7h/education-control", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Education%20control%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEducation%20control%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyYuon4QuxKn4iDq7h%2Feducation-control%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Education%20control%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyYuon4QuxKn4iDq7h%2Feducation-control", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyYuon4QuxKn4iDq7h%2Feducation-control", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 505, "htmlBody": "<p>I'm reading <a href=\"http://amzn.to/13BemZJ\"><em>Nurture Shock</em></a> by Po Bronson &amp; Ashley Merryman. Several things in the book, esp. the chapter on \"Tools of the Mind\", an intriguing education program, suggest that our education of young children not only isn't very good even when evaluated using tests that the curriculum was designed for, it's worse than just letting kids play. (My analogy and interpretation&mdash;don't blame this on the Tools people&mdash;is that conventional education may be like a Soviet five-year plan, trying to force children to acquire skills &amp; knowledge that they would have been motivated to learn on their own if there weren't a school, and that early education shouldn't focus entirely on teaching specific facts, but also on teaching how to think, form abstractions, and control impulses.)</p>\n<p>Say they're going to play fireman. The Tools teacher teaches the kids about what firemen do and what happens in a fire, and gives the kids different roles to play, then lets them play. They teach facts not because the facts are important, but to make the play session longer and more complicated.&nbsp; Tools does well in increasing test scores, but even better at reducing disruptive behavior. [1]</p>\n<p>Tools has a variety of computer games that are designed to get kids to exercise particular cognitive skills, like focusing on something while being aware of background events. But the games often sound like more-boring ways of teaching kids the same things that video-games teach them.</p>\n<p>Tools did no better than the existing curriculum on certain metrics in a recent <a href=\"http://www.danielwillingham.com/1/post/2012/08/promising-pre-k-curriculum-looking-less-promising.html\">larger study</a>. But it didn't perform worse, either.</p>\n<p>The first study you do with any biological intervention is to compare the intervention to a control group that has no intervention. But in education, AFAIK no one has ever done this. Everyone uses the existing curriculum as the control.</p>\n<p>Whatever country you're in, what metrics do you use, and what evidence do you have that your schools are better than nothing at all?</p>\n<p>There may be some things that you need to sit kids down and force them to learn&mdash;say, arithmetic, math, and typing&mdash;but I kinda doubt it's more than 20% of the grade school curriculum. I spent a lot of time practicing penmanship, futilely trying to memorizing the capitals and chief exports of all fifty states, and studying the history of Thanksgiving and the American Revolution over and over again.[2] We could have a short-hours classroom hours control group, where kids spend a few hours a day learning those few facts they need to know, and the rest of the time playing.</p>\n<p>ADDED: There is one kind of control--kids who've not gone to pre-school vs. kids who went to pre-school, or who went to <a href=\"http://en.wikipedia.org/wiki/Head_Start_Program\">Head Start</a>.</p>\n<p>&nbsp;</p>\n<p>[1] I fear somebody is going to complain that disruptive behavior is what we need to teach children so they can innovate and question authority. Open to discussion, but if it worked that way, we'd be overwhelmed with innovators and independent thinkers today.</p>\n<p>[2] I actually learned the names of all the states from a song, and learned where they are from a jigsaw puzzle.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yYuon4QuxKn4iDq7h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 21, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "22635", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T16:52:53.105Z", "modifiedAt": null, "url": null, "title": "Meetup : First Bristol meetup", "slug": "meetup-first-bristol-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:34.521Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benja", "createdAt": "2009-02-27T04:37:47.476Z", "isAdmin": false, "displayName": "Benya"}, "userId": "3vZZP8TBXvozbe5Cv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dpYSHeY2CkwibM5GP/meetup-first-bristol-meetup", "pageUrlRelative": "/posts/dpYSHeY2CkwibM5GP/meetup-first-bristol-meetup", "linkUrl": "https://www.lesswrong.com/posts/dpYSHeY2CkwibM5GP/meetup-first-bristol-meetup", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20First%20Bristol%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20First%20Bristol%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdpYSHeY2CkwibM5GP%2Fmeetup-first-bristol-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20First%20Bristol%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdpYSHeY2CkwibM5GP%2Fmeetup-first-bristol-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdpYSHeY2CkwibM5GP%2Fmeetup-first-bristol-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 92, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mx'>First Bristol meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">25 May 2013 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Friska Queens Road (on the Clifton triangle), Bristol</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Back in 2010, Bristol had <a href=\"http://lesswrong.com/lw/43s/starting_a_lw_meetup_is_easy/3gbz\">4000+ unique LW visitors</a>, but we've never had a meetup -- let's try and see what happens! I'll be in the <a href=\"https://maps.google.co.uk/maps?f=q&amp;source=embed&amp;hl=en&amp;geocode=&amp;q=http:%2F%2Fwww.friskafood.com%2Ffriska_clifton.kml&amp;aq=&amp;sll=51.44165,-2.562218&amp;sspn=0.017013,0.04755&amp;ie=UTF8&amp;t=m&amp;ll=51.47144,-2.613373&amp;spn=0.037532,0.073299&amp;z=13&amp;iwloc=lyrftr:kml:cF4pKjzpLljPRqPQIB6TAMGTakQA,g93b8002627e1b750,51.456895,-2.607536,0,-32\" rel=\"nofollow\">Friska on Queens Road</a> (on the Clifton triangle, right next to the university campus) on Saturday the 25th at 3pm, with a LessWrong sign and a paperback of HPMOR. Anyone going to join me? :-)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mx'>First Bristol meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dpYSHeY2CkwibM5GP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.2023484277648302e-06, "legacy": true, "legacyId": "22636", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___First_Bristol_meetup\">Discussion article for the meetup : <a href=\"/meetups/mx\">First Bristol meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">25 May 2013 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Friska Queens Road (on the Clifton triangle), Bristol</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Back in 2010, Bristol had <a href=\"http://lesswrong.com/lw/43s/starting_a_lw_meetup_is_easy/3gbz\">4000+ unique LW visitors</a>, but we've never had a meetup -- let's try and see what happens! I'll be in the <a href=\"https://maps.google.co.uk/maps?f=q&amp;source=embed&amp;hl=en&amp;geocode=&amp;q=http:%2F%2Fwww.friskafood.com%2Ffriska_clifton.kml&amp;aq=&amp;sll=51.44165,-2.562218&amp;sspn=0.017013,0.04755&amp;ie=UTF8&amp;t=m&amp;ll=51.47144,-2.613373&amp;spn=0.037532,0.073299&amp;z=13&amp;iwloc=lyrftr:kml:cF4pKjzpLljPRqPQIB6TAMGTakQA,g93b8002627e1b750,51.456895,-2.607536,0,-32\" rel=\"nofollow\">Friska on Queens Road</a> (on the Clifton triangle, right next to the university campus) on Saturday the 25th at 3pm, with a LessWrong sign and a paperback of HPMOR. Anyone going to join me? :-)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___First_Bristol_meetup1\">Discussion article for the meetup : <a href=\"/meetups/mx\">First Bristol meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : First Bristol meetup", "anchor": "Discussion_article_for_the_meetup___First_Bristol_meetup", "level": 1}, {"title": "Discussion article for the meetup : First Bristol meetup", "anchor": "Discussion_article_for_the_meetup___First_Bristol_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "10 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T17:57:27.518Z", "modifiedAt": null, "url": null, "title": "Meetup : [Cambridge] Sunk Cost Kata", "slug": "meetup-cambridge-sunk-cost-kata", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:36.793Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mT7LJfvTkkuec9kJ8/meetup-cambridge-sunk-cost-kata", "pageUrlRelative": "/posts/mT7LJfvTkkuec9kJ8/meetup-cambridge-sunk-cost-kata", "linkUrl": "https://www.lesswrong.com/posts/mT7LJfvTkkuec9kJ8/meetup-cambridge-sunk-cost-kata", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BCambridge%5D%20Sunk%20Cost%20Kata&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BCambridge%5D%20Sunk%20Cost%20Kata%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmT7LJfvTkkuec9kJ8%2Fmeetup-cambridge-sunk-cost-kata%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BCambridge%5D%20Sunk%20Cost%20Kata%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmT7LJfvTkkuec9kJ8%2Fmeetup-cambridge-sunk-cost-kata", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmT7LJfvTkkuec9kJ8%2Fmeetup-cambridge-sunk-cost-kata", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/my'>[Cambridge] Sunk Cost Kata</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">19 May 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">21 Ames St, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll present the Center for Applied Rationality's material on sunk costs and go over their exercises on how to apply this knowledge in daily life.</p>\n\n<p>Cambridge/Boston-area Less Wrong meetups are on the first and third Sunday of every month at 2pm in the MIT Whitaker Building (21 Ames St, Bldg 56), room 180. Room number subject to change based on availability. Signs will be posted with the actual room number. The side doors are sometimes locked; if so, you can get in through the main door at 25 Ames St.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/my'>[Cambridge] Sunk Cost Kata</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mT7LJfvTkkuec9kJ8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.2023954246628268e-06, "legacy": true, "legacyId": "22637", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Cambridge__Sunk_Cost_Kata\">Discussion article for the meetup : <a href=\"/meetups/my\">[Cambridge] Sunk Cost Kata</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">19 May 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">21 Ames St, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll present the Center for Applied Rationality's material on sunk costs and go over their exercises on how to apply this knowledge in daily life.</p>\n\n<p>Cambridge/Boston-area Less Wrong meetups are on the first and third Sunday of every month at 2pm in the MIT Whitaker Building (21 Ames St, Bldg 56), room 180. Room number subject to change based on availability. Signs will be posted with the actual room number. The side doors are sometimes locked; if so, you can get in through the main door at 25 Ames St.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Cambridge__Sunk_Cost_Kata1\">Discussion article for the meetup : <a href=\"/meetups/my\">[Cambridge] Sunk Cost Kata</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Cambridge] Sunk Cost Kata", "anchor": "Discussion_article_for_the_meetup____Cambridge__Sunk_Cost_Kata", "level": 1}, {"title": "Discussion article for the meetup : [Cambridge] Sunk Cost Kata", "anchor": "Discussion_article_for_the_meetup____Cambridge__Sunk_Cost_Kata1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-17T19:45:45.739Z", "modifiedAt": null, "url": null, "title": "LINK: Google research chief: 'Emergent artificial intelligence? Hogwash!'", "slug": "link-google-research-chief-emergent-artificial-intelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:35.891Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/35BoNAJRh7HkYvfZx/link-google-research-chief-emergent-artificial-intelligence", "pageUrlRelative": "/posts/35BoNAJRh7HkYvfZx/link-google-research-chief-emergent-artificial-intelligence", "linkUrl": "https://www.lesswrong.com/posts/35BoNAJRh7HkYvfZx/link-google-research-chief-emergent-artificial-intelligence", "postedAtFormatted": "Friday, May 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LINK%3A%20Google%20research%20chief%3A%20'Emergent%20artificial%20intelligence%3F%20Hogwash!'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALINK%3A%20Google%20research%20chief%3A%20'Emergent%20artificial%20intelligence%3F%20Hogwash!'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F35BoNAJRh7HkYvfZx%2Flink-google-research-chief-emergent-artificial-intelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LINK%3A%20Google%20research%20chief%3A%20'Emergent%20artificial%20intelligence%3F%20Hogwash!'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F35BoNAJRh7HkYvfZx%2Flink-google-research-chief-emergent-artificial-intelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F35BoNAJRh7HkYvfZx%2Flink-google-research-chief-emergent-artificial-intelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 250, "htmlBody": "<p><a href=\"http://www.theregister.co.uk/2013/05/17/google_ai_hogwash/\">The Register</a>&nbsp;talks to Google's&nbsp;<a href=\"http://en.wikipedia.org/wiki/Alfred_Spector\">Alfred Spector</a>:</p>\n<p style=\"font-family: Arial, FreeSans, Helvetica, sans-serif; font-size: 14px; line-height: 21px; padding-left: 30px;\">Google's approach toward artificial intelligence embodies a new way of designing and running complex systems. Rather than create a <strong>monolithic entity with its own modules for reasoning about certain inputs and developing hypotheses that let it bootstrap its own intelligence into higher and higher abstractions away from base inputs</strong>, as other AI researchers did through much of the 60s and 70s, Google has instead taken a modular approach.</p>\n<p style=\"font-family: Arial, FreeSans, Helvetica, sans-serif; font-size: 14px; line-height: 21px; padding-left: 30px;\">\"We have the knowledge graph, [the] ability to parse natural language, neural network tech [and] enormous opportunities to gain feedback from users,\" Spector said in an earlier speech at Google IO. \"<strong>If we combine all these things together with humans in the loop continually providing feedback our systems become ... intelligent.</strong>\"</p>\n<p style=\"font-family: Arial, FreeSans, Helvetica, sans-serif; font-size: 14px; line-height: 21px; padding-left: 30px;\">Spector calls this his \"combination hypothesis\", and though Google is not there yet &ndash; SkyNet does not exist &ndash; you can see the first green buds of systems that have the appearance of independent intelligence via some of the company's user-predictive technologies such as Google Now, the new Maps and, of course, the way it filters search results according to individual identity.</p>\n<p style=\"font-family: Arial, FreeSans, Helvetica, sans-serif; font-size: 14px; line-height: 21px;\">(Emphasis mine.) I don't have a transcript, but there are videos online. Spector is clearly smart, and apparently he expects an AI to appear in a completely different way than Eliezer does. And he has all the resources and financing he wants, probably 3-4 orders of magnitude over MIRI's. His approach, if workable, also appears safe: it requires human feedback in the loop. What do you guys think?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"N3CqcPdCZNspF9bFb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "35BoNAJRh7HkYvfZx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 6, "extendedScore": null, "score": 1.2024742558389927e-06, "legacy": true, "legacyId": "22638", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-18T18:31:10.901Z", "modifiedAt": null, "url": null, "title": "[Paper] On the 'Simulation Argument' and Selective Scepticism", "slug": "paper-on-the-simulation-argument-and-selective-scepticism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:39.992Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pablo_Stafforini", "createdAt": "2009-03-24T12:56:00.130Z", "isAdmin": false, "displayName": "Pablo"}, "userId": "W7ETRtvRMqYetyQE9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Bk9natf6bywLYTxsv/paper-on-the-simulation-argument-and-selective-scepticism", "pageUrlRelative": "/posts/Bk9natf6bywLYTxsv/paper-on-the-simulation-argument-and-selective-scepticism", "linkUrl": "https://www.lesswrong.com/posts/Bk9natf6bywLYTxsv/paper-on-the-simulation-argument-and-selective-scepticism", "postedAtFormatted": "Saturday, May 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BPaper%5D%20On%20the%20'Simulation%20Argument'%20and%20Selective%20Scepticism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BPaper%5D%20On%20the%20'Simulation%20Argument'%20and%20Selective%20Scepticism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBk9natf6bywLYTxsv%2Fpaper-on-the-simulation-argument-and-selective-scepticism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BPaper%5D%20On%20the%20'Simulation%20Argument'%20and%20Selective%20Scepticism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBk9natf6bywLYTxsv%2Fpaper-on-the-simulation-argument-and-selective-scepticism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBk9natf6bywLYTxsv%2Fpaper-on-the-simulation-argument-and-selective-scepticism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>Jonathan Birch recently <a href=\"http://philpapers.org/rec/BIROTS\">published</a> an interesting critique of Bostrom's simulation argument. &nbsp;Here's the abstract:</p>\n<blockquote>\n<p>Nick Bostrom&rsquo;s &lsquo;Simulation Argument&rsquo; purports to show that, unless we are confident that advanced &lsquo;posthuman&rsquo; civilizations are either extremely rare or extremely rarely interested in running simulations of their own ancestors, we should assign significant credence to the hypothesis that we are simulated. I argue that Bostrom does not succeed in grounding this constraint on credence. I first show that the Simulation Argument requires a curious form of selective scepticism, for it presupposes that we possess good evidence for claims about the physical limits of computation and yet lack good evidence for claims about our own physical constitution. I then show that two ways of modifying the argument so as to remove the need for this presupposition fail to preserve the original conclusion. Finally, I argue that, while there are unusual circumstances in which Bostrom&rsquo;s selective scepticism might be reasonable, we do not currently find ourselves in such circumstances. There is no good reason to uphold the selective scepticism the Simulation Argument presupposes. There is thus no good reason to believe its conclusion.</p>\n</blockquote>\n<p>The paper is behind a paywall, but I have uploaded it to my shared Dropbox folder, <a href=\"https://www.dropbox.com/sh/ifrylhwtyq8xyke/qmAqhqMYds/Birch%20-%20On%20the%20%E2%80%98simulation%20argument%E2%80%99%20and%20selective%20scepticism.pdf\">here</a>.</p>\n<p>EDIT: I emailed the author and am glad to see that he's decided to participate in the discussion below.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Bk9natf6bywLYTxsv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 14, "extendedScore": null, "score": 1.2034688908328854e-06, "legacy": true, "legacyId": "22641", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-18T19:47:43.270Z", "modifiedAt": null, "url": null, "title": "[LINK] Evidence-based giving by Laura and John Arnold Foundation", "slug": "link-evidence-based-giving-by-laura-and-john-arnold", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:35.204Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "brilee", "createdAt": "2009-11-24T14:36:56.816Z", "isAdmin": false, "displayName": "brilee"}, "userId": "bbMiGjzXWpEqRMwe6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yXht5NS3QmZQMzrNg/link-evidence-based-giving-by-laura-and-john-arnold", "pageUrlRelative": "/posts/yXht5NS3QmZQMzrNg/link-evidence-based-giving-by-laura-and-john-arnold", "linkUrl": "https://www.lesswrong.com/posts/yXht5NS3QmZQMzrNg/link-evidence-based-giving-by-laura-and-john-arnold", "postedAtFormatted": "Saturday, May 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Evidence-based%20giving%20by%20Laura%20and%20John%20Arnold%20Foundation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Evidence-based%20giving%20by%20Laura%20and%20John%20Arnold%20Foundation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyXht5NS3QmZQMzrNg%2Flink-evidence-based-giving-by-laura-and-john-arnold%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Evidence-based%20giving%20by%20Laura%20and%20John%20Arnold%20Foundation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyXht5NS3QmZQMzrNg%2Flink-evidence-based-giving-by-laura-and-john-arnold", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyXht5NS3QmZQMzrNg%2Flink-evidence-based-giving-by-laura-and-john-arnold", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 25, "htmlBody": "<p>http://online.wsj.com/article/SB10001424127887323372504578466992305986654.html</p>\n<p>&nbsp;</p>\n<p>Apparently a hedge fundie made 4 billion and is giving most of it away to what the WSJ describes as a \"moneyball\" approach to giving.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yXht5NS3QmZQMzrNg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 3, "extendedScore": null, "score": 1.203524688825412e-06, "legacy": true, "legacyId": "22643", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-19T07:49:00.825Z", "modifiedAt": null, "url": null, "title": "Epistemic and Instrumental Tradeoffs", "slug": "epistemic-and-instrumental-tradeoffs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:03.100Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "katydee", "createdAt": "2010-07-09T10:33:52.237Z", "isAdmin": false, "displayName": "katydee"}, "userId": "uHpk5J2f7BPBoiJFX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hZud7CxcEqfYTL7YX/epistemic-and-instrumental-tradeoffs", "pageUrlRelative": "/posts/hZud7CxcEqfYTL7YX/epistemic-and-instrumental-tradeoffs", "linkUrl": "https://www.lesswrong.com/posts/hZud7CxcEqfYTL7YX/epistemic-and-instrumental-tradeoffs", "postedAtFormatted": "Sunday, May 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Epistemic%20and%20Instrumental%20Tradeoffs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEpistemic%20and%20Instrumental%20Tradeoffs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhZud7CxcEqfYTL7YX%2Fepistemic-and-instrumental-tradeoffs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Epistemic%20and%20Instrumental%20Tradeoffs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhZud7CxcEqfYTL7YX%2Fepistemic-and-instrumental-tradeoffs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhZud7CxcEqfYTL7YX%2Fepistemic-and-instrumental-tradeoffs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 521, "htmlBody": "<p><strong>Related:</strong> <a href=\"/lw/31/what_do_we_mean_by_rationality/\">What Do We Mean By \"Rationality?\"</a></p>\n<p><a href=\"http://wiki.lesswrong.com/wiki/Rationality#Epistemic_rationality\">Epistemic rationality</a> and <a href=\"http://wiki.lesswrong.com/wiki/Rationality#Instrumental_rationality\">instrumental rationality</a> are both useful. However, some things may benefit one form of rationality yet detract from another. These tradeoffs are often not obvious, but can have serious consequences.</p>\n<p>For instance, take the example of learning debate skills. While involved in debate in high school, I learned how to argue a position quite convincingly, muster strong supporting evidence, prepare rebuttals for counterarguments, prepare deflections for counterarguments that are difficult to rebut, and so on.</p>\n<p>I also learned how to do so <em><a href=\"http://wiki.lesswrong.com/wiki/Arguments_as_soldiers\">regardless of what side of a topic I was assigned to</a>.</em></p>\n<p>My debate experience has made me a more convincing and more charismatic person, improved my public speaking skills, and bolstered my ability to win arguments. Instrumentally speaking, this can be a very useful skillset. Epistemically speaking, this sort of preparation is very dangerous, and I later had to unlearn many of these thought patterns in order to become better at finding the truth.</p>\n<p>For example, when writing research papers, the type of <a href=\"http://wiki.lesswrong.com/wiki/Motivated_cognition\">motivated cognition</a> used when searching for evidence to bolster a position in a debate is often counterproductive. Similarly, when discussing what the best move for my business to make is, the ability to argue convincingly for a position <em>regardless of whether it is right</em> is outright dangerous, and lessons learned from debate may actually decrease the odds of making the correct decision-- if I'm wrong but convincing and my colleagues are right but unconvincing, we could very well end up going down the wrong path!</p>\n<p>Epistemic and instrumental goals may also conflict in other ways. For instance, <a href=\"http://www.princeton.edu/%7Etkelly/papers/epistemicasinstrumental.pdf\">Kelly (2003)</a><sup>[1]</sup> points out that, from an epistemic rationality perspective, learning movie spoilers is desirable, since they will improve your model of the world. Nevertheless, many people consider spoilers to be instrumentally negative, since they prefer the tension of not knowing what will happen while they watch a movie.</p>\n<p><a href=\"http://www.nickbostrom.com/information-hazards.pdf\">Bostrom (2011)</a><sup>[2]</sup> describes many more situations where having a more accurate model of the world can be hazardous to various instrumental objectives. For instance, knowing where the best parties are held on campus can be a very useful piece of knowledge to have in many contexts, but can become a distracting temptation when you're writing your thesis. Knowing that one of your best friends has just died can be very relevant to your model of the world, but can also cause you to become dangerously depressed. Knowing that Stalin's wife <a href=\"http://en.wikipedia.org/wiki/Nadezhda_Alliluyeva\">didn't die from appendicitis</a> can be useful for understanding certain motivations, but can be extraordinarily dangerous to know if the secret police come calling.</p>\n<p>Thus, epistemic and instrumental rationality can in some cases come into conflict. Some instrumental skillsets might be better off neglected for reasons of <a href=\"http://wiki.lesswrong.com/wiki/Epistemic_hygiene\">epistemic hygeine</a>; similarly, some epistemic ventures might yield information that it would be instrumentally better not to know. When developing rationality practices and honing one's skills, we should take care to acknowledge these tradeoffs and plan accordingly.</p>\n<p>&nbsp;</p>\n<p>[1] Kelly, T., (2003). Epistemic Rationality as Instrumental Rationality: A Critique. <em>Philosophy and Phenomenological Research</em>, 66(3), <span id=\"ctl00_MainContent_PaperItem_YearJournal\" class=\"year\">pp. 612-640.</span></p>\n<p><span class=\"year\">[2] Bostrom, N., (2011). </span>Information Hazards: A Typology of Harms from Knowledge. <em>Review of Contemporary Philosophy, </em>10, pp. 44-79.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hZud7CxcEqfYTL7YX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 29, "extendedScore": null, "score": 7.2e-05, "legacy": true, "legacyId": "22639", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-19T08:03:05.421Z", "modifiedAt": null, "url": null, "title": "Terminology suggestion: Say \"degrees utility\" instead of \"utils\" to prompt affine thinking", "slug": "terminology-suggestion-say-degrees-utility-instead-of-utils", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:37.062Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Sniffnoy", "createdAt": "2009-10-25T00:27:41.113Z", "isAdmin": false, "displayName": "Sniffnoy"}, "userId": "66EwcncPSoZ25StpW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qgCkkkCrDz8qWiPZn/terminology-suggestion-say-degrees-utility-instead-of-utils", "pageUrlRelative": "/posts/qgCkkkCrDz8qWiPZn/terminology-suggestion-say-degrees-utility-instead-of-utils", "linkUrl": "https://www.lesswrong.com/posts/qgCkkkCrDz8qWiPZn/terminology-suggestion-say-degrees-utility-instead-of-utils", "postedAtFormatted": "Sunday, May 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Terminology%20suggestion%3A%20Say%20%22degrees%20utility%22%20instead%20of%20%22utils%22%20to%20prompt%20affine%20thinking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATerminology%20suggestion%3A%20Say%20%22degrees%20utility%22%20instead%20of%20%22utils%22%20to%20prompt%20affine%20thinking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgCkkkCrDz8qWiPZn%2Fterminology-suggestion-say-degrees-utility-instead-of-utils%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Terminology%20suggestion%3A%20Say%20%22degrees%20utility%22%20instead%20of%20%22utils%22%20to%20prompt%20affine%20thinking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgCkkkCrDz8qWiPZn%2Fterminology-suggestion-say-degrees-utility-instead-of-utils", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqgCkkkCrDz8qWiPZn%2Fterminology-suggestion-say-degrees-utility-instead-of-utils", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 349, "htmlBody": "<p><a href=\"/lw/ggm/pinpointing_utility/\">A common mistake people make with utility functions is taking individual utility numbers as meaningful</a>, and performing operations such as adding them or doubling them.&nbsp; But utility functions are only defined up to positive affine transformation.</p>\n<p>Talking about \"utils\" seems like it would encourage this sort of mistake; it makes it sound like some sort of quantity of <em>stuff</em>, that can be meaningfully added, scaled, etc.&nbsp; Now the use of a unit -- \"utils\" -- instead of bare real numbers does remind us that the scale we've picked is arbitrary, but it doesn't remind us that the <em>zero</em> we've picked is also arbitrary, and encourages such illegal operations as addition and scaling.&nbsp; It suggests linear, not affine.</p>\n<p>But there is a common everyday quantity which we ordinarily measure with an affine scale, and that's temperature.&nbsp; Now, in fact, temperatures really do have an absolute zero (and if you make sufficient use natural units, they have an absolute scale, as well), but generally we measure temperature with scales that were invented before that fact was recognized.&nbsp; And so while we may have Kelvins, we have \"degrees Fahrenheit\" or \"degrees Celsius\".</p>\n<p>If you've used these scales long enough you recognize that it is meaningless to e.g. add things measured on these scales, or to multiply them by scalars.&nbsp; So I think it would be a helpful cognitive reminder to say something like \"degrees utility\" instead of \"utils\", to suggest an affine scale like we use for temperature, rather than a linear scale like we use for length or time or mass.</p>\n<p>The analogy isn't entirely perfect, because as I've mentioned above, temperature actually can be measured on a linear scale (and with sufficient use of natural units, an absolute scale); but the point is just to prompt the right style of thinking, and in everyday life we usually think of temperature as an (ordered) affine thing, like utility.</p>\n<p>As such I recommend saying \"degrees utility\" instead of \"utils\".&nbsp; If there is some other familiar quantity we also tend to use an affine scale for, perhaps an analogy with that could be used instead or as well.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qgCkkkCrDz8qWiPZn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 14, "extendedScore": null, "score": 1.2040610131785587e-06, "legacy": true, "legacyId": "22644", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CQkGJ2t5Rw8GcZKJm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-19T16:39:29.354Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - Probabilistic Graphical Models, Take 2!", "slug": "meetup-west-la-meetup-probabilistic-graphical-models-take-2", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XvEwTPmJ5iZfzehkR/meetup-west-la-meetup-probabilistic-graphical-models-take-2", "pageUrlRelative": "/posts/XvEwTPmJ5iZfzehkR/meetup-west-la-meetup-probabilistic-graphical-models-take-2", "linkUrl": "https://www.lesswrong.com/posts/XvEwTPmJ5iZfzehkR/meetup-west-la-meetup-probabilistic-graphical-models-take-2", "postedAtFormatted": "Sunday, May 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20Probabilistic%20Graphical%20Models%2C%20Take%202!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20Probabilistic%20Graphical%20Models%2C%20Take%202!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXvEwTPmJ5iZfzehkR%2Fmeetup-west-la-meetup-probabilistic-graphical-models-take-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20Probabilistic%20Graphical%20Models%2C%20Take%202!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXvEwTPmJ5iZfzehkR%2Fmeetup-west-la-meetup-probabilistic-graphical-models-take-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXvEwTPmJ5iZfzehkR%2Fmeetup-west-la-meetup-probabilistic-graphical-models-take-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/mz'>West LA Meetup - Probabilistic Graphical Models, Take 2!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 May 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm Wednesday, May 22nd.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Lecture/Discussion:</strong> Graphs can make understanding causality very intuitive and easy. They are also a powerful tool for doing more complicated modeling. I will introduce PGMs as a concept, and show a few examples where they can be useful.</p>\n\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/mz'>West LA Meetup - Probabilistic Graphical Models, Take 2!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XvEwTPmJ5iZfzehkR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2044378894405928e-06, "legacy": true, "legacyId": "22647", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Probabilistic_Graphical_Models__Take_2_\">Discussion article for the meetup : <a href=\"/meetups/mz\">West LA Meetup - Probabilistic Graphical Models, Take 2!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 May 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm Wednesday, May 22nd.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Lecture/Discussion:</strong> Graphs can make understanding causality very intuitive and easy. They are also a powerful tool for doing more complicated modeling. I will introduce PGMs as a concept, and show a few examples where they can be useful.</p>\n\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Probabilistic_Graphical_Models__Take_2_1\">Discussion article for the meetup : <a href=\"/meetups/mz\">West LA Meetup - Probabilistic Graphical Models, Take 2!</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - Probabilistic Graphical Models, Take 2!", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Probabilistic_Graphical_Models__Take_2_", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - Probabilistic Graphical Models, Take 2!", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Probabilistic_Graphical_Models__Take_2_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-20T14:35:36.863Z", "modifiedAt": null, "url": null, "title": "Meetup : Buffalo LW Thursday meetup", "slug": "meetup-buffalo-lw-thursday-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "StonesOnCanvas", "createdAt": "2012-06-28T17:32:49.237Z", "isAdmin": false, "displayName": "StonesOnCanvas"}, "userId": "FAfkKGH6E8BLmXW4M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sjFdgrD9Je4Eqxqny/meetup-buffalo-lw-thursday-meetup", "pageUrlRelative": "/posts/sjFdgrD9Je4Eqxqny/meetup-buffalo-lw-thursday-meetup", "linkUrl": "https://www.lesswrong.com/posts/sjFdgrD9Je4Eqxqny/meetup-buffalo-lw-thursday-meetup", "postedAtFormatted": "Monday, May 20th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Buffalo%20LW%20Thursday%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Buffalo%20LW%20Thursday%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsjFdgrD9Je4Eqxqny%2Fmeetup-buffalo-lw-thursday-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Buffalo%20LW%20Thursday%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsjFdgrD9Je4Eqxqny%2Fmeetup-buffalo-lw-thursday-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsjFdgrD9Je4Eqxqny%2Fmeetup-buffalo-lw-thursday-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 141, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n0'>Buffalo LW Thursday meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">University at Buffalo- North Campus 31 Capen Hall</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Buffalo-area Less Wrong meetups on the first Sunday and Third Thursday of every month, in 31 Capen Hall at the University at Buffalo - North Campus.</p>\n\n<p>Hey all, \nWe're going to be talking about inferential distance. We'll have a few articles to demonstrate the idea and how it effects arguments (and perhaps what you could do if you notice its happening to you). As always, don't worry if you haven't read the article, we'll either read it beforehand or give a short cliff notes version of it.</p>\n\n<p>PS. James is doing a lot of the organizing for this one, so we should all give him major brownie points for it!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n0'>Buffalo LW Thursday meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sjFdgrD9Je4Eqxqny", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2053993629730045e-06, "legacy": true, "legacyId": "22656", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Buffalo_LW_Thursday_meetup\">Discussion article for the meetup : <a href=\"/meetups/n0\">Buffalo LW Thursday meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 May 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">University at Buffalo- North Campus 31 Capen Hall</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Buffalo-area Less Wrong meetups on the first Sunday and Third Thursday of every month, in 31 Capen Hall at the University at Buffalo - North Campus.</p>\n\n<p>Hey all, \nWe're going to be talking about inferential distance. We'll have a few articles to demonstrate the idea and how it effects arguments (and perhaps what you could do if you notice its happening to you). As always, don't worry if you haven't read the article, we'll either read it beforehand or give a short cliff notes version of it.</p>\n\n<p>PS. James is doing a lot of the organizing for this one, so we should all give him major brownie points for it!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Buffalo_LW_Thursday_meetup1\">Discussion article for the meetup : <a href=\"/meetups/n0\">Buffalo LW Thursday meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Buffalo LW Thursday meetup", "anchor": "Discussion_article_for_the_meetup___Buffalo_LW_Thursday_meetup", "level": 1}, {"title": "Discussion article for the meetup : Buffalo LW Thursday meetup", "anchor": "Discussion_article_for_the_meetup___Buffalo_LW_Thursday_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-20T17:56:59.904Z", "modifiedAt": null, "url": null, "title": "Meetup : RTLW Meetup: Contra Dance!", "slug": "meetup-rtlw-meetup-contra-dance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:35.723Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6ZzevvYhLP8CL5Lb9/meetup-rtlw-meetup-contra-dance", "pageUrlRelative": "/posts/6ZzevvYhLP8CL5Lb9/meetup-rtlw-meetup-contra-dance", "linkUrl": "https://www.lesswrong.com/posts/6ZzevvYhLP8CL5Lb9/meetup-rtlw-meetup-contra-dance", "postedAtFormatted": "Monday, May 20th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20RTLW%20Meetup%3A%20Contra%20Dance!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20RTLW%20Meetup%3A%20Contra%20Dance!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6ZzevvYhLP8CL5Lb9%2Fmeetup-rtlw-meetup-contra-dance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20RTLW%20Meetup%3A%20Contra%20Dance!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6ZzevvYhLP8CL5Lb9%2Fmeetup-rtlw-meetup-contra-dance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6ZzevvYhLP8CL5Lb9%2Fmeetup-rtlw-meetup-contra-dance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 251, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n1'>RTLW Meetup: Contra Dance!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 May 2013 06:50:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">100 N Greensboro St, Carrboro NC 27510</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>In lieu of our regular coffee and discussion, this week's meetup will be held at the Century Center in Carrboro, where A GREAT DANCE will be taking place.</p>\n\n<p>If you're a new dancer, there will be an intro lesson at 7 that will cover much of what you'll need to know. Try to arrive by about 6:50.</p>\n\n<p>If you can't arrive in time for the lesson or find you are running late, please come dance anyway! Ruthan, David, Evan, or any other experienced dancer will be happy to help you.</p>\n\n<p>You will need: <br />\n* $10 for admission <br />\n* Your dancing feet, in smooth-soled shoes, flat or low-heeled. (A few brave people do dance barefoot.)</p>\n\n<p>You might also like to have: <br />\n* A water bottle <br />\n* An extra shirt or two if you're given to sweating profusely <br />\n* A twirly skirt <br />\n* A brace or wrap for any problematic joints (if only to signal to other dancers that they should make a point of being gentle)</p>\n\n<p>The dance will run til 10:30, but staying the whole time isn't a requirement.  Dancers often partake of potables and comestibles at a local establishment afterwards, though this will be subject to what's open late on a Thursday.</p>\n\n<p>Requisite link to RTLW listserv: <a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a> Comment here or there if you're interested in a carpool!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n1'>RTLW Meetup: Contra Dance!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6ZzevvYhLP8CL5Lb9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 1.205546600595633e-06, "legacy": true, "legacyId": "22657", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___RTLW_Meetup__Contra_Dance_\">Discussion article for the meetup : <a href=\"/meetups/n1\">RTLW Meetup: Contra Dance!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 May 2013 06:50:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">100 N Greensboro St, Carrboro NC 27510</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>In lieu of our regular coffee and discussion, this week's meetup will be held at the Century Center in Carrboro, where A GREAT DANCE will be taking place.</p>\n\n<p>If you're a new dancer, there will be an intro lesson at 7 that will cover much of what you'll need to know. Try to arrive by about 6:50.</p>\n\n<p>If you can't arrive in time for the lesson or find you are running late, please come dance anyway! Ruthan, David, Evan, or any other experienced dancer will be happy to help you.</p>\n\n<p>You will need: <br>\n* $10 for admission <br>\n* Your dancing feet, in smooth-soled shoes, flat or low-heeled. (A few brave people do dance barefoot.)</p>\n\n<p>You might also like to have: <br>\n* A water bottle <br>\n* An extra shirt or two if you're given to sweating profusely <br>\n* A twirly skirt <br>\n* A brace or wrap for any problematic joints (if only to signal to other dancers that they should make a point of being gentle)</p>\n\n<p>The dance will run til 10:30, but staying the whole time isn't a requirement.  Dancers often partake of potables and comestibles at a local establishment afterwards, though this will be subject to what's open late on a Thursday.</p>\n\n<p>Requisite link to RTLW listserv: <a href=\"http://groups.google.com/group/rtlw\" rel=\"nofollow\">http://groups.google.com/group/rtlw</a> Comment here or there if you're interested in a carpool!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___RTLW_Meetup__Contra_Dance_1\">Discussion article for the meetup : <a href=\"/meetups/n1\">RTLW Meetup: Contra Dance!</a></h2>", "sections": [{"title": "Discussion article for the meetup : RTLW Meetup: Contra Dance!", "anchor": "Discussion_article_for_the_meetup___RTLW_Meetup__Contra_Dance_", "level": 1}, {"title": "Discussion article for the meetup : RTLW Meetup: Contra Dance!", "anchor": "Discussion_article_for_the_meetup___RTLW_Meetup__Contra_Dance_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-21T04:06:28.371Z", "modifiedAt": null, "url": null, "title": "[TED Talk] Peter Singer on Effective Altruism", "slug": "ted-talk-peter-singer-on-effective-altruism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:36.614Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vLgGjmzfzaZZxnykE/ted-talk-peter-singer-on-effective-altruism", "pageUrlRelative": "/posts/vLgGjmzfzaZZxnykE/ted-talk-peter-singer-on-effective-altruism", "linkUrl": "https://www.lesswrong.com/posts/vLgGjmzfzaZZxnykE/ted-talk-peter-singer-on-effective-altruism", "postedAtFormatted": "Tuesday, May 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BTED%20Talk%5D%20Peter%20Singer%20on%20Effective%20Altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BTED%20Talk%5D%20Peter%20Singer%20on%20Effective%20Altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvLgGjmzfzaZZxnykE%2Fted-talk-peter-singer-on-effective-altruism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BTED%20Talk%5D%20Peter%20Singer%20on%20Effective%20Altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvLgGjmzfzaZZxnykE%2Fted-talk-peter-singer-on-effective-altruism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvLgGjmzfzaZZxnykE%2Fted-talk-peter-singer-on-effective-altruism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p><a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html</a></p>\n<p>\n<blockquote>\n<p id=\"tagline\" style=\"margin: 0px 0px 1em; padding: 0px; font-family: arial, helvetica, sans-serif; font-size: 12px;\" lang=\"en\">If you're lucky enough to live without want, it's a natural impulse to be altruistic to others. But, asks philosopher Peter Singer, what's the most effective way to give? He talks through some surprising thought experiments to help you balance emotion and practicality -- and make the biggest impact with whatever you can share. Sometimes controversial, always practical ethicist Peter Singer stirs public debate about morality, from animal welfare to global poverty.</p>\n</blockquote>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vLgGjmzfzaZZxnykE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 21, "extendedScore": null, "score": 1.205992398678752e-06, "legacy": true, "legacyId": "22663", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-21T06:59:10.779Z", "modifiedAt": null, "url": null, "title": "High yield information sources for Software Development", "slug": "high-yield-information-sources-for-software-development", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:36.046Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rationalnoob", "createdAt": "2013-04-09T14:52:38.138Z", "isAdmin": false, "displayName": "rationalnoob"}, "userId": "RNgTsv4j9Lg6gZBcX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HYhuaQD79GeaDepyd/high-yield-information-sources-for-software-development", "pageUrlRelative": "/posts/HYhuaQD79GeaDepyd/high-yield-information-sources-for-software-development", "linkUrl": "https://www.lesswrong.com/posts/HYhuaQD79GeaDepyd/high-yield-information-sources-for-software-development", "postedAtFormatted": "Tuesday, May 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20High%20yield%20information%20sources%20for%20Software%20Development&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHigh%20yield%20information%20sources%20for%20Software%20Development%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHYhuaQD79GeaDepyd%2Fhigh-yield-information-sources-for-software-development%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=High%20yield%20information%20sources%20for%20Software%20Development%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHYhuaQD79GeaDepyd%2Fhigh-yield-information-sources-for-software-development", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHYhuaQD79GeaDepyd%2Fhigh-yield-information-sources-for-software-development", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<p>Software developers have to repeatedly and continually learn massive number of new concepts, procedures and techniques related to the latest languages, frameworks and technologies up and down the stack.</p>\n<p>The best way to learn would of course be to continuously read books in the spare time one isn't solving problems on the job and apply that knowledge.</p>\n<p>I personally find reading books too time consuming for me. Books are presented in a depth first fashion, delving into multiple areas in depth one by one. This is not ideal for becoming productive quickly. There is no explicit ordering of how necessary / frequent a particular concept / technique is either.</p>\n<p>What other sources of information / classes of sources are highest yield for picking up new technologies quickly [In the sense of getting productive fast].</p>\n<p>An example of a high yield resources are well made slide decks. As an example, a slide deck on a language(e.g. javascript) made for experienced developers new to the language is much faster to process than a book. I can absorb the major features of the language, the syntax etc from a good slide deck in a fraction of the time it would take to read the introductory chapter of a book.</p>\n<p>Any general comments (or specific sources) on how one would go about learning a new tech stack quickly would help too.</p>\n<p>My current stack is linux, apache, python, django, dynamo, js, backbone</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HYhuaQD79GeaDepyd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -2, "extendedScore": null, "score": 1.2061187775332602e-06, "legacy": true, "legacyId": "22666", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-21T13:47:11.736Z", "modifiedAt": null, "url": null, "title": "Meetup : Fermi Estimates in Chicago", "slug": "meetup-fermi-estimates-in-chicago", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:37.896Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nic_Smith", "createdAt": "2009-10-23T03:32:46.312Z", "isAdmin": false, "displayName": "Nic_Smith"}, "userId": "XP9GcTgRGLBCnf9ih", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8C9bY7DdsE9y6thyd/meetup-fermi-estimates-in-chicago", "pageUrlRelative": "/posts/8C9bY7DdsE9y6thyd/meetup-fermi-estimates-in-chicago", "linkUrl": "https://www.lesswrong.com/posts/8C9bY7DdsE9y6thyd/meetup-fermi-estimates-in-chicago", "postedAtFormatted": "Tuesday, May 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fermi%20Estimates%20in%20Chicago&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fermi%20Estimates%20in%20Chicago%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8C9bY7DdsE9y6thyd%2Fmeetup-fermi-estimates-in-chicago%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fermi%20Estimates%20in%20Chicago%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8C9bY7DdsE9y6thyd%2Fmeetup-fermi-estimates-in-chicago", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8C9bY7DdsE9y6thyd%2Fmeetup-fermi-estimates-in-chicago", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n2'>Fermi Estimates in Chicago</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">25 May 2013 03:00:59PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1 S Franklin, Chicago, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting at Argo Tea to discuss and practice Fermi estimates. When should they be used, and what considerations go into them? How many piano tuners ARE in Chicago?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n2'>Fermi Estimates in Chicago</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8C9bY7DdsE9y6thyd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2064174378656942e-06, "legacy": true, "legacyId": "22669", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fermi_Estimates_in_Chicago\">Discussion article for the meetup : <a href=\"/meetups/n2\">Fermi Estimates in Chicago</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">25 May 2013 03:00:59PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1 S Franklin, Chicago, IL</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting at Argo Tea to discuss and practice Fermi estimates. When should they be used, and what considerations go into them? How many piano tuners ARE in Chicago?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fermi_Estimates_in_Chicago1\">Discussion article for the meetup : <a href=\"/meetups/n2\">Fermi Estimates in Chicago</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fermi Estimates in Chicago", "anchor": "Discussion_article_for_the_meetup___Fermi_Estimates_in_Chicago", "level": 1}, {"title": "Discussion article for the meetup : Fermi Estimates in Chicago", "anchor": "Discussion_article_for_the_meetup___Fermi_Estimates_in_Chicago1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-21T16:04:59.806Z", "modifiedAt": null, "url": null, "title": "General intelligence test: no domains of stupidity", "slug": "general-intelligence-test-no-domains-of-stupidity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:42.582Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sRE9Gicjjc4x6NFX9/general-intelligence-test-no-domains-of-stupidity", "pageUrlRelative": "/posts/sRE9Gicjjc4x6NFX9/general-intelligence-test-no-domains-of-stupidity", "linkUrl": "https://www.lesswrong.com/posts/sRE9Gicjjc4x6NFX9/general-intelligence-test-no-domains-of-stupidity", "postedAtFormatted": "Tuesday, May 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20General%20intelligence%20test%3A%20no%20domains%20of%20stupidity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGeneral%20intelligence%20test%3A%20no%20domains%20of%20stupidity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsRE9Gicjjc4x6NFX9%2Fgeneral-intelligence-test-no-domains-of-stupidity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=General%20intelligence%20test%3A%20no%20domains%20of%20stupidity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsRE9Gicjjc4x6NFX9%2Fgeneral-intelligence-test-no-domains-of-stupidity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsRE9Gicjjc4x6NFX9%2Fgeneral-intelligence-test-no-domains-of-stupidity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 549, "htmlBody": "<p>It's been a productive conversation on my post <a href=\"/lw/hgl/the_flawed_turing_test_language_understanding_and/\">criticising the Turing test</a>. I claimed that I wouldn't take the Turing test as definitive evidence of general intelligence if the agent was specifically optimised on the test. I was challenged as to whether I had a different <a href=\"/lw/hgl/the_flawed_turing_test_language_understanding_and/90rg\">definition of thinking</a> than \"able to pass the Turing test\". As a consequence of that exchange, I think I do.</p>\n<p>Truly general intelligence is impossible, because of various \"<a href=\"http://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf\">no free lunch</a>\" theorems, that demonstrate that no algorithm can perform well in every environment (intuitively, this makes sense: a smarter being could always design an environment that specifically penalises a particular algorithm). Nevertheless, we have the intuitive definition of a general intelligence as one that performs well in most (or almost all) environments.</p>\n<p>I'd like to reverse that definition, and define a general intelligence as one that doesn't perform <em>stupidly</em> in a novel&nbsp;environment. A small change of emphasis, but it gets to the heart of what the Turing test is meant to do, and why I&nbsp;questioned&nbsp;it. The idea of the Turing test is to catch the (putative) AGI performing stupidly. Since we can't test the AGI on every&nbsp;environment, the idea is to have the Turing test be as general as possible <em>in potential</em>. If you give me the questions in advance, I can certainly craft an algorithm that aces that test; similarly, you can construct an AGI that would ace any <em>given</em> Turing test. But since the space of reasonable conversations is&nbsp;combinatorially&nbsp;huge, and since the judge could potentially pick any element from within that, the AGI could not just have a narrow list of responses: it would have to be genuinely generally intelligent, so that it would not end up being stupid on the particular conversation it was in.</p>\n<p>That's the theory, anyway. But maybe the space of conversations isn't as vast as all that, especially if the AGI has some simple classification algorithms. Maybe the data on the internet today, combined with some&nbsp;reasonably&nbsp;cunning algorithms, can carry a conversation as well as a human. After all, we are generating examples of conversations by the millions every hour of every day.</p>\n<p>Which is why I emphasised testing from outside the domain of competence of the AGI. You need to introduce it to a novel environment, and give it the possibility of being stupid. If the space of human&nbsp;conversations&nbsp;isn't large enough, you need to move to the much larger space of real-world problem solving - and pick something from it. It doesn't matter what it is, simply that you have the potential of picking anything. Hence only a general intelligence could be confident, in advance, of coping with it. That's why I emphasised not saying what your test was going to be, and changing the rules or outright cheating: the less restrictions you allow on the potential test, the more informative the actual test is.</p>\n<p>A related question, of course, is whether humans are generally intelligent. Well, humans are stupid in a lot of domains. Human groups augmented by data and computing technology, and given enough time, are much more generally intelligent that individual humans. So general intelligence is a matter of degree, not a binary classification (though it might be nearly binary for some AGI designs). Thus whether you call humans generally intelligent is a matter of taste and emphasis.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sRE9Gicjjc4x6NFX9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 15, "extendedScore": null, "score": 1.2065183353946213e-06, "legacy": true, "legacyId": "22670", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["er6G2DdzevvfdZWtg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-21T18:04:12.240Z", "modifiedAt": null, "url": null, "title": "[LINK]s: Who says Watson is only a narrow AI?", "slug": "link-s-who-says-watson-is-only-a-narrow-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:37.210Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JzFXw7bH4tK6n4h7q/link-s-who-says-watson-is-only-a-narrow-ai", "pageUrlRelative": "/posts/JzFXw7bH4tK6n4h7q/link-s-who-says-watson-is-only-a-narrow-ai", "linkUrl": "https://www.lesswrong.com/posts/JzFXw7bH4tK6n4h7q/link-s-who-says-watson-is-only-a-narrow-ai", "postedAtFormatted": "Tuesday, May 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5Ds%3A%20Who%20says%20Watson%20is%20only%20a%20narrow%20AI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5Ds%3A%20Who%20says%20Watson%20is%20only%20a%20narrow%20AI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJzFXw7bH4tK6n4h7q%2Flink-s-who-says-watson-is-only-a-narrow-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5Ds%3A%20Who%20says%20Watson%20is%20only%20a%20narrow%20AI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJzFXw7bH4tK6n4h7q%2Flink-s-who-says-watson-is-only-a-narrow-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJzFXw7bH4tK6n4h7q%2Flink-s-who-says-watson-is-only-a-narrow-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<p>OK, so it covers only a few human occupations:</p>\n<ul>\n<li>Trivia games (we all know about that one)</li>\n<li><a href=\"http://www-03.ibm.com/innovation/us/watson/watson_in_healthcare.shtml\">Clinical diagnosis</a></li>\n<li><a href=\"http://www-03.ibm.com/press/us/en/pressrelease/37029.wss\">Banking advisor</a></li>\n<li>and now <a href=\"http://www-03.ibm.com/innovation/us/watson/watson_for_engagement.shtml\">a call center grunt</a></li>\n</ul>\n<p>But the list is steadily growing.</p>\n<p>Now, connect it with a self-driving AI, and your cab e-driver can make small talk, advise on a suspicious skin lesion, evaluate your investment portfolio and help you fix an issue with your smartphone, all while cheaply and efficiently getting you to your destination.</p>\n<p>How long until it can evaluate verbal or written customer requirements and write better routine software than your average programmer?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ocGoDbHKBv46AwXnT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JzFXw7bH4tK6n4h7q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 6, "extendedScore": null, "score": 1.2066056305294074e-06, "legacy": true, "legacyId": "22671", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-21T18:31:34.516Z", "modifiedAt": null, "url": null, "title": "Meetup : Munich Meetup", "slug": "meetup-munich-meetup-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cadac", "createdAt": "2011-09-25T11:17:15.655Z", "isAdmin": false, "displayName": "cadac"}, "userId": "hMHAdTtN5PL9KThqu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/twoZddkwCaDwSzAHd/meetup-munich-meetup-0", "pageUrlRelative": "/posts/twoZddkwCaDwSzAHd/meetup-munich-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/twoZddkwCaDwSzAHd/meetup-munich-meetup-0", "postedAtFormatted": "Tuesday, May 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Munich%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Munich%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtwoZddkwCaDwSzAHd%2Fmeetup-munich-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Munich%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtwoZddkwCaDwSzAHd%2Fmeetup-munich-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtwoZddkwCaDwSzAHd%2Fmeetup-munich-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n3'>Munich Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">01 June 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Caf\u00e9 \"Le copain\", Gasteig, Rosenheimer Stra\u00dfe 5, 81667 Munich</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next meetup in Munich will be on Saturday, June 1st. At the last meetup, we decided that we would read the first three posts of the new <a href=\"http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners\">Epistemology sequence</a> until June, so we can try a more focused discussion the next time. Of course, if you haven\u2019t read them, or if you are new to LessWrong, you are welcome, too. If you have any suggestions for discussion topics or activities, it would be great if you could post them as a comment here.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n3'>Munich Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "twoZddkwCaDwSzAHd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2066256760076936e-06, "legacy": true, "legacyId": "22672", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Munich_Meetup\">Discussion article for the meetup : <a href=\"/meetups/n3\">Munich Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">01 June 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Caf\u00e9 \"Le copain\", Gasteig, Rosenheimer Stra\u00dfe 5, 81667 Munich</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next meetup in Munich will be on Saturday, June 1st. At the last meetup, we decided that we would read the first three posts of the new <a href=\"http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners\">Epistemology sequence</a> until June, so we can try a more focused discussion the next time. Of course, if you haven\u2019t read them, or if you are new to LessWrong, you are welcome, too. If you have any suggestions for discussion topics or activities, it would be great if you could post them as a comment here.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Munich_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/n3\">Munich Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Munich Meetup", "anchor": "Discussion_article_for_the_meetup___Munich_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Munich Meetup", "anchor": "Discussion_article_for_the_meetup___Munich_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-21T19:09:31.034Z", "modifiedAt": null, "url": null, "title": "[LINK] Soylent crowdfunding", "slug": "link-soylent-crowdfunding", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:36.994Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vp3bRZdfkbHvnsC5j/link-soylent-crowdfunding", "pageUrlRelative": "/posts/vp3bRZdfkbHvnsC5j/link-soylent-crowdfunding", "linkUrl": "https://www.lesswrong.com/posts/vp3bRZdfkbHvnsC5j/link-soylent-crowdfunding", "postedAtFormatted": "Tuesday, May 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Soylent%20crowdfunding&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Soylent%20crowdfunding%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvp3bRZdfkbHvnsC5j%2Flink-soylent-crowdfunding%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Soylent%20crowdfunding%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvp3bRZdfkbHvnsC5j%2Flink-soylent-crowdfunding", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvp3bRZdfkbHvnsC5j%2Flink-soylent-crowdfunding", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<p><a href=\"http://robrhinehart.com/\">Rob Rhinehart</a>'s food replacement&nbsp;<a href=\"https://campaign.soylent.me/soylent-free-your-body\">Soylent</a> now has a crowdfunding campaign.</p>\n<blockquote>\n<p>Soylent frees you from the time and money spent shopping, cooking and cleaning, puts you in excellent health, and vastly reduces your environmental impact by eliminating much of the waste and harm coming from agriculture, livestock, and food-related trash.</p>\n</blockquote>\n<p>If you're interested in one or more of these benefits, send in some money! There is also a <a href=\"http://robrhinehart.com/?p=507\">new blog post</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vp3bRZdfkbHvnsC5j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 11, "extendedScore": null, "score": 1.2066534639679398e-06, "legacy": true, "legacyId": "22673", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 170, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-22T01:09:51.917Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley: To-do lists and other systems", "slug": "meetup-berkeley-to-do-lists-and-other-systems", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:36.356Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jWAm2J6vSEAdyn2fz/meetup-berkeley-to-do-lists-and-other-systems", "pageUrlRelative": "/posts/jWAm2J6vSEAdyn2fz/meetup-berkeley-to-do-lists-and-other-systems", "linkUrl": "https://www.lesswrong.com/posts/jWAm2J6vSEAdyn2fz/meetup-berkeley-to-do-lists-and-other-systems", "postedAtFormatted": "Wednesday, May 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%3A%20To-do%20lists%20and%20other%20systems&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%3A%20To-do%20lists%20and%20other%20systems%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjWAm2J6vSEAdyn2fz%2Fmeetup-berkeley-to-do-lists-and-other-systems%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%3A%20To-do%20lists%20and%20other%20systems%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjWAm2J6vSEAdyn2fz%2Fmeetup-berkeley-to-do-lists-and-other-systems", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjWAm2J6vSEAdyn2fz%2Fmeetup-berkeley-to-do-lists-and-other-systems", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 111, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n4'>Berkeley: To-do lists and other systems</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 May 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, the topic of tomorrow's meetup is to-do lists, Getting Things Done, and other systems for managing time and tasks. I used to think of this as a mundane topic, but then I realized it's only as mundane as your goals are! I will be especially interested in learning about the systems or habits you employ, if you'd like to share.</p>\n\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n4'>Berkeley: To-do lists and other systems</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jWAm2J6vSEAdyn2fz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 1.2069174324412112e-06, "legacy": true, "legacyId": "22674", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley__To_do_lists_and_other_systems\">Discussion article for the meetup : <a href=\"/meetups/n4\">Berkeley: To-do lists and other systems</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 May 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, the topic of tomorrow's meetup is to-do lists, Getting Things Done, and other systems for managing time and tasks. I used to think of this as a mundane topic, but then I realized it's only as mundane as your goals are! I will be especially interested in learning about the systems or habits you employ, if you'd like to share.</p>\n\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley__To_do_lists_and_other_systems1\">Discussion article for the meetup : <a href=\"/meetups/n4\">Berkeley: To-do lists and other systems</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley: To-do lists and other systems", "anchor": "Discussion_article_for_the_meetup___Berkeley__To_do_lists_and_other_systems", "level": 1}, {"title": "Discussion article for the meetup : Berkeley: To-do lists and other systems", "anchor": "Discussion_article_for_the_meetup___Berkeley__To_do_lists_and_other_systems1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-22T07:22:20.482Z", "modifiedAt": null, "url": null, "title": "Potential Impacts of Climate Change", "slug": "potential-impacts-of-climate-change", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:51.084Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9qgQWEauLGuPwuYPh/potential-impacts-of-climate-change", "pageUrlRelative": "/posts/9qgQWEauLGuPwuYPh/potential-impacts-of-climate-change", "linkUrl": "https://www.lesswrong.com/posts/9qgQWEauLGuPwuYPh/potential-impacts-of-climate-change", "postedAtFormatted": "Wednesday, May 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Potential%20Impacts%20of%20Climate%20Change&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APotential%20Impacts%20of%20Climate%20Change%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9qgQWEauLGuPwuYPh%2Fpotential-impacts-of-climate-change%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Potential%20Impacts%20of%20Climate%20Change%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9qgQWEauLGuPwuYPh%2Fpotential-impacts-of-climate-change", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9qgQWEauLGuPwuYPh%2Fpotential-impacts-of-climate-change", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1129, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>1170</o:Words> <o:Characters>6675</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>55</o:Lines> <o:Paragraphs>15</o:Paragraphs> <o:CharactersWithSpaces>7830</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if !supportAnnotations]-->\n<script type=\"text/javascript\"></script>\n<!--[endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>1175</o:Words> <o:Characters>6701</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>55</o:Lines> <o:Paragraphs>15</o:Paragraphs> <o:CharactersWithSpaces>7861</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">According to <a href=\"http://www.law.berkeley.edu/14906.htm\">a recent press release</a> from UC Berkeley&rsquo;s School of Law:</p>\n<blockquote>\n<p class=\"MsoNormal\"><em>Overheated: The Human Cost of Climate Change</em> predicts a grim future for billions of people in this century. It is a factual account of a staggering toll, based on hard data [&hellip;] &ldquo;Climate change is the most important problem facing the international community in the 21<sup>st</sup> century,&rdquo; Guzman said.</p>\n</blockquote>\n<p class=\"MsoNormal\">Guzman's view is shared by many.</p>\n<p class=\"MsoNormal\">While I have not read Guzman&rsquo;s book, I have read <a href=\"http://www.givewell.org/shallow/climate-change/impacts\">GiveWell&rsquo;s summary of the IPCC</a>, as well as notes on GiveWell&rsquo;s <a href=\"http://www.givewell.org/conversations#ClimateChange\">conversations with climate change experts</a>. Based on these, I&rsquo;ve come to the tentative conclusion that <strong>while climate change is an important issue, it&rsquo;s unlikely to be the <em>most</em> important issue, though there is uncertainty, owing to poorly understood tail risk</strong>.&nbsp;</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<h2><strong>Potential Impacts according to the IPCC</strong><span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">GiveWell recently wrote up <a href=\"http://www.givewell.org/shallow/climate-change/impacts\">a summary and review</a> of some of the impacts of unmitigated climate change, as described by the Intergovernmental Panel on Climate Change's 2007 Fourth Assessment Report. GiveWell writes:</p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin-left: 0.25in;\">The report suggests that&nbsp;<strong>unmitigated climate change would have extraordinarily negative humanitarian impacts</strong>&nbsp;across all of the outcomes we looked at: hunger, water stress, flooding, extreme weather, health, biodiversity, and the economy. Successfully mitigating these negative impacts would carry vast humanitarian benefits.&nbsp;<br /><br />When looking at the range of possible futures outlined in the report, the bulk of the variation (in humanitarian terms) comes from variation in the level of assumed economic growth and adaptation, rather than variation in the amount of climate change. Of the outcomes we examined, only biodiversity is expected to be unambiguously worse off in the future as a result of both climate change and economic growth.</p>\n</blockquote>\n<p class=\"MsoNormal\">The most succinct summary of the expected impact is given by a&nbsp;<a href=\"http://www.givewell.org/shallow/climate-change/impacts#Economicwelfare\">GDP drop estimate</a>:</p>\n<blockquote>\n<p class=\"MsoNormal\">Most recently, Stern (2007) took account of a full range of both impacts and possible outcomes. [&hellip;] Using equity weights to reflect the expectation that a disproportionate share of the climate-change burden will fall on poor regions of the world increased their estimated reduction in equivalent consumption per head to 20%.</p>\n</blockquote>\n<p class=\"MsoNormal\">Such a drop would be highly undesirable, but far from catastrophic. World GDP has been <a href=\"http://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG/countries?display=graph\">growing at a rate of ~3%</a>, so this corresponds only to a set-back of ~6 years. &nbsp;Poor countries are expected to become richer regardless, and because of marginal diminishing utility, such a setback would carry less negative humanitarian impact than such a setback would if it occurred today.</p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Overly weak assumptions regarding adaptation?</span></strong><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">&nbsp;</span></strong></p>\n<p class=\"MsoNormal\">The IPCC considers what the impacts of climate change will be in 2050; a full 35 years away. My intuition is that over the course of the next 35 years, human society will adapt in such a way that the issues that the IPCC describes will have a smaller negative humanitarian impact than the IPCC suggests. <strong>I have not vetted the references given by the IPCC, and may be mistaken about their implicit assumptions, so my remarks should be taken with a grain of salt.</strong>&nbsp;&nbsp;</p>\n<p class=\"MsoNormal\">To explicitly address some of the impacts discussed in the IPCC:</p>\n<ul>\n<li><span style=\"font-family:Symbol;mso-fareast-font-family:Symbol;mso-bidi-font-family: Symbol\"><span style=\"font-size: 7pt; font-family: 'Times New Roman';\">&nbsp;</span></span><strong style=\"text-indent: -0.25in;\">Crop productivity and hunger in Africa&nbsp;</strong><span style=\"text-indent: -0.25in;\">&mdash;&nbsp;The IPCC projects that in 2050, at least 208 million people will be at risk of hunger even without climate change: only ~ 3x fewer than today. </span><a style=\"text-indent: -0.25in;\" href=\"http://www.pnas.org/content/110/18/7182\">New technologies for the production of starch</a><span style=\"text-indent: -0.25in;\"> could make the number much smaller.<br /><br /></span></li>\n<li><strong style=\"text-indent: -0.25in;\">Floods due to rising sea levels </strong><span style=\"text-indent: -0.25in;\">&mdash;&nbsp;The IPCC mentions </span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/shallow/climate-change/impacts#footnote37_dr8b9yt\">dikes and nourishment</a><span style=\"text-indent: -0.25in;\"> as possible adaptive responses, but doesn&rsquo;t mention the possibility that people will </span><em style=\"text-indent: -0.25in;\">move away from coastal areas as sea levels rise</em><span style=\"text-indent: -0.25in;\">. Individual people and families might move away to avoid flooding. On the time scale of 5 years, people are usually unwilling to move, but over the course of 35 years, it might happen organically. Over time, more cities will be built, and people will migrate to them. Cities are more likely to be built in areas that are not prone to flooding, than in areas that are.<span style=\"font-family: Symbol;\"><br /></span></span><strong style=\"text-indent: -0.25in;\"><br /></strong></li>\n<li><span style=\"text-indent: -0.25in;\"><strong>Significant loss of species and biodiversity</strong></span><span style=\"text-indent: -0.25in;\"> &mdash; Over the next 35 years, humans may make a concerted effort to preserve rare species by collecting them and housing them in zoos. (I recognize that this would have to happen well before 35 years elapsed in order to avoid the loss.)</span></li>\n</ul>\n<p class=\"MsoNormal\">There are also more general relevant considerations:</p>\n<ul>\n<li><strong style=\"text-indent: -0.25in;\">Geoengineering </strong><span style=\"text-indent: -0.25in;\">&mdash; It may be possible to reverse or halt climate change via </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Geoengineering\">geoengineering</a><span style=\"text-indent: -0.25in;\">. Geoengineering carries its own risks, but its potential would seem to be positive in expectation, although the situation is murky.<br /></span><strong style=\"text-indent: -0.25in;\"><br /></strong></li>\n<li><span style=\"text-indent: -0.25in;\"><strong>Unpredicted technologies</strong> </span><span style=\"text-indent: -0.25in;\">&mdash;&nbsp;Technological progress is unpredictable, and it could be that we can develop technologies that mitigate effects such as droughts, even if we can&rsquo;t see these technologies in advance. There are potential unpredicted technologies that would make climate change worse, such as those that facilitate cheaper extraction of fossil fuel, but on balance, technological progress usually enables humans to solve problems more than to create them.<br />\n<div style=\"text-indent: -24px;\"><br />Breakthroughs in genetic engineering, artificial intelligence and whole brain emulation could also radically alter human needs themselves.</div>\n</span></li>\n</ul>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">The IPCC as overly optimistic?</span></strong></p>\n<p class=\"MsoNormal\">Some people have <a href=\"http://en.wikipedia.org/wiki/Criticism_of_the_IPCC_Fourth_Assessment_Report\">voiced the concern</a> that the IPCC is overly optimistic in its predictions of climate change impacts. This is corroborated by the recent paper <em><a href=\"http://www.sciencedirect.com/science/article/pii/S0959378012001215\">Climate change prediction: Erring on the side of least drama</a></em>, which reports that historic IPCC predictions of current impacts of climate change have erred on the overcautious side. But given that the IPCC represents a consensus, barring tail risk, it seems unlikely that the IPCC is overly optimistic <em>by a huge margin</em>.&nbsp;</p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Tail risk</span></strong></p>\n<p class=\"MsoNormal\">The biggest reason to be concerned about climate change is that there&rsquo;s a small probability that the negative impact could be huge.</p>\n<p class=\"MsoNormal\">There is a danger of <a href=\"http://en.wikipedia.org/wiki/Arctic_methane_release\">permafrost in the Arctic melting and releasing methane</a>, creating a feedback loop where the release of methane, global warming, and the melting of the permafrost reinforce each other. This could <a href=\"http://www.givewell.org/files/conversations/Kirsten%20Zickfeld%2004-17-13%20(public).pdf\">increase global temperature by 3.5 degrees Celcius</a>, greatly exacerbating all other impacts of climate change. Even if this doesn&rsquo;t happen, it could be that climate models are wrong, and that the amount by which the earth temperature will rise is much greater than current models predict.</p>\n<p class=\"MsoNormal\">The potential impacts of a much larger increase in temperature than what the IPCC predicts are less studied. One starting point for reading on this is the <a href=\"http://www.eci.ox.ac.uk/4degrees/\">4degrees and beyond</a> international climate conference.</p>\n<p class=\"MsoNormal\">\n<hr />\n</p>\n<p class=\"MsoNormal\"><strong>About the author:<em>&nbsp;</em></strong>I worked as a research analyst at GiveWell from April 2012 to May 2013. All views expressed here are my own.</p>\n<p class=\"MsoNormal\"><strong>Acknowledgements: </strong>Thanks to Nick Beckstead, Vipul Naik and Carl Shulman for helpful suggestions.</p>\n<p class=\"MsoNormal\"><strong>To be continued: </strong>I'll be writing up a follow up report about the implications of the projected impacts for effective philanthropy.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"frcrRgCk9PDbEScua": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9qgQWEauLGuPwuYPh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 14, "extendedScore": null, "score": 3.4e-05, "legacy": true, "legacyId": "22681", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>1170</o:Words> <o:Characters>6675</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>55</o:Lines> <o:Paragraphs>15</o:Paragraphs> <o:CharactersWithSpaces>7830</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if !supportAnnotations]-->\n<script type=\"text/javascript\"></script>\n<!--[endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>1175</o:Words> <o:Characters>6701</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>55</o:Lines> <o:Paragraphs>15</o:Paragraphs> <o:CharactersWithSpaces>7861</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">According to <a href=\"http://www.law.berkeley.edu/14906.htm\">a recent press release</a> from UC Berkeley\u2019s School of Law:</p>\n<blockquote>\n<p class=\"MsoNormal\"><em>Overheated: The Human Cost of Climate Change</em> predicts a grim future for billions of people in this century. It is a factual account of a staggering toll, based on hard data [\u2026] \u201cClimate change is the most important problem facing the international community in the 21<sup>st</sup> century,\u201d Guzman said.</p>\n</blockquote>\n<p class=\"MsoNormal\">Guzman's view is shared by many.</p>\n<p class=\"MsoNormal\">While I have not read Guzman\u2019s book, I have read <a href=\"http://www.givewell.org/shallow/climate-change/impacts\">GiveWell\u2019s summary of the IPCC</a>, as well as notes on GiveWell\u2019s <a href=\"http://www.givewell.org/conversations#ClimateChange\">conversations with climate change experts</a>. Based on these, I\u2019ve come to the tentative conclusion that <strong>while climate change is an important issue, it\u2019s unlikely to be the <em>most</em> important issue, though there is uncertainty, owing to poorly understood tail risk</strong>.&nbsp;</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<h2 id=\"Potential_Impacts_according_to_the_IPCC_\"><strong>Potential Impacts according to the IPCC</strong><span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">GiveWell recently wrote up <a href=\"http://www.givewell.org/shallow/climate-change/impacts\">a summary and review</a> of some of the impacts of unmitigated climate change, as described by the Intergovernmental Panel on Climate Change's 2007 Fourth Assessment Report. GiveWell writes:</p>\n<blockquote>\n<p class=\"MsoNormal\" style=\"margin-left: 0.25in;\">The report suggests that&nbsp;<strong>unmitigated climate change would have extraordinarily negative humanitarian impacts</strong>&nbsp;across all of the outcomes we looked at: hunger, water stress, flooding, extreme weather, health, biodiversity, and the economy. Successfully mitigating these negative impacts would carry vast humanitarian benefits.&nbsp;<br><br>When looking at the range of possible futures outlined in the report, the bulk of the variation (in humanitarian terms) comes from variation in the level of assumed economic growth and adaptation, rather than variation in the amount of climate change. Of the outcomes we examined, only biodiversity is expected to be unambiguously worse off in the future as a result of both climate change and economic growth.</p>\n</blockquote>\n<p class=\"MsoNormal\">The most succinct summary of the expected impact is given by a&nbsp;<a href=\"http://www.givewell.org/shallow/climate-change/impacts#Economicwelfare\">GDP drop estimate</a>:</p>\n<blockquote>\n<p class=\"MsoNormal\">Most recently, Stern (2007) took account of a full range of both impacts and possible outcomes. [\u2026] Using equity weights to reflect the expectation that a disproportionate share of the climate-change burden will fall on poor regions of the world increased their estimated reduction in equivalent consumption per head to 20%.</p>\n</blockquote>\n<p class=\"MsoNormal\">Such a drop would be highly undesirable, but far from catastrophic. World GDP has been <a href=\"http://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG/countries?display=graph\">growing at a rate of ~3%</a>, so this corresponds only to a set-back of ~6 years. &nbsp;Poor countries are expected to become richer regardless, and because of marginal diminishing utility, such a setback would carry less negative humanitarian impact than such a setback would if it occurred today.</p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Overly weak assumptions regarding adaptation?</span></strong><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">&nbsp;</span></strong></p>\n<p class=\"MsoNormal\">The IPCC considers what the impacts of climate change will be in 2050; a full 35 years away. My intuition is that over the course of the next 35 years, human society will adapt in such a way that the issues that the IPCC describes will have a smaller negative humanitarian impact than the IPCC suggests. <strong>I have not vetted the references given by the IPCC, and may be mistaken about their implicit assumptions, so my remarks should be taken with a grain of salt.</strong>&nbsp;&nbsp;</p>\n<p class=\"MsoNormal\">To explicitly address some of the impacts discussed in the IPCC:</p>\n<ul>\n<li><span style=\"font-family:Symbol;mso-fareast-font-family:Symbol;mso-bidi-font-family: Symbol\"><span style=\"font-size: 7pt; font-family: 'Times New Roman';\">&nbsp;</span></span><strong style=\"text-indent: -0.25in;\">Crop productivity and hunger in Africa&nbsp;</strong><span style=\"text-indent: -0.25in;\">\u2014&nbsp;The IPCC projects that in 2050, at least 208 million people will be at risk of hunger even without climate change: only ~ 3x fewer than today. </span><a style=\"text-indent: -0.25in;\" href=\"http://www.pnas.org/content/110/18/7182\">New technologies for the production of starch</a><span style=\"text-indent: -0.25in;\"> could make the number much smaller.<br><br></span></li>\n<li><strong style=\"text-indent: -0.25in;\">Floods due to rising sea levels </strong><span style=\"text-indent: -0.25in;\">\u2014&nbsp;The IPCC mentions </span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/shallow/climate-change/impacts#footnote37_dr8b9yt\">dikes and nourishment</a><span style=\"text-indent: -0.25in;\"> as possible adaptive responses, but doesn\u2019t mention the possibility that people will </span><em style=\"text-indent: -0.25in;\">move away from coastal areas as sea levels rise</em><span style=\"text-indent: -0.25in;\">. Individual people and families might move away to avoid flooding. On the time scale of 5 years, people are usually unwilling to move, but over the course of 35 years, it might happen organically. Over time, more cities will be built, and people will migrate to them. Cities are more likely to be built in areas that are not prone to flooding, than in areas that are.<span style=\"font-family: Symbol;\"><br></span></span><strong style=\"text-indent: -0.25in;\"><br></strong></li>\n<li><span style=\"text-indent: -0.25in;\"><strong>Significant loss of species and biodiversity</strong></span><span style=\"text-indent: -0.25in;\"> \u2014 Over the next 35 years, humans may make a concerted effort to preserve rare species by collecting them and housing them in zoos. (I recognize that this would have to happen well before 35 years elapsed in order to avoid the loss.)</span></li>\n</ul>\n<p class=\"MsoNormal\">There are also more general relevant considerations:</p>\n<ul>\n<li><strong style=\"text-indent: -0.25in;\">Geoengineering </strong><span style=\"text-indent: -0.25in;\">\u2014 It may be possible to reverse or halt climate change via </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Geoengineering\">geoengineering</a><span style=\"text-indent: -0.25in;\">. Geoengineering carries its own risks, but its potential would seem to be positive in expectation, although the situation is murky.<br></span><strong style=\"text-indent: -0.25in;\"><br></strong></li>\n<li><span style=\"text-indent: -0.25in;\"><strong>Unpredicted technologies</strong> </span><span style=\"text-indent: -0.25in;\">\u2014&nbsp;Technological progress is unpredictable, and it could be that we can develop technologies that mitigate effects such as droughts, even if we can\u2019t see these technologies in advance. There are potential unpredicted technologies that would make climate change worse, such as those that facilitate cheaper extraction of fossil fuel, but on balance, technological progress usually enables humans to solve problems more than to create them.<br>\n<div style=\"text-indent: -24px;\"><br>Breakthroughs in genetic engineering, artificial intelligence and whole brain emulation could also radically alter human needs themselves.</div>\n</span></li>\n</ul>\n<p class=\"MsoNormal\"><strong id=\"The_IPCC_as_overly_optimistic_\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">The IPCC as overly optimistic?</span></strong></p>\n<p class=\"MsoNormal\">Some people have <a href=\"http://en.wikipedia.org/wiki/Criticism_of_the_IPCC_Fourth_Assessment_Report\">voiced the concern</a> that the IPCC is overly optimistic in its predictions of climate change impacts. This is corroborated by the recent paper <em><a href=\"http://www.sciencedirect.com/science/article/pii/S0959378012001215\">Climate change prediction: Erring on the side of least drama</a></em>, which reports that historic IPCC predictions of current impacts of climate change have erred on the overcautious side. But given that the IPCC represents a consensus, barring tail risk, it seems unlikely that the IPCC is overly optimistic <em>by a huge margin</em>.&nbsp;</p>\n<p class=\"MsoNormal\"><strong id=\"Tail_risk\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Tail risk</span></strong></p>\n<p class=\"MsoNormal\">The biggest reason to be concerned about climate change is that there\u2019s a small probability that the negative impact could be huge.</p>\n<p class=\"MsoNormal\">There is a danger of <a href=\"http://en.wikipedia.org/wiki/Arctic_methane_release\">permafrost in the Arctic melting and releasing methane</a>, creating a feedback loop where the release of methane, global warming, and the melting of the permafrost reinforce each other. This could <a href=\"http://www.givewell.org/files/conversations/Kirsten%20Zickfeld%2004-17-13%20(public).pdf\">increase global temperature by 3.5 degrees Celcius</a>, greatly exacerbating all other impacts of climate change. Even if this doesn\u2019t happen, it could be that climate models are wrong, and that the amount by which the earth temperature will rise is much greater than current models predict.</p>\n<p class=\"MsoNormal\">The potential impacts of a much larger increase in temperature than what the IPCC predicts are less studied. One starting point for reading on this is the <a href=\"http://www.eci.ox.ac.uk/4degrees/\">4degrees and beyond</a> international climate conference.</p>\n<p class=\"MsoNormal\">\n</p><hr>\n<p></p>\n<p class=\"MsoNormal\"><strong>About the author:<em>&nbsp;</em></strong>I worked as a research analyst at GiveWell from April 2012 to May 2013. All views expressed here are my own.</p>\n<p class=\"MsoNormal\"><strong>Acknowledgements: </strong>Thanks to Nick Beckstead, Vipul Naik and Carl Shulman for helpful suggestions.</p>\n<p class=\"MsoNormal\"><strong>To be continued: </strong>I'll be writing up a follow up report about the implications of the projected impacts for effective philanthropy.</p>", "sections": [{"title": "Potential Impacts according to the IPCC\u00a0", "anchor": "Potential_Impacts_according_to_the_IPCC_", "level": 1}, {"title": "The IPCC as overly optimistic?", "anchor": "The_IPCC_as_overly_optimistic_", "level": 2}, {"title": "Tail risk", "anchor": "Tail_risk", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "44 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-22T11:48:38.291Z", "modifiedAt": null, "url": null, "title": "Preparing for a Rational Financial Planning Sequence", "slug": "preparing-for-a-rational-financial-planning-sequence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.517Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "elharo", "createdAt": "2012-12-28T14:11:02.335Z", "isAdmin": false, "displayName": "elharo"}, "userId": "cgJcCeZhdRnGtwMMR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uJ7gdQ8ZRnn9M9zTE/preparing-for-a-rational-financial-planning-sequence", "pageUrlRelative": "/posts/uJ7gdQ8ZRnn9M9zTE/preparing-for-a-rational-financial-planning-sequence", "linkUrl": "https://www.lesswrong.com/posts/uJ7gdQ8ZRnn9M9zTE/preparing-for-a-rational-financial-planning-sequence", "postedAtFormatted": "Wednesday, May 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Preparing%20for%20a%20Rational%20Financial%20Planning%20Sequence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APreparing%20for%20a%20Rational%20Financial%20Planning%20Sequence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuJ7gdQ8ZRnn9M9zTE%2Fpreparing-for-a-rational-financial-planning-sequence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Preparing%20for%20a%20Rational%20Financial%20Planning%20Sequence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuJ7gdQ8ZRnn9M9zTE%2Fpreparing-for-a-rational-financial-planning-sequence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuJ7gdQ8ZRnn9M9zTE%2Fpreparing-for-a-rational-financial-planning-sequence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 795, "htmlBody": "<p>What follows is a rough outline for a possible rational financial planning sequence that was inspired by some other <a href=\"/lw/h9b/post_ridiculous_munchkin_ideas/8zkf\">recent</a> <a href=\"/lw/hfw/why_is_it_rational_to_invest_in_retirement_i_dont/\">discussion</a> here. I'm not sure how useful this would be to how many people. I know there are some LessWrongers who would enjoy and learn from this; but I don't know if there are 5, 50, or 500. If you'd like to read it, let me know. If 500 people tell me they can't wait for this, I'll probably write it. If 5 people say maybe they'll glance at it, then probably not.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Part I: Preliminaries:<br /><br />&nbsp;&nbsp;&nbsp; Financial Rationality<br />&nbsp;&nbsp;&nbsp; Multiplying uncertainties<br />&nbsp;&nbsp;&nbsp; The inside and outside views<br />&nbsp;&nbsp;&nbsp; Interpolation is reliable; extrapolation isn't<br /><br />Part II: This is important:</p>\n<ul>\n<li>Why to save for retirement</li>\n<li>Dying alone in a hole: the story of Jane.&nbsp;&nbsp;&nbsp; </li>\n<li>Why compound interest is cool</li>\n<li>65-year old you will not want to live like a grad student</li>\n<li>65-year old you will not want to work like 35-year old you</li>\n<li>Existential risk does not defeat personal risk</li>\n<li>Existential success does not defeat personal risk</li>\n</ul>\n<p><br />Part III: Analyzing Your Life<br /><br />&nbsp;&nbsp;&nbsp; (This section needs a lot more fleshing out, and thought) <br /><br />&nbsp;&nbsp;&nbsp; Personal satisfaction and happiness: do what you love, and adjust your financial expectations accordingly<br />&nbsp;&nbsp;&nbsp; How much do you need to retire?<br />&nbsp;&nbsp;&nbsp; When do you want to retire?<br />&nbsp;&nbsp;&nbsp; How much do you need to live on today?<br />&nbsp;&nbsp;&nbsp; Big expenses you need to plan for<br />&nbsp;&nbsp;&nbsp; Increasing Income<br />&nbsp;&nbsp;&nbsp; College the best financial decision you'll ever make or the worst?<br />&nbsp;&nbsp;&nbsp; Choosing a career: what is your comparative advantage?<br />&nbsp;&nbsp;&nbsp; Switching careers<br />&nbsp;&nbsp;&nbsp; Career Decisions<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; equity vs salary; steady singles or home run hitter<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; employee or owner<br />&nbsp;&nbsp;&nbsp; Career Tactics<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Salary negotiation<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; promotion<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; when to change jobs<br />&nbsp;&nbsp;&nbsp; Cutting Expenses<br />&nbsp;&nbsp;&nbsp; Save more tomorrow<br />&nbsp;&nbsp;&nbsp; Inheritance<br /><br />Part IV: The Practical How-to Advice:</p>\n<p>Emergency Cash<br />Credit cards: the good, the bad, and the criminal<br />Banking<br />Where to save (tax advantaged accounts)<br />The importance of fees<br />401K matching: the highest return you'll ever see<br />Social Security<br />Pensions<br />What to invest in (index funds)<br />&nbsp;&nbsp;&nbsp; diversification<br />&nbsp;&nbsp;&nbsp; stock vs bond funds<br />&nbsp;&nbsp;&nbsp; domestic vs. international<br />&nbsp;&nbsp;&nbsp; target retirement funds<br />&nbsp;&nbsp;&nbsp; Comic books are not a retirement plan (but a comic book store might be)<br />&nbsp;&nbsp;&nbsp; <br />Avoiding hucksters and doomsayers <br />Investment Advisors<br />What if the shit hits the fan?<br />Can smart, rational investors beat the market?<br />Good debt; bad debt<br />Cars and other expensive purchases<br />Cutting out the middleman: making money on Craig's list, amazon, eBay and AirB&amp;B<br />Buying a house<br />Renting vs. owning a house; rental parity<br />Student loans<br />Health Insurance<br />Life Insurance<br />Auto Insurance<br />Your Spouse: the most important financial decision you'll ever make<br />&nbsp;&nbsp;&nbsp; Diamonds are forever, but most women would rather have a house.<br />&nbsp;&nbsp;&nbsp; One or two incomes?<br />&nbsp;&nbsp;&nbsp; Live longer, be happier, get married</p>\n<p>Children<br />Charity</p>\n<p>&nbsp;</p>\n<hr />\n<p>If there are any topics you'd like to see covered that aren't here (wills? lawyers? the financial press?), let me know. Similarly, if you think there's a section that doesn't belong and should be dropped, let me know that too.</p>\n<p>&nbsp;</p>\n<p>One caveat: while some sections are fairly generic, others will be very U.S. centric. The most specific advice will not be applicable to non-U.S. citizens and residents. That does limit the audience, but there's not too much I can do about that. Perhaps if it's successful I can seek out co-authors to do UK, Canadian, or other country editions.</p>\n<p>A question for people who are interested in financial planning material: If this were available as a complete book (electronic and paper) today, how likely do you think it is that you would buy this book instead of one of the other available books on the subject? What would you pay for such a book?&nbsp; If this were available as both a book and a sequence on LessWrong, how might that change your decision?</p>\n<p>For now, this discussion thread is just a minimum viable product (MVP) to find out if a sequence is worth the time it would take me to complete. If the MVP pans out, I'll write and post one or two of these chapters to further gauge interest. If the MVP doesn't look promising, I'll drop it and move on to my next book idea.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jgcAJnksReZRuvgzp": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uJ7gdQ8ZRnn9M9zTE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 29, "extendedScore": null, "score": 0.000107, "legacy": true, "legacyId": "22634", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DBajPuTRK9x26jrvh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-23T07:08:46.116Z", "modifiedAt": null, "url": null, "title": "[link] Are All Dictator Game Results Artifacts?", "slug": "link-are-all-dictator-game-results-artifacts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:37.309Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g8mLJEYzCxLfi7pPg/link-are-all-dictator-game-results-artifacts", "pageUrlRelative": "/posts/g8mLJEYzCxLfi7pPg/link-are-all-dictator-game-results-artifacts", "linkUrl": "https://www.lesswrong.com/posts/g8mLJEYzCxLfi7pPg/link-are-all-dictator-game-results-artifacts", "postedAtFormatted": "Thursday, May 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Are%20All%20Dictator%20Game%20Results%20Artifacts%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Are%20All%20Dictator%20Game%20Results%20Artifacts%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg8mLJEYzCxLfi7pPg%2Flink-are-all-dictator-game-results-artifacts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Are%20All%20Dictator%20Game%20Results%20Artifacts%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg8mLJEYzCxLfi7pPg%2Flink-are-all-dictator-game-results-artifacts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg8mLJEYzCxLfi7pPg%2Flink-are-all-dictator-game-results-artifacts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 547, "htmlBody": "<p><a href=\"http://www.epjournal.net/blog/2013/05/are-all-dictator-game-results-artifacts/\">http://www.epjournal.net/blog/2013/05/are-all-dictator-game-results-artifacts/</a></p>\n<blockquote>\n<p>You walk into a laboratory, and you read a set of instructions that  tell you that your task is to decide how much of a $10 pie you want to  give to an anonymous other person who signed up for the experimental  session.</p>\n<p>This describes, more or less, the Dictator Game, a staple of  behavioral economics with a history dating back more than a quarter of a  century. The Dictator Game (DG) might not be the <em>drosophila melanogaster</em> of behavioral economics &ndash; the Prisoner&rsquo;s Dilemma can lay plausible  claim to that prized analogy &ndash; but it could reasonably aspire to an only  slightly more modest title, perhaps the&nbsp;<em>e. coli</em> of the discipline. Since the original work, more than 20,000 observations in the DG have been reported.</p>\n<p>[...]</p>\n<p><span class=\"userContent\">How much would  participants in a Dictator Game give to the other person if they did not  know they were in a Dictator Game study? Simply following me around  during the day and recording how much cash I dispense won<span class=\"text_exposed_show\">&rsquo;t answer this question because in the DG, the money is provided by the  experimenter. So, to build a parallel design, the method used must move  money to subjects as a windfall so that we can observe how much of this  &ldquo;house money&rdquo; they choose to give away.<br /> <br /> And that is what  Winking and Mizer did in a paper now in press and available online  (paywall) in Evolution and Human Behavior, using participants, fittingly  enough, in Las Vegas. Here&rsquo;s what they did. Two confederates were  needed. The first, destined to become the &ldquo;recipient,&rdquo; was occupied on a  phone call near a bus stop in Vegas. The second confederate approached  lone individuals at the bus stop, indicated that they were late for a  ride to the airport, and asked the subject if they wanted the $20 in  casino chips still in the confederate&rsquo;s possession, scamming people  into, rather than out of money, in sharp contradiction of the deep  traditions of Las Vegas. The question was how many chips the fortunate  subject transferred to the nearby confederate.</span></span></p>\n<p><span class=\"userContent\"><span class=\"text_exposed_show\">[...]<br /> <br /> In a  second condition, the confederate with the chips added a comment to the  effect that the subject could &ldquo;split it with that guy however you want,&rdquo;  indicating the first confederate. This condition brings the study a bit  closer, but not much closer, to lab conditions, In a third condition,  subjects were asked if they wanted to participate in a study, and then  did so along the lines of the usual DG, making the treatment  considerably closer to traditional lab-based conditions.<br /> <br /> The  difference between the first two treatments and the third treatments is  interesting, but, as I said at the beginning, the DG should be thought  of as a measuring tool. Figure 1 shows how many chips people give away  in the DG in the three treatments. In conditions 1 and 2, the number of  people (out of 60) who gave at least one chip to the second confederate  was&hellip; zero. To the extent you think that this method answers the  question, how much Dictator Game giving is due to people knowing they&rsquo;re  in an experiment, the answer is, &ldquo;all of it.&rdquo;</span></span></p>\n</blockquote>\n<p><span class=\"userContent\"><span class=\"text_exposed_show\"><a href=\"http://www.ehbonline.org/article/S1090-5138%2813%2900043-3/abstract\">Link to paper</a> (paywalled).<br /></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"b8FHrKqyXuYGWc6vn": 1, "vg4LDxjdwHLotCm8w": 1, "dBPou4ihoQNY4cquv": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g8mLJEYzCxLfi7pPg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 24, "extendedScore": null, "score": 1.2082367259928809e-06, "legacy": true, "legacyId": "22687", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-23T14:38:57.275Z", "modifiedAt": null, "url": null, "title": "[LINK] Does Time Exist? With Julian Barbour", "slug": "link-does-time-exist-with-julian-barbour", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:38.609Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benito", "createdAt": "2012-03-14T21:58:54.405Z", "isAdmin": true, "displayName": "Ben Pace"}, "userId": "EQNTWXLKMeWMp2FQS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oYoFTKbqP8Lm642xS/link-does-time-exist-with-julian-barbour", "pageUrlRelative": "/posts/oYoFTKbqP8Lm642xS/link-does-time-exist-with-julian-barbour", "linkUrl": "https://www.lesswrong.com/posts/oYoFTKbqP8Lm642xS/link-does-time-exist-with-julian-barbour", "postedAtFormatted": "Thursday, May 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Does%20Time%20Exist%3F%20With%20Julian%20Barbour&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Does%20Time%20Exist%3F%20With%20Julian%20Barbour%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoYoFTKbqP8Lm642xS%2Flink-does-time-exist-with-julian-barbour%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Does%20Time%20Exist%3F%20With%20Julian%20Barbour%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoYoFTKbqP8Lm642xS%2Flink-does-time-exist-with-julian-barbour", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoYoFTKbqP8Lm642xS%2Flink-does-time-exist-with-julian-barbour", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 79, "htmlBody": "<p>About six months ago, Julian Barbour did a introductory-level talk, attempting to explain the ideas in his book 'The End of Time'. The topic of his book, Yudkowsky has blogged about several times, but to the non-mathsy non-physicists, this talk might be a good introduction. It's very easygoing, and has also persuaded me to buy his book.</p>\n<p>http://ww3.tvo.org/video/185595/julian-barbour-does-time-exist</p>\n<p>&nbsp;</p>\n<p>If someone has already linked it, please say so.</p>\n<p>Yudkowsky's related posts can mostly be found by typing 'Julian Barbour' in the search bar.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oYoFTKbqP8Lm642xS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": -1, "extendedScore": null, "score": 1.2085672860733648e-06, "legacy": true, "legacyId": "22691", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-23T15:55:33.672Z", "modifiedAt": null, "url": null, "title": "Maximizing Financial Utility and Frugality", "slug": "maximizing-financial-utility-and-frugality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:29.439Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Petruchio", "createdAt": "2012-09-20T21:52:44.002Z", "isAdmin": false, "displayName": "Petruchio"}, "userId": "Sq97ckSEEWbQ6AxC9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iqvYGEmMHhFSEcfTr/maximizing-financial-utility-and-frugality", "pageUrlRelative": "/posts/iqvYGEmMHhFSEcfTr/maximizing-financial-utility-and-frugality", "linkUrl": "https://www.lesswrong.com/posts/iqvYGEmMHhFSEcfTr/maximizing-financial-utility-and-frugality", "postedAtFormatted": "Thursday, May 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Maximizing%20Financial%20Utility%20and%20Frugality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaximizing%20Financial%20Utility%20and%20Frugality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiqvYGEmMHhFSEcfTr%2Fmaximizing-financial-utility-and-frugality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Maximizing%20Financial%20Utility%20and%20Frugality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiqvYGEmMHhFSEcfTr%2Fmaximizing-financial-utility-and-frugality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiqvYGEmMHhFSEcfTr%2Fmaximizing-financial-utility-and-frugality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 470, "htmlBody": "<p>The past few days have seen an increase of chatter concerning retirement and financial planning. One of us is even putting out a prospectus for a rational financial planning sequence. Some others have derided the concept of saving for retirement, as there is a probability of death before that time.</p>\r\n<p>I am of the Extreme Early Retirement group. The idea is to save and invest 60-90% of your income, and you will have enough money to retire within a decade rather than four decades of the normal working career. This requires you to exercise your frugality muscle (such as cutting cable, biking to work, eating out less), but due to hedonistic adaptation, you will come out no less unhappy.</p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\">The <a href=\"/lw/4su/the_science_of_happiness/\">sequences</a> have already spoken on how spending money does not make us happier (after our basic needs are met). A Rational Financial plan should take this into account, even if a majority of people would not want to consider it.</p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\">I am just a beginner, so I linked the two big names in EEA, <a href=\"/mrmoneymustache.com\">Mr. Money Mustache</a> and <a href=\"/earlyretirementextreme.com\">Early Retirement Extreme</a>. You can find their journeys towards financial independence <a href=\"http://www.mrmoneymustache.com/2011/09/15/a-brief-history-of-the-stash-how-we-saved-from-zero-to-retirement-in-ten-years/\">here</a>&nbsp;and <a href=\"http://earlyretirementextreme.com/how-i-became-financially-independent-in-5-years-part-i.html\">here</a>.</p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\">ERE is an austerity heavyweight, while MMM lives a pretty luxurious lifestyle, but still spends much less than his former coworkers. He just spends on what is important to him, such as travelling with his family and eating organic food, and not on anything frivolous, such as cable or eating out. He lives very far from a deprived lifestyle which the average person would shy away from. It takes a paradigm shift and some grit, but the people of LessWrong are not the type to reject munchkin ideas because it takes a little bit of mental effort.</p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\">If I were to make a compilation of posts for a Rational Financial Planning sequence, it will go as such&hellip;</p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\"><a href=\"http://earlyretirementextreme.com/how-little-do-you-need-to-retir.html\">How</a><span style=\"mso-spacerun: yes\">&nbsp;</span><a href=\"http://earlyretirementextreme.com/how-i-live-on-7000-per-year.html\">Little</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2013/01/21/exposed-the-mmm-familys-2012-spending/\">Money</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2012/06/01/raising-a-family-on-under-2000-per-year/\">you</a><span style=\"mso-spacerun: yes\">&nbsp;</span><a href=\"http://www.mrmoneymustache.com/2012/12/15/high-cost-of-living-its-a-state-of-mind/\">need</a>&nbsp;<a href=\"http://earlyretirementextreme.com/how-rich-do-you-really-need-to-be.htm\">to</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2012/05/29/how-much-do-i-need-for-retirement/\">Retire</a>&nbsp;<a href=\"http://earlyretirementextreme.com/can-i-retire-young.html\">?</a> <br /><a href=\"http://www.mrmoneymustache.com/2012/01/13/the-shockingly-simple-math-behind-early-retirement/\">Basic</a>&nbsp;<a href=\"http://earlyretirementextreme.com/wiki/index.php?title=Calculate_Your_Time_to_Retirement\">Retirement</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2011/04/26/why-hardcore-saving-is-much-more-powerful-than-masterful-investing/\">Math</a><br /><a href=\"http://www.mrmoneymustache.com/2011/07/14/living-better-than-your-neighbors-on-75-less/\">Rationalist</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2011/10/06/the-true-cost-of-commuting/\">Spending</a>&nbsp;<br /><a href=\"http://www.mrmoneymustache.com/2011/06/21/frugality-as-a-muscle/\">Maximizing</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2012/12/18/your-money-or-your-life/\">Utilons</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2012/09/06/does-peak-happiness-really-come-at-75000year/\">per</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2011/10/22/what-is-hedonic-adaptation-and-how-can-it-turn-you-into-a-sukka/\">Dollar</a><br /><a href=\"http://earlyretirementextreme.com/day-5-find-a-free-hobb.html\">Utilons</a><span style=\"mso-spacerun: yes\"> </span><a href=\"http://earlyretirementextreme.com/day-18-join-a-challeng.html\">Free</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2011/10/20/mmm-challenge-try-getting-your-groceries-with-a-bike-trailer/\">Of</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2013/03/19/a-lifetime-of-riches-is-it-as-simple-as-a-few-habits/\">Charge</a><br /><a href=\"http://www.mrmoneymustache.com/2012/07/30/managed-payout-funds-automatic-grocery-buying-machines-for-the-early-retiree/\">Investing</a>&nbsp;<a href=\"http://www.mrmoneymustache.com/2011/08/15/become-a-lazy-landlord-with-reits/\">Rationally</a>&nbsp;<a href=\"http://earlyretirementextreme.com/day-14-investing-for-early-retiremen.html\">Basics</a></p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\">These are just the basics. Investment advice is scare, and the above does not talk about many fianacial aspects, such as insurance, children, career choice. The authors do speak about them on their blog&rsquo;s, but I omitted them for brevity. Read and follow these posts however, and you will be better off than 90% of your peers, and well on the road to Extreme Early Retirement.</p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\">[Edit] This idea of cutting your expenses and maximizing your savings obviously do not apply only to early retirement. Other financial goals, such as saving for a house, building up capital for a business, or giving more money to charity all will be more quickly accomplished if you learn to cut excesses from your life. The driving idea is the cost to live is very small, you are not made any happier by spending money on the extras, and you should put this money where it matters to you the most.</p>\r\n<p class=\"MsoNormal\" style=\"MARGIN: 0in 0in 10pt\">Petruchio</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iqvYGEmMHhFSEcfTr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 22, "extendedScore": null, "score": 5.7e-05, "legacy": true, "legacyId": "22692", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZbgCx2ntD5eu8Cno9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-23T16:14:42.953Z", "modifiedAt": null, "url": null, "title": "Random responses to surveys [reference request]", "slug": "random-responses-to-surveys-reference-request", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:37.128Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xZzZ2vH6PPaDHou69/random-responses-to-surveys-reference-request", "pageUrlRelative": "/posts/xZzZ2vH6PPaDHou69/random-responses-to-surveys-reference-request", "linkUrl": "https://www.lesswrong.com/posts/xZzZ2vH6PPaDHou69/random-responses-to-surveys-reference-request", "postedAtFormatted": "Thursday, May 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Random%20responses%20to%20surveys%20%5Breference%20request%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARandom%20responses%20to%20surveys%20%5Breference%20request%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxZzZ2vH6PPaDHou69%2Frandom-responses-to-surveys-reference-request%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Random%20responses%20to%20surveys%20%5Breference%20request%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxZzZ2vH6PPaDHou69%2Frandom-responses-to-surveys-reference-request", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxZzZ2vH6PPaDHou69%2Frandom-responses-to-surveys-reference-request", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 21, "htmlBody": "<p>I'm looking for research on the frequency with which survey participants answer questions without reading them. I'd greatly appreciate any references.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xZzZ2vH6PPaDHou69", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 6, "extendedScore": null, "score": 1.208637621774033e-06, "legacy": true, "legacyId": "22693", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-23T19:17:41.213Z", "modifiedAt": null, "url": null, "title": "Problems with Academia and the Rising Sea", "slug": "problems-with-academia-and-the-rising-sea", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:56.389Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JbqCJ98ZYzpSig6M7/problems-with-academia-and-the-rising-sea", "pageUrlRelative": "/posts/JbqCJ98ZYzpSig6M7/problems-with-academia-and-the-rising-sea", "linkUrl": "https://www.lesswrong.com/posts/JbqCJ98ZYzpSig6M7/problems-with-academia-and-the-rising-sea", "postedAtFormatted": "Thursday, May 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Problems%20with%20Academia%20and%20the%20Rising%20Sea&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProblems%20with%20Academia%20and%20the%20Rising%20Sea%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJbqCJ98ZYzpSig6M7%2Fproblems-with-academia-and-the-rising-sea%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Problems%20with%20Academia%20and%20the%20Rising%20Sea%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJbqCJ98ZYzpSig6M7%2Fproblems-with-academia-and-the-rising-sea", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJbqCJ98ZYzpSig6M7%2Fproblems-with-academia-and-the-rising-sea", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1157, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>1181</o:Words> <o:Characters>6737</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>56</o:Lines> <o:Paragraphs>15</o:Paragraphs> <o:CharactersWithSpaces>7903</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong>Severe problems with the biomedical research process</strong></p>\n<p class=\"MsoNormal\">GiveWell has recently been investigating ways to improve biomedical research. When I discovered GiveWell's research I was shocked by how severe and comprehensive the problems with the field seem to be:</p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Ferric%20Fang%2003-01-13%20(public).pdf\">conversation</a> with Ferric Fang:</p>\n<p class=\"MsoNormal\"><em>Because scientists have to compete for grants, they spend a very large fraction of their time fundraising, sometimes more than 50% of their working hours. Scientists feel </em>[<em>strong</em><span style=\"font-size:13.0pt; mso-bidi-font-size:12.0pt\">]</span><em> pressure to optimize their activities for getting tenure and grants, rather than for doing good science.</em>&nbsp;</p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Elizabeth%20Iorns%20conversation%2002-26-13%20(public).pdf\">conversation</a> with Elizabeth Iorns:</p>\n<p class=\"MsoNormal\"><em>Researchers are rewarded primarily for publishing papers in prestigious journals such as <span style=\"text-decoration: underline;\">Nature, Science and Cell. </span>These journals select for papers that report on surprising and unusual findings. Papers that report on unsound research that is apparently exciting are more likely to be published than papers which report on less exciting research that is sound.</em></p>\n<p class=\"MsoNormal\"><em>There is little post-publication check on the soundness of papers&rsquo; findings, because journals, especially prestigious ones, generally don&rsquo;t publish replications, and there is little funding for performing replications.</em></p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\"><em>Pharmaceutical companies such as Bayer and Amgen have studied the frequency with which studies are reproducible by trying to reproduce them, and they have found that about 70% of published papers in the areas that they considered don&rsquo;t reproduce.</em></p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\"><em>Because many published results are not reproducible, it is difficult for scientists to use the published literature as a basis for deciding what experiments to perform.</em></p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\"><em>As things stand, the pharmaceutical industry does replications, however, these are generally unpublished. Because a given lab doesn&rsquo;t know whether other labs have found that a study fails to replicate, labs duplicate a lot of effort.</em></p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Ken%20Witwer%2002-28-13%20(public).pdf\">conversation</a> with Ken Witwer:</p>\n<p class=\"MsoNormal\"><em>Dr. Witwer published a study in <span style=\"text-decoration: underline;\">Clinical Chemistry</span> examining 127 papers that had been published in between July 2011 and April 2012 in journals that ostensibly require that researchers deposit their microarray data. He found that the data was not submitted for almost 60% of papers, and that data for 75% of papers were not in a format suitable for replication.</em></p>\n<p class=\"MsoNormal\">The above remarks give the impression that the problems are deeply entrenched and mutually reinforcing. On first glance, it seems that while one might be able to make incremental improvements (such as funding a journal that publishes replications), prospects for big improvements are very poor. But I became more hopeful after learning more.</p>\n<p class=\"MsoNormal\"><strong>The Rising Sea</strong></p>\n<p class=\"MsoNormal\">The great mathematician Alexander Grothendieck <a href=\"http://www.math.jussieu.fr/~leila/grothendieckcircle/mclarty1.pdf\">wrote</a> about two approaches to solving a difficult problem:</p>\n<p class=\"MsoNormal\"><em>If you think of a theorem to be proved as a nut to be opened, so as to reach &ldquo;the nourishing \ufb02esh protected by the shell&rdquo;, then the hammer and chisel principle is: &ldquo;put the cutting edge of the chisel against the shell and strike hard. If needed, begin again at many di\ufb00erent points until the shell cracks&mdash;and you are satis\ufb01ed&rdquo;.</em></p>\n<p class=\"MsoNormal\">[<em>&hellip;</em>]</p>\n<p class=\"MsoNormal\"><em>I can illustrate the second approach with the same image of a nut to be opened. The \ufb01rst analogy that came to my mind is of immersing the nut in some softening liquid, and why not simply water? From time to time you rub so the liquid penetrates better, and otherwise you let time pass. The shell becomes more \ufb02exible through weeks and months&mdash;when the time is ripe, hand pressure is enough, the shell opens like a perfectly ripened avocado!</em></p>\n<p class=\"MsoNormal\"><em>A di\ufb00erent image came to me a few weeks ago. The unknown thing to be known appeared to me as some stretch of earth or hard marl, resisting penetration &hellip; the sea advances insensibly in silence, nothing seems to happen, nothing moves, the water is so far o\ufb00 you hardly hear it &hellip;. yet it \ufb01nally surrounds the resistant substance.</em></p>\n<p class=\"MsoNormal\">When a nut seems too hard to crack, it&rsquo;s wise to think about the second method that Grothendieck describes.</p>\n<p class=\"MsoNormal\"><strong>Alternative Metrics</strong></p>\n<p class=\"MsoNormal\">I was encouraged by GiveWell&rsquo;s subsequent conversations, with David Jay and Jason Priem, which suggest a &ldquo;rising sea&rdquo; type solution to the cluster of apparently severe problems with biomedical research.</p>\n<p class=\"MsoNormal\">In brief, the idea is that it may be possible to create online communities and interfaces that can be used to generate measures of how valuable researchers find research outputs, and which could be used for funding and tenure decisions, thereby rewarding producing the research outputs that other researchers find most valuable. If incentives become aligned with producing valuable research, the whole system will shift accordingly, greatly reducing the existing inefficiencies.</p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Jason%20Priem%2003-13-13%20(public).pdf\">conversation</a> with Jason Priem</p>\n<p class=\"MsoNormal\"><em>Historically, the academic community has filtered academic outputs for interest by peer review and, more specifically, the prestige of the journals where papers are published. This model is inadequate relative to filtering mechanisms that are now in principle possible using the Internet.</em></p>\n<p class=\"MsoNormal\"><em>It is now possible to use the web to measure the quality and impact of an academic output via alternative metrics (altmetrics)</em> <em>such as</em></p>\n<ul>\n<li><em style=\"text-indent: -0.25in;\">How many people downloaded it</em></li>\n<li><em style=\"text-indent: -0.25in;\">How much it has been discussed on Twitter</em></li>\n<li><em style=\"text-indent: -0.25in;\">How many websites link to it</em></li>\n<li><em style=\"text-indent: -0.25in;\">The caliber of the scientists who have recommended it</em></li>\n<li><em style=\"text-indent: -0.25in;\">How many people have saved it in a reference manager like Mendeley or Zotero</em></li>\n</ul>\n<p class=\"MsoNormal\"><em>This is similar to how Google generates a list of webpages corresponding to a search term, since you can benefit from PageRank-type algorithms that foreground popular&nbsp; content in an intelligent fashion.</em></p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\"><em>There&rsquo;s been a significant amount of interest from funders and administrators in more nuanced and broader measures of researcher impact than their journal publication record. </em>[&hellip;]<em> Algorithmically generated rankings of researchers&rsquo; influence as measured by the altmetrics mentioned previously could be an input into hiring, tenure, promotion, and grant decisions. ImpactStory and other providers of alternative metrics could help researchers&rsquo; aggregate their online impact so that they can present good summaries of it to administrators and funders.</em><em>&nbsp;</em></p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/David%20Jay%2003-14-13%20(public).pdf\">conversation</a> with David Jay</p>\n<p class=\"MsoNormal\"><em>Commenting systems could potentially be used to create much more useful altmetrics. Such altmetrics could be generated for a scientific output by examining the nature of the comments that scientists make about it, weighting the comments using factors such as the number of upvotes that a comment receives and how distinguished the commenter is.</em></p>\n<p class=\"MsoNormal\"><em>The metrics generated would be more informative than a journal publication record, because commenters give more specific feedback than the acceptance/rejection of a paper submitted to a given journal does.</em></p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\"><em>If scientists were to routinely use online commenting systems to discuss scientific outputs, it seems likely that altmetrics generated from them would be strong enough for them to be used for hiring, promotion and grant-making decisions (in conjunction with, or in place of, the traditional metric of journal publication record).</em></p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\"><em>David Jay envisages a future in which there is </em>[...]&nbsp;<em>A website which collects analytics from other websites so as to aggregate the impact of individual researchers, both for their own information and for use by hiring/promotion/grant committees.</em></p>\n<!--EndFragment-->\n<p>The viability of this approach remains to be seen, but it could work really well, and illustrate a general principle.</p>\n<p class=\"MsoNormal\"><strong>About the author:<em>&nbsp;</em></strong>I worked as a research analyst at GiveWell from April 2012 to May 2013. All views expressed here are my own.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZpG9rheyAkgCoEQea": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JbqCJ98ZYzpSig6M7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 46, "extendedScore": null, "score": 0.000123, "legacy": true, "legacyId": "22694", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>1181</o:Words> <o:Characters>6737</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>56</o:Lines> <o:Paragraphs>15</o:Paragraphs> <o:CharactersWithSpaces>7903</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong id=\"Severe_problems_with_the_biomedical_research_process\">Severe problems with the biomedical research process</strong></p>\n<p class=\"MsoNormal\">GiveWell has recently been investigating ways to improve biomedical research. When I discovered GiveWell's research I was shocked by how severe and comprehensive the problems with the field seem to be:</p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Ferric%20Fang%2003-01-13%20(public).pdf\">conversation</a> with Ferric Fang:</p>\n<p class=\"MsoNormal\"><em>Because scientists have to compete for grants, they spend a very large fraction of their time fundraising, sometimes more than 50% of their working hours. Scientists feel </em>[<em>strong</em><span style=\"font-size:13.0pt; mso-bidi-font-size:12.0pt\">]</span><em> pressure to optimize their activities for getting tenure and grants, rather than for doing good science.</em>&nbsp;</p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Elizabeth%20Iorns%20conversation%2002-26-13%20(public).pdf\">conversation</a> with Elizabeth Iorns:</p>\n<p class=\"MsoNormal\"><em>Researchers are rewarded primarily for publishing papers in prestigious journals such as <span style=\"text-decoration: underline;\">Nature, Science and Cell. </span>These journals select for papers that report on surprising and unusual findings. Papers that report on unsound research that is apparently exciting are more likely to be published than papers which report on less exciting research that is sound.</em></p>\n<p class=\"MsoNormal\"><em>There is little post-publication check on the soundness of papers\u2019 findings, because journals, especially prestigious ones, generally don\u2019t publish replications, and there is little funding for performing replications.</em></p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\"><em>Pharmaceutical companies such as Bayer and Amgen have studied the frequency with which studies are reproducible by trying to reproduce them, and they have found that about 70% of published papers in the areas that they considered don\u2019t reproduce.</em></p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\"><em>Because many published results are not reproducible, it is difficult for scientists to use the published literature as a basis for deciding what experiments to perform.</em></p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\"><em>As things stand, the pharmaceutical industry does replications, however, these are generally unpublished. Because a given lab doesn\u2019t know whether other labs have found that a study fails to replicate, labs duplicate a lot of effort.</em></p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Ken%20Witwer%2002-28-13%20(public).pdf\">conversation</a> with Ken Witwer:</p>\n<p class=\"MsoNormal\"><em>Dr. Witwer published a study in <span style=\"text-decoration: underline;\">Clinical Chemistry</span> examining 127 papers that had been published in between July 2011 and April 2012 in journals that ostensibly require that researchers deposit their microarray data. He found that the data was not submitted for almost 60% of papers, and that data for 75% of papers were not in a format suitable for replication.</em></p>\n<p class=\"MsoNormal\">The above remarks give the impression that the problems are deeply entrenched and mutually reinforcing. On first glance, it seems that while one might be able to make incremental improvements (such as funding a journal that publishes replications), prospects for big improvements are very poor. But I became more hopeful after learning more.</p>\n<p class=\"MsoNormal\"><strong id=\"The_Rising_Sea\">The Rising Sea</strong></p>\n<p class=\"MsoNormal\">The great mathematician Alexander Grothendieck <a href=\"http://www.math.jussieu.fr/~leila/grothendieckcircle/mclarty1.pdf\">wrote</a> about two approaches to solving a difficult problem:</p>\n<p class=\"MsoNormal\"><em>If you think of a theorem to be proved as a nut to be opened, so as to reach \u201cthe nourishing \ufb02esh protected by the shell\u201d, then the hammer and chisel principle is: \u201cput the cutting edge of the chisel against the shell and strike hard. If needed, begin again at many di\ufb00erent points until the shell cracks\u2014and you are satis\ufb01ed\u201d.</em></p>\n<p class=\"MsoNormal\">[<em>\u2026</em>]</p>\n<p class=\"MsoNormal\"><em>I can illustrate the second approach with the same image of a nut to be opened. The \ufb01rst analogy that came to my mind is of immersing the nut in some softening liquid, and why not simply water? From time to time you rub so the liquid penetrates better, and otherwise you let time pass. The shell becomes more \ufb02exible through weeks and months\u2014when the time is ripe, hand pressure is enough, the shell opens like a perfectly ripened avocado!</em></p>\n<p class=\"MsoNormal\"><em>A di\ufb00erent image came to me a few weeks ago. The unknown thing to be known appeared to me as some stretch of earth or hard marl, resisting penetration \u2026 the sea advances insensibly in silence, nothing seems to happen, nothing moves, the water is so far o\ufb00 you hardly hear it \u2026. yet it \ufb01nally surrounds the resistant substance.</em></p>\n<p class=\"MsoNormal\">When a nut seems too hard to crack, it\u2019s wise to think about the second method that Grothendieck describes.</p>\n<p class=\"MsoNormal\"><strong id=\"Alternative_Metrics\">Alternative Metrics</strong></p>\n<p class=\"MsoNormal\">I was encouraged by GiveWell\u2019s subsequent conversations, with David Jay and Jason Priem, which suggest a \u201crising sea\u201d type solution to the cluster of apparently severe problems with biomedical research.</p>\n<p class=\"MsoNormal\">In brief, the idea is that it may be possible to create online communities and interfaces that can be used to generate measures of how valuable researchers find research outputs, and which could be used for funding and tenure decisions, thereby rewarding producing the research outputs that other researchers find most valuable. If incentives become aligned with producing valuable research, the whole system will shift accordingly, greatly reducing the existing inefficiencies.</p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/Jason%20Priem%2003-13-13%20(public).pdf\">conversation</a> with Jason Priem</p>\n<p class=\"MsoNormal\"><em>Historically, the academic community has filtered academic outputs for interest by peer review and, more specifically, the prestige of the journals where papers are published. This model is inadequate relative to filtering mechanisms that are now in principle possible using the Internet.</em></p>\n<p class=\"MsoNormal\"><em>It is now possible to use the web to measure the quality and impact of an academic output via alternative metrics (altmetrics)</em> <em>such as</em></p>\n<ul>\n<li><em style=\"text-indent: -0.25in;\">How many people downloaded it</em></li>\n<li><em style=\"text-indent: -0.25in;\">How much it has been discussed on Twitter</em></li>\n<li><em style=\"text-indent: -0.25in;\">How many websites link to it</em></li>\n<li><em style=\"text-indent: -0.25in;\">The caliber of the scientists who have recommended it</em></li>\n<li><em style=\"text-indent: -0.25in;\">How many people have saved it in a reference manager like Mendeley or Zotero</em></li>\n</ul>\n<p class=\"MsoNormal\"><em>This is similar to how Google generates a list of webpages corresponding to a search term, since you can benefit from PageRank-type algorithms that foreground popular&nbsp; content in an intelligent fashion.</em></p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\"><em>There\u2019s been a significant amount of interest from funders and administrators in more nuanced and broader measures of researcher impact than their journal publication record. </em>[\u2026]<em> Algorithmically generated rankings of researchers\u2019 influence as measured by the altmetrics mentioned previously could be an input into hiring, tenure, promotion, and grant decisions. ImpactStory and other providers of alternative metrics could help researchers\u2019 aggregate their online impact so that they can present good summaries of it to administrators and funders.</em><em>&nbsp;</em></p>\n<p class=\"MsoNormal\">From a <a href=\"http://www.givewell.org/files/conversations/David%20Jay%2003-14-13%20(public).pdf\">conversation</a> with David Jay</p>\n<p class=\"MsoNormal\"><em>Commenting systems could potentially be used to create much more useful altmetrics. Such altmetrics could be generated for a scientific output by examining the nature of the comments that scientists make about it, weighting the comments using factors such as the number of upvotes that a comment receives and how distinguished the commenter is.</em></p>\n<p class=\"MsoNormal\"><em>The metrics generated would be more informative than a journal publication record, because commenters give more specific feedback than the acceptance/rejection of a paper submitted to a given journal does.</em></p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\"><em>If scientists were to routinely use online commenting systems to discuss scientific outputs, it seems likely that altmetrics generated from them would be strong enough for them to be used for hiring, promotion and grant-making decisions (in conjunction with, or in place of, the traditional metric of journal publication record).</em></p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\"><em>David Jay envisages a future in which there is </em>[...]&nbsp;<em>A website which collects analytics from other websites so as to aggregate the impact of individual researchers, both for their own information and for use by hiring/promotion/grant committees.</em></p>\n<!--EndFragment-->\n<p>The viability of this approach remains to be seen, but it could work really well, and illustrate a general principle.</p>\n<p class=\"MsoNormal\"><strong>About the author:<em>&nbsp;</em></strong>I worked as a research analyst at GiveWell from April 2012 to May 2013. All views expressed here are my own.</p>", "sections": [{"title": "Severe problems with the biomedical research process", "anchor": "Severe_problems_with_the_biomedical_research_process", "level": 1}, {"title": "The Rising Sea", "anchor": "The_Rising_Sea", "level": 1}, {"title": "Alternative Metrics", "anchor": "Alternative_Metrics", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "39 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-24T12:19:13.010Z", "modifiedAt": null, "url": null, "title": "Orwell and fictional evidence for dictatorship stability", "slug": "orwell-and-fictional-evidence-for-dictatorship-stability", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:31.792Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/73GboJqDCk6nBd2py/orwell-and-fictional-evidence-for-dictatorship-stability", "pageUrlRelative": "/posts/73GboJqDCk6nBd2py/orwell-and-fictional-evidence-for-dictatorship-stability", "linkUrl": "https://www.lesswrong.com/posts/73GboJqDCk6nBd2py/orwell-and-fictional-evidence-for-dictatorship-stability", "postedAtFormatted": "Friday, May 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Orwell%20and%20fictional%20evidence%20for%20dictatorship%20stability&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOrwell%20and%20fictional%20evidence%20for%20dictatorship%20stability%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F73GboJqDCk6nBd2py%2Forwell-and-fictional-evidence-for-dictatorship-stability%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Orwell%20and%20fictional%20evidence%20for%20dictatorship%20stability%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F73GboJqDCk6nBd2py%2Forwell-and-fictional-evidence-for-dictatorship-stability", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F73GboJqDCk6nBd2py%2Forwell-and-fictional-evidence-for-dictatorship-stability", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 498, "htmlBody": "<blockquote>\n<p>\"If you want a picture of the future, imagine a boot stamping on a human face&mdash;<strong>forever</strong>.\"<br />George Orwell (Eric Arthur Blair),&nbsp;Nineteen Eighty-Four</p>\n</blockquote>\n<p>Orwell's&nbsp;Nineteen Eighty-Four&nbsp;is brilliant, terrifying and useful. It's been at its best fighting against governmental intrusions, and is often quoted by journalists and even <a href=\"http://thehill.com/blogs/blog-briefing-room/news/192445-justice-breyer-warns-of-orwellian-government\">judges</a>. It's cultural impact has been immense. And, hey, it's well written.</p>\n<p>But that doesn't mean it's <a href=\"/lw/k9/the_logical_fallacy_of_generalization_from/\">accurate</a> as a source of predictions or counterfactuals. Orwell's belief that \"British democracy as it existed before 1939 would not survive the war\" was wrong. Nineteen Eighty-Four did not predict the future course of&nbsp;communism. There is no evidence that anything like the world he envisaged could (or will) happen. Which isn't the same as saying that it couldn't, but we do require some evidence before accepting Orwell's world as realistic.</p>\n<p>Yet from this book, a lot of implicit assumptions have seeped into our consciousness. The most important one (shared with many other&nbsp;dystopian&nbsp;novels) is that dictatorships are stable forms of government. Note the \"forever\" in the quote above - the society Orwell warned about would never change, never improve, never transform. In several conversations (about future governments, for instance), I've heard - and made - the argument that a dictatorship was inevitable, because it's an absorbing state. Democracies can come become dictatorships, but dictatorships (barring revolutions) will endure for good. And so the idea is that if revolutions become impossible (because of ubiquitous&nbsp;surveillance, for instance), then we're stuck with Big Brother for life, and for our children's children'c children's lives.</p>\n<p>But thinking about this in the context of history, this doesn't seem credible. The most stable forms of government are democracies and monarchies; nothing else endures that long. And laying revolutions aside, there have been plenty of examples of even quite nasty governments improving themselves. Robespierre was deposed from within his own government - and so the <a href=\"http://en.wikipedia.org/wiki/Reign_of_Terror\">Terror</a>, for all its bloodshed, didn't even last a full year. The worse excesses of Stalinism ended with Stalin. Gorbachev voluntarily opened up his regime (to a certain extent). Mao would&nbsp;excoriate&nbsp;the China of today. Britain's leaders in the 19th and 20th century gradually opened up the franchise, without ever coming close to being deposed by force of arms. The dictatorships of Latin America have mostly fallen to democracies (though revolutions played a larger role there). Looking over the course of recent history, I see very little evidence the dictatorships have much lasting power at all - or that they are incapable of drastic internal change and even improvements.</p>\n<p>Now, caveats abound. The future won't be like the past - maybe an Orwellian dictatorship will become possible with advanced surveillance technologies. Maybe a world government won't see any neighbouring government doing a better job, and feel compelled to match it by improving lot of its citizens. Maybe the <em>threat</em> of revolution remains necessary, even if revolts don't&nbsp;actually&nbsp;happen.</p>\n<p>Still, we should refrain from assuming that dictatorships, whether party or individual, are somehow the default state, and conduct a much more evidence-based analysis of the matter.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GBpwq8cWvaeRoE9X5": 2, "5f5c37ee1b5cdee568cfb125": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "73GboJqDCk6nBd2py", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 22, "extendedScore": null, "score": 6e-05, "legacy": true, "legacyId": "22703", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 79, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rHBdcHGLJ7KvLJQPk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-24T15:07:32.948Z", "modifiedAt": null, "url": null, "title": "New LW Meetups: Bristol, Tel Aviv", "slug": "new-lw-meetups-bristol-tel-aviv", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ij8ZF7Bo9CSeY3rL7/new-lw-meetups-bristol-tel-aviv", "pageUrlRelative": "/posts/ij8ZF7Bo9CSeY3rL7/new-lw-meetups-bristol-tel-aviv", "linkUrl": "https://www.lesswrong.com/posts/ij8ZF7Bo9CSeY3rL7/new-lw-meetups-bristol-tel-aviv", "postedAtFormatted": "Friday, May 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20LW%20Meetups%3A%20Bristol%2C%20Tel%20Aviv&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20LW%20Meetups%3A%20Bristol%2C%20Tel%20Aviv%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fij8ZF7Bo9CSeY3rL7%2Fnew-lw-meetups-bristol-tel-aviv%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20LW%20Meetups%3A%20Bristol%2C%20Tel%20Aviv%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fij8ZF7Bo9CSeY3rL7%2Fnew-lw-meetups-bristol-tel-aviv", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fij8ZF7Bo9CSeY3rL7%2Fnew-lw-meetups-bristol-tel-aviv", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 570, "htmlBody": "<p><strong>This summary was posted to LW main on May 17th. The following week's summary is <a href=\"/lw/hip/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>New meetups (or meetups with a hiatus of more than a year) are happening in:</p>\n<ul>\n<li><a href=\"/meetups/mx\">First Bristol meetup:&nbsp;<span class=\"date\">25 May 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/mw\">Tel Aviv, Israel Meetup - Goal Clarification with special guest Cat from CFAR:&nbsp;<span class=\"date\">23 May 2013 07:00PM</span></a></li>\n</ul>\n<p>Other irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m4\"><span style=\"font-family: Arial, Helvetica, sans-serif; color: #8a8a8b;\"><span style=\"line-height: 19px; text-align: justify;\">Atlanta Lesswrong's May Meetup: The Rationality of Social Relationships, Friendship, Love, and Family.:&nbsp;</span></span><span class=\"date\" style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\">17 May 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/mu\">Bielefeld Meetup May 22nd:&nbsp;<span class=\"date\">22 May 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m2\">Bratislava lesswrong meetup III:&nbsp;<span class=\"date\">20 May 2013 06:30PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m5\">Brussels meetup:&nbsp;<span class=\"date\">18 May 2013 01:00PM</span></a></li>\n<li><a href=\"/meetups/ms\">Durham/RTLW HPMoR discussion, ch. 65-68:&nbsp;<span class=\"date\">18 May 2013 12:30PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m2\"></a><a href=\"/meetups/mv\">London Meetup: 26th May:&nbsp;<span class=\"date\">26 May 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/mt\">[Moscow] Belief cleaning:&nbsp;<span class=\"date\">26 May 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/lo\"></a><a href=\"/meetups/mr\">Paris Meetup: Sunday, May 26.:&nbsp;<span class=\"date\">26 May 2013 02:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">18 May 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/mn\">Seattle-Vancouver Kilomeetup:&nbsp;<span class=\"date\">18 May 2013 11:54AM</span></a></li>\n<li><a href=\"/meetups/lt\">Vienna meetup #3:&nbsp;<span class=\"date\">18 May 2013 04:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ij8ZF7Bo9CSeY3rL7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 1.2096467502410404e-06, "legacy": true, "legacyId": "22631", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CqdcQFXyLgicamscY", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-24T18:14:34.898Z", "modifiedAt": null, "url": null, "title": "[LINK] Raw Story: US seizes operator accounts of a subsidiary of Mt. Gox", "slug": "link-raw-story-us-seizes-operator-accounts-of-a-subsidiary", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.183Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5cCZXrsKjZ63KeWyq/link-raw-story-us-seizes-operator-accounts-of-a-subsidiary", "pageUrlRelative": "/posts/5cCZXrsKjZ63KeWyq/link-raw-story-us-seizes-operator-accounts-of-a-subsidiary", "linkUrl": "https://www.lesswrong.com/posts/5cCZXrsKjZ63KeWyq/link-raw-story-us-seizes-operator-accounts-of-a-subsidiary", "postedAtFormatted": "Friday, May 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Raw%20Story%3A%20US%20seizes%20operator%20accounts%20of%20a%20subsidiary%20of%20Mt.%20Gox&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Raw%20Story%3A%20US%20seizes%20operator%20accounts%20of%20a%20subsidiary%20of%20Mt.%20Gox%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5cCZXrsKjZ63KeWyq%2Flink-raw-story-us-seizes-operator-accounts-of-a-subsidiary%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Raw%20Story%3A%20US%20seizes%20operator%20accounts%20of%20a%20subsidiary%20of%20Mt.%20Gox%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5cCZXrsKjZ63KeWyq%2Flink-raw-story-us-seizes-operator-accounts-of-a-subsidiary", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5cCZXrsKjZ63KeWyq%2Flink-raw-story-us-seizes-operator-accounts-of-a-subsidiary", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 20, "htmlBody": "<p>It's all right there in the title. <a href=\"http://www.rawstory.com/rs/2013/05/17/u-s-seizes-operator-accounts-of-major-japanese-bitcoin-exchange/\">Link</a>. I believe the law under which the seizure occurred is <a href=\"http://en.wikipedia.org/wiki/Title_31_of_the_United_States_Code\">Title 31</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5cCZXrsKjZ63KeWyq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -3, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "22706", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-24T19:34:59.071Z", "modifiedAt": null, "url": null, "title": "Is a paperclipper better than nothing?", "slug": "is-a-paperclipper-better-than-nothing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:08.482Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8toMZiL4xw9tMzfLQ/is-a-paperclipper-better-than-nothing", "pageUrlRelative": "/posts/8toMZiL4xw9tMzfLQ/is-a-paperclipper-better-than-nothing", "linkUrl": "https://www.lesswrong.com/posts/8toMZiL4xw9tMzfLQ/is-a-paperclipper-better-than-nothing", "postedAtFormatted": "Friday, May 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20a%20paperclipper%20better%20than%20nothing%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20a%20paperclipper%20better%20than%20nothing%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8toMZiL4xw9tMzfLQ%2Fis-a-paperclipper-better-than-nothing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20a%20paperclipper%20better%20than%20nothing%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8toMZiL4xw9tMzfLQ%2Fis-a-paperclipper-better-than-nothing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8toMZiL4xw9tMzfLQ%2Fis-a-paperclipper-better-than-nothing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 133, "htmlBody": "<p>Thought experiment:</p>\n<p>Through whatever accident of history underlies these philosophical dilemmas, you are faced with a choice between two, and only two, mutually exclusive options:</p>\n<p>* Choose A, and all life and sapience in the solar system (and presumably the universe), save for a sapient <a href=\"http://wiki.lesswrong.com/wiki/Paperclip_maximizer\">paperclipping AI</a>, dies.</p>\n<p>* Choose B, and all life and sapience in the solar system, including the paperclipping AI, dies.</p>\n<p>Phrased another way: does the existence of any intelligence at all, even a paperclipper, have even the smallest amount of utility above no intelligence at all?</p>\n<p>&nbsp;</p>\n<p>If anyone responds positively, subsequent questions would be which would be preferred, a paperclipper or a single bacteria; a paperclipper or a self-sustaining population of trilobites and their supporting ecology; a paperclipper or a self-sustaining population of australopithecines; and so forth, until the equivalent value is determined.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"QH4LhvnyR4QkW9MG8": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8toMZiL4xw9tMzfLQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 10, "extendedScore": null, "score": 1.20984350751781e-06, "legacy": true, "legacyId": "22707", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 116, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-24T20:28:43.492Z", "modifiedAt": null, "url": null, "title": "Robustness of Cost-Effectiveness Estimates and Philanthropy", "slug": "robustness-of-cost-effectiveness-estimates-and-philanthropy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:02.824Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rNuBzyWkigrf6BWg7/robustness-of-cost-effectiveness-estimates-and-philanthropy", "pageUrlRelative": "/posts/rNuBzyWkigrf6BWg7/robustness-of-cost-effectiveness-estimates-and-philanthropy", "linkUrl": "https://www.lesswrong.com/posts/rNuBzyWkigrf6BWg7/robustness-of-cost-effectiveness-estimates-and-philanthropy", "postedAtFormatted": "Friday, May 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Robustness%20of%20Cost-Effectiveness%20Estimates%20and%20Philanthropy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARobustness%20of%20Cost-Effectiveness%20Estimates%20and%20Philanthropy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrNuBzyWkigrf6BWg7%2Frobustness-of-cost-effectiveness-estimates-and-philanthropy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Robustness%20of%20Cost-Effectiveness%20Estimates%20and%20Philanthropy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrNuBzyWkigrf6BWg7%2Frobustness-of-cost-effectiveness-estimates-and-philanthropy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrNuBzyWkigrf6BWg7%2Frobustness-of-cost-effectiveness-estimates-and-philanthropy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1793, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>2270</o:Words> <o:Characters>12943</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>107</o:Lines> <o:Paragraphs>30</o:Paragraphs> <o:CharactersWithSpaces>15183</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong>Note:<em>&nbsp;</em></strong>I formerly worked as a research analyst at <a href=\"http://www.givewell.org/\">GiveWell</a>. This post describes the evolution of my thinking about robustness of cost-effectiveness estimates in philanthropy. All views expressed here are my own.</p>\n<p class=\"MsoNormal\">Up until 2012, I believed that detailed explicit cost-effectiveness estimates are very important in the context of philanthropy. My position was reflected in a <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/comment-page-1/#comment-230938\">comment that I made</a> in 2011:&nbsp;</p>\n<p class=\"MsoNormal\" style=\"margin-left:.5in\">The problem with using unquantified heuristics and intuitions is that the &ldquo;true&rdquo; expected values of philanthropic efforts plausibly differ by many orders of magnitude, and unquantified heuristics and intuitions are frequently insensitive to this. The last order of magnitude is the only one that matters; all others are negligible by comparison. So if at all possible, one should do one&rsquo;s best to pin down the philanthropic efforts with the &ldquo;true&rdquo; expected value per dollar of the highest (positive) order of magnitude. It seems to me as though any feasible strategy for attacking this problem involves explicit computation.</p>\n<p class=\"MsoNormal\">During my time at GiveWell, my position on this matter shifted. I still believe that there are instances in which <em>rough</em> cost-effectiveness estimates can be useful for determining good philanthropic foci. But I&rsquo;ve shifted toward the position that <strong>effective altruists should spend much more time on qualitative analysis than on quantitative analysis in determining how they can maximize their positive social impact</strong>.</p>\n<p class=\"MsoNormal\">In this post I&rsquo;ll focus on one reason for my shift: <strong>explicit cost-effectiveness estimates are generally much less robust than I had previously thought</strong>.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">The history of GiveWell&rsquo;s estimates for lives saved per dollar</span></strong></p>\n<p class=\"MsoNormal\">Historically, GiveWell used &ldquo;cost per life saved&rdquo; as a measure of the cost-effectiveness of its global health recommendations. Examination of the trajectory of GiveWell&rsquo;s cost-effectiveness estimates shows that <strong>GiveWell has consistently updated in the direction of its ranked charities having higher &ldquo;cost per life saved&rdquo; than GiveWell had previously thought. </strong>I give the details below.</p>\n<p class=\"MsoNormal\">The discussion should be read with the understanding that <strong>donating to GiveWell&rsquo;s top charities has benefits that extend beyond saving lives</strong>, so that &ldquo;number of lives saved&rdquo; understates cost-effectiveness..</p>\n<p class=\"MsoNormal\">At the end of each of 2009 and 2010, GiveWell named <a href=\"http://www.givewell.org/international/charities/villagereach\">VillageReach</a> its #1 ranked charity. VillageReach <a href=\"http://www.givewell.org/international/top-charities/villagereach/December-2009-review#Pastcosteffectivenesspilotprogram\">estimated</a> the cost-per-life-saved of its pilot project as being &lt; $200, and at the end of 2009, GiveWell gave a &ldquo;conservative&rdquo; estimate of $545/life saved. In 2011, GiveWell <a href=\"http://blog.givewell.org/2012/07/26/rethinking-villagereachs-pilot-project/\">reassessed VillageReach&rsquo;s pilot project</a>, commending VillageReach for being transparent enough for reassessment to be possible, and concluding that</p>\n<p class=\"MsoNormal\" style=\"margin-left:.5in\">We feel that within the framework of &ldquo;delivering proven, cost-effective interventions to improve health,&rdquo; AMF and SCI are solidly better giving opportunities than VillageReach (both now and at the time when we recommended it). Given the information we have, we see less room for doubt in the cases for AMF&rsquo;s and SCI&rsquo;s impact than in the case for VillageReach&rsquo;s.</p>\n<p class=\"MsoNormal\">Here &ldquo;AMF&rdquo; refers to <a href=\"http://www.givewell.org/international/top-charities/AMF\">Against Malaria Foundation</a>, which is GiveWell&rsquo;s current #1 ranked charity. If AMF is currently more cost-effective than VillageReach was at the time when GiveWell recommended VillageReach, then the best cost-per-life-saved figure for GiveWell&rsquo;s recommended charities is (and was) the cost-effectiveness of donating to AMF.&nbsp;</p>\n<p class=\"MsoNormal\">AMF delivers long-lasting insecticide treated nets (LLINs) to the developing world to protect people against mosquitoes that spread malaria. This contrasts with VillageReach, which works to increase vaccination rates. Vaccines are thought to be more cost-effective than LLINs, and <a href=\"http://blog.givewell.org/2013/03/21/trying-and-failing-to-find-more-funding-gaps-for-delivering-proven-cost-effective-interventions/\">GiveWell has not been able to find strong giving opportunities in vaccination</a>, so the cost per life saved of the best opportunity that GiveWell has found for individual donors is correspondingly higher.&nbsp;</p>\n<p class=\"MsoNormal\">At the end of 2011, GiveWell estimated that the marginal cost per life associated with donating to AMF at <a href=\"http://www.givewell.org/international/top-charities/AMF/2011-review#Costperlifesaved\">$1600/life saved</a>. During 2012, I vetted GiveWell&rsquo;s page on LLINs and <a href=\"http://blog.givewell.org/2012/10/18/revisiting-the-case-for-insecticide-treated-nets-itns/\">uncovered an issue</a>, which led GiveWell to revise its estimate for AMF&rsquo;s marginal cost per life saved to <a href=\"http://www.givewell.org/international/top-charities/AMF#Costperlifesaved\">$2300/life saved</a> at the end of 2012. This does not take into account <a href=\"http://www.givingwhatwecan.org/where-to-give/methodology/regression-to-the-mean\">regression to the mean</a>, which can be expected to raise the cost per life saved.&nbsp;</p>\n<p class=\"MsoNormal\">The discussion above shows a consistent trend in the direction of the marginal cost per life saved in the developing world being higher than initially meets the eye. Note that the difference between VillageReach&rsquo;s original estimate and GiveWell&rsquo;s current estimate is about an order of magnitude.&nbsp;</p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Concrete factors that further reduce the expected value of donating to AMF</span></strong></p>\n<p class=\"MsoNormal\">A key point that I had missed when I thought about these things earlier in my life is that <strong>there are many small probability failure modes which are not significant individually, but which collectively substantially reduce cost-effectiveness</strong>. When I encountered such a potential failure mode, my reaction was to think &ldquo;this is very unlikely to be an issue&rdquo; and then to forget about it. I didn&rsquo;t notice that I was doing this many times in a row.</p>\n<p class=\"MsoNormal\">I list many relevant factors that reduce AMF&rsquo;s expected cost-effectiveness below. Some of these are from GiveWell&rsquo;s discussion of <a href=\"http://www.givewell.org/international/top-charities/AMF#Possiblenegativeoroffsettingimpact\">possible negative or offsetting impacts</a> in GiveWell&rsquo;s review of AMF. Others are implicitly present in GiveWell&rsquo;s review of AMF and<a href=\"http://www.givewell.org/international/technical/programs/insecticide-treated-nets\"> GiveWell&rsquo;s review of LLINs</a>, and others are issues that have emerged in the interim. I would emphasize that <strong>I don&rsquo;t think that any of the points listed is a big issue</strong> and that <strong>GiveWell and AMF take precautionary efforts to guard against them</strong>. But I think that they <em>collectively</em> reduce cost-effectiveness by a substantial amount.</p>\n<ul>\n<li>If GiveWell&rsquo;s customers weren&rsquo;t funding AMF, another funder might, and that funder might instead be funding much less effective activities.</li>\n<li>If AMF weren&rsquo;t working in a given region, there might be other organizations that would deliver LLINs to that region, and these other organizations may instead be funding much less effective activities.</li>\n<li>It could be that the workers who distribute the LLINs would otherwise be providing more cost-effective health care interventions.</li>\n<li>The five RCTs that found that LLIN distribution reduces mortality could be systematically flawed in a non-obvious way.</li>\n<li>While the Cochrane Review that contains a meta-analysis of the RCTs referred to unpublished studies so as to counteract&nbsp;<a href=\"http://blog.givewell.org/2009/01/25/publication-bias-over-reporting-good-news/\">publication bias</a>, there may be unpublished studies that were missed, and which were not published, because they found no effect.</li>\n<li>The field workers who are assigned to distribute LLINs may&nbsp;<a href=\"http://www.givewell.org/international/top-charities/amf/updates/March-2012#DistributioninNtcheudistrictofMalawi\">steal the nets to sell them for a profit</a>.</li>\n<li>Fathers&nbsp;<a href=\"http://ugandaradionetwork.com/a/story.php?s=18197\">may steal nets from pregnant mothers</a>&nbsp;and sell them for a profit.</li>\n<li>LLIN recipients may&nbsp;<a href=\"http://www.malariajournal.com/content/7/1/165\">use the nets for fishing</a>.</li>\n<li>LLIN users may not fasten LLINs properly.</li>\n<li>Mosquitoes may develop&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/21856232\">biological resistance to the insecticide used on LLINs</a>.</li>\n<li>Mosquitoes&nbsp;<a href=\"http://blog.givewell.org/2012/11/09/insecticide-resistance-and-malaria-control/\">may develop &ldquo;behavioral resistance&rdquo;</a>&nbsp;to the insecticides used on LLINs by evolving to bite during the day (when LLINs are not used) rather than during the night.</li>\n</ul>\n<p class=\"MsoNormal\">Most of the relevant factors will vary by region where AMF ships nets, and some may be present in certain locations and not others.</p>\n<p><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Do these considerations argue against donating to AMF?</span></strong><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">&nbsp;</span></strong></p>\n<p class=\"MsoNormal\">In view of the issues above, one might wonder whether it&rsquo;s better to donate to a charity in a different cause, or better not to donate at all. Some relevant points follow:</p>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\">Donating to AMF has benefits beyond saving lives. </strong><span style=\"text-indent: -0.25in;\">The above discussion of cost-effectiveness figures concerns &ldquo;cost per life saved&rdquo; specifically. But there are benefits to donating to AMF that go beyond saving lives.</span></p>\n<ul>\n<li><span style=\"text-indent: -0.25in;\">Malaria control reduces the morbidity of malaria. A Cochrane Review of the&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/programs/insecticide-treated-nets#Evidencefromsmallscalehighqualitystudies\">health benefits of LLINs</a><span style=\"text-indent: -0.25in;\">&nbsp;reports on reductions in anemia, enlarged spleen, and other health outcomes.<span style=\"text-indent: -0.25in;\"><br /></span></span></li>\n<li><span style=\"text-indent: -0.25in;\"><span style=\"text-indent: -0.25in;\">People are more productive when they&rsquo;re healthy than they are when they&rsquo;re ill.</span></span></li>\n<li><span style=\"text-indent: -0.25in;\">There is some evidence that malaria control&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/programs/insecticide-treated-nets#Possibledevelopmentaleffects\">increases children&rsquo;s income later on in life</a><span style=\"text-indent: -0.25in;\">.</span></li>\n<li><span style=\"text-indent: -0.25in;\">The above benefits could be massively leveraged via&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a><span style=\"text-indent: -0.25in;\">.</span></li>\n</ul>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\">Updates in the direction of reduced cost-effectiveness aren&rsquo;t specific to global health.</strong><span style=\"text-indent: -0.25in;\"> Based on my experience at GiveWell, I&rsquo;ve found that </span><em style=\"text-indent: -0.25in;\">regardless</em><span style=\"text-indent: -0.25in;\"> of the cause within which one investigates giving opportunities, there&rsquo;s a strong tendency for giving opportunities to appear progressively less promising as one learns more. AMF and LLIN distribution have stood up to scrutiny </span><em style=\"text-indent: -0.25in;\">unusually well</em><span style=\"text-indent: -0.25in;\">. It remains the case that </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2011/12/22/my-favorite-cause-for-individual-donors-global-health-and-nutrition/\">Global health and nutrition</a><span style=\"text-indent: -0.25in;\"> may be an unusually good cause for individual donors.</span></p>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\">Updates in the direction of reduced LLIN cost-effectiveness push in favor of cash transfers over LLINs. </strong><span style=\"text-indent: -0.25in;\">Transferring cash to people in the developing world is an unusually straightforward intervention. While there are </span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/programs/cash-transfers#Whatarethepotentialdownsidesoftheintervention\">potential downsides to transferring cash</a><span style=\"text-indent: -0.25in;\">, there seem to be fewer potential failure modes associated with it than there are potential failure modes associated with LLIN distribution. There are </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/05/30/giving-cash-versus-giving-bednets/\">strong arguments that favor LLINs over cash transfers</a><span style=\"text-indent: -0.25in;\">, but difference in straightforwardness of the interventions in juxtaposition with the phenomenon of surprisingly large updates in the direction of reduced cost-effectiveness is a countervailing consideration.</span></p>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Why do cost-effectiveness updates skew so negatively?</span></strong></p>\n<p class=\"MsoNormal\">When I first started thinking seriously about philanthropy in 2009, I thought that if one has impressions of a philanthropic opportunity, one will be equally likely to update in the direction of it being better than meets the eye as one will be to update the direction of the opportunity being worse than meets the eye. So I was surprised to discover how strong the tendency is for philanthropic opportunities to look worse over time rather than better over time.</p>\n<p class=\"MsoNormal\">Aside from the empirical data, something that shifted my view is Holden&rsquo;s observation that outlier cost-effectiveness estimates <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">&nbsp;need to be regressed to one&rsquo;s Bayesian prior</a> over the values of all possible philanthropic opportunities. Another reason for my shift is GiveWell finding that <a href=\"http://blog.givewell.org/2013/05/02/broad-market-efficiency/\">philanthropic markets are more efficient than it had previously thought</a>. &nbsp;I think that <a href=\"http://en.wikipedia.org/wiki/Optimism_bias\">optimism bias</a> also plays a role.&nbsp;</p>\n<p class=\"MsoNormal\">This is all consistent with GiveWell&rsquo;s view that <a href=\"http://blog.givewell.org/2011/06/11/why-we-should-expect-good-giving-to-be-hard/\">one should expect good giving to be hard</a>.</p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Implications for maximizing cost-effectiveness</span></strong></p>\n<p class=\"MsoNormal\">The remarks and observations above imply that <strong>Bayesian regression in the context of philanthropy is substantially larger than expected</strong>. &nbsp;This favors:</p>\n<ul>\n<li><span style=\"text-indent: -24px;\">Examining a philanthropic opportunity&nbsp;</span><a style=\"text-indent: -24px;\" href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">from many angles</a><span style=\"text-indent: -24px;\">&nbsp;rather than relying too heavily on a single perspective.<br /></span></li>\n<li><span style=\"text-indent: -24px;\"><span style=\"text-indent: -0.25in;\">Giving more weight to robust inputs into one&rsquo;s assessment of a philanthropic opportunity</span><span style=\"text-indent: -0.25in;\">. Estimating the cost-effectiveness of health interventions in the developing world has proved to be exceedingly difficult, and this pushes in favor of giving more weight to inputs for which it&rsquo;s possible to make relatively well-grounded assessments. Some of these are&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/criteria/scalability\">room for more funding</a><span style=\"text-indent: -0.25in;\">,&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/10/25/evaluating-people/\">the quality of the people behind a project</a><span style=\"text-indent: -0.25in;\">&nbsp;and&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2013/04/09/givewells-history-of-philanthropyphilanthropy-journalism-project/\">historical precedent</a><span style=\"text-indent: -0.25in;\">.</span></span><span style=\"text-indent: -0.25in;\"><br /></span></li>\n<li><span style=\"text-indent: -0.25in;\">Choosing giving opportunities that </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/12/20/more-on-the-ranking-of-our-top-charities/\">it will be possible to learn from</a><span class=\"MsoHyperlink\" style=\"text-indent: -0.25in;\">, </span><span style=\"text-indent: -0.25in;\">and </span><span class=\"MsoHyperlink\" style=\"text-indent: -0.25in;\">&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2011/12/20/give-now-or-give-later/\">giving now instead of giving later</a><span style=\"text-indent: -0.25in;\"> when one encounters such an opportunity.</span></li>\n<li><span style=\"text-indent: -0.25in;\"><span style=\"text-indent: -0.25in;\">Choosing giving opportunities </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2011/05/27/in-defense-of-the-streetlight-effect/\">about which one has a lot of information</a><span style=\"text-indent: -0.25in;\">. GiveWell has been </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2013/03/14/update-on-givewells-plans-for-2013/\">moving away from</a><span style=\"text-indent: -0.25in;\"> the old criterion of recommending proven interventions, and giving more weight to </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/01/19/trading-off-upside-vs-track-record/\">upside relative to track record</a><span style=\"text-indent: -0.25in;\"> than GiveWell used to. However, this partially reflects the discovery that the expected effectiveness of ostensibly &ldquo;proven&rdquo; interventions is lower than previously thought.&nbsp;</span></span></li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qAvbtzdG2A2RBn7in": 1, "EeSkeTcT4wtW2fWsL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rNuBzyWkigrf6BWg7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 43, "baseScore": 56, "extendedScore": null, "score": 0.000135, "legacy": true, "legacyId": "22695", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 56, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>2270</o:Words> <o:Characters>12943</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>107</o:Lines> <o:Paragraphs>30</o:Paragraphs> <o:CharactersWithSpaces>15183</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong>Note:<em>&nbsp;</em></strong>I formerly worked as a research analyst at <a href=\"http://www.givewell.org/\">GiveWell</a>. This post describes the evolution of my thinking about robustness of cost-effectiveness estimates in philanthropy. All views expressed here are my own.</p>\n<p class=\"MsoNormal\">Up until 2012, I believed that detailed explicit cost-effectiveness estimates are very important in the context of philanthropy. My position was reflected in a <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/comment-page-1/#comment-230938\">comment that I made</a> in 2011:&nbsp;</p>\n<p class=\"MsoNormal\" style=\"margin-left:.5in\">The problem with using unquantified heuristics and intuitions is that the \u201ctrue\u201d expected values of philanthropic efforts plausibly differ by many orders of magnitude, and unquantified heuristics and intuitions are frequently insensitive to this. The last order of magnitude is the only one that matters; all others are negligible by comparison. So if at all possible, one should do one\u2019s best to pin down the philanthropic efforts with the \u201ctrue\u201d expected value per dollar of the highest (positive) order of magnitude. It seems to me as though any feasible strategy for attacking this problem involves explicit computation.</p>\n<p class=\"MsoNormal\">During my time at GiveWell, my position on this matter shifted. I still believe that there are instances in which <em>rough</em> cost-effectiveness estimates can be useful for determining good philanthropic foci. But I\u2019ve shifted toward the position that <strong>effective altruists should spend much more time on qualitative analysis than on quantitative analysis in determining how they can maximize their positive social impact</strong>.</p>\n<p class=\"MsoNormal\">In this post I\u2019ll focus on one reason for my shift: <strong>explicit cost-effectiveness estimates are generally much less robust than I had previously thought</strong>.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\"><strong id=\"The_history_of_GiveWell_s_estimates_for_lives_saved_per_dollar\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">The history of GiveWell\u2019s estimates for lives saved per dollar</span></strong></p>\n<p class=\"MsoNormal\">Historically, GiveWell used \u201ccost per life saved\u201d as a measure of the cost-effectiveness of its global health recommendations. Examination of the trajectory of GiveWell\u2019s cost-effectiveness estimates shows that <strong>GiveWell has consistently updated in the direction of its ranked charities having higher \u201ccost per life saved\u201d than GiveWell had previously thought. </strong>I give the details below.</p>\n<p class=\"MsoNormal\">The discussion should be read with the understanding that <strong>donating to GiveWell\u2019s top charities has benefits that extend beyond saving lives</strong>, so that \u201cnumber of lives saved\u201d understates cost-effectiveness..</p>\n<p class=\"MsoNormal\">At the end of each of 2009 and 2010, GiveWell named <a href=\"http://www.givewell.org/international/charities/villagereach\">VillageReach</a> its #1 ranked charity. VillageReach <a href=\"http://www.givewell.org/international/top-charities/villagereach/December-2009-review#Pastcosteffectivenesspilotprogram\">estimated</a> the cost-per-life-saved of its pilot project as being &lt; $200, and at the end of 2009, GiveWell gave a \u201cconservative\u201d estimate of $545/life saved. In 2011, GiveWell <a href=\"http://blog.givewell.org/2012/07/26/rethinking-villagereachs-pilot-project/\">reassessed VillageReach\u2019s pilot project</a>, commending VillageReach for being transparent enough for reassessment to be possible, and concluding that</p>\n<p class=\"MsoNormal\" style=\"margin-left:.5in\">We feel that within the framework of \u201cdelivering proven, cost-effective interventions to improve health,\u201d AMF and SCI are solidly better giving opportunities than VillageReach (both now and at the time when we recommended it). Given the information we have, we see less room for doubt in the cases for AMF\u2019s and SCI\u2019s impact than in the case for VillageReach\u2019s.</p>\n<p class=\"MsoNormal\">Here \u201cAMF\u201d refers to <a href=\"http://www.givewell.org/international/top-charities/AMF\">Against Malaria Foundation</a>, which is GiveWell\u2019s current #1 ranked charity. If AMF is currently more cost-effective than VillageReach was at the time when GiveWell recommended VillageReach, then the best cost-per-life-saved figure for GiveWell\u2019s recommended charities is (and was) the cost-effectiveness of donating to AMF.&nbsp;</p>\n<p class=\"MsoNormal\">AMF delivers long-lasting insecticide treated nets (LLINs) to the developing world to protect people against mosquitoes that spread malaria. This contrasts with VillageReach, which works to increase vaccination rates. Vaccines are thought to be more cost-effective than LLINs, and <a href=\"http://blog.givewell.org/2013/03/21/trying-and-failing-to-find-more-funding-gaps-for-delivering-proven-cost-effective-interventions/\">GiveWell has not been able to find strong giving opportunities in vaccination</a>, so the cost per life saved of the best opportunity that GiveWell has found for individual donors is correspondingly higher.&nbsp;</p>\n<p class=\"MsoNormal\">At the end of 2011, GiveWell estimated that the marginal cost per life associated with donating to AMF at <a href=\"http://www.givewell.org/international/top-charities/AMF/2011-review#Costperlifesaved\">$1600/life saved</a>. During 2012, I vetted GiveWell\u2019s page on LLINs and <a href=\"http://blog.givewell.org/2012/10/18/revisiting-the-case-for-insecticide-treated-nets-itns/\">uncovered an issue</a>, which led GiveWell to revise its estimate for AMF\u2019s marginal cost per life saved to <a href=\"http://www.givewell.org/international/top-charities/AMF#Costperlifesaved\">$2300/life saved</a> at the end of 2012. This does not take into account <a href=\"http://www.givingwhatwecan.org/where-to-give/methodology/regression-to-the-mean\">regression to the mean</a>, which can be expected to raise the cost per life saved.&nbsp;</p>\n<p class=\"MsoNormal\">The discussion above shows a consistent trend in the direction of the marginal cost per life saved in the developing world being higher than initially meets the eye. Note that the difference between VillageReach\u2019s original estimate and GiveWell\u2019s current estimate is about an order of magnitude.&nbsp;</p>\n<p class=\"MsoNormal\"><strong id=\"Concrete_factors_that_further_reduce_the_expected_value_of_donating_to_AMF\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Concrete factors that further reduce the expected value of donating to AMF</span></strong></p>\n<p class=\"MsoNormal\">A key point that I had missed when I thought about these things earlier in my life is that <strong>there are many small probability failure modes which are not significant individually, but which collectively substantially reduce cost-effectiveness</strong>. When I encountered such a potential failure mode, my reaction was to think \u201cthis is very unlikely to be an issue\u201d and then to forget about it. I didn\u2019t notice that I was doing this many times in a row.</p>\n<p class=\"MsoNormal\">I list many relevant factors that reduce AMF\u2019s expected cost-effectiveness below. Some of these are from GiveWell\u2019s discussion of <a href=\"http://www.givewell.org/international/top-charities/AMF#Possiblenegativeoroffsettingimpact\">possible negative or offsetting impacts</a> in GiveWell\u2019s review of AMF. Others are implicitly present in GiveWell\u2019s review of AMF and<a href=\"http://www.givewell.org/international/technical/programs/insecticide-treated-nets\"> GiveWell\u2019s review of LLINs</a>, and others are issues that have emerged in the interim. I would emphasize that <strong>I don\u2019t think that any of the points listed is a big issue</strong> and that <strong>GiveWell and AMF take precautionary efforts to guard against them</strong>. But I think that they <em>collectively</em> reduce cost-effectiveness by a substantial amount.</p>\n<ul>\n<li>If GiveWell\u2019s customers weren\u2019t funding AMF, another funder might, and that funder might instead be funding much less effective activities.</li>\n<li>If AMF weren\u2019t working in a given region, there might be other organizations that would deliver LLINs to that region, and these other organizations may instead be funding much less effective activities.</li>\n<li>It could be that the workers who distribute the LLINs would otherwise be providing more cost-effective health care interventions.</li>\n<li>The five RCTs that found that LLIN distribution reduces mortality could be systematically flawed in a non-obvious way.</li>\n<li>While the Cochrane Review that contains a meta-analysis of the RCTs referred to unpublished studies so as to counteract&nbsp;<a href=\"http://blog.givewell.org/2009/01/25/publication-bias-over-reporting-good-news/\">publication bias</a>, there may be unpublished studies that were missed, and which were not published, because they found no effect.</li>\n<li>The field workers who are assigned to distribute LLINs may&nbsp;<a href=\"http://www.givewell.org/international/top-charities/amf/updates/March-2012#DistributioninNtcheudistrictofMalawi\">steal the nets to sell them for a profit</a>.</li>\n<li>Fathers&nbsp;<a href=\"http://ugandaradionetwork.com/a/story.php?s=18197\">may steal nets from pregnant mothers</a>&nbsp;and sell them for a profit.</li>\n<li>LLIN recipients may&nbsp;<a href=\"http://www.malariajournal.com/content/7/1/165\">use the nets for fishing</a>.</li>\n<li>LLIN users may not fasten LLINs properly.</li>\n<li>Mosquitoes may develop&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/21856232\">biological resistance to the insecticide used on LLINs</a>.</li>\n<li>Mosquitoes&nbsp;<a href=\"http://blog.givewell.org/2012/11/09/insecticide-resistance-and-malaria-control/\">may develop \u201cbehavioral resistance\u201d</a>&nbsp;to the insecticides used on LLINs by evolving to bite during the day (when LLINs are not used) rather than during the night.</li>\n</ul>\n<p class=\"MsoNormal\">Most of the relevant factors will vary by region where AMF ships nets, and some may be present in certain locations and not others.</p>\n<p><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Do these considerations argue against donating to AMF?</span></strong><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">&nbsp;</span></strong></p>\n<p class=\"MsoNormal\">In view of the issues above, one might wonder whether it\u2019s better to donate to a charity in a different cause, or better not to donate at all. Some relevant points follow:</p>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\">Donating to AMF has benefits beyond saving lives. </strong><span style=\"text-indent: -0.25in;\">The above discussion of cost-effectiveness figures concerns \u201ccost per life saved\u201d specifically. But there are benefits to donating to AMF that go beyond saving lives.</span></p>\n<ul>\n<li><span style=\"text-indent: -0.25in;\">Malaria control reduces the morbidity of malaria. A Cochrane Review of the&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/programs/insecticide-treated-nets#Evidencefromsmallscalehighqualitystudies\">health benefits of LLINs</a><span style=\"text-indent: -0.25in;\">&nbsp;reports on reductions in anemia, enlarged spleen, and other health outcomes.<span style=\"text-indent: -0.25in;\"><br></span></span></li>\n<li><span style=\"text-indent: -0.25in;\"><span style=\"text-indent: -0.25in;\">People are more productive when they\u2019re healthy than they are when they\u2019re ill.</span></span></li>\n<li><span style=\"text-indent: -0.25in;\">There is some evidence that malaria control&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/programs/insecticide-treated-nets#Possibledevelopmentaleffects\">increases children\u2019s income later on in life</a><span style=\"text-indent: -0.25in;\">.</span></li>\n<li><span style=\"text-indent: -0.25in;\">The above benefits could be massively leveraged via&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a><span style=\"text-indent: -0.25in;\">.</span></li>\n</ul>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\">Updates in the direction of reduced cost-effectiveness aren\u2019t specific to global health.</strong><span style=\"text-indent: -0.25in;\"> Based on my experience at GiveWell, I\u2019ve found that </span><em style=\"text-indent: -0.25in;\">regardless</em><span style=\"text-indent: -0.25in;\"> of the cause within which one investigates giving opportunities, there\u2019s a strong tendency for giving opportunities to appear progressively less promising as one learns more. AMF and LLIN distribution have stood up to scrutiny </span><em style=\"text-indent: -0.25in;\">unusually well</em><span style=\"text-indent: -0.25in;\">. It remains the case that </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2011/12/22/my-favorite-cause-for-individual-donors-global-health-and-nutrition/\">Global health and nutrition</a><span style=\"text-indent: -0.25in;\"> may be an unusually good cause for individual donors.</span></p>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\">Updates in the direction of reduced LLIN cost-effectiveness push in favor of cash transfers over LLINs. </strong><span style=\"text-indent: -0.25in;\">Transferring cash to people in the developing world is an unusually straightforward intervention. While there are </span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/programs/cash-transfers#Whatarethepotentialdownsidesoftheintervention\">potential downsides to transferring cash</a><span style=\"text-indent: -0.25in;\">, there seem to be fewer potential failure modes associated with it than there are potential failure modes associated with LLIN distribution. There are </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/05/30/giving-cash-versus-giving-bednets/\">strong arguments that favor LLINs over cash transfers</a><span style=\"text-indent: -0.25in;\">, but difference in straightforwardness of the interventions in juxtaposition with the phenomenon of surprisingly large updates in the direction of reduced cost-effectiveness is a countervailing consideration.</span></p>\n<p class=\"MsoNormal\"><strong style=\"text-indent: -0.25in;\" id=\"Why_do_cost_effectiveness_updates_skew_so_negatively_\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Why do cost-effectiveness updates skew so negatively?</span></strong></p>\n<p class=\"MsoNormal\">When I first started thinking seriously about philanthropy in 2009, I thought that if one has impressions of a philanthropic opportunity, one will be equally likely to update in the direction of it being better than meets the eye as one will be to update the direction of the opportunity being worse than meets the eye. So I was surprised to discover how strong the tendency is for philanthropic opportunities to look worse over time rather than better over time.</p>\n<p class=\"MsoNormal\">Aside from the empirical data, something that shifted my view is Holden\u2019s observation that outlier cost-effectiveness estimates <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">&nbsp;need to be regressed to one\u2019s Bayesian prior</a> over the values of all possible philanthropic opportunities. Another reason for my shift is GiveWell finding that <a href=\"http://blog.givewell.org/2013/05/02/broad-market-efficiency/\">philanthropic markets are more efficient than it had previously thought</a>. &nbsp;I think that <a href=\"http://en.wikipedia.org/wiki/Optimism_bias\">optimism bias</a> also plays a role.&nbsp;</p>\n<p class=\"MsoNormal\">This is all consistent with GiveWell\u2019s view that <a href=\"http://blog.givewell.org/2011/06/11/why-we-should-expect-good-giving-to-be-hard/\">one should expect good giving to be hard</a>.</p>\n<p class=\"MsoNormal\"><strong id=\"Implications_for_maximizing_cost_effectiveness\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Implications for maximizing cost-effectiveness</span></strong></p>\n<p class=\"MsoNormal\">The remarks and observations above imply that <strong>Bayesian regression in the context of philanthropy is substantially larger than expected</strong>. &nbsp;This favors:</p>\n<ul>\n<li><span style=\"text-indent: -24px;\">Examining a philanthropic opportunity&nbsp;</span><a style=\"text-indent: -24px;\" href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">from many angles</a><span style=\"text-indent: -24px;\">&nbsp;rather than relying too heavily on a single perspective.<br></span></li>\n<li><span style=\"text-indent: -24px;\"><span style=\"text-indent: -0.25in;\">Giving more weight to robust inputs into one\u2019s assessment of a philanthropic opportunity</span><span style=\"text-indent: -0.25in;\">. Estimating the cost-effectiveness of health interventions in the developing world has proved to be exceedingly difficult, and this pushes in favor of giving more weight to inputs for which it\u2019s possible to make relatively well-grounded assessments. Some of these are&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://www.givewell.org/international/technical/criteria/scalability\">room for more funding</a><span style=\"text-indent: -0.25in;\">,&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/10/25/evaluating-people/\">the quality of the people behind a project</a><span style=\"text-indent: -0.25in;\">&nbsp;and&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2013/04/09/givewells-history-of-philanthropyphilanthropy-journalism-project/\">historical precedent</a><span style=\"text-indent: -0.25in;\">.</span></span><span style=\"text-indent: -0.25in;\"><br></span></li>\n<li><span style=\"text-indent: -0.25in;\">Choosing giving opportunities that </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/12/20/more-on-the-ranking-of-our-top-charities/\">it will be possible to learn from</a><span class=\"MsoHyperlink\" style=\"text-indent: -0.25in;\">, </span><span style=\"text-indent: -0.25in;\">and </span><span class=\"MsoHyperlink\" style=\"text-indent: -0.25in;\">&nbsp;</span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2011/12/20/give-now-or-give-later/\">giving now instead of giving later</a><span style=\"text-indent: -0.25in;\"> when one encounters such an opportunity.</span></li>\n<li><span style=\"text-indent: -0.25in;\"><span style=\"text-indent: -0.25in;\">Choosing giving opportunities </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2011/05/27/in-defense-of-the-streetlight-effect/\">about which one has a lot of information</a><span style=\"text-indent: -0.25in;\">. GiveWell has been </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2013/03/14/update-on-givewells-plans-for-2013/\">moving away from</a><span style=\"text-indent: -0.25in;\"> the old criterion of recommending proven interventions, and giving more weight to </span><a style=\"text-indent: -0.25in;\" href=\"http://blog.givewell.org/2012/01/19/trading-off-upside-vs-track-record/\">upside relative to track record</a><span style=\"text-indent: -0.25in;\"> than GiveWell used to. However, this partially reflects the discovery that the expected effectiveness of ostensibly \u201cproven\u201d interventions is lower than previously thought.&nbsp;</span></span></li>\n</ul>", "sections": [{"title": "The history of GiveWell\u2019s estimates for lives saved per dollar", "anchor": "The_history_of_GiveWell_s_estimates_for_lives_saved_per_dollar", "level": 1}, {"title": "Concrete factors that further reduce the expected value of donating to AMF", "anchor": "Concrete_factors_that_further_reduce_the_expected_value_of_donating_to_AMF", "level": 1}, {"title": "Why do cost-effectiveness updates skew so negatively?", "anchor": "Why_do_cost_effectiveness_updates_skew_so_negatively_", "level": 1}, {"title": "Implications for maximizing cost-effectiveness", "anchor": "Implications_for_maximizing_cost_effectiveness", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "37 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-24T22:06:54.688Z", "modifiedAt": null, "url": null, "title": "Could Robots Take All Our Jobs?: A Philosophical Perspective", "slug": "could-robots-take-all-our-jobs-a-philosophical-perspective", "viewCount": null, "lastCommentedAt": "2017-06-17T04:21:33.857Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ChrisHallquist", "createdAt": "2011-05-25T19:16:15.462Z", "isAdmin": false, "displayName": "ChrisHallquist"}, "userId": "wvT2xWQqHKxkp9NWN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X7rWCw5fMRc2MetBD/could-robots-take-all-our-jobs-a-philosophical-perspective", "pageUrlRelative": "/posts/X7rWCw5fMRc2MetBD/could-robots-take-all-our-jobs-a-philosophical-perspective", "linkUrl": "https://www.lesswrong.com/posts/X7rWCw5fMRc2MetBD/could-robots-take-all-our-jobs-a-philosophical-perspective", "postedAtFormatted": "Friday, May 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Could%20Robots%20Take%20All%20Our%20Jobs%3F%3A%20A%20Philosophical%20Perspective&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACould%20Robots%20Take%20All%20Our%20Jobs%3F%3A%20A%20Philosophical%20Perspective%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX7rWCw5fMRc2MetBD%2Fcould-robots-take-all-our-jobs-a-philosophical-perspective%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Could%20Robots%20Take%20All%20Our%20Jobs%3F%3A%20A%20Philosophical%20Perspective%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX7rWCw5fMRc2MetBD%2Fcould-robots-take-all-our-jobs-a-philosophical-perspective", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX7rWCw5fMRc2MetBD%2Fcould-robots-take-all-our-jobs-a-philosophical-perspective", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 5319, "htmlBody": "<p><em>Note: The following is a draft of a paper written with an audience of philosophers in mind. It focuses on answering objections to AI likely to be made by contemporary philosophers, but it is still likely to be of interest to readers of LessWrong for obvious reasons, and I've tried to avoid assuming any specialized philosophical background.</em></p>\n<p>The title of this paper probably sounds a little strange. Philosophy is generally thought of as an armchair discipline, and the question of whether robots could take all our jobs doesn&rsquo;t seem like a question that can be settled from the armchair. But it turns out that when you look at this question, it leads you to some other questions that philosophers have had quite a bit to say about.</p>\n<p>Some of these other questions are conceptual. They seem like they could in fact be answered from the armchair. Others are empirical but very general. They seem like they require going out and looking at the world, but they&rsquo;re not about specific technologies. They&rsquo;re about how the universe works, how the mind works, or how computers work in general. It&rsquo;s been suggested that one of the distinctive things about philosophical questions is their level of generality. I don&rsquo;t know whether that&rsquo;s true, but I do know that some of these general empirical questions are ones that philosophers have had quite a bit to say about.</p>\n<p>The line of reasoning in this paper is similar to arguments discussed by Alan Turing (1950), Hubert Dreyfus (1992), and David Chalmers (2010). I won&rsquo;t say much about those discussions, though, for reasons of space and also because I&rsquo;ll frame the discussion a bit differently. I want to avoid debates about what &ldquo;intelligence&rdquo; is, what &ldquo;information processing&rdquo; is, or what it would mean to say the brain is a machine. Hence the focus on machines taking human jobs. I should mention that I&rsquo;m not the first to suggest this focus; after writing the first draft of this paper I found out that one AI researcher had already proposed replacing the &ldquo;Turing test&rdquo; with an &ldquo;employment test&rdquo; (Nilsson 2005).</p>\n<p>Here, I&rsquo;m going to assume no job has &ldquo;done by a human&rdquo; as part of its definition. I realize that in the future, there may be demand for having jobs specifically done by humans. People might want to be served by human bartenders even if robot bartenders do just as good of a job, in the same way that some people prefer handmade goods even when mass-produced ones are cheaper for the same or better quality (Doctorow 2011). But having acknowledged this issue, I&rsquo;m going to spend the rest of the paper ignoring it. &nbsp;<a id=\"more\"></a></p>\n<p>I&rsquo;ll assume, for example, that &ldquo;generated by a human&rdquo; is not part of the definition of &ldquo;mathematical proof.&rdquo; That&rsquo;s because machines replacing humans in a wide variety of roles that don&rsquo;t have &ldquo;done by a human&rdquo; as part of their definition would still be a big deal.</p>\n<h1>1. What a simulation could do</h1>\n<p>Speaking of mathematical proofs, Daniel Dennett (1981) writes:</p>\n<blockquote>\n<p>Suppose we made a computer simulation of a mathematician, and suppose it worked well. Would we complain that what we had hoped for was proofs, but alas, all we got instead was mere representations of proofs? But representations of proofs are proofs, aren&rsquo;t they? It depends on how good the proofs represented are. When cartoonists represent scientists pondering blackboards, what they typically represent as proofs of formulae on the blackboard is pure gibberish, however &ldquo;realistic&rdquo; these figures appear to the layman. If the simulation of the mathematician produced phony proofs like those in the cartoons, it might still simulate something of theoretical interest about mathematicians &ndash; their verbal mannerisms, perhaps, or their absentmindedness. &nbsp;On the other hand, if the simulation were designed to produce representations of the proofs a good mathematician would produce, it would be as valuable a &ldquo;colleague&rdquo; &ndash; in the proof producing department &ndash; as the mathematician. That is the difference it seems, between abstract, formal products like proofs or songs... and concrete, material products like milk. On which side of this divide does the mind fall? Is mentality like milk or like a song?</p>\n<p>If we think of the mind&rsquo;s product as something like control of the body, it seems its product is quite abstract.</p>\n</blockquote>\n<p>Dennett&rsquo;s point is not, as far as I can tell, very controversial. Proponents of G&ouml;delian arguments against artificial intelligence, such as John Lucas and Roger Penrose (who I&rsquo;ll talk about in a bit), might deny that it would be possible to create such a simulated mathematician. But it doesn&rsquo;t seem like they&rsquo;d deny that if you could create one, it would be able to produce real proofs and be a good &ldquo;colleague&rdquo; to a mathematician.</p>\n<p>Similarly, John Searle, who&rsquo;s known for his &ldquo;Chinese Room&rdquo; argument against AI (Searle 1980), would deny that the simulation really understands mathematics. But Searle (1997) has also written a critique of Penrose where he argued that a simulated mathematician like the one Dennett imagines &ldquo;would be able to do in practice what mathematicians do,&rdquo; perhaps producing a computer printout with proofs on it.</p>\n<p>So Dennett&rsquo;s point doesn&rsquo;t seem very controversial, but I think it&rsquo;s an important one, and it generalizes to lots of different kinds of work. For example, instead of talking about mathematicians and proofs, we could talk about academics and journal articles in general. Of course there&rsquo;d be problems with producing papers that report new empirical results, but for papers based entirely on library research (like this one), you could feed the simulation a whole library worth of digitized books and journal articles, and then it could simulate the process of a professor researching and writing an original article using that library.</p>\n<p>We can generalize even further. Today, lots of jobs involve work that is done or at least could be done entirely on a computer, and then sent to your boss or your customer over the internet. Long lists of such jobs can be found on websites like Elance.com, which allows people to hire freelancers and get work done without ever meeting them in person. And with all these jobs, it seems like, in principle at least, they could be done by a simulation analogous to Dennett&rsquo;s simulated mathematician.</p>\n<p>Now with manual labor, the problem is obviously more complicated, but it&rsquo;s also more similar to the simulated mathematician case than you might think. For many manual tasks, the hard part of replacing humans with robots is not building the robot body, but building a computer brain that responds in the right way to information it&rsquo;s getting from its sensors, its video cameras, its microphone ears. As Dennett says, control of the body seems to be an abstract product. So I think what I say in this paper could be applied to manual labor, but for simplicity I&rsquo;ll focuses on cases like the mathematician case, and focus on what computers could do rather than what robots could do. (Again, even if it only mathematicians and philosophers were be replaced by computers, this would still be significant, at least to mathematicians and philosophers.)</p>\n<p>Now once you accept that simulations could replace human workers in a wide variety of roles, the question becomes whether it&rsquo;s actually possible to create such simulations. That&rsquo;s what I&rsquo;m going to be focusing on for the rest of the paper.</p>\n<h1>2. Simulation and philosophy of mind</h1>\n<p>I want to be clear that, in this paper, when I imagine simulated workers, I&rsquo;m not making any claims about what&rsquo;s &ldquo;really&rdquo; going on with the simulation, aside from the end product. Feel free to mentally insert scare-quotes or the word &ldquo;simulated&rdquo; wherever you think it&rsquo;s necessary to resolve a problem with something I say. What matters is that you agree that for certain kinds of end products, like mathematical proofs, there&rsquo;s no distinction between a simulated version and the real thing. Everything else is irrelevant for my purposes.</p>\n<p>In particular, I&rsquo;m not saying anything about mental states like beliefs. That means that criticisms of &ldquo;functionalism&rdquo; or &ldquo;the computational theory of mind&rdquo; don&rsquo;t matter here, because those terms typically refer to views about mental states (Levin 2010, Horst 2011).</p>\n<p>But some other major ideas in philosophy of mind do matter here. One is physicalism, the view that everything is physical. Another is epiphenomenal dualism, which allows for things that aren&rsquo;t physical but says they have no effect on the physical. This is roughly the view of David Chalmers (1996)--Chalmers quibbles a bit about terminology, but he&rsquo;s at least close enough to being an epiphenomalist that we can treat him as one here.&nbsp;</p>\n<p>A third position we&rsquo;ll need to deal with here is interactionist dualism, which allows for things that aren&rsquo;t physical and have an effect on the physical. Rene Descartes, who thought that the soul influences the body through the pineal gland, is probably the most famous example. A more recent example is neuroscientist John Eccles, who proposed a theory of the mind involving what he called &ldquo;psychons&rdquo; in the 90s.</p>\n<p>Though I don&rsquo;t hear it put this way very often, I think modern physicalists and epiphenomenalists would agree with the following claim, which I&rsquo;ll call bottom-up predictability: if you know the initial states of the lowest-level parts of a physical system, along with the lowest-level laws that apply to those parts, then in principle you&rsquo;ll be able to predict the behavior of that system, whether or not it&rsquo;s practical to do so. Even if the laws aren&rsquo;t deterministic, they&rsquo;ll at least tell you the probability of the system behaving in different ways.</p>\n<p>One way that this claim could be false, of course, is if souls or psychons or whatever could come in and affect the behavior of physical systems. Another way it could be false is if there were certain laws that affect the behavior of the low-level components only when they are part of some larger whole. For example, there might be a law that says when hydrogen and oxygen atoms are put together into water molecules, they behave in a certain way, and the way they behave when they&rsquo;re put together into water molecules is actually different than you&rsquo;d expect from knowing just the laws that apply to all atoms all the time.</p>\n<p>This second way of rejecting bottom-up predictability shows up in C. D. Broad&rsquo;s book The Mind and its Place in Nature, which was published in 1925. Within just a couple years of that book&rsquo;s publication, though, physicists started giving accounts of chemical phenomena in quantum mechanical terms. And our ability to confirm that molecules behave as the laws of quantum mechanics would predict has increased over time, as computers have gotten more powerful and approximation techniques have improved.</p>\n<p>We don&rsquo;t have the computing power to rigorously check bottom-up predictability for larger systems like cells, much less entire organisms, but the scientists I&rsquo;ve heard talk about this issue seem quite confident in the idea. As someone who came very close to getting a degree in neuroscience before deciding to become a philosopher, I can say that it seems to be the working assumption of molecular biology and neuroscience, and personally I&rsquo;m confident that this assumption is just going to just continue to be confirmed. (I don&rsquo;t have a general philosophical argument here; I&rsquo;m just going by sum of what I know about of physics, chemistry, molecular biology, and neuroscience.)</p>\n<p>Now I said that I&rsquo;m not saying anything about mental states. Another thing I&rsquo;ve tried to avoid saying anything about is the exact relationship between the low-level physical laws and higher-level laws and phenomena. There are philosophers who call themselves &ldquo;non-reductive physicalists&rdquo; or &ldquo;non-reductive materialists&rdquo; who might deny that the low-level physical law fully explain the higher-level stuff, but don&rsquo;t, if I understand them correctly, mean to deny bottom-up predictability.</p>\n<p>For example, Hilary Putnam (1980) has a paper where he asks how we might explain the fact that a particular square peg fits in a square hole, but not a round one. He argues that even if you could compute all possible trajectories of the peg through the holes and deduce from just the laws of quantum mechanics that the square peg will never pass through the round hole, that deduction wouldn't be an explanation of why the peg won't fit.&nbsp;</p>\n<p>What counts as an explanation doesn&rsquo;t matter here, though. All that matters is whether you could, in principle, use the low-level physical laws (like quantum mechanics) to make predictions in the way Putnam talks about. And Putnam&rsquo;s non-reductive materialism isn&rsquo;t about denying you could do that. It isn&rsquo;t about denying bottom-up predictability. As far as I can tell, very few people today are going to deny bottom-up predictability, unless they&rsquo;re interactionist dualists.</p>\n<p>The significance of bottom-up predictability is that if it&rsquo;s true, and if the lowest-level physical laws allow any physical system to be simulated (at least in principle), then human brains and human bodies can be simulated (at least in principle), and a wide variety of human workers can be replaced by simulations (at least in principle). From what I understand, it does seem like the laws of physics allow physical systems in general to be simulated (at least in principle). I don&rsquo;t know if anyone knows for sure whether that&rsquo;s true, but it would be important if it were true.</p>\n<p>I keep having to say &ldquo;in principle&rdquo; here because even if in principle you could use quantum mechanics to predict people&rsquo;s behavior or at least get a good idea of the probabilities, the amount of computing power you&rsquo;d need would so ridiculously huge that doing that would probably never become practical. The idea of simulating an entire mathematician at the quantum-mechanical level is just a thought-experiment.&nbsp;</p>\n<p>Near the end, I&rsquo;ll talk about what might be more realistic ways to simulate a mathematician. But first I want to talk about two important arguments which both suggest that doing that might be impossible even in principle.</p>\n<h1>3. G&ouml;delian arguments against AI</h1>\n<p><span style=\"white-space:pre\"> </span>In 1936, mathematician Alan Turing described a certain kind of theoretical machine called a Turing machine, which can be thought of as a theoretical model for a programmable digital computer. (That&rsquo;s anachronistic, because Turing&rsquo;s paper came before modern digital computers, but that&rsquo;s probably the easiest way to explain the idea to a modern audience.)&nbsp;</p>\n<p>Turing proved that some Turing machines can can act as universal Turing machines, meaning that with the right program they can simulate any other Turing machine, which amounts to being able to do anything any Turing machine can do. (Notice the parallel to the worker-simulation thought-experiment.)</p>\n<p>The fact that a universal Turing machine can do anything any Turing machine can do helps explain why modern computers are so wonderfully flexible. Note, however, that when we talk about what Turing machines can do, generally we&rsquo;re only saying what they can do in some arbitrary but finite amount of time, not what they can do in a reasonable amount of time. So there are some things that modern computers can&rsquo;t do because they aren&rsquo;t fast enough. And again, you need the right program, and in some cases we haven&rsquo;t solved the programming problem.</p>\n<p>Furthermore, there are some limitations to what Turing machines can do even in principle. &ldquo;In principle&rdquo; here means &ldquo;with some finite amount of time and the right program.&rdquo; G&ouml;del's theorem shows that for any consistent formal system as powerful as basic arithmetic, there will always be some statement that can&rsquo;t be proven in the system. Since Turing machines are logically equivalent to formal systems, this limitation applies to Turing machines as well. This leads to the argument that the human mind doesn&rsquo;t have this limitation and therefore can&rsquo;t be a Turing machine.</p>\n<p>Turing (1950) considered and rejected this argument in his paper &ldquo;Computing Machinery and Intelligence,&rdquo; which is famous for having proposed the &ldquo;Turing test&rdquo; of whether a particular machine can think. Turing called this argument &ldquo;the mathematical objection.&rdquo; Later, John Lucas (1961) defended the argument in a paper where he wrote:</p>\n<blockquote>\n<p>G&ouml;del's theorem must apply to cybernetical machines, because it is of the essence of being a machine, that it should be a concrete instantiation of a formal system. It follows that given any machine which is consistent and capable of doing simple arithmetic, there is a formula which it is incapable of producing as being true---i.e., the formula is unprovable-in-the-system-but which we can see to be true. It follows that no machine can be a complete or adequate model of the mind, that minds are essentially different from machines.</p>\n</blockquote>\n<p>This argument makes a number of assumptions. Since G&ouml;del's theorem only applies to consistent formal systems, we must assume that if the mind is a formal system, it is &nbsp;consistent. Also, since different formal systems have different statements which they can&rsquo;t prove, it isn&rsquo;t enough to to say we can see the truth of some statements that certain formal systems can&rsquo;t prove. It has to be the case that for any formal system, we will be able to see the truth of at least one statement the system can&rsquo;t prove. Finally, Lucas implicitly assumes that if the mind is a formal systems, then our &ldquo;seeing&rdquo; a statement to be true involves the statement being proved in that formal system.</p>\n<p>These assumptions can all be challenged, and Lucas responds to some of the possible challenges. In particular, he spends quite a bit of time arguing that the fact that humans make mistakes does not mean we could be represented by an inconsistent formal system.</p>\n<p>After Lucas&rsquo; original article, similar arguments against the possibility of AI were defended by Roger Penrose in his books The Emperor&rsquo;s New Mind and Shadows of the Mind, and also in a response to critics published in the online journal Psyche.</p>\n<p>Many of the criticisms of Penrose published in Psyche are worth reading, particularly the one by Chalmers (1995). But I&rsquo;m not going to recap the entire debate because I don&rsquo;t have much to say about it that hasn&rsquo;t already been said. Instead, I&rsquo;m just going to comment on one thing Penrose does in his reply in Psyche (Penrose 1996).</p>\n<p>Penrose emphasizes that he&rsquo;s interested in whether there could ever be a formal system that, &ldquo;encapsulates all the humanly accessible methods of mathematical proof.&rdquo; In response to the point that humans make mistakes, he says:</p>\n<blockquote>\n<p>I fully accept that individual mathematicians can frequently make errors, as do human beings in many other activities of their lives. This is not the point. Mathematical errors are in principle correctable, and I was concerned mainly with the ideal of what can indeed be perceived in principle by mathematical understanding and insight... The arguments given above... were also concerned with this ideal notion only. The position that I have been strongly arguing for is that this ideal notion of human mathematical understanding is something beyond computation.</p>\n</blockquote>\n<p>Even if Penrose were right about this, it&rsquo;s not clear that this would mean that simulation of individual humans is impossible. A simulation doesn&rsquo;t have to claim to encapsulate &ldquo;all the humanly accessible methods of mathematical proof&rdquo;; it just needs to be a good simulation of an individual mathematician. It doesn&rsquo;t even need to say anything directly about mathematics. To use the implausible thought-experiment, it might only talk about the subatomic particles that make up the mathematician.</p>\n<p>This is John Searle&rsquo;s (1997) response to Penrose, except that instead of subatomic particles, Searle imagines that the simulation would refer to things like neurotransmitters and synaptic clefts and cell assemblies, which is probably a more realistic assumption. (Again, more on the more realistic assumptions later.)</p>\n<h1>4. Could the brain be a hypercomputer?</h1>\n<p>Another line of thought that&rsquo;s somewhat similar to G&ouml;delian arguments against AI comes from the philosophers Diane Proudfoot and Jack Copeland, who in 1999 coined the term &ldquo;hypercomputation&rdquo; to refer to the idea that it might be possible to build a machine that&rsquo;s similar to a modern computer but which can do things no Turing machine can do (Copeland 2000).&nbsp;</p>\n<p>In a sense, we already know how to build some kinds of machines like this. Strictly speaking, Turing machines are defined to be deterministic; there&rsquo;s no random element. But if you wanted to, you could build a device that generates truly random numbers by measuring the decay of a nuclear isotope, and then have a computer use the measurement in calculations. You could get a similar effect with a device that measures atmospheric noise (which is the method used by the website Random.org).</p>\n<p>There are some situations where a random element like that might be useful, mainly because you want to keep other people from predicting how exactly your computer will behave (think slot machines or generating encryption keys). For the same reason, it wouldn&rsquo;t be surprising if humans and other animals had evolved to have a random element in their behavior.</p>\n<p>But as Turing himself pointed out, it&rsquo;s possible to write a program that isn&rsquo;t really random but merely appears random (Copeland 2000). Today, such programs are known as pseudo-random number generators and many programming languages have one built in. If you&rsquo;re just learning programming, one exercise worth trying is to write a program that somehow uses the random number generator, like a simulated dice roller. Its behavior should appear random the first time you run the program, but depending on how you&rsquo;ve written it, it may do exactly the same thing the second time your run it.</p>\n<p>There are some well-known arguments from neuroscience that are supposed to show individual quantum events can&rsquo;t play much of a role in the brain (Tegmark 2000), so it may be that human behavior has evolved to sometimes appear partly random using something like a pseudo-random number generator rather than genuine quantum randomness. In any case, the point is that even if human behavior included a genuinely random element--or even a non-deterministic form of free will that looks random from the outside, if you believe in such things--the point is we already know how to build machines that can simulate that.</p>\n<p>Some things, however, can&rsquo;t be done by any machine we know how to build. Famously, the formal definition of a Turing machine allows the machine to sometimes &ldquo;halt,&rdquo; and there&rsquo;s no way to make a Turing machine that will look at a program for simulating any other Turing machine and determine whether the other machine will halt. This is known as the halting problem, and we don&rsquo;t know how to build any machine that could solve it. And it&rsquo;s this sense of hypercomputation, of machines with abilities beyond those of any machines we know how to build, that&rsquo;s most interesting.</p>\n<p>Unlike Penrose, Proudfoot and Copeland don&rsquo;t claim to know that the brain does anything Turing machine&rsquo;s can&rsquo;t, but Copeland (2000) treats this as an important possibility, and they&rsquo;ve claimed as recently as last year that &ldquo;it remains unknown, however, whether hypercomputation is permitted or excluded by real-world physics&rdquo; (Proudfoot and Copeland 2012). So they&rsquo;re claiming it might be true that computers as we know them today are in principle incapable of simulating a human, but they&rsquo;re not claiming that&rsquo;s definitely true. They don&rsquo;t think we know.&nbsp;</p>\n<p>They do, however, assume that whatever humans do, we do through physical means, which means that if humans do hypercomputation, then it should also be possible to build a physical device that does hypercomputation. Of course, since we have no idea how to do that right now, humans doing hypercomputation would put full simulation of human beings a lot further off into the future.</p>\n<p>While I don&rsquo;t know of any arguments that show that our current understanding of physics totally rules out hypercomputation, there seems to be a tendency for proposals for hypercomputation to rely on implausible physical assumptions, especially when applied to the brain. For example, if you could somehow get access to infinite time, you could find out if any Turing machine halts by running it for an infinite length of time and seeing what happens. It&rsquo;s been suggested that the theory of relativity could allow spacetime to be bent in a way that gives you the necessary infinite time (Ord 2006). Whether or not that&rsquo;s actually possible, though, it seems unlikely that our brains bend spacetime in that way.</p>\n<p>Similarly, there are some theoretical proposals for how an analog computer (as opposed to a digital computer, which is what modern computers are) might be able to do things like solve the halting problem, and it&rsquo;s sometimes suggested that since the brain is analog, maybe the brain can do things like solve the halting problem. But these proposals tend to assume a device with unlimited precision (Cotogno 2003, Davis 2004, Ord 2006). It&rsquo;s not clear that it&rsquo;s physically possible to build a device with unlimited precision, and there&rsquo;s good reason to think the brain&rsquo;s precision is limited. Chris Eliasmith (2001) cites an estimate that &ldquo;neurons tend to encode approximately 3-7 bits of information per spike,&rdquo; which is less than a single byte.</p>\n<h1>5. Hardware and software issues</h1>\n<p>I&rsquo;ve been arguing that it&rsquo;s probably possible, in principle, to simulate mathematicians and philosophers and so on using the kinds of devices we already know how to build. Again, by &ldquo;in principle&rdquo; I mean not ruled out by the kind of philosophical and mathematical objections I&rsquo;ve been talking about; possible with enough time and storage and with the right program. Since in the real world, it&rsquo;s easier to design faster hardware than it is to design more time, it&rsquo;s helpful to rephrase what I just said as, &ldquo;what computers can do with powerful enough hardware and the right software.&rdquo;</p>\n<p>Maybe you think the hardware and software issues with AI were the real issues all along. However, if on the one hand you think we&rsquo;ll never replace human mathematicians with computers, but on the other hand you don&rsquo;t think that because of any in principle objection like some version of the G&ouml;delian argument, it&rsquo;s worth being clear about that.</p>\n<p>It&rsquo;s less clear what philosophers can say about hardware and software issues, but I&rsquo;ll mention a few things. As I&rsquo;ve said, simulating a human being at the level of subatomic particles is unlikely to ever be practical, but it&rsquo;s also unlikely to ever be necessary. As I&rsquo;ve also noted, individual quantum events probably don&rsquo;t play an important role in the brain. The behavior of any individual molecule or ion is also unlikely to matter; events in the brain generally involve too many molecules and ions for the behavior of any one of them to matter.</p>\n<p>So there&rsquo;s a limit to how much detail a simulation of an actual brain would need. Where exactly that limit is is unclear; Anders Sandberg and Nick Bostrom (2008) have a paper where they list some possibilities. This approach to simulation would require a simulated body and simulated environment, but level of detail required for those would probably be much less than the level of detail required for the brain. Also, for the purposes of replacing particular human workers with computer programs, it wouldn&rsquo;t be necessary to simulate the inner workings of the brain closely at all. What matters is simulating the outward behavior, and maybe you could do that through something like machine learning algorithms trained on actual human behavior.</p>\n<p>So the hardware requirements for a mathematician simulation wouldn&rsquo;t be quite as large as it might have seemed, but they could still be very large. So can we meet them? The rapid improvements in hardware that we&rsquo;re all used to by now have relied on making transistors smaller and smaller, but we&rsquo;ll reach a point where the size of transistors is measured in atoms and we can&rsquo;t do that anymore. There are some suggestions for how we might continue making improvements in computer hardware even after we reach that point (Sandberg and Bostrom 2008), but I&rsquo;m not the right person to evaluate them.</p>\n<p>Even if we develop powerful enough hardware and the software is out there somewhere in the space of all possible software, maybe we&rsquo;ll never find the software because searching that space of possible software will turn out to be too hard. One thing to say about this is that people in robotics and AI have realized that it&rsquo;s easy to for computers to beat humans at things we didn&rsquo;t evolve to do, like arithmetic, but hard for computers to beat humans at things we did evolve to do, like walking upright (Moravec 1988, Pinker 1997).&nbsp;</p>\n<p>That suggests getting computers to do everything humans do is going to be difficult, but at least there&rsquo;s a non-mysterious reason for the difficulty (because humans have evolved over millions of years to be really good at certain things without even realizing how good we are). It also suggests that there&rsquo;s a limit to how hard getting computers to do everything humans do can be, because evolution produced humans just by going at the blind process of natural selection for a long enough period of time.</p>\n<p>However, there is the possibility that humans are a fluke. Maybe you only get something like human brains once for every million or more planets where something like mammal brains have already developed. So maybe building things like humans is harder than a first-glance evolutionary argument would suggest. Nick Bostrom has a paper discussing that issue in greater depth (Shulman and Bostrom 2012).</p>\n<p>Finally, I&rsquo;ve focused on the ability of computers to take over human jobs, but that shouldn&rsquo;t be interpreted as a claim that that&rsquo;s going to be the most important effect of advances in AI. If computers become able to take over the vast majority of human jobs, there may be much bigger consequences than just unemployment (Hanson 2008, Muehlhauser and Salamon forthcoming). But that&rsquo;s a topic for another day.</p>\n<h1>Bibliography</h1>\n<p>Chalmers, D. (1995). &ldquo;Minds, Machines, and Mathematics.&rdquo; Psyche, 2: 11-20.&nbsp;</p>\n<p>---- (1996). The Conscious Mind: In Search of a Fundamental Theory. Oxford University Press.</p>\n<p>---- (2010). &ldquo;The Singularity: A Philosophical Analysis.&rdquo; Journal of Consciousness Studies, 17: 7-65.</p>\n<p>Copeland, B. J. (2000). &ldquo;Narrow Versus Wide Mechanism.&rdquo; Journal of Philosophy, 96: 5-32.</p>\n<p>Cotogno, P. (2003). \"Hypercomputation and the Physical Church-Turing Thesis,\" British Journal for the Philosophy of Science, 54 (2): 181-224.</p>\n<p>Davis, M. (2004). &ldquo;The Myth of Hypercomputation.&rdquo; in C. Teuscher (ed.) Alan Turing: Life and legacy of a great thinker. Springer, 195-212.</p>\n<p>Dennett, D. (1981). &ldquo;Reflections,&rdquo; in D. Hofstadter and D. Dennett, The Mind&rsquo;s I: Fantasies and Reflections on Self and Soul. Bantam Books, 92-95.</p>\n<p>Doctorow, C. (2011). &ldquo;Untouched By Human Hands.&rdquo; MAKE, 25: 16.</p>\n<p>Dreyfus, H. (1992). What Computers Still Can&rsquo;t Do: A Critique of Artificial Reason. MIT Press.</p>\n<p>Eliasmith, C. (2001). &ldquo;Attractive and in-discrete: A critique of two putative virtues of the dynamicist theory of mind.&rdquo; Minds and Machines, 11: 417-426.</p>\n<p>Hanson, R. (2008). &ldquo;Economics of the Singularity.&rdquo; Spectrum, IEEE, 45 (6): 45-50.</p>\n<p>Horst, S. (2011). &ldquo;The Computational Theory of Mind&rdquo;, in E. N. Zalta (ed.) The Stanford Encyclopedia of Philosophy (Spring 2011 Edition). URL: http://plato.stanford.edu/archives/sum2010/entries/functionalism/.</p>\n<p>Levin, J. (2010). &ldquo;Functionalism&rdquo;, in E. N. Zalta (ed.) The Stanford Encyclopedia of Philosophy (Summer 2010 Edition). URL: http://plato.stanford.edu/archives/sum2010/entries/functionalism/.</p>\n<p>Lucas, J. (1961). &ldquo;Minds, Machines, and G&ouml;del.&rdquo; Philosophy, 36: 112-127.</p>\n<p>Moravec, H. (1988). Mind Children: The Future of Robot and Human Intelligence. Harvard University Press.&nbsp;</p>\n<p>Muehlhauser, L. and A. Salamon. (forthcoming). In A. Eden, J. S&oslash;raker, J. H. Moor, and E. Steinhart (ed.) Singularity Hypotheses: A scientific and philosophical assessment. Springer.</p>\n<p>Nilsson, N. (2005). &ldquo;Human-Level Artificial Intelligence? Be Serious!&rdquo;&nbsp;</p>\n<p>Ord, T. (2006). &ldquo;The Many Forms of Hypercomputation.&rdquo; Applied Mathematics and Computation, 178: 143-153.</p>\n<p>Penrose, R. (1996). &ldquo;Beyond the Doubting of a Shadow.&rdquo; Psyche 2.</p>\n<p>Pinker, S. (1997). How the Mind Works. W. W. Norton &amp; Company.</p>\n<p>Proudfoot, D. and B. J. Copeland. (2012). &ldquo;Artificial Intelligence,&rdquo; in E. Margolis, R. Samuels, and S. Stich (ed.) The Oxford Handbook of Philosophy of Cognitive Science. Oxford University Press.</p>\n<p>Putnam, H. (1980). &ldquo;Philosophy and our mental life&rdquo;, in Ned Block (ed.) Readings in the Philosophy of Psychology, Volume 1, 134-143.</p>\n<p>Sandberg, A. and N. Bostrom. (2008). Whole Brain Emulation: A Roadmap, Technical Report #2008\u20103, Future of Humanity Institute, Oxford University.</p>\n<p>Searle, J. (1980). &ldquo;Minds, Brains, and Programs.&rdquo; Behavioral and Brain Sciences, 3 (3): 433-460.</p>\n<p>---- (1997). The Mystery of Consciousness. The New York Review of Books.</p>\n<p>Shulman, C. and N. Bostrom. (2012). &ldquo;How Hard is Artificial Intelligence? Evolutionary Arguments and Selection Effects.&rdquo; Journal of Consciousness Studies, 19: 103-130.</p>\n<p>Tegmark, M. (2000). \"Importance of quantum decoherence in brain processes.\" Physical Review E, 61 (4): 4194&ndash;4206.</p>\n<p>Turing, A. (1950). &ldquo;Computing Machinery and Intelligence.&rdquo; Mind, 49: 433-460.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X7rWCw5fMRc2MetBD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 3, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "22709", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>Note: The following is a draft of a paper written with an audience of philosophers in mind. It focuses on answering objections to AI likely to be made by contemporary philosophers, but it is still likely to be of interest to readers of LessWrong for obvious reasons, and I've tried to avoid assuming any specialized philosophical background.</em></p>\n<p>The title of this paper probably sounds a little strange. Philosophy is generally thought of as an armchair discipline, and the question of whether robots could take all our jobs doesn\u2019t seem like a question that can be settled from the armchair. But it turns out that when you look at this question, it leads you to some other questions that philosophers have had quite a bit to say about.</p>\n<p>Some of these other questions are conceptual. They seem like they could in fact be answered from the armchair. Others are empirical but very general. They seem like they require going out and looking at the world, but they\u2019re not about specific technologies. They\u2019re about how the universe works, how the mind works, or how computers work in general. It\u2019s been suggested that one of the distinctive things about philosophical questions is their level of generality. I don\u2019t know whether that\u2019s true, but I do know that some of these general empirical questions are ones that philosophers have had quite a bit to say about.</p>\n<p>The line of reasoning in this paper is similar to arguments discussed by Alan Turing (1950), Hubert Dreyfus (1992), and David Chalmers (2010). I won\u2019t say much about those discussions, though, for reasons of space and also because I\u2019ll frame the discussion a bit differently. I want to avoid debates about what \u201cintelligence\u201d is, what \u201cinformation processing\u201d is, or what it would mean to say the brain is a machine. Hence the focus on machines taking human jobs. I should mention that I\u2019m not the first to suggest this focus; after writing the first draft of this paper I found out that one AI researcher had already proposed replacing the \u201cTuring test\u201d with an \u201cemployment test\u201d (Nilsson 2005).</p>\n<p>Here, I\u2019m going to assume no job has \u201cdone by a human\u201d as part of its definition. I realize that in the future, there may be demand for having jobs specifically done by humans. People might want to be served by human bartenders even if robot bartenders do just as good of a job, in the same way that some people prefer handmade goods even when mass-produced ones are cheaper for the same or better quality (Doctorow 2011). But having acknowledged this issue, I\u2019m going to spend the rest of the paper ignoring it. &nbsp;<a id=\"more\"></a></p>\n<p>I\u2019ll assume, for example, that \u201cgenerated by a human\u201d is not part of the definition of \u201cmathematical proof.\u201d That\u2019s because machines replacing humans in a wide variety of roles that don\u2019t have \u201cdone by a human\u201d as part of their definition would still be a big deal.</p>\n<h1 id=\"1__What_a_simulation_could_do\">1. What a simulation could do</h1>\n<p>Speaking of mathematical proofs, Daniel Dennett (1981) writes:</p>\n<blockquote>\n<p>Suppose we made a computer simulation of a mathematician, and suppose it worked well. Would we complain that what we had hoped for was proofs, but alas, all we got instead was mere representations of proofs? But representations of proofs are proofs, aren\u2019t they? It depends on how good the proofs represented are. When cartoonists represent scientists pondering blackboards, what they typically represent as proofs of formulae on the blackboard is pure gibberish, however \u201crealistic\u201d these figures appear to the layman. If the simulation of the mathematician produced phony proofs like those in the cartoons, it might still simulate something of theoretical interest about mathematicians \u2013 their verbal mannerisms, perhaps, or their absentmindedness. &nbsp;On the other hand, if the simulation were designed to produce representations of the proofs a good mathematician would produce, it would be as valuable a \u201ccolleague\u201d \u2013 in the proof producing department \u2013 as the mathematician. That is the difference it seems, between abstract, formal products like proofs or songs... and concrete, material products like milk. On which side of this divide does the mind fall? Is mentality like milk or like a song?</p>\n<p>If we think of the mind\u2019s product as something like control of the body, it seems its product is quite abstract.</p>\n</blockquote>\n<p>Dennett\u2019s point is not, as far as I can tell, very controversial. Proponents of G\u00f6delian arguments against artificial intelligence, such as John Lucas and Roger Penrose (who I\u2019ll talk about in a bit), might deny that it would be possible to create such a simulated mathematician. But it doesn\u2019t seem like they\u2019d deny that if you could create one, it would be able to produce real proofs and be a good \u201ccolleague\u201d to a mathematician.</p>\n<p>Similarly, John Searle, who\u2019s known for his \u201cChinese Room\u201d argument against AI (Searle 1980), would deny that the simulation really understands mathematics. But Searle (1997) has also written a critique of Penrose where he argued that a simulated mathematician like the one Dennett imagines \u201cwould be able to do in practice what mathematicians do,\u201d perhaps producing a computer printout with proofs on it.</p>\n<p>So Dennett\u2019s point doesn\u2019t seem very controversial, but I think it\u2019s an important one, and it generalizes to lots of different kinds of work. For example, instead of talking about mathematicians and proofs, we could talk about academics and journal articles in general. Of course there\u2019d be problems with producing papers that report new empirical results, but for papers based entirely on library research (like this one), you could feed the simulation a whole library worth of digitized books and journal articles, and then it could simulate the process of a professor researching and writing an original article using that library.</p>\n<p>We can generalize even further. Today, lots of jobs involve work that is done or at least could be done entirely on a computer, and then sent to your boss or your customer over the internet. Long lists of such jobs can be found on websites like Elance.com, which allows people to hire freelancers and get work done without ever meeting them in person. And with all these jobs, it seems like, in principle at least, they could be done by a simulation analogous to Dennett\u2019s simulated mathematician.</p>\n<p>Now with manual labor, the problem is obviously more complicated, but it\u2019s also more similar to the simulated mathematician case than you might think. For many manual tasks, the hard part of replacing humans with robots is not building the robot body, but building a computer brain that responds in the right way to information it\u2019s getting from its sensors, its video cameras, its microphone ears. As Dennett says, control of the body seems to be an abstract product. So I think what I say in this paper could be applied to manual labor, but for simplicity I\u2019ll focuses on cases like the mathematician case, and focus on what computers could do rather than what robots could do. (Again, even if it only mathematicians and philosophers were be replaced by computers, this would still be significant, at least to mathematicians and philosophers.)</p>\n<p>Now once you accept that simulations could replace human workers in a wide variety of roles, the question becomes whether it\u2019s actually possible to create such simulations. That\u2019s what I\u2019m going to be focusing on for the rest of the paper.</p>\n<h1 id=\"2__Simulation_and_philosophy_of_mind\">2. Simulation and philosophy of mind</h1>\n<p>I want to be clear that, in this paper, when I imagine simulated workers, I\u2019m not making any claims about what\u2019s \u201creally\u201d going on with the simulation, aside from the end product. Feel free to mentally insert scare-quotes or the word \u201csimulated\u201d wherever you think it\u2019s necessary to resolve a problem with something I say. What matters is that you agree that for certain kinds of end products, like mathematical proofs, there\u2019s no distinction between a simulated version and the real thing. Everything else is irrelevant for my purposes.</p>\n<p>In particular, I\u2019m not saying anything about mental states like beliefs. That means that criticisms of \u201cfunctionalism\u201d or \u201cthe computational theory of mind\u201d don\u2019t matter here, because those terms typically refer to views about mental states (Levin 2010, Horst 2011).</p>\n<p>But some other major ideas in philosophy of mind do matter here. One is physicalism, the view that everything is physical. Another is epiphenomenal dualism, which allows for things that aren\u2019t physical but says they have no effect on the physical. This is roughly the view of David Chalmers (1996)--Chalmers quibbles a bit about terminology, but he\u2019s at least close enough to being an epiphenomalist that we can treat him as one here.&nbsp;</p>\n<p>A third position we\u2019ll need to deal with here is interactionist dualism, which allows for things that aren\u2019t physical and have an effect on the physical. Rene Descartes, who thought that the soul influences the body through the pineal gland, is probably the most famous example. A more recent example is neuroscientist John Eccles, who proposed a theory of the mind involving what he called \u201cpsychons\u201d in the 90s.</p>\n<p>Though I don\u2019t hear it put this way very often, I think modern physicalists and epiphenomenalists would agree with the following claim, which I\u2019ll call bottom-up predictability: if you know the initial states of the lowest-level parts of a physical system, along with the lowest-level laws that apply to those parts, then in principle you\u2019ll be able to predict the behavior of that system, whether or not it\u2019s practical to do so. Even if the laws aren\u2019t deterministic, they\u2019ll at least tell you the probability of the system behaving in different ways.</p>\n<p>One way that this claim could be false, of course, is if souls or psychons or whatever could come in and affect the behavior of physical systems. Another way it could be false is if there were certain laws that affect the behavior of the low-level components only when they are part of some larger whole. For example, there might be a law that says when hydrogen and oxygen atoms are put together into water molecules, they behave in a certain way, and the way they behave when they\u2019re put together into water molecules is actually different than you\u2019d expect from knowing just the laws that apply to all atoms all the time.</p>\n<p>This second way of rejecting bottom-up predictability shows up in C. D. Broad\u2019s book The Mind and its Place in Nature, which was published in 1925. Within just a couple years of that book\u2019s publication, though, physicists started giving accounts of chemical phenomena in quantum mechanical terms. And our ability to confirm that molecules behave as the laws of quantum mechanics would predict has increased over time, as computers have gotten more powerful and approximation techniques have improved.</p>\n<p>We don\u2019t have the computing power to rigorously check bottom-up predictability for larger systems like cells, much less entire organisms, but the scientists I\u2019ve heard talk about this issue seem quite confident in the idea. As someone who came very close to getting a degree in neuroscience before deciding to become a philosopher, I can say that it seems to be the working assumption of molecular biology and neuroscience, and personally I\u2019m confident that this assumption is just going to just continue to be confirmed. (I don\u2019t have a general philosophical argument here; I\u2019m just going by sum of what I know about of physics, chemistry, molecular biology, and neuroscience.)</p>\n<p>Now I said that I\u2019m not saying anything about mental states. Another thing I\u2019ve tried to avoid saying anything about is the exact relationship between the low-level physical laws and higher-level laws and phenomena. There are philosophers who call themselves \u201cnon-reductive physicalists\u201d or \u201cnon-reductive materialists\u201d who might deny that the low-level physical law fully explain the higher-level stuff, but don\u2019t, if I understand them correctly, mean to deny bottom-up predictability.</p>\n<p>For example, Hilary Putnam (1980) has a paper where he asks how we might explain the fact that a particular square peg fits in a square hole, but not a round one. He argues that even if you could compute all possible trajectories of the peg through the holes and deduce from just the laws of quantum mechanics that the square peg will never pass through the round hole, that deduction wouldn't be an explanation of why the peg won't fit.&nbsp;</p>\n<p>What counts as an explanation doesn\u2019t matter here, though. All that matters is whether you could, in principle, use the low-level physical laws (like quantum mechanics) to make predictions in the way Putnam talks about. And Putnam\u2019s non-reductive materialism isn\u2019t about denying you could do that. It isn\u2019t about denying bottom-up predictability. As far as I can tell, very few people today are going to deny bottom-up predictability, unless they\u2019re interactionist dualists.</p>\n<p>The significance of bottom-up predictability is that if it\u2019s true, and if the lowest-level physical laws allow any physical system to be simulated (at least in principle), then human brains and human bodies can be simulated (at least in principle), and a wide variety of human workers can be replaced by simulations (at least in principle). From what I understand, it does seem like the laws of physics allow physical systems in general to be simulated (at least in principle). I don\u2019t know if anyone knows for sure whether that\u2019s true, but it would be important if it were true.</p>\n<p>I keep having to say \u201cin principle\u201d here because even if in principle you could use quantum mechanics to predict people\u2019s behavior or at least get a good idea of the probabilities, the amount of computing power you\u2019d need would so ridiculously huge that doing that would probably never become practical. The idea of simulating an entire mathematician at the quantum-mechanical level is just a thought-experiment.&nbsp;</p>\n<p>Near the end, I\u2019ll talk about what might be more realistic ways to simulate a mathematician. But first I want to talk about two important arguments which both suggest that doing that might be impossible even in principle.</p>\n<h1 id=\"3__G_delian_arguments_against_AI\">3. G\u00f6delian arguments against AI</h1>\n<p><span style=\"white-space:pre\"> </span>In 1936, mathematician Alan Turing described a certain kind of theoretical machine called a Turing machine, which can be thought of as a theoretical model for a programmable digital computer. (That\u2019s anachronistic, because Turing\u2019s paper came before modern digital computers, but that\u2019s probably the easiest way to explain the idea to a modern audience.)&nbsp;</p>\n<p>Turing proved that some Turing machines can can act as universal Turing machines, meaning that with the right program they can simulate any other Turing machine, which amounts to being able to do anything any Turing machine can do. (Notice the parallel to the worker-simulation thought-experiment.)</p>\n<p>The fact that a universal Turing machine can do anything any Turing machine can do helps explain why modern computers are so wonderfully flexible. Note, however, that when we talk about what Turing machines can do, generally we\u2019re only saying what they can do in some arbitrary but finite amount of time, not what they can do in a reasonable amount of time. So there are some things that modern computers can\u2019t do because they aren\u2019t fast enough. And again, you need the right program, and in some cases we haven\u2019t solved the programming problem.</p>\n<p>Furthermore, there are some limitations to what Turing machines can do even in principle. \u201cIn principle\u201d here means \u201cwith some finite amount of time and the right program.\u201d G\u00f6del's theorem shows that for any consistent formal system as powerful as basic arithmetic, there will always be some statement that can\u2019t be proven in the system. Since Turing machines are logically equivalent to formal systems, this limitation applies to Turing machines as well. This leads to the argument that the human mind doesn\u2019t have this limitation and therefore can\u2019t be a Turing machine.</p>\n<p>Turing (1950) considered and rejected this argument in his paper \u201cComputing Machinery and Intelligence,\u201d which is famous for having proposed the \u201cTuring test\u201d of whether a particular machine can think. Turing called this argument \u201cthe mathematical objection.\u201d Later, John Lucas (1961) defended the argument in a paper where he wrote:</p>\n<blockquote>\n<p>G\u00f6del's theorem must apply to cybernetical machines, because it is of the essence of being a machine, that it should be a concrete instantiation of a formal system. It follows that given any machine which is consistent and capable of doing simple arithmetic, there is a formula which it is incapable of producing as being true---i.e., the formula is unprovable-in-the-system-but which we can see to be true. It follows that no machine can be a complete or adequate model of the mind, that minds are essentially different from machines.</p>\n</blockquote>\n<p>This argument makes a number of assumptions. Since G\u00f6del's theorem only applies to consistent formal systems, we must assume that if the mind is a formal system, it is &nbsp;consistent. Also, since different formal systems have different statements which they can\u2019t prove, it isn\u2019t enough to to say we can see the truth of some statements that certain formal systems can\u2019t prove. It has to be the case that for any formal system, we will be able to see the truth of at least one statement the system can\u2019t prove. Finally, Lucas implicitly assumes that if the mind is a formal systems, then our \u201cseeing\u201d a statement to be true involves the statement being proved in that formal system.</p>\n<p>These assumptions can all be challenged, and Lucas responds to some of the possible challenges. In particular, he spends quite a bit of time arguing that the fact that humans make mistakes does not mean we could be represented by an inconsistent formal system.</p>\n<p>After Lucas\u2019 original article, similar arguments against the possibility of AI were defended by Roger Penrose in his books The Emperor\u2019s New Mind and Shadows of the Mind, and also in a response to critics published in the online journal Psyche.</p>\n<p>Many of the criticisms of Penrose published in Psyche are worth reading, particularly the one by Chalmers (1995). But I\u2019m not going to recap the entire debate because I don\u2019t have much to say about it that hasn\u2019t already been said. Instead, I\u2019m just going to comment on one thing Penrose does in his reply in Psyche (Penrose 1996).</p>\n<p>Penrose emphasizes that he\u2019s interested in whether there could ever be a formal system that, \u201cencapsulates all the humanly accessible methods of mathematical proof.\u201d In response to the point that humans make mistakes, he says:</p>\n<blockquote>\n<p>I fully accept that individual mathematicians can frequently make errors, as do human beings in many other activities of their lives. This is not the point. Mathematical errors are in principle correctable, and I was concerned mainly with the ideal of what can indeed be perceived in principle by mathematical understanding and insight... The arguments given above... were also concerned with this ideal notion only. The position that I have been strongly arguing for is that this ideal notion of human mathematical understanding is something beyond computation.</p>\n</blockquote>\n<p>Even if Penrose were right about this, it\u2019s not clear that this would mean that simulation of individual humans is impossible. A simulation doesn\u2019t have to claim to encapsulate \u201call the humanly accessible methods of mathematical proof\u201d; it just needs to be a good simulation of an individual mathematician. It doesn\u2019t even need to say anything directly about mathematics. To use the implausible thought-experiment, it might only talk about the subatomic particles that make up the mathematician.</p>\n<p>This is John Searle\u2019s (1997) response to Penrose, except that instead of subatomic particles, Searle imagines that the simulation would refer to things like neurotransmitters and synaptic clefts and cell assemblies, which is probably a more realistic assumption. (Again, more on the more realistic assumptions later.)</p>\n<h1 id=\"4__Could_the_brain_be_a_hypercomputer_\">4. Could the brain be a hypercomputer?</h1>\n<p>Another line of thought that\u2019s somewhat similar to G\u00f6delian arguments against AI comes from the philosophers Diane Proudfoot and Jack Copeland, who in 1999 coined the term \u201chypercomputation\u201d to refer to the idea that it might be possible to build a machine that\u2019s similar to a modern computer but which can do things no Turing machine can do (Copeland 2000).&nbsp;</p>\n<p>In a sense, we already know how to build some kinds of machines like this. Strictly speaking, Turing machines are defined to be deterministic; there\u2019s no random element. But if you wanted to, you could build a device that generates truly random numbers by measuring the decay of a nuclear isotope, and then have a computer use the measurement in calculations. You could get a similar effect with a device that measures atmospheric noise (which is the method used by the website Random.org).</p>\n<p>There are some situations where a random element like that might be useful, mainly because you want to keep other people from predicting how exactly your computer will behave (think slot machines or generating encryption keys). For the same reason, it wouldn\u2019t be surprising if humans and other animals had evolved to have a random element in their behavior.</p>\n<p>But as Turing himself pointed out, it\u2019s possible to write a program that isn\u2019t really random but merely appears random (Copeland 2000). Today, such programs are known as pseudo-random number generators and many programming languages have one built in. If you\u2019re just learning programming, one exercise worth trying is to write a program that somehow uses the random number generator, like a simulated dice roller. Its behavior should appear random the first time you run the program, but depending on how you\u2019ve written it, it may do exactly the same thing the second time your run it.</p>\n<p>There are some well-known arguments from neuroscience that are supposed to show individual quantum events can\u2019t play much of a role in the brain (Tegmark 2000), so it may be that human behavior has evolved to sometimes appear partly random using something like a pseudo-random number generator rather than genuine quantum randomness. In any case, the point is that even if human behavior included a genuinely random element--or even a non-deterministic form of free will that looks random from the outside, if you believe in such things--the point is we already know how to build machines that can simulate that.</p>\n<p>Some things, however, can\u2019t be done by any machine we know how to build. Famously, the formal definition of a Turing machine allows the machine to sometimes \u201chalt,\u201d and there\u2019s no way to make a Turing machine that will look at a program for simulating any other Turing machine and determine whether the other machine will halt. This is known as the halting problem, and we don\u2019t know how to build any machine that could solve it. And it\u2019s this sense of hypercomputation, of machines with abilities beyond those of any machines we know how to build, that\u2019s most interesting.</p>\n<p>Unlike Penrose, Proudfoot and Copeland don\u2019t claim to know that the brain does anything Turing machine\u2019s can\u2019t, but Copeland (2000) treats this as an important possibility, and they\u2019ve claimed as recently as last year that \u201cit remains unknown, however, whether hypercomputation is permitted or excluded by real-world physics\u201d (Proudfoot and Copeland 2012). So they\u2019re claiming it might be true that computers as we know them today are in principle incapable of simulating a human, but they\u2019re not claiming that\u2019s definitely true. They don\u2019t think we know.&nbsp;</p>\n<p>They do, however, assume that whatever humans do, we do through physical means, which means that if humans do hypercomputation, then it should also be possible to build a physical device that does hypercomputation. Of course, since we have no idea how to do that right now, humans doing hypercomputation would put full simulation of human beings a lot further off into the future.</p>\n<p>While I don\u2019t know of any arguments that show that our current understanding of physics totally rules out hypercomputation, there seems to be a tendency for proposals for hypercomputation to rely on implausible physical assumptions, especially when applied to the brain. For example, if you could somehow get access to infinite time, you could find out if any Turing machine halts by running it for an infinite length of time and seeing what happens. It\u2019s been suggested that the theory of relativity could allow spacetime to be bent in a way that gives you the necessary infinite time (Ord 2006). Whether or not that\u2019s actually possible, though, it seems unlikely that our brains bend spacetime in that way.</p>\n<p>Similarly, there are some theoretical proposals for how an analog computer (as opposed to a digital computer, which is what modern computers are) might be able to do things like solve the halting problem, and it\u2019s sometimes suggested that since the brain is analog, maybe the brain can do things like solve the halting problem. But these proposals tend to assume a device with unlimited precision (Cotogno 2003, Davis 2004, Ord 2006). It\u2019s not clear that it\u2019s physically possible to build a device with unlimited precision, and there\u2019s good reason to think the brain\u2019s precision is limited. Chris Eliasmith (2001) cites an estimate that \u201cneurons tend to encode approximately 3-7 bits of information per spike,\u201d which is less than a single byte.</p>\n<h1 id=\"5__Hardware_and_software_issues\">5. Hardware and software issues</h1>\n<p>I\u2019ve been arguing that it\u2019s probably possible, in principle, to simulate mathematicians and philosophers and so on using the kinds of devices we already know how to build. Again, by \u201cin principle\u201d I mean not ruled out by the kind of philosophical and mathematical objections I\u2019ve been talking about; possible with enough time and storage and with the right program. Since in the real world, it\u2019s easier to design faster hardware than it is to design more time, it\u2019s helpful to rephrase what I just said as, \u201cwhat computers can do with powerful enough hardware and the right software.\u201d</p>\n<p>Maybe you think the hardware and software issues with AI were the real issues all along. However, if on the one hand you think we\u2019ll never replace human mathematicians with computers, but on the other hand you don\u2019t think that because of any in principle objection like some version of the G\u00f6delian argument, it\u2019s worth being clear about that.</p>\n<p>It\u2019s less clear what philosophers can say about hardware and software issues, but I\u2019ll mention a few things. As I\u2019ve said, simulating a human being at the level of subatomic particles is unlikely to ever be practical, but it\u2019s also unlikely to ever be necessary. As I\u2019ve also noted, individual quantum events probably don\u2019t play an important role in the brain. The behavior of any individual molecule or ion is also unlikely to matter; events in the brain generally involve too many molecules and ions for the behavior of any one of them to matter.</p>\n<p>So there\u2019s a limit to how much detail a simulation of an actual brain would need. Where exactly that limit is is unclear; Anders Sandberg and Nick Bostrom (2008) have a paper where they list some possibilities. This approach to simulation would require a simulated body and simulated environment, but level of detail required for those would probably be much less than the level of detail required for the brain. Also, for the purposes of replacing particular human workers with computer programs, it wouldn\u2019t be necessary to simulate the inner workings of the brain closely at all. What matters is simulating the outward behavior, and maybe you could do that through something like machine learning algorithms trained on actual human behavior.</p>\n<p>So the hardware requirements for a mathematician simulation wouldn\u2019t be quite as large as it might have seemed, but they could still be very large. So can we meet them? The rapid improvements in hardware that we\u2019re all used to by now have relied on making transistors smaller and smaller, but we\u2019ll reach a point where the size of transistors is measured in atoms and we can\u2019t do that anymore. There are some suggestions for how we might continue making improvements in computer hardware even after we reach that point (Sandberg and Bostrom 2008), but I\u2019m not the right person to evaluate them.</p>\n<p>Even if we develop powerful enough hardware and the software is out there somewhere in the space of all possible software, maybe we\u2019ll never find the software because searching that space of possible software will turn out to be too hard. One thing to say about this is that people in robotics and AI have realized that it\u2019s easy to for computers to beat humans at things we didn\u2019t evolve to do, like arithmetic, but hard for computers to beat humans at things we did evolve to do, like walking upright (Moravec 1988, Pinker 1997).&nbsp;</p>\n<p>That suggests getting computers to do everything humans do is going to be difficult, but at least there\u2019s a non-mysterious reason for the difficulty (because humans have evolved over millions of years to be really good at certain things without even realizing how good we are). It also suggests that there\u2019s a limit to how hard getting computers to do everything humans do can be, because evolution produced humans just by going at the blind process of natural selection for a long enough period of time.</p>\n<p>However, there is the possibility that humans are a fluke. Maybe you only get something like human brains once for every million or more planets where something like mammal brains have already developed. So maybe building things like humans is harder than a first-glance evolutionary argument would suggest. Nick Bostrom has a paper discussing that issue in greater depth (Shulman and Bostrom 2012).</p>\n<p>Finally, I\u2019ve focused on the ability of computers to take over human jobs, but that shouldn\u2019t be interpreted as a claim that that\u2019s going to be the most important effect of advances in AI. If computers become able to take over the vast majority of human jobs, there may be much bigger consequences than just unemployment (Hanson 2008, Muehlhauser and Salamon forthcoming). But that\u2019s a topic for another day.</p>\n<h1 id=\"Bibliography\">Bibliography</h1>\n<p>Chalmers, D. (1995). \u201cMinds, Machines, and Mathematics.\u201d Psyche, 2: 11-20.&nbsp;</p>\n<p>---- (1996). The Conscious Mind: In Search of a Fundamental Theory. Oxford University Press.</p>\n<p>---- (2010). \u201cThe Singularity: A Philosophical Analysis.\u201d Journal of Consciousness Studies, 17: 7-65.</p>\n<p>Copeland, B. J. (2000). \u201cNarrow Versus Wide Mechanism.\u201d Journal of Philosophy, 96: 5-32.</p>\n<p>Cotogno, P. (2003). \"Hypercomputation and the Physical Church-Turing Thesis,\" British Journal for the Philosophy of Science, 54 (2): 181-224.</p>\n<p>Davis, M. (2004). \u201cThe Myth of Hypercomputation.\u201d in C. Teuscher (ed.) Alan Turing: Life and legacy of a great thinker. Springer, 195-212.</p>\n<p>Dennett, D. (1981). \u201cReflections,\u201d in D. Hofstadter and D. Dennett, The Mind\u2019s I: Fantasies and Reflections on Self and Soul. Bantam Books, 92-95.</p>\n<p>Doctorow, C. (2011). \u201cUntouched By Human Hands.\u201d MAKE, 25: 16.</p>\n<p>Dreyfus, H. (1992). What Computers Still Can\u2019t Do: A Critique of Artificial Reason. MIT Press.</p>\n<p>Eliasmith, C. (2001). \u201cAttractive and in-discrete: A critique of two putative virtues of the dynamicist theory of mind.\u201d Minds and Machines, 11: 417-426.</p>\n<p>Hanson, R. (2008). \u201cEconomics of the Singularity.\u201d Spectrum, IEEE, 45 (6): 45-50.</p>\n<p>Horst, S. (2011). \u201cThe Computational Theory of Mind\u201d, in E. N. Zalta (ed.) The Stanford Encyclopedia of Philosophy (Spring 2011 Edition). URL: http://plato.stanford.edu/archives/sum2010/entries/functionalism/.</p>\n<p>Levin, J. (2010). \u201cFunctionalism\u201d, in E. N. Zalta (ed.) The Stanford Encyclopedia of Philosophy (Summer 2010 Edition). URL: http://plato.stanford.edu/archives/sum2010/entries/functionalism/.</p>\n<p>Lucas, J. (1961). \u201cMinds, Machines, and G\u00f6del.\u201d Philosophy, 36: 112-127.</p>\n<p>Moravec, H. (1988). Mind Children: The Future of Robot and Human Intelligence. Harvard University Press.&nbsp;</p>\n<p>Muehlhauser, L. and A. Salamon. (forthcoming). In A. Eden, J. S\u00f8raker, J. H. Moor, and E. Steinhart (ed.) Singularity Hypotheses: A scientific and philosophical assessment. Springer.</p>\n<p>Nilsson, N. (2005). \u201cHuman-Level Artificial Intelligence? Be Serious!\u201d&nbsp;</p>\n<p>Ord, T. (2006). \u201cThe Many Forms of Hypercomputation.\u201d Applied Mathematics and Computation, 178: 143-153.</p>\n<p>Penrose, R. (1996). \u201cBeyond the Doubting of a Shadow.\u201d Psyche 2.</p>\n<p>Pinker, S. (1997). How the Mind Works. W. W. Norton &amp; Company.</p>\n<p>Proudfoot, D. and B. J. Copeland. (2012). \u201cArtificial Intelligence,\u201d in E. Margolis, R. Samuels, and S. Stich (ed.) The Oxford Handbook of Philosophy of Cognitive Science. Oxford University Press.</p>\n<p>Putnam, H. (1980). \u201cPhilosophy and our mental life\u201d, in Ned Block (ed.) Readings in the Philosophy of Psychology, Volume 1, 134-143.</p>\n<p>Sandberg, A. and N. Bostrom. (2008). Whole Brain Emulation: A Roadmap, Technical Report #2008\u20103, Future of Humanity Institute, Oxford University.</p>\n<p>Searle, J. (1980). \u201cMinds, Brains, and Programs.\u201d Behavioral and Brain Sciences, 3 (3): 433-460.</p>\n<p>---- (1997). The Mystery of Consciousness. The New York Review of Books.</p>\n<p>Shulman, C. and N. Bostrom. (2012). \u201cHow Hard is Artificial Intelligence? Evolutionary Arguments and Selection Effects.\u201d Journal of Consciousness Studies, 19: 103-130.</p>\n<p>Tegmark, M. (2000). \"Importance of quantum decoherence in brain processes.\" Physical Review E, 61 (4): 4194\u20134206.</p>\n<p>Turing, A. (1950). \u201cComputing Machinery and Intelligence.\u201d Mind, 49: 433-460.</p>", "sections": [{"title": "1. What a simulation could do", "anchor": "1__What_a_simulation_could_do", "level": 1}, {"title": "2. Simulation and philosophy of mind", "anchor": "2__Simulation_and_philosophy_of_mind", "level": 1}, {"title": "3. G\u00f6delian arguments against AI", "anchor": "3__G_delian_arguments_against_AI", "level": 1}, {"title": "4. Could the brain be a hypercomputer?", "anchor": "4__Could_the_brain_be_a_hypercomputer_", "level": 1}, {"title": "5. Hardware and software issues", "anchor": "5__Hardware_and_software_issues", "level": 1}, {"title": "Bibliography", "anchor": "Bibliography", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "14 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-25T00:58:11.748Z", "modifiedAt": null, "url": null, "title": "Being Foreign and Being Sane ", "slug": "being-foreign-and-being-sane", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:56.700Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fowlertm", "createdAt": "2012-01-07T20:35:26.490Z", "isAdmin": false, "displayName": "fowlertm"}, "userId": "gDAt4FezxH8dDr5EY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RgKAFasnPmPZ2kBps/being-foreign-and-being-sane", "pageUrlRelative": "/posts/RgKAFasnPmPZ2kBps/being-foreign-and-being-sane", "linkUrl": "https://www.lesswrong.com/posts/RgKAFasnPmPZ2kBps/being-foreign-and-being-sane", "postedAtFormatted": "Saturday, May 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Being%20Foreign%20and%20Being%20Sane%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeing%20Foreign%20and%20Being%20Sane%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRgKAFasnPmPZ2kBps%2Fbeing-foreign-and-being-sane%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Being%20Foreign%20and%20Being%20Sane%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRgKAFasnPmPZ2kBps%2Fbeing-foreign-and-being-sane", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRgKAFasnPmPZ2kBps%2Fbeing-foreign-and-being-sane", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2202, "htmlBody": "<p>I've been reading Less Wrong for a while now, and have recently been casting about for suitable topics to write on. &nbsp;I've decided to break the ice now with an essay on what living and working abroad in Korea has taught me which carries over into studying rationality. &nbsp;While more personal than technical, this inaugural post contains generalizable lessons that I think will be of interest to anyone trying to improve their thinking. &nbsp;</p>\n<p>You may be skeptical, so let me briefly make my case that traveling offers something to the aspiring rationalist. &nbsp;Many have written about the benefits of traveling, but for our purposes here is what matters:</p>\n<p><strong>Being abroad can make certain important concepts in rationality a part of you in ways studying can't match</strong>.</p>\n<p>It's easy to read -- and to <em>really believe</em>&nbsp;-- that the map is not the territory, say, without it changing how you actually act. Information often gathers dust on the shelves in your frontal lobe without ever making it into the largely unconscious bits of your brain where so much of your deciding&nbsp;takes place<em>. &nbsp;</em></p>\n<p>With this in mind travel can be seen as part of the class of efforts to learn rationality without directly studying the science, instead doing something like playing&nbsp;<a href=\"/lw/2m6/rationality_lessons_in_the_game_of_go/\">Go</a>&nbsp;or <a href=\"/lw/4yk/verifying_rationality_via_rationalpokercom/\">poker</a>, for example. &nbsp; I don't know for sure, but such efforts could hold the promise of teaching us to incorporate insights into emotional attachment, statistical probabilities, strategy, maximizing utility, and the like -- things we've <em>known</em> for a long time -- into our instincts, deep down where they can actually change how we behave. &nbsp;</p>\n<p>I say all this because what living in a foreign country has given me is not so much a software update which has remade me into a paragon of rationality, but rather a hearty appreciation for certain facts which might make my thought-improvement efforts more fruitful. &nbsp;No doubt many of you have already long-ago internalized all of this, and for you I won't be saying anything very profound. &nbsp;</p>\n<p>Nevertheless, here is what I've learned:</p>\n<p>&nbsp;</p>\n<p><strong>1) You are vastly more complicated than you think you are. &nbsp;</strong></p>\n<p><strong><br /></strong></p>\n<p>The proposal for the Dartmouth conference of 1956, considered by some to be the birth of the field of AI research, had <a href=\"http://en.wikipedia.org/wiki/Dartmouth_Conferences\">this </a>to say:</p>\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"font-family: Times; font-size: medium;\">An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.</span></p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Not to deny that considerable progress has been made in the past half century, but I think we can all agree that this thinking was just a tad bit optimistic. &nbsp;</p>\n<p>I'm not an expert on AI research history, but it seems reasonable to assume that these proto-AI researchers perhaps didn't appreciate how complex humans are. &nbsp;You look at a triangle and you see a triangle; you reach for a coffee cup and grasp it; you start speaking a sentence and finish it with only the occasional pause. &nbsp;What could be simpler? &nbsp;We all forget our car keys sometimes, and some of us know a little bit about bizarre neurological problems like aphasia, but still. &nbsp;In general we function so well that it never occurs to us that the things we do might actually be difficult to implement. &nbsp; &nbsp;</p>\n<p>The problem runs deeper than this, though, because there doesn't seem to be much in the way of techniques for elucidating this complexity from the inside. &nbsp;If there were, neuroscience might've been discovered a millennium ago in East Asia by Buddhist adepts. &nbsp;But instead our efforts at aiming the introspective flashlights on the machinery of our minds are thwarted by their presence totally outside our conscious awareness. &nbsp; &nbsp;</p>\n<p>Well, if you ever feel like you're not fully appreciating the intricacies of your wetware, sit in a coffee shop or bus stop in a foreign country while eavesdropping on people whose effortless bantering <em>could not be more inscrutable, </em>and you'll have it impressed upon you<em>.&nbsp;</em>Alternatively, try to explain to someone with little-to-no English knowledge what something like \"simple\" or \"almost all of\" means. &nbsp;&nbsp;Even without a bit of neuroscience training you'll start to get a grasp on the vastness of the gears and levers that make every utterance possible. &nbsp;</p>\n<p>This insight, at least for me, seems to creep into the rest of your thinking life, though in my case it's hard to tell because I've always pondered things like this. &nbsp;It isn't a far leap from here to see the potential value of research into topics like Friendly AI. If human language and vision are complicated, what are the chances that human value systems are simple? &nbsp;If you didn't manage to notice your retinal blind spot or the mechanisms by which you conjugate verbs in your native tongue, what are the chances that you aren't at least a little mistaken about your true goals and desires and how best to achieve them? &nbsp;Exactly. &nbsp;So maybe it's time to start reading those sequences, eh? &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>2)</strong>&nbsp;<strong>Don't be bewitched by words</strong></p>\n<p>&nbsp;</p>\n<p>Obviously if you go to a country where English or a different language you're already fluent in is spoken, this won't apply as much. But my experience has shown me that living in and learning a foreign language bestows several valuable insights on those intrepid enough to stick with it. &nbsp;Simply put, a sufficiently reflective and intelligent person could independently figure out about half of the sequence <a href=\"http://wiki.lesswrong.com/wiki/A_Human%27s_Guide_to_Words\">A Human's Guide to Words</a>&nbsp;just by being in a foreign country and thinking about the experience. &nbsp;</p>\n<p>First you'd have to go through the shocking revelation that so much of what you say is a fairly arbitrary set of language conventions, and then you'd begin to relearn how to communicate. &nbsp;You'd come to realize that <a href=\"/lw/o9/words_as_mental_paintbrush_handles/\">words are mental paintbrush handles</a>&nbsp;with which you guide the attention of other humans to certain <a href=\"/lw/nl/the_cluster_structure_of_thingspace/\">clusters in thingspace</a>, and that they are often <a href=\"/lw/nm/disguised_queries/\">disgusied queries</a> with <a href=\"/lw/ny/sneaking_in_connotations/\">hidden connotations</a>.&nbsp; This will be triply reinforced by the fact that you'd often have to resort to empiricism to get your point across - accompanying the word 'red' or 'chair' by actually point to red things or chairs. &nbsp;If you're spending time with natives the inverse will happen, and they will have to point to the parts of the world that words <em>represent</em>&nbsp;to communicate. You'll have a head start in <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">replacing the symbol with the substance</a> because you'll be <a href=\"/lw/nu/taboo_your_words/\">playing taboo</a> with nearly every word you know. &nbsp;Since you'll be doing this with low-level language, it'll require elbow grease to port this into your native tongue when discussing topics like free will. &nbsp;But if you can avoid slipping into <a href=\"/lw/k5/cached_thoughts/\">cached thoughts</a>, the training you received when you were a foreigner will likely prove useful. &nbsp;&nbsp;</p>\n<p>Beyond this, however, is the tantalizing possibility that we may be <a href=\"http://www.wired.com/wiredscience/2012/04/language-and-bias/\">more</a>&nbsp;<a href=\"http://pss.sagepub.com/content/early/2012/04/18/0956797611432178\">rational </a>when we think in a foreign language, perhaps because it increases reliance on the slow, analytic System 2 at the expense of the rapid-fire, emotional System 1. Psychologists from the University of Chicago tested this idea using English speakers proficient in Japanese, Korean speakers proficient in English, and English speakers proficient in French (Keysar, hayakawa, &amp; An, 2011) [NOTE: I'm aware this study <a href=\"/lw/el0/thinking_in_another_language_could_reduce_biases/\">has</a> <a href=\"/lw/c2b/thinking_in_a_foreign_language_reduces_risk/\">been</a><a href=\"/lw/da3/framing_a_problem_in_a_foreign_language_seems_to/\"> mentioned</a>&nbsp;<a href=\"/lw/bxn/learn_a_foreign_language_to_reduce_bias/\">before</a>&nbsp;on Less Wrong, but I believe this is the first actual discussion of the experiment and its methodology]. In the first few experiments participants were randomly sorted into two groups, one of which was given a test in their native language and one of which was given a test in the foreign language. &nbsp;These tests were designed to elicit a well-known tendency for humans to differ in their risk preference depending on how the situation is framed. &nbsp;</p>\n<p>Here's how it works: imagine that you turn on the news today to find out that an exotic new disease is ravaging Asia, with an expected final death toll of 600,000. &nbsp;The governments of the world decided that the best solution would be to design two separate drugs, and then to randomly select one reader of Less Wrong to decide between the two. &nbsp;Your number came up, and now you have a choice to make. &nbsp;</p>\n<p>Drug A is guaranteed to save 200,000 people. &nbsp;Drug B has a 33% chance of saving everyone and a 66% chance of saving no one. &nbsp;</p>\n<p>This is called the gain-framing, because what's emphasized is how many lives you'll <em>save</em>, or gain. &nbsp;When framed this way, people often prefer to administer Drug A. &nbsp;But studies find that if the same problem is loss-framed - that is, with drug A it is guaranteed that 400,000 people die while with Drug B there is a 33% chance that no one will die and a 66% that everyone will - far fewer people prefer Drug A, even though the results of using the drugs are identical.</p>\n<p>Besides being sorted by foreign language participants were also randomly sorted by whether or not they got the gain or loss framing. Participants tested in their native language showed the predicted bias, but when tested in the foreign language, about an equal number of people preferred Drug A and Drug B.</p>\n<p>An additional study found the same effect of foreign language on reasoning, but using a different bias. &nbsp;People tend to be loss averse, preferring to avoid a loss more than they prefer to gain an identical (or slightly better) amount. &nbsp;This means that people will often turn down an even bet which holds the possibility of gaining $12 and the possibility of losing $10, even though this bet has positive expected value. &nbsp;As with the other studies, Korean speakers proficient in English more often showed this tendency when reasoning in their native language than when reasoning in a foreign one, especially for larger bets. &nbsp;</p>\n<p>There are a million reasons to learn a foreign language, but it'd be a very costly way to improve rationality. &nbsp;With that said, for anyone willing to invest the time and effort, better thinking could be the outcome. &nbsp;But even if you don't go to the trouble, simply trying to communicate with people who don't speak the same language as you will teach you a lot about how cognition and communication work. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>3) The Zen of the Unfamiliar</strong></p>\n<p><strong><br /></strong></p>\n<p>Living in another culture can make you aware of so many things that you previously failed to notice at all. &nbsp;I remember not long after I got to Korea, I was in my kitchen and noticed that my sink was different from any of the ones I'd seen back in the States. &nbsp;It was a single open pit sunk into the counter, with a strange spinning mechanism where the drain usually is. &nbsp;After investigating for a while, I realized two things: one, the spinning mechanism was actually a multi-part contraption meant to catch food before it went down the drain (no idea why it could spin) and two, I'd just spend 100 times longer thinking about sinks than I had in the rest of my life combined. &nbsp;</p>\n<p>To successfully live in a foreign country you'll have to master the art of noticing things fairly quickly. &nbsp;You'll start to watch how people dress, how they talk, how close they stand to each other, the relative frequency of eye contact, how they chew their food, what order people get served drinks. &nbsp;You'll learn to read the environment to learn where to stand in line, where to catch the bus, where and how to buy things, which door is the exit and which one the entrance, whether or not certain places are likely to be safe, etc. &nbsp;</p>\n<p>You'll accomplish most of this by gathering evidence, forming hypotheses, using induction and deduction, and updating on new evidence. &nbsp;The things you've been reading about on Less Wrong will be put to use in finding food and shelter, the tools of rationality will be your compass in a world where you can't read what's written on signs or buildings and most people can't understand your questions. &nbsp;So there's a box on your wall with three buttons, two dials, a bunch of lights, and you're pretty sure it can make hot water come out of the shower? &nbsp;Not a word of English anywhere on it, you say? &nbsp;Well then you'll have to change one variable at a time and take note of the results, like any good scientist would. &nbsp;</p>\n<p>Being immersed in a set of shared cultural and linguistic norms that you don't understand makes almost every aspect of your life an experiment. &nbsp;It's exhausting, and one of the most informative experiences I've ever had. &nbsp;On an emotional level, it will teach you to be more at ease with partial understanding, frustration, and confusion. &nbsp;With your comfort zone an ocean away, you'll either persevere and think on your feet, or you'll end up sleeping in the rain. &nbsp;</p>\n<p>&nbsp;</p>\n<p>__</p>\n<p>&nbsp;</p>\n<p>Like with learning a foreign language, there are many reasons to travel abroad and experience another culture. &nbsp;And of course, a plane ticket alone is not enough to make you a better thinker. &nbsp;But if you know what to look for and are actively seeking to grow from the experience, I can attest that being foreign for a little while is one way to become a bit more sane. &nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"o4rMP6GJto7ccBL3a": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RgKAFasnPmPZ2kBps", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 35, "extendedScore": null, "score": 1.2100813757820674e-06, "legacy": true, "legacyId": "18088", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I've been reading Less Wrong for a while now, and have recently been casting about for suitable topics to write on. &nbsp;I've decided to break the ice now with an essay on what living and working abroad in Korea has taught me which carries over into studying rationality. &nbsp;While more personal than technical, this inaugural post contains generalizable lessons that I think will be of interest to anyone trying to improve their thinking. &nbsp;</p>\n<p>You may be skeptical, so let me briefly make my case that traveling offers something to the aspiring rationalist. &nbsp;Many have written about the benefits of traveling, but for our purposes here is what matters:</p>\n<p><strong>Being abroad can make certain important concepts in rationality a part of you in ways studying can't match</strong>.</p>\n<p>It's easy to read -- and to <em>really believe</em>&nbsp;-- that the map is not the territory, say, without it changing how you actually act. Information often gathers dust on the shelves in your frontal lobe without ever making it into the largely unconscious bits of your brain where so much of your deciding&nbsp;takes place<em>. &nbsp;</em></p>\n<p>With this in mind travel can be seen as part of the class of efforts to learn rationality without directly studying the science, instead doing something like playing&nbsp;<a href=\"/lw/2m6/rationality_lessons_in_the_game_of_go/\">Go</a>&nbsp;or <a href=\"/lw/4yk/verifying_rationality_via_rationalpokercom/\">poker</a>, for example. &nbsp; I don't know for sure, but such efforts could hold the promise of teaching us to incorporate insights into emotional attachment, statistical probabilities, strategy, maximizing utility, and the like -- things we've <em>known</em> for a long time -- into our instincts, deep down where they can actually change how we behave. &nbsp;</p>\n<p>I say all this because what living in a foreign country has given me is not so much a software update which has remade me into a paragon of rationality, but rather a hearty appreciation for certain facts which might make my thought-improvement efforts more fruitful. &nbsp;No doubt many of you have already long-ago internalized all of this, and for you I won't be saying anything very profound. &nbsp;</p>\n<p>Nevertheless, here is what I've learned:</p>\n<p>&nbsp;</p>\n<p><strong id=\"1__You_are_vastly_more_complicated_than_you_think_you_are___\">1) You are vastly more complicated than you think you are. &nbsp;</strong></p>\n<p><strong><br></strong></p>\n<p>The proposal for the Dartmouth conference of 1956, considered by some to be the birth of the field of AI research, had <a href=\"http://en.wikipedia.org/wiki/Dartmouth_Conferences\">this </a>to say:</p>\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"font-family: Times; font-size: medium;\">An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.</span></p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Not to deny that considerable progress has been made in the past half century, but I think we can all agree that this thinking was just a tad bit optimistic. &nbsp;</p>\n<p>I'm not an expert on AI research history, but it seems reasonable to assume that these proto-AI researchers perhaps didn't appreciate how complex humans are. &nbsp;You look at a triangle and you see a triangle; you reach for a coffee cup and grasp it; you start speaking a sentence and finish it with only the occasional pause. &nbsp;What could be simpler? &nbsp;We all forget our car keys sometimes, and some of us know a little bit about bizarre neurological problems like aphasia, but still. &nbsp;In general we function so well that it never occurs to us that the things we do might actually be difficult to implement. &nbsp; &nbsp;</p>\n<p>The problem runs deeper than this, though, because there doesn't seem to be much in the way of techniques for elucidating this complexity from the inside. &nbsp;If there were, neuroscience might've been discovered a millennium ago in East Asia by Buddhist adepts. &nbsp;But instead our efforts at aiming the introspective flashlights on the machinery of our minds are thwarted by their presence totally outside our conscious awareness. &nbsp; &nbsp;</p>\n<p>Well, if you ever feel like you're not fully appreciating the intricacies of your wetware, sit in a coffee shop or bus stop in a foreign country while eavesdropping on people whose effortless bantering <em>could not be more inscrutable, </em>and you'll have it impressed upon you<em>.&nbsp;</em>Alternatively, try to explain to someone with little-to-no English knowledge what something like \"simple\" or \"almost all of\" means. &nbsp;&nbsp;Even without a bit of neuroscience training you'll start to get a grasp on the vastness of the gears and levers that make every utterance possible. &nbsp;</p>\n<p>This insight, at least for me, seems to creep into the rest of your thinking life, though in my case it's hard to tell because I've always pondered things like this. &nbsp;It isn't a far leap from here to see the potential value of research into topics like Friendly AI. If human language and vision are complicated, what are the chances that human value systems are simple? &nbsp;If you didn't manage to notice your retinal blind spot or the mechanisms by which you conjugate verbs in your native tongue, what are the chances that you aren't at least a little mistaken about your true goals and desires and how best to achieve them? &nbsp;Exactly. &nbsp;So maybe it's time to start reading those sequences, eh? &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>2)</strong>&nbsp;<strong>Don't be bewitched by words</strong></p>\n<p>&nbsp;</p>\n<p>Obviously if you go to a country where English or a different language you're already fluent in is spoken, this won't apply as much. But my experience has shown me that living in and learning a foreign language bestows several valuable insights on those intrepid enough to stick with it. &nbsp;Simply put, a sufficiently reflective and intelligent person could independently figure out about half of the sequence <a href=\"http://wiki.lesswrong.com/wiki/A_Human%27s_Guide_to_Words\">A Human's Guide to Words</a>&nbsp;just by being in a foreign country and thinking about the experience. &nbsp;</p>\n<p>First you'd have to go through the shocking revelation that so much of what you say is a fairly arbitrary set of language conventions, and then you'd begin to relearn how to communicate. &nbsp;You'd come to realize that <a href=\"/lw/o9/words_as_mental_paintbrush_handles/\">words are mental paintbrush handles</a>&nbsp;with which you guide the attention of other humans to certain <a href=\"/lw/nl/the_cluster_structure_of_thingspace/\">clusters in thingspace</a>, and that they are often <a href=\"/lw/nm/disguised_queries/\">disgusied queries</a> with <a href=\"/lw/ny/sneaking_in_connotations/\">hidden connotations</a>.&nbsp; This will be triply reinforced by the fact that you'd often have to resort to empiricism to get your point across - accompanying the word 'red' or 'chair' by actually point to red things or chairs. &nbsp;If you're spending time with natives the inverse will happen, and they will have to point to the parts of the world that words <em>represent</em>&nbsp;to communicate. You'll have a head start in <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">replacing the symbol with the substance</a> because you'll be <a href=\"/lw/nu/taboo_your_words/\">playing taboo</a> with nearly every word you know. &nbsp;Since you'll be doing this with low-level language, it'll require elbow grease to port this into your native tongue when discussing topics like free will. &nbsp;But if you can avoid slipping into <a href=\"/lw/k5/cached_thoughts/\">cached thoughts</a>, the training you received when you were a foreigner will likely prove useful. &nbsp;&nbsp;</p>\n<p>Beyond this, however, is the tantalizing possibility that we may be <a href=\"http://www.wired.com/wiredscience/2012/04/language-and-bias/\">more</a>&nbsp;<a href=\"http://pss.sagepub.com/content/early/2012/04/18/0956797611432178\">rational </a>when we think in a foreign language, perhaps because it increases reliance on the slow, analytic System 2 at the expense of the rapid-fire, emotional System 1. Psychologists from the University of Chicago tested this idea using English speakers proficient in Japanese, Korean speakers proficient in English, and English speakers proficient in French (Keysar, hayakawa, &amp; An, 2011) [NOTE: I'm aware this study <a href=\"/lw/el0/thinking_in_another_language_could_reduce_biases/\">has</a> <a href=\"/lw/c2b/thinking_in_a_foreign_language_reduces_risk/\">been</a><a href=\"/lw/da3/framing_a_problem_in_a_foreign_language_seems_to/\"> mentioned</a>&nbsp;<a href=\"/lw/bxn/learn_a_foreign_language_to_reduce_bias/\">before</a>&nbsp;on Less Wrong, but I believe this is the first actual discussion of the experiment and its methodology]. In the first few experiments participants were randomly sorted into two groups, one of which was given a test in their native language and one of which was given a test in the foreign language. &nbsp;These tests were designed to elicit a well-known tendency for humans to differ in their risk preference depending on how the situation is framed. &nbsp;</p>\n<p>Here's how it works: imagine that you turn on the news today to find out that an exotic new disease is ravaging Asia, with an expected final death toll of 600,000. &nbsp;The governments of the world decided that the best solution would be to design two separate drugs, and then to randomly select one reader of Less Wrong to decide between the two. &nbsp;Your number came up, and now you have a choice to make. &nbsp;</p>\n<p>Drug A is guaranteed to save 200,000 people. &nbsp;Drug B has a 33% chance of saving everyone and a 66% chance of saving no one. &nbsp;</p>\n<p>This is called the gain-framing, because what's emphasized is how many lives you'll <em>save</em>, or gain. &nbsp;When framed this way, people often prefer to administer Drug A. &nbsp;But studies find that if the same problem is loss-framed - that is, with drug A it is guaranteed that 400,000 people die while with Drug B there is a 33% chance that no one will die and a 66% that everyone will - far fewer people prefer Drug A, even though the results of using the drugs are identical.</p>\n<p>Besides being sorted by foreign language participants were also randomly sorted by whether or not they got the gain or loss framing. Participants tested in their native language showed the predicted bias, but when tested in the foreign language, about an equal number of people preferred Drug A and Drug B.</p>\n<p>An additional study found the same effect of foreign language on reasoning, but using a different bias. &nbsp;People tend to be loss averse, preferring to avoid a loss more than they prefer to gain an identical (or slightly better) amount. &nbsp;This means that people will often turn down an even bet which holds the possibility of gaining $12 and the possibility of losing $10, even though this bet has positive expected value. &nbsp;As with the other studies, Korean speakers proficient in English more often showed this tendency when reasoning in their native language than when reasoning in a foreign one, especially for larger bets. &nbsp;</p>\n<p>There are a million reasons to learn a foreign language, but it'd be a very costly way to improve rationality. &nbsp;With that said, for anyone willing to invest the time and effort, better thinking could be the outcome. &nbsp;But even if you don't go to the trouble, simply trying to communicate with people who don't speak the same language as you will teach you a lot about how cognition and communication work. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"3__The_Zen_of_the_Unfamiliar\">3) The Zen of the Unfamiliar</strong></p>\n<p><strong><br></strong></p>\n<p>Living in another culture can make you aware of so many things that you previously failed to notice at all. &nbsp;I remember not long after I got to Korea, I was in my kitchen and noticed that my sink was different from any of the ones I'd seen back in the States. &nbsp;It was a single open pit sunk into the counter, with a strange spinning mechanism where the drain usually is. &nbsp;After investigating for a while, I realized two things: one, the spinning mechanism was actually a multi-part contraption meant to catch food before it went down the drain (no idea why it could spin) and two, I'd just spend 100 times longer thinking about sinks than I had in the rest of my life combined. &nbsp;</p>\n<p>To successfully live in a foreign country you'll have to master the art of noticing things fairly quickly. &nbsp;You'll start to watch how people dress, how they talk, how close they stand to each other, the relative frequency of eye contact, how they chew their food, what order people get served drinks. &nbsp;You'll learn to read the environment to learn where to stand in line, where to catch the bus, where and how to buy things, which door is the exit and which one the entrance, whether or not certain places are likely to be safe, etc. &nbsp;</p>\n<p>You'll accomplish most of this by gathering evidence, forming hypotheses, using induction and deduction, and updating on new evidence. &nbsp;The things you've been reading about on Less Wrong will be put to use in finding food and shelter, the tools of rationality will be your compass in a world where you can't read what's written on signs or buildings and most people can't understand your questions. &nbsp;So there's a box on your wall with three buttons, two dials, a bunch of lights, and you're pretty sure it can make hot water come out of the shower? &nbsp;Not a word of English anywhere on it, you say? &nbsp;Well then you'll have to change one variable at a time and take note of the results, like any good scientist would. &nbsp;</p>\n<p>Being immersed in a set of shared cultural and linguistic norms that you don't understand makes almost every aspect of your life an experiment. &nbsp;It's exhausting, and one of the most informative experiences I've ever had. &nbsp;On an emotional level, it will teach you to be more at ease with partial understanding, frustration, and confusion. &nbsp;With your comfort zone an ocean away, you'll either persevere and think on your feet, or you'll end up sleeping in the rain. &nbsp;</p>\n<p>&nbsp;</p>\n<p>__</p>\n<p>&nbsp;</p>\n<p>Like with learning a foreign language, there are many reasons to travel abroad and experience another culture. &nbsp;And of course, a plane ticket alone is not enough to make you a better thinker. &nbsp;But if you know what to look for and are actively seeking to grow from the experience, I can attest that being foreign for a little while is one way to become a bit more sane. &nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "sections": [{"title": "1) You are vastly more complicated than you think you are. \u00a0", "anchor": "1__You_are_vastly_more_complicated_than_you_think_you_are___", "level": 1}, {"title": "3) The Zen of the Unfamiliar", "anchor": "3__The_Zen_of_the_Unfamiliar", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "42 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vJ8fo9FAPp3LbDKXu", "xjMDAtz5T3Ssz9Y7X", "YF9HB6cWCJrDK5pBM", "WBw8dDkAWohFjWQSk", "4FcxgdvdQP45D6Skg", "yuKaWPRTxZoov4z8K", "GKfPL6LQFgB49FEnv", "WBdvyyHLdxZSAMmoz", "2MD3NMLBPCqPfnfre", "HnL9ZWbDBrjSB23Xa", "xAahkgfRDm5pRzaKA", "oohAJqJx6fSito3ja", "eC3WyMspAwTfp8giv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}